public String getUrl()
{    return url;}
0
public void setUrl(String url)
{    this.url = url;}
0
public Map<String, String> getFunctions()
{    return functions;}
0
public void setFunctions(Map<String, String> functions)
{    this.functions = functions;}
0
public String toString()
{    return "Endpoint{" + "url='" + url + '\'' + ", functions=" + functions + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Endpoint endpoint = (Endpoint) o;    if (getUrl() != null ? !getUrl().equals(endpoint.getUrl()) : endpoint.getUrl() != null)        return false;    return getFunctions() != null ? getFunctions().equals(endpoint.getFunctions()) : endpoint.getFunctions() == null;}
0
public int hashCode()
{    int result = getUrl() != null ? getUrl().hashCode() : 0;    result = 31 * result + (getFunctions() != null ? getFunctions().hashCode() : 0);    return result;}
0
public String getServiceRoot()
{    return serviceRoot;}
0
public void setServiceRoot(String serviceRoot)
{    this.serviceRoot = serviceRoot;}
0
public QueueHandler getQueue()
{    return queue;}
0
public void setQueue(QueueHandler queue)
{    this.queue = queue;}
0
public Map<String, Object> getQueueConfig()
{    return queueConfig;}
0
public void setQueueConfig(Map<String, Object> queueConfig)
{    this.queueConfig = queueConfig;}
0
public Queue<ModelRequest> createQueue(Map<String, Object> additionalConfig)
{    Map<String, Object> configs = new HashMap<>(getQueueConfig());    configs.putAll(additionalConfig);    return getQueue().create(configs);}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String getVersion()
{    return version;}
0
public void setVersion(String version)
{    this.version = version;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Model model = (Model) o;    if (getName() != null ? !getName().equals(model.getName()) : model.getName() != null)        return false;    return getVersion() != null ? getVersion().equals(model.getVersion()) : model.getVersion() == null;}
0
public int hashCode()
{    int result = getName() != null ? getName().hashCode() : 0;    result = 31 * result + (getVersion() != null ? getVersion().hashCode() : 0);    return result;}
0
public String getContainerId()
{    return containerId;}
0
public Endpoint getEndpoint()
{    return endpoint;}
0
public void setEndpoint(Endpoint endpoint)
{    this.endpoint = endpoint;}
0
public String toString()
{    return name + ":" + version + " @ " + endpoint.getUrl() + " serving:\n\t" + Joiner.on("\n\t").join(getEndpoint().getFunctions().entrySet());}
0
public void setContainerId(String containerId)
{    this.containerId = containerId;}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String getVersion()
{    return version;}
0
public void setVersion(String version)
{    this.version = version;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ModelEndpoint that = (ModelEndpoint) o;    if (getEndpoint() != null ? !getEndpoint().equals(that.getEndpoint()) : that.getEndpoint() != null)        return false;    if (getName() != null ? !getName().equals(that.getName()) : that.getName() != null)        return false;    if (getVersion() != null ? !getVersion().equals(that.getVersion()) : that.getVersion() != null)        return false;    return getContainerId() != null ? getContainerId().equals(that.getContainerId()) : that.getContainerId() == null;}
0
public int hashCode()
{    int result = getEndpoint() != null ? getEndpoint().hashCode() : 0;    result = 31 * result + (getName() != null ? getName().hashCode() : 0);    result = 31 * result + (getVersion() != null ? getVersion().hashCode() : 0);    result = 31 * result + (getContainerId() != null ? getContainerId().hashCode() : 0);    return result;}
0
public String getPath()
{    return path;}
0
public void setPath(String path)
{    this.path = path;}
0
public Action getAction()
{    return action;}
0
public void setAction(Action action)
{    this.action = action;}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String getVersion()
{    return version;}
0
public void setVersion(String version)
{    this.version = version;}
0
public int getNumInstances()
{    return numInstances;}
0
public void setNumInstances(int numInstances)
{    this.numInstances = numInstances;}
0
public int getMemory()
{    return memory;}
0
public void setMemory(int memory)
{    this.memory = memory;}
0
public void resetState()
{    rwLock.readLock().lock();    ServiceInstance<ModelEndpoint> ep = null;    try {        for (Map.Entry<String, ServiceInstance<ModelEndpoint>> kv : containerToEndpoint.entrySet()) {            ep = kv.getValue();            serviceDiscovery.unregisterService(ep);        }    } catch (Exception e) {            } finally {        rwLock.readLock().unlock();    }}
1
public ServiceDiscovery<ModelEndpoint> getServiceDiscovery()
{    return serviceDiscovery;}
0
private void updateState()
{    Map<Model, List<ModelEndpoint>> state = new HashMap<>();    Map<String, String> modelToVersion = new HashMap<>();    Map<String, ServiceInstance<ModelEndpoint>> containerToEndpoint = new HashMap<>();    try {        for (String name : serviceDiscovery.queryForNames()) {            for (ServiceInstance<ModelEndpoint> endpoint : serviceDiscovery.queryForInstances(name)) {                ModelEndpoint ep = endpoint.getPayload();                if (LOG.isDebugEnabled()) {                                    }                                String currentVersion = modelToVersion.getOrDefault(ep.getName(), ep.getVersion());                                                                currentVersion = currentVersion.compareTo(ep.getVersion()) < 0 ? ep.getVersion() : currentVersion;                modelToVersion.put(ep.getName(), currentVersion);                containerToEndpoint.put(ep.getContainerId(), endpoint);                Model model = new Model(ep.getName(), ep.getVersion());                List<ModelEndpoint> endpoints = state.get(model);                if (endpoints == null) {                    endpoints = new ArrayList<>();                    state.put(model, endpoints);                }                endpoints.add(ep);            }        }        rwLock.writeLock().lock();        try {            this.modelToCurrentVersion = modelToVersion;            this.state = state;            this.containerToEndpoint = containerToEndpoint;            if (LOG.isDebugEnabled()) {                            }        } finally {            rwLock.writeLock().unlock();        }    } catch (Exception e) {            } finally {    }}
1
public void start()
{    try {        serviceDiscovery.start();        cache.start();        updateState();    } catch (Exception e) {                throw new IllegalStateException("Unable to start", e);    }}
1
public void unregisterByContainer(String containerIdRaw)
{    rwLock.readLock().lock();    try {        String containerId = containerIdRaw;                                ServiceInstance<ModelEndpoint> ep = containerToEndpoint.get(containerId);        if (ep != null) {            serviceDiscovery.unregisterService(ep);        } else {                        throw new IllegalStateException("Unable.");        }    } catch (Exception e) {            } finally {        rwLock.readLock().unlock();    }}
1
public List<ModelEndpoint> getEndpoints(Model model)
{    rwLock.readLock().lock();    try {        return state.getOrDefault(model, new ArrayList<>());    } finally {        rwLock.readLock().unlock();    }}
0
public void blacklist(ModelEndpoint endpoint)
{    blacklist(toUrl(endpoint.getEndpoint().getUrl()));}
0
public void blacklist(URL url)
{    rwLock.writeLock().lock();    try {        blacklist.put(url, true);    } finally {        rwLock.writeLock().unlock();    }}
0
public ModelEndpoint getEndpoint(String modelName)
{    String version = null;    rwLock.readLock().lock();    try {        version = modelToCurrentVersion.get(modelName);    } finally {        rwLock.readLock().unlock();    }    if (version == null) {        throw new IllegalStateException("Unable to find version for " + modelName);    }    return getEndpoint(modelName, version);}
0
private static URL toUrl(String url)
{    try {        return new URL(url);    } catch (MalformedURLException e) {        throw new IllegalStateException("Endpoint does not refer to an actual URL");    }}
0
public ModelEndpoint getEndpoint(String modelName, String modelVersion)
{    return getEndpoint(new Model(modelName, modelVersion));}
0
public ModelEndpoint getEndpoint(Model model)
{    rwLock.readLock().lock();    try {        List<ModelEndpoint> endpoints = state.get(model);        ModelEndpoint ret = null;        if (endpoints != null) {            for (int j = 0; j < 10; ++j) {                int i = ThreadLocalRandom.current().nextInt(endpoints.size());                ret = endpoints.get(i);                try {                    if (blacklist.asMap().containsKey(toUrl(ret.getEndpoint().getUrl()))) {                        continue;                    } else {                        return ret;                    }                } catch (IllegalStateException ise) {                /*             If an exception happens on an attempt then we move on.             Frankly this is an excess of caution since we parse the             URLs in the Runner before they go into zookeeper, so they are valid.             */                }            }        }        return ret;    } finally {        rwLock.readLock().unlock();    }}
0
public Map<Model, List<ModelEndpoint>> listEndpoints(Model model)
{    Map<Model, List<ModelEndpoint>> ret = new HashMap<>();    rwLock.readLock().lock();    try {        Query query = new Query(model);        for (Map.Entry<Model, List<ModelEndpoint>> kv : state.entrySet()) {            if (query.match(kv.getKey())) {                ret.put(kv.getKey(), kv.getValue());            }        }        return ret;    } finally {        rwLock.readLock().unlock();    }}
0
public void close()
{    if (cache != null) {        CloseableUtils.closeQuietly(cache);    }    if (serviceDiscovery != null) {        CloseableUtils.closeQuietly(serviceDiscovery);    }}
0
public boolean match(Model m)
{    boolean isNameMatch = ((model.getName() != null && model.getName().equals(m.getName())) || model.getName() == null);    if (!isNameMatch) {        return false;    }    boolean isVersionMatch = (model.getVersion() != null && model.getVersion().equals(m.getVersion())) || model.getVersion() == null;    if (!isVersionMatch) {        return false;    }    return true;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ModelCacheKey that = (ModelCacheKey) o;    if (name != null ? !name.equals(that.name) : that.name != null)        return false;    if (version != null ? !version.equals(that.version) : that.version != null)        return false;    if (method != null ? !method.equals(that.method) : that.method != null)        return false;    return args != null ? args.equals(that.args) : that.args == null;}
0
public int hashCode()
{    int result = name != null ? name.hashCode() : 0;    result = 31 * result + (version != null ? version.hashCode() : 0);    result = 31 * result + (method != null ? method.hashCode() : 0);    result = 31 * result + (args != null ? args.hashCode() : 0);    return result;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < 2) {        throw new ParseException("Unable to execute model_apply. " + "Expected arguments: endpoint_map:map, " + " [endpoint method:string], model_args:map");    }    if (!isInitialized) {        return null;    }    int i = 0;    if (args.size() == 0) {        return null;    }    Object endpointObj = args.get(i++);    Map endpoint = null;    String modelName;    String modelVersion;    String modelUrl;    if (endpointObj instanceof Map) {        endpoint = (Map) endpointObj;        modelName = endpoint.get("name") + "";        modelVersion = endpoint.get("version") + "";        modelUrl = endpoint.get("url") + "";    } else {        return null;    }    String modelFunction = "apply";    Map<String, String> modelArgs = new HashMap<>();    if (args.get(i) instanceof String) {        String func = (String) args.get(i);        if (endpoint.containsKey("endpoint:" + func)) {            modelFunction = "" + endpoint.get("endpoint:" + func);        } else {            modelFunction = func;        }        i++;    }    if (args.get(i) instanceof Map) {        if (endpoint.containsKey("endpoint:apply")) {            modelFunction = "" + endpoint.get("endpoint:apply");        }        modelArgs = (Map) args.get(i);    }    if (modelName == null || modelVersion == null || modelFunction == null) {        return null;    }    ModelCacheKey cacheKey = new ModelCacheKey(modelName, modelVersion, modelFunction, modelArgs);    Map<String, Object> ret = resultCache.getIfPresent(cacheKey);    if (ret != null) {        return ret;    } else {        String url = modelUrl;        if (url.endsWith("/")) {            url = url.substring(0, url.length() - 1);        }        if (modelFunction.startsWith("/")) {            modelFunction = modelFunction.substring(1);        }        try {            URL u = new URL(url + "/" + modelFunction);            String results = RESTUtil.INSTANCE.getRESTJSONResults(u, modelArgs);            ret = JSONUtils.INSTANCE.load(results, JSONUtils.MAP_SUPPLIER);            resultCache.put(cacheKey, ret);            return ret;        } catch (Exception e) {                        if (discoverer != null) {                try {                    URL u = new URL(modelUrl);                    discoverer.blacklist(u);                } catch (MalformedURLException e1) {                }            }        }    }    return null;}
1
public synchronized void initialize(Context context)
{    try {        Optional<ServiceDiscoverer> discovererOpt = (Optional) (context.getCapability(Context.Capabilities.SERVICE_DISCOVERER));        if (discovererOpt.isPresent()) {            discoverer = discovererOpt.get();        } else {            Optional<Object> clientOptional = context.getCapability(Context.Capabilities.ZOOKEEPER_CLIENT);            CuratorFramework client = null;            if (clientOptional.isPresent() && clientOptional.get() instanceof CuratorFramework) {                client = (CuratorFramework) clientOptional.get();            } else {                throw new IllegalStateException("Unable to initialize function: Cannot find zookeeper client.");            }            discoverer = createDiscoverer(client);        }    } catch (Exception ex) {            } finally {                isInitialized = true;    }}
1
public boolean isInitialized()
{    return isInitialized;}
0
private static ServiceDiscoverer createDiscoverer(CuratorFramework client) throws Exception
{    MaaSConfig config = ConfigUtil.INSTANCE.read(client, "/metron/maas/config", new MaaSConfig(), MaaSConfig.class);    ServiceDiscoverer discoverer = new ServiceDiscoverer(client, config.getServiceRoot());    discoverer.start();    return discoverer;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (!isValidState) {                return null;    }    String modelName = null;    String modelVersion = null;    if (args.size() >= 1) {        modelName = args.get(0).toString();    }    if (args.size() >= 2) {        modelVersion = args.get(1).toString();    }    if (modelName == null) {        return null;    }    try {        ModelEndpoint ep = null;        if (modelVersion == null) {            ep = discoverer.getEndpoint(modelName);        } else {            ep = discoverer.getEndpoint(modelName, modelVersion);        }        return ep == null ? null : endpointToMap(ep.getName(), ep.getVersion(), ep.getEndpoint());    } catch (Exception ex) {                return null;    }}
1
public static Map<String, String> endpointToMap(String name, String version, Endpoint ep)
{    Map<String, String> ret = new HashMap<>();    ret.put("url", ep.getUrl());    ret.put("name", name);    ret.put("version", version);    for (Map.Entry<String, String> kv : ep.getFunctions().entrySet()) {        ret.put("endpoint:" + kv.getKey(), kv.getValue());    }    return ret;}
0
public synchronized void initialize(Context context)
{    try {        Optional<Object> clientOptional = context.getCapability(Context.Capabilities.ZOOKEEPER_CLIENT);        CuratorFramework client = null;        if (clientOptional.isPresent() && clientOptional.get() instanceof CuratorFramework) {            client = (CuratorFramework) clientOptional.get();        } else {            throw new IllegalStateException("Unable to initialize function: Cannot find zookeeper client.");        }        try {            discoverer = createDiscoverer(client);            context.addCapability(Context.Capabilities.SERVICE_DISCOVERER, () -> discoverer);            isValidState = true;        } catch (Exception e) {                        throw new IllegalStateException("Unable to initialize MAAS_GET_ENDPOINT", e);        }    } finally {        isInitialized = true;    }}
1
public boolean isInitialized()
{    return isInitialized;}
0
public Queue<ModelRequest> create(Map<String, Object> config)
{    return queueCreator.apply(config);}
0
public ModelRequest dequeue()
{    try {        byte[] payload = queue.take();        return ConfigUtil.INSTANCE.read(payload, ModelRequest.class);    } catch (Exception e) {        throw new IllegalStateException("Unable to dequeue: " + e.getMessage(), e);    }}
0
public void enqueue(ModelRequest request)
{    try {        byte[] payload = ConfigUtil.INSTANCE.toBytes(request);        queue.offer(payload);    } catch (Exception e) {        throw new IllegalStateException("Unable to enqueue: " + e.getMessage(), e);    }}
0
public void configure(Map<String, Object> config)
{    String path = (String) config.get(ZK_PATH);    if (path == null) {        throw new IllegalStateException("You must specify " + ZK_PATH + " for a zk queue");    }    CuratorFramework client = (CuratorFramework) config.get(ZK_CLIENT);    queue = new SimpleDistributedQueue(client, path);}
0
protected ObjectMapper initialValue()
{    return new ObjectMapper();}
0
public T read(CuratorFramework client, String root, T def, Class<T> clazz) throws Exception
{    try {        byte[] data = client.getData().forPath(root);        return read(data, clazz);    } catch (KeeperException.NoNodeException nne) {        return def;    }}
0
public T read(byte[] data, Class<T> clazz) throws Exception
{    return _mapper.get().readValue(data, clazz);}
0
public byte[] toBytes(Object o) throws IOException
{    return _mapper.get().writeValueAsBytes(o);}
0
protected HttpClient initialValue()
{        return new DefaultHttpClient();}
0
public String getRESTJSONResults(URL endpointUrl, Map<String, String> getArgs) throws IOException, URISyntaxException
{    String encodedParams = encodeParams(getArgs);    HttpGet get = new HttpGet(appendToUrl(endpointUrl, encodedParams).toURI());    get.addHeader("accept", "application/json");    HttpResponse response = CLIENT.get().execute(get);    if (response.getStatusLine().getStatusCode() != 200) {        throw new IllegalStateException("Failed : HTTP error code : " + response.getStatusLine().getStatusCode());    }    return new BufferedReader(new InputStreamReader(response.getEntity().getContent(), StandardCharsets.UTF_8)).lines().collect(Collectors.joining("\n"));}
0
public URL appendToUrl(URL endpointUrl, String params) throws MalformedURLException
{    return new URL(endpointUrl.toString() + "?" + params);}
0
public String encodeParams(Map<String, String> params)
{    Iterable<NameValuePair> nvp = Iterables.transform(params.entrySet(), kv -> new BasicNameValuePair(kv.getKey(), kv.getValue()));    return URLEncodedUtils.format(nvp, Charset.defaultCharset());}
0
public void setup() throws Exception
{    testZkServer = new TestingServer(true);    zookeeperUrl = testZkServer.getConnectString();    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    client = CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);    client.start();    discoverer = new ServiceDiscoverer(client, "/maas/discover");    discoverer.start();}
0
private ServiceInstance<ModelEndpoint> createInstance(ModelEndpoint ep) throws Exception
{    URL url = new URL(ep.getEndpoint().getUrl());    ServiceInstanceBuilder<ModelEndpoint> builder = ServiceInstance.<ModelEndpoint>builder().address(url.getHost()).id(ep.getContainerId()).name(ep.getName()).port(url.getPort()).registrationTimeUTC(System.currentTimeMillis()).serviceType(ServiceType.STATIC).payload(ep);    return builder.build();}
0
private void registerService(ModelEndpoint ep) throws Exception
{    discoverer.getServiceDiscovery().registerService(createInstance(ep));}
0
private void registerService(String name, String version, AtomicInteger containerId) throws Exception
{    ModelEndpoint ep = new ModelEndpoint();    ep.setName(name);    ep.setVersion(version);    ep.setContainerId(containerId.incrementAndGet() + "");    ep.setEndpoint(new Endpoint() {        {            setUrl("http://localhost:9080/ep1");        }    });    registerService(ep);}
0
public void testDiscovery() throws Exception
{        AtomicInteger containerId = new AtomicInteger(0);    registerService("casey", "3.14159", containerId);    registerService("casey", "3.14159", containerId);    registerService("casey", "3.14159", containerId);    registerService("casey", "3.1416", containerId);        Thread.sleep(2000);    Assert.assertEquals(3, discoverer.getEndpoints(new Model("casey", "3.14159")).size());    Assert.assertEquals(1, discoverer.getEndpoints(new Model("casey", "3.1416")).size());    Assert.assertEquals(0, discoverer.getEndpoints(new Model("casey", "3.17")).size());    discoverer.unregisterByContainer("1");    Thread.sleep(2000);    Assert.assertEquals(2, discoverer.getEndpoints(new Model("casey", "3.14159")).size());    Assert.assertEquals(1, discoverer.getEndpoints(new Model("casey", "3.1416")).size());    Assert.assertEquals(0, discoverer.getEndpoints(new Model("casey", "3.17")).size());    Assert.assertEquals(2, discoverer.listEndpoints(new Model("casey", null)).keySet().size());    Assert.assertEquals(1, discoverer.listEndpoints(new Model("casey", "3.1416")).keySet().size());    Assert.assertEquals(1, discoverer.listEndpoints(new Model("casey", "3.1416")).get(new Model("casey", "3.1416")).size());    Assert.assertEquals("4", discoverer.listEndpoints(new Model("casey", "3.1416")).get(new Model("casey", "3.1416")).get(0).getContainerId());    Assert.assertEquals(0, discoverer.listEndpoints(new Model("casey", "3.17")).keySet().size());    Assert.assertEquals(0, discoverer.listEndpoints(new Model("dummy", null)).keySet().size());}
0
public void teardown() throws Exception
{    if (discoverer != null) {        CloseableUtils.closeQuietly(discoverer);    }    if (client != null) {        CloseableUtils.closeQuietly(client);    }    if (testZkServer != null) {        CloseableUtils.closeQuietly(testZkServer);    }}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public String get(CommandLine cli, String def)
{    return has(cli) ? cli.getOptionValue(shortCode) : def;}
0
public Map.Entry<AMOptions, String> of(String value)
{    if (option.hasArg()) {        return new AbstractMap.SimpleEntry<>(this, value);    }    return new AbstractMap.SimpleEntry<>(this, null);}
0
public static String toArgs(Map.Entry<AMOptions, String>... arg)
{    return Joiner.on(" ").join(Iterables.transform(Arrays.asList(arg), a -> "-" + a.getKey().shortCode + (a.getValue() == null ? "" : (" " + a.getValue()))));}
0
public static CommandLine parse(CommandLineParser parser, String[] args) throws ParseException
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        throw e;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("MaaSApplicationMaster", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (AMOptions o : AMOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public static void main(String[] args)
{    boolean result = false;    try {        ApplicationMaster appMaster = new ApplicationMaster();                boolean doRun = appMaster.init(args);        if (!doRun) {            System.exit(0);        }        appMaster.run();        result = appMaster.finish();    } catch (Throwable t) {                LogManager.shutdown();        ExitUtil.terminate(1, t);    }    if (result) {                System.exit(0);    } else {                System.exit(2);    }}
1
public boolean init(String[] args) throws ParseException, IOException
{    CommandLine cliParser = AMOptions.parse(new GnuParser(), args);        if (fileExist(log4jPath)) {        try {            Log4jPropertyHelper.updateLog4jConfiguration(ApplicationMaster.class, log4jPath);        } catch (Exception e) {                    }    }    if (AMOptions.HELP.has(cliParser)) {        AMOptions.printHelp();        return false;    }    zkQuorum = AMOptions.ZK_QUORUM.get(cliParser);    zkRoot = AMOptions.ZK_ROOT.get(cliParser);    appJarPath = new Path(AMOptions.APP_JAR_PATH.get(cliParser));    Map<String, String> envs = System.getenv();    if (!envs.containsKey(Environment.CONTAINER_ID.name())) {        if (AMOptions.APP_ATTEMPT_ID.has(cliParser)) {            String appIdStr = AMOptions.APP_ATTEMPT_ID.get(cliParser, "");            appAttemptID = ConverterUtils.toApplicationAttemptId(appIdStr);        } else {            throw new IllegalArgumentException("Application Attempt Id not set in the environment");        }    } else {        ContainerId containerId = ConverterUtils.toContainerId(envs.get(Environment.CONTAINER_ID.name()));        appAttemptID = containerId.getApplicationAttemptId();    }    if (!envs.containsKey(ApplicationConstants.APP_SUBMIT_TIME_ENV)) {        throw new RuntimeException(ApplicationConstants.APP_SUBMIT_TIME_ENV + " not set in the environment");    }    if (!envs.containsKey(Environment.NM_HOST.name())) {        throw new RuntimeException(Environment.NM_HOST.name() + " not set in the environment");    }    if (!envs.containsKey(Environment.NM_HTTP_PORT.name())) {        throw new RuntimeException(Environment.NM_HTTP_PORT + " not set in the environment");    }    if (!envs.containsKey(Environment.NM_PORT.name())) {        throw new RuntimeException(Environment.NM_PORT.name() + " not set in the environment");    }        if (cliParser.hasOption("shell_env")) {        String[] shellEnvs = cliParser.getOptionValues("shell_env");        for (String env : shellEnvs) {            env = env.trim();            int index = env.indexOf('=');            if (index == -1) {                shellEnv.put(env, "");                continue;            }            String key = env.substring(0, index);            String val = "";            if (index < (env.length() - 1)) {                val = env.substring(index + 1);            }            shellEnv.put(key, val);        }    }    if (envs.containsKey(Constants.TIMELINEDOMAIN)) {        domainId = envs.get(Constants.TIMELINEDOMAIN);    }    return true;}
1
public void run() throws YarnException, IOException, InterruptedException
{                Credentials credentials = UserGroupInformation.getCurrentUser().getCredentials();    allTokens = YarnUtils.INSTANCE.tokensFromCredentials(credentials);        appSubmitterUgi = YarnUtils.INSTANCE.createUserGroup(credentials);    startTimelineClient(conf);    if (timelineClient != null) {        YarnUtils.INSTANCE.publishApplicationAttemptEvent(timelineClient, appAttemptID.toString(), ContainerEvents.APP_ATTEMPT_START, domainId, appSubmitterUgi);    }    int minSize = getMinContainerMemoryIncrement(conf);    listener = new ContainerRequestListener(timelineClient, appSubmitterUgi, domainId, minSize);    amRMClient = AMRMClientAsync.createAMRMClientAsync(1000, listener);    amRMClient.init(conf);    amRMClient.start();    nmClientAsync = new NMClientAsyncImpl(listener);    nmClientAsync.init(conf);    nmClientAsync.start();                                appMasterHostname = NetUtils.getHostname();    RegisterApplicationMasterResponse response = amRMClient.registerApplicationMaster(appMasterHostname, appMasterRpcPort, appMasterTrackingUrl);            int maxMem = response.getMaximumResourceCapability().getMemory();        int maxVCores = response.getMaximumResourceCapability().getVirtualCores();        maasHandler = new MaaSHandler(zkQuorum, zkRoot);    try {        maasHandler.start();        maasHandler.getDiscoverer().resetState();        listener.initialize(amRMClient, nmClientAsync, maasHandler.getDiscoverer());    } catch (Exception e) {        throw new IllegalStateException("Unable to find zookeeper", e);    }    EnumMap<Resources, Integer> maxResources = Resources.toResourceMap(Resources.MEMORY.of(maxMem), Resources.V_CORE.of(maxVCores));    requestQueue = maasHandler.getConfig().createQueue(ImmutableMap.of(ZKQueue.ZK_CLIENT, maasHandler.getClient()));        while (true) {        ModelRequest request = requestQueue.dequeue();        if (request == null) {                        continue;        }                EnumMap<Resources, Integer> resourceRequest = Resources.toResourceMap(Resources.MEMORY.of(request.getMemory()), Resources.V_CORE.of(1));        EnumMap<Resources, Integer> resources = Resources.getRealisticResourceRequest(maxResources, Resources.toResource(resourceRequest));        Resource resource = Resources.toResource(resources);        Path appMasterJar = getAppMasterJar();        if (request.getAction() == Action.ADD) {            listener.requestContainers(request.getNumInstances(), resource);            for (int i = 0; i < request.getNumInstances(); ++i) {                Container container = listener.getContainers(resource).take();                                executor.execute(new LaunchContainer(conf, zkQuorum, zkRoot, nmClientAsync, request, container, allTokens, appMasterJar));                listener.getContainerState().registerRequest(container, request);            }        } else if (request.getAction() == Action.REMOVE) {            listener.removeContainers(request.getNumInstances(), request);        }    }}
1
private Path getAppMasterJar()
{    return appJarPath;}
0
private int getMinContainerMemoryIncrement(Configuration conf)
{    String incrementStr = conf.get("yarn.scheduler.increment-allocation-mb");    if (incrementStr == null || incrementStr.length() == 0) {        incrementStr = conf.get("yarn.scheduler.minimum-allocation-mb");    }    return Integer.parseInt(incrementStr);}
0
 void startTimelineClient(final Configuration conf) throws YarnException, IOException, InterruptedException
{    try {        appSubmitterUgi.doAs(new PrivilegedExceptionAction<Void>() {            @Override            public Void run() throws Exception {                if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {                                        timelineClient = TimelineClient.createTimelineClient();                    timelineClient.init(conf);                    timelineClient.start();                } else {                    timelineClient = null;                                    }                return null;            }        });    } catch (UndeclaredThrowableException e) {        throw new YarnException(e.getCause());    }}
1
public Void run() throws Exception
{    if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {                timelineClient = TimelineClient.createTimelineClient();        timelineClient.init(conf);        timelineClient.start();    } else {        timelineClient = null;            }    return null;}
1
protected boolean finish()
{    return true;}
0
private boolean fileExist(String filePath)
{    return new File(filePath).exists();}
0
public void initialize(AMRMClientAsync<AMRMClient.ContainerRequest> amRMClient, NMClientAsync nmClient, ServiceDiscoverer serviceDiscoverer)
{    this.nmClient = nmClient;    this.amRMClient = amRMClient;    this.serviceDiscoverer = serviceDiscoverer;}
0
public void removeContainers(int number, ModelRequest request)
{    int i = 0;    for (Container c : state.getList(request)) {        if (i < number) {            amRMClient.releaseAssignedContainer(c.getId());            nmClient.stopContainerAsync(c.getId(), c.getNodeId());        } else {            break;        }        i++;    }}
0
public ContainerTracker getContainerState()
{    return state;}
0
private void removeContainer(ContainerId id)
{    containers.remove(id);    state.removeContainer(id);}
0
public void requestContainers(int number, Resource characteristic)
{    Priority pri = Priority.newInstance(0);    state.getQueue(characteristic);    AMRMClient.ContainerRequest request = new AMRMClient.ContainerRequest(characteristic, null, null, pri, true);    for (int i = 0; i < number; ++i) {        amRMClient.addContainerRequest(request);    }}
0
public void onContainersCompleted(List<ContainerStatus> completedContainers)
{        for (ContainerStatus containerStatus : completedContainers) {                removeContainer(containerStatus.getContainerId());                serviceDiscoverer.unregisterByContainer(containerStatus.getContainerId() + "");                assert (containerStatus.getState() == ContainerState.COMPLETE);                int exitStatus = containerStatus.getExitStatus();        if (0 != exitStatus) {                        if (ContainerExitStatus.ABORTED != exitStatus) {                                    } else {                                                            }        } else {                                            }        if (timelineClient != null) {            YarnUtils.INSTANCE.publishContainerEndEvent(timelineClient, containerStatus, domainId, appSubmitterUgi);        }    }}
1
public BlockingQueue<Container> getContainers(Resource resource)
{    return state.getQueue(resource);}
0
public void onContainersAllocated(List<Container> allocatedContainers)
{        for (Container allocatedContainer : allocatedContainers) {        containers.put(allocatedContainer.getId(), allocatedContainer);        state.registerContainer(allocatedContainer.getResource(), allocatedContainer);            }}
1
public void onShutdownRequest()
{}
0
public void onNodesUpdated(List<NodeReport> updatedNodes)
{}
0
public float getProgress()
{        float progress = 0;    return progress;}
0
public void onError(Throwable e)
{    }
1
public void onContainerStopped(ContainerId containerId)
{    if (LOG.isDebugEnabled()) {            }    if (containerId == null) {                throw new IllegalStateException("onContainerStopped returned null container ID!");    }    serviceDiscoverer.unregisterByContainer(containerId.getContainerId() + "");    removeContainer(containerId);}
1
public void onContainerStatusReceived(ContainerId containerId, ContainerStatus containerStatus)
{    if (LOG.isDebugEnabled()) {            }}
1
public void onContainerStarted(ContainerId containerId, Map<String, ByteBuffer> allServiceResponse)
{    if (LOG.isDebugEnabled()) {            }    Container container = containers.get(containerId);    if (container != null) {        nmClient.getContainerStatusAsync(containerId, container.getNodeId());    }    if (timelineClient != null && container != null) {        YarnUtils.INSTANCE.publishContainerStartEvent(timelineClient, container, domainId, appSubmitterUgi);    }}
1
public void onStartContainerError(ContainerId containerId, Throwable t)
{        serviceDiscoverer.unregisterByContainer(containerId.getContainerId() + "");    removeContainer(containerId);}
1
public void onGetContainerStatusError(ContainerId containerId, Throwable t)
{    }
1
public void onStopContainerError(ContainerId containerId, Throwable t)
{        serviceDiscoverer.unregisterByContainer(containerId.getContainerId() + "");    removeContainer(containerId);}
1
public void run()
{            Map<String, LocalResource> localResources = new HashMap<>();        for (File f : new File(".").listFiles()) {            }        String modelScript = localizeResources(localResources, new Path(request.getPath()), appJarLocation);    for (Map.Entry<String, LocalResource> entry : localResources.entrySet()) {            }                        Map<String, String> env = new HashMap<>();                            StringBuffer classPathEnv = new StringBuffer("$CLASSPATH:./*:");        classPathEnv.append(System.getProperty("java.class.path"));        env.put("CLASSPATH", classPathEnv.toString());        String command = ApplicationConstants.Environment.JAVA_HOME.$$() + "/bin/java " + Runner.class.getName() + " " + RunnerOptions.toArgs(RunnerOptions.CONTAINER_ID.of(container.getId().getContainerId() + ""), RunnerOptions.ZK_QUORUM.of(zkQuorum), RunnerOptions.ZK_ROOT.of(zkRoot), RunnerOptions.SCRIPT.of(modelScript), RunnerOptions.NAME.of(request.getName()), RunnerOptions.HOSTNAME.of(containerHostname()), RunnerOptions.VERSION.of(request.getVersion())) + " 1>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/stdout" + " 2>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/stderr";    List<String> commands = new ArrayList<String>();        commands.add(command);                                    ContainerLaunchContext ctx = ContainerLaunchContext.newInstance(localResources, env, commands, null, allTokens.duplicate(), null);        nmClientAsync.startContainerAsync(container, ctx);}
1
private Map.Entry<String, LocalResource> localizeResource(FileStatus status)
{    URL url = ConverterUtils.getYarnUrlFromURI(status.getPath().toUri());    LocalResource resource = LocalResource.newInstance(url, LocalResourceType.FILE, LocalResourceVisibility.APPLICATION, status.getLen(), status.getModificationTime());    String name = status.getPath().getName();    return new AbstractMap.SimpleEntry<>(name, resource);}
0
public String localizeResources(Map<String, LocalResource> resources, Path scriptLocation, Path appJarLocation)
{    try {                        FileSystem fs = scriptLocation.getFileSystem(conf);        String script = null;        Map.Entry<String, LocalResource> kv = localizeResource(fs.getFileStatus(appJarLocation));        resources.put(kv.getKey(), kv.getValue());        for (RemoteIterator<LocatedFileStatus> it = fs.listFiles(scriptLocation, true); it.hasNext(); ) {            LocatedFileStatus status = it.next();            kv = localizeResource(status);            String name = kv.getKey();            if (name.endsWith(".sh")) {                script = name;            }                        resources.put(name, kv.getValue());        }        return script;    } catch (Exception e) {                return null;    }}
1
private String containerHostname()
{    String nodeHost = null;    try {        boolean hasProtocol = container.getNodeHttpAddress().startsWith("http");        java.net.URL nodehttpAddress = new java.net.URL((hasProtocol ? "" : "http://") + container.getNodeHttpAddress());        nodeHost = nodehttpAddress.getHost();    } catch (MalformedURLException e) {                throw new IllegalStateException("Unable to parse " + container.getNodeHttpAddress() + " into a URL");    }    return nodeHost;}
1
public static void main(String[] args)
{    boolean result = false;    try {        Client client = new Client();                try {            boolean doRun = client.init(args);            if (!doRun) {                System.exit(0);            }        } catch (IllegalArgumentException e) {            System.err.println(e.getLocalizedMessage());            System.exit(-1);        }        result = client.run();    } catch (Throwable t) {                System.exit(1);    }    if (result) {                System.exit(0);    }        System.exit(2);}
1
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public String get(CommandLine cli, String def)
{    return has(cli) ? cli.getOptionValue(shortCode) : def;}
0
public Map.Entry<ClientOptions, String> of(String value)
{    if (option.hasArg()) {        return new AbstractMap.SimpleEntry<>(this, value);    }    return new AbstractMap.SimpleEntry<>(this, null);}
0
public static String toArgs(Map.Entry<ClientOptions, String>... arg)
{    return Joiner.on(" ").join(Iterables.transform(Arrays.asList(arg), a -> "-" + a.getKey().shortCode + (a.getValue() == null ? "" : (" " + a.getValue()))));}
0
public static CommandLine parse(CommandLineParser parser, String[] args) throws ParseException
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        throw e;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("MaaSClient", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (ClientOptions o : ClientOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public static String getJar(Class klass) throws URISyntaxException
{    return klass.getProtectionDomain().getCodeSource().getLocation().toURI().getPath();}
0
public boolean init(String[] args) throws ParseException
{    CommandLine cli = ClientOptions.parse(new PosixParser(), args);    if (LOG4J_PROPERTIES.has(cli)) {        String log4jPath = LOG4J_PROPERTIES.get(cli);        try {            Log4jPropertyHelper.updateLog4jConfiguration(Client.class, log4jPath);        } catch (Exception e) {                    }    }    keepContainers = false;    zkQuorum = ZK_QUORUM.get(cli);    zkRoot = ZK_ROOT.get(cli, "/metron/maas/config");    appName = "MaaS";    amPriority = 0;    amQueue = QUEUE.get(cli, "default");    amMemory = Integer.parseInt(MASTER_MEMORY.get(cli, "10"));    amVCores = Integer.parseInt(MASTER_VCORE.get(cli, "1"));    if (amMemory < 0) {        throw new IllegalArgumentException("Invalid memory specified for application master, exiting." + " Specified memory=" + amMemory);    }    if (amVCores < 0) {        throw new IllegalArgumentException("Invalid virtual cores specified for application master, exiting." + " Specified virtual cores=" + amVCores);    }    if (!JAR.has(cli)) {        try {            appMasterJar = getJar(ApplicationMaster.class);        } catch (URISyntaxException e) {            throw new IllegalArgumentException("No jar file specified for application master: " + e.getMessage(), e);        }    } else {        appMasterJar = JAR.get(cli);    }    if (SHELL_ENV.has(cli)) {        String[] envs = cli.getOptionValues(SHELL_ENV.option.getOpt());        for (String env : envs) {            env = env.trim();            int index = env.indexOf('=');            if (index == -1) {                shellEnv.put(env, "");                continue;            }            String key = env.substring(0, index);            String val = "";            if (index < (env.length() - 1)) {                val = env.substring(index + 1);            }            shellEnv.put(key, val);        }    }    nodeLabelExpression = NODE_LABEL_EXPRESSION.get(cli, null);    clientTimeout = Integer.parseInt(TIMEOUT.get(cli, "600000"));    attemptFailuresValidityInterval = -1;    log4jPropFile = LOG4J_PROPERTIES.get(cli, "");        if (DOMAIN.has(cli)) {        domainId = DOMAIN.get(cli);        toCreateDomain = CREATE.has(cli);        if (VIEW_ACLS.has(cli)) {            viewACLs = VIEW_ACLS.get(cli);        }        if (MODIFY_ACLS.has(cli)) {            modifyACLs = MODIFY_ACLS.get(cli);        }    }    return true;}
1
private boolean monitorApplication(ApplicationId appId) throws YarnException, IOException
{    while (true) {                try {            Thread.sleep(1000);        } catch (InterruptedException e) {                    }                ApplicationReport report = yarnClient.getApplicationReport(appId);                YarnApplicationState state = report.getYarnApplicationState();        FinalApplicationStatus dsStatus = report.getFinalApplicationStatus();        if (YarnApplicationState.RUNNING == state) {                        return true;        }        if (YarnApplicationState.FINISHED == state) {            if (FinalApplicationStatus.SUCCEEDED == dsStatus) {                                return true;            } else {                                return false;            }        } else if (YarnApplicationState.KILLED == state || YarnApplicationState.FAILED == state) {                        return false;        }        if (System.currentTimeMillis() > (clientStartTime + clientTimeout)) {                        forceKillApplication(appId);            return false;        }    }}
1
private void forceKillApplication(ApplicationId appId) throws YarnException, IOException
{                        yarnClient.killApplication(appId);}
0
private void createMaaSDirectory(FileSystem fs, String appId) throws IOException
{    for (Path p : ImmutableList.of(new Path(fs.getHomeDirectory(), appName), new Path(fs.getHomeDirectory(), appName + "/" + appId))) {        if (!fs.exists(p)) {            fs.mkdirs(p);            fs.setPermission(p, new FsPermission((short) 0755));        }    }}
0
private Path addToLocalResources(FileSystem fs, String fileSrcPath, String fileDstPath, String appId, Map<String, LocalResource> localResources, String resources) throws IOException
{    String suffix = appName + "/" + appId + "/" + fileDstPath;    Path dst = new Path(fs.getHomeDirectory(), suffix);    if (fileSrcPath == null) {        FSDataOutputStream ostream = null;        try {            ostream = FileSystem.create(fs, dst, new FsPermission((short) 0710));            ostream.writeUTF(resources);        } finally {            IOUtils.closeQuietly(ostream);        }    } else {        fs.copyFromLocalFile(new Path(fileSrcPath), dst);    }    fs.setPermission(dst, new FsPermission((short) 0755));    FileStatus scFileStatus = fs.getFileStatus(dst);    LocalResource scRsrc = LocalResource.newInstance(ConverterUtils.getYarnUrlFromURI(dst.toUri()), LocalResourceType.FILE, LocalResourceVisibility.APPLICATION, scFileStatus.getLen(), scFileStatus.getModificationTime());    localResources.put(fileDstPath, scRsrc);    return dst;}
0
private void prepareTimelineDomain()
{    TimelineClient timelineClient = null;    if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {        timelineClient = TimelineClient.createTimelineClient();        timelineClient.init(conf);        timelineClient.start();    } else {                return;    }    try {        TimelineDomain domain = new TimelineDomain();        domain.setId(domainId);        domain.setReaders(viewACLs != null && viewACLs.length() > 0 ? viewACLs : " ");        domain.setWriters(modifyACLs != null && modifyACLs.length() > 0 ? modifyACLs : " ");        timelineClient.putDomain(domain);            } catch (Exception e) {            } finally {        timelineClient.stop();    }}
1
public int getAdjustedSize(int size)
{    return (int) (minimumContainerSize * Math.ceil(1.0 * size / minimumContainerSize));}
0
public BlockingQueue<Container> getQueue(Resource resource)
{    synchronized (acceptedContainersByResource) {        int key = getAdjustedSize(resource.getMemory());        BlockingQueue<Container> queue = acceptedContainersByResource.get(key);        if (queue == null) {            queue = new LinkedBlockingDeque<>();            acceptedContainersByResource.put(key, queue);        }        return queue;    }}
0
public void removeContainer(ContainerId container)
{    synchronized (acceptedContainersByResource) {        for (Map.Entry<Model, List<Container>> kv : launchedContainers.entrySet()) {            for (Iterator<Container> it = kv.getValue().iterator(); it.hasNext(); ) {                Container c = it.next();                if (c.getId().equals(container)) {                    it.remove();                }            }        }    }}
0
public List<Container> getList(ModelRequest request)
{    synchronized (acceptedContainersByResource) {        List<Container> containers = launchedContainers.get(new Model(request.getName(), request.getVersion()));        if (containers == null) {            containers = new ArrayList<>();            launchedContainers.put(new Model(request.getName(), request.getVersion()), containers);        }        return containers;    }}
0
public void registerContainer(Resource resource, Container container)
{    synchronized (acceptedContainersByResource) {        BlockingQueue<Container> queue = getQueue(resource);        queue.add(container);    }}
0
public void registerRequest(Container container, ModelRequest request)
{    synchronized (acceptedContainersByResource) {        getList(request).add(container);    }}
0
public static void updateLog4jConfiguration(Class<?> targetClass, String log4jPath) throws Exception
{    Properties customProperties = new Properties();    FileInputStream fs = null;    InputStream is = null;    try {        fs = new FileInputStream(log4jPath);        is = targetClass.getResourceAsStream("/log4j.properties");        customProperties.load(fs);        Properties originalProperties = new Properties();        originalProperties.load(is);        for (Entry<Object, Object> entry : customProperties.entrySet()) {            originalProperties.setProperty(entry.getKey().toString(), entry.getValue().toString());        }        LogManager.resetConfiguration();        PropertyConfigurator.configure(originalProperties);    } finally {        IOUtils.closeQuietly(is);        IOUtils.closeQuietly(fs);    }}
0
public MaaSConfig getConfig()
{    return config;}
0
public CuratorFramework getClient()
{    return client;}
0
public void start() throws Exception
{    if (client == null) {        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);        client = CuratorFrameworkFactory.newClient(zkQuorum, retryPolicy);        client.start();    }    config = ConfigUtil.INSTANCE.read(client, root, new MaaSConfig(), MaaSConfig.class);    cache = new NodeCache(client, root);    cache.getListenable().addListener(() -> {        byte[] data = cache.getCurrentData().getData();        Lock wLock = lock.writeLock();        wLock.lock();        try {            config = _mapper.readValue(data, MaaSConfig.class);        } finally {            wLock.unlock();        }    });    discoverer = new ServiceDiscoverer(client, config.getServiceRoot());    discoverer.start();}
0
public ServiceDiscoverer getDiscoverer()
{    return discoverer;}
0
public Map.Entry<RunnerOptions, String> of(String value)
{    if (option.hasArg()) {        return new AbstractMap.SimpleEntry<>(this, value);    }    return new AbstractMap.SimpleEntry<>(this, null);}
0
public static String toArgs(Map.Entry<RunnerOptions, String>... arg)
{    return Joiner.on(" ").join(Iterables.transform(Arrays.asList(arg), a -> "-" + a.getKey().shortCode + (a.getValue() == null ? "" : (" " + a.getValue()))));}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public String get(CommandLine cli, String def)
{    return has(cli) ? cli.getOptionValue(shortCode) : def;}
0
public static CommandLine parse(CommandLineParser parser, String[] args) throws ParseException
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        throw e;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("MaaSRunner", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (RunnerOptions o : RunnerOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public static void main(String... argv) throws Exception
{    CommandLine cli = RunnerOptions.parse(new PosixParser(), argv);    String zkQuorum = RunnerOptions.ZK_QUORUM.get(cli);    String zkRoot = RunnerOptions.ZK_ROOT.get(cli);    String script = RunnerOptions.SCRIPT.get(cli);    String name = RunnerOptions.NAME.get(cli);    String version = RunnerOptions.VERSION.get(cli);    String containerId = RunnerOptions.CONTAINER_ID.get(cli);    String hostname = RunnerOptions.HOSTNAME.get(cli);    CuratorFramework client = null;            for (File f : new File(".").listFiles()) {            }    try {        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);        client = CuratorFrameworkFactory.newClient(zkQuorum, retryPolicy);        client.start();        MaaSConfig config = ConfigUtil.INSTANCE.read(client, zkRoot, new MaaSConfig(), MaaSConfig.class);        JsonInstanceSerializer<ModelEndpoint> serializer = new JsonInstanceSerializer<>(ModelEndpoint.class);        try {            serviceDiscovery = ServiceDiscoveryBuilder.builder(ModelEndpoint.class).client(client).basePath(config.getServiceRoot()).serializer(serializer).build();        } finally {        }                serviceDiscovery.start();        File cwd = new File(script).getParentFile();        File scriptFile = new File(cwd, script);        if (scriptFile.exists() && !scriptFile.canExecute()) {            scriptFile.setExecutable(true);        }        final String cmd = scriptFile.getAbsolutePath();        try {            p = new ProcessBuilder(cmd).directory(cwd).start();        } catch (Exception e) {                                    throw new IllegalStateException(e.getMessage(), e);        }        try {                        Endpoint ep = readEndpoint(cwd);            URL endpointUrl = correctLocalUrl(hostname, ep.getUrl());            ep.setUrl(endpointUrl.toString());                        ModelEndpoint endpoint = new ModelEndpoint();            {                endpoint.setName(name);                endpoint.setContainerId(containerId);                endpoint.setEndpoint(ep);                endpoint.setVersion(version);            }            ;            ServiceInstanceBuilder<ModelEndpoint> builder = ServiceInstance.<ModelEndpoint>builder().address(endpointUrl.getHost()).id(containerId).name(name).port(endpointUrl.getPort()).registrationTimeUTC(System.currentTimeMillis()).serviceType(ServiceType.STATIC).payload(endpoint);            final ServiceInstance<ModelEndpoint> instance = builder.build();            try {                                serviceDiscovery.registerService(instance);                            } catch (Throwable t) {                            }            Runtime.getRuntime().addShutdownHook(new Thread() {                @Override                public void run() {                                        if (p != null) {                                                p.destroyForcibly();                    }                }            });        } finally {            if (p.waitFor() != 0) {                String stderr = Joiner.on("\n").join(IOUtils.readLines(p.getErrorStream()));                String stdout = Joiner.on("\n").join(IOUtils.readLines(p.getInputStream()));                throw new IllegalStateException("Unable to execute " + script + ".  Stderr is: " + stderr + "\nStdout is: " + stdout);            }        }    } finally {        if (serviceDiscovery != null) {            CloseableUtils.closeQuietly(serviceDiscovery);        }        if (client != null) {            CloseableUtils.closeQuietly(client);        }    }}
1
public void run()
{        if (p != null) {                p.destroyForcibly();    }}
1
private static URL correctLocalUrl(String hostname, String tmpUrl) throws MalformedURLException
{    URL tmp = new URL(tmpUrl);    if (hostname != null && hostname.length() > 0 && localAddresses.contains(tmp.getHost())) {        URL endpointUrl = null;        try {            endpointUrl = new URL(tmp.getProtocol(), hostname, tmp.getPort(), tmp.getFile());        } catch (MalformedURLException e) {                        return tmp;        }        return endpointUrl;    }    return tmp;}
1
private static Endpoint readEndpoint(File cwd) throws Exception
{    String content = "";    File f = new File(cwd, Constants.ENDPOINT_DAT);    for (int i = 0; i < NUM_ATTEMPTS; i++) {        if (f.exists()) {            try {                content = Files.toString(f, Charsets.US_ASCII);            } catch (IOException ioe) {            }            if (content != null && content.length() > 0) {                try {                    Endpoint ep = ConfigUtil.INSTANCE.read(content.getBytes(StandardCharsets.UTF_8), Endpoint.class);                    return ep;                } catch (Exception ex) {                                    }            }        }        Thread.sleep(SLEEP_AMT);    }    throw new IllegalStateException("Unable to start process within the allotted time (10 minutes)");}
1
public static EnumMap<Resources, Integer> getRealisticResourceRequest(EnumMap<Resources, Integer> requestedResources, Resource resource)
{    EnumMap<Resources, Integer> ret = new EnumMap<>(Resources.class);    for (Resources r : values()) {        Integer request = requestedResources.get(r);        int resourceAmt = r.callback.apply(resource);        if (request == null || request < 0) {            ret.put(r, resourceAmt);        } else {            ret.put(r, Math.min(resourceAmt, request));        }    }    return ret;}
0
public Map.Entry<Resources, Integer> of(int n)
{    return new AbstractMap.SimpleEntry<>(this, n);}
0
public static EnumMap<Resources, Integer> toResourceMap(Map.Entry<Resources, Integer>... entry)
{    EnumMap<Resources, Integer> ret = new EnumMap<>(Resources.class);    for (Map.Entry<Resources, Integer> kv : entry) {        ret.put(kv.getKey(), kv.getValue());    }    return ret;}
0
public static Resource toResource(EnumMap<Resources, Integer> resourceMap)
{    return Resource.newInstance(resourceMap.get(Resources.MEMORY), resourceMap.get(Resources.V_CORE));}
0
public UserGroupInformation createUserGroup(Credentials credentials) throws IOException
{    credentials = credentials == null ? UserGroupInformation.getCurrentUser().getCredentials() : credentials;    String appSubmitterUserName = System.getenv(ApplicationConstants.Environment.USER.name());    UserGroupInformation appSubmitterUgi = UserGroupInformation.createRemoteUser(appSubmitterUserName);    appSubmitterUgi.addCredentials(credentials);    return appSubmitterUgi;}
0
public ByteBuffer tokensFromCredentials(Credentials credentials) throws IOException
{            credentials = credentials == null ? UserGroupInformation.getCurrentUser().getCredentials() : credentials;    DataOutputBuffer dob = new DataOutputBuffer();    credentials.writeTokenStorageToStream(dob);        Iterator<Token<?>> iter = credentials.getAllTokens().iterator();        while (iter.hasNext()) {        Token<?> token = iter.next();                if (token.getKind().equals(AMRMTokenIdentifier.KIND_NAME)) {            iter.remove();        }    }    return ByteBuffer.wrap(dob.getData(), 0, dob.getLength());}
1
public void publishContainerEndEvent(final TimelineClient timelineClient, ContainerStatus container, String domainId, UserGroupInformation ugi)
{    final TimelineEntity entity = new TimelineEntity();    entity.setEntityId(container.getContainerId().toString());    entity.setEntityType(ApplicationMaster.DSEntity.DS_CONTAINER.toString());    entity.setDomainId(domainId);    entity.addPrimaryFilter("user", ugi.getShortUserName());    TimelineEvent event = new TimelineEvent();    event.setTimestamp(System.currentTimeMillis());    event.setEventType(ContainerEvents.CONTAINER_END.toString());    event.addEventInfo("State", container.getState().name());    event.addEventInfo("Exit Status", container.getExitStatus());    entity.addEvent(event);    try {        timelineClient.putEntities(entity);    } catch (YarnException | IOException e) {            }}
1
public void publishApplicationAttemptEvent(final TimelineClient timelineClient, String appAttemptId, ContainerEvents appEvent, String domainId, UserGroupInformation ugi)
{    final TimelineEntity entity = new TimelineEntity();    entity.setEntityId(appAttemptId);    entity.setEntityType(ApplicationMaster.DSEntity.DS_APP_ATTEMPT.toString());    entity.setDomainId(domainId);    entity.addPrimaryFilter("user", ugi.getShortUserName());    TimelineEvent event = new TimelineEvent();    event.setEventType(appEvent.toString());    event.setTimestamp(System.currentTimeMillis());    entity.addEvent(event);    try {        timelineClient.putEntities(entity);    } catch (YarnException | IOException e) {            }}
1
public void publishContainerStartEvent(final TimelineClient timelineClient, Container container, String domainId, UserGroupInformation ugi)
{    final TimelineEntity entity = new TimelineEntity();    entity.setEntityId("" + container.getId());    entity.setEntityType(ApplicationMaster.DSEntity.DS_CONTAINER.toString());    entity.setDomainId(domainId);    entity.addPrimaryFilter("user", ugi.getShortUserName());    TimelineEvent event = new TimelineEvent();    event.setTimestamp(System.currentTimeMillis());    event.setEventType(ContainerEvents.CONTAINER_START.toString());    event.addEventInfo("Node", container.getNodeId().toString());    event.addEventInfo("Resources", container.getResource().toString());    entity.addEvent(event);    try {        ugi.doAs(new PrivilegedExceptionAction<TimelinePutResponse>() {            @Override            public TimelinePutResponse run() throws Exception {                return timelineClient.putEntities(entity);            }        });    } catch (Exception e) {            }}
1
public TimelinePutResponse run() throws Exception
{    return timelineClient.putEntities(entity);}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public String get(CommandLine cli, String def)
{    return has(cli) ? cli.getOptionValue(shortCode) : def;}
0
public Map.Entry<ModelSubmissionOptions, String> of(String value)
{    if (option.hasArg()) {        return new AbstractMap.SimpleEntry<>(this, value);    }    return new AbstractMap.SimpleEntry<>(this, null);}
0
public static String toArgs(Map.Entry<ModelSubmissionOptions, String>... arg)
{    return Joiner.on(" ").join(Iterables.transform(Arrays.asList(arg), a -> "-" + a.getKey().option.getOpt() + (a.getValue() == null ? "" : (" " + a.getValue()))));}
0
public static CommandLine parse(CommandLineParser parser, String[] args) throws ParseException
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        throw e;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("ModelSubmission", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (ModelSubmissionOptions o : ModelSubmissionOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public void execute(FileSystem fs, String... argv) throws Exception
{    CommandLine cli = ModelSubmissionOptions.parse(new PosixParser(), argv);    if (ModelSubmissionOptions.LOG4J_PROPERTIES.has(cli)) {        Log4jPropertyHelper.updateLog4jConfiguration(ModelSubmission.class, ModelSubmissionOptions.LOG4J_PROPERTIES.get(cli));    }    ModelRequest request = null;    CuratorFramework client = null;    try {        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);        client = CuratorFrameworkFactory.newClient(ModelSubmissionOptions.ZK_QUORUM.get(cli), retryPolicy);        client.start();        MaaSConfig config = ConfigUtil.INSTANCE.read(client, ModelSubmissionOptions.ZK_ROOT.get(cli, "/metron/maas/config"), new MaaSConfig(), MaaSConfig.class);        String mode = ModelSubmissionOptions.MODE.get(cli);        if (mode.equalsIgnoreCase("ADD")) {            request = new ModelRequest() {                {                    setName(ModelSubmissionOptions.NAME.get(cli));                    setAction(Action.ADD);                    setVersion(ModelSubmissionOptions.VERSION.get(cli));                    setNumInstances(Integer.parseInt(ModelSubmissionOptions.NUM_INSTANCES.get(cli)));                    setMemory(Integer.parseInt(ModelSubmissionOptions.MEMORY.get(cli)));                    setPath(ModelSubmissionOptions.HDFS_MODEL_PATH.get(cli));                }            };        } else if (mode.equalsIgnoreCase("REMOVE")) {            request = new ModelRequest() {                {                    setName(ModelSubmissionOptions.NAME.get(cli));                    setAction(Action.REMOVE);                    setNumInstances(Integer.parseInt(ModelSubmissionOptions.NUM_INSTANCES.get(cli)));                    setVersion(ModelSubmissionOptions.VERSION.get(cli));                }            };        } else if (mode.equalsIgnoreCase("LIST")) {            String name = ModelSubmissionOptions.NAME.get(cli, null);            String version = ModelSubmissionOptions.VERSION.get(cli, null);            ServiceDiscoverer serviceDiscoverer = new ServiceDiscoverer(client, config.getServiceRoot());            Model model = new Model(name, version);            Map<Model, List<ModelEndpoint>> endpoints = serviceDiscoverer.listEndpoints(model);            for (Map.Entry<Model, List<ModelEndpoint>> kv : endpoints.entrySet()) {                String modelTitle = "Model " + kv.getKey().getName() + " @ " + kv.getKey().getVersion();                System.out.println(modelTitle);                for (ModelEndpoint endpoint : kv.getValue()) {                    System.out.println(endpoint);                }            }        }        if (ModelSubmissionOptions.LOCAL_MODEL_PATH.has(cli)) {            File localDir = new File(ModelSubmissionOptions.LOCAL_MODEL_PATH.get(cli));            Path hdfsPath = new Path(ModelSubmissionOptions.HDFS_MODEL_PATH.get(cli));            updateHDFS(fs, localDir, hdfsPath);        }        Queue<ModelRequest> queue = config.createQueue(ImmutableMap.of(ZKQueue.ZK_CLIENT, client));        queue.enqueue(request);    } finally {        if (client != null) {            client.close();        }    }}
0
public static void main(String... argv) throws Exception
{    FileSystem fs = FileSystem.get(new Configuration());    ModelSubmission submission = new ModelSubmission();    submission.execute(fs, argv);}
0
public static void updateHDFS(FileSystem fs, File localDir, Path hdfsPath) throws IOException
{    if (localDir.exists() && localDir.isDirectory()) {        if (!fs.exists(hdfsPath)) {            fs.mkdirs(hdfsPath);        }        for (File f : localDir.listFiles()) {            if (f.getName().equals(Constants.ENDPOINT_DAT)) {                                continue;            }            Path p = new Path(hdfsPath, f.getName());            FSDataOutputStream out = fs.create(p);            BufferedInputStream in = new BufferedInputStream(new FileInputStream(f));            IOUtils.copy(in, out);            IOUtils.closeQuietly(in);            IOUtils.closeQuietly(out);        }    }}
0
public static void setupBeforeClass() throws Exception
{    UnitTestHelper.setJavaLoggingLevel(Level.SEVERE);        zkServerComponent = new ZKServerComponent();    yarnComponent = new YarnComponent().withApplicationMasterClass(ApplicationMaster.class).withTestName(MaasIntegrationTest.class.getSimpleName());    runner = new ComponentRunner.Builder().withComponent("yarn", yarnComponent).withComponent("zk", zkServerComponent).withMillisecondsBetweenAttempts(15000).withNumRetries(10).build();    runner.start();    String zookeeperUrl = zkServerComponent.getConnectionString();    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    client = CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);    client.start();}
1
public static void tearDownAfterClass()
{    if (client != null) {        client.close();    }    runner.stop();}
0
public void tearDown()
{    runner.reset();}
0
public void testMaaSWithDomain() throws Exception
{    testDSShell(true);}
0
public void testMaaSWithoutDomain() throws Exception
{    testDSShell(false);}
0
public void testDSShell(boolean haveDomain) throws Exception
{    MaaSConfig config = new MaaSConfig() {        {            setServiceRoot("/maas/service");            setQueueConfig(new HashMap<String, Object>() {                {                    put(ZKQueue.ZK_PATH, "/maas/queue");                }            });        }    };    String configRoot = "/maas/config";    byte[] configData = ConfigUtil.INSTANCE.toBytes(config);    try {        client.setData().forPath(configRoot, configData);    } catch (KeeperException.NoNodeException e) {        client.create().creatingParentsIfNeeded().forPath(configRoot, configData);    }    String[] args = { "--jar", yarnComponent.getAppMasterJar(), "--zk_quorum", zkServerComponent.getConnectionString(), "--zk_root", configRoot, "--master_memory", "512", "--master_vcores", "2" };    if (haveDomain) {        String[] domainArgs = { "--domain", "TEST_DOMAIN", "--view_acls", "reader_user reader_group", "--modify_acls", "writer_user writer_group", "--create" };        List<String> argsList = new ArrayList<String>(Arrays.asList(args));        argsList.addAll(Arrays.asList(domainArgs));        args = argsList.toArray(new String[argsList.size()]);    }    YarnConfiguration conf = yarnComponent.getConfig();        final Client client = new Client(new Configuration(conf));    boolean initSuccess = client.init(args);    Assert.assertTrue(initSuccess);        final AtomicBoolean result = new AtomicBoolean(false);    Thread t = new Thread() {        @Override        public void run() {            try {                result.set(client.run());            } catch (Exception e) {                throw new RuntimeException(e);            }        }    };    t.start();    YarnClient yarnClient = YarnClient.createYarnClient();    yarnClient.init(new Configuration(conf));    yarnClient.start();    String hostName = NetUtils.getHostname();    boolean verified = false;    String errorMessage = "";    while (!verified) {        List<ApplicationReport> apps = yarnClient.getApplications();        if (apps.size() == 0) {            Thread.sleep(10);            continue;        }        ApplicationReport appReport = apps.get(0);        if (appReport.getHost().equals("N/A")) {            Thread.sleep(10);            continue;        }        errorMessage = "Expected host name to start with '" + hostName + "', was '" + appReport.getHost() + "'. Expected rpc port to be '-1', was '" + appReport.getRpcPort() + "'.";        if (checkHostname(appReport.getHost()) && appReport.getRpcPort() == -1) {            verified = true;        }        if (appReport.getYarnApplicationState() == YarnApplicationState.FINISHED) {            break;        }    }    Assert.assertTrue(errorMessage, verified);    FileSystem fs = FileSystem.get(conf);    try {        new ModelSubmission().execute(FileSystem.get(conf), new String[] { "--name", "dummy", "--version", "1.0", "--zk_quorum", zkServerComponent.getConnectionString(), "--zk_root", configRoot, "--local_model_path", "src/test/resources/maas", "--hdfs_model_path", new Path(fs.getHomeDirectory(), "maas/dummy").toString(), "--num_instances", "1", "--memory", "100", "--mode", "ADD", "--log4j", "src/test/resources/log4j.properties" });        ServiceDiscoverer discoverer = new ServiceDiscoverer(this.client, config.getServiceRoot());        discoverer.start();        {            boolean passed = false;            for (int i = 0; i < 100; ++i) {                try {                    List<ModelEndpoint> endpoints = discoverer.getEndpoints(new Model("dummy", "1.0"));                    if (endpoints != null && endpoints.size() == 1) {                        LOG.trace("Found endpoints: " + endpoints.get(0));                        String output = makeRESTcall(new URL(endpoints.get(0).getEndpoint().getUrl() + "/echo/casey"));                        if (output.contains("casey")) {                            passed = true;                            break;                        }                    }                } catch (Exception e) {                }                Thread.sleep(2000);            }            Assert.assertTrue(passed);        }        {            List<ModelEndpoint> endpoints = discoverer.getEndpoints(new Model("dummy", "1.0"));            Assert.assertNotNull(endpoints);            Assert.assertEquals(1, endpoints.size());        }        new ModelSubmission().execute(FileSystem.get(conf), new String[] { "--name", "dummy", "--version", "1.0", "--zk_quorum", zkServerComponent.getConnectionString(), "--zk_root", configRoot, "--num_instances", "1", "--mode", "REMOVE" });        {            boolean passed = false;            for (int i = 0; i < 100; ++i) {                try {                    List<ModelEndpoint> endpoints = discoverer.getEndpoints(new Model("dummy", "1.0"));                                        if (endpoints == null || endpoints.size() == 0) {                        passed = true;                        break;                    }                } catch (Exception e) {                }                Thread.sleep(2000);            }            Assert.assertTrue(passed);        }    } finally {        cleanup();    }}
1
public void run()
{    try {        result.set(client.run());    } catch (Exception e) {        throw new RuntimeException(e);    }}
0
private void cleanup()
{    try {        LOG.trace("Cleaning up...");        String line;        Process p = Runtime.getRuntime().exec("ps -e");        BufferedReader input = new BufferedReader(new InputStreamReader(p.getInputStream(), StandardCharsets.UTF_8));        while ((line = input.readLine()) != null) {            if (line.contains("dummy_rest.sh")) {                String pid = Iterables.get(Splitter.on(" ").split(line.replaceAll("\\s+", " ").trim()), 0);                LOG.trace("Killing " + pid + " from " + line);                Runtime.getRuntime().exec("kill -9 " + pid);            }        }        input.close();    } catch (Exception err) {        err.printStackTrace();    }}
0
private String makeRESTcall(URL url) throws IOException
{    HttpURLConnection conn = null;        try {        conn = (HttpURLConnection) url.openConnection();        conn.setRequestMethod("GET");        if (conn.getResponseCode() != 200) {            throw new RuntimeException("Failed : HTTP error code : " + conn.getResponseCode());        }        BufferedReader br = new BufferedReader(new InputStreamReader((conn.getInputStream()), StandardCharsets.UTF_8));        String output = "";        String line;        while ((line = br.readLine()) != null) {            output += line + "\n";        }        return output;    } finally {        if (conn != null) {            conn.disconnect();        }    }}
0
private boolean checkHostname(String appHostname) throws Exception
{    String hostname = NetUtils.getHostname();    if (hostname.equals(appHostname)) {        return true;    }    Assert.assertTrue("Unknown format for hostname " + appHostname, appHostname.contains("/"));    Assert.assertTrue("Unknown format for hostname " + hostname, hostname.contains("/"));    String[] appHostnameParts = appHostname.split("/");    String[] hostnameParts = hostname.split("/");    return (compareFQDNs(appHostnameParts[0], hostnameParts[0]) && checkIPs(hostnameParts[0], hostnameParts[1], appHostnameParts[1]));}
0
private boolean compareFQDNs(String appHostname, String hostname) throws Exception
{    if (appHostname.equals(hostname)) {        return true;    }    String appFQDN = InetAddress.getByName(appHostname).getCanonicalHostName();    String localFQDN = InetAddress.getByName(hostname).getCanonicalHostName();    return appFQDN.equals(localFQDN);}
0
private boolean checkIPs(String hostname, String localIP, String appIP) throws Exception
{    if (localIP.equals(appIP)) {        return true;    }    boolean appIPCheck = false;    boolean localIPCheck = false;    InetAddress[] addresses = InetAddress.getAllByName(hostname);    for (InetAddress ia : addresses) {        if (ia.getHostAddress().equals(appIP)) {            appIPCheck = true;            continue;        }        if (ia.getHostAddress().equals(localIP)) {            localIPCheck = true;        }    }    return (appIPCheck && localIPCheck);}
0
private int verifyContainerLog(int containerNum, List<String> expectedContent, boolean count, String expectedWord)
{    File logFolder = new File(yarnComponent.getYARNCluster().getNodeManager(0).getConfig().get(YarnConfiguration.NM_LOG_DIRS, YarnConfiguration.DEFAULT_NM_LOG_DIRS));    File[] listOfFiles = logFolder.listFiles();    int currentContainerLogFileIndex = -1;    for (int i = listOfFiles.length - 1; i >= 0; i--) {        if (listOfFiles[i].listFiles().length == containerNum + 1) {            currentContainerLogFileIndex = i;            break;        }    }    Assert.assertTrue(currentContainerLogFileIndex != -1);    File[] containerFiles = listOfFiles[currentContainerLogFileIndex].listFiles();    int numOfWords = 0;    for (int i = 0; i < containerFiles.length; i++) {        for (File output : containerFiles[i].listFiles()) {            if (output.getName().trim().contains("stdout")) {                BufferedReader br = null;                List<String> stdOutContent = new ArrayList<String>();                try {                    String sCurrentLine;                    br = new BufferedReader(new InputStreamReader(new FileInputStream(output), StandardCharsets.UTF_8));                    int numOfline = 0;                    while ((sCurrentLine = br.readLine()) != null) {                        if (count) {                            if (sCurrentLine.contains(expectedWord)) {                                numOfWords++;                            }                        } else if (output.getName().trim().equals("stdout")) {                            if (!Shell.WINDOWS) {                                Assert.assertEquals("The current is" + sCurrentLine, expectedContent.get(numOfline), sCurrentLine.trim());                                numOfline++;                            } else {                                stdOutContent.add(sCurrentLine.trim());                            }                        }                    }                    /* By executing bat script using cmd /c,             * it will output all contents from bat script first             * It is hard for us to do check line by line             * Simply check whether output from bat file contains             * all the expected messages             */                    if (Shell.WINDOWS && !count && output.getName().trim().equals("stdout")) {                        Assert.assertTrue(stdOutContent.containsAll(expectedContent));                    }                } catch (IOException e) {                    e.printStackTrace();                } finally {                    try {                        if (br != null)                            br.close();                    } catch (IOException ex) {                        ex.printStackTrace();                    }                }            }        }    }    return numOfWords;}
0
public Response apply(@QueryParam("host") String host) throws JsonProcessingException
{    Boolean b = isMalicious.get(host);    boolean isMalicious = b != null && b;    Map<String, Boolean> ret = new HashMap<String, Boolean>();    ret.put("is_malicious", isMalicious);    String resp = JSONUtils.INSTANCE.toJSON(ret, true);    return Response.ok(resp, MediaType.APPLICATION_JSON_TYPE).build();}
0
public Set<Class<?>> getClasses()
{    return classes;}
0
public static void start(int port) throws IOException
{        URI uri = UriBuilder.fromUri("http://localhost/").port(port).build();    server = HttpServer.create(new InetSocketAddress(uri.getPort()), 0);    HttpHandler handler = RuntimeDelegate.getInstance().createEndpoint(new ApplicationConfig(), HttpHandler.class);    server.createContext(uri.getPath(), handler);    server.start();}
0
public static void shutdown()
{    if (server != null) {        server.stop(0);    }}
0
public static void setup() throws Exception
{    UnitTestHelper.setJavaLoggingLevel(WebApplicationImpl.class, Level.WARNING);    MockDGAModel.start(8282);    testZkServer = new TestingServer(true);    zookeeperUrl = testZkServer.getConnectString();    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    client = CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);    client.start();    context = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client).build();    MaaSConfig config = ConfigUtil.INSTANCE.read(client, "/metron/maas/config", new MaaSConfig(), MaaSConfig.class);    discoverer = new ServiceDiscoverer(client, config.getServiceRoot());    discoverer.start();    endpointUrl = new URL("http://localhost:8282");    ModelEndpoint endpoint = new ModelEndpoint();    {        endpoint.setName("dga");        endpoint.setContainerId("0");        Endpoint ep = new Endpoint();        ep.setUrl(endpointUrl.toString());        endpoint.setEndpoint(ep);        endpoint.setVersion("1.0");    }    ;    ServiceInstanceBuilder<ModelEndpoint> builder = ServiceInstance.<ModelEndpoint>builder().address(endpointUrl.getHost()).id("0").name("dga").port(endpointUrl.getPort()).registrationTimeUTC(System.currentTimeMillis()).serviceType(ServiceType.STATIC).payload(endpoint);    final ServiceInstance<ModelEndpoint> instance = builder.build();    discoverer.getServiceDiscovery().registerService(instance);        for (int i = 0; i < 10; ++i) {        try {            Object o = discoverer.getEndpoint("dga");            if (o != null) {                break;            }        } catch (Exception e) {        }        Thread.sleep(1000);    }}
0
public void testGetEndpointWithoutVersion() throws Exception
{    String stellar = "MAAS_GET_ENDPOINT('dga')";    Object result = run(stellar, new HashMap<>(), context);    Assert.assertTrue(result instanceof Map);    Map<String, String> resMap = (Map<String, String>) result;    Assert.assertEquals(resMap.get("url"), "http://localhost:8282");    Assert.assertEquals(resMap.get("name"), "dga");    Assert.assertEquals(resMap.get("version"), "1.0");    Assert.assertEquals(resMap.get("endpoint:apply"), "apply");}
0
public void testGetEndpointWithVersion() throws Exception
{    String stellar = "MAAS_GET_ENDPOINT('dga', '1.0')";    Object result = run(stellar, new HashMap<>(), context);    Assert.assertTrue(result instanceof Map);    Map<String, String> resMap = (Map<String, String>) result;    Assert.assertEquals(resMap.get("url"), "http://localhost:8282");    Assert.assertEquals(resMap.get("name"), "dga");    Assert.assertEquals(resMap.get("version"), "1.0");    Assert.assertEquals(resMap.get("endpoint:apply"), "apply");}
0
public void testGetEndpointWithWrongVersion() throws Exception
{    String stellar = "MAAS_GET_ENDPOINT('dga', '2.0')";    Object result = run(stellar, new HashMap<>(), context);    Assert.assertNull(result);}
0
public void testModelApply() throws Exception
{    {        String stellar = "MAP_GET('is_malicious', MAAS_MODEL_APPLY(MAAS_GET_ENDPOINT('dga'), {'host': host}))";        Object result = run(stellar, ImmutableMap.of("host", "badguy.com"), context);        Assert.assertTrue((Boolean) result);    }    {        String stellar = "MAP_GET('is_malicious', MAAS_MODEL_APPLY(MAAS_GET_ENDPOINT('dga'), {'host': host}))";        Object result = run(stellar, ImmutableMap.of("host", "youtube.com"), context);        Assert.assertFalse((Boolean) result);    }    {        String stellar = "MAP_GET('is_malicious', MAAS_MODEL_APPLY(MAAS_GET_ENDPOINT('dga'), 'apply', {'host': host}))";        Object result = run(stellar, ImmutableMap.of("host", "youtube.com"), context);        Assert.assertFalse((Boolean) result);    }}
0
public void testModelApplyNegative()
{    {        String stellar = "MAP_GET('is_malicious', MAAS_MODEL_APPLY(MAAS_GET_ENDPOINT('dga', '2.0'), {'host': host}))";        Object result = run(stellar, ImmutableMap.of("host", "youtube.com"), context);        Assert.assertNull(result);    }}
0
public static void teardown()
{    MockDGAModel.shutdown();    if (discoverer != null) {        CloseableUtils.closeQuietly(discoverer);    }    if (client != null) {        CloseableUtils.closeQuietly(client);    }    if (testZkServer != null) {        CloseableUtils.closeQuietly(testZkServer);    }}
0
public List<ProfileMeasurement> fetch(Class<T> clazz, String profile, String entity, List<Object> groups, long start, long end, Optional<T> defaultValue)
{    List<ProfilePeriod> periods = ProfilePeriod.visitPeriods(start, end, periodDurationMillis, TimeUnit.MILLISECONDS, Optional.empty(), period -> period);    return fetch(clazz, profile, entity, groups, periods, defaultValue);}
0
public List<ProfileMeasurement> fetch(Class<T> clazz, String profile, String entity, List<Object> groups, Iterable<ProfilePeriod> periods, Optional<T> defaultValue)
{        List<ProfileMeasurement> toFetch = new ArrayList<>();    for (ProfilePeriod period : periods) {        toFetch.add(new ProfileMeasurement().withProfileName(profile).withEntity(entity).withPeriod(period).withGroups(groups));    }        return doFetch(toFetch, clazz, defaultValue);}
0
private List<ProfileMeasurement> doFetch(List<ProfileMeasurement> measurements, Class<T> clazz, Optional<T> defaultValue)
{    List<ProfileMeasurement> values = new ArrayList<>();        byte[] columnFamily = Bytes.toBytes(columnBuilder.getColumnFamily());    byte[] columnQualifier = columnBuilder.getColumnQualifier("value");    List<Get> gets = new ArrayList<>();    for (ProfileMeasurement measurement : measurements) {        byte[] rowKey = rowKeyBuilder.rowKey(measurement);        Get get = new Get(rowKey).addColumn(columnFamily, columnQualifier);        gets.add(get);    }        try {        Result[] results = tableProvider.getTable(hbaseConfig, tableName).get(gets);        for (int i = 0; i < results.length; ++i) {            Result result = results[i];            ProfileMeasurement measurement = measurements.get(i);            boolean exists = result.containsColumn(columnFamily, columnQualifier);            if (exists) {                                byte[] value = result.getValue(columnFamily, columnQualifier);                measurement.withProfileValue(SerDeUtils.fromBytes(value, clazz));                values.add(measurement);            } else if (defaultValue.isPresent()) {                                measurement.withProfileValue(defaultValue.get());                values.add(measurement);            } else {                        }        }    } catch (IOException e) {        throw new RuntimeException(e);    }    return values;}
0
public void setTableProvider(TableProvider tableProvider)
{    this.tableProvider = tableProvider;}
0
public void setRowKeyBuilder(RowKeyBuilder rowKeyBuilder)
{    this.rowKeyBuilder = rowKeyBuilder;}
0
public void setColumnBuilder(ColumnBuilder columnBuilder)
{    this.columnBuilder = columnBuilder;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    Optional<Map> configOverridesMap = Optional.empty();    long durationAgo = Util.getArg(0, Long.class, args);    String unitsName = Util.getArg(1, String.class, args);    TimeUnit units = TimeUnit.valueOf(unitsName);    if (args.size() > 2) {        Map rawMap = Util.getArg(2, Map.class, args);        configOverridesMap = rawMap == null || rawMap.isEmpty() ? Optional.empty() : Optional.of(rawMap);    }    Map<String, Object> effectiveConfigs = Util.getEffectiveConfig(context, configOverridesMap.orElse(null));    Long tickDuration = ProfilerClientConfig.PROFILER_PERIOD.get(effectiveConfigs, Long.class);    TimeUnit tickUnit = TimeUnit.valueOf(ProfilerClientConfig.PROFILER_PERIOD_UNITS.get(effectiveConfigs, String.class));    long end = System.currentTimeMillis();    long start = end - units.toMillis(durationAgo);    return ProfilePeriod.visitPeriods(start, end, tickDuration, tickUnit, Optional.empty(), period -> period);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String profile = getArg(0, String.class, args);    String entity = getArg(1, String.class, args);    Optional<List<ProfilePeriod>> periods = Optional.ofNullable(getArg(2, List.class, args));        @SuppressWarnings("unchecked")    List<Object> groups = null;    Map configOverridesMap = null;    if (args.size() < 4) {                groups = new ArrayList<>(0);    } else if (args.get(3) instanceof List) {                groups = getArg(3, List.class, args);        if (args.size() >= 5) {            configOverridesMap = getArg(4, Map.class, args);            if (configOverridesMap.isEmpty())                configOverridesMap = null;        }    } else {                        groups = getGroupsArg(3, args);    }    Map<String, Object> effectiveConfig = getEffectiveConfig(context, configOverridesMap);    Object defaultValue = null;        if (client == null || !cachedConfigMap.equals(effectiveConfig)) {        RowKeyBuilder rowKeyBuilder = getRowKeyBuilder(effectiveConfig);        ColumnBuilder columnBuilder = getColumnBuilder(effectiveConfig);        long periodDuration = getPeriodDurationInMillis(effectiveConfig);        String tableName = PROFILER_HBASE_TABLE.get(effectiveConfig, String.class);        Configuration hbaseConfig = HBaseConfiguration.create();        client = new HBaseProfilerClient(getTableProvider(effectiveConfig), rowKeyBuilder, columnBuilder, periodDuration, tableName, hbaseConfig);        cachedConfigMap = effectiveConfig;    }    if (cachedConfigMap != null) {        defaultValue = ProfilerClientConfig.PROFILER_DEFAULT_VALUE.get(cachedConfigMap);    }    List<ProfileMeasurement> measurements = client.fetch(Object.class, profile, entity, groups, periods.orElse(new ArrayList<>(0)), Optional.ofNullable(defaultValue));        List<Object> values = new ArrayList<>();    for (ProfileMeasurement m : measurements) {        values.add(m.getProfileValue());    }    return values;}
0
private List<Object> getGroupsArg(int startIndex, List<Object> args)
{    List<Object> groups = new ArrayList<>();    for (int i = startIndex; i < args.size(); i++) {        String group = getArg(i, String.class, args);        groups.add(group);    }    return groups;}
0
private ColumnBuilder getColumnBuilder(Map<String, Object> global)
{    ColumnBuilder columnBuilder;    String columnFamily = PROFILER_COLUMN_FAMILY.get(global, String.class);    columnBuilder = new ValueOnlyColumnBuilder(columnFamily);    return columnBuilder;}
0
private RowKeyBuilder getRowKeyBuilder(Map<String, Object> global)
{        long duration = PROFILER_PERIOD.get(global, Long.class);            String configuredUnits = PROFILER_PERIOD_UNITS.get(global, String.class);    TimeUnit units = TimeUnit.valueOf(configuredUnits);            Integer saltDivisor = PROFILER_SALT_DIVISOR.get(global, Integer.class);        return new SaltyRowKeyBuilder(saltDivisor, duration, units);}
1
private TableProvider getTableProvider(Map<String, Object> global)
{    String clazzName = PROFILER_HBASE_TABLE_PROVIDER.get(global, String.class);    TableProvider provider;    try {        @SuppressWarnings("unchecked")        Class<? extends TableProvider> clazz = (Class<? extends TableProvider>) Class.forName(clazzName);        provider = clazz.getConstructor().newInstance();    } catch (Exception e) {        provider = new HTableProvider();    }    return provider;}
0
private boolean containsInclusive(Range<Long> interval, long ts)
{    return interval.contains(ts) || interval.getMaximum() == ts;}
0
public boolean test(T x)
{    long ts = timestampTransformer.apply(x);    int pos = Collections.binarySearch(intervals, Range.is(ts), INTERVAL_COMPARATOR);    if (pos < 0) {        pos = -pos - 1;    }    Optional<Range<Long>> right = pos >= 0 && pos < intervals.size() ? Optional.of(intervals.get(pos)) : Optional.empty();    Optional<Range<Long>> left = pos - 1 >= 0 && pos - 1 < intervals.size() ? Optional.of(intervals.get(pos - 1)) : Optional.empty();    return (right.isPresent() ? containsInclusive(right.get(), ts) : false) || (left.isPresent() ? containsInclusive(left.get(), ts) : false);}
0
public String getKey()
{    return key;}
0
public Object getDefault()
{    return getDefault(valueType);}
0
public T getDefault(Class<T> clazz)
{    return defaultValue == null ? null : ConversionUtils.convert(defaultValue, clazz);}
0
public Object get(Map<String, Object> profilerConfig)
{    return getOrDefault(profilerConfig, defaultValue);}
0
public Object getOrDefault(Map<String, Object> profilerConfig, Object defaultValue)
{    return getOrDefault(profilerConfig, defaultValue, valueType);}
0
public T get(Map<String, Object> profilerConfig, Class<T> clazz)
{    return getOrDefault(profilerConfig, defaultValue, clazz);}
0
public T getOrDefault(Map<String, Object> profilerConfig, Object defaultValue, Class<T> clazz)
{    Object o = profilerConfig.getOrDefault(key, defaultValue);    return o == null ? null : ConversionUtils.convert(o, clazz);}
0
public String toString()
{    return key;}
0
public static void validateCapabilities(Context context, Context.Capabilities[] required) throws IllegalStateException
{        String missing = Stream.of(required).filter(c -> !context.getCapability(c).isPresent()).map(c -> c.toString()).collect(Collectors.joining(", "));    if (StringUtils.isNotBlank(missing) || context == null) {        throw new IllegalStateException("missing required context: " + missing);    }}
0
public static Map<String, Object> getEffectiveConfig(Context context, Map configOverridesMap) throws ParseException
{        final Context.Capabilities[] required = { GLOBAL_CONFIG };    validateCapabilities(context, required);    @SuppressWarnings("unchecked")    Map<String, Object> global = (Map<String, Object>) context.getCapability(GLOBAL_CONFIG).get();    Map<String, Object> result = new HashMap<>(6);        for (ProfilerClientConfig k : ProfilerClientConfig.values()) {        Object globalValue = global.containsKey(k.key) ? ConversionUtils.convert(global.get(k.key), k.valueType) : null;        Object overrideValue = configOverridesMap == null ? null : k.getOrDefault(configOverridesMap, null);        Object defaultValue = k.defaultValue;        if (overrideValue != null) {            result.put(k.key, overrideValue);        } else if (globalValue != null) {            result.put(k.key, globalValue);        } else if (defaultValue != null) {            result.put(k.key, defaultValue);        }    }    return result;}
0
public static T getArg(int index, Class<T> clazz, List<Object> args)
{    if (index >= args.size()) {        throw new IllegalArgumentException(format("expected at least %d argument(s), found %d", index + 1, args.size()));    }    return ConversionUtils.convert(args.get(index), clazz);}
0
public static long getPeriodDurationInMillis(Map<String, Object> global)
{    long duration = PROFILER_PERIOD.get(global, Long.class);        String configuredUnits = PROFILER_PERIOD_UNITS.get(global, String.class);    TimeUnit units = TimeUnit.valueOf(configuredUnits);        return units.toMillis(duration);}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        String profile = getArg(0, String.class, args);    String entity = getArg(1, String.class, args);    List<ProfilePeriod> periods = getArg(2, List.class, args);        List<Object> groups = new ArrayList<>();    if (args.size() >= 4) {        groups = getArg(3, List.class, args);    }        Map<String, Object> globals = (Map<String, Object>) context.getCapability(GLOBAL_CONFIG).orElse(Collections.emptyMap());        if (client == null) {        RowKeyBuilder rowKeyBuilder = getRowKeyBuilder(globals);        ColumnBuilder columnBuilder = getColumnBuilder(globals);        TableProvider provider = getTableProvider(globals);        long periodDuration = getPeriodDurationInMillis(globals);        client = new HBaseProfilerClient(provider, rowKeyBuilder, columnBuilder, periodDuration, getTableName(globals), HBaseConfiguration.create());    }        Optional<Object> defaultValue = Optional.empty();    if (globals != null) {        defaultValue = Optional.ofNullable(PROFILER_DEFAULT_VALUE.get(globals));    }    List<ProfileMeasurement> measurements = client.fetch(Object.class, profile, entity, groups, periods, defaultValue);        List<Object> results = new ArrayList<>();    for (ProfileMeasurement measurement : measurements) {        results.add(render(measurement));    }    return results;}
0
private Map<String, Object> render(ProfileMeasurement measurement)
{    Map<String, Object> view = new HashMap<>();    view.put(PROFILE_KEY, measurement.getProfileName());    view.put(ENTITY_KEY, measurement.getEntity());    view.put(PERIOD_KEY, measurement.getPeriod().getPeriod());    view.put(PERIOD_START_KEY, measurement.getPeriod().getStartTimeMillis());    view.put(PERIOD_END_KEY, measurement.getPeriod().getEndTimeMillis());    view.put(VALUE_KEY, measurement.getProfileValue());    view.put(GROUPS_KEY, measurement.getGroups());    return view;}
0
private ColumnBuilder getColumnBuilder(Map<String, Object> global)
{    String columnFamily = PROFILER_COLUMN_FAMILY.get(global, String.class);    return new ValueOnlyColumnBuilder(columnFamily);}
0
private RowKeyBuilder getRowKeyBuilder(Map<String, Object> global)
{    Integer saltDivisor = PROFILER_SALT_DIVISOR.get(global, Integer.class);    return new SaltyRowKeyBuilder(saltDivisor, getPeriodDurationInMillis(global), TimeUnit.MILLISECONDS);}
0
private String getTableName(Map<String, Object> global)
{    return PROFILER_HBASE_TABLE.get(global, String.class);}
0
private TableProvider getTableProvider(Map<String, Object> global)
{    String clazzName = PROFILER_HBASE_TABLE_PROVIDER.get(global, String.class);    TableProvider provider;    try {        @SuppressWarnings("unchecked")        Class<? extends TableProvider> clazz = (Class<? extends TableProvider>) Class.forName(clazzName);        provider = clazz.getConstructor().newInstance();    } catch (Exception e) {        provider = new HTableProvider();    }    return provider;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    Optional<Map> configOverridesMap = Optional.empty();    long now = System.currentTimeMillis();    String windowSelector = Util.getArg(0, String.class, args);    if (args.size() > 1) {        Optional<Object> arg2 = Optional.ofNullable(args.get(1));        Optional<Object> mapArg = args.size() > 2 ? Optional.ofNullable(args.get(2)) : Optional.empty();        if (!mapArg.isPresent() && arg2.isPresent() && arg2.get() instanceof Map) {            mapArg = arg2;        }        if (arg2.isPresent() && arg2.get() instanceof Number) {            now = ConversionUtils.convert(arg2.get(), Long.class);        }        if (mapArg.isPresent()) {            Map rawMap = ConversionUtils.convert(mapArg.get(), Map.class);            configOverridesMap = rawMap == null || rawMap.isEmpty() ? Optional.empty() : Optional.of(rawMap);        }    }    Map<String, Object> effectiveConfigs = Util.getEffectiveConfig(context, configOverridesMap.orElse(null));    Long tickDuration = ProfilerClientConfig.PROFILER_PERIOD.get(effectiveConfigs, Long.class);    TimeUnit tickUnit = TimeUnit.valueOf(ProfilerClientConfig.PROFILER_PERIOD_UNITS.get(effectiveConfigs, String.class));    Window w = null;    try {        w = windowCache.get(windowSelector, (selector) -> WindowProcessor.process(selector));    } catch (ParseException e) {        throw new IllegalStateException("Unable to process " + windowSelector + ": " + e.getMessage(), e);    }    long end = w.getEndMillis(now);    long start = w.getStartMillis(now);    IntervalPredicate<ProfilePeriod> intervalSelector = new IntervalPredicate<>(period -> period.getStartTimeMillis(), w.toIntervals(now), ProfilePeriod.class);    return ProfilePeriod.visitPeriods(start, end, tickDuration, tickUnit, Optional.of(intervalSelector), period -> period);}
0
public void initialize(Context context)
{    windowCache = Caffeine.newBuilder().maximumSize(200).expireAfterAccess(10, TimeUnit.MINUTES).build();}
0
public boolean isInitialized()
{    return windowCache != null;}
0
public void enterWindow(WindowParser.WindowContext ctx)
{}
0
public void exitWindow(WindowParser.WindowContext ctx)
{}
0
public void enterNonRepeatingWindow(WindowParser.NonRepeatingWindowContext ctx)
{}
0
public void exitNonRepeatingWindow(WindowParser.NonRepeatingWindowContext ctx)
{}
0
public void enterRepeatingWindow(WindowParser.RepeatingWindowContext ctx)
{}
0
public void exitRepeatingWindow(WindowParser.RepeatingWindowContext ctx)
{}
0
public void enterDenseWindow(WindowParser.DenseWindowContext ctx)
{}
0
public void exitDenseWindow(WindowParser.DenseWindowContext ctx)
{}
0
public void enterExcluding_specifier(WindowParser.Excluding_specifierContext ctx)
{}
0
public void exitExcluding_specifier(WindowParser.Excluding_specifierContext ctx)
{}
0
public void enterIncluding_specifier(WindowParser.Including_specifierContext ctx)
{}
0
public void exitIncluding_specifier(WindowParser.Including_specifierContext ctx)
{}
0
public void enterSpecifier(WindowParser.SpecifierContext ctx)
{}
0
public void exitSpecifier(WindowParser.SpecifierContext ctx)
{}
0
public void enterSpecifier_arg_list(WindowParser.Specifier_arg_listContext ctx)
{}
0
public void exitSpecifier_arg_list(WindowParser.Specifier_arg_listContext ctx)
{}
0
public void enterDay_specifier(WindowParser.Day_specifierContext ctx)
{}
0
public void exitDay_specifier(WindowParser.Day_specifierContext ctx)
{}
0
public void enterIdentifier(WindowParser.IdentifierContext ctx)
{}
0
public void exitIdentifier(WindowParser.IdentifierContext ctx)
{}
0
public void enterSpecifier_list(WindowParser.Specifier_listContext ctx)
{}
0
public void exitSpecifier_list(WindowParser.Specifier_listContext ctx)
{}
0
public void enterFromToDuration(WindowParser.FromToDurationContext ctx)
{}
0
public void exitFromToDuration(WindowParser.FromToDurationContext ctx)
{}
0
public void enterFromDuration(WindowParser.FromDurationContext ctx)
{}
0
public void exitFromDuration(WindowParser.FromDurationContext ctx)
{}
0
public void enterSkipDistance(WindowParser.SkipDistanceContext ctx)
{}
0
public void exitSkipDistance(WindowParser.SkipDistanceContext ctx)
{}
0
public void enterWindowWidth(WindowParser.WindowWidthContext ctx)
{}
0
public void exitWindowWidth(WindowParser.WindowWidthContext ctx)
{}
0
public void enterTimeInterval(WindowParser.TimeIntervalContext ctx)
{}
0
public void exitTimeInterval(WindowParser.TimeIntervalContext ctx)
{}
0
public void enterTimeAmount(WindowParser.TimeAmountContext ctx)
{}
0
public void exitTimeAmount(WindowParser.TimeAmountContext ctx)
{}
0
public void enterTimeUnit(WindowParser.TimeUnitContext ctx)
{}
0
public void exitTimeUnit(WindowParser.TimeUnitContext ctx)
{}
0
public void enterEveryRule(ParserRuleContext ctx)
{}
0
public void exitEveryRule(ParserRuleContext ctx)
{}
0
public void visitTerminal(TerminalNode node)
{}
0
public void visitErrorNode(ErrorNode node)
{}
0
public String[] getTokenNames()
{    return tokenNames;}
0
public Vocabulary getVocabulary()
{    return VOCABULARY;}
0
public String getGrammarFileName()
{    return "Window.g4";}
0
public String[] getRuleNames()
{    return ruleNames;}
0
public String getSerializedATN()
{    return _serializedATN;}
0
public String[] getModeNames()
{    return modeNames;}
0
public ATN getATN()
{    return _ATN;}
0
public String[] getTokenNames()
{    return tokenNames;}
0
public Vocabulary getVocabulary()
{    return VOCABULARY;}
0
public String getGrammarFileName()
{    return "Window.g4";}
0
public String[] getRuleNames()
{    return ruleNames;}
0
public String getSerializedATN()
{    return _serializedATN;}
0
public ATN getATN()
{    return _ATN;}
0
public Window_expressionContext window_expression()
{    return getRuleContext(Window_expressionContext.class, 0);}
0
public TerminalNode EOF()
{    return getToken(WindowParser.EOF, 0);}
0
public int getRuleIndex()
{    return RULE_window;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterWindow(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitWindow(this);}
0
public final WindowContext window() throws RecognitionException
{    WindowContext _localctx = new WindowContext(_ctx, getState());    enterRule(_localctx, 0, RULE_window);    try {        enterOuterAlt(_localctx, 1);        {            setState(30);            window_expression();            setState(31);            match(EOF);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_window_expression;}
0
public void copyFrom(Window_expressionContext ctx)
{    super.copyFrom(ctx);}
0
public Window_widthContext window_width()
{    return getRuleContext(Window_widthContext.class, 0);}
0
public Skip_distanceContext skip_distance()
{    return getRuleContext(Skip_distanceContext.class, 0);}
0
public DurationContext duration()
{    return getRuleContext(DurationContext.class, 0);}
0
public Including_specifierContext including_specifier()
{    return getRuleContext(Including_specifierContext.class, 0);}
0
public Excluding_specifierContext excluding_specifier()
{    return getRuleContext(Excluding_specifierContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterRepeatingWindow(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitRepeatingWindow(this);}
0
public DurationContext duration()
{    return getRuleContext(DurationContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterDenseWindow(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitDenseWindow(this);}
0
public Window_widthContext window_width()
{    return getRuleContext(Window_widthContext.class, 0);}
0
public Including_specifierContext including_specifier()
{    return getRuleContext(Including_specifierContext.class, 0);}
0
public Excluding_specifierContext excluding_specifier()
{    return getRuleContext(Excluding_specifierContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterNonRepeatingWindow(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitNonRepeatingWindow(this);}
0
public final Window_expressionContext window_expression() throws RecognitionException
{    Window_expressionContext _localctx = new Window_expressionContext(_ctx, getState());    enterRule(_localctx, 2, RULE_window_expression);    int _la;    try {        setState(50);        switch(getInterpreter().adaptivePredict(_input, 4, _ctx)) {            case 1:                _localctx = new NonRepeatingWindowContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(33);                    window_width();                    setState(35);                    _la = _input.LA(1);                    if (_la == INCLUDE) {                        {                            setState(34);                            including_specifier();                        }                    }                    setState(38);                    _la = _input.LA(1);                    if (_la == EXCLUDE) {                        {                            setState(37);                            excluding_specifier();                        }                    }                }                break;            case 2:                _localctx = new RepeatingWindowContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(40);                    window_width();                    setState(41);                    skip_distance();                    setState(42);                    duration();                    setState(44);                    _la = _input.LA(1);                    if (_la == INCLUDE) {                        {                            setState(43);                            including_specifier();                        }                    }                    setState(47);                    _la = _input.LA(1);                    if (_la == EXCLUDE) {                        {                            setState(46);                            excluding_specifier();                        }                    }                }                break;            case 3:                _localctx = new DenseWindowContext(_localctx);                enterOuterAlt(_localctx, 3);                {                    setState(49);                    duration();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode EXCLUDE()
{    return getToken(WindowParser.EXCLUDE, 0);}
0
public Specifier_listContext specifier_list()
{    return getRuleContext(Specifier_listContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_excluding_specifier;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterExcluding_specifier(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitExcluding_specifier(this);}
0
public final Excluding_specifierContext excluding_specifier() throws RecognitionException
{    Excluding_specifierContext _localctx = new Excluding_specifierContext(_ctx, getState());    enterRule(_localctx, 4, RULE_excluding_specifier);    try {        enterOuterAlt(_localctx, 1);        {            setState(52);            match(EXCLUDE);            setState(53);            specifier_list(0);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode INCLUDE()
{    return getToken(WindowParser.INCLUDE, 0);}
0
public Specifier_listContext specifier_list()
{    return getRuleContext(Specifier_listContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_including_specifier;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterIncluding_specifier(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitIncluding_specifier(this);}
0
public final Including_specifierContext including_specifier() throws RecognitionException
{    Including_specifierContext _localctx = new Including_specifierContext(_ctx, getState());    enterRule(_localctx, 6, RULE_including_specifier);    try {        enterOuterAlt(_localctx, 1);        {            setState(55);            match(INCLUDE);            setState(56);            specifier_list(0);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Day_specifierContext day_specifier()
{    return getRuleContext(Day_specifierContext.class, 0);}
0
public Specifier_arg_listContext specifier_arg_list()
{    return getRuleContext(Specifier_arg_listContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_specifier;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterSpecifier(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitSpecifier(this);}
0
public final SpecifierContext specifier() throws RecognitionException
{    SpecifierContext _localctx = new SpecifierContext(_ctx, getState());    enterRule(_localctx, 8, RULE_specifier);    try {        setState(62);        switch(getInterpreter().adaptivePredict(_input, 5, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(58);                    day_specifier();                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(59);                    day_specifier();                    setState(60);                    specifier_arg_list();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public IdentifierContext identifier()
{    return getRuleContext(IdentifierContext.class, 0);}
0
public Specifier_arg_listContext specifier_arg_list()
{    return getRuleContext(Specifier_arg_listContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_specifier_arg_list;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterSpecifier_arg_list(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitSpecifier_arg_list(this);}
0
public final Specifier_arg_listContext specifier_arg_list() throws RecognitionException
{    Specifier_arg_listContext _localctx = new Specifier_arg_listContext(_ctx, getState());    enterRule(_localctx, 10, RULE_specifier_arg_list);    try {        setState(68);        switch(getInterpreter().adaptivePredict(_input, 6, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(64);                    identifier();                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(65);                    identifier();                    setState(66);                    specifier_arg_list();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode DAY_SPECIFIER()
{    return getToken(WindowParser.DAY_SPECIFIER, 0);}
0
public int getRuleIndex()
{    return RULE_day_specifier;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterDay_specifier(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitDay_specifier(this);}
0
public final Day_specifierContext day_specifier() throws RecognitionException
{    Day_specifierContext _localctx = new Day_specifierContext(_ctx, getState());    enterRule(_localctx, 12, RULE_day_specifier);    try {        enterOuterAlt(_localctx, 1);        {            setState(70);            match(DAY_SPECIFIER);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode NUMBER()
{    return getToken(WindowParser.NUMBER, 0);}
0
public TerminalNode IDENTIFIER()
{    return getToken(WindowParser.IDENTIFIER, 0);}
0
public int getRuleIndex()
{    return RULE_identifier;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterIdentifier(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitIdentifier(this);}
0
public final IdentifierContext identifier() throws RecognitionException
{    IdentifierContext _localctx = new IdentifierContext(_ctx, getState());    enterRule(_localctx, 14, RULE_identifier);    int _la;    try {        enterOuterAlt(_localctx, 1);        {            setState(72);            _la = _input.LA(1);            if (!(_la == NUMBER || _la == IDENTIFIER)) {                _errHandler.recoverInline(this);            } else {                consume();            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public SpecifierContext specifier()
{    return getRuleContext(SpecifierContext.class, 0);}
0
public Specifier_listContext specifier_list()
{    return getRuleContext(Specifier_listContext.class, 0);}
0
public TerminalNode COMMA()
{    return getToken(WindowParser.COMMA, 0);}
0
public int getRuleIndex()
{    return RULE_specifier_list;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterSpecifier_list(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitSpecifier_list(this);}
0
public final Specifier_listContext specifier_list() throws RecognitionException
{    return specifier_list(0);}
0
private Specifier_listContext specifier_list(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Specifier_listContext _localctx = new Specifier_listContext(_ctx, _parentState);    Specifier_listContext _prevctx = _localctx;    int _startState = 16;    enterRecursionRule(_localctx, 16, RULE_specifier_list, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            {                setState(75);                specifier();            }            _ctx.stop = _input.LT(-1);            setState(82);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 7, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        {                            _localctx = new Specifier_listContext(_parentctx, _parentState);                            pushNewRecursionContext(_localctx, _startState, RULE_specifier_list);                            setState(77);                            if (!(precpred(_ctx, 1)))                                throw new FailedPredicateException(this, "precpred(_ctx, 1)");                            setState(78);                            match(COMMA);                            setState(79);                            specifier();                        }                    }                }                setState(84);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 7, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_duration;}
0
public void copyFrom(DurationContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode FROM()
{    return getToken(WindowParser.FROM, 0);}
0
public List<Time_intervalContext> time_interval()
{    return getRuleContexts(Time_intervalContext.class);}
0
public Time_intervalContext time_interval(int i)
{    return getRuleContext(Time_intervalContext.class, i);}
0
public TerminalNode TO()
{    return getToken(WindowParser.TO, 0);}
0
public List<TerminalNode> AGO()
{    return getTokens(WindowParser.AGO);}
0
public TerminalNode AGO(int i)
{    return getToken(WindowParser.AGO, i);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterFromToDuration(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitFromToDuration(this);}
0
public TerminalNode FROM()
{    return getToken(WindowParser.FROM, 0);}
0
public Time_intervalContext time_interval()
{    return getRuleContext(Time_intervalContext.class, 0);}
0
public TerminalNode AGO()
{    return getToken(WindowParser.AGO, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterFromDuration(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitFromDuration(this);}
0
public final DurationContext duration() throws RecognitionException
{    DurationContext _localctx = new DurationContext(_ctx, getState());    enterRule(_localctx, 18, RULE_duration);    int _la;    try {        setState(100);        switch(getInterpreter().adaptivePredict(_input, 11, _ctx)) {            case 1:                _localctx = new FromToDurationContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(85);                    match(FROM);                    setState(86);                    time_interval();                    setState(88);                    _la = _input.LA(1);                    if (_la == AGO) {                        {                            setState(87);                            match(AGO);                        }                    }                    setState(90);                    match(TO);                    setState(91);                    time_interval();                    setState(93);                    _la = _input.LA(1);                    if (_la == AGO) {                        {                            setState(92);                            match(AGO);                        }                    }                }                break;            case 2:                _localctx = new FromDurationContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(95);                    match(FROM);                    setState(96);                    time_interval();                    setState(98);                    _la = _input.LA(1);                    if (_la == AGO) {                        {                            setState(97);                            match(AGO);                        }                    }                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_skip_distance;}
0
public void copyFrom(Skip_distanceContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode EVERY()
{    return getToken(WindowParser.EVERY, 0);}
0
public Time_intervalContext time_interval()
{    return getRuleContext(Time_intervalContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterSkipDistance(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitSkipDistance(this);}
0
public final Skip_distanceContext skip_distance() throws RecognitionException
{    Skip_distanceContext _localctx = new Skip_distanceContext(_ctx, getState());    enterRule(_localctx, 20, RULE_skip_distance);    try {        _localctx = new SkipDistanceContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(102);            match(EVERY);            setState(103);            time_interval();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_window_width;}
0
public void copyFrom(Window_widthContext ctx)
{    super.copyFrom(ctx);}
0
public Time_intervalContext time_interval()
{    return getRuleContext(Time_intervalContext.class, 0);}
0
public TerminalNode WINDOW()
{    return getToken(WindowParser.WINDOW, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterWindowWidth(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitWindowWidth(this);}
0
public final Window_widthContext window_width() throws RecognitionException
{    Window_widthContext _localctx = new Window_widthContext(_ctx, getState());    enterRule(_localctx, 22, RULE_window_width);    int _la;    try {        _localctx = new WindowWidthContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(105);            time_interval();            setState(107);            _la = _input.LA(1);            if (_la == WINDOW) {                {                    setState(106);                    match(WINDOW);                }            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_time_interval;}
0
public void copyFrom(Time_intervalContext ctx)
{    super.copyFrom(ctx);}
0
public Time_amountContext time_amount()
{    return getRuleContext(Time_amountContext.class, 0);}
0
public Time_unitContext time_unit()
{    return getRuleContext(Time_unitContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterTimeInterval(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitTimeInterval(this);}
0
public final Time_intervalContext time_interval() throws RecognitionException
{    Time_intervalContext _localctx = new Time_intervalContext(_ctx, getState());    enterRule(_localctx, 24, RULE_time_interval);    try {        _localctx = new TimeIntervalContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(109);            time_amount();            setState(110);            time_unit();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_time_amount;}
0
public void copyFrom(Time_amountContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode NUMBER()
{    return getToken(WindowParser.NUMBER, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterTimeAmount(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitTimeAmount(this);}
0
public final Time_amountContext time_amount() throws RecognitionException
{    Time_amountContext _localctx = new Time_amountContext(_ctx, getState());    enterRule(_localctx, 26, RULE_time_amount);    try {        _localctx = new TimeAmountContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(112);            match(NUMBER);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_time_unit;}
0
public void copyFrom(Time_unitContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode TIME_UNIT()
{    return getToken(WindowParser.TIME_UNIT, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).enterTimeUnit(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof WindowListener)        ((WindowListener) listener).exitTimeUnit(this);}
0
public final Time_unitContext time_unit() throws RecognitionException
{    Time_unitContext _localctx = new Time_unitContext(_ctx, getState());    enterRule(_localctx, 28, RULE_time_unit);    try {        _localctx = new TimeUnitContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(114);            match(TIME_UNIT);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public boolean sempred(RuleContext _localctx, int ruleIndex, int predIndex)
{    switch(ruleIndex) {        case 8:            return specifier_list_sempred((Specifier_listContext) _localctx, predIndex);    }    return true;}
0
private boolean specifier_list_sempred(Specifier_listContext _localctx, int predIndex)
{    switch(predIndex) {        case 0:            return precpred(_ctx, 1);    }    return true;}
0
protected SimpleDateFormat initialValue()
{    return new SimpleDateFormat("yyyy/MM/dd");}
0
public boolean test(Long ts)
{    return DateUtils.isSameDay(new Date(ts), date);}
0
private static Calendar toCalendar(Long ts)
{    Calendar c = Calendar.getInstance();    c.setTime(new Date(ts));    return c;}
0
public static int getDayOfWeek(Long ts)
{    return toCalendar(ts).get(Calendar.DAY_OF_WEEK);}
0
public static Predicate<Long> dayOfWeekPredicate(int dayOfWeek)
{    return ts -> getDayOfWeek(ts) == dayOfWeek;}
0
public static Predicate<Long> create(String name, List<String> arg)
{    return DayPredicates.valueOf(name).predicateCreator.apply(arg);}
0
private static Optional<HolidayCalendar> getCalendar(String code)
{    for (HolidayCalendar cal : HolidayCalendar.values()) {        if (cal.getId().equalsIgnoreCase(code) || cal.name().equalsIgnoreCase(code)) {            return Optional.of(cal);        }    }    return Optional.empty();}
0
public boolean test(Long ts)
{    Calendar c = Calendar.getInstance();    c.setTime(new Date(ts));    return manager.isHoliday(c, args);}
0
public long getStartMillis(long now)
{    return startMillis.apply(now);}
0
 void setStartMillis(Function<Long, Long> startMillis)
{    this.startMillis = startMillis;}
0
public long getEndMillis(long now)
{    return endMillis.apply(now);}
0
 void setEndMillis(Function<Long, Long> endMillis)
{    this.endMillis = endMillis;}
0
public Iterable<Predicate<Long>> getIncludes(long now)
{    return includes.stream().map(include -> include.apply(now)).collect(Collectors.toList());}
0
 void setIncludes(List<Function<Long, Predicate<Long>>> includes)
{    this.includes = includes;}
0
public Iterable<Predicate<Long>> getExcludes(long now)
{    return excludes.stream().map(exclude -> exclude.apply(now)).collect(Collectors.toList());}
0
 void setExcludes(List<Function<Long, Predicate<Long>>> excludes)
{    this.excludes = excludes;}
0
public Optional<Long> getBinWidth()
{    return binWidth;}
0
 void setBinWidth(long binWidth)
{    this.binWidth = Optional.of(binWidth);}
0
public Optional<Long> getSkipDistance()
{    return skipDistance;}
0
 void setSkipDistance(long skipDistance)
{    this.skipDistance = Optional.of(skipDistance);}
0
public List<Range<Long>> toIntervals(long now)
{    List<Range<Long>> intervals = new ArrayList<>();    long startMillis = getStartMillis(now);    long endMillis = getEndMillis(now);    Iterable<Predicate<Long>> includes = getIncludes(now);    Iterable<Predicate<Long>> excludes = getExcludes(now);        long skipDistance = getSkipDistance().orElse(Long.MAX_VALUE);        Optional<Long> binWidthOpt = getBinWidth();    long binWidth = binWidthOpt.isPresent() ? binWidthOpt.get() : endMillis - startMillis;    for (long left = startMillis; left >= 0 && left + binWidth <= endMillis; left += skipDistance) {        Range<Long> interval = Range.between(left, left + binWidth);        boolean include = includes.iterator().hasNext() ? false : true;        for (Predicate<Long> inclusionPredicate : includes) {            include |= inclusionPredicate.test(left);        }        if (include) {            for (Predicate<Long> exclusionPredicate : excludes) {                include &= !exclusionPredicate.test(left);            }        }        if (include) {            intervals.add(interval);        }    }    return intervals;}
0
public Window getWindow()
{    return window;}
0
private void enterList()
{    stack.push(LIST_MARKER);}
0
private List<Function<Long, Predicate<Long>>> getPredicates()
{    LinkedList<Function<Long, Predicate<Long>>> predicates = new LinkedList<>();    while (true) {        Token<?> token = stack.pop();        if (token == LIST_MARKER) {            break;        } else {            predicates.addFirst((Function<Long, Predicate<Long>>) token.getValue());        }    }    return predicates;}
0
public void exitIdentifier(WindowParser.IdentifierContext ctx)
{    if (checkForException(ctx)) {        return;    }    stack.push(new Token<>(ctx.getText().substring(1), String.class));}
0
public void enterSpecifier(WindowParser.SpecifierContext ctx)
{    if (checkForException(ctx)) {        return;    }    stack.push(SPECIFIER_MARKER);}
0
public void exitSpecifier(WindowParser.SpecifierContext ctx)
{    LinkedList<String> args = new LinkedList<>();    while (true) {        Token<?> token = stack.pop();        if (token == SPECIFIER_MARKER) {            break;        } else {            args.addFirst((String) token.getValue());        }    }    String specifier = args.removeFirst();    List<String> arg = args.size() > 0 ? args : new ArrayList<>();    Function<Long, Predicate<Long>> predicate = null;    try {        if (specifier.equals("THIS DAY OF THE WEEK") || specifier.equals("THIS DAY OF WEEK")) {            predicate = now -> DayPredicates.dayOfWeekPredicate(DayPredicates.getDayOfWeek(now));        } else {            final Predicate<Long> dayOfWeekPredicate = DayPredicates.create(specifier, arg);            predicate = now -> dayOfWeekPredicate;        }        stack.push(new Token<>(predicate, Function.class));    } catch (Throwable t) {        throwable = t;    }}
0
public void exitDay_specifier(WindowParser.Day_specifierContext ctx)
{    if (checkForException(ctx)) {        return;    }    String specifier = ctx.getText().toUpperCase();    if (specifier.length() == 0 && ctx.exception != null) {        IllegalStateException ise = new IllegalStateException("Invalid day specifier: " + ctx.getStart().getText(), ctx.exception);        throwable = ise;        throw ise;    }    if (specifier.endsWith("S")) {        specifier = specifier.substring(0, specifier.length() - 1);    }    stack.push(new Token<>(specifier, String.class));}
0
public void enterExcluding_specifier(WindowParser.Excluding_specifierContext ctx)
{    if (checkForException(ctx)) {        return;    }    enterList();}
0
public void exitExcluding_specifier(WindowParser.Excluding_specifierContext ctx)
{    if (checkForException(ctx)) {        return;    }    window.setExcludes(getPredicates());}
0
public void enterIncluding_specifier(WindowParser.Including_specifierContext ctx)
{    if (checkForException(ctx)) {        return;    }    enterList();}
0
public void exitIncluding_specifier(WindowParser.Including_specifierContext ctx)
{    if (checkForException(ctx)) {        return;    }    window.setIncludes(getPredicates());}
0
private void setFromTo(long from, long to)
{    window.setEndMillis(now -> now - Math.min(to, from));    window.setStartMillis(now -> now - Math.max(from, to));}
0
public void exitFromToDuration(org.apache.metron.profiler.client.window.generated.WindowParser.FromToDurationContext ctx)
{    if (checkForException(ctx)) {        return;    }    Token<?> toInterval = stack.pop();    Token<?> fromInterval = stack.pop();    Long to = (Long) toInterval.getValue();    Long from = (Long) fromInterval.getValue();    setFromTo(from, to);}
0
public void exitFromDuration(org.apache.metron.profiler.client.window.generated.WindowParser.FromDurationContext ctx)
{    if (checkForException(ctx)) {        return;    }    Token<?> timeInterval = stack.pop();    Long from = (Long) timeInterval.getValue();    setFromTo(from, 0);}
0
public void exitSkipDistance(org.apache.metron.profiler.client.window.generated.WindowParser.SkipDistanceContext ctx)
{    if (checkForException(ctx)) {        return;    }    Token<?> timeInterval = stack.pop();    Long width = (Long) timeInterval.getValue();    window.setSkipDistance(width);}
0
public void exitWindowWidth(org.apache.metron.profiler.client.window.generated.WindowParser.WindowWidthContext ctx)
{    if (checkForException(ctx)) {        return;    }    Token<?> timeInterval = stack.pop();    Long width = (Long) timeInterval.getValue();    window.setBinWidth(width);    window.setStartMillis(now -> now - width);    window.setEndMillis(now -> now);}
0
public void exitTimeInterval(org.apache.metron.profiler.client.window.generated.WindowParser.TimeIntervalContext ctx)
{    if (checkForException(ctx)) {        return;    }    Token<?> timeUnit = stack.pop();    Token<?> timeDuration = stack.pop();    long duration = ConversionUtils.convert(timeDuration.getValue(), Long.class);    TimeUnit unit = (TimeUnit) timeUnit.getValue();    stack.push(new Token<>(unit.toMillis(duration), Long.class));}
0
public void exitTimeAmount(org.apache.metron.profiler.client.window.generated.WindowParser.TimeAmountContext ctx)
{    if (checkForException(ctx)) {        return;    }    if (ctx.getText().length() == 0) {        throwable = new IllegalStateException("Unable to process empty string.");        return;    }    long duration = Long.parseLong(ctx.getText());    stack.push(new Token<>(duration, Long.class));}
0
public void exitTimeUnit(org.apache.metron.profiler.client.window.generated.WindowParser.TimeUnitContext ctx)
{    checkForException(ctx);    switch(normalizeTimeUnit(ctx.getText())) {        case "DAY":            stack.push(new Token<>(TimeUnit.DAYS, TimeUnit.class));            break;        case "HOUR":            stack.push(new Token<>(TimeUnit.HOURS, TimeUnit.class));            break;        case "MINUTE":            stack.push(new Token<>(TimeUnit.MINUTES, TimeUnit.class));            break;        case "SECOND":            stack.push(new Token<>(TimeUnit.SECONDS, TimeUnit.class));            break;        default:            throw new IllegalStateException("Unsupported time unit: " + ctx.getText() + ".  Supported units are limited to: day, hour, minute, second " + "with any pluralization or capitalization.");    }}
0
private boolean checkForException(ParserRuleContext ctx)
{    if (throwable != null) {        return true;    } else if (ctx.exception != null) {        return true;    }    return false;}
0
private static String normalizeTimeUnit(String s)
{    String ret = s.toUpperCase().replaceAll("[^A-Z]", "");    if (ret.endsWith("S")) {        return ret.substring(0, ret.length() - 1);    }    return ret;}
0
private static TokenStream createTokenStream(String statement)
{    if (statement == null || isEmpty(statement.trim())) {        return null;    }    statement = statement.trim();    ANTLRInputStream input = new ANTLRInputStream(statement);    WindowLexer lexer = new WindowLexer(input);    lexer.removeErrorListeners();    lexer.addErrorListener(new ErrorListener());    TokenStream tokens = new CommonTokenStream(lexer);    return tokens;}
0
private static WindowParser createParser(TokenStream tokens, Optional<WindowProcessor> windowProcessor)
{    WindowParser parser = new WindowParser(tokens);    if (windowProcessor.isPresent()) {        parser.addParseListener(windowProcessor.get());    }    parser.removeErrorListeners();    parser.addErrorListener(new ErrorListener());    return parser;}
0
public static Window process(String statement) throws ParseException
{    TokenStream tokens = createTokenStream(statement);    if (tokens == null) {        return null;    }    WindowProcessor treeBuilder = new WindowProcessor();    WindowParser parser = createParser(tokens, Optional.of(treeBuilder));    parser.window();    if (treeBuilder.throwable != null) {        throw new ParseException(treeBuilder.throwable.getMessage(), treeBuilder.throwable);    }    return treeBuilder.getWindow();}
0
public static String syntaxTree(String statement)
{    TokenStream tokens = createTokenStream(statement);    if (tokens == null) {        return null;    }    WindowParser parser = createParser(tokens, Optional.empty());    ParseTree tree = parser.window();    return GrammarUtils.toSyntaxTree(tree);}
0
public void setup() throws Exception
{    provider = new MockHBaseTableProvider();    executor = new DefaultStellarStatefulExecutor();    MockHBaseTableProvider.addToCache(tableName, columnFamily);        long periodDurationMillis = periodUnits.toMillis(periodDuration);    RowKeyBuilder rowKeyBuilder = new SaltyRowKeyBuilder();    ColumnBuilder columnBuilder = new ValueOnlyColumnBuilder(columnFamily);    profileWriter = new ProfileWriter(rowKeyBuilder, columnBuilder, provider, periodDurationMillis, tableName, null);    client = new HBaseProfilerClient(provider, rowKeyBuilder, columnBuilder, periodDurationMillis, tableName, null);}
0
public void tearDown() throws Exception
{    ((MockHTable) provider.getTable(null, tableName)).clear();}
0
public void Should_ReturnMeasurements_When_DataExistsForAGroup() throws Exception
{    final String profile = "profile1";    final String entity = "entity1";    final int expectedValue = 2302;    final int hours = 2;    final int count = hours * periodsPerHour + 1;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);        ProfileMeasurement prototype = new ProfileMeasurement().withProfileName(profile).withEntity(entity).withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(prototype, count, Arrays.asList("weekdays"), val -> expectedValue);    profileWriter.write(prototype, count, Arrays.asList("weekends"), val -> 0);    long end = System.currentTimeMillis();    long start = end - TimeUnit.HOURS.toMillis(2);    {                List<Object> groups = Arrays.asList("weekdays");        List<ProfileMeasurement> results = client.fetch(Integer.class, profile, entity, groups, start, end, Optional.empty());        assertEquals(count, results.size());        results.forEach(actual -> {            assertEquals(profile, actual.getProfileName());            assertEquals(entity, actual.getEntity());            assertEquals(groups, actual.getGroups());            assertEquals(expectedValue, actual.getProfileValue());        });    }    {                List<Object> groups = Arrays.asList("weekends");        List<ProfileMeasurement> results = client.fetch(Integer.class, profile, entity, groups, start, end, Optional.empty());        assertEquals(count, results.size());        results.forEach(actual -> {            assertEquals(profile, actual.getProfileName());            assertEquals(entity, actual.getEntity());            assertEquals(groups, actual.getGroups());            assertEquals(0, actual.getProfileValue());        });    }}
0
public void Should_ReturnResultFromGroup_When_MultipleGroupsExist() throws Exception
{    final String profile = "profile1";    final String entity = "entity1";    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final int count = hours * periodsPerHour;    final long endTime = System.currentTimeMillis();    final long startTime = endTime - TimeUnit.HOURS.toMillis(hours);        ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, Arrays.asList("weekdays"), val -> expectedValue);    profileWriter.write(m, count, Arrays.asList("weekends"), val -> 0);    List<Object> weekdays = Arrays.asList("weekdays");    List<ProfileMeasurement> results = client.fetch(Integer.class, profile, entity, weekdays, startTime, endTime, Optional.empty());        assertEquals(count, results.size());    results.forEach(actual -> assertEquals(weekdays, actual.getGroups()));}
0
public void Should_ReturnNoResults_When_GroupDoesNotExist()
{    final String profile = "profile1";    final String entity = "entity1";    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final int count = hours * periodsPerHour;    final long endTime = System.currentTimeMillis();    final long startTime = endTime - TimeUnit.HOURS.toMillis(hours);        ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, Arrays.asList("weekdays"), val -> expectedValue);    profileWriter.write(m, count, Arrays.asList("weekends"), val -> 0);        List<Object> groups = Arrays.asList("does-not-exist");    List<ProfileMeasurement> results = client.fetch(Integer.class, profile, entity, groups, startTime, endTime, Optional.empty());    assertEquals(0, results.size());}
0
public void Should_ReturnNoResults_When_NoDataInStartToEnd() throws Exception
{    final String profile = "profile1";    final String entity = "entity1";    final int hours = 2;    int numberToWrite = hours * periodsPerHour;    final List<Object> group = Arrays.asList("weekends");    final long measurementTime = System.currentTimeMillis() - TimeUnit.DAYS.toMillis(1);        ProfileMeasurement prototype = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(measurementTime, periodDuration, periodUnits);    profileWriter.write(prototype, numberToWrite, group, val -> 1000);        final long endFetchAt = System.currentTimeMillis();    final long startFetchAt = endFetchAt - TimeUnit.MILLISECONDS.toMillis(30);    List<ProfileMeasurement> results = client.fetch(Integer.class, profile, entity, group, startFetchAt, endFetchAt, Optional.empty());    assertEquals(0, results.size());}
0
public void write(ProfileMeasurement prototype, int count, List<Object> group, Function<Object, Object> valueGenerator)
{    ProfileMeasurement m = prototype;    ProfilePeriod period = m.getPeriod();    for (int i = 0; i < count; i++) {                Object nextValue = valueGenerator.apply(m.getProfileValue());                m = new ProfileMeasurement().withProfileName(prototype.getProfileName()).withEntity(prototype.getEntity()).withPeriod(period).withGroups(group).withProfileValue(nextValue);        write(m);                period = m.getPeriod().next();    }}
0
private void write(ProfileMeasurement m)
{    byte[] rowKey = rowKeyBuilder.rowKey(m);    ColumnList cols = columnBuilder.columns(m);    hbaseClient.addMutation(rowKey, cols, Durability.SKIP_WAL);    hbaseClient.mutate();}
0
public static void main(String[] args) throws Exception
{    RowKeyBuilder rowKeyBuilder = new SaltyRowKeyBuilder();    ColumnBuilder columnBuilder = new ValueOnlyColumnBuilder();    Configuration config = HBaseConfiguration.create();    config.set("hbase.master.hostname", "node1");    config.set("hbase.regionserver.hostname", "node1");    config.set("hbase.zookeeper.quorum", "node1");    HTableProvider provider = new HTableProvider();    String tableName = "profiler";    long periodDurationMillis = TimeUnit.MINUTES.toMillis(15);    long when = System.currentTimeMillis() - TimeUnit.DAYS.toMillis(2);    ProfileMeasurement measure = new ProfileMeasurement().withProfileName("profile1").withEntity("192.168.66.121").withPeriod(when, periodDurationMillis, TimeUnit.MILLISECONDS);    ProfileWriter writer = new ProfileWriter(rowKeyBuilder, columnBuilder, provider, periodDurationMillis, tableName, config);    writer.write(measure, 2 * 24 * 4, Collections.emptyList(), val -> new Random().nextInt(10));}
0
private T run(String expression, Class<T> clazz)
{    return executor.execute(expression, state, clazz);}
0
public void setup()
{    state = new HashMap<>();    final Table table = MockHBaseTableProvider.addToCache(tableName, columnFamily);        long periodDurationMillis = TimeUnit.MINUTES.toMillis(15);    RowKeyBuilder rowKeyBuilder = new SaltyRowKeyBuilder();    ColumnBuilder columnBuilder = new ValueOnlyColumnBuilder(columnFamily);    profileWriter = new ProfileWriter(rowKeyBuilder, columnBuilder, new MockHBaseTableProvider(), periodDurationMillis, tableName, null);        Map<String, Object> global = new HashMap<String, Object>() {        {            put(PROFILER_HBASE_TABLE.getKey(), tableName);            put(PROFILER_COLUMN_FAMILY.getKey(), columnFamily);            put(PROFILER_HBASE_TABLE_PROVIDER.getKey(), MockHBaseTableProvider.class.getName());            put(PROFILER_PERIOD.getKey(), Long.toString(periodDuration));            put(PROFILER_PERIOD_UNITS.getKey(), periodUnits.toString());            put(PROFILER_SALT_DIVISOR.getKey(), Integer.toString(saltDivisor));        }    };        executor = new DefaultStellarStatefulExecutor(new SimpleFunctionResolver().withClass(GetProfile.class).withClass(FixedLookback.class), new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> global).build());}
0
private Context setup2()
{    state = new HashMap<>();        Map<String, Object> global = new HashMap<String, Object>() {        {            put(PROFILER_HBASE_TABLE.getKey(), tableName);            put(PROFILER_COLUMN_FAMILY.getKey(), columnFamily);            put(PROFILER_HBASE_TABLE_PROVIDER.getKey(), MockHBaseTableProvider.class.getName());            put(PROFILER_PERIOD.getKey(), Long.toString(periodDuration2));            put(PROFILER_PERIOD_UNITS.getKey(), periodUnits2.toString());            put(PROFILER_SALT_DIVISOR.getKey(), Integer.toString(saltDivisor2));        }    };        Context context2 = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> global).build();        executor = new DefaultStellarStatefulExecutor(new SimpleFunctionResolver().withClass(GetProfile.class).withClass(FixedLookback.class), context2);        return context2;}
0
public void testWithNoGroups()
{    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Collections.emptyList();        final int count = hours * periodsPerHour;    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, group, val -> expectedValue);        String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'))";    @SuppressWarnings("unchecked")    List<Integer> result = run(expr, List.class);        Assert.assertEquals(count, result.size());    result.forEach(actual -> Assert.assertEquals(expectedValue, actual.intValue()));}
0
public void testWithOneGroup()
{    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Arrays.asList("weekends");        final int count = hours * periodsPerHour;    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, group, val -> expectedValue);        state.put("groups", group);        String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'), ['weekends'])";    @SuppressWarnings("unchecked")    List<Integer> result = run(expr, List.class);        Assert.assertEquals(count, result.size());        expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'), 'weekends')";    result = run(expr, List.class);        Assert.assertEquals(count, result.size());    result.forEach(actual -> Assert.assertEquals(expectedValue, actual.intValue()));}
0
public void testWithTwoGroups()
{    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Arrays.asList("weekdays", "tuesday");        final int count = hours * periodsPerHour;    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, group, val -> expectedValue);        state.put("groups", group);        String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'), ['weekdays', 'tuesday'])";    @SuppressWarnings("unchecked")    List<Integer> result = run(expr, List.class);        Assert.assertEquals(count, result.size());        expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'), 'weekdays', 'tuesday')";    result = run(expr, List.class);        Assert.assertEquals(count, result.size());    result.forEach(actual -> Assert.assertEquals(expectedValue, actual.intValue()));}
0
public void testMissingContext()
{    Context empty = Context.EMPTY_CONTEXT();        executor.setContext(empty);        SingletonFunctionResolver.getInstance().initialize(empty);        String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(1000, 'SECONDS'), groups)";    run(expr, List.class);}
0
public void testOutsideTimeHorizon()
{    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Collections.emptyList();        ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, 1, group, val -> expectedValue);        state.put("groups", group);        String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'SECONDS'))";    @SuppressWarnings("unchecked")    List<Integer> result = run(expr, List.class);        Assert.assertEquals(0, result.size());}
0
public void testWithDefaultValue()
{    String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'))";    @SuppressWarnings("unchecked")    List<Integer> result = run(expr, List.class);        Assert.assertEquals(0, result.size());            testOverride("{'profiler.default.value' : 0}", 0);    testOverride("{'profiler.default.value' : 'metron'}", "metron");    testOverride("{'profiler.default.value' : []}", new ArrayList<>());}
0
private void testOverride(String overrides, Object defaultVal)
{    String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'), [], " + overrides + ")";    List<Object> result = run(expr, List.class);            Assert.assertTrue(result.size() == 16 || result.size() == 17);    result.forEach(actual -> Assert.assertEquals(defaultVal, actual));}
0
public void testWithConfigOverride()
{    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Collections.emptyList();        final int count = hours * periodsPerHour;    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, group, val -> expectedValue);        Context context2 = setup2();        @SuppressWarnings("unchecked")    Map<String, Object> global = (Map<String, Object>) context2.getCapability(Context.Capabilities.GLOBAL_CONFIG).get();    Assert.assertEquals(PROFILER_PERIOD.get(global), periodDuration2);    Assert.assertNotEquals(periodDuration, periodDuration2);                String expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'))";    @SuppressWarnings("unchecked")    List<Integer> result = run(expr, List.class);        Assert.assertEquals(0, result.size());            String overrides = "{'profiler.client.period.duration' : '" + periodDuration + "', " + "'profiler.client.period.duration.units' : '" + periodUnits.toString() + "', " + "'profiler.client.salt.divisor' : " + saltDivisor + " }";    expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS', " + overrides + "), [], " + overrides + ")";    result = run(expr, List.class);        Assert.assertEquals(count, result.size());    result.forEach(actual -> Assert.assertEquals(expectedValue, actual.intValue()));}
0
public void testWithConfigAndOneGroup()
{    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Arrays.asList("weekends");        final int count = hours * periodsPerHour;    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, group, val -> expectedValue);        state.put("groups", group);        Context context2 = setup2();        @SuppressWarnings("unchecked")    Map<String, Object> global = (Map<String, Object>) context2.getCapability(Context.Capabilities.GLOBAL_CONFIG).get();    Assert.assertEquals(global.get(PROFILER_PERIOD.getKey()), Long.toString(periodDuration2));    Assert.assertNotEquals(periodDuration, periodDuration2);            String overrides = "{'profiler.client.period.duration' : '" + periodDuration + "', " + "'profiler.client.period.duration.units' : '" + periodUnits.toString() + "', " + "'profiler.client.salt.divisor' : " + saltDivisor + " }";    String expr = "PROFILE_GET('profile1', 'entity1'" + ", PROFILE_FIXED(4, 'HOURS', " + overrides + "), ['weekends'], " + overrides + ")";    @SuppressWarnings("unchecked")    List<Integer> result = run(expr, List.class);        Assert.assertEquals(count, result.size());                expr = "PROFILE_GET('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'), ['weekends'])";    result = run(expr, List.class);        Assert.assertEquals(0, result.size());}
0
public void testBasicTest()
{    List<Range<Long>> intervals = new ArrayList<Range<Long>>() {        {            add(Range.between(0L, 10L));            add(Range.between(20L, 30L));            add(Range.between(40L, 50L));        }    };    IntervalPredicate<Long> predicate = new IntervalPredicate.Identity(intervals);    Assert.assertTrue(predicate.test(0L));    Assert.assertTrue(predicate.test(10L));    Assert.assertTrue(predicate.test(5L));    Assert.assertFalse(predicate.test(51L));    Assert.assertFalse(predicate.test(15L));}
0
public void testWithOverlap()
{    List<Range<Long>> intervals = new ArrayList<Range<Long>>() {        {            add(Range.between(0L, 10L));            add(Range.between(5L, 30L));            add(Range.between(40L, 50L));        }    };    IntervalPredicate<Long> predicate = new IntervalPredicate.Identity(intervals);    Assert.assertTrue(predicate.test(0L));    Assert.assertTrue(predicate.test(5L));    Assert.assertTrue(predicate.test(30L));    Assert.assertTrue(predicate.test(10L));    Assert.assertFalse(predicate.test(51L));    Assert.assertTrue(predicate.test(15L));    Assert.assertFalse(predicate.test(31L));    Assert.assertTrue(predicate.test(45L));}
0
public void testTrivialCase()
{    List<Range<Long>> intervals = new ArrayList<Range<Long>>() {        {            add(Range.between(0L, 10L));        }    };    IntervalPredicate<Long> predicate = new IntervalPredicate.Identity(intervals);    Assert.assertTrue(predicate.test(0L));    Assert.assertTrue(predicate.test(5L));    Assert.assertTrue(predicate.test(10L));    Assert.assertFalse(predicate.test(51L));    Assert.assertFalse(predicate.test(15L));}
0
public void testDegenerateCase()
{    List<Range<Long>> intervals = new ArrayList<Range<Long>>() {        {            add(Range.between(10L, 10L));        }    };    IntervalPredicate<Long> predicate = new IntervalPredicate.Identity(intervals);    Assert.assertFalse(predicate.test(0L));    Assert.assertFalse(predicate.test(5L));    Assert.assertTrue(predicate.test(10L));    Assert.assertFalse(predicate.test(11L));}
0
private T run(String expression, Class<T> clazz)
{    return executor.execute(expression, state, clazz);}
0
public void setup()
{    state = new HashMap<>();    final Table table = MockHBaseTableProvider.addToCache(tableName, columnFamily);    TableProvider provider = new MockHBaseTableProvider();        long periodDurationMillis = TimeUnit.MINUTES.toMillis(15);    RowKeyBuilder rowKeyBuilder = new SaltyRowKeyBuilder();    ColumnBuilder columnBuilder = new ValueOnlyColumnBuilder(columnFamily);    profileWriter = new ProfileWriter(rowKeyBuilder, columnBuilder, provider, periodDurationMillis, tableName, null);        globals = new HashMap<String, Object>() {        {            put(PROFILER_HBASE_TABLE.getKey(), tableName);            put(PROFILER_COLUMN_FAMILY.getKey(), columnFamily);            put(PROFILER_HBASE_TABLE_PROVIDER.getKey(), MockHBaseTableProvider.class.getName());            put(PROFILER_PERIOD.getKey(), Long.toString(periodDuration));            put(PROFILER_PERIOD_UNITS.getKey(), periodUnits.toString());            put(PROFILER_SALT_DIVISOR.getKey(), Integer.toString(saltDivisor));        }    };        executor = new DefaultStellarStatefulExecutor(new SimpleFunctionResolver().withClass(VerboseProfile.class).withClass(FixedLookback.class), new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> globals).build());}
0
public void shouldReturnMeasurementsWhenNotGrouped()
{    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Collections.emptyList();        final int count = hours * periodsPerHour;    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, group, val -> expectedValue);        List<Map<String, Object>> results;    results = run("PROFILE_VERBOSE('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'))", List.class);    Assert.assertEquals(count, results.size());    for (Map<String, Object> actual : results) {        Assert.assertEquals("profile1", actual.get(PROFILE_KEY));        Assert.assertEquals("entity1", actual.get(ENTITY_KEY));        Assert.assertNotNull(actual.get(PERIOD_KEY));        Assert.assertNotNull(actual.get(PERIOD_START_KEY));        Assert.assertNotNull(actual.get(PERIOD_END_KEY));        Assert.assertNotNull(actual.get(GROUPS_KEY));        Assert.assertEquals(expectedValue, actual.get(VALUE_KEY));    }}
0
public void shouldReturnMeasurementsWhenGrouped()
{    final int periodsPerHour = 4;    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Arrays.asList("weekends");        final int count = hours * periodsPerHour;    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, count, group, val -> expectedValue);        state.put("groups", group);        List<Map<String, Object>> results;    results = run("PROFILE_VERBOSE('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'), groups)", List.class);    Assert.assertEquals(count, results.size());    for (Map<String, Object> actual : results) {        Assert.assertEquals("profile1", actual.get(PROFILE_KEY));        Assert.assertEquals("entity1", actual.get(ENTITY_KEY));        Assert.assertNotNull(actual.get(PERIOD_KEY));        Assert.assertNotNull(actual.get(PERIOD_START_KEY));        Assert.assertNotNull(actual.get(PERIOD_END_KEY));        Assert.assertNotNull(actual.get(GROUPS_KEY));        Assert.assertEquals(expectedValue, actual.get(VALUE_KEY));    }}
0
public void shouldReturnNothingWhenNoMeasurementsExist()
{    final int expectedValue = 2302;    final int hours = 2;    final long startTime = System.currentTimeMillis() - TimeUnit.HOURS.toMillis(hours);    final List<Object> group = Collections.emptyList();        ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile1").withEntity("entity1").withPeriod(startTime, periodDuration, periodUnits);    profileWriter.write(m, 1, group, val -> expectedValue);        List<Map<String, Object>> result;    result = run("PROFILE_VERBOSE('profile1', 'entity1', PROFILE_FIXED(4, 'SECONDS'))", List.class);    Assert.assertEquals(0, result.size());}
0
public void shouldReturnDefaultValueWhenNoMeasurementsExist()
{        String defaultVal = "this is the default value";    globals.put("profiler.default.value", defaultVal);        String expr = "PROFILE_VERBOSE('profile1', 'entity1', PROFILE_FIXED(4, 'HOURS'))";    List<Map<String, Object>> results = run(expr, List.class);        Assert.assertTrue(results.size() == 16 || results.size() == 17);    for (Map<String, Object> actual : results) {        Assert.assertEquals("profile1", actual.get(PROFILE_KEY));        Assert.assertEquals("entity1", actual.get(ENTITY_KEY));        Assert.assertNotNull(actual.get(PERIOD_KEY));        Assert.assertNotNull(actual.get(PERIOD_START_KEY));        Assert.assertNotNull(actual.get(PERIOD_END_KEY));        Assert.assertNotNull(actual.get(GROUPS_KEY));                Assert.assertEquals(defaultVal, actual.get(VALUE_KEY));    }}
0
public static void setup()
{    resolver = new SimpleFunctionResolver().withClass(GetProfile.class).withClass(FixedLookback.class).withClass(WindowLookback.class);    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> new HashMap<>()).build();}
0
public void testSpecifyingConfig() throws Exception
{                long durationMs = 60000;    Map<String, Object> config = new HashMap<>();    config.put(ProfilerClientConfig.PROFILER_PERIOD.getKey(), 1);    State state = test("1 hour", new Date(), Optional.of(config), Assertions.NOT_EMPTY, Assertions.CONTIGUOUS);    Assert.assertEquals(TimeUnit.HOURS.toMillis(1) / durationMs, state.periods.size());}
0
public void testSpecifyingOnlySelector()
{    String stellarStatement = "PROFILE_WINDOW('1 hour')";    Map<String, Object> variables = new HashMap<>();    StellarProcessor stellar = new StellarProcessor();    List<ProfilePeriod> periods = (List<ProfilePeriod>) stellar.parse(stellarStatement, new DefaultVariableResolver(k -> variables.get(k), k -> variables.containsKey(k)), resolver, context);    Assert.assertEquals(TimeUnit.HOURS.toMillis(1) / getDurationMs(), periods.size());}
0
public void testDenseLookback() throws Exception
{    State state = test("1 hour", Assertions.NOT_EMPTY, Assertions.CONTIGUOUS);    Assert.assertEquals(TimeUnit.HOURS.toMillis(1) / getDurationMs(), state.periods.size());}
0
public void testShiftedDenseLookback() throws Exception
{    State state = test("from 2 hours ago to 30 minutes ago", Assertions.NOT_EMPTY, Assertions.CONTIGUOUS, Assertions.INTERVALS_CONTAIN_ALL_PERIODS);    Assert.assertEquals(TimeUnit.MINUTES.toMillis(90) / getDurationMs(), state.periods.size());}
0
public void testShiftedSparseLookback() throws Exception
{    State state = test("30 minute window every 1 hour from 2 hours ago to 30 minutes ago", Assertions.NOT_EMPTY, Assertions.DISCONTIGUOUS, Assertions.INTERVALS_CONTAIN_ALL_PERIODS);    Assert.assertEquals(TimeUnit.MINUTES.toMillis(60) / getDurationMs(), state.periods.size());}
0
public void testEmptyDueToExclusions() throws Exception
{    test("30 minute window every 24 hours from 7 days ago including saturdays excluding weekends", Assertions.EMPTY);}
0
public void testErrorInSelector() throws Exception
{    test("30 minute idow every 24 hours from 7 days ago including saturdays excluding weekends", Assertions.EMPTY);}
0
 long getDurationMs()
{    int duration = ProfilerClientConfig.PROFILER_PERIOD.getDefault(Integer.class);    TimeUnit unit = TimeUnit.valueOf(ProfilerClientConfig.PROFILER_PERIOD_UNITS.getDefault(String.class));    return unit.toMillis(duration);}
0
public State test(String windowSelector, Assertions... assertions)
{    return test(windowSelector, new Date(), Optional.empty(), assertions);}
0
public State test(String windowSelector, Date now, Optional<Map<String, Object>> config, Assertions... assertions)
{    List<Range<Long>> windowIntervals = WindowProcessor.process(windowSelector).toIntervals(now.getTime());    String stellarStatement = "PROFILE_WINDOW('" + windowSelector + "', now" + (config.isPresent() ? ", config" : "") + ")";    Map<String, Object> variables = new HashMap<>();    variables.put("now", now.getTime());    if (config.isPresent()) {        variables.put("config", config.get());    }    StellarProcessor stellar = new StellarProcessor();    List<ProfilePeriod> periods = (List<ProfilePeriod>) stellar.parse(stellarStatement, new DefaultVariableResolver(k -> variables.get(k), k -> variables.containsKey(k)), resolver, context);    State state = new State(windowIntervals, periods);    for (Assertions assertion : assertions) {        Assert.assertTrue(assertion.name(), assertion.test(state));    }    return state;}
0
public boolean test(State s)
{    return predicate.test(s);}
0
public void testBaseCase()
{    for (String text : new String[] { "1 hour", "1 hour(s)", "1 hours" }) {        Window w = WindowProcessor.process(text);        Date now = new Date();        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(1, intervals.size());        Assert.assertEquals(now.getTime(), (long) intervals.get(0).getMaximum());        Assert.assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(1), (long) intervals.get(0).getMinimum());    }}
0
public void testDenseWindow()
{    for (String text : new String[] { "from 2 hours ago to 30 minutes ago", "starting from 2 hours until 30 minutes", "starting from 2 hours ago until 30 minutes ago", "starting from 30 minutes ago until 2 hours ago", "from 30 minutes ago to 2 hours ago " }) {        Window w = WindowProcessor.process(text);        /*    A dense window starting 2 hour ago and continuing until 30 minutes ago     */        Date now = new Date();        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(1, intervals.size());        assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(2), intervals.get(0).getMinimum());        assertEquals(now.getTime() - TimeUnit.MINUTES.toMillis(30), intervals.get(0).getMaximum());    }}
0
public void testSparse()
{    for (String text : new String[] { "30 minute window every 1 hour from 2 hours ago to 30 minutes ago", "30 minute window every 1 hour starting from 2 hours ago to 30 minutes ago", "30 minute window every 1 hour starting from 2 hours ago until 30 minutes ago", "30 minute window for every 1 hour starting from 2 hours ago until 30 minutes ago" }) {        Window w = WindowProcessor.process(text);        /*    A window size of 30 minutes    Starting 2 hour ago and continuing until 30 minutes ago    window 1: ( now - 2 hour, now - 2 hour + 30 minutes)    window 2: (now - 1 hour, now - 1 hour + 30 minutes)     */        Date now = new Date();        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(2, intervals.size());        assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(2), intervals.get(0).getMinimum());        assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(2) + TimeUnit.MINUTES.toMillis(30), intervals.get(0).getMaximum());        assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(1), intervals.get(1).getMinimum());        assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(1) + TimeUnit.MINUTES.toMillis(30), intervals.get(1).getMaximum());    }}
0
public void testRepeatTilNow()
{    Window w = WindowProcessor.process("30 minute window every 1 hour from 3 hours ago");    /*    A window size of 30 minutes    Starting 3 hours ago and continuing until now    window 1: ( now - 3 hour, now - 3 hour + 30 minutes)    window 2: ( now - 2 hour, now - 2 hour + 30 minutes)    window 3: ( now - 1 hour, now - 1 hour + 30 minutes)     */    Date now = new Date();    List<Range<Long>> intervals = w.toIntervals(now.getTime());    Assert.assertEquals(3, intervals.size());    assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(3), intervals.get(0).getMinimum());    assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(3) + TimeUnit.MINUTES.toMillis(30), intervals.get(0).getMaximum());    assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(2), intervals.get(1).getMinimum());    assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(2) + TimeUnit.MINUTES.toMillis(30), intervals.get(1).getMaximum());    assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(1), intervals.get(2).getMinimum());    assertEquals(now.getTime() - TimeUnit.HOURS.toMillis(1) + TimeUnit.MINUTES.toMillis(30), intervals.get(2).getMaximum());}
0
public void testRepeatWithInclusions()
{    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago including tuesdays");        /*    A window size of 30 minutes    Starting 14 days ago  and continuing until now    Gotta be 2 tuesdays in 14 days.     */        Date now = new Date();                now.setHours(6);        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(2, intervals.size());    }    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago including this day of the week");        /*    A window size of 30 minutes    Starting 14 days ago  and continuing until now    Gotta be 2 days with the same dow in 14 days.     */        Date now = new Date();                now.setHours(6);        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(2, intervals.size());    }    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago");        /*    A window size of 30 minutes    Starting 14 days ago  and continuing until now    Gotta be 14 intervals in 14 days.     */        Date now = new Date();        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(14, intervals.size());    }}
0
public void testRepeatWithConflictingExclusionInclusion() throws ParseException
{    Window w = WindowProcessor.process("30 minute window every 24 hours from 7 days ago including saturdays excluding weekends");    Date now = new Date();        now.setHours(6);    List<Range<Long>> intervals = w.toIntervals(now.getTime());    Assert.assertEquals(0, intervals.size());}
0
public void testRepeatWithWeekendExclusion() throws ParseException
{    Window w = WindowProcessor.process("30 minute window every 24 hours from 7 days ago excluding weekends");    Date now = new Date();        now.setHours(6);    List<Range<Long>> intervals = w.toIntervals(now.getTime());    Assert.assertEquals(5, intervals.size());}
0
public void testRepeatWithInclusionExclusion() throws ParseException
{    Window w = WindowProcessor.process("30 minute window every 24 hours from 7 days ago including holidays:us excluding weekends");    SimpleDateFormat sdf = new SimpleDateFormat("yyyy/MM/dd HH:mm");    Date now = sdf.parse("2017/12/26 12:00");    List<Range<Long>> intervals = w.toIntervals(now.getTime());    Assert.assertEquals(1, intervals.size());}
0
public void testManyMoonsAgo() throws ParseException
{    {        Window w = WindowProcessor.process("1 hour window every 24 hours starting from 56 days ago");        Date now = new Date();        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(56, intervals.size());    }    {        Window w = WindowProcessor.process("1 hour window every 24 hours starting from 56 days ago including this day of the week");        Date now = new Date();                now.setHours(6);        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(8, intervals.size());    }}
0
public void testRepeatWithWeekdayExclusion() throws ParseException
{    Window w = WindowProcessor.process("30 minute window every 24 hours from 7 days ago excluding weekdays");    Date now = new Date();        now.setHours(6);    List<Range<Long>> intervals = w.toIntervals(now.getTime());    Assert.assertEquals(2, intervals.size());}
0
public void testRepeatWithHolidayExclusion() throws ParseException
{    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago excluding holidays:us");        SimpleDateFormat sdf = new SimpleDateFormat("yyyy/MM/dd HH:mm");        Date now = sdf.parse("2017/12/26 12:00");        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(13, intervals.size());    }    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago excluding holidays:us:nyc");        SimpleDateFormat sdf = new SimpleDateFormat("yyyy/MM/dd HH:mm");        Date now = sdf.parse("2017/12/26 12:00");        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(13, intervals.size());    }    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago excluding holidays:us");        SimpleDateFormat sdf = new SimpleDateFormat("yyyy/MM/dd HH:mm");        Date now = sdf.parse("2017/08/26 12:00");        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(14, intervals.size());    }}
0
public void testDateDaySpecifier() throws ParseException
{    for (String text : new String[] { "30 minute window every 24 hours from 14 days ago including date:20171225:yyyyMMdd", "30 minute window every 24 hours from 14 days ago including date:2017-12-25:yyyy-MM-dd", "30 minute window every 24 hours from 14 days ago including date:2017/12/25" }) {        Window w = WindowProcessor.process(text);        SimpleDateFormat sdf = new SimpleDateFormat("yyyy/MM/dd HH:mm");        Date now = sdf.parse("2017/12/26 12:00");        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(1, intervals.size());        Date includedDate = new Date(intervals.get(0).getMinimum());        SimpleDateFormat equalityFormat = new SimpleDateFormat("yyyyMMdd");        Assert.assertEquals("20171225", equalityFormat.format(includedDate));    }    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago excluding date:2017/12/25");        SimpleDateFormat sdf = new SimpleDateFormat("yyyy/MM/dd HH:mm");        Date now = sdf.parse("2017/12/26 12:00");        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(13, intervals.size());    }    {        Window w = WindowProcessor.process("30 minute window every 24 hours from 14 days ago including date:2017/12/25, date:2017/12/24");        SimpleDateFormat sdf = new SimpleDateFormat("yyyy/MM/dd HH:mm");        Date now = sdf.parse("2017/12/26 12:00");        List<Range<Long>> intervals = w.toIntervals(now.getTime());        Assert.assertEquals(2, intervals.size());        {            Date includedDate = new Date(intervals.get(0).getMinimum());            SimpleDateFormat equalityFormat = new SimpleDateFormat("yyyyMMdd");            Assert.assertEquals("20171224", equalityFormat.format(includedDate));        }        {            Date includedDate = new Date(intervals.get(1).getMinimum());            SimpleDateFormat equalityFormat = new SimpleDateFormat("yyyyMMdd");            Assert.assertEquals("20171225", equalityFormat.format(includedDate));        }    }}
0
public void testWithInvalidDaySpecifier() throws ParseException
{    WindowProcessor.process("30 minute window every 24 hours from 14 days ago excluding hoolidays:us");}
0
public void testWithInvalidTimeUnit() throws ParseException
{    WindowProcessor.process("30 minute window every 24 months from 14 days ago");}
0
public void testWithInvalidWindowUnit() throws ParseException
{    WindowProcessor.process("30 minuete window every 24 hours from 14 days ago");}
0
public void testWithInvalidTimeNumber() throws ParseException
{    WindowProcessor.process("30p minute window every 24 hours from 14 days ago");}
0
public void testInvalidDaySpecifier() throws ParseException
{    WindowProcessor.process("30 minute window every 14 hours from 14 days ago including date");}
0
private static void assertEquals(long expected, long actual)
{    long diff = expected - actual;    long diffInMinutes = TimeUnit.MILLISECONDS.toMinutes(diff);    String message = expected + " - " + actual + " = " + diffInMinutes + " minutes off.";    Assert.assertEquals(message, expected, actual);}
0
public Clock createClock(ProfilerConfig config)
{    Clock clock;    boolean isEventTime = config.getTimestampField().isPresent();    if (isEventTime) {                String timestampField = config.getTimestampField().get();        clock = new EventTimeClock(timestampField);    } else {                clock = new WallClock();    }    return clock;}
0
public Optional<Long> currentTimeMillis(JSONObject message)
{    Long result;    if (message != null && message.containsKey(timestampField)) {                Object timestamp = message.get(timestampField);        result = ConversionUtils.convert(timestamp, Long.class);    } else {                        result = null;    }    return Optional.ofNullable(result);}
1
public Clock createClock(ProfilerConfig config)
{    Clock clock;    boolean isEventTime = config.getTimestampField().isPresent();    if (isEventTime) {        String timestampField = config.getTimestampField().get();        clock = new EventTimeClock(timestampField);    } else {        throw new IllegalStateException("Expected profiler to use event time.");    }    return clock;}
0
public void setTime(long epochMillis)
{    this.epochMillis = epochMillis;}
0
public Optional<Long> currentTimeMillis(JSONObject message)
{    return Optional.of(this.epochMillis);}
0
public Clock createClock(ProfilerConfig config)
{    return new FixedClock(timestamp);}
0
public Optional<Long> currentTimeMillis(JSONObject message)
{        return Optional.of(System.currentTimeMillis());}
0
public void distribute(MessageRoute route, Context context)
{    try {        ProfileBuilder builder = getBuilder(route, context);        builder.apply(route.getMessage(), route.getTimestamp());    } catch (ExecutionException e) {                throw new RuntimeException(e);    }}
1
public List<ProfileMeasurement> flush()
{            cacheMaintenance();    List<ProfileMeasurement> measurements = flushCache(activeCache);    return measurements;}
1
public List<ProfileMeasurement> flushExpired()
{            cacheMaintenance();        List<ProfileMeasurement> measurements = flushCache(expiredCache);        expiredCache.invalidateAll();    return measurements;}
1
private void cacheMaintenance()
{    activeCache.cleanUp();        expiredCache.cleanUp();    }
1
private List<ProfileMeasurement> flushCache(Cache<Integer, ProfileBuilder> cache)
{    List<ProfileMeasurement> measurements = new ArrayList<>();    for (ProfileBuilder profileBuilder : cache.asMap().values()) {                if (profileBuilder.isInitialized()) {                        Optional<ProfileMeasurement> measurement = profileBuilder.flush();            measurement.ifPresent(m -> measurements.add(m));        }    }    return measurements;}
0
public ProfileBuilder getBuilder(MessageRoute route, Context context) throws ExecutionException
{    ProfileConfig profile = route.getProfileDefinition();    String entity = route.getEntity();    Function<Integer, ProfileBuilder> profileCreator = (k) -> new DefaultProfileBuilder.Builder().withDefinition(profile).withEntity(entity).withPeriodDurationMillis(periodDurationMillis).withContext(context).build();    return activeCache.get(cacheKey(profile, entity), profileCreator);}
0
private int cacheKey(ProfileConfig profile, String entity)
{    return new HashCodeBuilder(17, 37).append(profile).append(entity).hashCode();}
0
public DefaultMessageDistributor withPeriodDurationMillis(long periodDurationMillis)
{    this.periodDurationMillis = periodDurationMillis;    return this;}
0
public DefaultMessageDistributor withPeriodDuration(int duration, TimeUnit units)
{    return withPeriodDurationMillis(units.toMillis(duration));}
0
public void write(@Nonnull Integer key, @Nonnull ProfileBuilder value)
{}
0
public void write(@Nonnull Integer key, @Nonnull ProfileBuilder value)
{}
0
public List<MessageRoute> route(JSONObject message, ProfilerConfig config, Context context)
{    List<MessageRoute> routes = new ArrayList<>();        for (ProfileConfig profile : config.getProfiles()) {        Clock clock = clockFactory.createClock(config);        Optional<MessageRoute> route = routeToProfile(message, profile, clock);        route.ifPresent(routes::add);    }    return routes;}
0
private Optional<MessageRoute> routeToProfile(JSONObject message, ProfileConfig profile, Clock clock)
{    Optional<MessageRoute> route = Optional.empty();        @SuppressWarnings("unchecked")    final Map<String, Object> state = (Map<String, Object>) message;    try {                if (executor.execute(profile.getOnlyif(), state, Boolean.class)) {                        Optional<Long> timestamp = clock.currentTimeMillis(message);            if (timestamp.isPresent()) {                                String entity = executor.execute(profile.getForeach(), state, String.class);                route = Optional.of(new MessageRoute(profile, entity, message, timestamp.get()));            }        }    } catch (Throwable e) {                String msg = format("error while executing profile; profile='%s', error='%s'", profile.getProfile(), e.getMessage());            }    return route;}
1
public void setExecutor(StellarStatefulExecutor executor)
{    this.executor = executor;}
0
public void setClockFactory(ClockFactory clockFactory)
{    this.clockFactory = clockFactory;}
0
public Optional<ProfileMeasurement> flush()
{    Optional<ProfileMeasurement> result;    ProfilePeriod period = ProfilePeriod.fromTimestamp(maxTimestamp, periodDurationMillis, TimeUnit.MILLISECONDS);    try {                String profileExpression = definition.getResult().getProfileExpressions().getExpression();        Object profileValue = execute(profileExpression, "result/profile");                Map<String, Object> triageValues = definition.getResult().getTriageExpressions().getExpressions().entrySet().stream().collect(Collectors.toMap(e -> e.getKey(), e -> execute(e.getValue(), "result/triage")));                Map<String, Object> state = new HashMap<>();        state.put("profile", profileName);        state.put("entity", entity);        state.put("start", period.getStartTimeMillis());        state.put("end", period.getEndTimeMillis());        state.put("duration", period.getDurationMillis());        state.put("result", profileValue);                List<Object> groups = execute(definition.getGroupBy(), state, "groupBy");        result = Optional.of(new ProfileMeasurement().withProfileName(profileName).withEntity(entity).withGroups(groups).withPeriod(period).withProfileValue(profileValue).withTriageValues(triageValues).withDefinition(definition));    } catch (Throwable e) {                        result = Optional.empty();    }        isInitialized = false;    return result;}
1
public Object valueOf(String variable)
{    return executor.getState().get(variable);}
0
public boolean isInitialized()
{    return isInitialized;}
0
public ProfileConfig getDefinition()
{    return definition;}
0
private Object execute(String expression, Map<String, Object> transientState, String expressionType)
{    Object result = null;    List<Object> allResults = execute(Collections.singletonList(expression), transientState, expressionType);    if (allResults.size() > 0) {        result = allResults.get(0);    }    return result;}
0
private Object execute(String expression, String expressionType)
{    return execute(expression, Collections.emptyMap(), expressionType);}
0
private void assign(Map<String, String> expressions, Map<String, Object> transientState, String expressionType)
{        for (Map.Entry<String, String> entry : MapUtils.emptyIfNull(expressions).entrySet()) {        String var = entry.getKey();        String expr = entry.getValue();        try {                        executor.assign(var, expr, transientState);        } catch (Throwable e) {                        Set<String> variablesInScope = new HashSet<>();            variablesInScope.addAll(transientState.keySet());            variablesInScope.addAll(executor.getState().keySet());            String msg = format("Bad '%s' expression: error='%s', expr='%s', profile='%s', entity='%s', variables-available='%s'", expressionType, e.getMessage(), expr, profileName, entity, variablesInScope);                        throw new ParseException(msg, e);        }    }}
1
private List<Object> execute(List<String> expressions, Map<String, Object> transientState, String expressionType)
{    List<Object> results = new ArrayList<>();    for (String expr : ListUtils.emptyIfNull(expressions)) {        try {                        Object result = executor.execute(expr, transientState, Object.class);            results.add(result);        } catch (Throwable e) {                        Set<String> variablesInScope = new HashSet<>();            variablesInScope.addAll(transientState.keySet());            variablesInScope.addAll(executor.getState().keySet());            String msg = format("Bad '%s' expression: error='%s', expr='%s', profile='%s', entity='%s', variables-available='%s'", expressionType, e.getMessage(), expr, profileName, entity, variablesInScope);                        throw new ParseException(msg, e);        }    }    return results;}
1
public String getEntity()
{    return entity;}
0
public Builder withContext(Context context)
{    this.context = context;    return this;}
0
public Builder withDefinition(ProfileConfig definition)
{    this.definition = definition;    return this;}
0
public Builder withEntity(String entity)
{    this.entity = entity;    return this;}
0
public Builder withPeriodDuration(long duration, TimeUnit units)
{    this.periodDurationMillis = units.toMillis(duration);    return this;}
0
public Builder withPeriodDurationMillis(long millis)
{    this.periodDurationMillis = millis;    return this;}
0
public ProfileBuilder build()
{    if (definition == null) {        throw new IllegalArgumentException("missing profiler definition; got null");    }    if (StringUtils.isEmpty(entity)) {        throw new IllegalArgumentException(format("missing entity name; got '%s'", entity));    }    if (periodDurationMillis == null) {        throw new IllegalArgumentException("missing period duration");    }    return new DefaultProfileBuilder(definition, entity, periodDurationMillis, context);}
0
public List<byte[]> rowKeys(String profile, String entity, List<Object> groups, long start, long end)
{        long max = Math.max(start, end);    start = Math.min(start, end);    end = max;        return ProfilePeriod.visitPeriods(start, end, periodDurationMillis, TimeUnit.MILLISECONDS, Optional.empty(), period -> rowKey(profile, entity, period, groups));}
0
public List<byte[]> rowKeys(String profile, String entity, List<Object> groups, Iterable<ProfilePeriod> periods)
{    List<byte[]> ret = new ArrayList<>();    for (ProfilePeriod period : periods) {        ret.add(rowKey(profile, entity, period, groups));    }    return ret;}
0
public byte[] rowKey(ProfileMeasurement m)
{    return rowKey(m.getProfileName(), m.getEntity(), m.getPeriod(), m.getGroups());}
0
public byte[] rowKey(String profile, String entity, ProfilePeriod period, List<Object> groups)
{    return rowKey(profile, entity, period.getPeriod(), groups);}
0
public byte[] rowKey(String profile, String entity, long period, List<Object> groups)
{        byte[] salt = getSalt(period, saltDivisor);    byte[] prefixKey = prefixKey(profile, entity);    byte[] groupKey = groupKey(groups);    byte[] timeKey = timeKey(period);    int capacity = salt.length + prefixKey.length + groupKey.length + timeKey.length;    return ByteBuffer.allocate(capacity).put(salt).put(prefixKey).put(groupKey).put(timeKey).array();}
0
private static byte[] prefixKey(String profile, String entity)
{    byte[] profileBytes = Bytes.toBytes(profile);    byte[] entityBytes = Bytes.toBytes(entity);    return ByteBuffer.allocate(profileBytes.length + entityBytes.length).put(profileBytes).put(entityBytes).array();}
0
private static byte[] groupKey(List<Object> groups)
{    StringBuilder builder = new StringBuilder();    groups.forEach(g -> builder.append(g));    return Bytes.toBytes(builder.toString());}
0
private static byte[] timeKey(ProfilePeriod period)
{    return timeKey(period.getPeriod());}
0
private static byte[] timeKey(long period)
{    return Bytes.toBytes(period);}
0
public static byte[] getSalt(ProfilePeriod period, int saltDivisor)
{    return getSalt(period.getPeriod(), saltDivisor);}
0
public static byte[] getSalt(long period, int saltDivisor)
{    try {                MessageDigest digest = MessageDigest.getInstance("MD5");        byte[] hash = digest.digest(timeKey(period));        int salt = Bytes.toShort(hash) % saltDivisor;        return Bytes.toBytes(salt);    } catch (NoSuchAlgorithmException e) {        throw new RuntimeException(e);    }}
0
public void withPeriodDuration(long duration, TimeUnit units)
{    periodDurationMillis = units.toMillis(duration);}
0
public void setSaltDivisor(int saltDivisor)
{    this.saltDivisor = saltDivisor;}
0
public ColumnList columns(ProfileMeasurement measurement)
{    ColumnList cols = new ColumnList();    cols.addColumn(columnFamilyBytes, getColumnQualifier("value"), SerDeUtils.toBytes(measurement.getProfileValue()));    return cols;}
0
public String getColumnFamily()
{    return this.columnFamily;}
0
public void setColumnFamily(String columnFamily)
{    this.columnFamily = columnFamily;    this.columnFamilyBytes = Bytes.toBytes(columnFamily);}
0
public byte[] getColumnQualifier(String fieldName)
{    if ("value".equals(fieldName)) {        return Bytes.toBytes("value");    }    throw new IllegalArgumentException(("unexpected field name: " + fieldName));}
0
public String getEntity()
{    return entity;}
0
public void setEntity(String entity)
{    this.entity = entity;}
0
public ProfileConfig getProfileDefinition()
{    return profileDefinition;}
0
public void setProfileDefinition(ProfileConfig profileDefinition)
{    this.profileDefinition = profileDefinition;}
0
public JSONObject getMessage()
{    return message;}
0
public void setMessage(JSONObject message)
{    this.message = message;}
0
public void setMessage(Map message)
{    this.message = new JSONObject(message);}
0
public Long getTimestamp()
{    return timestamp;}
0
public void setTimestamp(Long timestamp)
{    this.timestamp = timestamp;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    MessageRoute that = (MessageRoute) o;    return new EqualsBuilder().append(profileDefinition, that.profileDefinition).append(entity, that.entity).append(message, that.message).append(timestamp, that.timestamp).isEquals();}
0
public int hashCode()
{    return new HashCodeBuilder(17, 37).append(profileDefinition).append(entity).append(message).append(timestamp).toHashCode();}
0
public ProfileMeasurement withProfileName(String profileName)
{    this.profileName = profileName;    return this;}
0
public ProfileMeasurement withEntity(String entity)
{    this.entity = entity;    return this;}
0
public ProfileMeasurement withGroups(List<Object> groups)
{    this.groups = groups;    return this;}
0
public ProfileMeasurement withPeriod(long whenMillis, long periodDuration, TimeUnit periodUnits)
{    this.withPeriod(ProfilePeriod.fromTimestamp(whenMillis, periodDuration, periodUnits));    return this;}
0
public ProfileMeasurement withPeriod(ProfilePeriod period)
{    this.period = period;    return this;}
0
public ProfileMeasurement withDefinition(ProfileConfig definition)
{    this.definition = definition;    return this;}
0
public ProfileMeasurement withProfileValue(Object profileValue)
{    this.profileValue = profileValue;    return this;}
0
public ProfileMeasurement withTriageValues(Map<String, Object> triageValues)
{    this.triageValues = triageValues;    return this;}
0
public String getProfileName()
{    return profileName;}
0
public void setProfileName(String profileName)
{    this.profileName = profileName;}
0
public String getEntity()
{    return entity;}
0
public void setEntity(String entity)
{    this.entity = entity;}
0
public List<Object> getGroups()
{    return groups;}
0
public void setGroups(List<Object> groups)
{    this.groups = groups;}
0
public ProfilePeriod getPeriod()
{    return period;}
0
public void setPeriod(ProfilePeriod period)
{    this.period = period;}
0
public ProfileConfig getDefinition()
{    return definition;}
0
public void setDefinition(ProfileConfig definition)
{    this.definition = definition;}
0
public Object getProfileValue()
{    return profileValue;}
0
public void setProfileValue(Object profileValue)
{    this.profileValue = profileValue;}
0
public Map<String, Object> getTriageValues()
{    return triageValues;}
0
public void setTriageValues(Map<String, Object> triageValues)
{    this.triageValues = triageValues;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    ProfileMeasurement that = (ProfileMeasurement) o;    return new EqualsBuilder().append(profileName, that.profileName).append(entity, that.entity).append(groups, that.groups).append(period, that.period).append(definition, that.definition).append(profileValue, that.profileValue).append(triageValues, that.triageValues).isEquals();}
0
public int hashCode()
{    return new HashCodeBuilder(17, 37).append(profileName).append(entity).append(groups).append(period).append(definition).append(profileValue).append(triageValues).toHashCode();}
0
public static ProfilePeriod fromTimestamp(long epochMillis, long duration, TimeUnit units)
{    if (duration <= 0) {        throw new IllegalArgumentException(format("period duration must be > 0; got '%d %s'", duration, units));    }    long durationMillis = units.toMillis(duration);    long periodId = epochMillis / durationMillis;    return new ProfilePeriod(periodId, duration, units);}
0
public static ProfilePeriod fromPeriodId(long periodId, long duration, TimeUnit units)
{    if (periodId < 0) {        throw new IllegalArgumentException(format("period id must be >= 0; got '%d'", periodId));    }    return new ProfilePeriod(periodId, duration, units);}
0
public long getStartTimeMillis()
{    return period * durationMillis;}
0
public long getEndTimeMillis()
{    return getStartTimeMillis() + getDurationMillis();}
0
public ProfilePeriod next()
{    return fromPeriodId(period + 1, durationMillis, TimeUnit.MILLISECONDS);}
0
public long getPeriod()
{    return period;}
0
public long getDurationMillis()
{    return durationMillis;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ProfilePeriod that = (ProfilePeriod) o;    if (period != that.period)        return false;    return durationMillis == that.durationMillis;}
0
public int hashCode()
{    int result = (int) (period ^ (period >>> 32));    result = 31 * result + (int) (durationMillis ^ (durationMillis >>> 32));    return result;}
0
public String toString()
{    return "ProfilePeriod{" + "period=" + period + ", durationMillis=" + durationMillis + ", startTime=" + Instant.ofEpochMilli(getStartTimeMillis()).toString() + ", endTime=" + Instant.ofEpochMilli(getEndTimeMillis()).toString() + '}';}
0
public static List<T> visitPeriods(long startEpochMillis, long endEpochMillis, long duration, TimeUnit units, Optional<Predicate<ProfilePeriod>> inclusionPredicate, Function<ProfilePeriod, T> transformation)
{    ProfilePeriod period = ProfilePeriod.fromTimestamp(startEpochMillis, duration, units);    List<T> ret = new ArrayList<>();    while (period.getStartTimeMillis() <= endEpochMillis) {        if (!inclusionPredicate.isPresent() || inclusionPredicate.get().test(period)) {            ret.add(transformation.apply(period));        }        period = period.next();    }    return ret;}
0
public void setup()
{    clockFactory = new DefaultClockFactory();}
0
public void testCreateEventTimeClock()
{        ProfilerConfig config = new ProfilerConfig();    config.setTimestampField(Optional.of("timestamp"));        Clock clock = clockFactory.createClock(config);    assertTrue(clock instanceof EventTimeClock);}
0
public void testCreateProcessingTimeClock()
{        ProfilerConfig config = new ProfilerConfig();        Clock clock = clockFactory.createClock(config);    assertTrue(clock instanceof WallClock);}
0
public JSONObject createMessage()
{    return new JSONObject();}
0
public void testEventTime()
{    JSONObject message = createMessage();        final Long timestamp = System.currentTimeMillis();    message.put(timestampField, timestamp);        EventTimeClock clock = new EventTimeClock(timestampField);    Optional<Long> result = clock.currentTimeMillis(message);        assertTrue(result.isPresent());    assertEquals(timestamp, result.get());}
0
public void testEventTimeWithString()
{    JSONObject message = createMessage();        final Long timestamp = System.currentTimeMillis();    message.put(timestampField, timestamp.toString());        EventTimeClock clock = new EventTimeClock(timestampField);    Optional<Long> result = clock.currentTimeMillis(message);        assertTrue(result.isPresent());    assertEquals(timestamp, result.get());}
0
public void testMissingTimestampField()
{        JSONObject message = createMessage();        EventTimeClock clock = new EventTimeClock(timestampField);    Optional<Long> result = clock.currentTimeMillis(message);        assertFalse(result.isPresent());}
0
public void testInvalidValue()
{        JSONObject message = createMessage();    message.put(timestampField, "invalid-timestamp-value");        EventTimeClock clock = new EventTimeClock(timestampField);    Optional<Long> result = clock.currentTimeMillis(message);        assertFalse(result.isPresent());}
0
public void setup()
{    clockFactory = new EventTimeOnlyClockFactory();}
0
public void testCreateEventTimeClock()
{        ProfilerConfig config = new ProfilerConfig();    config.setTimestampField(Optional.of("timestamp"));        Clock clock = clockFactory.createClock(config);    assertTrue(clock instanceof EventTimeClock);}
0
public void testCreateProcessingTimeClock()
{        ProfilerConfig config = new ProfilerConfig();    clockFactory.createClock(config);    fail("Expected exception");}
0
public JSONObject createMessage()
{    return new JSONObject();}
0
public void testCurrentTimeMillis()
{    JSONObject message = createMessage();    long before = System.currentTimeMillis();        WallClock clock = new WallClock();    Optional<Long> result = clock.currentTimeMillis(message);        long after = System.currentTimeMillis();    assertTrue(result.isPresent());    assertTrue(result.get() >= before);    assertTrue(result.get() <= after);}
0
public void setup() throws Exception
{    context = Context.EMPTY_CONTEXT();    JSONParser parser = new JSONParser();    messageOne = (JSONObject) parser.parse(inputOne);    messageTwo = (JSONObject) parser.parse(inputTwo);    distributor = new DefaultMessageDistributor(periodDurationMillis, profileTimeToLiveMillis, maxNumberOfRoutes, Ticker.systemTicker());}
0
private ProfileConfig createDefinition(String json) throws IOException
{    return JSONUtils.INSTANCE.load(json, ProfileConfig.class);}
0
public void testDistribute() throws Exception
{        long timestamp = 100;    ProfileConfig definition = createDefinition(profileOne);    String entity = (String) messageOne.get("ip_src_addr");    MessageRoute route = new MessageRoute(definition, entity, messageOne, timestamp);        distributor.distribute(route, context);    List<ProfileMeasurement> measurements = distributor.flush();        assertEquals(1, measurements.size());    ProfileMeasurement m = measurements.get(0);    assertEquals(definition.getProfile(), m.getProfileName());    assertEquals(entity, m.getEntity());}
0
public void testDistributeWithTwoProfiles() throws Exception
{        long timestamp = 100;    String entity = (String) messageOne.get("ip_src_addr");        MessageRoute routeOne = new MessageRoute(createDefinition(profileOne), entity, messageOne, timestamp);    distributor.distribute(routeOne, context);        MessageRoute routeTwo = new MessageRoute(createDefinition(profileTwo), entity, messageOne, timestamp);    distributor.distribute(routeTwo, context);        List<ProfileMeasurement> measurements = distributor.flush();    assertEquals(2, measurements.size());}
0
public void testDistributeWithTwoEntities() throws Exception
{        long timestamp = 100;        String entityOne = (String) messageOne.get("ip_src_addr");    MessageRoute routeOne = new MessageRoute(createDefinition(profileOne), entityOne, messageOne, timestamp);    distributor.distribute(routeOne, context);        String entityTwo = (String) messageTwo.get("ip_src_addr");    MessageRoute routeTwo = new MessageRoute(createDefinition(profileTwo), entityTwo, messageTwo, timestamp);    distributor.distribute(routeTwo, context);        List<ProfileMeasurement> measurements = distributor.flush();    assertEquals(2, measurements.size());}
0
public void testNotYetTimeToExpireProfiles() throws Exception
{        FixedTicker ticker = new FixedTicker();        ProfileConfig definition = createDefinition(profileOne);    String entity = (String) messageOne.get("ip_src_addr");    MessageRoute route = new MessageRoute(definition, entity, messageOne, ticker.read());    distributor = new DefaultMessageDistributor(periodDurationMillis, profileTimeToLiveMillis, maxNumberOfRoutes, ticker);        distributor.distribute(route, context);        ticker.advanceTime(profileTimeToLiveMillis - 1000, MILLISECONDS);        assertEquals(0, distributor.flushExpired().size());    assertEquals(1, distributor.flush().size());}
0
public void testProfilesShouldExpire() throws Exception
{        FixedTicker ticker = new FixedTicker();        ProfileConfig definition = createDefinition(profileOne);    String entity = (String) messageOne.get("ip_src_addr");    MessageRoute route = new MessageRoute(definition, entity, messageOne, ticker.read());    distributor = new DefaultMessageDistributor(periodDurationMillis, profileTimeToLiveMillis, maxNumberOfRoutes, ticker);        distributor.distribute(route, context);        ticker.advanceTime(profileTimeToLiveMillis + 1000, MILLISECONDS);        assertEquals(1, distributor.flushExpired().size());    assertEquals(0, distributor.flush().size());}
0
public void testExpiredProfilesShouldBeRemoved() throws Exception
{        FixedTicker ticker = new FixedTicker();        ProfileConfig definition = createDefinition(profileOne);    String entity = (String) messageOne.get("ip_src_addr");    MessageRoute route = new MessageRoute(definition, entity, messageOne, ticker.read());    distributor = new DefaultMessageDistributor(periodDurationMillis, profileTimeToLiveMillis, maxNumberOfRoutes, ticker);        distributor.distribute(route, context);        ticker.advanceTime(2, HOURS);        assertEquals(0, distributor.flush().size());        ticker.advanceTime(2, HOURS);        assertEquals(0, distributor.flushExpired().size());}
0
public FixedTicker startAt(long timestampNanos)
{    this.timestampNanos = timestampNanos;    return this;}
0
public FixedTicker advanceTime(long time, TimeUnit units)
{    this.timestampNanos += units.toNanos(time);    return this;}
0
public long read()
{    return this.timestampNanos;}
0
private ProfilerConfig createConfig(String json) throws IOException
{    return JSONUtils.INSTANCE.load(json, ProfilerConfig.class);}
0
public void setup() throws Exception
{    this.router = new DefaultMessageRouter(Context.EMPTY_CONTEXT());    this.context = Context.EMPTY_CONTEXT();    JSONParser parser = new JSONParser();    this.messageOne = (JSONObject) parser.parse(inputOne);    this.messageTwo = (JSONObject) parser.parse(inputTwo);    this.messageWithTimestamp = (JSONObject) parser.parse(inputWithTimestamp);}
0
public void testWithOneRoute() throws Exception
{    List<MessageRoute> routes = router.route(messageOne, createConfig(oneProfile), context);    assertEquals(1, routes.size());    MessageRoute route1 = routes.get(0);    assertEquals(messageOne.get("ip_src_addr"), route1.getEntity());    assertEquals("profile-one", route1.getProfileDefinition().getProfile());}
0
public void testWithNoRoutes() throws Exception
{    List<MessageRoute> routes = router.route(messageOne, createConfig(noProfiles), context);    assertEquals(0, routes.size());}
0
public void testWithTwoRoutes() throws Exception
{    List<MessageRoute> routes = router.route(messageOne, createConfig(twoProfiles), context);    assertEquals(2, routes.size());    {        MessageRoute route1 = routes.get(0);        assertEquals(messageOne.get("ip_src_addr"), route1.getEntity());        assertEquals("profile-one", route1.getProfileDefinition().getProfile());    }    {        MessageRoute route2 = routes.get(1);        assertEquals(messageOne.get("ip_src_addr"), route2.getEntity());        assertEquals("profile-two", route2.getProfileDefinition().getProfile());    }}
0
public void testExclusiveProfile() throws Exception
{    List<MessageRoute> routes = router.route(messageOne, createConfig(exclusiveProfile), context);    assertEquals(0, routes.size());}
0
public void testWithBadForeachExpression() throws Exception
{    List<MessageRoute> routes = router.route(messageOne, createConfig(badForeach), context);    assertEquals(0, routes.size());}
0
public void testWithBadOnlyifExpression() throws Exception
{    List<MessageRoute> routes = router.route(messageOne, createConfig(badForeach), context);    assertEquals(0, routes.size());}
0
public void testWithGoodAndBad() throws Exception
{    List<MessageRoute> routes = router.route(messageOne, createConfig(goodAndBad), context);    assertEquals(1, routes.size());    MessageRoute route1 = routes.get(0);    assertEquals("good-profile", route1.getProfileDefinition().getProfile());    assertEquals(messageOne.get("ip_src_addr"), route1.getEntity());}
0
public void testMessageWithTimestamp() throws Exception
{    List<MessageRoute> routes = router.route(messageWithTimestamp, createConfig(profileWithEventTime), context);    ;    assertEquals(1, routes.size());    MessageRoute route1 = routes.get(0);    assertEquals("profile-one", route1.getProfileDefinition().getProfile());    assertEquals(messageWithTimestamp.get("ip_src_addr"), route1.getEntity());    assertEquals(messageWithTimestamp.get("timestamp"), route1.getTimestamp());}
0
public void testMessageWithMissingTimestamp() throws Exception
{        List<MessageRoute> routes = router.route(messageOne, createConfig(profileWithEventTime), context);    assertEquals(0, routes.size());}
0
public void setup() throws Exception
{    message = (JSONObject) new JSONParser().parse(input);}
0
public void testInit() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testInitProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(100 + 200, (int) convert(m.get().getProfileValue(), Integer.class));}
0
public void testInitWithNoMessage() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testInitProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(0, (int) convert(m.get().getProfileValue(), Integer.class));}
0
public void testUpdate() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testUpdateProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        int count = 10;    for (int i = 0; i < count; i++) {                builder.apply(message, timestamp);                timestamp += 5;    }    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(count * 1 + count * 2, (int) convert(m.get().getProfileValue(), Integer.class));}
0
public void testResult() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testResultProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(100, (int) convert(m.get().getProfileValue(), Integer.class));}
0
public void testProfilePeriodOnFlush() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testResultProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();    {                builder.apply(message, timestamp);        Optional<ProfileMeasurement> m = builder.flush();        assertTrue(m.isPresent());                ProfilePeriod expected = ProfilePeriod.fromTimestamp(timestamp, 10, TimeUnit.MINUTES);        assertEquals(expected, m.get().getPeriod());    }    {                timestamp += TimeUnit.MINUTES.toMillis(10);                builder.apply(message, timestamp);        Optional<ProfileMeasurement> m = builder.flush();        assertTrue(m.isPresent());                ProfilePeriod expected = ProfilePeriod.fromTimestamp(timestamp, 10, TimeUnit.MINUTES);        assertEquals(expected, m.get().getPeriod());    }}
0
public void testGroupBy() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testGroupByProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(2, m.get().getGroups().size());    assertEquals(100, m.get().getGroups().get(0));    assertEquals(200, m.get().getGroups().get(1));}
0
public void testStateAvailableToGroupBy() throws Exception
{        long timestamp = 1503081070340L;    ProfilePeriod period = ProfilePeriod.fromTimestamp(timestamp, 10, TimeUnit.MINUTES);    definition = JSONUtils.INSTANCE.load(testStateAvailableToGroupBy, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(6, m.get().getGroups().size());    assertEquals("invalid profile", "test-profile", m.get().getGroups().get(0));    assertEquals("invalid entity", "10.0.0.1", m.get().getGroups().get(1));    assertEquals("invalid start", period.getStartTimeMillis(), m.get().getGroups().get(2));    assertEquals("invalid end", period.getEndTimeMillis(), m.get().getGroups().get(3));    assertEquals("invalid duration", period.getDurationMillis(), m.get().getGroups().get(4));    assertEquals("invalid result", 100, m.get().getGroups().get(5));}
0
public void testFlushDoesNotClearsState() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testFlushProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        int count = 10;    for (int i = 0; i < count; i++) {                builder.apply(message, timestamp);                timestamp += 5;    }    builder.flush();        timestamp += TimeUnit.MINUTES.toMillis(20);        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();        assertTrue(m.isPresent());    assertEquals(33, m.get().getProfileValue());}
0
public void testFlushDoesNotClearsStateButInitDoes() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testFlushProfileWithNaiveInit, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        int count = 10;    for (int i = 0; i < count; i++) {                builder.apply(message, timestamp);                timestamp += 5;    }    builder.flush();        timestamp += TimeUnit.MINUTES.toMillis(20);        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(3, m.get().getProfileValue());}
0
public void testEntity() throws Exception
{        long timestamp = 100;    final String entity = "10.0.0.1";    definition = JSONUtils.INSTANCE.load(testFlushProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity(entity).withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(entity, m.get().getEntity());}
0
public void testResultWithProfileExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testResultWithProfileExpression, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(100, m.get().getProfileValue());}
0
public void testResultWithTriageExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(testResultWithTriageExpression, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());        assertEquals(0, m.get().getTriageValues().get("zero"));    assertEquals(100, m.get().getTriageValues().get("hundred"));    assertEquals(100, m.get().getProfileValue());}
0
public void testBadInitExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(badInitProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    assertFalse(builder.flush().isPresent());}
0
public void testBadResultExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(badSimpleResultProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    assertFalse(builder.flush().isPresent());}
0
public void testBadGroupByExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(badGroupByProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    assertFalse(builder.flush().isPresent());}
0
public void testBadResultProfileExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(badResultProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    assertFalse(builder.flush().isPresent());}
0
public void testBadResultTriageExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(badResultTriage, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);    assertFalse(builder.flush().isPresent());}
0
public void testBadUpdateExpression() throws Exception
{        long timestamp = 100;    definition = JSONUtils.INSTANCE.load(badUpdateProfile, ProfileConfig.class);    builder = new DefaultProfileBuilder.Builder().withDefinition(definition).withEntity("10.0.0.1").withPeriodDuration(10, TimeUnit.MINUTES).withContext(Context.EMPTY_CONTEXT()).build();        builder.apply(message, timestamp);        Optional<ProfileMeasurement> m = builder.flush();    assertTrue(m.isPresent());    assertEquals(0, m.get().getProfileValue());}
0
public void setup() throws Exception
{        measurement = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withPeriod(AUG2016, periodDuration, periodUnits);    rowKeyBuilder = new SaltyRowKeyBuilder(saltDivisor, periodDuration, periodUnits);}
0
public void testRowKeyWithOneGroup() throws Exception
{        measurement.withGroups(Arrays.asList("group1"));        ByteBuffer buffer = ByteBuffer.allocate(100).put(SaltyRowKeyBuilder.getSalt(measurement.getPeriod(), saltDivisor)).put(measurement.getProfileName().getBytes(StandardCharsets.UTF_8)).put(measurement.getEntity().getBytes(StandardCharsets.UTF_8)).put("group1".getBytes(StandardCharsets.UTF_8)).putLong(1635701L);    buffer.flip();    final byte[] expected = new byte[buffer.limit()];    buffer.get(expected, 0, buffer.limit());        byte[] actual = rowKeyBuilder.rowKey(measurement);    Assert.assertTrue(Arrays.equals(expected, actual));}
0
public void testRowKeyWithTwoGroups() throws Exception
{        measurement.withGroups(Arrays.asList("group1", "group2"));        ByteBuffer buffer = ByteBuffer.allocate(100).put(SaltyRowKeyBuilder.getSalt(measurement.getPeriod(), saltDivisor)).put(measurement.getProfileName().getBytes(StandardCharsets.UTF_8)).put(measurement.getEntity().getBytes(StandardCharsets.UTF_8)).put("group1".getBytes(StandardCharsets.UTF_8)).put("group2".getBytes(StandardCharsets.UTF_8)).putLong(1635701L);    buffer.flip();    final byte[] expected = new byte[buffer.limit()];    buffer.get(expected, 0, buffer.limit());        byte[] actual = rowKeyBuilder.rowKey(measurement);    Assert.assertTrue(Arrays.equals(expected, actual));}
0
public void testRowKeyWithOneIntegerGroup() throws Exception
{        measurement.withGroups(Arrays.asList(200));        ByteBuffer buffer = ByteBuffer.allocate(100).put(SaltyRowKeyBuilder.getSalt(measurement.getPeriod(), saltDivisor)).put(measurement.getProfileName().getBytes(StandardCharsets.UTF_8)).put(measurement.getEntity().getBytes(StandardCharsets.UTF_8)).put("200".getBytes(StandardCharsets.UTF_8)).putLong(1635701L);    buffer.flip();    final byte[] expected = new byte[buffer.limit()];    buffer.get(expected, 0, buffer.limit());        byte[] actual = rowKeyBuilder.rowKey(measurement);    Assert.assertTrue(Arrays.equals(expected, actual));}
0
public void testRowKeyWithMixedGroups() throws Exception
{        measurement.withGroups(Arrays.asList(200, "group1"));        ByteBuffer buffer = ByteBuffer.allocate(100).put(SaltyRowKeyBuilder.getSalt(measurement.getPeriod(), saltDivisor)).put(measurement.getProfileName().getBytes(StandardCharsets.UTF_8)).put(measurement.getEntity().getBytes(StandardCharsets.UTF_8)).put("200".getBytes(StandardCharsets.UTF_8)).put("group1".getBytes(StandardCharsets.UTF_8)).putLong(1635701L);    buffer.flip();    final byte[] expected = new byte[buffer.limit()];    buffer.get(expected, 0, buffer.limit());        byte[] actual = rowKeyBuilder.rowKey(measurement);    Assert.assertTrue(Arrays.equals(expected, actual));}
0
public void testRowKeyWithNoGroup() throws Exception
{        measurement.withGroups(Collections.emptyList());        ByteBuffer buffer = ByteBuffer.allocate(100).put(SaltyRowKeyBuilder.getSalt(measurement.getPeriod(), saltDivisor)).put(measurement.getProfileName().getBytes(StandardCharsets.UTF_8)).put(measurement.getEntity().getBytes(StandardCharsets.UTF_8)).putLong(1635701L);    buffer.flip();    final byte[] expected = new byte[buffer.limit()];    buffer.get(expected, 0, buffer.limit());        byte[] actual = rowKeyBuilder.rowKey(measurement);    Assert.assertTrue(Arrays.equals(expected, actual));}
0
public void testRowKeys() throws Exception
{    int hoursAgo = 1;        List<Object> groups = Collections.emptyList();    rowKeyBuilder = new SaltyRowKeyBuilder(saltDivisor, periodDuration, periodUnits);        long now = System.currentTimeMillis();    long oldest = now - TimeUnit.HOURS.toMillis(hoursAgo);    ProfileMeasurement m = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withPeriod(oldest, periodDuration, periodUnits).withProfileValue(22);        List<byte[]> expectedKeys = new ArrayList<>();    for (int i = 0; i < (hoursAgo * 4) + 1; i++) {                byte[] rk = rowKeyBuilder.rowKey(m);        expectedKeys.add(rk);                ProfilePeriod next = m.getPeriod().next();        m = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withPeriod(next.getStartTimeMillis(), periodDuration, periodUnits);    }        List<byte[]> actualKeys = rowKeyBuilder.rowKeys(measurement.getProfileName(), measurement.getEntity(), groups, oldest, now);        for (int i = 0; i < actualKeys.size(); i++) {        byte[] actual = actualKeys.get(i);        byte[] expected = expectedKeys.get(i);        assertThat(actual, equalTo(expected));    }}
0
private void printBytes(byte[] bytes)
{    StringBuilder sb = new StringBuilder(bytes.length * 2);    Formatter formatter = new Formatter(sb);    for (byte b : bytes) {        formatter.format("%02x ", b);    }    System.out.println(sb.toString());}
0
public void setup() throws Exception
{    definition = ProfileConfig.fromJSON(profile);    measurement = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withDefinition(definition).withPeriod(System.currentTimeMillis(), 10, TimeUnit.MINUTES).withProfileValue(22).withTriageValues(Collections.singletonMap("max", 200));}
0
public void testKryoSerialization() throws Exception
{    assertNotNull(measurement);    Kryo kryo = new Kryo();        ByteArrayOutputStream byteStream = new ByteArrayOutputStream();    Output output = new Output(byteStream);    kryo.writeObject(output, measurement);        byte[] bits = output.toBytes();    assertNotNull(bits);        Input input = new Input(new ByteArrayInputStream(bits));    ProfileMeasurement actual = kryo.readObject(input, ProfileMeasurement.class);        assertNotNull(actual);    assertEquals(measurement, actual);}
0
public void testJavaSerialization() throws Exception
{    assertNotNull(measurement);        ByteArrayOutputStream bytes = new ByteArrayOutputStream();    ObjectOutputStream out = new ObjectOutputStream(bytes);    out.writeObject(measurement);        byte[] raw = bytes.toByteArray();    assertTrue(raw.length > 0);        ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(raw));    Object actual = in.readObject();        assertEquals(measurement, actual);}
0
public void testFirstPeriodAtEpoch()
{    long duration = 1;    TimeUnit units = TimeUnit.HOURS;    ProfilePeriod period = ProfilePeriod.fromTimestamp(0, duration, units);    assertEquals(0, period.getPeriod());    assertEquals(0, period.getStartTimeMillis());    assertEquals(units.toMillis(duration), period.getDurationMillis());}
0
public void testOneMinutePeriods()
{    long duration = 1;    TimeUnit units = TimeUnit.MINUTES;    ProfilePeriod period = ProfilePeriod.fromTimestamp(AUG2016, duration, units);    assertEquals(24535527, period.getPeriod());        assertEquals(1472131620000L, period.getStartTimeMillis());    assertEquals(units.toMillis(duration), period.getDurationMillis());}
0
public void testFifteenMinutePeriods()
{    long duration = 15;    TimeUnit units = TimeUnit.MINUTES;    ProfilePeriod period = ProfilePeriod.fromTimestamp(AUG2016, duration, units);    assertEquals(1635701, period.getPeriod());        assertEquals(1472130900000L, period.getStartTimeMillis());    assertEquals(units.toMillis(duration), period.getDurationMillis());}
0
public void testOneHourPeriods()
{    long duration = 1;    TimeUnit units = TimeUnit.HOURS;    ProfilePeriod period = ProfilePeriod.fromTimestamp(AUG2016, duration, units);    assertEquals(408925, period.getPeriod());        assertEquals(1472130000000L, period.getStartTimeMillis());    assertEquals(units.toMillis(duration), period.getDurationMillis());}
0
public void testTwoHourPeriods()
{    long duration = 2;    TimeUnit units = TimeUnit.HOURS;    ProfilePeriod period = ProfilePeriod.fromTimestamp(AUG2016, duration, units);    assertEquals(204462, period.getPeriod());        assertEquals(1472126400000L, period.getStartTimeMillis());    assertEquals(units.toMillis(duration), period.getDurationMillis());}
0
public void testEightHourPeriods()
{    long duration = 8;    TimeUnit units = TimeUnit.HOURS;    ProfilePeriod period = ProfilePeriod.fromTimestamp(AUG2016, duration, units);    assertEquals(51115, period.getPeriod());        assertEquals(1472112000000L, period.getStartTimeMillis());    assertEquals(units.toMillis(duration), period.getDurationMillis());}
0
public void testNextWithFifteenMinutePeriods()
{    long duration = 15;    TimeUnit units = TimeUnit.MINUTES;    ProfilePeriod previous = ProfilePeriod.fromTimestamp(AUG2016, duration, units);    IntStream.range(0, 100).forEach(i -> {        ProfilePeriod next = previous.next();        assertEquals(previous.getPeriod() + 1, next.getPeriod());        assertEquals(previous.getStartTimeMillis() + previous.getDurationMillis(), next.getStartTimeMillis());        assertEquals(previous.getDurationMillis(), next.getDurationMillis());    });}
0
public void testPeriodDurationOfZero()
{    long duration = 0;    TimeUnit units = TimeUnit.HOURS;    ProfilePeriod.fromTimestamp(0, duration, units);}
0
public void testKryoSerialization() throws Exception
{    ProfilePeriod expected = ProfilePeriod.fromTimestamp(AUG2016, 1, TimeUnit.HOURS);    Kryo kryo = new Kryo();        ByteArrayOutputStream byteStream = new ByteArrayOutputStream();    Output output = new Output(byteStream);    kryo.writeObject(output, expected);        byte[] bits = output.toBytes();    assertNotNull(bits);        Input input = new Input(new ByteArrayInputStream(bits));    ProfilePeriod actual = kryo.readObject(input, ProfilePeriod.class);        assertNotNull(actual);    assertEquals(expected, actual);}
0
public void testJavaSerialization() throws Exception
{    ProfilePeriod expected = ProfilePeriod.fromTimestamp(AUG2016, 1, TimeUnit.HOURS);        ByteArrayOutputStream bytes = new ByteArrayOutputStream();    ObjectOutputStream out = new ObjectOutputStream(bytes);    out.writeObject(expected);        byte[] raw = bytes.toByteArray();    assertTrue(raw.length > 0);        ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(raw));    Object actual = in.readObject();        assertEquals(expected, actual);}
0
public void testFromPeriodId()
{    ProfilePeriod expected = ProfilePeriod.fromTimestamp(AUG2016, 1, TimeUnit.HOURS);        long periodId = expected.getPeriod();    long duration = expected.getDurationMillis();    ProfilePeriod actual = ProfilePeriod.fromPeriodId(periodId, duration, TimeUnit.MILLISECONDS);    assertEquals(expected, actual);}
0
public void testWithNegativePeriodId()
{    ProfilePeriod.fromPeriodId(-1, 1, TimeUnit.HOURS);}
0
public void testFromPeriodIdAtEpoch()
{    assertEquals(ProfilePeriod.fromTimestamp(0, 1, TimeUnit.HOURS), ProfilePeriod.fromPeriodId(0, 1, TimeUnit.HOURS));}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context)
{    @SuppressWarnings("unchecked")    Map<String, Object> global = (Map<String, Object>) context.getCapability(GLOBAL_CONFIG, false).orElse(Collections.emptyMap());        long duration = PROFILER_PERIOD.getOrDefault(global, PROFILER_PERIOD.getDefault(), Long.class);    String configuredUnits = PROFILER_PERIOD_UNITS.getOrDefault(global, PROFILER_PERIOD_UNITS.getDefault(), String.class);    long periodDurationMillis = TimeUnit.valueOf(configuredUnits).toMillis(duration);        String arg0 = Util.getArg(0, String.class, args);    ProfilerConfig profilerConfig;    try {        profilerConfig = JSONUtils.INSTANCE.load(arg0, ProfilerConfig.class);    } catch (IOException e) {        throw new IllegalArgumentException("Invalid profiler configuration", e);    }        long profileTimeToLiveMillis = Long.MAX_VALUE;    long maxNumberOfRoutes = Long.MAX_VALUE;    return new StandAloneProfiler(profilerConfig, periodDurationMillis, profileTimeToLiveMillis, maxNumberOfRoutes, context);}
0
public void initialize(Context context)
{    parser = new JSONParser();}
0
public boolean isInitialized()
{    return parser != null;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        Object arg0 = Util.getArg(0, Object.class, args);    List<JSONObject> messages = getMessages(arg0);        StandAloneProfiler profiler = Util.getArg(1, StandAloneProfiler.class, args);    for (JSONObject message : messages) {        profiler.apply(message);    }    return profiler;}
0
private List<JSONObject> getMessages(Object arg)
{    List<JSONObject> messages;    if (arg instanceof String) {        messages = getMessagesFromString((String) arg);    } else if (arg instanceof Iterable) {        messages = getMessagesFromIterable((Iterable<String>) arg);    } else if (arg instanceof JSONObject) {        messages = Collections.singletonList((JSONObject) arg);    } else {        throw new IllegalArgumentException(format("invalid message: found '%s', expected String, List, or JSONObject", ClassUtils.getShortClassName(arg, "null")));    }    return messages;}
0
private List<JSONObject> getMessagesFromIterable(Iterable<String> strings)
{    List<JSONObject> messages = new ArrayList<>();        for (String str : strings) {        messages.addAll(getMessagesFromString(str));    }    return messages;}
0
private List<JSONObject> getMessagesFromString(String arg0)
{    List<JSONObject> messages = new ArrayList<>();    try {        Object parsedArg0 = parser.parse(arg0);        if (parsedArg0 instanceof JSONObject) {                        messages.add((JSONObject) parsedArg0);        } else if (parsedArg0 instanceof JSONArray) {                        JSONArray jsonArray = (JSONArray) parsedArg0;            for (Object item : jsonArray) {                messages.addAll(getMessages(item));            }        } else {            throw new IllegalArgumentException(format("invalid message: found '%s', expected JSONObject or JSONArray", ClassUtils.getShortClassName(parsedArg0, "null")));        }    } catch (org.json.simple.parser.ParseException e) {        throw new IllegalArgumentException(format("invalid message: '%s'", e.getMessage()), e);    }    return messages;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        StandAloneProfiler profiler = Util.getArg(0, StandAloneProfiler.class, args);    if (profiler == null) {        throw new IllegalArgumentException(format("expected the profiler returned by PROFILER_INIT, found null"));    }        List<Map<String, Object>> measurements = new ArrayList<>();    for (ProfileMeasurement m : profiler.flush()) {                Map<String, Object> period = new HashMap<>();        period.put("period", m.getPeriod().getPeriod());        period.put("start", m.getPeriod().getStartTimeMillis());        period.put("duration", m.getPeriod().getDurationMillis());        period.put("end", m.getPeriod().getEndTimeMillis());                Map<String, Object> measurement = new HashMap<>();        measurement.put("profile", m.getProfileName());        measurement.put("entity", m.getEntity());        measurement.put("value", m.getProfileValue());        measurement.put("groups", m.getGroups());        measurement.put("period", period);        measurements.add(measurement);    }    return measurements;}
0
public void apply(JSONObject message)
{        List<MessageRoute> routes = router.route(message, config, context);    for (MessageRoute route : routes) {        distributor.distribute(route, context);    }    routeCount += routes.size();    messageCount += 1;}
0
public List<ProfileMeasurement> flush()
{    return distributor.flush();}
0
public ProfilerConfig getConfig()
{    return config;}
0
public int getProfileCount()
{    return (config == null) ? 0 : config.getProfiles().size();}
0
public int getMessageCount()
{    return messageCount;}
0
public int getRouteCount()
{    return routeCount;}
0
public String toString()
{    return "Profiler{" + getProfileCount() + " profile(s), " + getMessageCount() + " messages(s), " + getRouteCount() + " route(s)" + '}';}
0
private T run(String expression, Class<T> clazz)
{    return executor.execute(expression, state, clazz);}
0
public void setup()
{    state = new HashMap<>();        Map<String, Object> global = new HashMap<String, Object>() {        {            put(PROFILER_PERIOD.getKey(), Long.toString(periodDuration));            put(PROFILER_PERIOD_UNITS.getKey(), periodUnits.toString());        }    };        executor = new DefaultStellarStatefulExecutor(new SimpleFunctionResolver().withClass(ProfilerFunctions.ProfilerInit.class).withClass(ProfilerFunctions.ProfilerApply.class).withClass(ProfilerFunctions.ProfilerFlush.class), new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> global).build());}
0
public void testProfilerInitNoProfiles()
{    state.put("config", "{ \"profiles\" : [] }");    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    assertNotNull(profiler);    assertEquals(0, profiler.getProfileCount());    assertEquals(0, profiler.getMessageCount());    assertEquals(0, profiler.getRouteCount());}
0
public void testProfilerInitWithProfiles()
{    state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    assertNotNull(profiler);    assertEquals(1, profiler.getProfileCount());    assertEquals(0, profiler.getMessageCount());    assertEquals(0, profiler.getRouteCount());}
0
public void testProfilerInitNoArgs()
{    run("PROFILER_INIT()", StandAloneProfiler.class);}
0
public void testProfilerInitInvalidArg()
{    run("PROFILER_INIT({ \"invalid\": 2 })", StandAloneProfiler.class);}
0
public void testProfilerInitWithNoGlobalConfig()
{    state.put("config", helloWorldProfilerDef);    String expression = "PROFILER_INIT(config)";        StellarStatefulExecutor executor = new DefaultStellarStatefulExecutor(new SimpleFunctionResolver().withClass(ProfilerFunctions.ProfilerInit.class).withClass(ProfilerFunctions.ProfilerApply.class).withClass(ProfilerFunctions.ProfilerFlush.class), Context.EMPTY_CONTEXT());    StandAloneProfiler profiler = executor.execute(expression, state, StandAloneProfiler.class);    assertNotNull(profiler);    assertEquals(1, profiler.getProfileCount());    assertEquals(0, profiler.getMessageCount());    assertEquals(0, profiler.getRouteCount());}
0
public void testProfilerApplyWithString()
{        state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    state.put("profiler", profiler);        state.put("message", message);    StandAloneProfiler result = run("PROFILER_APPLY(message, profiler)", StandAloneProfiler.class);        assertSame(profiler, result);    assertEquals(1, profiler.getProfileCount());    assertEquals(1, profiler.getMessageCount());    assertEquals(1, profiler.getRouteCount());}
0
public void testProfilerApplyWithJSONObject() throws Exception
{        state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    state.put("profiler", profiler);        JSONParser parser = new JSONParser();    JSONObject jsonObject = (JSONObject) parser.parse(message);    state.put("jsonObj", jsonObject);    StandAloneProfiler result = run("PROFILER_APPLY(jsonObj, profiler)", StandAloneProfiler.class);        assertSame(profiler, result);    assertEquals(1, profiler.getProfileCount());    assertEquals(1, profiler.getMessageCount());    assertEquals(1, profiler.getRouteCount());}
0
public void testProfilerApplyWithMultipleMessagesInJSONString()
{        state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    state.put("profiler", profiler);        state.put("messages", messages);    StandAloneProfiler result = run("PROFILER_APPLY(messages, profiler)", StandAloneProfiler.class);        assertSame(profiler, result);    assertEquals(1, profiler.getProfileCount());    assertEquals(3, profiler.getMessageCount());    assertEquals(3, profiler.getRouteCount());}
0
public void testProfilerApplyWithListOfMessages()
{        state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    state.put("profiler", profiler);        state.put("msg", message);    StandAloneProfiler result = run("PROFILER_APPLY([msg, msg, msg], profiler)", StandAloneProfiler.class);        assertSame(profiler, result);    assertEquals(1, profiler.getProfileCount());    assertEquals(3, profiler.getMessageCount());    assertEquals(3, profiler.getRouteCount());}
0
public void testProfilerApplyWithEmptyList()
{        state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    state.put("profiler", profiler);        state.put("messages", "[ ]");    StandAloneProfiler result = run("PROFILER_APPLY(messages, profiler)", StandAloneProfiler.class);        assertSame(profiler, result);    assertEquals(1, profiler.getProfileCount());    assertEquals(0, profiler.getMessageCount());    assertEquals(0, profiler.getRouteCount());}
0
public void testProfilerApplyWithNoArgs()
{    run("PROFILER_APPLY()", StandAloneProfiler.class);}
0
public void testProfilerApplyWithInvalidArg()
{    run("PROFILER_APPLY(undefined)", StandAloneProfiler.class);}
0
public void testProfilerApplyWithNullMessage()
{        state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    state.put("profiler", profiler);        run("PROFILER_APPLY(messages, profiler)", StandAloneProfiler.class);}
0
public void testProfilerFlush()
{        state.put("config", helloWorldProfilerDef);    StandAloneProfiler profiler = run("PROFILER_INIT(config)", StandAloneProfiler.class);    state.put("profiler", profiler);        state.put("message", message);    run("PROFILER_APPLY(message, profiler)", StandAloneProfiler.class);        List<Map<String, Object>> measurements = run("PROFILER_FLUSH(profiler)", List.class);        assertNotNull(measurements);    assertEquals(1, measurements.size());    Map<String, Object> measurement = measurements.get(0);    assertEquals("hello-world", measurement.get("profile"));    assertEquals("10.0.0.1", measurement.get("entity"));    assertEquals(1, measurement.get("value"));    assertEquals(Collections.emptyList(), measurement.get("groups"));}
0
public void testProfilerFlushNoArgs()
{    run("PROFILER_FLUSH()", StandAloneProfiler.class);}
0
public void testProfilerFlushInvalidArg()
{    run("PROFILER_FLUSH(undefined)", StandAloneProfiler.class);}
0
public void setup() throws Exception
{        JSONParser parser = new JSONParser();    message = (JSONObject) parser.parse(messageJson);}
0
public void testWithOneProfile() throws Exception
{    StandAloneProfiler profiler = createProfiler(oneProfile);    profiler.apply(message);    profiler.apply(message);    profiler.apply(message);    List<ProfileMeasurement> measurements = profiler.flush();    assertEquals(1, measurements.size());        ProfileMeasurement m = measurements.get(0);    assertEquals("profile1", m.getProfileName());    assertEquals(3, m.getProfileValue());}
0
public void testWithTwoProfiles() throws Exception
{    StandAloneProfiler profiler = createProfiler(twoProfiles);    profiler.apply(message);    profiler.apply(message);    profiler.apply(message);    List<ProfileMeasurement> measurements = profiler.flush();    assertEquals(2, measurements.size());        List<String> expected = Arrays.asList(new String[] { "profile1", "profile2" });    {        ProfileMeasurement m = measurements.get(0);        assertTrue(expected.contains(m.getProfileName()));        assertEquals("result", m.getProfileValue());    }    {        ProfileMeasurement m = measurements.get(1);        assertTrue(expected.contains(m.getProfileName()));        assertEquals("result", m.getProfileValue());    }}
0
public void testRouteAndMessageCounters() throws Exception
{    {        StandAloneProfiler profiler = createProfiler(noProfiles);        profiler.apply(message);        assertEquals(1, profiler.getMessageCount());        assertEquals(0, profiler.getRouteCount());        profiler.apply(message);        assertEquals(2, profiler.getMessageCount());        assertEquals(0, profiler.getRouteCount());        profiler.apply(message);        assertEquals(3, profiler.getMessageCount());        assertEquals(0, profiler.getRouteCount());    }    {        StandAloneProfiler profiler = createProfiler(oneProfile);        profiler.apply(message);        assertEquals(1, profiler.getMessageCount());        assertEquals(1, profiler.getRouteCount());        profiler.apply(message);        assertEquals(2, profiler.getMessageCount());        assertEquals(2, profiler.getRouteCount());        profiler.apply(message);        assertEquals(3, profiler.getMessageCount());        assertEquals(3, profiler.getRouteCount());    }    {        StandAloneProfiler profiler = createProfiler(twoProfiles);        profiler.apply(message);        assertEquals(1, profiler.getMessageCount());        assertEquals(2, profiler.getRouteCount());        profiler.apply(message);        assertEquals(2, profiler.getMessageCount());        assertEquals(4, profiler.getRouteCount());        profiler.apply(message);        assertEquals(3, profiler.getMessageCount());        assertEquals(6, profiler.getRouteCount());    }}
0
public void testProfileCount() throws Exception
{    {        StandAloneProfiler profiler = createProfiler(noProfiles);        assertEquals(0, profiler.getProfileCount());    }    {        StandAloneProfiler profiler = createProfiler(oneProfile);        assertEquals(1, profiler.getProfileCount());    }    {        StandAloneProfiler profiler = createProfiler(twoProfiles);        assertEquals(2, profiler.getProfileCount());    }}
0
private ProfilerConfig toProfilerConfig(String configAsJSON) throws Exception
{    InputStream in = new ByteArrayInputStream(configAsJSON.getBytes(StandardCharsets.UTF_8));    return JSONUtils.INSTANCE.load(in, ProfilerConfig.class);}
0
private StandAloneProfiler createProfiler(String profileJson) throws Exception
{        long profileTimeToLiveMillis = Long.MAX_VALUE;    long maxNumberOfRoutes = Long.MAX_VALUE;    ProfilerConfig config = toProfilerConfig(profileJson);    return new StandAloneProfiler(config, periodDurationMillis, profileTimeToLiveMillis, maxNumberOfRoutes, context);}
0
public long run(SparkSession spark, Properties profilerProps, Properties globalProperties, Properties readerProps, ProfilerConfig profiles)
{        Map<String, String> globals = Maps.fromProperties(globalProperties);        TelemetryReader reader = TelemetryReaders.create(TELEMETRY_INPUT_READER.get(profilerProps, String.class));    Dataset<String> telemetry = reader.read(spark, profilerProps, readerProps);            Dataset<MessageRoute> routes = telemetry.flatMap(messageRouterFunction(profilerProps, profiles, globals), Encoders.bean(MessageRoute.class));            Dataset<ProfileMeasurementAdapter> measurements = routes.groupByKey(new GroupByPeriodFunction(profilerProps), Encoders.STRING()).mapGroups(new ProfileBuilderFunction(profilerProps, globals), Encoders.bean(ProfileMeasurementAdapter.class));            long count = measurements.mapPartitions(new HBaseWriterFunction(profilerProps), Encoders.INT()).agg(sum("value")).head().getLong(0);        return count;}
1
private MessageRouterFunction messageRouterFunction(Properties profilerProps, ProfilerConfig profiles, Map<String, String> globals)
{    MessageRouterFunction routerFunction = new MessageRouterFunction(profiles, globals);        Optional<Long> beginAt = timestampParser.parse(TELEMETRY_INPUT_BEGIN.get(profilerProps, String.class));    beginAt.ifPresent(begin -> routerFunction.withBegin(begin));        Optional<Long> endAt = timestampParser.parse(TELEMETRY_INPUT_END.get(profilerProps, String.class));    endAt.ifPresent(end -> routerFunction.withEnd(end));    return routerFunction;}
0
public String getKey()
{    return key;}
0
public Object getDefault()
{    return getDefault(valueType);}
0
public T getDefault(Class<T> clazz)
{    return defaultValue == null ? null : ConversionUtils.convert(defaultValue, clazz);}
0
public Object get(Map<String, String> config)
{    return getOrDefault(config, defaultValue);}
0
public Object get(Properties properties)
{    return getOrDefault(properties, defaultValue);}
0
public T get(Map<String, String> config, Class<T> clazz)
{    return getOrDefault(config, defaultValue, clazz);}
0
public T get(Properties properties, Class<T> clazz)
{    return getOrDefault(properties, defaultValue, clazz);}
0
private Object getOrDefault(Map<String, String> config, Object defaultValue)
{    return getOrDefault(config, defaultValue, valueType);}
0
private Object getOrDefault(Properties properties, Object defaultValue)
{    return getOrDefault(properties, defaultValue, valueType);}
0
private T getOrDefault(Map<String, String> config, Object defaultValue, Class<T> clazz)
{    Object value = config.getOrDefault(key, defaultValue.toString());    return value == null ? null : ConversionUtils.convert(value, clazz);}
0
private T getOrDefault(Properties properties, Object defaultValue, Class<T> clazz)
{    Object value = properties.getOrDefault(key, defaultValue);    return value == null ? null : ConversionUtils.convert(value, clazz);}
0
public String toString()
{    return key;}
0
public static void main(String[] args) throws IOException, org.apache.commons.cli.ParseException, Exception
{        CommandLine commandLine = parseCommandLine(args);        profiles = Preconditions.checkNotNull(handleProfileDefinitions(commandLine), "An error occurred while reading profile data");    profilerProps = handleProfilerProperties(commandLine);    globals = handleGlobals(commandLine);    readerProps = handleReaderProperties(commandLine);        if (!profiles.getTimestampField().isPresent()) {        throw new IllegalArgumentException("The Batch Profiler must use event time. The 'timestampField' must be defined in the profile definitions file or via the --timestampField argument.");    }        if (profiles.getProfiles().size() == 0) {        throw new IllegalArgumentException("No profile definitions found.");    }    SparkSession spark = SparkSession.builder().config(new SparkConf()).getOrCreate();    BatchProfiler profiler = new BatchProfiler();    long count = profiler.run(spark, profilerProps, globals, readerProps, profiles);    }
1
private static ProfilerConfig handleProfileDefinitions(CommandLine commandLine) throws MissingOptionException, IOException
{    final String PROFILE_LOCATION_ERROR = "A single profile location (--profiles or --zookeeper) must be specified";    ProfilerConfig profiles;    if ((!PROFILE_ZK.has(commandLine)) && (!PROFILE_DEFN_FILE.has(commandLine))) {        throw new MissingOptionException(PROFILE_LOCATION_ERROR);    }    if (PROFILE_ZK.has(commandLine) && PROFILE_DEFN_FILE.has(commandLine)) {        throw new IllegalArgumentException(PROFILE_LOCATION_ERROR);    }    if (PROFILE_ZK.has(commandLine)) {        profiles = handleProfileDefinitionsZK(commandLine);    } else {        profiles = handleProfileDefinitionsFile(commandLine);    }        if (PROFILE_TIMESTAMP_FLD.has(commandLine)) {        final String timestampField = PROFILE_TIMESTAMP_FLD.get(commandLine);        Preconditions.checkArgument(!Strings.isNullOrEmpty(timestampField), "timestampField must be not be empty if specified");        profiles.setTimestampField(timestampField);    }        return profiles;}
1
private static CuratorFramework createZKClient(final String zkQuorum)
{        final CuratorFramework zkClient = ZKCache.createClient(zkQuorum, Optional.empty());    zkClient.start();        return zkClient;}
1
private static Properties handleGlobals(CommandLine commandLine) throws IOException
{    Properties globals = new Properties();    if (GLOBALS_FILE.has(commandLine)) {        String globalsPath = GLOBALS_FILE.get(commandLine);                globals.load(new FileInputStream(globalsPath));            }    return globals;}
1
private static Properties handleProfilerProperties(CommandLine commandLine) throws IOException
{    Properties config = new Properties();    if (PROFILER_PROPS_FILE.has(commandLine)) {        String propertiesPath = PROFILER_PROPS_FILE.get(commandLine);                config.load(new FileInputStream(propertiesPath));            }    return config;}
1
private static Properties handleReaderProperties(CommandLine commandLine) throws IOException
{    Properties config = new Properties();    if (READER_PROPS_FILE.has(commandLine)) {        String readerPropsPath = READER_PROPS_FILE.get(commandLine);                config.load(new FileInputStream(readerPropsPath));            }    return config;}
1
private static ProfilerConfig handleProfileDefinitionsFile(CommandLine commandLine) throws IOException
{    ProfilerConfig profiles;    if (PROFILE_DEFN_FILE.has(commandLine)) {        String profilePath = PROFILE_DEFN_FILE.get(commandLine);                String contents = IOUtils.toString(new FileInputStream(profilePath));        profiles = ProfilerConfig.fromJSON(contents);            } else {        throw new IllegalArgumentException("No profile(s) defined");    }    return profiles;}
1
private static ProfilerConfig handleProfileDefinitionsZK(final CommandLine commandLine) throws IOException
{    Preconditions.checkArgument(PROFILE_ZK.has(commandLine));    ProfilerConfig profiles;    final String zkQuorum = PROFILE_ZK.get(commandLine);    try (final CuratorFramework zkClient = createZKClient(zkQuorum)) {        profiles = readProfileFromZK(zkClient);    }    return profiles;}
0
 static ProfilerConfig readProfileFromZK(CuratorFramework zkClient) throws IOException
{    ProfilerConfig profiles;    try {                profiles = ConfigurationsUtils.readProfilerConfigFromZookeeper(zkClient);            } catch (Exception ex) {        throw new IOException(String.format("Error reading configuration from Zookeeper client %s", zkClient.toString()), ex);    }    return profiles;}
1
private static CommandLine parseCommandLine(String[] args) throws ParseException
{    CommandLineParser parser = new PosixParser();    return parse(parser, args);}
0
public static Properties getGlobals()
{    return globals;}
0
public static Properties getProfilerProps()
{    return profilerProps;}
0
public static ProfilerConfig getProfiles()
{    return profiles;}
0
public static Properties getReaderProps()
{    return readerProps;}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(option.getOpt());}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(option.getOpt());}
0
public String get(CommandLine cli, String defaultValue)
{    return has(cli) ? cli.getOptionValue(option.getOpt()) : defaultValue;}
0
public static CommandLine parse(CommandLineParser parser, String[] args) throws ParseException
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("invalid arguments: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        throw e;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    String header = "options:";    String footer = "";    String cmd = String.format("spark-submit --class %s --properties-file [spark.properties] [jar] [options]", BatchProfilerCLI.class.getCanonicalName());    formatter.printHelp(cmd, header, getOptions(), footer);}
0
public static Options getOptions()
{    Options allOptions = new Options();    for (BatchProfilerCLIOptions o : BatchProfilerCLIOptions.values()) {        allOptions.addOption(o.option);    }    return allOptions;}
0
public String call(MessageRoute route)
{    ProfilePeriod period = ProfilePeriod.fromTimestamp(route.getTimestamp(), periodDuration, periodDurationUnits);    return new StringBuilder().append(route.getProfileDefinition().getProfile()).append(SEPARATOR).append(route.getEntity()).append(SEPARATOR).append(period.getPeriod()).toString();}
0
public static String profileFromKey(String groupKey)
{    String[] pieces = groupKey.split(SEPARATOR);    if (pieces.length == 3) {        return pieces[0];    } else {        return "unknown";    }}
0
public static String entityFromKey(String groupKey)
{    String[] pieces = groupKey.split(SEPARATOR);    if (pieces.length == 3) {        return pieces[1];    } else {        return "unknown";    }}
0
public static String periodFromKey(String groupKey)
{    String[] pieces = groupKey.split(SEPARATOR);    if (pieces.length == 3) {        return pieces[2];    } else {        return "unknown";    }}
0
public Iterator<Integer> call(Iterator<ProfileMeasurementAdapter> iterator) throws Exception
{    int count = 0;            List<ProfileMeasurementAdapter> measurements = IteratorUtils.toList(iterator);    if (measurements.size() > 0) {                Configuration config = HBaseConfiguration.create();        try (HBaseClient client = new HBaseClient(tableProvider, config, tableName)) {            for (ProfileMeasurementAdapter adapter : measurements) {                ProfileMeasurement m = adapter.toProfileMeasurement();                client.addMutation(rowKeyBuilder.rowKey(m), columnBuilder.columns(m), durability);            }            count = client.mutate();        } catch (IOException e) {                        throw new RuntimeException(e);        }    }        return IteratorUtils.singletonIterator(count);}
1
public HBaseWriterFunction withTableProviderImpl(String providerImpl)
{    this.tableProvider = createTableProvider(providerImpl);    return this;}
0
private static TableProvider createTableProvider(String providerImpl)
{    LOG.trace("Creating table provider; className={}", providerImpl);        if (StringUtils.isEmpty(providerImpl) || providerImpl.charAt(0) == '$') {        return new HTableProvider();    }        try {        Class<? extends TableProvider> clazz = (Class<? extends TableProvider>) Class.forName(providerImpl);        return clazz.getConstructor().newInstance();    } catch (InstantiationException | IllegalAccessException | IllegalStateException | InvocationTargetException | NoSuchMethodException | ClassNotFoundException e) {        throw new IllegalStateException("Unable to instantiate connector", e);    }}
0
public Iterator<MessageRoute> call(String jsonMessage) throws Exception
{    List<MessageRoute> routes = Collections.emptyList();    JSONParser parser = new JSONParser();    Context context = TaskUtils.getContext(globals);    MessageRouter router = new DefaultMessageRouter(context);        Optional<JSONObject> message = toMessage(jsonMessage, parser);    if (message.isPresent()) {                Optional<Long> timestampOpt = clock.currentTimeMillis(message.get());        if (timestampOpt.isPresent()) {                        Long timestamp = timestampOpt.get();            if (timestamp >= begin && timestamp <= end) {                routes = router.route(message.get(), profilerConfig, context);                LOG.trace("Found {} route(s) for a message", routes.size());            } else {                LOG.trace("Ignoring message; timestamp={} not in [{},{}]", () -> timestamp, () -> prettyPrint(begin), () -> prettyPrint(end));            }        } else {            LOG.trace("No timestamp in message. Message will be ignored.");        }    } else {        LOG.trace("Unable to parse message. Message will be ignored");    }    return routes.iterator();}
0
public MessageRouterFunction withBegin(Long begin)
{    this.begin = begin;    return this;}
0
public MessageRouterFunction withEnd(Long end)
{    this.end = end;    return this;}
0
public MessageRouterFunction withClockFactory(ClockFactory clockFactory)
{    this.clock = clockFactory.createClock(profilerConfig);    return this;}
0
private static String prettyPrint(Long value)
{    String result;    if (value == Long.MIN_VALUE) {        result = "MIN";    } else if (value == Long.MAX_VALUE) {        result = "MAX";    } else {        result = value.toString();    }    return result;}
0
private static Stream<T> toStream(Iterator<T> iterator)
{    Iterable<T> iterable = () -> iterator;    return StreamSupport.stream(iterable.spliterator(), false);}
0
public static Context getContext(Map<String, String> globals)
{    Context context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> globals).with(Context.Capabilities.STELLAR_CONFIG, () -> globals).build();    StellarFunctions.initialize(context);    return context;}
0
public ProfileMeasurement toProfileMeasurement()
{    ProfilePeriod period = ProfilePeriod.fromPeriodId(periodId, durationMillis, TimeUnit.MILLISECONDS);    ProfileMeasurement measurement = new ProfileMeasurement().withProfileName(profileName).withEntity(entity).withPeriod(period).withProfileValue(SerDeUtils.fromBytes(profileValue, Object.class));    return measurement;}
0
public String getProfileName()
{    return profileName;}
0
public void setProfileName(String profileName)
{    this.profileName = profileName;}
0
public String getEntity()
{    return entity;}
0
public void setEntity(String entity)
{    this.entity = entity;}
0
public Long getPeriodId()
{    return periodId;}
0
public void setPeriodId(Long periodId)
{    this.periodId = periodId;}
0
public Long getDurationMillis()
{    return durationMillis;}
0
public void setDurationMillis(Long durationMillis)
{    this.durationMillis = durationMillis;}
0
public byte[] getProfileValue()
{    return profileValue;}
0
public void setProfileValue(byte[] profileValue)
{    this.profileValue = profileValue;}
0
public void setProfileValue(Object profileValue)
{    this.profileValue = SerDeUtils.toBytes(profileValue);}
0
public static TelemetryReader create(String propertyValue)
{        TelemetryReader reader = null;    try {        String key = StringUtils.upperCase(propertyValue);        TelemetryReaders strategy = TelemetryReaders.valueOf(key);        reader = strategy.supplier.get();    } catch (IllegalArgumentException e) {                throw e;    }    return reader;}
1
public Dataset<String> read(SparkSession spark, Properties profilerProps, Properties readerProps)
{    return supplier.get().read(spark, profilerProps, readerProps);}
0
public Optional<Long> parse(String inputString)
{    Optional<Long> epochMilli = Optional.empty();        if (StringUtils.isNotBlank(inputString)) {        epochMilli = Optional.of(new DateTimeFormatterBuilder().append(DateTimeFormatter.ISO_INSTANT).toFormatter().parse(inputString, Instant::from).toEpochMilli());    }    return epochMilli;}
0
public static void setupSpark()
{    SparkConf conf = new SparkConf().setMaster("local").setAppName("BatchProfilerIntegrationTest").set("spark.sql.shuffle.partitions", "8");    spark = SparkSession.builder().config(conf).getOrCreate();}
0
public static void tearDownSpark()
{    if (spark != null) {        spark.close();    }}
0
public void setup()
{    readerProperties = new Properties();    profilerProperties = new Properties();        String tableName = HBASE_TABLE_NAME.get(profilerProperties, String.class);    String columnFamily = HBASE_COLUMN_FAMILY.get(profilerProperties, String.class);    profilerProperties.put(HBASE_TABLE_PROVIDER.getKey(), MockHBaseTableProvider.class.getName());        MockHBaseTableProvider.addToCache(tableName, columnFamily);        Map<String, Object> global = new HashMap<String, Object>() {        {            put(PROFILER_HBASE_TABLE.getKey(), tableName);            put(PROFILER_COLUMN_FAMILY.getKey(), columnFamily);            put(PROFILER_HBASE_TABLE_PROVIDER.getKey(), MockHBaseTableProvider.class.getName());        }    };        executor = new DefaultStellarStatefulExecutor(new SimpleFunctionResolver().withClass(GetProfile.class).withClass(FixedLookback.class).withClass(WindowLookback.class), new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> global).build());}
0
public void testBatchProfilerWithJSON() throws Exception
{        profilerProperties.put(TELEMETRY_INPUT_READER.getKey(), JSON.toString());    profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), "src/test/resources/telemetry.json");    BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(profileJson));    validateProfiles();}
0
public void testBatchProfilerWithORC() throws Exception
{        String pathToORC = tempFolder.getRoot().getAbsolutePath();    spark.read().format("json").load("src/test/resources/telemetry.json").write().mode("overwrite").format("org.apache.spark.sql.execution.datasources.orc").save(pathToORC);        profilerProperties.put(TELEMETRY_INPUT_READER.getKey(), ORC.toString());    profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), pathToORC);    BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(profileJson));    validateProfiles();}
0
public void testBatchProfilerWithParquet() throws Exception
{        String inputPath = tempFolder.getRoot().getAbsolutePath();    spark.read().format("json").load("src/test/resources/telemetry.json").write().mode("overwrite").format("parquet").save(inputPath);        profilerProperties.put(TELEMETRY_INPUT_READER.getKey(), PARQUET.toString());    profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), inputPath);    BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(profileJson));    validateProfiles();}
0
public void testBatchProfilerWithCSV() throws Exception
{        String pathToCSV = tempFolder.getRoot().getAbsolutePath();    spark.read().format("text").load("src/test/resources/telemetry.json").as(Encoders.STRING()).write().mode("overwrite").option("header", "true").format("csv").save(pathToCSV);            profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), pathToCSV);    profilerProperties.put(TELEMETRY_INPUT_READER.getKey(), "text");    profilerProperties.put(TELEMETRY_INPUT_FORMAT.getKey(), "csv");        readerProperties.put("header", "true");    BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(profileJson));    validateProfiles();}
0
public void testBatchProfilerWithEndTimeConstraint() throws Exception
{        profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), "src/test/resources/telemetry.json");    profilerProperties.put(TELEMETRY_INPUT_FORMAT.getKey(), "text");        profilerProperties.put(TELEMETRY_INPUT_BEGIN.getKey(), "");    profilerProperties.put(TELEMETRY_INPUT_END.getKey(), "2018-07-07T15:51:48Z");    BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(profileJson));        assign("maxTimestamp", "1530978728982L");        assign("window", "PROFILE_WINDOW('from 5 hours ago', maxTimestamp)");    assertTrue(execute("[12] == PROFILE_GET('count-by-ip', '192.168.66.1', window)", Boolean.class));    assertTrue(execute("[28] == PROFILE_GET('count-by-ip', '192.168.138.158', window)", Boolean.class));    assertTrue(execute("[40] == PROFILE_GET('total-count', 'total', window)", Boolean.class));}
0
public void testBatchProfilerWithBeginTimeConstraint() throws Exception
{        profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), "src/test/resources/telemetry.json");    profilerProperties.put(TELEMETRY_INPUT_FORMAT.getKey(), "text");        profilerProperties.put(TELEMETRY_INPUT_BEGIN.getKey(), "2018-07-07T15:51:48Z");    profilerProperties.put(TELEMETRY_INPUT_END.getKey(), "");    BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(profileJson));        assign("maxTimestamp", "1530978728982L");        assign("window", "PROFILE_WINDOW('from 5 hours ago', maxTimestamp)");    assertTrue(execute("[14] == PROFILE_GET('count-by-ip', '192.168.66.1', window)", Boolean.class));    assertTrue(execute("[46] == PROFILE_GET('count-by-ip', '192.168.138.158', window)", Boolean.class));    assertTrue(execute("[60] == PROFILE_GET('total-count', 'total', window)", Boolean.class));}
0
public void testBatchProfilerWithInvalidProfile() throws Exception
{    profilerProperties.put(TELEMETRY_INPUT_READER.getKey(), JSON.toString());    profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), "src/test/resources/telemetry.json");        BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(invalidProfileJson));}
0
public void testBatchProfilerWithStatsFunctions() throws Exception
{    profilerProperties.put(TELEMETRY_INPUT_READER.getKey(), JSON.toString());    profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), "src/test/resources/telemetry.json");    BatchProfiler profiler = new BatchProfiler();    profiler.run(spark, profilerProperties, getGlobals(), readerProperties, fromJSON(statsProfileJson));        validateProfiles();}
0
private void validateProfiles()
{        assign("maxTimestamp", "1530978728982L");        assign("window", "PROFILE_WINDOW('from 5 hours ago', maxTimestamp)");        assertTrue(execute("[26] == PROFILE_GET('count-by-ip', '192.168.66.1', window)", Boolean.class));        assertTrue(execute("[74] == PROFILE_GET('count-by-ip', '192.168.138.158', window)", Boolean.class));        assertTrue(execute("[100] == PROFILE_GET('total-count', 'total', window)", Boolean.class));}
0
private Properties getGlobals()
{    return new Properties();}
0
private void assign(String var, String expression)
{    executor.assign(var, expression, Collections.emptyMap());}
0
private T execute(String expression, Class<T> clazz)
{    T results = executor.execute(expression, Collections.emptyMap(), clazz);        return results;}
1
public void mustDefineTimestampField() throws Exception
{    String[] args = new String[] { "--profiles", "src/test/resources/profiles-no-timestamp-field.json" };    BatchProfilerCLI.main(args);}
0
public void mustDefineProfilesOption() throws Exception
{    String[] args = new String[] {};    BatchProfilerCLI.main(args);}
0
public void mustDefineOnlyOneProfilesOption() throws Exception
{    String[] args = new String[] { "--profiles", "src/test/resources/profiles-no-timestamp-field.json", "--zookeeper", "node1:2181" };    BatchProfilerCLI.main(args);}
0
public void mustDefineFieldnametoGoWithTimestamp() throws Exception
{    String[] args = new String[] { "--timestampfield" };    BatchProfilerCLI.main(args);}
0
public void mustDefineProfiles() throws Exception
{    String[] args = new String[] { "--profiles", "src/test/resources/profiles-empty.json" };    BatchProfilerCLI.main(args);}
0
public void testProfilerZookeeperIntegration() throws Exception
{    final byte[] profileExpectedByte = profile.getBytes(StandardCharsets.UTF_8);    final ProfilerConfig expectedProfileConfig = ProfilerConfig.fromBytes(profileExpectedByte);    TestZKServer.runWithZK((zkServer, zkClient) -> {                ConfigurationsUtils.writeProfilerConfigToZookeeper(profileExpectedByte, zkClient);                final ProfilerConfig profiles = BatchProfilerCLI.readProfileFromZK(zkClient);                Assert.assertEquals("Profile read from zookeeper has changes", expectedProfileConfig, profiles);    });}
0
public void testProfileZookeeperIntegrationFails() throws Exception
{    final byte[] profileExpectedByte = profile.getBytes(StandardCharsets.UTF_8);    final ProfilerConfig expectedProfileConfig = ProfilerConfig.fromBytes(profileExpectedByte);    expectedProfileConfig.setTimestampField("foobar");    TestZKServer.runWithZK((zkServer, zkClient) -> {                ConfigurationsUtils.writeProfilerConfigToZookeeper(profileExpectedByte, zkClient);                final ProfilerConfig profiles = BatchProfilerCLI.readProfileFromZK(zkClient);                Assert.assertNotEquals("Profile zookeeper integration test fails to detect change", expectedProfileConfig, profiles);    });}
0
public void shouldDecodeGroupKey() throws Exception
{    final ProfileConfig profile = ProfileConfig.fromJSON(profileJSON);    final Long timestamp = System.currentTimeMillis();    final String entity = "192.168.1.1";    final JSONObject message = new JSONObject();    final String periodId = new Long(ProfilePeriod.fromTimestamp(timestamp, 15, TimeUnit.MINUTES).getPeriod()).toString();    MessageRoute route = new MessageRoute(profile, entity, message, timestamp);    String groupKey = new GroupByPeriodFunction(new Properties()).call(route);        Assert.assertEquals("my-profile-name", GroupByPeriodFunction.profileFromKey(groupKey));    Assert.assertEquals(entity, GroupByPeriodFunction.entityFromKey(groupKey));    Assert.assertEquals(periodId, GroupByPeriodFunction.periodFromKey(groupKey));}
0
public void setup()
{    profilerProperties = getProfilerProperties();        String tableName = HBASE_TABLE_NAME.get(profilerProperties, String.class);    String columnFamily = HBASE_COLUMN_FAMILY.get(profilerProperties, String.class);    MockHBaseTableProvider.addToCache(tableName, columnFamily);}
0
public void testWrite() throws Exception
{    JSONObject message = getMessage();    String entity = (String) message.get("ip_src_addr");    long timestamp = (Long) message.get("timestamp");    ProfileConfig profile = getProfile();        List<ProfileMeasurementAdapter> measurements = createMeasurements(1, entity, timestamp, profile);        HBaseWriterFunction function = new HBaseWriterFunction(profilerProperties);    function.withTableProviderImpl(MockHBaseTableProvider.class.getName());        Iterator<Integer> results = function.call(measurements.iterator());        List<Integer> counts = IteratorUtils.toList(results);    Assert.assertEquals(1, counts.size());    Assert.assertEquals(1, counts.get(0).intValue());}
0
public void testWriteMany() throws Exception
{    JSONObject message = getMessage();    String entity = (String) message.get("ip_src_addr");    long timestamp = (Long) message.get("timestamp");    ProfileConfig profile = getProfile();        List<ProfileMeasurementAdapter> measurements = createMeasurements(10, entity, timestamp, profile);        HBaseWriterFunction function = new HBaseWriterFunction(profilerProperties);    function.withTableProviderImpl(MockHBaseTableProvider.class.getName());        Iterator<Integer> results = function.call(measurements.iterator());        List<Integer> counts = IteratorUtils.toList(results);    Assert.assertEquals(1, counts.size());    Assert.assertEquals(10, counts.get(0).intValue());}
0
public void testWriteNone() throws Exception
{        List<ProfileMeasurementAdapter> measurements = new ArrayList<>();        HBaseWriterFunction function = new HBaseWriterFunction(profilerProperties);    function.withTableProviderImpl(MockHBaseTableProvider.class.getName());        Iterator<Integer> results = function.call(measurements.iterator());        List<Integer> counts = IteratorUtils.toList(results);    Assert.assertEquals(1, counts.size());    Assert.assertEquals(0, counts.get(0).intValue());}
0
private List<ProfileMeasurementAdapter> createMeasurements(int count, String entity, long timestamp, ProfileConfig profile)
{    List<ProfileMeasurementAdapter> measurements = new ArrayList<>();    for (int i = 0; i < count; i++) {        ProfileMeasurement measurement = new ProfileMeasurement().withProfileName(profile.getProfile()).withEntity(entity).withPeriod(timestamp, 15, TimeUnit.MINUTES);                measurements.add(new ProfileMeasurementAdapter(measurement));    }    return measurements;}
0
private JSONObject getMessage()
{    JSONObject message = new JSONObject();    message.put("ip_src_addr", "192.168.1.1");    message.put("status", "red");    message.put("timestamp", System.currentTimeMillis());    return message;}
0
private Properties getProfilerProperties()
{    return new Properties();}
0
private ProfileConfig getProfile()
{    return new ProfileConfig().withProfile("profile1").withForeach("ip_src_addr").withUpdate("count", "count + 1").withResult("count");}
0
public void testFindRoutes() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals());    Iterator<MessageRoute> iter = function.call(goodMessage);    List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(1, routes.size());    Assert.assertEquals("profile1", routes.get(0).getProfileDefinition().getProfile());}
0
public void testWithSystemTime() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profileWithSystemTime(), getGlobals());    Iterator<MessageRoute> iter = function.call(goodMessage);    Assert.fail("Exception expected as system time is not supported.");}
0
public void testWithBadMessage() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals());    Iterator<MessageRoute> iter = function.call(badMessage);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(0, routes.size());}
0
public void testFindMultipleRoutes() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(twoProfiles(), getGlobals());    Iterator<MessageRoute> iter = function.call(goodMessage);    List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(2, routes.size());    Assert.assertEquals("profile1", routes.get(0).getProfileDefinition().getProfile());    Assert.assertEquals("profile2", routes.get(1).getProfileDefinition().getProfile());}
0
public void testWithNoTimestampInMessage() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals());    Iterator<MessageRoute> iter = function.call(messageNoTimestamp);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(0, routes.size());}
0
public void testMessageFilteredByBegin() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals()).withBegin(messageTimestamp + 1000);    Iterator<MessageRoute> iter = function.call(goodMessage);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(0, routes.size());}
0
public void testMessageNotFilteredByBegin() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals()).withBegin(messageTimestamp - 1000);    Iterator<MessageRoute> iter = function.call(goodMessage);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(1, routes.size());}
0
public void testMessageFilteredByEnd() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals()).withEnd(messageTimestamp - 1000);    Iterator<MessageRoute> iter = function.call(goodMessage);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(0, routes.size());}
0
public void testMessageNotFilteredByEnd() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals()).withEnd(messageTimestamp + 1000);    Iterator<MessageRoute> iter = function.call(goodMessage);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(1, routes.size());}
0
public void testMessageFilteredByBeginAndEnd() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals()).withBegin(messageTimestamp + 1000).withEnd(messageTimestamp + 2000);    Iterator<MessageRoute> iter = function.call(goodMessage);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(0, routes.size());}
0
public void testMessageNotFilteredByBeginAndEnd() throws Exception
{    MessageRouterFunction function = new MessageRouterFunction(profile(), getGlobals()).withBegin(messageTimestamp - 1000).withEnd(messageTimestamp + 1000);    Iterator<MessageRoute> iter = function.call(goodMessage);        List<MessageRoute> routes = Lists.newArrayList(iter);    Assert.assertEquals(1, routes.size());}
0
private ProfilerConfig profile()
{    ProfileConfig profile = new ProfileConfig().withProfile("profile1").withForeach("ip_src_addr").withUpdate("count", "count + 1").withResult("count");    return new ProfilerConfig().withProfile(profile).withTimestampField(Optional.of("timestamp"));}
0
private ProfilerConfig twoProfiles()
{    ProfileConfig profile1 = new ProfileConfig().withProfile("profile1").withForeach("ip_src_addr").withUpdate("count", "count + 1").withResult("count");    ProfileConfig profile2 = new ProfileConfig().withProfile("profile2").withForeach("ip_src_addr").withUpdate("count", "count + 1").withResult("count");    return new ProfilerConfig().withProfile(profile1).withProfile(profile2).withTimestampField(Optional.of("timestamp"));}
0
private ProfilerConfig profileWithSystemTime()
{    ProfileConfig profile = new ProfileConfig().withProfile("profile1").withForeach("ip_src_addr").withUpdate("count", "count + 1").withResult("count");    return new ProfilerConfig().withProfile(profile);}
0
private Map<String, String> getGlobals()
{    return Collections.emptyMap();}
0
public void shouldBuildProfileMeasurement() throws Exception
{        JSONObject message = getMessage();    String entity = "192.168.1.1";    long timestamp = (Long) message.get("timestamp");    ProfileConfig profile = ProfileConfig.fromJSON(profileJSON);        MessageRoute route = new MessageRoute(profile, entity, message, timestamp);    List<MessageRoute> routes = new ArrayList();    routes.add(route);    routes.add(route);    routes.add(route);    Properties profilerProperties = getProfilerProperties();        int periodDuration = PERIOD_DURATION.get(profilerProperties, Integer.class);    TimeUnit periodDurationUnits = TimeUnit.valueOf(PERIOD_DURATION_UNITS.get(profilerProperties, String.class));    ProfilePeriod expectedPeriod = ProfilePeriod.fromTimestamp(timestamp, periodDuration, periodDurationUnits);        ProfileBuilderFunction function = new ProfileBuilderFunction(profilerProperties, getGlobals());    ProfileMeasurementAdapter measurement = function.call("profile1-192.168.1.1-0", routes.iterator());        Assert.assertEquals(entity, measurement.getEntity());    Assert.assertEquals(profile.getProfile(), measurement.getProfileName());    Assert.assertEquals(routes.size(), measurement.toProfileMeasurement().getProfileValue());    Assert.assertEquals(expectedPeriod.getPeriod(), (long) measurement.getPeriodId());}
0
public void shouldThrowExceptionIfInvalidProfile() throws Exception
{        JSONObject message = getMessage();    String entity = "192.168.1.1";    long timestamp = (Long) message.get("timestamp");    ProfileConfig profile = ProfileConfig.fromJSON(invalidProfileJson);        MessageRoute route = new MessageRoute(profile, entity, message, timestamp);    List<MessageRoute> routes = new ArrayList();    routes.add(route);    routes.add(route);    routes.add(route);    Properties profilerProperties = getProfilerProperties();        ProfileBuilderFunction function = new ProfileBuilderFunction(profilerProperties, getGlobals());    ProfileMeasurementAdapter measurement = function.call("profile1-192.168.1.1-0", routes.iterator());}
0
private JSONObject getMessage()
{    JSONObject message = new JSONObject();    message.put("ip_src_addr", "192.168.1.1");    message.put("status", "red");    message.put("timestamp", System.currentTimeMillis());    return message;}
0
private Properties getProfilerProperties()
{    return new Properties();}
0
private Map<String, String> getGlobals()
{    return Collections.emptyMap();}
0
public static void setupSpark()
{    SparkConf conf = new SparkConf().setMaster("local").setAppName("BatchProfilerIntegrationTest").set("spark.sql.shuffle.partitions", "8");    spark = SparkSession.builder().config(conf).getOrCreate();}
0
public static void tearDownSpark()
{    if (spark != null) {        spark.close();    }}
0
public void setup()
{    readerProperties = new Properties();    profilerProperties = new Properties();}
0
public void testParquet()
{        String inputPath = tempFolder.getRoot().getAbsolutePath();    spark.read().format("json").load("src/test/resources/telemetry.json").write().mode("overwrite").format("parquet").save(inputPath);        profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), inputPath);    profilerProperties.put(TELEMETRY_INPUT_FORMAT.getKey(), "parquet");        readerProperties.put("header", "true");        Dataset<String> telemetry = TelemetryReaders.COLUMNAR.read(spark, profilerProperties, readerProperties);    Assert.assertEquals(100, telemetry.filter(new IsValidJSON()).count());}
0
public void testORC()
{        String pathToORC = tempFolder.getRoot().getAbsolutePath();    spark.read().format("json").load("src/test/resources/telemetry.json").write().mode("overwrite").format("org.apache.spark.sql.execution.datasources.orc").save(pathToORC);        profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), pathToORC);    profilerProperties.put(TELEMETRY_INPUT_FORMAT.getKey(), "org.apache.spark.sql.execution.datasources.orc");        Dataset<String> telemetry = TelemetryReaders.COLUMNAR.read(spark, profilerProperties, readerProperties);    Assert.assertEquals(100, telemetry.filter(new IsValidJSON()).count());}
0
public boolean call(String text) throws Exception
{    JSONParser parser = new JSONParser();    JSONObject json = (JSONObject) parser.parse(text);        return json.keySet().size() >= 32;}
0
public void testJsonReader()
{    String key = JSON.toString();    Assert.assertTrue(TelemetryReaders.create(key) instanceof TextEncodedTelemetryReader);}
0
public void testJsonReaderLowerCase()
{    String key = JSON.toString().toLowerCase();    Assert.assertTrue(TelemetryReaders.create(key) instanceof TextEncodedTelemetryReader);}
0
public void testOrcReader()
{    String key = ORC.toString();    Assert.assertTrue(TelemetryReaders.create(key) instanceof ColumnEncodedTelemetryReader);}
0
public void testOrcReaderLowerCase()
{    String key = ORC.toString().toLowerCase();    Assert.assertTrue(TelemetryReaders.create(key) instanceof ColumnEncodedTelemetryReader);}
0
public void testParquetReader()
{    String key = PARQUET.toString();    Assert.assertTrue(TelemetryReaders.create(key) instanceof ColumnEncodedTelemetryReader);}
0
public void testParquetReaderLowerCase()
{    String key = PARQUET.toString().toLowerCase();    Assert.assertTrue(TelemetryReaders.create(key) instanceof ColumnEncodedTelemetryReader);}
0
public void testTextReader()
{    String key = TEXT.toString();    Assert.assertTrue(TelemetryReaders.create(key) instanceof TextEncodedTelemetryReader);}
0
public void testColumnReader()
{    String key = COLUMNAR.toString();    Assert.assertTrue(TelemetryReaders.create(key) instanceof ColumnEncodedTelemetryReader);}
0
public void testInvalidReader()
{    TelemetryReaders.create("invalid");    Assert.fail("exception expected");}
0
public static void setupSpark()
{    SparkConf conf = new SparkConf().setMaster("local").setAppName("BatchProfilerIntegrationTest").set("spark.sql.shuffle.partitions", "8");    spark = SparkSession.builder().config(conf).getOrCreate();}
0
public static void tearDownSpark()
{    if (spark != null) {        spark.close();    }}
0
public void setup()
{    readerProperties = new Properties();    profilerProperties = new Properties();}
0
public void testCSV()
{        String pathToCSV = tempFolder.getRoot().getAbsolutePath();    spark.read().format("text").load("src/test/resources/telemetry.json").as(Encoders.STRING()).write().mode("overwrite").option("header", "true").format("csv").save(pathToCSV);        profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), pathToCSV);    profilerProperties.put(TELEMETRY_INPUT_FORMAT.getKey(), "csv");        readerProperties.put("header", "true");        Dataset<String> telemetry = TelemetryReaders.TEXT.read(spark, profilerProperties, readerProperties);    Assert.assertEquals(100, telemetry.filter(new IsValidJSON()).count());}
0
public void testJSON()
{        profilerProperties.put(TELEMETRY_INPUT_PATH.getKey(), "src/test/resources/telemetry.json");    profilerProperties.put(TELEMETRY_INPUT_FORMAT.getKey(), "text");        readerProperties.put("header", "true");        Dataset<String> telemetry = TelemetryReaders.TEXT.read(spark, profilerProperties, readerProperties);    Assert.assertEquals(100, telemetry.filter(new IsValidJSON()).count());}
0
public void setup()
{    parser = new TimestampParser();}
0
public void testEmpty()
{    Optional<Long> millis = parser.parse("");    assertFalse(millis.isPresent());}
0
public void testBlank()
{    Optional<Long> millis = parser.parse("      ");    assertFalse(millis.isPresent());}
0
public void testIsoInstantFormat()
{        Optional<Long> millis = parser.parse("2011-12-03T10:15:30Z");    assertTrue(millis.isPresent());    assertEquals(1322907330000L, millis.get().longValue());}
0
public void testInvalidFormat()
{    parser.parse("1537502400000");    fail("Expected exception");}
0
public void fail(Exception e)
{    collector.reportError(e);    for (Tuple t : tupleBatch) {        collector.fail(t);    }    tupleBatch.clear();    forceFlush = false;}
0
public void ack()
{    for (Tuple t : tupleBatch) {        collector.ack(t);    }    tupleBatch.clear();    forceFlush = false;}
0
public boolean shouldHandle(Tuple tuple)
{    if (isTick(tuple)) {                forceFlush = true;        return false;    } else {        return true;    }}
1
public void addBatch(Tuple tuple)
{    tupleBatch.add(tuple);    if (tupleBatch.size() >= batchSize) {        forceFlush = true;    }}
0
public List<Tuple> getBatchTuples()
{    return this.tupleBatch;}
0
public int getBatchSize()
{    return this.batchSize;}
0
public boolean shouldFlush()
{    return forceFlush && !tupleBatch.isEmpty();}
0
public boolean isTick(Tuple tuple)
{    return tuple != null && Constants.SYSTEM_COMPONENT_ID.equals(tuple.getSourceComponent()) && Constants.SYSTEM_TICK_STREAM_ID.equals(tuple.getSourceStreamId());}
0
public HBaseBolt writeToWAL(boolean writeToWAL)
{    this.writeToWAL = writeToWAL;    return this;}
0
public HBaseBolt withTableProvider(String tableProvider)
{    this.tableProviderClazzName = tableProvider;    return this;}
0
public HBaseBolt withTableProviderInstance(TableProvider tableProvider)
{    this.tableProvider = tableProvider;    return this;}
0
public HBaseBolt withBatchSize(int batchSize)
{    this.batchSize = batchSize;    return this;}
0
public HBaseBolt withFlushIntervalSecs(int flushIntervalSecs)
{    this.flushIntervalSecs = flushIntervalSecs;    return this;}
0
public void setClient(HBaseClient hbaseClient)
{    this.hbaseClient = hbaseClient;}
0
public Map<String, Object> getComponentConfiguration()
{        Config conf = new Config();    conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, flushIntervalSecs);    return conf;}
1
public void prepare(Map map, TopologyContext topologyContext, OutputCollector collector)
{    this.collector = collector;    this.batchHelper = new BatchHelper(batchSize, collector);    TableProvider provider;    if (this.tableProvider == null) {        provider = createTableProvider(tableProviderClazzName);    } else {        provider = this.tableProvider;    }    hbaseClient = new HBaseClient(provider, HBaseConfiguration.create(), tableName);}
0
public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer)
{}
0
public void execute(Tuple tuple)
{    LOG.trace("Received a tuple.");    try {        if (batchHelper.shouldHandle(tuple)) {            save(tuple);        }        if (batchHelper.shouldFlush()) {            flush();        }    } catch (Exception e) {        batchHelper.fail(e);        hbaseClient.clearMutations();    }}
0
private void flush()
{        this.hbaseClient.mutate();    batchHelper.ack();}
1
private static TableProvider createTableProvider(String connectorImpl)
{    LOG.trace("Creating table provider; className={}", connectorImpl);        if (StringUtils.isEmpty(connectorImpl) || connectorImpl.charAt(0) == '$') {        return new HTableProvider();    }        try {        Class<? extends TableProvider> clazz = (Class<? extends TableProvider>) Class.forName(connectorImpl);        return clazz.getConstructor().newInstance();    } catch (InstantiationException | IllegalAccessException | IllegalStateException | InvocationTargetException | NoSuchMethodException | ClassNotFoundException e) {        throw new IllegalStateException("Unable to instantiate connector", e);    }}
0
public void reset()
{    minTime = Long.MAX_VALUE;    maxTime = Long.MIN_VALUE;    }
1
public void update(long timestamp)
{    if (LOG.isWarnEnabled()) {        checkIfOutOfOrder(timestamp);    }    if (timestamp < minTime) {        minTime = timestamp;    }    if (timestamp > maxTime) {        maxTime = timestamp;    }}
0
private void checkIfOutOfOrder(long timestamp)
{        if (maxTime > Long.MIN_VALUE) {        long outOfOrderBy = maxTime - timestamp;        if (Math.abs(outOfOrderBy) > flushFrequency) {                    }    }}
1
public long currentTimeMillis()
{    return maxTime;}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    declarer.declareStream(getStreamId(), new Fields("measurement"));}
0
public String getStreamId()
{    return streamId;}
0
public void setStreamId(String streamId)
{    this.streamId = streamId;}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{        declarer.declareStream(getStreamId(), new Fields("message"));}
0
private JSONObject createMessage(ProfileMeasurement measurement)
{    JSONObject message = new JSONObject();    message.put(PROFILE_FIELD, measurement.getDefinition().getProfile());    message.put(ENTITY_FIELD, measurement.getEntity());    message.put(PERIOD_ID_FIELD, measurement.getPeriod().getPeriod());    message.put(PERIOD_START_FIELD, measurement.getPeriod().getStartTimeMillis());    message.put(PERIOD_END_FIELD, measurement.getPeriod().getEndTimeMillis());    message.put(TIMESTAMP_FIELD, System.currentTimeMillis());    message.put(Constants.SENSOR_TYPE, sourceType);    message.put(ALERT_FIELD, "true");    message.put(Constants.GUID, UUID.randomUUID().toString());    return message;}
0
private boolean isValidType(Object value)
{    return value != null && (value instanceof String || ClassUtils.isPrimitiveOrWrapper(value.getClass()));}
0
public String getStreamId()
{    return streamId;}
0
public void setStreamId(String streamId)
{    this.streamId = streamId;}
0
public String getSourceType()
{    return sourceType;}
0
public void setSourceType(String sourceType)
{    this.sourceType = sourceType;}
0
public void setFlushNow(boolean flushNow)
{    this.flushNow = flushNow;}
0
public boolean isTimeToFlush()
{    return flushNow;}
0
public void update(long timestamp)
{}
0
public void reset()
{}
0
public long currentTimeMillis()
{        return 0;}
0
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)
{    super.prepare(stormConf, context, collector);    if (periodDurationMillis <= 0) {        throw new IllegalArgumentException("expect 'profiler.period.duration' >= 0");    }    if (profileTimeToLiveMillis <= 0) {        throw new IllegalArgumentException("expect 'profiler.ttl' >= 0");    }    if (profileTimeToLiveMillis < periodDurationMillis) {        throw new IllegalArgumentException("expect 'profiler.ttl' >= 'profiler.period.duration'");    }    if (maxNumberOfRoutes <= 0) {        throw new IllegalArgumentException("expect 'profiler.max.routes.per.bolt' > 0");    }    if (windowDurationMillis <= 0) {        throw new IllegalArgumentException("expect 'profiler.window.duration' > 0");    }    if (windowDurationMillis > periodDurationMillis) {        throw new IllegalArgumentException("expect 'profiler.period.duration' >= 'profiler.window.duration'");    }    if (periodDurationMillis % windowDurationMillis != 0) {        throw new IllegalArgumentException("expect 'profiler.period.duration' % 'profiler.window.duration' == 0");    }    this.collector = collector;    this.parser = new JSONParser();    this.messageDistributor = new DefaultMessageDistributor(periodDurationMillis, profileTimeToLiveMillis, maxNumberOfRoutes);    this.configurations = new ProfilerConfigurations();    this.activeFlushSignal = new FixedFrequencyFlushSignal(periodDurationMillis);    setupZookeeper();    startFlushingExpiredProfiles();}
0
public void cleanup()
{    try {        zookeeperCache.close();        zookeeperClient.close();        flushExpiredExecutor.shutdown();    } catch (Throwable e) {            }}
1
private void setupZookeeper()
{    try {        if (zookeeperClient == null) {            RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);            zookeeperClient = CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);        }        zookeeperClient.start();                        ConfigurationsUtils.setupStellarStatically(zookeeperClient);        if (zookeeperCache == null) {            ConfigurationsUpdater<ProfilerConfigurations> updater = createUpdater();            SimpleEventListener listener = new SimpleEventListener.Builder().with(updater::update, TreeCacheEvent.Type.NODE_ADDED, TreeCacheEvent.Type.NODE_UPDATED).with(updater::delete, TreeCacheEvent.Type.NODE_REMOVED).build();            zookeeperCache = new ZKCache.Builder().withClient(zookeeperClient).withListener(listener).withRoot(Constants.ZOOKEEPER_TOPOLOGY_ROOT).build();            updater.forceUpdate(zookeeperClient);            zookeeperCache.start();        }    } catch (Exception e) {                throw new RuntimeException(e);    }}
1
protected ConfigurationsUpdater<ProfilerConfigurations> createUpdater()
{    return new ProfilerUpdater(this, this::getConfigurations);}
0
public ProfilerConfigurations getConfigurations()
{    return configurations;}
0
public void reloadCallback(String name, ConfigurationType type)
{}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    if (emitters.size() == 0) {        throw new IllegalStateException("At least one destination handler must be defined.");    }        emitters.forEach(emitter -> emitter.declareOutputFields(declarer));}
0
private Context getStellarContext()
{    Map<String, Object> global = getConfigurations().getGlobalConfig();    return new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> zookeeperClient).with(Context.Capabilities.GLOBAL_CONFIG, () -> global).with(Context.Capabilities.STELLAR_CONFIG, () -> global).build();}
0
public void execute(TupleWindow window)
{    if (LOG.isDebugEnabled()) {        log(window);    }    try {                for (Tuple tuple : window.get()) {            handleMessage(tuple);        }                if (activeFlushSignal.isTimeToFlush()) {            flushActive();        }    } catch (Throwable e) {                collector.reportError(e);    }}
1
protected void flushActive()
{    activeFlushSignal.reset();        List<ProfileMeasurement> measurements;    synchronized (messageDistributor) {        measurements = messageDistributor.flush();        emitMeasurements(measurements);    }    }
1
protected void flushExpired()
{    List<ProfileMeasurement> measurements = null;    try {                synchronized (messageDistributor) {            measurements = messageDistributor.flushExpired();            emitMeasurements(measurements);        }    } catch (Throwable t) {                            }    }
1
private void handleMessage(Tuple input)
{        JSONObject message = getField(MESSAGE_TUPLE_FIELD, input, JSONObject.class);    ProfileConfig definition = getField(PROFILE_TUPLE_FIELD, input, ProfileConfig.class);    String entity = getField(ENTITY_TUPLE_FIELD, input, String.class);    Long timestamp = getField(TIMESTAMP_TUPLE_FIELD, input, Long.class);        activeFlushSignal.update(timestamp);        MessageRoute route = new MessageRoute(definition, entity, message, timestamp);    synchronized (messageDistributor) {        messageDistributor.distribute(route, getStellarContext());    }    }
1
private T getField(String fieldName, Tuple tuple, Class<T> clazz)
{    T value = ConversionUtils.convert(tuple.getValueByField(fieldName), clazz);    if (value == null) {        throw new IllegalStateException(format("Invalid tuple: missing or invalid field '%s'", fieldName));    }    return value;}
0
private void startFlushingExpiredProfiles()
{    long initialDelay = profileTimeToLiveMillis;    long period = profileTimeToLiveMillis;    flushExpiredExecutor = Executors.newSingleThreadScheduledExecutor();    flushExpiredExecutor.scheduleAtFixedRate(() -> flushExpired(), initialDelay, period, TimeUnit.MILLISECONDS);}
0
public BaseWindowedBolt withTumblingWindow(BaseWindowedBolt.Duration duration)
{        this.windowDurationMillis = duration.value;    return super.withTumblingWindow(duration);}
0
public long getPeriodDurationMillis()
{    return periodDurationMillis;}
0
public ProfileBuilderBolt withPeriodDurationMillis(long periodDurationMillis)
{    this.periodDurationMillis = periodDurationMillis;    return this;}
0
public ProfileBuilderBolt withPeriodDuration(int duration, TimeUnit units)
{    return withPeriodDurationMillis(units.toMillis(duration));}
0
public ProfileBuilderBolt withProfileTimeToLiveMillis(long timeToLiveMillis)
{    this.profileTimeToLiveMillis = timeToLiveMillis;    return this;}
0
public long getWindowDurationMillis()
{    return windowDurationMillis;}
0
public ProfileBuilderBolt withProfileTimeToLive(int duration, TimeUnit units)
{    return withProfileTimeToLiveMillis(units.toMillis(duration));}
0
public ProfileBuilderBolt withEmitter(ProfileMeasurementEmitter emitter)
{    this.emitters.add(emitter);    return this;}
0
public MessageDistributor getMessageDistributor()
{    return messageDistributor;}
0
public ProfileBuilderBolt withZookeeperUrl(String zookeeperUrl)
{    this.zookeeperUrl = zookeeperUrl;    return this;}
0
public ProfileBuilderBolt withZookeeperClient(CuratorFramework zookeeperClient)
{    this.zookeeperClient = zookeeperClient;    return this;}
0
public ProfileBuilderBolt withZookeeperCache(ZKCache zookeeperCache)
{    this.zookeeperCache = zookeeperCache;    return this;}
0
public ProfileBuilderBolt withProfilerConfigurations(ProfilerConfigurations configurations)
{    this.configurations = configurations;    return this;}
0
public ProfileBuilderBolt withMaxNumberOfRoutes(long maxNumberOfRoutes)
{    this.maxNumberOfRoutes = maxNumberOfRoutes;    return this;}
0
public ProfileBuilderBolt withFlushSignal(FlushSignal flushSignal)
{    this.activeFlushSignal = flushSignal;    return this;}
0
public ProfileBuilderBolt withMessageDistributor(MessageDistributor messageDistributor)
{    this.messageDistributor = messageDistributor;    return this;}
0
public byte[] rowKey(Tuple tuple)
{    ProfileMeasurement measurement = (ProfileMeasurement) tuple.getValueByField("measurement");    return rowKeyBuilder.rowKey(measurement);}
0
public ColumnList columns(Tuple tuple)
{    ProfileMeasurement measurement = (ProfileMeasurement) tuple.getValueByField("measurement");    return columnBuilder.columns(measurement);}
0
public Optional<Long> getTTL(Tuple tuple)
{    Optional<Long> expiresMillis = Optional.empty();    ProfileMeasurement measurement = (ProfileMeasurement) tuple.getValueByField("measurement");    ProfileConfig profileConfig = measurement.getDefinition();    if (profileConfig.getExpires() != null) {                long expiresDays = profileConfig.getExpires();        expiresMillis = Optional.of(TimeUnit.DAYS.toMillis(expiresDays));    }    return expiresMillis;}
0
public void setRowKeyBuilder(RowKeyBuilder rowKeyBuilder)
{    this.rowKeyBuilder = rowKeyBuilder;}
0
public void setColumnBuilder(ColumnBuilder columnBuilder)
{    this.columnBuilder = columnBuilder;}
0
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)
{    super.prepare(stormConf, context, collector);    this.collector = collector;    this.parser = new JSONParser();    this.router = new DefaultMessageRouter(getStellarContext());}
0
public Context getStellarContext()
{    Map<String, Object> global = getConfigurations().getGlobalConfig();    return new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client).with(Context.Capabilities.GLOBAL_CONFIG, () -> global).with(Context.Capabilities.STELLAR_CONFIG, () -> global).build();}
0
private void doExecute(Tuple input) throws ParseException, UnsupportedEncodingException
{        byte[] data = input.getBinaryByField(VALUE.getFieldName());    if (data == null) {                return;    }        ProfilerConfig config = getProfilerConfig();    if (config == null || getProfilerConfig().getProfiles().size() == 0) {                return;    }    JSONObject message = (JSONObject) parser.parse(new String(data, StandardCharsets.UTF_8));    routeMessage(input, message, config);}
1
public void declareOutputFields(OutputFieldsDeclarer declarer)
{        Fields fields = new Fields(MESSAGE_TUPLE_FIELD, TIMESTAMP_TUPLE_FIELD, ENTITY_TUPLE_FIELD, PROFILE_TUPLE_FIELD);    declarer.declare(fields);}
0
private Values createValues(MessageRoute route)
{        return new Values(route.getMessage(), route.getTimestamp(), route.getEntity(), route.getProfileDefinition());}
0
protected MessageRouter getMessageRouter()
{    return router;}
0
public void setRouter(MessageRouter router)
{    this.router = router;}
0
public void setupTuples() throws Exception
{        widget1 = new Widget("widget1", 100);    when(tuple1.getValueByField(eq("widget"))).thenReturn(widget1);        widget2 = new Widget("widget2", 200);    when(tuple2.getValueByField(eq("widget"))).thenReturn(widget2);}
0
public void setup() throws Exception
{    tuple1 = mock(Tuple.class);    tuple2 = mock(Tuple.class);    client = mock(HBaseClient.class);    provider = mock(TableProvider.class);}
0
private HBaseBolt createBolt(int batchSize, WidgetMapper mapper) throws IOException
{    HBaseBolt bolt = new HBaseBolt(tableName, mapper).withBatchSize(batchSize).withTableProviderInstance(provider);    bolt.prepare(Collections.emptyMap(), topologyContext, outputCollector);    bolt.setClient(client);    return bolt;}
0
public void testBatchReady() throws Exception
{    HBaseBolt bolt = createBolt(2, new WidgetMapper());    bolt.execute(tuple1);    bolt.execute(tuple2);        verify(client, times(2)).addMutation(any(), any(), any());    verify(client, times(1)).mutate();}
0
public void testBatchNotReady() throws Exception
{    HBaseBolt bolt = createBolt(2, new WidgetMapper());    bolt.execute(tuple1);        verify(client, times(1)).addMutation(any(), any(), any());    verify(client, times(0)).mutate();}
0
public void testTimeFlush() throws Exception
{    HBaseBolt bolt = createBolt(2, new WidgetMapper());        bolt.execute(tuple1);    verify(client, times(1)).addMutation(any(), any(), any());    verify(client, times(0)).mutate();        bolt.execute(mockTickTuple());    verify(client, times(1)).mutate();}
0
public void testWriteWithTTL() throws Exception
{        final Long expectedTTL = 2000L;    WidgetMapper mapperWithTTL = new WidgetMapper(expectedTTL);        HBaseBolt bolt = createBolt(2, mapperWithTTL);    bolt.execute(tuple1);    bolt.execute(tuple2);        ArgumentCaptor<Long> ttlCaptor = ArgumentCaptor.forClass(Long.class);        verify(client, times(2)).addMutation(any(), any(), any(), ttlCaptor.capture());    Assert.assertEquals(expectedTTL, ttlCaptor.getValue());}
0
private static Tuple mockTuple(String componentId, String streamId)
{    Tuple tuple = mock(Tuple.class);    when(tuple.getSourceComponent()).thenReturn(componentId);    when(tuple.getSourceStreamId()).thenReturn(streamId);    return tuple;}
0
private static Tuple mockTickTuple()
{    return mockTuple(Constants.SYSTEM_COMPONENT_ID, Constants.SYSTEM_TICK_STREAM_ID);}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public int getCost()
{    return cost;}
0
public void setCost(int cost)
{    this.cost = cost;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Widget widget = (Widget) o;    if (cost != widget.cost)        return false;    return name != null ? name.equals(widget.name) : widget.name == null;}
0
public int hashCode()
{    int result = name != null ? name.hashCode() : 0;    result = 31 * result + cost;    return result;}
0
public String toString()
{    return "Widget{" + "name='" + name + '\'' + ", cost=" + cost + '}';}
0
public byte[] rowKey(Tuple tuple)
{    Widget w = (Widget) tuple.getValueByField("widget");    return Bytes.toBytes(w.getName());}
0
public ColumnList columns(Tuple tuple)
{    Widget w = (Widget) tuple.getValueByField("widget");    ColumnList cols = new ColumnList();    cols.addColumn(CF, QNAME, Bytes.toBytes(w.getName()));    cols.addColumn(CF, QCOST, Bytes.toBytes(w.getCost()));    return cols;}
0
public Optional<Long> getTTL(Tuple tuple)
{    return ttl;}
0
public void testSignalFlush()
{    int flushFreq = 1000;    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(flushFreq);        assertFalse(signal.isTimeToFlush());        signal.update(5000);    assertFalse(signal.isTimeToFlush());        signal.update(7000);    assertTrue(signal.isTimeToFlush());}
0
public void testOutOfOrderTimestamps()
{    int flushFreq = 5000;    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(flushFreq);        signal.update(5000);    assertFalse(signal.isTimeToFlush());        signal.update(1000);    assertFalse(signal.isTimeToFlush());        signal.update(7000);    assertTrue(signal.isTimeToFlush());        signal.update(3000);    assertTrue(signal.isTimeToFlush());        assertTrue(signal.isTimeToFlush());}
0
public void testOutOfOrderTimestampsNoFlush()
{    int flushFreq = 7000;    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(flushFreq);        signal.update(5000);    assertFalse(signal.isTimeToFlush());        signal.update(1000);    assertFalse(signal.isTimeToFlush());        signal.update(7000);    assertFalse(signal.isTimeToFlush());        signal.update(3000);    assertFalse(signal.isTimeToFlush());}
0
public void testTimestampsDescending()
{    int flushFreq = 3000;    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(flushFreq);        signal.update(4100);    assertFalse(signal.isTimeToFlush());        signal.update(3000);    assertFalse(signal.isTimeToFlush());        signal.update(2000);    assertFalse(signal.isTimeToFlush());        signal.update(1000);    assertTrue(signal.isTimeToFlush());}
0
public void testTimestampsDescendingNoFlush()
{    int flushFreq = 4000;    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(flushFreq);        signal.update(4000);    assertFalse(signal.isTimeToFlush());        signal.update(3000);    assertFalse(signal.isTimeToFlush());        signal.update(2000);    assertFalse(signal.isTimeToFlush());        signal.update(1000);    assertFalse(signal.isTimeToFlush());}
0
public void testTimestampsAscending()
{    int flushFreq = 3000;    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(flushFreq);        signal.update(1000);    assertFalse(signal.isTimeToFlush());        signal.update(2000);    assertFalse(signal.isTimeToFlush());        signal.update(3000);    assertFalse(signal.isTimeToFlush());        signal.update(4000);}
0
public void testTimestampsAscendingNoFlush()
{    int flushFreq = 4000;    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(flushFreq);        signal.update(1000);    assertFalse(signal.isTimeToFlush());        signal.update(2000);    assertFalse(signal.isTimeToFlush());        signal.update(3000);    assertFalse(signal.isTimeToFlush());        signal.update(4000);    assertFalse(signal.isTimeToFlush());}
0
public void testNegativeFrequency()
{        new FixedFrequencyFlushSignal(-1000);}
0
public void testReset()
{    FixedFrequencyFlushSignal signal = new FixedFrequencyFlushSignal(4000);    signal.update(1000);    signal.update(6000);        assertTrue(signal.isTimeToFlush());        signal.reset();    assertFalse(signal.isTimeToFlush());}
0
public void setup() throws Exception
{    emitter = new HBaseEmitter();    profile = createDefinition(profileDefinition);    collector = Mockito.mock(OutputCollector.class);}
0
public void testEmit() throws Exception
{        ProfileMeasurement measurement = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withDefinition(profile).withProfileValue(22);        emitter.emit(measurement, collector);        ProfileMeasurement actual = expectMeasurement(emitter, collector);    assertEquals(measurement, actual);}
0
private ProfileMeasurement expectMeasurement(HBaseEmitter hbaseEmitter, OutputCollector collector)
{    ArgumentCaptor<Values> arg = ArgumentCaptor.forClass(Values.class);    verify(collector, times(1)).emit(eq(hbaseEmitter.getStreamId()), arg.capture());    Values values = arg.getValue();    assertTrue(values.get(0) instanceof ProfileMeasurement);    return (ProfileMeasurement) values.get(0);}
0
private ProfileConfig createDefinition(String json) throws IOException
{    return JSONUtils.INSTANCE.load(json, ProfileConfig.class);}
0
public void start() throws UnableToStartException
{    try {        upload();    } catch (Exception e) {        throw new UnableToStartException(e.getMessage(), e);    }}
0
public void stop()
{}
0
public void update() throws UnableToStartException
{    try {        upload();    } catch (Exception e) {        throw new UnableToStartException(e.getMessage(), e);    }}
0
private void upload() throws Exception
{    final String zookeeperUrl = topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY);    try (CuratorFramework client = getClient(zookeeperUrl)) {        if (client.getState() != CuratorFrameworkState.STARTED) {            client.start();        }        uploadGlobalConfig(client);        uploadProfilerConfig(client);    }}
0
private void uploadProfilerConfig(CuratorFramework client) throws Exception
{    byte[] configBytes = null;    if (profilerConfigurationPath != null) {        configBytes = readProfilerConfigFromFile(profilerConfigurationPath);    } else if (profilerConfig != null) {        configBytes = profilerConfig.toJSON().getBytes(StandardCharsets.UTF_8);    }    if (ArrayUtils.getLength(configBytes) > 0) {        writeProfilerConfigToZookeeper(configBytes, client);    }}
0
private void uploadGlobalConfig(CuratorFramework client) throws Exception
{    if (globalConfiguration != null) {        byte[] globalConfig = readGlobalConfigFromFile(globalConfiguration);        if (globalConfig.length > 0) {            writeGlobalConfigToZookeeper(readGlobalConfigFromFile(globalConfiguration), client);        }    }}
0
public ConfigUploadComponent withTopologyProperties(Properties topologyProperties)
{    this.topologyProperties = topologyProperties;    return this;}
0
public ConfigUploadComponent withGlobalConfiguration(String path)
{    this.globalConfiguration = path;    return this;}
0
public ConfigUploadComponent withProfilerConfigurationPath(String path)
{    this.profilerConfigurationPath = path;    return this;}
0
public ConfigUploadComponent withProfilerConfiguration(ProfilerConfig profilerConfig)
{    this.profilerConfig = profilerConfig;    return this;}
0
public MessageBuilder withFields(JSONObject prototype)
{    prototype.forEach((key, val) -> this.fields.put(key, val));    return this;}
0
public MessageBuilder withField(String key, Object value)
{    this.fields.put(key, value);    return this;}
0
public JSONObject build()
{    return new JSONObject(fields);}
0
public void testProcessingTime() throws Exception
{    uploadConfigToZookeeper(ProfilerConfig.fromJSON(processingTimeProfile));        fluxComponent.submitTopology();    kafkaComponent.writeMessages(inputTopic, message1);    kafkaComponent.writeMessages(inputTopic, message2);    kafkaComponent.writeMessages(inputTopic, message3);        String profileGetExpression = "PROFILE_GET('processing-time-test', '10.0.0.1', PROFILE_FIXED('15', 'MINUTES'))";    List<Integer> measurements = execute(profileGetExpression, List.class);        int attempt = 0;    while (measurements.size() == 0 && attempt++ < 10) {                long sleep = windowDurationMillis;                Thread.sleep(sleep);                                kafkaComponent.writeMessages(inputTopic, message2);                measurements = execute(profileGetExpression, List.class);    }            assertTrue(measurements.size() > 0);            assertTrue(measurements.get(0) >= 3);}
1
public void testProcessingTimeWithTimeToLiveFlush() throws Exception
{    uploadConfigToZookeeper(ProfilerConfig.fromJSON(processingTimeProfile));        fluxComponent.submitTopology();    kafkaComponent.writeMessages(inputTopic, message1);    kafkaComponent.writeMessages(inputTopic, message2);    kafkaComponent.writeMessages(inputTopic, message3);            long sleep = windowLagMillis + periodDurationMillis;        Thread.sleep(sleep);    kafkaComponent.writeMessages(inputTopic, message3);        assertEventually(() -> {        List<Integer> results = execute("PROFILE_GET('processing-time-test', '10.0.0.1', PROFILE_FIXED('15', 'MINUTES'))", List.class);        assertThat(results, hasItem(3));    }, timeout);}
1
public void testEventTime() throws Exception
{    uploadConfigToZookeeper(ProfilerConfig.fromJSON(eventTimeProfile));        fluxComponent.submitTopology();    List<String> messages = FileUtils.readLines(new File("src/test/resources/telemetry.json"));    kafkaComponent.writeMessages(inputTopic, messages);    long timestamp = System.currentTimeMillis();        kafkaComponent.writeMessages(inputTopic, getMessage("192.168.66.1", timestamp));    kafkaComponent.writeMessages(inputTopic, getMessage("192.168.138.158", timestamp));        assign("maxTimestamp", "1530978728982L");    assign("window", "PROFILE_WINDOW('from 5 hours ago', maxTimestamp)");                    assertEventually(() -> {        List<Integer> results = execute("PROFILE_GET('count-by-ip', '192.168.66.1', window)", List.class);        assertThat(results, hasItems(14, 12));    }, timeout);        assertEventually(() -> {        List<Integer> results = execute("PROFILE_GET('count-by-ip', '192.168.138.158', window)", List.class);        assertThat(results, hasItems(36, 38));    }, timeout);        assertEventually(() -> {        List<Integer> results = execute("PROFILE_GET('total-count', 'total', window)", List.class);        assertThat(results, hasItems(50, 50));    }, timeout);}
1
public void testProfileWithStatsObject() throws Exception
{    uploadConfigToZookeeper(ProfilerConfig.fromJSON(profileWithStats));        fluxComponent.submitTopology();    List<String> messages = FileUtils.readLines(new File("src/test/resources/telemetry.json"));    kafkaComponent.writeMessages(inputTopic, messages);    assertEventually(() -> {                        assign("maxTimestamp", "1530978728982L");        assign("window", "PROFILE_WINDOW('from 5 hours ago', maxTimestamp)");                List results = execute("PROFILE_GET('profile-with-stats', 'global', window)", List.class);        assertTrue(results.size() > 0);        assertTrue(results.get(0) instanceof OnlineStatisticsProvider);    }, timeout);}
0
public void testProfileWithTriageResult() throws Exception
{    uploadConfigToZookeeper(ProfilerConfig.fromJSON(profileWithTriageResult));        fluxComponent.submitTopology();    List<String> telemetry = FileUtils.readLines(new File("src/test/resources/telemetry.json"));    kafkaComponent.writeMessages(inputTopic, telemetry);        assertEventually(() -> {        outputMessages = kafkaComponent.readMessages(outputTopic);        assertEquals(1, outputMessages.size());    }, timeout);        JSONObject message = (JSONObject) new JSONParser().parse(new String(outputMessages.get(0), StandardCharsets.UTF_8));    assertEquals("profile-with-triage", message.get(PROFILE_FIELD));    assertEquals("global", message.get(ENTITY_FIELD));    assertEquals(76548935L, message.get(PERIOD_ID_FIELD));    assertEquals(1530978700000L, message.get(PERIOD_START_FIELD));    assertEquals(1530978720000L, message.get(PERIOD_END_FIELD));    assertEquals("profiler", message.get(Constants.SENSOR_TYPE));    assertEquals("true", message.get(ALERT_FIELD));    assertEquals(1.0, message.get("min"));    assertEquals(1.0, message.get("max"));    assertEquals(1.0, message.get("mean"));    assertTrue(message.containsKey(TIMESTAMP_FIELD));    assertTrue(message.containsKey(Constants.GUID));}
0
private static String getMessage(String ipSource, long timestamp)
{    return new MessageBuilder().withField("ip_src_addr", ipSource).withField("timestamp", timestamp).build().toJSONString();}
0
public static void setupBeforeClass() throws UnableToStartException
{        message1 = getMessage(entity, startAt);    message2 = getMessage(entity, startAt + 100);    message3 = getMessage(entity, startAt + (windowDurationMillis * 2));        final Properties topologyProperties = new Properties() {        {                        setProperty("profiler.workers", "1");            setProperty("profiler.executors", "0");            setProperty(Config.TOPOLOGY_AUTO_CREDENTIALS, "[]");            setProperty(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, "60");            setProperty(Config.TOPOLOGY_MAX_SPOUT_PENDING, "100000");                                    setProperty(Config.TOPOLOGY_TESTING_ALWAYS_TRY_SERIALIZE, "true");            setProperty(Config.TOPOLOGY_FALL_BACK_ON_JAVA_SERIALIZATION, "false");            setProperty(Config.TOPOLOGY_KRYO_REGISTER, kryoSerializers);                        setProperty("profiler.input.topic", inputTopic);            setProperty("profiler.output.topic", outputTopic);            setProperty("kafka.start", "EARLIEST");            setProperty("kafka.security.protocol", "PLAINTEXT");                        setProperty("profiler.hbase.salt.divisor", Integer.toString(saltDivisor));            setProperty("profiler.hbase.table", tableName);            setProperty("profiler.hbase.column.family", columnFamily);            setProperty("profiler.hbase.batch", "10");            setProperty("profiler.hbase.flush.interval.seconds", "1");            setProperty("hbase.provider.impl", "" + MockHBaseTableProvider.class.getName());                        setProperty("profiler.period.duration", Long.toString(periodDurationMillis));            setProperty("profiler.period.duration.units", "MILLISECONDS");            setProperty("profiler.ttl", Long.toString(profileTimeToLiveMillis));            setProperty("profiler.ttl.units", "MILLISECONDS");            setProperty("profiler.window.duration", Long.toString(windowDurationMillis));            setProperty("profiler.window.duration.units", "MILLISECONDS");            setProperty("profiler.window.lag", Long.toString(windowLagMillis));            setProperty("profiler.window.lag.units", "MILLISECONDS");            setProperty("profiler.max.routes.per.bolt", Long.toString(maxRoutesPerBolt));        }    };        profilerTable = (MockHTable) MockHBaseTableProvider.addToCache(tableName, columnFamily);    zkComponent = getZKServerComponent(topologyProperties);        kafkaComponent = getKafkaComponent(topologyProperties, Arrays.asList(new KafkaComponent.Topic(inputTopic, 1), new KafkaComponent.Topic(outputTopic, 1)));        configUploadComponent = new ConfigUploadComponent().withTopologyProperties(topologyProperties);        fluxComponent = new FluxTopologyComponent.Builder().withTopologyLocation(new File(FLUX_PATH)).withTopologyName("profiler").withTopologyProperties(topologyProperties).build();        runner = new ComponentRunner.Builder().withComponent("zk", zkComponent).withComponent("kafka", kafkaComponent).withComponent("config", configUploadComponent).withComponent("storm", fluxComponent).withMillisecondsBetweenAttempts(15000).withNumRetries(10).withCustomShutdownOrder(new String[] { "storm", "config", "kafka", "zk" }).build();    runner.start();}
0
public static void tearDownAfterClass() throws Exception
{    MockHBaseTableProvider.clear();    if (runner != null) {        runner.stop();    }}
0
public void setup()
{        profilerTable = (MockHTable) MockHBaseTableProvider.addToCache(tableName, columnFamily);        Map<String, Object> global = new HashMap<String, Object>() {        {            put(PROFILER_HBASE_TABLE.getKey(), tableName);            put(PROFILER_COLUMN_FAMILY.getKey(), columnFamily);            put(PROFILER_HBASE_TABLE_PROVIDER.getKey(), MockHBaseTableProvider.class.getName());                        put(PROFILER_PERIOD.getKey(), Long.toString(periodDurationMillis));            put(PROFILER_PERIOD_UNITS.getKey(), "MILLISECONDS");                        put(PROFILER_SALT_DIVISOR.getKey(), saltDivisor);        }    };        executor = new DefaultStellarStatefulExecutor(new SimpleFunctionResolver().withClass(GetProfile.class).withClass(FixedLookback.class).withClass(WindowLookback.class), new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> global).build());}
0
public void tearDown() throws Exception
{    MockHBaseTableProvider.clear();    profilerTable.clear();    if (runner != null) {        runner.reset();    }}
0
public void uploadConfigToZookeeper(ProfilerConfig profilerConfig) throws Exception
{    configUploadComponent.withProfilerConfiguration(profilerConfig).update();}
0
private void assign(String var, String expression)
{    executor.assign(var, expression, Collections.emptyMap());}
0
private T execute(String expression, Class<T> clazz)
{    T results = executor.execute(expression, Collections.emptyMap(), clazz);        return results;}
1
public void setup() throws Exception
{    kafkaEmitter = new KafkaEmitter();    profile = createDefinition(profileDefinitionWithTriage);    collector = Mockito.mock(OutputCollector.class);}
0
public void testEmit() throws Exception
{        ProfileMeasurement measurement = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withDefinition(profile).withTriageValues(Collections.singletonMap("triage-key", "triage-value"));        kafkaEmitter.emit(measurement, collector);        verify(collector, times(1)).emit(eq(kafkaEmitter.getStreamId()), any());}
0
public void testDoNotEmit() throws Exception
{        ProfileMeasurement measurement = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withDefinition(profile);        kafkaEmitter.emit(measurement, collector);        verify(collector, times(0)).emit(eq(kafkaEmitter.getStreamId()), any());}
0
public void testTriageValueInMessage() throws Exception
{        ProfileMeasurement measurement = new ProfileMeasurement().withDefinition(profile).withProfileName(profile.getProfile()).withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withTriageValues(Collections.singletonMap("triage-key", "triage-value"));        kafkaEmitter.emit(measurement, collector);    JSONObject actual = expectJsonObject(kafkaEmitter, collector);        assertEquals(measurement.getProfileName(), actual.get("profile"));    assertEquals(measurement.getEntity(), actual.get("entity"));    assertEquals(measurement.getPeriod().getPeriod(), actual.get("period"));    assertEquals(measurement.getPeriod().getStartTimeMillis(), actual.get("period.start"));    assertEquals(measurement.getPeriod().getEndTimeMillis(), actual.get("period.end"));    assertEquals("profiler", actual.get("source.type"));    assertNotNull(actual.get("timestamp"));    assertNotNull(actual.get(Constants.GUID));        assertEquals(measurement.getTriageValues().get("triage-key"), actual.get("triage-key"));}
0
public void testMultipleTriageValueInMessage() throws Exception
{        Map<String, Object> triageValues = ImmutableMap.of("x", 2, "y", "4", "z", 6.0);        ProfileMeasurement measurement = new ProfileMeasurement().withDefinition(profile).withProfileName(profile.getProfile()).withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withTriageValues(triageValues);        kafkaEmitter.emit(measurement, collector);    JSONObject actual = expectJsonObject(kafkaEmitter, collector);        assertEquals(measurement.getTriageValues().get("x"), actual.get("x"));    assertEquals(measurement.getTriageValues().get("y"), actual.get("y"));    assertEquals(measurement.getTriageValues().get("z"), actual.get("z"));}
0
public void testInvalidType() throws Exception
{        Map<String, Object> triageValues = ImmutableMap.of("invalid", new OnlineStatisticsProvider(), "valid", 4);        ProfileMeasurement measurement = new ProfileMeasurement().withDefinition(profile).withProfileName(profile.getProfile()).withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withTriageValues(triageValues);        kafkaEmitter.emit(measurement, collector);    JSONObject actual = expectJsonObject(kafkaEmitter, collector);        assertEquals(measurement.getProfileName(), actual.get("profile"));    assertEquals(measurement.getEntity(), actual.get("entity"));    assertEquals(measurement.getPeriod().getPeriod(), actual.get("period"));    assertEquals(measurement.getPeriod().getStartTimeMillis(), actual.get("period.start"));    assertEquals(measurement.getPeriod().getEndTimeMillis(), actual.get("period.end"));    assertEquals("profiler", actual.get("source.type"));    assertNotNull(actual.get("timestamp"));    assertNotNull(actual.get(Constants.GUID));        assertFalse(actual.containsKey("invalid"));        assertEquals(triageValues.get("valid"), actual.get("valid"));}
0
public void testIntegerIsValidType() throws Exception
{        ProfileMeasurement measurement = new ProfileMeasurement().withDefinition(profile).withProfileName(profile.getProfile()).withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withTriageValues(Collections.singletonMap("triage-key", 123));        kafkaEmitter.emit(measurement, collector);    JSONObject actual = expectJsonObject(kafkaEmitter, collector);        assertEquals(measurement.getTriageValues().get("triage-key"), actual.get("triage-key"));}
0
public void testStringIsValidType() throws Exception
{        ProfileMeasurement measurement = new ProfileMeasurement().withDefinition(profile).withProfileName(profile.getProfile()).withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withTriageValues(Collections.singletonMap("triage-key", "value"));        kafkaEmitter.emit(measurement, collector);    JSONObject actual = expectJsonObject(kafkaEmitter, collector);        assertEquals(measurement.getTriageValues().get("triage-key"), actual.get("triage-key"));}
0
private JSONObject expectJsonObject(KafkaEmitter kafkaEmitter, OutputCollector collector)
{    ArgumentCaptor<Values> arg = ArgumentCaptor.forClass(Values.class);    verify(collector, times(1)).emit(eq(kafkaEmitter.getStreamId()), arg.capture());    Values values = arg.getValue();    assertTrue(values.get(0) instanceof JSONObject);    return (JSONObject) values.get(0);}
0
private ProfileConfig createDefinition(String json) throws IOException
{    return JSONUtils.INSTANCE.load(json, ProfileConfig.class);}
0
public void setup() throws Exception
{    message1 = new MessageBuilder().withField("ip_src_addr", "10.0.0.1").withField("value", "22").build();    message2 = new MessageBuilder().withField("ip_src_addr", "10.0.0.2").withField("value", "22").build();    profile1 = new ProfileConfig().withProfile("profile1").withForeach("ip_src_addr").withInit("x", "0").withUpdate("x", "x + 1").withResult("x");    profile2 = new ProfileConfig().withProfile("profile2").withForeach("ip_src_addr").withInit(Collections.singletonMap("x", "0")).withUpdate(Collections.singletonMap("x", "x + 1")).withResult("x");    measurement = new ProfileMeasurement().withEntity("entity1").withProfileName("profile1").withPeriod(1000, 500, TimeUnit.MILLISECONDS).withProfileValue(22);    flushSignal = new ManualFlushSignal();    flushSignal.setFlushNow(false);}
0
public void testExtractMessage() throws Exception
{    ProfileBuilderBolt bolt = createBolt();        MessageDistributor distributor = mock(MessageDistributor.class);    bolt.withMessageDistributor(distributor);        final long timestamp1 = 100000000L;    Tuple tuple1 = createTuple("entity1", message1, profile1, timestamp1);        TupleWindow tupleWindow = createWindow(tuple1);    bolt.execute(tupleWindow);        verify(distributor).distribute(any(MessageRoute.class), any());}
0
public void testFlushActiveProfiles() throws Exception
{    ProfileBuilderBolt bolt = createBolt();        MessageDistributor distributor = mock(MessageDistributor.class);    when(distributor.flush()).thenReturn(Collections.singletonList(measurement));    bolt.withMessageDistributor(distributor);        flushSignal.setFlushNow(true);        Tuple tuple1 = createTuple("entity1", message1, profile1, 1000L);    TupleWindow tupleWindow = createWindow(tuple1);    bolt.execute(tupleWindow);        List<ProfileMeasurement> measurements = getProfileMeasurements(outputCollector, 1);    assertEquals(1, measurements.size());    assertEquals(measurement, measurements.get(0));}
0
public void testDoNotFlushActiveProfiles() throws Exception
{    ProfileBuilderBolt bolt = createBolt();        MessageDistributor distributor = mock(MessageDistributor.class);    when(distributor.flush()).thenReturn(Collections.singletonList(measurement));    bolt.withMessageDistributor(distributor);        flushSignal.setFlushNow(false);        Tuple tuple1 = createTuple("entity1", message1, profile1, 1000L);    TupleWindow tupleWindow = createWindow(tuple1);    bolt.execute(tupleWindow);        getProfileMeasurements(outputCollector, 0);}
0
public void testFlushExpiredProfiles() throws Exception
{    ProfileBuilderBolt bolt = createBolt();        MessageDistributor distributor = mock(MessageDistributor.class);    when(distributor.flushExpired()).thenReturn(Collections.singletonList(measurement));    bolt.withMessageDistributor(distributor);        bolt.flushExpired();        List<ProfileMeasurement> measurements = getProfileMeasurements(outputCollector, 1);    assertEquals(1, measurements.size());    assertEquals(measurement, measurements.get(0));}
0
public void testEmitters() throws Exception
{        ProfilerConfigurations configurations = new ProfilerConfigurations();    configurations.updateGlobalConfig(Collections.emptyMap());        ProfileBuilderBolt bolt = (ProfileBuilderBolt) new ProfileBuilderBolt().withProfileTimeToLive(30, TimeUnit.MINUTES).withPeriodDuration(10, TimeUnit.MINUTES).withMaxNumberOfRoutes(Long.MAX_VALUE).withZookeeperClient(client).withZookeeperCache(cache).withEmitter(new TestEmitter("destination1")).withEmitter(new TestEmitter("destination2")).withEmitter(new TestEmitter("destination3")).withProfilerConfigurations(configurations).withTumblingWindow(new BaseWindowedBolt.Duration(10, TimeUnit.MINUTES));    bolt.prepare(new HashMap<>(), topologyContext, outputCollector);        bolt.withFlushSignal(flushSignal);    flushSignal.setFlushNow(true);        Tuple tuple1 = createTuple("entity", message1, profile1, System.currentTimeMillis());    TupleWindow window = createWindow(tuple1);    bolt.execute(window);        verify(outputCollector, times(1)).emit(eq("destination1"), any());    verify(outputCollector, times(1)).emit(eq("destination2"), any());    verify(outputCollector, times(1)).emit(eq("destination3"), any());}
0
public void testExceptionWhenFlushingExpiredProfiles() throws Exception
{        ProfileMeasurementEmitter badEmitter = mock(ProfileMeasurementEmitter.class);    doThrow(new RuntimeException("flushExpired() should catch this exception")).when(badEmitter).emit(any(), any());        MessageDistributor distributor = mock(MessageDistributor.class);    when(distributor.flushExpired()).thenReturn(Collections.singletonList(measurement));        ProfileBuilderBolt bolt = (ProfileBuilderBolt) new ProfileBuilderBolt().withEmitter(badEmitter).withMessageDistributor(distributor);        bolt.flushExpired();}
0
private List<ProfileMeasurement> getProfileMeasurements(OutputCollector collector, int expected)
{        final String streamId = emitter.getStreamId();        ArgumentCaptor<Values> argCaptor = ArgumentCaptor.forClass(Values.class);    verify(collector, times(expected)).emit(eq(streamId), argCaptor.capture());        return argCaptor.getAllValues().stream().map(val -> (ProfileMeasurement) val.get(0)).collect(Collectors.toList());}
0
private Tuple createTuple(String entity, JSONObject message, ProfileConfig profile, long timestamp)
{    Tuple tuple = mock(Tuple.class);    when(tuple.getValueByField(eq(ProfileSplitterBolt.MESSAGE_TUPLE_FIELD))).thenReturn(message);    when(tuple.getValueByField(eq(ProfileSplitterBolt.TIMESTAMP_TUPLE_FIELD))).thenReturn(timestamp);    when(tuple.getValueByField(eq(ProfileSplitterBolt.ENTITY_TUPLE_FIELD))).thenReturn(entity);    when(tuple.getValueByField(eq(ProfileSplitterBolt.PROFILE_TUPLE_FIELD))).thenReturn(profile);    return tuple;}
0
private ProfileBuilderBolt createBolt() throws IOException
{        ProfilerConfigurations configurations = new ProfilerConfigurations();    configurations.updateGlobalConfig(Collections.emptyMap());    emitter = new HBaseEmitter();    ProfileBuilderBolt bolt = (ProfileBuilderBolt) new ProfileBuilderBolt().withProfileTimeToLive(30, TimeUnit.MINUTES).withMaxNumberOfRoutes(Long.MAX_VALUE).withZookeeperClient(client).withZookeeperCache(cache).withEmitter(emitter).withProfilerConfigurations(configurations).withPeriodDuration(1, TimeUnit.MINUTES).withTumblingWindow(new BaseWindowedBolt.Duration(30, TimeUnit.SECONDS));    bolt.prepare(new HashMap<>(), topologyContext, outputCollector);        bolt.withFlushSignal(flushSignal);    return bolt;}
0
private TupleWindow createWindow(Tuple... tuples)
{    TupleWindow window = mock(TupleWindow.class);    when(window.get()).thenReturn(Arrays.asList(tuples));    return window;}
0
public String getStreamId()
{    return streamId;}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    declarer.declareStream(getStreamId(), new Fields("measurement"));}
0
public void emit(ProfileMeasurement measurement, OutputCollector collector)
{    collector.emit(getStreamId(), new Values(measurement));}
0
public void setup()
{    rowKeyBuilder = mock(RowKeyBuilder.class);    mapper = new ProfileHBaseMapper();    mapper.setRowKeyBuilder(rowKeyBuilder);    profile = new ProfileConfig("profile", "ip_src_addr", new ProfileResult("2 + 2"));    measurement = new ProfileMeasurement().withProfileName("profile").withEntity("entity").withPeriod(20000, 15, TimeUnit.MINUTES).withProfileValue(22).withDefinition(profile);        tuple = mock(Tuple.class);    when(tuple.getValueByField(eq("measurement"))).thenReturn(measurement);}
0
public void testExpires() throws Exception
{    final Long expiresDays = 30L;    profile.setExpires(expiresDays);    Optional<Long> actual = mapper.getTTL(tuple);    Assert.assertTrue(actual.isPresent());    Assert.assertEquals(expiresDays, (Long) TimeUnit.MILLISECONDS.toDays(actual.get()));}
0
public void testExpiresUndefined() throws Exception
{        Optional<Long> actual = mapper.getTTL(tuple);    Assert.assertFalse(actual.isPresent());}
0
public void setup() throws ParseException
{        JSONParser parser = new JSONParser();    message = (JSONObject) parser.parse(input);        when(tuple.getBinaryByField(VALUE.getFieldName())).thenReturn(input.getBytes(StandardCharsets.UTF_8));}
0
public void testEmitTupleWithOneProfile() throws Exception
{        ProfilerConfig config = toProfilerConfig(profileWithOnlyIfTrue);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        String expectedEntity = "10.0.0.1";    ProfileConfig expectedConfig = config.getProfiles().get(0);    Values expected = new Values(message, timestamp, expectedEntity, expectedConfig);        verify(outputCollector, times(1)).emit(eq(tuple), eq(expected));        verify(outputCollector, times(1)).ack(eq(tuple));}
0
public void testEmitTupleWithTwoProfiles() throws Exception
{        ProfilerConfig config = toProfilerConfig(twoProfilesDefined);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        final String expectedEntity = "global";    {                ProfileConfig profile1 = config.getProfiles().get(0);        Values expected = new Values(message, timestamp, expectedEntity, profile1);        verify(outputCollector, times(1)).emit(eq(tuple), eq(expected));    }    {                ProfileConfig profile2 = config.getProfiles().get(1);        Values expected = new Values(message, timestamp, expectedEntity, profile2);        verify(outputCollector, times(1)).emit(eq(tuple), eq(expected));    }        verify(outputCollector, times(1)).ack(eq(tuple));}
0
public void testNoProfilesDefined() throws Exception
{        ProfilerConfig config = toProfilerConfig(noProfilesDefined);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        verify(outputCollector, times(0)).emit(any(Tuple.class), any());        verify(outputCollector, times(1)).ack(eq(tuple));}
0
public void testOnlyIfTrue() throws Exception
{    ProfilerConfig config = toProfilerConfig(profileWithOnlyIfTrue);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        verify(outputCollector, times(1)).emit(eq(tuple), any(Values.class));        verify(outputCollector, times(1)).ack(eq(tuple));}
0
public void testOnlyIfMissing() throws Exception
{    ProfilerConfig config = toProfilerConfig(profileWithOnlyIfMissing);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        verify(outputCollector, times(1)).emit(eq(tuple), any(Values.class));        verify(outputCollector, times(1)).ack(eq(tuple));}
0
public void testOnlyIfFalse() throws Exception
{    ProfilerConfig config = toProfilerConfig(profileWithOnlyIfFalse);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        verify(outputCollector, times(0)).emit(any());        verify(outputCollector, times(1)).ack(eq(tuple));}
0
public void testResolveEntityName() throws Exception
{    ProfilerConfig config = toProfilerConfig(profileWithOnlyIfTrue);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        String expectedEntity = "10.0.0.1";    ProfileConfig expectedConfig = config.getProfiles().get(0);    Values expected = new Values(message, timestamp, expectedEntity, expectedConfig);        verify(outputCollector, times(1)).emit(eq(tuple), eq(expected));        verify(outputCollector, times(1)).ack(eq(tuple));}
0
public void testOnlyIfInvalid() throws Exception
{    ProfilerConfig config = toProfilerConfig(profileWithOnlyIfInvalid);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        verify(outputCollector, times(0)).emit(any(Values.class));}
0
public void testWithNullMessage() throws Exception
{        when(tuple.getBinary(0)).thenReturn(null);    ProfilerConfig config = toProfilerConfig(profileWithOnlyIfInvalid);    ProfileSplitterBolt bolt = createBolt(config);    bolt.execute(tuple);        verify(outputCollector, times(0)).emit(any(Values.class));}
0
private ProfilerConfig toProfilerConfig(String configAsJSON) throws Exception
{    InputStream in = new ByteArrayInputStream(configAsJSON.getBytes(StandardCharsets.UTF_8));    return JSONUtils.INSTANCE.load(in, ProfilerConfig.class);}
0
private ProfileSplitterBolt createBolt(ProfilerConfig config) throws Exception
{    ProfileSplitterBolt bolt = new ProfileSplitterBolt("zookeeperURL");    bolt.setCuratorFramework(client);    bolt.setZKCache(cache);    bolt.getConfigurations().updateProfilerConfig(config);    bolt.prepare(new HashMap<>(), topologyContext, outputCollector);        DefaultMessageRouter router = new DefaultMessageRouter(bolt.getStellarContext());    router.setClockFactory(new FixedClockFactory(timestamp));    bolt.setRouter(router);    return bolt;}
0
public static void main(String[] args)
{    Options options = new Options();    try {        CommandLineParser parser = new PosixParser();        CommandLine cmd = null;        try {            cmd = ParserOptions.parse(parser, args);        } catch (ParseException pe) {            pe.printStackTrace();            final HelpFormatter usageFormatter = new HelpFormatter();            usageFormatter.printHelp("HLLPMeasurement", null, options, null, true);            System.exit(-1);        }        if (cmd.hasOption("h")) {            final HelpFormatter usageFormatter = new HelpFormatter();            usageFormatter.printHelp("HLLPMeasurement", null, options, null, true);            System.exit(0);        }        final String chartDelim = ParserOptions.CHART_DELIM.get(cmd, "|");        final int numTrials = Integer.parseInt(ParserOptions.NUM_TRIALS.get(cmd, "5000"));        final int cardMin = Integer.parseInt(ParserOptions.CARD_MIN.get(cmd, "200"));        final int cardMax = Integer.parseInt(ParserOptions.CARD_MAX.get(cmd, "1000"));        final int cardStep = Integer.parseInt(ParserOptions.CARD_STEP.get(cmd, "200"));        final int cardStart = (((cardMin - 1) / cardStep) * cardStep) + cardStep;        final int spMin = Integer.parseInt(ParserOptions.SP_MIN.get(cmd, "4"));        final int spMax = Integer.parseInt(ParserOptions.SP_MAX.get(cmd, "32"));        final int spStep = Integer.parseInt(ParserOptions.SP_STEP.get(cmd, "4"));        final int pMin = Integer.parseInt(ParserOptions.P_MIN.get(cmd, "4"));        final int pMax = Integer.parseInt(ParserOptions.P_MAX.get(cmd, "32"));        final int pStep = Integer.parseInt(ParserOptions.P_STEP.get(cmd, "4"));        final double errorPercentile = Double.parseDouble(ParserOptions.ERR_PERCENTILE.get(cmd, "50"));        final double timePercentile = Double.parseDouble(ParserOptions.TIME_PERCENTILE.get(cmd, "50"));        final double sizePercentile = Double.parseDouble(ParserOptions.SIZE_PERCENTILE.get(cmd, "50"));        final boolean formatErrPercent = Boolean.parseBoolean(ParserOptions.ERR_FORMAT_PERCENT.get(cmd, "true"));        final int errMultiplier = formatErrPercent ? 100 : 1;        final Function<Double, String> errorFormatter = (v -> ERR_FORMAT.format(v * errMultiplier));        final Function<Double, String> timeFormatter = (v -> TIME_FORMAT.format(v / NANO_TO_MILLIS));        final Function<Double, String> sizeFormatter = (v -> SIZE_FORMAT.format(v));        final String[] chartKey = new String[] { "card: cardinality", "sp: sparse precision value", "p: normal precision value", "err: error as a percent of the expected cardinality; ", "time: total time to add all values to the hllp estimator and calculate a cardinality estimate", "size: size of the hllp set in bytes once all values have been added for the specified cardinality", "l=low, m=mid(based on percentile chosen), h=high, std=standard deviation" };        final String[] chartHeader = new String[] { "card", "sp", "p", "err l/m/h/std (% of actual)", "time l/m/h/std (ms)", "size l/m/h/std (b)" };        final int[] chartPadding = new int[] { 10, 10, 10, 40, 40, 30 };        if (spMin < pMin) {            throw new IllegalArgumentException("p must be <= sp");        }        if (spMax < pMax) {            throw new IllegalArgumentException("p must be <= sp");        }        println("Options Used");        println("------------");        println("num trials: " + numTrials);        println("card min: " + cardMin);        println("card max: " + cardMax);        println("card step: " + cardStep);        println("card start: " + cardStart);        println("sp min: " + spMin);        println("sp max: " + spMax);        println("sp step: " + spStep);        println("p min: " + pMin);        println("p max: " + pMax);        println("p step: " + pStep);        println("error percentile: " + errorPercentile);        println("time percentile: " + timePercentile);        println("size percentile: " + sizePercentile);        println("format err as %: " + formatErrPercent);        println("");        printHeading(chartKey, chartHeader, chartPadding, chartDelim);        for (int c = cardStart; c <= cardMax; c += cardStep) {            for (int sp = spMin; sp <= spMax; sp += spStep) {                for (int p = pMin; p <= pMax; p += pStep) {                    DescriptiveStatistics errorStats = new DescriptiveStatistics();                    DescriptiveStatistics timeStats = new DescriptiveStatistics();                    DescriptiveStatistics sizeStats = new DescriptiveStatistics();                    for (int i = 0; i < numTrials; i++) {                        List<Object> trialSet = buildTrialSet(c);                        Set unique = new HashSet();                        unique.addAll(trialSet);                        long distinctVals = unique.size();                        HyperLogLogPlus hllp = new HyperLogLogPlus(p, sp);                        long timeStart = System.nanoTime();                        hllp.addAll(trialSet);                        long dvEstimate = hllp.cardinality();                        long timeEnd = System.nanoTime();                        long timeElapsed = timeEnd - timeStart;                        double rawError = Math.abs(dvEstimate - distinctVals) / (double) distinctVals;                        errorStats.addValue(rawError);                        timeStats.addValue(timeElapsed);                        sizeStats.addValue(SerDeUtils.toBytes(hllp).length);                    }                    MeasureResultFormatter errorRF = new MeasureResultFormatter(errorStats, errorFormatter, errorPercentile);                    MeasureResultFormatter timeRF = new MeasureResultFormatter(timeStats, timeFormatter, timePercentile);                    MeasureResultFormatter sizeRF = new MeasureResultFormatter(sizeStats, sizeFormatter, sizePercentile);                    println(formatWithPadding(new String[] { "" + c, "" + sp, "" + p, errorRF.getFormattedResults(), timeRF.getFormattedResults(), sizeRF.getFormattedResults() }, chartPadding, chartDelim));                }            }        }    } catch (Exception e) {        e.printStackTrace();        System.exit(-1);    }}
0
private static void printHeading(String[] key, String[] header, int[] chartPadding, String chartDelim)
{    printHeadingKey(key);    printDescription();    printHeaderRow(header, chartPadding, chartDelim);    printChartSpacer(header.length, chartPadding, chartDelim, CHART_SPACER);}
0
private static void printHeadingKey(String[] key)
{    println("Table Key");    println("---------");    for (String v : key) {        println(v);    }    println("");}
0
private static void printDescription()
{    println("Metrics Table");    println("-------------");}
0
private static void printHeaderRow(String[] header, int[] padding, String delim)
{    String headerPadded = formatWithPadding(header, padding, delim);    println(headerPadded);}
0
private static void printChartSpacer(int totlength, int[] padding, String delim, String spacerStr)
{    String[] spacer = new String[totlength];    Arrays.fill(spacer, spacerStr);    String spacerPadded = formatWithPadding(spacer, padding, delim, spacerStr);    println(spacerPadded);}
0
private static void println(String val)
{    System.out.println(val);}
0
private static String formatWithPadding(String[] columns, int[] padding, String delim)
{    return formatWithPadding(columns, padding, delim, " ");}
0
private static String formatWithPadding(String[] columns, int[] padding, String delim, String paddingStr)
{    StringBuilder sb = new StringBuilder();    sb.append(delim);    for (int i = 0; i < columns.length; i++) {        sb.append(org.apache.commons.lang.StringUtils.rightPad(columns[i], padding[i], paddingStr));        sb.append(delim);    }    return sb.toString();}
0
public String getMin()
{    return formatter.apply(stats.getMin());}
0
public String getPercentile()
{    return formatter.apply(stats.getPercentile(percentile));}
0
public String getMax()
{    return formatter.apply(stats.getMax());}
0
public MeasureResultFormatter showStandardDeviation(boolean showStd)
{    this.showStd = showStd;    return this;}
0
public String getFormattedResults()
{    if (showStd) {        return Joiner.on(delim).join(getMin(), getPercentile(), getMax(), getStd());    } else {        return Joiner.on(delim).join(getMin(), getPercentile(), getMax());    }}
0
public String getStd()
{    return formatter.apply(stats.getStandardDeviation());}
0
private static List<Object> buildTrialSet(int cardinality)
{    List<Object> trialSet = new ArrayList(cardinality);    for (int i = 0; i < cardinality; i++) {        trialSet.add(Math.random());    }    return trialSet;}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public String get(CommandLine cli, String defaultVal)
{    return has(cli) ? cli.getOptionValue(shortCode) : defaultVal;}
0
public static CommandLine parse(CommandLineParser parser, String[] args) throws ParseException
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        throw e;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("HLLPMeasurement", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (ParserOptions o : ParserOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public int getSp()
{    return sp;}
0
public int getP()
{    return p;}
0
public boolean addAll(List<Object> objects)
{    boolean updated = false;    for (Object o : objects) {        updated |= add(o);    }    return updated;}
0
public boolean add(Object o)
{    return hllp.offer(o);}
0
public long cardinality()
{    return hllp.cardinality();}
0
public HyperLogLogPlus merge(List<HyperLogLogPlus> estimators)
{    List<com.clearspring.analytics.stream.cardinality.HyperLogLogPlus> converted = Lists.transform(estimators, s -> s.hllp);    ICardinality merged = null;    try {        merged = hllp.merge(converted.toArray(new com.clearspring.analytics.stream.cardinality.HyperLogLogPlus[] {}));    } catch (CardinalityMergeException e) {        throw new IllegalArgumentException("Unable to merge estimators", e);    }    return new HyperLogLogPlus(p, sp, (com.clearspring.analytics.stream.cardinality.HyperLogLogPlus) merged);}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    HyperLogLogPlus that = (HyperLogLogPlus) o;    return hllp.equals(that.hllp);}
0
public int hashCode()
{    return hllp.hashCode();}
0
public Object apply(List<Object> args)
{    if (args.size() < 2) {        throw new IllegalArgumentException("Must pass an hllp estimator set and at least one value to add to the set");    } else {        HyperLogLogPlus hllp = ConversionUtils.convert(args.get(0), HyperLogLogPlus.class);        if (hllp == null) {            hllp = new HyperLogLogPlus();        }        Object secondArg = args.get(1);        if (secondArg instanceof List) {            hllp.addAll((List) secondArg);        } else {            hllp.add(secondArg);        }        return hllp;    }}
0
public Object apply(List<Object> args)
{    if (args.size() == 1) {        if (args.get(0) instanceof HyperLogLogPlus) {            HyperLogLogPlus hllpSet = (HyperLogLogPlus) args.get(0);            return hllpSet.cardinality();        } else {            return 0L;        }    } else {        return 0L;    }}
0
public Object apply(List<Object> args)
{    if (args.size() == 0) {        return new HyperLogLogPlus();    } else if (args.size() == 1) {        Integer p = ConversionUtils.convert(args.get(0), Integer.class);        if (p == null) {            throw new IllegalArgumentException(String.format("Unable to get p value from '%s'", args.get(0)));        }        return new HyperLogLogPlus(p);    } else {        Integer p = ConversionUtils.convert(args.get(0), Integer.class);        Integer sp = ConversionUtils.convert(args.get(1), Integer.class);        if (p == null) {            throw new IllegalArgumentException(String.format("Unable to get p value from '%s'", args.get(0)));        }        if (sp == null) {            throw new IllegalArgumentException(String.format("Unable to get sp value from '%s'", args.get(1)));        }        return new HyperLogLogPlus(p, sp);    }}
0
public Object apply(List<Object> args)
{    if (args.size() != 1) {        throw new IllegalArgumentException("Must pass single list of hllp sets to merge");    } else {        List<Object> estimators = new ArrayList();        if (args.get(0) instanceof List) {            estimators = (List) args.get(0);        } else {            estimators.add(args.get(0));        }        if (estimators.size() == 0) {            return null;        }        HyperLogLogPlus hllp = ConversionUtils.convert(estimators.get(0), HyperLogLogPlus.class);        if (estimators.size() > 1) {            hllp = hllp.merge(getEstimatorsFromIndex(estimators, 1));        }        return hllp;    }}
0
private List<HyperLogLogPlus> getEstimatorsFromIndex(List<Object> args, int index)
{    return ConversionUtils.convertList(args.subList(index, args.size()), HyperLogLogPlus.class);}
0
public static int getBin(double value, int numBins, Function<Integer, Double> boundFunc)
{    double lastBound = Double.NEGATIVE_INFINITY;    for (int bin = 0; bin < numBins; ++bin) {        double bound = boundFunc.apply(bin);        if (lastBound > bound) {            throw new IllegalStateException("Your bins must be non-decreasing");        }        if (value <= bound) {            return bin;        }        lastBound = bound;    }    return numBins;}
0
public Object apply(List<Object> args)
{    Double value = convert(args.get(0), Double.class);    final List<Number> bins = args.size() > 1 ? convert(args.get(1), List.class) : null;    if (value == null || bins == null || bins.size() == 0) {        return -1;    }    return getBin(value, bins.size(), bin -> bins.get(bin).doubleValue());}
0
public Object apply(List<Object> args)
{    if (args.isEmpty()) {        throw new IllegalArgumentException("IT_ENTROPY expects exactly one argument.");    }    Object inputObj = args.get(0);    if (inputObj == null) {        return null;    }    if (!(inputObj instanceof Map)) {        throw new IllegalArgumentException("IT_ENTROPY expects exactly one argument and expects it to be a map of counts (e.g. Map<?, Integer>)");    }    Map<?, Integer> countMap = (Map<?, Integer>) inputObj;    return InformationTheoryUtil.INSTANCE.bitEntropy(countMap);}
0
public double entropy(Map<?, Integer> counts, double logOfBase)
{    double ret = 0.0;    int n = 0;    if (counts == null || counts.isEmpty()) {        return ret;    }    for (Integer f : counts.values()) {        n += f;    }    for (Integer f : counts.values()) {        double p = f.doubleValue() / n;        ret -= p * Math.log(p) / logOfBase;    }    return ret;}
0
public double entropy(Map<?, Integer> counts, int base)
{    return entropy(counts, Math.log(base));}
0
public double bitEntropy(Map<?, Integer> counts)
{    return entropy(counts, LOG2);}
0
public void addValue(double value)
{    long n1 = n;    min = min == null ? value : Math.min(min, value);    max = max == null ? value : Math.max(max, value);    sum += value;    sumOfLogs += Math.log(value);    sumOfSquares += value * value;    digest.add(value);    n++;    double delta, delta_n, delta_n2, term1;        delta = value - M1;        delta_n = delta / n;    delta_n2 = delta_n * delta_n;    term1 = delta * delta_n * n1;        M1 += delta_n;        M4 += term1 * delta_n2 * (n * n - 3 * n + 3) + 6 * delta_n2 * M2 - 4 * delta_n * M3;    M3 += term1 * delta_n * (n - 2) - 3 * delta_n * M2;    M2 += term1;    checkFlowError(sumOfSquares, sum, sumOfSquares, M1, M2, M3, M4);}
0
private void checkFlowError(double sumOfSquares, double sum, double... vals)
{        for (double val : vals) {        if (Double.isInfinite(val)) {            throw new IllegalStateException("Double overflow!");        }    }        if (sumOfSquares == 0.0 && sum > 0) {        throw new IllegalStateException("Double overflow!");    }}
0
public long getCount()
{    return n;}
0
public double getMin()
{    return min == null ? Double.NaN : min;}
0
public double getMax()
{    return max == null ? Double.NaN : max;}
0
public double getMean()
{    return getSum() / getCount();}
0
public double getSum()
{    return sum;}
0
public double getVariance()
{    return M2 / (n - 1.0);}
0
public double getStandardDeviation()
{    return FastMath.sqrt(getVariance());}
0
public double getGeometricMean()
{    throw new UnsupportedOperationException("Unwilling to compute the geometric mean.");}
0
public double getPopulationVariance()
{    throw new UnsupportedOperationException("Unwilling to compute the geometric mean.");}
0
public double getQuadraticMean()
{    return FastMath.sqrt(sumOfSquares / n);}
0
public double getSumLogs()
{    return sumOfLogs;}
0
public double getSumSquares()
{    return sumOfSquares;}
0
public double getKurtosis()
{        if (n < 4) {        return Double.NaN;    }    double std = getStandardDeviation();    double t1 = (1.0 * n) * (n + 1) / ((n - 1) * (n - 2) * (n - 3));    double t3 = 3.0 * ((n - 1) * (n - 1)) / ((n - 2) * (n - 3));    return t1 * (M4 / FastMath.pow(std, 4)) - t3;}
0
public double getSkewness()
{        if (n < 3) {        return Double.NaN;    }    double t1 = (1.0 * n) / ((n - 1) * (n - 2));    double std = getStandardDeviation();    return t1 * M3 / FastMath.pow(std, 3);}
0
public double getPercentile(double p)
{    return digest.quantile(p / 100.0);}
0
public StatisticsProvider merge(StatisticsProvider provider)
{    OnlineStatisticsProvider combined = new OnlineStatisticsProvider();    OnlineStatisticsProvider a = this;    OnlineStatisticsProvider b = (OnlineStatisticsProvider) provider;        combined.n = a.n + b.n;    combined.sum = a.sum + b.sum;    if (a.min != null && b.min != null) {        combined.min = Math.min(a.min, b.min);        combined.max = Math.max(a.max, b.max);    } else {        combined.min = a.min;        combined.max = a.max;    }    combined.sumOfSquares = a.sumOfSquares + b.sumOfSquares;    combined.sumOfLogs = a.sumOfLogs + b.sumOfLogs;        double delta = b.M1 - a.M1;    double delta2 = delta * delta;    double delta3 = delta * delta2;    double delta4 = delta2 * delta2;    combined.M1 = (a.n * a.M1 + b.n * b.M1) / combined.n;    combined.M2 = a.M2 + b.M2 + delta2 * a.n * b.n / combined.n;    combined.M3 = a.M3 + b.M3 + delta3 * a.n * b.n * (a.n - b.n) / (combined.n * combined.n);    combined.M3 += 3.0 * delta * (a.n * b.M2 - b.n * a.M2) / combined.n;    combined.M4 = a.M4 + b.M4 + delta4 * a.n * b.n * (a.n * a.n - a.n * b.n + b.n * b.n) / (combined.n * combined.n * combined.n);    combined.M4 += 6.0 * delta2 * (a.n * a.n * b.M2 + b.n * b.n * a.M2) / (combined.n * combined.n) + 4.0 * delta * (a.n * b.M3 - b.n * a.M3) / combined.n;        combined.digest.add(a.digest);    combined.digest.add(b.digest);    checkFlowError(combined.sumOfSquares, sum, combined.sumOfSquares, combined.M1, combined.M2, combined.M3, combined.M4);    return combined;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    OnlineStatisticsProvider that = (OnlineStatisticsProvider) o;    if (n != that.n)        return false;    if (Double.compare(that.sum, sum) != 0)        return false;    if (Double.compare(that.sumOfSquares, sumOfSquares) != 0)        return false;    if (Double.compare(that.sumOfLogs, sumOfLogs) != 0)        return false;    if (Double.compare(that.M1, M1) != 0)        return false;    if (Double.compare(that.M2, M2) != 0)        return false;    if (Double.compare(that.M3, M3) != 0)        return false;    if (Double.compare(that.M4, M4) != 0)        return false;    if (digest != null ? !digest.equals(that.digest) : that.digest != null)        return false;    if (min != null ? !min.equals(that.min) : that.min != null)        return false;    return max != null ? max.equals(that.max) : that.max == null;}
0
public int hashCode()
{    int result;    long temp;    result = digest != null ? digest.hashCode() : 0;    result = 31 * result + (int) (n ^ (n >>> 32));    temp = Double.doubleToLongBits(sum);    result = 31 * result + (int) (temp ^ (temp >>> 32));    temp = Double.doubleToLongBits(sumOfSquares);    result = 31 * result + (int) (temp ^ (temp >>> 32));    temp = Double.doubleToLongBits(sumOfLogs);    result = 31 * result + (int) (temp ^ (temp >>> 32));    result = 31 * result + (min != null ? min.hashCode() : 0);    result = 31 * result + (max != null ? max.hashCode() : 0);    temp = Double.doubleToLongBits(M1);    result = 31 * result + (int) (temp ^ (temp >>> 32));    temp = Double.doubleToLongBits(M2);    result = 31 * result + (int) (temp ^ (temp >>> 32));    temp = Double.doubleToLongBits(M3);    result = 31 * result + (int) (temp ^ (temp >>> 32));    temp = Double.doubleToLongBits(M4);    result = 31 * result + (int) (temp ^ (temp >>> 32));    return result;}
0
public void write(Kryo kryo, Output output)
{        ByteBuffer outBuffer = ByteBuffer.allocate(digest.byteSize());    digest.asBytes(outBuffer);    byte[] tdigestSerialized = outBuffer.array();    output.writeInt(tdigestSerialized.length);    output.writeBytes(tdigestSerialized);    output.writeLong(n);    output.writeDouble(sum);    output.writeDouble(sumOfSquares);    output.writeDouble(sumOfLogs);    output.writeDouble(getMin());    output.writeDouble(getMax());    output.writeDouble(M1);    output.writeDouble(M2);    output.writeDouble(M3);    output.writeDouble(M4);}
0
public void read(Kryo kryo, Input input)
{    int digestSize = input.readInt();    byte[] digestBytes = input.readBytes(digestSize);    ByteBuffer digestBuff = ByteBuffer.wrap(digestBytes);    digest = AVLTreeDigest.fromBytes(digestBuff);    n = input.readLong();    sum = input.readDouble();    sumOfSquares = input.readDouble();    sumOfLogs = input.readDouble();    min = input.readDouble();    max = input.readDouble();    M1 = input.readDouble();    M2 = input.readDouble();    M3 = input.readDouble();    M4 = input.readDouble();}
0
public void add(Double d)
{    if (!Double.isNaN(d)) {        tickMedianProvider.addValue(d);        double deviation = Math.abs(d - windowMedianProvider.getPercentile(50));        windowMedianProvider.addValue(d);        if (!Double.isNaN(deviation)) {            windowMADProvider.addValue(deviation);            tickMADProvider.addValue(deviation);        }    }}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    State state = null;    @SuppressWarnings("unchecked")    List<State> states = (List<State>) args.get(0);    State currentState = null;    if (args.size() > 1) {        currentState = (State) args.get(1);    }    state = new State(Optional.ofNullable(states), Optional.ofNullable(currentState));    return state;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    State state = (State) args.get(0);    Object o = args.get(1);    List<Double> data = new ArrayList<>();    if (o != null) {        if (o instanceof List) {            @SuppressWarnings("unchecked")            List<Object> oList = (List<Object>) o;            for (Object datum : oList) {                Number n = (Number) datum;                data.add(n.doubleValue());            }        } else {            Number n = (Number) o;            data.add(n.doubleValue());        }    }    if (state != null) {        for (Double d : data) {            state.add(d);        }    }    return state;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    double scale = 0.6745;    State state = (State) args.get(0);    Number datum = (Number) args.get(1);    if (args.size() > 2) {        Number scaleNum = (Number) args.get(2);        if (scaleNum != null) {            scale = scaleNum.doubleValue();        }    }    if (datum == null || state == null) {        return Double.NaN;    }    double deviation = Math.abs(datum.doubleValue() - state.windowMedianProvider.getPercentile(50));    double medianAbsoluteDeviation = state.windowMADProvider.getPercentile(50);    double modifiedZScore = scale * deviation / medianAbsoluteDeviation;    return modifiedZScore;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
 void addAll(Iterable<? extends Object> vals)
{    if (vals == null) {        return;    }    for (Object o : vals) {        add(o);    }}
0
public Sampler merge(Iterable<Sampler> samplers, Optional<Sampler> baseSampler)
{    if (Iterables.isEmpty(samplers)) {        return null;    }    Sampler ret = baseSampler.orElse(Iterables.getFirst(samplers, null).cloneEmpty());    for (Sampler s : samplers) {        ret.addAll(s.get());    }    return ret;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() == 0) {        return new UniformSampler();    } else {        Optional<Integer> sizeArg = get(args, 0, "Size", Integer.class);        if (sizeArg.isPresent() && sizeArg.get() <= 0) {            throw new IllegalStateException("Size must be a positive integer");        } else {            return new UniformSampler(sizeArg.orElse(Sampler.DEFAULT_SIZE));        }    }}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public static Optional<T> get(List<Object> args, int offset, String argName, Class<T> expectedClazz)
{    Object obj = args.get(offset);    T ret = ConversionUtils.convert(obj, expectedClazz);    if (ret == null) {        if (obj != null) {            throw new IllegalStateException(argName + "argument(" + obj + " is expected to be an " + expectedClazz.getName() + ", but was " + obj);        }    }    return Optional.ofNullable(ret);}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() == 0) {        return null;    }    Sampler s = null;    Object sObj = args.get(0);    if (sObj == null) {        return null;    } else if (sObj instanceof Sampler) {        s = (Sampler) sObj;    } else {        throw new IllegalStateException("Expected a sampler, but found " + sObj);    }    return s.get();}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() == 0) {        return null;    }    if (args.size() < 2) {        throw new IllegalStateException("Expected sampler and value to add");    }    Sampler s = null;    Object sObj = args.get(0);    if (sObj == null) {        s = new UniformSampler();    } else if (sObj instanceof Sampler) {        s = (Sampler) sObj;    } else {        throw new IllegalStateException("Expected a sampler, but found " + sObj);    }    Object valsObj = args.get(1);    if (valsObj == null) {        return s;    } else if (valsObj instanceof Iterable) {        Iterable<Object> vals = (Iterable<Object>) valsObj;        s.addAll(vals);    } else {        s.add(valsObj);    }    return s;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() == 0) {        return null;    }    Object reservoirsObj = args.get(0);    if (reservoirsObj == null) {        return null;    }    if (!(reservoirsObj instanceof Iterable)) {        throw new IllegalStateException("Expected a collection of Samplers");    }    Iterable<Sampler> reservoirs = (Iterable<Sampler>) reservoirsObj;    Sampler baseSampler = null;    if (args.size() > 1) {        Object baseSamplerObj = args.get(1);        if (baseSamplerObj != null) {            if (!(baseSamplerObj instanceof Sampler)) {                throw new IllegalStateException("Expected baseSampler to be a Sampler");            } else {                baseSampler = (Sampler) baseSamplerObj;            }        }    }    return SamplerUtil.INSTANCE.merge(reservoirs, Optional.ofNullable(baseSampler));}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Iterable<Object> get()
{    return reservoir;}
0
public void add(Object o)
{    if (o == null) {        return;    }    if (reservoir.size() < size) {        reservoir.add(o);    } else {        int rIndex = rng.nextInt(seen + 1);        if (rIndex < size) {            reservoir.set(rIndex, o);        }    }    seen++;}
0
public Sampler cloneEmpty()
{    return new UniformSampler(getSize());}
0
public int getSize()
{    return size;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    UniformSampler that = (UniformSampler) o;    if (getSize() != that.getSize())        return false;    return reservoir != null ? reservoir.equals(that.reservoir) : that.reservoir == null;}
0
public int hashCode()
{    int result = reservoir != null ? reservoir.hashCode() : 0;    result = 31 * result + getSize();    return result;}
0
private static StatisticsProvider statsInit(List<Object> args)
{    int windowSize = 0;    if (args.size() > 0 && args.get(0) instanceof Number) {        windowSize = convert(args.get(0), Integer.class);    }    if (windowSize > 0) {        return new WindowedStatisticsProvider(windowSize);    }    return new OnlineStatisticsProvider();}
0
public Object apply(List<Object> args)
{    if (args.size() > 0) {        Object firstArg = args.get(0);        if (firstArg instanceof List) {            StatisticsProvider ret = null;            for (Object sp : (List) firstArg) {                if (sp instanceof StatisticsProvider) {                    if (ret == null) {                        ret = (StatisticsProvider) sp;                    } else {                        ret = ret.merge((StatisticsProvider) sp);                    }                }            }            return ret;        } else {            return null;        }    }    return null;}
0
public Object apply(List<Object> args)
{    return statsInit(args);}
0
public Object apply(List<Object> args)
{        StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    if (stats == null) {        stats = statsInit(Collections.emptyList());    }        for (int i = 1; i < args.size(); i++) {        Object n = args.get(i);        if (n != null) {            if (n instanceof Iterable) {                for (Object num : (Iterable<Object>) n) {                    if (num != null) {                        Double value = convert(num, Double.class);                        stats.addValue(value);                    }                }            } else {                Double value = convert(args.get(i), Double.class);                stats.addValue(value);            }        }    }    return stats;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getMean() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getGeometricMean() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getSum() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getMax() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getMin() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? convert(stats.getCount(), Double.class) : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getPopulationVariance() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getVariance() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getQuadraticMean() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getStandardDeviation() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getSumLogs() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getSumSquares() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getKurtosis() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    return (stats != null) ? stats.getSkewness() : Double.NaN;}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    Double p = convert(args.get(1), Double.class);    Double result;    if (stats == null || p == null) {        result = Double.NaN;    } else {        result = stats.getPercentile(p);    }    return result;}
0
public static List<Number> getSplit(Object o)
{    if (o instanceof String) {        return BinSplits.valueOf((String) o).split;    } else if (o instanceof List) {        return ConversionUtils.convert(o, List.class);    }    throw new IllegalStateException("The split you tried to pass is not a valid split: " + o.toString());}
0
public Object apply(List<Object> args)
{    StatisticsProvider stats = convert(args.get(0), StatisticsProvider.class);    Double value = convert(args.get(1), Double.class);    final List<Number> bins = args.size() > 2 ? BinSplits.getSplit(args.get(2)) : BinSplits.QUARTILE.split;    if (stats == null || value == null || bins.size() == 0) {        return -1;    }    return BinFunctions.Bin.getBin(value, bins.size(), bin -> stats.getPercentile(bins.get(bin).doubleValue()));}
0
public void addValue(double value)
{    descStats.addValue(value);}
0
public long getCount()
{    return descStats.getN();}
0
public double getMin()
{    return descStats.getMin();}
0
public double getMax()
{    return descStats.getMax();}
0
public double getMean()
{    return descStats.getMean();}
0
public double getSum()
{    return descStats.getSum();}
0
public double getVariance()
{    return descStats.getVariance();}
0
public double getStandardDeviation()
{    return descStats.getStandardDeviation();}
0
public double getGeometricMean()
{    return descStats.getGeometricMean();}
0
public double getPopulationVariance()
{    return descStats.getPopulationVariance();}
0
public double getQuadraticMean()
{    return descStats.getQuadraticMean();}
0
public double getSumLogs()
{    throw new UnsupportedOperationException("sum logs not available if 'windowSize' > 0");}
0
public double getSumSquares()
{    return descStats.getSumsq();}
0
public double getKurtosis()
{    return descStats.getKurtosis();}
0
public double getSkewness()
{    return descStats.getSkewness();}
0
public double getPercentile(double p)
{    return descStats.getPercentile(p);}
0
public StatisticsProvider merge(StatisticsProvider provider)
{    throw new UnsupportedOperationException("Windowed Statistics cannot be merged.");}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    WindowedStatisticsProvider that = (WindowedStatisticsProvider) o;    return descStats != null ? descStats.equals(that.descStats) : that.descStats == null;}
0
public int hashCode()
{    return descStats != null ? descStats.hashCode() : 0;}
0
public void cardinality_gives_distinct_value_estimate_for_default_constructor()
{    Long estimate = (Long) StellarProcessorUtils.run(hllpDefaultConstructorRule, values);    Assert.assertThat("Incorrect cardinality returned", estimate, equalTo(2L));}
0
public void cardinality_gives_distinct_value_estimate_with_precisions_set()
{    Long estimate = (Long) StellarProcessorUtils.run(hllpBasicRule, values);    Assert.assertThat("Incorrect cardinality returned", estimate, equalTo(2L));}
0
public void hllp_add_accepts_multiple_items()
{    Long estimate = (Long) StellarProcessorUtils.run(hllpMultipleAddItems, values);    Assert.assertThat("Incorrect cardinality returned", estimate, equalTo(4L));}
0
public void merges_estimators()
{    Long estimate = (Long) StellarProcessorUtils.run(hllpMergeRule, values);    Assert.assertThat("Incorrect cardinality returned", estimate, equalTo(4L));}
0
public void cardinality_of_null_value_is_0()
{    Long estimate = (Long) StellarProcessorUtils.run(zeroCardinalityRule, values);    Assert.assertThat("Incorrect cardinality returned", estimate, equalTo(0L));}
0
public void hllp_init_creates_HyperLogLogPlus_set()
{    HyperLogLogPlus hllp = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of());    Assert.assertThat(hllp.getSp(), equalTo(25));    Assert.assertThat(hllp.getP(), equalTo(14));    Assert.assertThat("instance types should match for constructor with default precision values", new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5)), instanceOf(HyperLogLogPlus.class));    Assert.assertThat("instance types should match for constructor with sparse set disabled", new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5)), instanceOf(HyperLogLogPlus.class));    Assert.assertThat("instance types should match for full constructor", new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6)), instanceOf(HyperLogLogPlus.class));}
0
public void hllp_init_with_incorrect_args_throws_exception()
{    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage("Unable to get p value from 'turkey'");    new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of("turkey"));}
0
public void hllp_add_returns_hllp_with_item_added_to_set()
{    HyperLogLogPlus actual = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6));    actual = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(actual, "item-1"));    actual = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(actual, "item-2"));    HyperLogLogPlus expected = new HyperLogLogPlus(5, 6);    expected.add("item-1");    expected.add("item-2");    Assert.assertThat("hllp set should have cardinality based on added values", actual.cardinality(), equalTo(2L));    Assert.assertThat("estimators should be equal", actual, equalTo(expected));}
0
public void hllp_add_with_null_set_inits_and_returns_new_hllp_with_item_added_to_set()
{    HyperLogLogPlus actual = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(Arrays.asList(null, "item-1"));    Assert.assertThat(actual, notNullValue());}
0
public void hllp_add_throws_exception_with_incorrect_args()
{    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage("Must pass an hllp estimator set and at least one value to add to the set");    new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6))));}
0
public void hllp_cardinality_returns_number_of_distinct_values()
{    HyperLogLogPlus hllp = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6));    hllp = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp, "item-1"));    hllp = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp, "item-2"));    hllp = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp, "item-3"));    Assert.assertThat("cardinality not expected value", new HyperLogLogPlusFunctions.HLLPCardinality().apply(ImmutableList.of(hllp)), equalTo(3L));}
0
public void hllp_cardinality_returns_0_for_null_set()
{    List nullArg = new ArrayList() {        {            add(null);        }    };    Assert.assertThat("Cardinality should be 0", new HyperLogLogPlusFunctions.HLLPCardinality().apply(nullArg), equalTo(0L));}
0
public void hllp_merge_combines_hllp_sets()
{    HyperLogLogPlus hllp1 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6));    hllp1 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp1, "item-1"));    hllp1 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp1, "item-2"));    HyperLogLogPlus hllp2 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6));    hllp2 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp2, "item-3"));    HyperLogLogPlus merged = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPMerge().apply(ImmutableList.of(ImmutableList.of(hllp1, hllp2)));    Long actual = (Long) new HyperLogLogPlusFunctions.HLLPCardinality().apply(ImmutableList.of(merged));    Assert.assertThat("cardinality should match merged set", actual, equalTo(3L));    HyperLogLogPlus hllp3 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6));    hllp3 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp3, "item-4"));    merged = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPMerge().apply(ImmutableList.of(ImmutableList.of(hllp1, hllp2, hllp3)));    actual = (Long) new HyperLogLogPlusFunctions.HLLPCardinality().apply(ImmutableList.of(merged));    Assert.assertThat("cardinality should match merged set", actual, equalTo(4L));}
0
public void hllp_merge_with_single_estimator_acts_as_identity_function()
{    HyperLogLogPlus hllp1 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of(5, 6));    hllp1 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp1, "item-1"));    hllp1 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPAdd().apply(ImmutableList.of(hllp1, "item-2"));    HyperLogLogPlus merged = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPMerge().apply(ImmutableList.of(hllp1));    Long actual = (Long) new HyperLogLogPlusFunctions.HLLPCardinality().apply(ImmutableList.of(merged));    Assert.assertThat("cardinality should match merged set", actual, equalTo(2L));}
0
public void hllp_merge_throws_exception_with_no_arguments()
{    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage("Must pass single list of hllp sets to merge");    new HyperLogLogPlusFunctions.HLLPMerge().apply(ImmutableList.of());}
0
public void hllp_merge_throws_exception_on_invalid_arguments()
{    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage("Must pass single list of hllp sets to merge");    HyperLogLogPlus hllp1 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of());    HyperLogLogPlus hllp2 = (HyperLogLogPlus) new HyperLogLogPlusFunctions.HLLPInit().apply(ImmutableList.of());    new HyperLogLogPlusFunctions.HLLPMerge().apply(ImmutableList.of(hllp1, hllp2));}
0
public void merge_returns_null_if_passed_an_empty_list_to_merge()
{    List emptyList = ImmutableList.of();    Assert.assertThat("Should be empty list", new HyperLogLogPlusFunctions.HLLPMerge().apply(ImmutableList.of(emptyList)), equalTo(null));}
0
public static Object run(String rule, Map<String, Object> variables)
{    Context context = Context.EMPTY_CONTEXT();    StellarProcessor processor = new StellarProcessor();    Assert.assertTrue(rule + " not valid.", processor.validate(rule, context));    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void testBin()
{    Assert.assertEquals(run("BIN(value, bounds)", ImmutableMap.of("value", 0, "bounds", ImmutableList.of(10, 20, 30))), 0);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 0)), 0);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 9)), 0);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 10)), 0);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 11)), 1);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 19)), 1);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 21)), 2);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 29)), 2);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 31)), 3);    Assert.assertEquals(run("BIN(value, [ 10, 20, 30 ])", ImmutableMap.of("value", 1000)), 3);}
0
public void entropyTest() throws Exception
{        Assert.assertEquals(0.0, (Double) run("IT_ENTROPY({})", new HashMap<>()), 0.0);    /*    Now consider the string aaaaaaaaaabbbbbccccc or 10 a's followed by 5 b's and 5 c's.    The probabilities of each character is as follows:    p(a) = 1/2    p(b) = 1/4    p(c) = 1/4    so the shannon entropy should be      -p(a)*log_2(p(a)) - p(b)*log_2(p(b)) - p(c)*log_2(p(c)) =      -0.5*-1 - 0.25*-2 - 0.25*-2 = 1.5     */    Assert.assertEquals(1.5, (Double) run("IT_ENTROPY({ 'a' : 10, 'b' : 5, 'c' : 5} )", new HashMap<>()), 0.0);}
0
public static void validateStatisticsProvider(StatisticsProvider statsProvider, SummaryStatistics summaryStats, DescriptiveStatistics stats)
{        Assert.assertEquals(statsProvider.getCount(), stats.getN());        Assert.assertEquals(statsProvider.getSum(), stats.getSum(), 1e-3);        Assert.assertEquals(statsProvider.getSumSquares(), stats.getSumsq(), 1e-3);        Assert.assertEquals(statsProvider.getSumLogs(), summaryStats.getSumOfLogs(), 1e-3);        Assert.assertEquals(statsProvider.getMean(), stats.getMean(), 1e-3);        Assert.assertEquals(statsProvider.getQuadraticMean(), summaryStats.getQuadraticMean(), 1e-3);        Assert.assertEquals(statsProvider.getStandardDeviation(), stats.getStandardDeviation(), 1e-3);        Assert.assertEquals(statsProvider.getVariance(), stats.getVariance(), 1e-3);        Assert.assertEquals(statsProvider.getMin(), stats.getMin(), 1e-3);        Assert.assertEquals(statsProvider.getMax(), stats.getMax(), 1e-3);        Assert.assertEquals(stats.getKurtosis(), statsProvider.getKurtosis(), 1e-3);        Assert.assertEquals(stats.getSkewness(), statsProvider.getSkewness(), 1e-3);    for (double d = 10.0; d < 100.0; d += 10) {                Assert.assertEquals("Percentile mismatch for " + d + "th %ile", statsProvider.getPercentile(d), stats.getPercentile(d), 1e-2);    }}
0
private void validateEquality(Iterable<Double> values)
{    DescriptiveStatistics stats = new DescriptiveStatistics();    SummaryStatistics summaryStats = new SummaryStatistics();    OnlineStatisticsProvider statsProvider = new OnlineStatisticsProvider();        List<OnlineStatisticsProvider> providers = new ArrayList<>();    for (int i = 0; i < 10; ++i) {        providers.add(new OnlineStatisticsProvider());    }    int i = 0;    for (double d : values) {        i++;        stats.addValue(d);        summaryStats.addValue(d);        providers.get(i % providers.size()).addValue(d);        statsProvider.addValue(d);    }    StatisticsProvider aggregatedProvider = providers.get(0);    for (int j = 1; j < providers.size(); ++j) {        aggregatedProvider = aggregatedProvider.merge(providers.get(j));    }    validateStatisticsProvider(statsProvider, summaryStats, stats);    validateStatisticsProvider(aggregatedProvider, summaryStats, stats);}
0
public void testOverflow()
{    OnlineStatisticsProvider statsProvider = new OnlineStatisticsProvider();    statsProvider.addValue(Double.MAX_VALUE + 1);}
0
public void testUnderflow()
{    OnlineStatisticsProvider statsProvider = new OnlineStatisticsProvider();    double d = 3e-305;    for (int i = 0; i < 5; ++i, d /= 100000) {        statsProvider.addValue(d);    }}
0
public void testNormallyDistributedRandomData()
{    List<Double> values = new ArrayList<>();    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(0L));    for (int i = 0; i < 1000000; ++i) {        double d = gaussian.nextNormalizedDouble();        values.add(d);    }    validateEquality(values);}
0
public void testNormallyDistributedRandomDataShifted()
{    List<Double> values = new ArrayList<>();    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(0L));    for (int i = 0; i < 1000000; ++i) {        double d = gaussian.nextNormalizedDouble() + 10;        values.add(d);    }    validateEquality(values);}
0
public void testNormallyDistributedRandomDataShiftedBackwards()
{    List<Double> values = new ArrayList<>();    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(0L));    for (int i = 0; i < 1000000; ++i) {        double d = gaussian.nextNormalizedDouble() - 10;        values.add(d);    }    validateEquality(values);}
0
public void testNormallyDistributedRandomDataSkewed()
{    List<Double> values = new ArrayList<>();    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(0L));    for (int i = 0; i < 1000000; ++i) {        double d = (gaussian.nextNormalizedDouble() + 10000) / 1000;        values.add(d);    }    validateEquality(values);}
0
public void testNormallyDistributedRandomDataAllNegative()
{    List<Double> values = new ArrayList<>();    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(0L));    for (int i = 0; i < 1000000; ++i) {        double d = -1 * gaussian.nextNormalizedDouble();        values.add(d);    }    validateEquality(values);}
0
public void testUniformlyDistributedRandomData()
{    List<Double> values = new ArrayList<>();    for (int i = 0; i < 100000; ++i) {        double d = Math.random();        values.add(d);    }    validateEquality(values);}
0
public static Object run(String rule, Map<String, Object> variables)
{    Context context = Context.EMPTY_CONTEXT();    StellarProcessor processor = new StellarProcessor();    Assert.assertTrue(rule + " not valid.", processor.validate(rule, context));    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
private void assertScoreEquals(MedianAbsoluteDeviationFunctions.State currentState, MedianAbsoluteDeviationFunctions.State clonedState, double value)
{    Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", value));    Double clonedScore = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", clonedState, "value", value));    Assert.assertEquals(score, clonedScore, 1e-6);}
0
public void testSerialization()
{    MedianAbsoluteDeviationFunctions.State currentState = null;    List<MedianAbsoluteDeviationFunctions.State> states = new ArrayList<>();    currentState = (MedianAbsoluteDeviationFunctions.State) run("OUTLIER_MAD_STATE_MERGE(states, NULL)", ImmutableMap.of("states", states));    for (int i = 0; i < 100; ++i) {        double d = 1.2 * i;        run("OUTLIER_MAD_ADD(currentState, data)", ImmutableMap.of("currentState", currentState, "data", d));    }    byte[] stateBytes = SerDeUtils.toBytes(currentState);    MedianAbsoluteDeviationFunctions.State clonedState = SerDeUtils.fromBytes(stateBytes, MedianAbsoluteDeviationFunctions.State.class);    assertScoreEquals(currentState, clonedState, 0d);    assertScoreEquals(currentState, clonedState, 1d);    assertScoreEquals(currentState, clonedState, 10d);}
0
public void test()
{    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(0L));    DescriptiveStatistics stats = new DescriptiveStatistics();    List<MedianAbsoluteDeviationFunctions.State> states = new ArrayList<>();    MedianAbsoluteDeviationFunctions.State currentState = null;        currentState = (MedianAbsoluteDeviationFunctions.State) run("OUTLIER_MAD_STATE_MERGE(states, NULL)", ImmutableMap.of("states", states));    for (int i = 0, j = 0; i < 10000; ++i, ++j) {        Double d = gaussian.nextNormalizedDouble();        stats.addValue(d);        run("OUTLIER_MAD_ADD(currentState, data)", ImmutableMap.of("currentState", currentState, "data", d));        if (j >= 1000) {            j = 0;            List<MedianAbsoluteDeviationFunctions.State> stateWindow = new ArrayList<>();            for (int stateIndex = Math.max(0, states.size() - 5); stateIndex < states.size(); ++stateIndex) {                stateWindow.add(states.get(stateIndex));            }            currentState = (MedianAbsoluteDeviationFunctions.State) run("OUTLIER_MAD_STATE_MERGE(states, currentState)", ImmutableMap.of("states", stateWindow, "currentState", currentState));        }    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMin()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being a minimum.", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMax()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being a maximum", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMean() + 4 * stats.getStandardDeviation()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being 4 std deviations away from the mean", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMean() - 4 * stats.getStandardDeviation()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being 4 std deviations away from the mean", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMean()));        Assert.assertFalse("Score: " + score + " is an outlier despite being the mean", score > 3.5);    }}
0
public void testLongTailed()
{    TDistribution generator = new TDistribution(new MersenneTwister(0L), 100);    DescriptiveStatistics stats = new DescriptiveStatistics();    List<MedianAbsoluteDeviationFunctions.State> states = new ArrayList<>();    MedianAbsoluteDeviationFunctions.State currentState = null;        currentState = (MedianAbsoluteDeviationFunctions.State) run("OUTLIER_MAD_STATE_MERGE(states, NULL)", ImmutableMap.of("states", states));    for (int i = 0, j = 0; i < 10000; ++i, ++j) {        Double d = generator.sample();        stats.addValue(d);        run("OUTLIER_MAD_ADD(currentState, data)", ImmutableMap.of("currentState", currentState, "data", d));        if (j >= 1000) {            j = 0;            List<MedianAbsoluteDeviationFunctions.State> stateWindow = new ArrayList<>();            for (int stateIndex = Math.max(0, states.size() - 5); stateIndex < states.size(); ++stateIndex) {                stateWindow.add(states.get(stateIndex));            }            currentState = (MedianAbsoluteDeviationFunctions.State) run("OUTLIER_MAD_STATE_MERGE(states, currentState)", ImmutableMap.of("states", stateWindow, "currentState", currentState));        }    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMin()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being a minimum.", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMax()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being a maximum", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMean() + 4 * stats.getStandardDeviation()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being 4 std deviations away from the mean", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMean() - 4 * stats.getStandardDeviation()));        Assert.assertTrue("Score: " + score + " is not an outlier despite being 4 std deviations away from the mean", score > 3.5);    }    {        Double score = (Double) run("OUTLIER_MAD_SCORE(currentState, value)", ImmutableMap.of("currentState", currentState, "value", stats.getMean()));        Assert.assertFalse("Score: " + score + " is an outlier despite being the mean", score > 3.5);    }}
0
public static void beforeClass()
{    Random rng = new Random(0);    int sampleSize = 1000000;    int numSubSamples = 10;    int subSampleSize = sampleSize / numSubSamples;    int currSample = -1;    for (int i = 0, j = 0; i < sampleSize; ++i, j = (j + 1) % subSampleSize) {        double us = 10 * rng.nextDouble();        sample.add(us);        sampleString.add(us + "");        if (j == 0) {            Sampler s = new UniformSampler(subSampleSize / 10);            samplers.add(s);            currSample++;        }        samplers.get(currSample).add(us);    }}
0
public void testValidInit_default() throws Exception
{    String stmt = "SAMPLE_INIT()";    Sampler s = (Sampler) StellarProcessorUtils.run(stmt, new HashMap<>());    Assert.assertEquals(Sampler.DEFAULT_SIZE, s.getSize());}
0
public void testValidInit_withSize() throws Exception
{    String stmt = "SAMPLE_INIT(size)";    Sampler s = (Sampler) StellarProcessorUtils.run(stmt, ImmutableMap.of("size", 10));    Assert.assertEquals(10, s.getSize());}
0
public void testInvalidInit()
{    String stmt = "SAMPLE_INIT(size)";    Sampler s = (Sampler) StellarProcessorUtils.run(stmt, ImmutableMap.of("size", -10));}
0
public void testGet() throws Exception
{    String stmt = "SAMPLE_GET(SAMPLE_ADD(SAMPLE_INIT(size), values))";    Iterable<? extends Object> s = (Iterable<? extends Object>) StellarProcessorUtils.run(stmt, ImmutableMap.of("size", 10, "values", sample));    Assert.assertEquals(10, Iterables.size(s));    for (Object o : s) {        Assert.assertTrue(o instanceof Double);        Assert.assertTrue(sample.contains(o));    }}
0
public void testAddSingle() throws Exception
{    String stmt = "SAMPLE_ADD(SAMPLE_INIT(size), value)";    Sampler s = (Sampler) StellarProcessorUtils.run(stmt, ImmutableMap.of("size", 10, "value", "blah"));    Assert.assertEquals(10, s.getSize());    Assert.assertTrue(Iterables.getFirst(s.get(), null) instanceof String);}
0
public void testAddAll() throws Exception
{    String stmt = "SAMPLE_ADD(SAMPLE_INIT(size), value)";    Sampler s = (Sampler) StellarProcessorUtils.run(stmt, ImmutableMap.of("size", 10, "value", sampleString));    Assert.assertEquals(10, s.getSize());    for (Object o : s.get()) {        Assert.assertTrue(o instanceof String);        Assert.assertTrue(sampleString.contains(o));    }}
0
public void testMerge() throws Exception
{    Double sampleMean = null;    Double mergedSampleMean = null;    {                String stmt = "STATS_MEAN(STATS_ADD(STATS_INIT(), SAMPLE_GET(SAMPLE_ADD(SAMPLE_INIT(size), values))))";        sampleMean = (Double) StellarProcessorUtils.run(stmt, ImmutableMap.of("size", sample.size() / 10, "values", sample));    }    {                String stmt = "STATS_MEAN(STATS_ADD(STATS_INIT(), SAMPLE_GET(SAMPLE_MERGE(samples))))";        mergedSampleMean = (Double) StellarProcessorUtils.run(stmt, ImmutableMap.of("samples", samplers));    }    Assert.assertEquals(sampleMean, mergedSampleMean, .1);    {                String stmt = "SAMPLE_MERGE(samples, SAMPLE_INIT(10))";        Sampler s = (Sampler) StellarProcessorUtils.run(stmt, ImmutableMap.of("samples", samplers));        Assert.assertEquals(10, s.getSize());    }}
0
public static void beforeClass()
{    Random rng = new Random(0);    GaussianRandomGenerator gen = new GaussianRandomGenerator(new MersenneTwister(0));    for (int i = 0; i < SAMPLE_SIZE; ++i) {        double us = 10 * rng.nextDouble();        uniformSample.add(us);        uniformStats.addValue(us);        double gs = 10 * gen.nextNormalizedDouble();        gaussianSample.add(gs);        gaussianStats.addValue(gs);    }}
0
public void testUniformDistributionIsPreserved()
{    Sampler s = new UniformSampler(SAMPLE_SIZE / 10);    s.addAll(uniformSample);    validateDistribution(s, uniformStats);}
0
public void testGaussianDistributionIsPreserved()
{    Sampler s = new UniformSampler(SAMPLE_SIZE / 10);    s.addAll(gaussianSample);    validateDistribution(s, gaussianStats);}
0
public void validateDistribution(Sampler sample, DescriptiveStatistics distribution)
{    DescriptiveStatistics s = new DescriptiveStatistics();    for (Object d : sample.get()) {        s.addValue((Double) d);    }    Assert.assertEquals(s.getMean(), distribution.getMean(), .1);    Assert.assertEquals(s.getStandardDeviation(), distribution.getStandardDeviation(), .1);}
0
public void testMergeUniform()
{    Iterable<Sampler> subsamples = getSubsamples(uniformSample);    Sampler s = SamplerUtil.INSTANCE.merge(subsamples, Optional.empty());    validateDistribution(s, uniformStats);}
0
public void testMerge()
{    UniformSampler sampler = new UniformSampler(10);    Iterable<Sampler> subsamples = getSubsamples(uniformSample);    Sampler s = SamplerUtil.INSTANCE.merge(subsamples, Optional.of(sampler));    Assert.assertEquals(s.getSize(), 10);}
0
public void testMergeGaussian()
{    Iterable<Sampler> subsamples = getSubsamples(gaussianSample);    Sampler s = SamplerUtil.INSTANCE.merge(subsamples, Optional.empty());    validateDistribution(s, gaussianStats);}
0
public Iterable<Sampler> getSubsamples(List<Double> sample)
{    int numSamplers = 20;    int numSamplesPerSampler = SAMPLE_SIZE / numSamplers;    Sampler[] samplers = new Sampler[numSamplers];    int j = 0;    for (int i = 0; i < numSamplers; ++i) {        samplers[i] = new UniformSampler(numSamplesPerSampler / 10);        for (; j < (i + 1) * numSamplesPerSampler && j < sample.size(); ++j) {            samplers[i].add(sample.get(j));        }    }    List<Sampler> ret = new ArrayList<>();    for (int i = 0; i < samplers.length; ++i) {        ret.add(samplers[i]);    }    return ret;}
0
public static void main(String... argv)
{    DescriptiveStatistics perfStats = new DescriptiveStatistics();    OnlineStatisticsProvider statsProvider = new OnlineStatisticsProvider();    List<Double> values = new ArrayList<>();    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(0L));    for (int i = 0; i < NUM_DATA_POINTS; ++i) {                double d = 1000 * gaussian.nextNormalizedDouble();        values.add(d);        statsProvider.addValue(d);    }    for (int perfRun = 0; perfRun < NUM_RUNS; ++perfRun) {        StellarStatisticsFunctions.StatsBin bin = new StellarStatisticsFunctions.StatsBin();        long start = System.currentTimeMillis();        Random r = new Random(0);        for (int i = 0; i < TRIALS_PER_RUN; ++i) {                        bin.apply(ImmutableList.of(statsProvider, values.get(r.nextInt(values.size())) - 3.5, PERCENTILES));        }        perfStats.addValue(System.currentTimeMillis() - start);    }    System.out.println("Min/25th/50th/75th/Max Milliseconds: " + perfStats.getMin() + " / " + perfStats.getPercentile(25) + " / " + perfStats.getPercentile(50) + " / " + perfStats.getPercentile(75) + " / " + perfStats.getMax());}
0
public static Collection<Object[]> data()
{        return Arrays.asList(new Object[][] { { 0 }, { 100 } });}
0
private static void tolerantAssertEquals(Function<StatisticsProvider, Number> func, StatisticsProvider left, StatisticsProvider right)
{    tolerantAssertEquals(func, left, right, null);}
0
private static void tolerantAssertEquals(Function<StatisticsProvider, Number> func, StatisticsProvider left, StatisticsProvider right, Double epsilon)
{    try {        Number leftVal = func.apply(left);        Number rightVal = func.apply(left);        if (epsilon != null) {            Assert.assertEquals((double) leftVal, (double) rightVal, epsilon);        } else {            Assert.assertEquals(leftVal, rightVal);        }    } catch (UnsupportedOperationException uoe) {        }}
0
private static Object run(String expr, Map<String, Object> variables)
{    StellarProcessor processor = new StellarProcessor();    Object ret = processor.parse(expr, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), Context.EMPTY_CONTEXT());    byte[] raw = SerDeUtils.toBytes(ret);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    if (ret instanceof StatisticsProvider) {        StatisticsProvider left = (StatisticsProvider) ret;        StatisticsProvider right = (StatisticsProvider) actual;                tolerantAssertEquals(prov -> prov.getCount(), left, right);                tolerantAssertEquals(prov -> prov.getSum(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getSumSquares(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getSumLogs(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getMean(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getQuadraticMean(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getStandardDeviation(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getVariance(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getMin(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getMax(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getKurtosis(), left, right, 1e-3);                tolerantAssertEquals(prov -> prov.getSkewness(), left, right, 1e-3);        for (double d = 10.0; d < 100.0; d += 10) {            final double pctile = d;                        tolerantAssertEquals(prov -> prov.getPercentile(pctile), left, right, 1e-2);        }    }    return ret;}
0
public void setup()
{    variables = new HashMap<>();        values = Arrays.asList(10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0);        stats = new DescriptiveStatistics(1000);    values.stream().forEach(val -> stats.addValue(val));        summaryStats = new SummaryStatistics();    values.stream().forEach(val -> summaryStats.addValue(val));}
0
private void statsInit(int windowSize)
{        Object result = run("STATS_INIT(" + windowSize + ")", variables);    assertNotNull(result);    variables.put("stats", result);        values.stream().forEach(val -> run(format("STATS_ADD (stats, %f)", val), variables));}
0
public void testOverflow() throws Exception
{    run(format("STATS_ADD(STATS_INIT(), %f)", (Double.MAX_VALUE + 1)), new HashMap<>());}
0
public void ensureDeterminism() throws Exception
{    for (int i = 0; i < 20; ++i) {        testMergeProviders();    }}
0
public void testMergeProviders() throws Exception
{    List<StatisticsProvider> providers = new ArrayList<>();    /*    Create 10 providers, each with a sample drawn from a gaussian distribution.    Update the reference stats from commons math to ensure we are     */    GaussianRandomGenerator gaussian = new GaussianRandomGenerator(new MersenneTwister(1L));    SummaryStatistics sStatistics = new SummaryStatistics();    DescriptiveStatistics dStatistics = new DescriptiveStatistics();    for (int i = 0; i < 10; ++i) {        List<Double> sample = new ArrayList<>();        for (int j = 0; j < 100; ++j) {            double s = gaussian.nextNormalizedDouble();            sample.add(s);            sStatistics.addValue(s);            dStatistics.addValue(s);        }        StatisticsProvider provider = (StatisticsProvider) run("STATS_ADD(STATS_INIT(), " + Joiner.on(",").join(sample) + ")", new HashMap<>());        providers.add(provider);    }    /*    Merge the providers and validate     */    Map<String, Object> providerVariables = new HashMap<>();    for (int i = 0; i < providers.size(); ++i) {        providerVariables.put("provider_" + i, providers.get(i));    }    StatisticsProvider mergedProvider = (StatisticsProvider) run("STATS_MERGE([" + Joiner.on(",").join(providerVariables.keySet()) + "])", providerVariables);    OnlineStatisticsProviderTest.validateStatisticsProvider(mergedProvider, sStatistics, dStatistics);}
0
public void testAddAllManyIntegers() throws Exception
{    statsInit(windowSize);    Object result = run("STATS_COUNT(stats)", variables);    double countAtStart = (double) result;    run("STATS_ADD(stats, [10, 20, 30, 40, 50])", variables);    Object actual = run("STATS_COUNT(stats)", variables);    assertEquals(countAtStart + 5.0, (double) actual, 0.1);}
0
public void testAddManyIntegers() throws Exception
{    statsInit(windowSize);    Object result = run("STATS_COUNT(stats)", variables);    double countAtStart = (double) result;    run("STATS_ADD(stats, 10, 20, 30, 40, 50)", variables);    Object actual = run("STATS_COUNT(stats)", variables);    assertEquals(countAtStart + 5.0, (double) actual, 0.1);}
0
public void testAllManyFloat() throws Exception
{    statsInit(windowSize);    Object result = run("STATS_COUNT(stats)", variables);    double countAtStart = (double) result;    run("STATS_ADD(stats, [10.0, 20.0, 30.0, 40.0, 50.0, null])", variables);    Object actual = run("STATS_COUNT(stats)", variables);    assertEquals(countAtStart + 5.0, (double) actual, 0.1);}
0
public void testAddManyFloats() throws Exception
{    statsInit(windowSize);    Object result = run("STATS_COUNT(stats)", variables);    double countAtStart = (double) result;    run("STATS_ADD(stats, 10.0, 20.0, 30.0, 40.0, 50.0)", variables);    Object actual = run("STATS_COUNT(stats)", variables);    assertEquals(countAtStart + 5.0, (double) actual, 0.1);}
0
public void testCount() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_COUNT(stats)", variables);    assertEquals(stats.getN(), (double) actual, 0.1);}
0
public void testMean() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_MEAN(stats)", variables);    assertEquals(stats.getMean(), (Double) actual, 0.1);}
0
public void testGeometricMean() throws Exception
{    if (windowSize > 0) {        statsInit(windowSize);        Object actual = run("STATS_GEOMETRIC_MEAN(stats)", variables);        assertEquals(stats.getGeometricMean(), (Double) actual, 0.1);    }}
0
public void testMax() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_MAX(stats)", variables);    assertEquals(stats.getMax(), (Double) actual, 0.1);}
0
public void testMin() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_MIN(stats)", variables);    assertEquals(stats.getMin(), (Double) actual, 0.1);}
0
public void testSum() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_SUM(stats)", variables);    assertEquals(stats.getSum(), (Double) actual, 0.1);}
0
public void testStandardDeviation() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_SD(stats)", variables);    assertEquals(stats.getStandardDeviation(), (Double) actual, 0.1);}
0
public void testVariance() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_VARIANCE(stats)", variables);    assertEquals(stats.getVariance(), (Double) actual, 0.1);}
0
public void testPopulationVariance() throws Exception
{    if (windowSize > 0) {        statsInit(windowSize);        Object actual = run("STATS_POPULATION_VARIANCE(stats)", variables);        assertEquals(stats.getPopulationVariance(), (Double) actual, 0.1);    }}
0
public void testQuadraticMean() throws Exception
{    if (windowSize > 0) {        statsInit(windowSize);        Object actual = run("STATS_QUADRATIC_MEAN(stats)", variables);        assertEquals(stats.getQuadraticMean(), (Double) actual, 0.1);    }}
0
public void testSumLogsNoWindow() throws Exception
{    statsInit(0);    Object actual = run("STATS_SUM_LOGS(stats)", variables);    assertEquals(summaryStats.getSumOfLogs(), (Double) actual, 0.1);}
0
public void testSumLogsWithWindow() throws Exception
{    statsInit(100);    run("STATS_SUM_LOGS(stats)", variables);}
0
public void testSumSquares() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_SUM_SQUARES(stats)", variables);    assertEquals(stats.getSumsq(), (Double) actual, 0.1);}
0
public void testKurtosis() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_KURTOSIS(stats)", variables);    assertEquals(stats.getKurtosis(), (Double) actual, 0.1);}
0
public void testSkewness() throws Exception
{    statsInit(windowSize);    Object actual = run("STATS_SKEWNESS(stats)", variables);    assertEquals(stats.getSkewness(), (Double) actual, 0.1);}
0
public void testStatsBin() throws Exception
{    statsInit(windowSize);    statsBinRunner(StellarStatisticsFunctions.StatsBin.BinSplits.QUARTILE.split);    statsBinRunner(StellarStatisticsFunctions.StatsBin.BinSplits.QUARTILE.split, "'QUARTILE'");    statsBinRunner(StellarStatisticsFunctions.StatsBin.BinSplits.QUINTILE.split, "'QUINTILE'");    statsBinRunner(StellarStatisticsFunctions.StatsBin.BinSplits.DECILE.split, "'DECILE'");    statsBinRunner(ImmutableList.of(25.0, 50.0, 75.0), "[25.0, 50.0, 75.0]");}
0
public void testStatsBin_singleValue() throws Exception
{    StatisticsProvider provider = (StatisticsProvider) run("STATS_INIT(" + windowSize + ")", variables);    provider.addValue(10);    variables.put("stats", provider);    Assert.assertEquals(0, run(format("STATS_BIN(stats, %f)", 9.0), variables));    Assert.assertEquals(0, run(format("STATS_BIN(stats, %f)", 10.0), variables));    Assert.assertEquals(3, run(format("STATS_BIN(stats, %f)", 11.0), variables));}
0
public void statsBinRunner(List<Number> splits) throws Exception
{    statsBinRunner(splits, null);}
0
public void statsBinRunner(List<Number> splits, String splitsName) throws Exception
{    int bin = 0;    StatisticsProvider provider = (StatisticsProvider) variables.get("stats");    for (Double d : stats.getSortedValues()) {        while (bin < splits.size() && d > provider.getPercentile(splits.get(bin).doubleValue())) {                        bin++;        }        Object actual = null;        if (splitsName != null) {            actual = run(format("STATS_BIN(stats, %f, %s)", d, splitsName), variables);        } else {            actual = run(format("STATS_BIN(stats, %f)", d), variables);        }        assertEquals(bin, actual);    }}
0
public void testPercentileNoWindow() throws Exception
{    statsInit(0);    final double percentile = 0.9;    Object actual = run(format("STATS_PERCENTILE(stats, %f)", percentile), variables);    assertEquals(stats.getPercentile(percentile), (Double) actual, 1);}
0
public void testPercentileWithWindow() throws Exception
{    statsInit(100);    final double percentile = 0.9;    Object actual = run(format("STATS_PERCENTILE(stats, %f)", percentile), variables);    assertEquals(stats.getPercentile(percentile), (Double) actual, 0.1);}
0
public void testWithNull() throws Exception
{    Object actual = run("STATS_MEAN(null)", variables);    assertTrue(((Double) actual).isNaN());    actual = run("STATS_COUNT(null)", variables);    assertTrue(((Double) actual).isNaN());    actual = run("STATS_VARIANCE(null)", variables);    assertTrue(((Double) actual).isNaN());}
0
public static void main(String[] args) throws Exception
{    CommandLine cli = LoadOptions.parse(new PosixParser(), args);    EnumMap<LoadOptions, Optional<Object>> evaluatedArgs = LoadOptions.createConfig(cli);    Map<String, Object> kafkaConfig = new HashMap<>();    kafkaConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());    kafkaConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());    kafkaConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());    kafkaConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());    if (LoadOptions.ZK.has(cli)) {        String zkQuorum = (String) evaluatedArgs.get(LoadOptions.ZK).get();        kafkaConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, Joiner.on(",").join(KafkaUtils.INSTANCE.getBrokersFromZookeeper(zkQuorum)));    }    String groupId = evaluatedArgs.get(LoadOptions.CONSUMER_GROUP).get().toString();    System.out.println("Consumer Group: " + groupId);    kafkaConfig.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);    if (LoadOptions.KAFKA_CONFIG.has(cli)) {        kafkaConfig.putAll((Map<String, Object>) evaluatedArgs.get(LoadOptions.KAFKA_CONFIG).get());    }    kafkaProducer = ThreadLocal.withInitial(() -> new KafkaProducer<>(kafkaConfig));    int numThreads = (int) evaluatedArgs.get(LoadOptions.NUM_THREADS).get();    System.out.println("Thread pool size: " + numThreads);    pool = Executors.newFixedThreadPool(numThreads);    Optional<Object> eps = evaluatedArgs.get(LoadOptions.EPS);    Optional<Object> outputTopic = evaluatedArgs.get(LoadOptions.OUTPUT_TOPIC);    Optional<Object> monitorTopic = evaluatedArgs.get(LoadOptions.MONITOR_TOPIC);    long sendDelta = (long) evaluatedArgs.get(LoadOptions.SEND_DELTA).get();    long monitorDelta = (long) evaluatedArgs.get(LoadOptions.MONITOR_DELTA).get();    if ((eps.isPresent() && outputTopic.isPresent()) || monitorTopic.isPresent()) {        Timer timer = new Timer(false);        long startTimeMs = System.currentTimeMillis();        if (outputTopic.isPresent() && eps.isPresent()) {            List<String> templates = (List<String>) evaluatedArgs.get(LoadOptions.TEMPLATE).get();            if (templates.isEmpty()) {                System.out.println("Empty templates, so nothing to do.");                return;            }            Optional<Object> biases = evaluatedArgs.get(LoadOptions.BIASED_SAMPLE);            Sampler sampler = new UnbiasedSampler();            if (biases.isPresent()) {                sampler = new BiasedSampler((List<Map.Entry<Integer, Integer>>) biases.get(), templates.size());            }            MessageGenerator generator = new MessageGenerator(templates, sampler);            Long targetLoad = (Long) eps.get();            int periodsPerSecond = (int) (1000 / sendDelta);            long messagesPerPeriod = targetLoad / periodsPerSecond;            String outputTopicStr = (String) outputTopic.get();            System.out.println("Generating data to " + outputTopicStr + " at " + targetLoad + " events per second");            System.out.println("Sending " + messagesPerPeriod + " messages to " + outputTopicStr + " every " + sendDelta + "ms");            timer.scheduleAtFixedRate(new SendToKafka(outputTopicStr, messagesPerPeriod, numThreads, generator, pool, numSent, kafkaProducer), 0, sendDelta);        }        List<AbstractMonitor> monitors = new ArrayList<>();        if (outputTopic.isPresent() && monitorTopic.isPresent()) {            System.out.println("Monitoring " + monitorTopic.get() + " every " + monitorDelta + " ms");            monitors.add(new EPSGeneratedMonitor(outputTopic, numSent));            monitors.add(new EPSThroughputWrittenMonitor(monitorTopic, kafkaConfig));        } else if (outputTopic.isPresent() && !monitorTopic.isPresent()) {            System.out.println("Monitoring " + outputTopic.get() + " every " + monitorDelta + " ms");            monitors.add(new EPSGeneratedMonitor(outputTopic, numSent));            monitors.add(new EPSThroughputWrittenMonitor(outputTopic, kafkaConfig));        } else if (!outputTopic.isPresent() && monitorTopic.isPresent()) {            System.out.println("Monitoring " + monitorTopic.get() + " every " + monitorDelta + " ms");            monitors.add(new EPSThroughputWrittenMonitor(monitorTopic, kafkaConfig));        } else if (!outputTopic.isPresent() && !monitorTopic.isPresent()) {            System.out.println("You have not specified an output topic or a monitoring topic, so I have nothing to do here.");        }        int lookback = (int) evaluatedArgs.get(LoadOptions.SUMMARY_LOOKBACK).get();        if (lookback > 0) {            System.out.println("Summarizing over the last " + lookback + " monitoring periods (" + lookback * monitorDelta + "ms)");        } else {            System.out.println("Turning off summarization.");        }        final CSVWriter csvWriter = new CSVWriter((File) evaluatedArgs.get(LoadOptions.CSV).orElse(null));        Writer writer = new Writer(monitors, lookback, new ArrayList<Consumer<Writable>>() {            {                add(new ConsoleWriter());                add(csvWriter);            }        });        timer.scheduleAtFixedRate(new MonitorTask(writer), 0, monitorDelta);        Optional<Object> timeLimit = evaluatedArgs.get(LoadOptions.TIME_LIMIT);        if (timeLimit.isPresent()) {            System.out.println("Ending in " + timeLimit.get() + " ms.");            timer.schedule(new TimerTask() {                @Override                public void run() {                    timer.cancel();                    long durationS = (System.currentTimeMillis() - startTimeMs) / 1000;                    System.out.println("\nGenerated " + numSent.get() + " in " + durationS + " seconds.");                    csvWriter.close();                    System.exit(0);                }            }, (Long) timeLimit.get());        }    }}
0
public void run()
{    timer.cancel();    long durationS = (System.currentTimeMillis() - startTimeMs) / 1000;    System.out.println("\nGenerated " + numSent.get() + " in " + durationS + " seconds.");    csvWriter.close();    System.exit(0);}
0
public Option getOption()
{    return option;}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public OptionHandler<LoadOptions> getHandler()
{    return null;}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
0
public static EnumMap<LoadOptions, Optional<Object>> createConfig(CommandLine cli)
{    EnumMap<LoadOptions, Optional<Object>> ret = new EnumMap<>(LoadOptions.class);    for (LoadOptions option : values()) {        ret.put(option, option.handler.getValue(option, cli));    }    return ret;}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("Generator", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (LoadOptions o : LoadOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public String getShortCode()
{    return "h";}
0
public Option apply(@Nullable String s)
{    return new Option(s, "help", false, "Generate Help screen");}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "zk_quorum", true, "zookeeper quorum");    o.setArgName("QUORUM");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (option.has(cli)) {        return Optional.ofNullable(option.get(cli));    } else {        return Optional.empty();    }}
0
public String getShortCode()
{    return "z";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "consumer_group", true, "Consumer Group.  The default is " + LoadGenerator.CONSUMER_GROUP);    o.setArgName("GROUP_ID");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (option.has(cli)) {        return Optional.ofNullable(option.get(cli));    } else {        return Optional.of(LoadGenerator.CONSUMER_GROUP);    }}
0
public String getShortCode()
{    return "cg";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "sample_bias", true, "The discrete distribution to bias the sampling. " + "This is a CSV of 2 columns.  The first column is the % of the templates " + "and the 2nd column is the probability (0-100) that it's chosen.  For instance:\n" + "  20,80\n" + "  80,20\n" + "implies that 20% of the templates will comprise 80% of the output and the remaining 80% of the templates will comprise 20% of the output.");    o.setArgName("BIAS_FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (!option.has(cli)) {        return Optional.empty();    }    File discreteDistributionFile = new File(option.get(cli));    if (discreteDistributionFile.exists()) {        try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(discreteDistributionFile), StandardCharsets.UTF_8))) {            return Optional.ofNullable(BiasedSampler.readDistribution(br));        } catch (IOException e) {            throw new IllegalStateException("Unable to read distribution file: " + option.get(cli), e);        }    } else {        throw new IllegalStateException("Unable to read distribution file: " + option.get(cli) + " file doesn't exist.");    }}
0
public String getShortCode()
{    return "bs";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "csv", true, "A CSV file to emit monitoring data to.  " + "The format is a CSV with the following schema: timestamp, (name, eps, historical_mean, historical_stddev)+");    o.setArgName("CSV_FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (!option.has(cli)) {        return Optional.empty();    }    return Optional.of(new File(option.get(cli)));}
0
public String getShortCode()
{    return "c";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "template", true, "The template file to use for generation.  This should be a file with a template per line with $METRON_TS and $METRON_GUID in the spots for timestamp and guid, if you so desire them.");    o.setArgName("TEMPLATE_FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (!option.has(cli)) {        return Optional.empty();    }    File templateFile = new File(option.get(cli));    if (templateFile.exists()) {        List<String> templates = new ArrayList<>();        try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(templateFile), StandardCharsets.UTF_8))) {            for (String line = null; (line = br.readLine()) != null; ) {                templates.add(line);            }            return Optional.of(templates);        } catch (IOException e) {            throw new IllegalStateException("Unable to read template file: " + option.get(cli), e);        }    } else {        throw new IllegalStateException("Unable to read template file: " + option.get(cli) + " file doesn't exist.");    }}
0
public String getShortCode()
{    return "t";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "lookback", true, "When summarizing, how many monitoring periods should we summarize over?  If 0, then no summary.  Default: 5");    o.setArgName("LOOKBACK");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (option.has(cli)) {        return Optional.of(ConversionUtils.convert(option.get(cli), Integer.class));    } else {        return Optional.of(5);    }}
0
public String getShortCode()
{    return "l";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "eps", true, "The target events per second");    o.setArgName("EPS");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (option.has(cli)) {        return Optional.of(ConversionUtils.convert(option.get(cli), Long.class));    } else {        return Optional.empty();    }}
0
public String getShortCode()
{    return "e";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "kafka_config", true, "The kafka config.  This is a file containing a JSON map with the kafka config.");    o.setArgName("CONFIG_FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (!option.has(cli)) {        return Optional.empty();    }    File configFile = new File(option.get(cli));    if (configFile.exists()) {        try {            return Optional.ofNullable(JSONUtils.INSTANCE.load(configFile, JSONUtils.MAP_SUPPLIER));        } catch (FileNotFoundException e) {            throw new IllegalStateException("Unable to read file: " + option.get(cli), e);        } catch (IOException e) {            throw new IllegalStateException("Unable to read file: " + option.get(cli), e);        }    } else {        throw new IllegalStateException("Unable to read file: " + option.get(cli) + " file doesn't exist.");    }}
0
public String getShortCode()
{    return "k";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "send_delta_ms", true, "The time (in ms) between sending a batch of messages. Default is " + LoadGenerator.SEND_PERIOD_MS);    o.setArgName("TIME_IN_MS");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (option.has(cli)) {        Object res = option.get(cli);        return Optional.ofNullable(ConversionUtils.convert(res, Long.class));    }    return Optional.of(LoadGenerator.SEND_PERIOD_MS);}
0
public String getShortCode()
{    return "sd";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "monitor_delta_ms", true, "The time (in ms) between monitoring output. Default is " + LoadGenerator.MONITOR_PERIOD_MS);    o.setArgName("TIME_IN_MS");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (option.has(cli)) {        Object res = option.get(cli);        return Optional.ofNullable(ConversionUtils.convert(res, Long.class));    }    return Optional.of(LoadGenerator.MONITOR_PERIOD_MS);}
0
public String getShortCode()
{    return "md";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "time_limit_ms", true, "The total amount of time to run this in milliseconds.  By default, it never stops.");    o.setArgName("MS");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    if (option.has(cli)) {        Object res = option.get(cli);        Long timeMs = ConversionUtils.convert(res, Long.class);        return Optional.ofNullable(timeMs);    }    return Optional.empty();}
0
public String getShortCode()
{    return "tl";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "threads", true, "The number of threads to use when extracting data.  The default is the number of cores of your machine.");    o.setArgName("NUM_THREADS");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    int numThreads = Runtime.getRuntime().availableProcessors();    if (option.has(cli)) {        Object res = option.get(cli);        if (res instanceof String && res.toString().toUpperCase().endsWith("C")) {            numThreads *= ConversionUtils.convert(res.toString().trim().replace("C", ""), Integer.class);        } else {            numThreads = ConversionUtils.convert(res, Integer.class);        }    }    return Optional.of(numThreads);}
0
public String getShortCode()
{    return "p";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "output_topic", true, "The kafka topic to write to");    o.setArgName("TOPIC");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli));}
0
public String getShortCode()
{    return "ot";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "monitor_topic", true, "The kafka topic to monitor.");    o.setArgName("TOPIC");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli));}
0
public String getShortCode()
{    return "mt";}
0
public String get()
{    int sample = sampler.sample(rng.get(), patterns.size());    String pattern = patterns.get(sample);    long guidId = guidOffset.getAndIncrement();    String guid = guidPrefix + guidId;    String ts = "" + System.currentTimeMillis();    return pattern.replace("$METRON_TS", ts).replace("$METRON_GUID", guid);}
0
public Long get()
{    long timeStarted = System.currentTimeMillis();    Long ret = null;    if (timestampPrevious > 0) {        double deltaTs = (timeStarted - timestampPrevious) / 1000.0;        if (Math.abs(deltaTs) > EPSILON) {            ret = monitor(deltaTs);        }    }    timestampPrevious = timeStarted;    return ret;}
0
protected Long monitor(double deltaTs)
{    if (kafkaTopic.isPresent()) {        long totalProcessed = numSent.get();        long written = (totalProcessed - numSentPrevious);        long epsWritten = (long) (written / deltaTs);        numSentPrevious = totalProcessed;        return epsWritten;    }    return null;}
0
public String format()
{    return "%d eps generated to " + kafkaTopic.get();}
0
public String name()
{    return "generated";}
0
private Long writtenSince(Map<Integer, Long> partitionOffsets, Map<Integer, Long> lastOffsetMap)
{    if (partitionOffsets == null) {        return null;    }    long sum = 0;    for (Map.Entry<Integer, Long> partitionOffset : partitionOffsets.entrySet()) {        sum += partitionOffset.getValue() - lastOffsetMap.get(partitionOffset.getKey());    }    return sum;}
0
protected Long monitor(double deltaTs)
{    Optional<Long> epsWritten = Optional.empty();    if (kafkaTopic.isPresent()) {        if (lastOffsetMap != null) {            Map<Integer, Long> currentOffsets = KafkaUtil.INSTANCE.getKafkaOffsetMap(consumer, (String) kafkaTopic.get());            Long eventsWrittenSince = writtenSince(currentOffsets, lastOffsetMap);            if (eventsWrittenSince != null) {                epsWritten = Optional.of((long) (eventsWrittenSince / deltaTs));            }            lastOffsetMap = currentOffsets == null ? lastOffsetMap : currentOffsets;            if (epsWritten.isPresent()) {                return epsWritten.get();            }        } else {            lastOffsetMap = KafkaUtil.INSTANCE.getKafkaOffsetMap(consumer, (String) kafkaTopic.get());        }    }    return null;}
0
public String format()
{    return "%d eps throughput measured for " + kafkaTopic.get();}
0
public String name()
{    return "throughput measured";}
0
public void run()
{    writer.writeAll();}
0
public String getName()
{    return name;}
0
public Long getEps()
{    return eps;}
0
public String getFormat()
{    return format;}
0
public Optional<DescriptiveStatistics> getHistory()
{    return history;}
0
private String getSummary(DescriptiveStatistics stats)
{    return String.format("Mean: %d, Std Dev: %d", (int) stats.getMean(), (int) Math.sqrt(stats.getVariance()));}
0
public void accept(Writable writable)
{    List<String> parts = new ArrayList<>();    Date date = writable.getDate();    for (Results r : writable.getResults()) {        Long eps = r.getEps();        if (eps != null) {            String part = String.format(r.getFormat(), eps);            if (r.getHistory().isPresent()) {                part += " (" + getSummary(r.getHistory().get()) + ")";            }            parts.add(part);        }    }    if (date != null) {        DateFormat dateFormat = new SimpleDateFormat("yyyy/MM/dd HH:mm:ss");        String header = dateFormat.format(date) + " - ";        String emptyHeader = StringUtils.repeat(" ", header.length());        for (int i = 0; i < parts.size(); ++i) {            String part = parts.get(i);            if (i == 0) {                System.out.println(header + (part == null ? "" : part));            } else {                System.out.println(emptyHeader + (part == null ? "" : part));            }        }    }}
0
public void accept(Writable writable)
{    if (pw.isPresent()) {        List<String> parts = new ArrayList<>();        parts.add("" + writable.getDate().getTime());        for (Results r : writable.getResults()) {            parts.add(r.getName());            parts.add(r.getEps() == null ? "" : (r.getEps() + ""));            if (r.getHistory().isPresent()) {                parts.add("" + (int) r.getHistory().get().getMean());                parts.add("" + (int) Math.sqrt(r.getHistory().get().getVariance()));            } else {                parts.add("");                parts.add("");            }        }        pw.get().println(Joiner.on(",").join(parts));        pw.get().flush();    }}
0
public void close()
{    if (pw.isPresent()) {        pw.get().close();    }}
0
public Date getDate()
{    return date;}
0
public List<Results> getResults()
{    return results;}
0
public void writeAll()
{    int i = 0;    Date dateOf = new Date();    List<Results> results = new ArrayList<>();    for (AbstractMonitor m : monitors) {        Long eps = m.get();        if (eps != null && summaryLookback > 0) {            LinkedList<Double> summary = summaries.get(i);            addToLookback(eps.doubleValue(), summary);            results.add(new Results(m.format(), m.name(), eps, Optional.of(getStats(summary))));        } else {            results.add(new Results(m.format(), m.name(), eps, Optional.empty()));        }        i++;    }    Writable writable = new Writable(dateOf, results);    for (Consumer<Writable> writer : writers) {        writer.accept(writable);    }}
0
private void addToLookback(Double d, LinkedList<Double> lookback)
{    if (lookback.size() >= summaryLookback) {        lookback.removeFirst();    }    lookback.addLast(d);}
0
public DescriptiveStatistics getStats(List<Double> avg)
{    DescriptiveStatistics stats = new DescriptiveStatistics();    for (Double d : avg) {        if (d == null || Double.isNaN(d)) {            continue;        }        stats.addValue(d);    }    return stats;}
0
public void run()
{    long numSentCurrent = numSent.get();    long numSentSince = numSentCurrent - numSentLast;    boolean sendMessages = numSentLast == 0 || numSentSince >= numMessagesSent;    if (sendMessages) {        Collection<Future<Long>> futures = Collections.synchronizedList(new ArrayList<>());        for (int batch = 0; batch < numBatches; ++batch) {            try {                futures.add(pool.submit(() -> {                    KafkaProducer<String, String> producer = kafkaProducer.get();                    Collection<Future<?>> b = Collections.synchronizedCollection(new ArrayList<>());                    for (int i = 0; i < batchSize; ++i) {                        b.add(sendToKafka(producer, kafkaTopic, messageSupplier.get()));                    }                    for (Future<?> f : b) {                        f.get();                    }                    return batchSize;                }));            } catch (Exception e) {                e.printStackTrace(System.err);            }        }        for (Future<Long> f : futures) {            try {                f.get();            } catch (Exception e) {                e.printStackTrace(System.err);            }        }        numSentLast = numSentCurrent;    }}
0
protected Future<?> sendToKafka(KafkaProducer<String, String> producer, String kafkaTopic, String message)
{    return producer.send(new ProducerRecord<>(kafkaTopic, message), (recordMetadata, e) -> {        if (e != null) {            e.printStackTrace(System.err);        }        numSent.incrementAndGet();    });}
0
public static List<Map.Entry<Integer, Integer>> readDistribution(BufferedReader distrFile) throws IOException
{    return readDistribution(distrFile, false);}
0
public static List<Map.Entry<Integer, Integer>> readDistribution(BufferedReader distrFile, boolean quiet) throws IOException
{    List<Map.Entry<Integer, Integer>> ret = new ArrayList<>();    if (!quiet) {        System.out.println("Using biased sampler with the following biases:");    }    int sumLeft = 0;    int sumRight = 0;    for (String line = null; (line = distrFile.readLine()) != null; ) {        if (line.startsWith("#")) {            continue;        }        Iterable<String> it = Splitter.on(",").split(line.trim());        if (Iterables.size(it) != 2) {            throw new IllegalArgumentException(line + " should be a comma separated pair of integers, but was not.");        }        int left = Integer.parseInt(Iterables.getFirst(it, null));        int right = Integer.parseInt(Iterables.getLast(it, null));        if (left <= 0 || left > 100) {            throw new IllegalArgumentException(line + ": " + (left < 0 ? left : right) + " must a positive integer in (0, 100]");        }        if (right <= 0 || right > 100) {            throw new IllegalArgumentException(line + ": " + right + " must a positive integer in (0, 100]");        }        if (!quiet) {            System.out.println("\t" + left + "% of templates will comprise roughly " + right + "% of sample output");        }        ret.add(new AbstractMap.SimpleEntry<>(left, right));        sumLeft += left;        sumRight += right;    }    if (sumLeft > 100 || sumRight > 100) {        throw new IllegalStateException("Neither columns must sum to beyond 100.  " + "The first column is the % of templates. " + "The second column is the % of the sample that % of template occupies.");    } else if (sumLeft < 100 && sumRight < 100) {        int left = 100 - sumLeft;        int right = 100 - sumRight;        if (!quiet) {            System.out.println("\t" + left + "% of templates will comprise roughly " + right + "% of sample output");        }        ret.add(new AbstractMap.SimpleEntry<>(left, right));    }    return ret;}
0
private static TreeMap<Double, Map.Entry<Integer, Integer>> createDistribution(List<Map.Entry<Integer, Integer>> discreteDistribution, int max)
{    TreeMap<Double, Map.Entry<Integer, Integer>> ret = new TreeMap<>();    int from = 0;    double weight = 0.0d;    for (Map.Entry<Integer, Integer> kv : discreteDistribution) {        double pctVals = kv.getKey() / 100.0;        int to = from + (int) (max * pctVals);        double pctWeight = kv.getValue() / 100.0;        ret.put(weight, new AbstractMap.SimpleEntry<>(from, to));        weight += pctWeight;        from = to;    }    return ret;}
0
public int sample(Random rng, int limit)
{    double weight = rng.nextDouble();    Map.Entry<Integer, Integer> range = discreteDistribution.floorEntry(weight).getValue();    return rng.nextInt(range.getValue() - range.getKey()) + range.getKey();}
0
public int sample(Random rng, int limit)
{    return rng.nextInt(limit);}
0
public List<TopicPartition> getTopicPartition(KafkaConsumer<String, String> consumer, String topic)
{    List<PartitionInfo> partitions = consumer.partitionsFor(topic);    List<TopicPartition> ret = new ArrayList<>(partitions.size());    for (PartitionInfo par : partitions) {        ret.add(new TopicPartition(topic, par.partition()));    }    return ret;}
0
public Map<Integer, Long> getKafkaOffsetMap(KafkaConsumer<String, String> consumer, String topic)
{    Map<Integer, Long> ret = new HashMap<>();    if (!consumer.subscription().contains(topic)) {        consumer.subscribe(Collections.singletonList(topic));    }    consumer.poll(0);    List<TopicPartition> partitions = getTopicPartition(consumer, topic);    consumer.seekToEnd(partitions);    for (TopicPartition par : partitions) {        ret.put(par.partition(), consumer.position(par) - 1);    }    return ret;}
0
public void testHappyPath() throws Exception
{    CommandLine cli = LoadOptions.parse(new PosixParser(), new String[] { "-eps", "1000", "-ot", "foo" });    EnumMap<LoadOptions, Optional<Object>> results = LoadOptions.createConfig(cli);    Assert.assertEquals(1000L, results.get(LoadOptions.EPS).get());    Assert.assertEquals("foo", results.get(LoadOptions.OUTPUT_TOPIC).get());    Assert.assertEquals(LoadGenerator.CONSUMER_GROUP, results.get(LoadOptions.CONSUMER_GROUP).get());    Assert.assertEquals(Runtime.getRuntime().availableProcessors(), results.get(LoadOptions.NUM_THREADS).get());    Assert.assertFalse(results.get(LoadOptions.BIASED_SAMPLE).isPresent());    Assert.assertFalse(results.get(LoadOptions.CSV).isPresent());}
0
public void testCsvPresent() throws Exception
{    CommandLine cli = LoadOptions.parse(new PosixParser(), new String[] { "-c", "/tmp/blah" });    EnumMap<LoadOptions, Optional<Object>> results = LoadOptions.createConfig(cli);    Assert.assertEquals(new File("/tmp/blah"), results.get(LoadOptions.CSV).get());}
0
public void testCsvMissing() throws Exception
{    CommandLine cli = LoadOptions.parse(new PosixParser(), new String[] {});    EnumMap<LoadOptions, Optional<Object>> results = LoadOptions.createConfig(cli);    Assert.assertFalse(results.get(LoadOptions.CSV).isPresent());}
0
public void testThreadsByCores() throws Exception
{    CommandLine cli = LoadOptions.parse(new PosixParser(), new String[] { "-p", "2C" });    EnumMap<LoadOptions, Optional<Object>> results = LoadOptions.createConfig(cli);    Assert.assertEquals(2 * Runtime.getRuntime().availableProcessors(), results.get(LoadOptions.NUM_THREADS).get());}
0
public void testThreadsByNum() throws Exception
{    CommandLine cli = LoadOptions.parse(new PosixParser(), new String[] { "-p", "5" });    EnumMap<LoadOptions, Optional<Object>> results = LoadOptions.createConfig(cli);    Assert.assertEquals(5, results.get(LoadOptions.NUM_THREADS).get());}
0
public void testTemplatePresent() throws Exception
{    File templateFile = new File("target/template");    String template = "test template1";    try (BufferedWriter w = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(templateFile), StandardCharsets.UTF_8))) {        IOUtils.write(template, w);    }    templateFile.deleteOnExit();    CommandLine cli = LoadOptions.parse(new PosixParser(), new String[] { "-t", templateFile.getPath() });    EnumMap<LoadOptions, Optional<Object>> results = LoadOptions.createConfig(cli);    List<String> templates = (List<String>) results.get(LoadOptions.TEMPLATE).get();    Assert.assertEquals(1, templates.size());    Assert.assertEquals(template, templates.get(0));}
0
public void testTemplateMissing() throws Exception
{    LoadOptions.createConfig(LoadOptions.parse(new PosixParser(), new String[] { "-t", "target/template2" }));}
0
public void testWritesCorrectNumber()
{    ExecutorService executor = ForkJoinPool.commonPool();    AtomicLong numSent = new AtomicLong(0);    long expectedSent = 100;    SendToKafka sender = new SendToKafka(null, expectedSent, 10, () -> "msg", executor, numSent, ThreadLocal.withInitial(() -> null)) {        @Override        protected Future<?> sendToKafka(KafkaProducer producer, String kafkaTopic, String message) {            Assert.assertEquals(message, "msg");            return ForkJoinPool.commonPool().submit(() -> {                numSent.incrementAndGet();            });        }    };    sender.run();    Assert.assertEquals(numSent.get(), expectedSent);}
0
protected Future<?> sendToKafka(KafkaProducer producer, String kafkaTopic, String message)
{    Assert.assertEquals(message, "msg");    return ForkJoinPool.commonPool().submit(() -> {        numSent.incrementAndGet();    });}
0
private void testSampler(Sampler sampler, Map<Integer, Double> expectedProbs)
{    Random rng = new Random(0);    Map<Integer, Double> empiricalProbs = new HashMap<>();    for (int i = 0; i < SIMULATION_SIZE; ++i) {        int sample = sampler.sample(rng, 10);        Double cnt = empiricalProbs.get(sample);        empiricalProbs.put(sample, ((cnt == null) ? 0 : cnt) + 1);    }    for (Map.Entry<Integer, Double> kv : empiricalProbs.entrySet()) {        double empiricalProb = kv.getValue() / SIMULATION_SIZE;        String msg = expectedProbs.get(kv.getKey()) + " != " + empiricalProb;        Assert.assertEquals(msg, expectedProbs.get(kv.getKey()), empiricalProb, 1e-2);    }}
0
public void testUnbiasedSampler()
{    Sampler sampler = new UnbiasedSampler();    testSampler(sampler, new HashMap<Integer, Double>() {        {            for (int i = 0; i < 10; ++i) {                put(i, 0.1);            }        }    });}
0
public void testBiasedSampler()
{    Sampler sampler = new BiasedSampler(new ArrayList<Map.Entry<Integer, Integer>>() {        {            add(new AbstractMap.SimpleEntry<>(30, 80));            add(new AbstractMap.SimpleEntry<>(70, 20));        }    }, 10);    testSampler(sampler, new HashMap<Integer, Double>() {        {            for (int i = 0; i < 3; ++i) {                put(i, 0.8 / 3);            }            for (int i = 3; i < 10; ++i) {                put(i, 0.2 / 7);            }        }    });}
0
public void testDistributionRead() throws IOException
{    for (String config : ImmutableList.of(paretoConfig, paretoConfigImplicit)) {        List<Map.Entry<Integer, Integer>> endpoints = BiasedSampler.readDistribution(new BufferedReader(new StringReader(config)), true);        Assert.assertEquals(2, endpoints.size());        Assert.assertEquals(new AbstractMap.SimpleEntry<>(80, 20), endpoints.get(0));        Assert.assertEquals(new AbstractMap.SimpleEntry<>(20, 80), endpoints.get(1));    }}
0
public void testDistributionReadLonger() throws IOException
{    for (String config : ImmutableList.of(longerConfig, longerConfigImplicit)) {        List<Map.Entry<Integer, Integer>> endpoints = BiasedSampler.readDistribution(new BufferedReader(new StringReader(config)), true);        Assert.assertEquals(3, endpoints.size());        Assert.assertEquals(new AbstractMap.SimpleEntry<>(80, 20), endpoints.get(0));        Assert.assertEquals(new AbstractMap.SimpleEntry<>(10, 70), endpoints.get(1));        Assert.assertEquals(new AbstractMap.SimpleEntry<>(10, 10), endpoints.get(2));    }}
0
public void testDistributionRead_garbage() throws IOException
{    BiasedSampler.readDistribution(new BufferedReader(new StringReader("blah foo")), true);}
0
public void testDistributionRead_negative() throws IOException
{    BiasedSampler.readDistribution(new BufferedReader(new StringReader("80,-20")), true);}
0
public void testDistributionRead_over100() throws IOException
{    BiasedSampler.readDistribution(new BufferedReader(new StringReader("200,20")), true);}
0
public Grok commonGrok() throws GrokException
{    Grok grok = new Grok();    grok.addPatternFromReader(new InputStreamReader(getClass().getResourceAsStream("/patterns/common"), StandardCharsets.UTF_8));    return grok;}
0
public org.apache.hadoop.conf.Configuration configuration() throws IOException
{    org.apache.hadoop.conf.Configuration configuration = new org.apache.hadoop.conf.Configuration();    if (environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)) {        UserGroupInformation.setConfiguration(configuration);        String keyTabLocation = environment.getProperty(MetronRestConstants.KERBEROS_KEYTAB_SPRING_PROPERTY);        String userPrincipal = environment.getProperty(MetronRestConstants.KERBEROS_PRINCIPLE_SPRING_PROPERTY);        UserGroupInformation.loginUserFromKeytab(userPrincipal, keyTabLocation);    }    return configuration;}
0
public UserSettingsClient userSettingsClient()
{    UserSettingsClient userSettingsClient = new UserSettingsClient();    userSettingsClient.init(() -> {        try {            return globalConfigService.get();        } catch (RestException e) {            throw new IllegalStateException("Unable to retrieve the global config.", e);        }    }, new HTableProvider());    return userSettingsClient;}
0
public HBaseClient hBaseClient()
{    Map<String, Object> restConfig = null;    try {        restConfig = globalConfigService.get();    } catch (RestException e) {        throw new IllegalStateException("Unable to retrieve the global config.", e);    }    TableProvider provider = null;    try {        provider = TableProvider.create((String) restConfig.get(EnrichmentConfigurations.TABLE_PROVIDER), HTableProvider::new);    } catch (ClassNotFoundException | InstantiationException | InvocationTargetException | IllegalAccessException | NoSuchMethodException e) {        throw new IllegalStateException("Unable to create table provider", e);    }    return new HBaseClient(provider, HBaseConfiguration.create(), (String) restConfig.get(EnrichmentConfigurations.TABLE_NAME));}
0
public IndexDao indexDao()
{    try {        String hbaseProviderImpl = environment.getProperty(MetronRestConstants.INDEX_HBASE_TABLE_PROVIDER_IMPL, String.class, null);        String indexDaoImpl = environment.getProperty(MetronRestConstants.INDEX_DAO_IMPL, String.class, null);        int searchMaxResults = environment.getProperty(MetronRestConstants.SEARCH_MAX_RESULTS, Integer.class, 1000);        int searchMaxGroups = environment.getProperty(MetronRestConstants.SEARCH_MAX_GROUPS, Integer.class, 1000);        String metaDaoImpl = environment.getProperty(MetronRestConstants.META_DAO_IMPL, String.class, null);        String metaDaoSort = environment.getProperty(MetronRestConstants.META_DAO_SORT, String.class, null);        AccessConfig config = new AccessConfig();        config.setMaxSearchResults(searchMaxResults);        config.setMaxSearchGroups(searchMaxGroups);        config.setGlobalConfigSupplier(() -> {            try {                return globalConfigService.get();            } catch (RestException e) {                throw new IllegalStateException("Unable to retrieve the global config.", e);            }        });        config.setIndexSupplier(IndexingCacheUtil.getIndexLookupFunction(cache, environment.getProperty(INDEX_WRITER_NAME)));        config.setTableProvider(TableProvider.create(hbaseProviderImpl, () -> new HTableProvider()));        config.setKerberosEnabled(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false));        if (indexDaoImpl == null) {            throw new IllegalStateException("You must provide an index DAO implementation via the " + INDEX_DAO_IMPL + " config");        }        IndexDao indexDao = IndexDaoFactory.combine(IndexDaoFactory.create(indexDaoImpl, config));        if (indexDao == null) {            throw new IllegalStateException("IndexDao is unable to be created.");        }        if (metaDaoImpl == null) {                        return indexDao;        }                MetaAlertDao ret = (MetaAlertDao) IndexDaoFactory.create(metaDaoImpl, config).get(0);        ret.init(indexDao, Optional.ofNullable(metaDaoSort));        return ret;    } catch (RuntimeException re) {        throw re;    } catch (Exception e) {        throw new IllegalStateException("Unable to create index DAO: " + e.getMessage(), e);    }}
0
protected AbstractJpaVendorAdapter createJpaVendorAdapter()
{    return new EclipseLinkJpaVendorAdapter();}
0
protected Map<String, Object> getVendorProperties()
{    return Collections.singletonMap("eclipselink.weaving", "false");}
0
public ZkUtils zkUtils()
{    return ZkUtils.apply(zkClient, false);}
0
public Map<String, Object> consumerProperties()
{    final Map<String, Object> props = new HashMap<>();    props.put("bootstrap.servers", environment.getProperty(MetronRestConstants.KAFKA_BROKER_URL_SPRING_PROPERTY));    props.put("group.id", "metron-rest");    props.put("enable.auto.commit", "false");    props.put("auto.commit.interval.ms", "1000");    props.put("session.timeout.ms", "30000");    props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");    props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");    if (environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)) {        props.put("security.protocol", KafkaUtils.INSTANCE.normalizeProtocol(environment.getProperty(MetronRestConstants.KAFKA_SECURITY_PROTOCOL_SPRING_PROPERTY)));    }    return props;}
0
public ConsumerFactory<String, String> createConsumerFactory()
{    return new DefaultKafkaConsumerFactory<>(consumerProperties());}
0
public Map<String, Object> producerProperties()
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", environment.getProperty(MetronRestConstants.KAFKA_BROKER_URL_SPRING_PROPERTY));    producerConfig.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");    producerConfig.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");    producerConfig.put("request.required.acks", 1);    if (environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)) {        producerConfig.put("security.protocol", KafkaUtils.INSTANCE.normalizeProtocol(environment.getProperty(MetronRestConstants.KAFKA_SECURITY_PROTOCOL_SPRING_PROPERTY)));    }    return producerConfig;}
0
public KafkaProducer kafkaProducer()
{    return new KafkaProducer<>(producerProperties());}
0
public AdminUtils$ adminUtils()
{    return AdminUtils$.MODULE$;}
0
public void init(FilterConfig filterConfig)
{}
0
public void destroy()
{}
0
public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException
{    HttpServletRequest httpRequest = (HttpServletRequest) request;        String authHeader = httpRequest.getHeader("Authorization");    if (authHeader == null || !authHeader.startsWith("Basic")) {        String serializedJWT = getJWTFromCookie(httpRequest);        if (serializedJWT != null) {            SignedJWT jwtToken;            try {                jwtToken = SignedJWT.parse(serializedJWT);                String userName = jwtToken.getJWTClaimsSet().getSubject();                                if (isValid(jwtToken, userName)) {                    Authentication authentication = getAuthentication(userName, httpRequest);                    SecurityContextHolder.getContext().setAuthentication(authentication);                }            } catch (ParseException e) {                            }        }    }    chain.doFilter(request, response);}
1
protected boolean isValid(SignedJWT jwtToken, String userName) throws ParseException
{        if (userName == null || userName.isEmpty()) {                return false;    }    Date now = new Date();        Date expirationTime = jwtToken.getJWTClaimsSet().getExpirationTime();    if (expirationTime != null && now.after(expirationTime)) {                return false;    }        Date notBeforeTime = jwtToken.getJWTClaimsSet().getNotBeforeTime();    if (notBeforeTime != null && now.before(notBeforeTime)) {                return false;    }    return validateSignature(jwtToken);}
1
protected boolean validateSignature(SignedJWT jwtToken)
{        String receivedSigAlg = jwtToken.getHeader().getAlgorithm().getName();    if (!receivedSigAlg.equals(JWSAlgorithm.RS256.getName())) {        return false;    }        if (JWSObject.State.SIGNED == jwtToken.getState()) {                if (jwtToken.getSignature() != null) {                        try {                JWSVerifier verifier = new RSASSAVerifier(SecurityUtils.parseRSAPublicKey(getKnoxKey()));                if (jwtToken.verify(verifier)) {                                        return true;                } else {                                    }            } catch (Exception e) {                            }        }    }    return false;}
1
protected String getJWTFromCookie(HttpServletRequest req)
{    String serializedJWT = null;    Cookie[] cookies = req.getCookies();    if (cookies != null) {        for (Cookie cookie : cookies) {                        if (knoxCookie.equals(cookie.getName())) {                if (LOG.isDebugEnabled()) {                                    }                serializedJWT = cookie.getValue();                break;            }        }    } else {        if (LOG.isDebugEnabled()) {                    }    }    return serializedJWT;}
1
protected String getKnoxKey() throws IOException
{    String knoxKey;    if ((this.knoxKeyString == null || this.knoxKeyString.isEmpty()) && this.knoxKeyFile != null) {        List<String> keyLines = Files.readAllLines(knoxKeyFile, StandardCharsets.UTF_8);        knoxKey = String.join("", keyLines);    } else {        knoxKey = this.knoxKeyString;    }    return knoxKey;}
0
protected Authentication getAuthentication(String userName, HttpServletRequest httpRequest)
{    String ldapName = LdapNameBuilder.newInstance().add(userSearchBase).add("uid", userName).build().toString();        List<GrantedAuthority> grantedAuths = ldapTemplate.search(query().where("objectclass").is("groupOfNames").and("member").is(ldapName), (AttributesMapper<String>) attrs -> (String) attrs.get("cn").get()).stream().map(group -> String.format("%s%s", SECURITY_ROLE_PREFIX, group.toUpperCase())).map(SimpleGrantedAuthority::new).collect(Collectors.toList());    final UserDetails principal = new User(userName, "", grantedAuths);    final UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(principal, "", grantedAuths);    WebAuthenticationDetails webDetails = new WebAuthenticationDetails(httpRequest);    authentication.setDetails(webDetails);    return authentication;}
0
public LdapTemplate ldapTemplate()
{    LdapContextSource contextSource = new LdapContextSource();    contextSource.setUrl(environment.getProperty(LDAP_PROVIDER_URL_SPRING_PROPERTY));    contextSource.setUserDn(environment.getProperty(LDAP_PROVIDER_USERDN_SPRING_PROPERTY));    contextSource.setPassword(environment.getProperty(LDAP_PROVIDER_PASSWORD_SPRING_PROPERTY));    contextSource.afterPropertiesSet();    return new LdapTemplate(contextSource);}
0
public CommonsRequestLoggingFilter logFilter()
{    CommonsRequestLoggingFilter filter = new CommonsRequestLoggingFilter();    filter.setIncludeQueryString(true);    filter.setIncludePayload(true);    filter.setMaxPayloadLength(10000);    filter.setIncludeHeaders(true);    filter.setAfterMessagePrefix("request: ");    filter.setAfterMessageSuffix("");    return filter;}
0
public String getUserRole()
{    return userRole;}
0
public void setUserRole(String userRole)
{    this.userRole = userRole;}
0
public String getAdminRole()
{    return adminRole;}
0
public void setAdminRole(String adminRole)
{    this.adminRole = adminRole;}
0
public String getPrefix()
{    return prefix;}
0
public void setPrefix(String prefix)
{    this.prefix = prefix;}
0
public void addCorsMappings(CorsRegistry registry)
{    registry.addMapping("/**");}
0
public JobManager jobManager()
{    return new InMemoryJobManager();}
0
public PcapJobSupplier pcapJobSupplier()
{    return new PcapJobSupplier();}
0
public PcapToPdmlScriptWrapper pcapToPdmlScriptWrapper()
{    return new PcapToPdmlScriptWrapper();}
0
public Statusable<Path> get()
{    try {        PcapJob<Path> pcapJob = createPcapJob();        return pcapJob.submit(PcapFinalizerStrategies.REST, pcapRequest);    } catch (JobException e) {        throw new RuntimeJobException(e.getMessage(), e);    }}
0
public void setPcapRequest(PcapRequest pcapRequest)
{    this.pcapRequest = pcapRequest;}
0
protected PcapJob createPcapJob()
{    return new PcapJob();}
0
public RestTemplate restTemplate()
{    if (environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)) {        String keyTabLocation = environment.getProperty(MetronRestConstants.KERBEROS_KEYTAB_SPRING_PROPERTY);        String userPrincipal = environment.getProperty(MetronRestConstants.KERBEROS_PRINCIPLE_SPRING_PROPERTY);        return new KerberosRestTemplate(keyTabLocation, userPrincipal);    } else {        return new RestTemplate();    }}
0
public StormCLIWrapper stormCLIClientWrapper()
{    if (Arrays.asList(environment.getActiveProfiles()).contains(DOCKER_PROFILE)) {        return new DockerStormCLIWrapper(environment);    } else {        return new StormCLIWrapper();    }}
0
public StormStatusService stormStatusService(@Autowired @Qualifier("StormStatusServiceImpl") StormStatusService wrappedService)
{    long maxCacheSize = environment.getProperty(MetronRestConstants.STORM_STATUS_CACHE_MAX_SIZE, Long.class, 10000L);    long maxCacheTimeoutSeconds = environment.getProperty(MetronRestConstants.STORM_STATUS_CACHE_TIMEOUT_SECONDS, Long.class, 5L);    return new CachedStormStatusServiceImpl(wrappedService, maxCacheSize, maxCacheTimeoutSeconds);}
0
public Docket api()
{    List<String> activeProfiles = Arrays.asList(environment.getActiveProfiles());    Docket docket = new Docket(DocumentationType.SWAGGER_2);    if (activeProfiles.contains(KNOX_PROFILE)) {        String knoxRoot = environment.getProperty(MetronRestConstants.KNOX_ROOT_SPRING_PROPERTY, String.class, "");        docket = docket.pathProvider(new RelativePathProvider(servletContext) {            @Override            protected String applicationPath() {                return knoxRoot;            }            @Override            protected String getDocumentationPath() {                return knoxRoot;            }            @Override            public String getApplicationBasePath() {                return knoxRoot;            }            @Override            public String getOperationPath(String operationPath) {                return knoxRoot + super.getOperationPath(operationPath);            }        });    }    return docket.select().apis(RequestHandlerSelectors.withClassAnnotation(RestController.class)).paths(PathSelectors.any()).build();}
0
protected String applicationPath()
{    return knoxRoot;}
0
protected String getDocumentationPath()
{    return knoxRoot;}
0
public String getApplicationBasePath()
{    return knoxRoot;}
0
public String getOperationPath(String operationPath)
{    return knoxRoot + super.getOperationPath(operationPath);}
0
public String handleNGRequests()
{    return "forward:/index.html";}
0
protected void configure(HttpSecurity http) throws Exception
{    http.authorizeRequests().antMatchers("/", "/home", "/login").permitAll().antMatchers("/app/**").permitAll().antMatchers("/vendor/**").permitAll().antMatchers("/fonts/**").permitAll().antMatchers("/assets/images/**").permitAll().antMatchers("/*.js").permitAll().antMatchers("/*.ttf").permitAll().antMatchers("/*.woff2").permitAll().anyRequest().authenticated().and().httpBasic().and().logout().logoutUrl("/api/v1/logout").logoutSuccessHandler(new HttpStatusReturningLogoutSuccessHandler()).invalidateHttpSession(true).deleteCookies("JSESSIONID", knoxCookie);    List<String> activeProfiles = Arrays.asList(environment.getActiveProfiles());    if (activeProfiles.contains(MetronRestConstants.CSRF_ENABLE_PROFILE)) {        http.csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());    } else {        http.csrf().disable();    }    if (activeProfiles.contains(MetronRestConstants.KNOX_PROFILE)) {        http.addFilterAt(new KnoxSSOAuthenticationFilter(userSearchBase, knoxKeyFile, knoxKeyString, knoxCookie, ldapTemplate), UsernamePasswordAuthenticationFilter.class);    }}
0
public PasswordEncoder passwordEncoder()
{    return NoOpPasswordEncoder.getInstance();}
0
public ConfigurationsCache cache(CuratorFramework client)
{    return new ZKConfigurationsCache(client, ZKConfigurationsCache.ConfiguredTypes.ENRICHMENT, ZKConfigurationsCache.ConfiguredTypes.PARSER, ZKConfigurationsCache.ConfiguredTypes.INDEXING);}
0
public CuratorFramework client(Environment environment)
{    int sleepTime = Integer.parseInt(environment.getProperty(MetronRestConstants.CURATOR_SLEEP_TIME));    int maxRetries = Integer.parseInt(environment.getProperty(MetronRestConstants.CURATOR_MAX_RETRIES));    RetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, maxRetries);    CuratorFramework ret = CuratorFrameworkFactory.newClient(environment.getProperty(MetronRestConstants.ZK_URL_SPRING_PROPERTY), retryPolicy);    return ret;}
0
public ZkClient zkClient(Environment environment)
{    int sessionTimeout = Integer.parseInt(environment.getProperty(MetronRestConstants.ZK_CLIENT_SESSION_TIMEOUT));    int connectionTimeout = Integer.parseInt(environment.getProperty(MetronRestConstants.ZK_CLIENT_CONNECTION_TIMEOUT));    return new ZkClient(environment.getProperty(MetronRestConstants.ZK_URL_SPRING_PROPERTY), sessionTimeout, connectionTimeout, ZKStringSerializer$.MODULE$);}
0
 ResponseEntity<Void> escalate(@ApiParam(name = "alerts", value = "The alerts to be escalated", required = true) @RequestBody final List<Map<String, Object>> alerts) throws RestException
{    alertsUIService.escalateAlerts(alerts);    return new ResponseEntity<>(HttpStatus.OK);}
0
 ResponseEntity<AlertsUIUserSettings> get() throws RestException
{    Optional<AlertsUIUserSettings> alertUserSettings = alertsUIService.getAlertsUIUserSettings();    if (alertUserSettings.isPresent()) {        return new ResponseEntity<>(alertUserSettings.get(), HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Map<String, AlertsUIUserSettings>> findAll() throws RestException
{    return new ResponseEntity<>(alertsUIService.findAllAlertsUIUserSettings(), HttpStatus.OK);}
0
 ResponseEntity<Void> save(@ApiParam(name = "alertsUIUserSettings", value = "The user settings to be saved", required = true) @RequestBody AlertsUIUserSettings alertsUIUserSettings) throws RestException
{    ResponseEntity<Void> responseEntity;    if (alertsUIService.getAlertsUIUserSettings().isPresent()) {        responseEntity = new ResponseEntity<>(HttpStatus.OK);    } else {        responseEntity = new ResponseEntity<>(HttpStatus.CREATED);    }    alertsUIService.saveAlertsUIUserSettings(alertsUIUserSettings);    return responseEntity;}
0
 ResponseEntity<Void> delete(@ApiParam(name = "user", value = "The user whose settings will be deleted", required = true) @PathVariable String user) throws RestException
{    if (alertsUIService.deleteAlertsUIUserSettings(user)) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Map<String, Object>> save(@ApiParam(name = "globalConfig", value = "The Global Config JSON to be saved", required = true) @RequestBody Map<String, Object> globalConfig) throws RestException
{    if (globalConfigService.get() == null) {        return new ResponseEntity<>(globalConfigService.save(globalConfig), HttpStatus.CREATED);    } else {        return new ResponseEntity<>(globalConfigService.save(globalConfig), HttpStatus.OK);    }}
0
 ResponseEntity<Map<String, Object>> get() throws RestException
{    Map<String, Object> globalConfig = globalConfigService.get();    if (globalConfig != null) {        return new ResponseEntity<>(globalConfig, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Void> delete() throws RestException
{    if (globalConfigService.delete()) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<GrokValidation> post(@ApiParam(name = "grokValidation", value = "Object containing Grok statement and sample message", required = true) @RequestBody GrokValidation grokValidation) throws RestException
{    return new ResponseEntity<>(grokService.validateGrokStatement(grokValidation), HttpStatus.OK);}
0
 ResponseEntity<Map<String, String>> list() throws RestException
{    return new ResponseEntity<>(grokService.getCommonGrokPatterns(), HttpStatus.OK);}
0
 ResponseEntity<String> get(@ApiParam(name = "path", value = "Path to classpath resource", required = true) @RequestParam String path) throws RestException
{    return new ResponseEntity<>(grokService.getStatementFromClasspath(path), HttpStatus.OK);}
0
 ResponseEntity<List<String>> list(@ApiParam(name = "path", value = "Path to HDFS directory", required = true) @RequestParam String path) throws RestException
{    return new ResponseEntity<>(hdfsService.list(new Path(path)), HttpStatus.OK);}
0
 ResponseEntity<String> read(@ApiParam(name = "path", value = "Path to HDFS file", required = true) @RequestParam String path) throws RestException
{    String contents = hdfsService.read(new Path(path));    if (contents != null) {        return new ResponseEntity<>(hdfsService.read(new Path(path)), HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Void> write(@ApiParam(name = "path", value = "Path to HDFS file", required = true) @RequestParam String path, @ApiParam(name = "contents", value = "File contents", required = true) @RequestBody String contents, @ApiParam(name = "userMode", value = "requested user permissions") @RequestParam(required = false, defaultValue = "") String userMode, @ApiParam(name = "groupMode", value = "requested group permissions") @RequestParam(required = false, defaultValue = "") String groupMode, @ApiParam(name = "otherMode", value = "requested other permissions") @RequestParam(required = false, defaultValue = "") String otherMode) throws RestException
{    hdfsService.write(new Path(path), contents.getBytes(UTF_8), userMode, groupMode, otherMode);    return new ResponseEntity<>(HttpStatus.OK);}
0
 ResponseEntity<Boolean> delete(@ApiParam(name = "path", value = "Path to HDFS file", required = true) @RequestParam String path, @ApiParam(name = "recursive", value = "Delete files recursively") @RequestParam(required = false, defaultValue = "false") boolean recursive) throws RestException
{    if (hdfsService.delete(new Path(path), recursive)) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<KafkaTopic> save(@ApiParam(name = "topic", value = "Kafka topic", required = true) @RequestBody final KafkaTopic topic) throws RestException
{    return new ResponseEntity<>(kafkaService.createTopic(topic), HttpStatus.CREATED);}
0
 ResponseEntity<KafkaTopic> get(@ApiParam(name = "name", value = "Kafka topic name", required = true) @PathVariable final String name) throws RestException
{    KafkaTopic kafkaTopic = kafkaService.getTopic(name);    if (kafkaTopic != null) {        return new ResponseEntity<>(kafkaTopic, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Set<String>> list() throws Exception
{    return new ResponseEntity<>(kafkaService.listTopics(), HttpStatus.OK);}
0
 ResponseEntity<Void> delete(@ApiParam(name = "name", value = "Kafka topic name", required = true) @PathVariable final String name) throws RestException
{    if (kafkaService.deleteTopic(name)) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<String> getSample(@ApiParam(name = "name", value = "Kafka topic name", required = true) @PathVariable final String name) throws RestException
{    String sampleMessage = kafkaService.getSampleMessage(name);    if (sampleMessage != null) {        return new ResponseEntity<>(sampleMessage, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<String> produce(@ApiParam(name = "name", value = "Kafka topic name", required = true) @PathVariable final String name, @ApiParam(name = "message", value = "Message", required = true) @RequestBody final String message) throws RestException
{    kafkaService.produceMessage(name, message);    return new ResponseEntity<>(HttpStatus.OK);}
0
 ResponseEntity<SearchResponse> searchByAlert(@ApiParam(name = "guid", value = "Alert GUID", required = true) @RequestBody final String guid) throws RestException
{    return new ResponseEntity<>(metaAlertService.getAllMetaAlertsForAlert(guid), HttpStatus.OK);}
0
 ResponseEntity<Document> create(@ApiParam(name = "createRequest", value = "Meta alert create request which includes a list of alert " + "get requests and a list of custom groups used to annotate a meta alert", required = true) @RequestBody final MetaAlertCreateRequest createRequest) throws RestException
{    return new ResponseEntity<>(metaAlertService.create(createRequest), HttpStatus.OK);}
0
 ResponseEntity<Document> addAlertsToMetaAlert(@ApiParam(name = "metaAlertAddRemoveRequest", value = "Meta alert add request which includes a meta alert GUID and list of alert get requests", required = true) @RequestBody final MetaAlertAddRemoveRequest metaAlertAddRemoveRequest) throws RestException
{    return new ResponseEntity<>(metaAlertService.addAlertsToMetaAlert(metaAlertAddRemoveRequest), HttpStatus.OK);}
0
 ResponseEntity<Document> removeAlertsFromMetaAlert(@ApiParam(name = "metaAlertAddRemoveRequest", value = "Meta alert remove request which includes a meta alert GUID and list of alert get requests", required = true) @RequestBody final MetaAlertAddRemoveRequest metaAlertAddRemoveRequest) throws RestException
{    return new ResponseEntity<>(metaAlertService.removeAlertsFromMetaAlert(metaAlertAddRemoveRequest), HttpStatus.OK);}
0
 ResponseEntity<Document> updateMetaAlertStatus(@ApiParam(name = "guid", value = "Meta alert GUID", required = true) @PathVariable final String guid, @ApiParam(name = "status", value = "Meta alert status with a value of either 'ACTIVE' or 'INACTIVE'", required = true) @PathVariable final String status) throws RestException
{    return new ResponseEntity<>(metaAlertService.updateMetaAlertStatus(guid, MetaAlertStatus.valueOf(status.toUpperCase())), HttpStatus.OK);}
0
 ResponseEntity<PcapStatus> fixed(@ApiParam(name = "fixedPcapRequest", value = "A Fixed Pcap Request" + " which includes fixed filter fields like ip source address and protocol", required = true) @RequestBody FixedPcapRequest fixedPcapRequest) throws RestException
{    PcapStatus pcapStatus = pcapQueryService.submit(SecurityUtils.getCurrentUser(), fixedPcapRequest);    return new ResponseEntity<>(pcapStatus, HttpStatus.OK);}
0
 ResponseEntity<PcapStatus> query(@ApiParam(name = "queryPcapRequest", value = "A Query Pcap Request" + " which includes Stellar query field", required = true) @RequestBody QueryPcapRequest queryPcapRequest) throws RestException
{    PcapStatus pcapStatus = pcapQueryService.submit(SecurityUtils.getCurrentUser(), queryPcapRequest);    return new ResponseEntity<>(pcapStatus, HttpStatus.OK);}
0
 ResponseEntity<PcapStatus> getStatus(@ApiParam(name = "jobId", value = "Job ID of submitted job", required = true) @PathVariable String jobId) throws RestException
{    PcapStatus jobStatus = pcapQueryService.getJobStatus(SecurityUtils.getCurrentUser(), jobId);    if (jobStatus != null) {        return new ResponseEntity<>(jobStatus, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<List<PcapStatus>> getStatuses(@ApiParam(name = "state", value = "Job state", required = true) @RequestParam String state) throws RestException
{    List<PcapStatus> jobs = pcapQueryService.getJobStatus(SecurityUtils.getCurrentUser(), JobStatus.State.valueOf(state));    return new ResponseEntity<>(jobs, HttpStatus.OK);}
0
 ResponseEntity<Pdml> pdml(@ApiParam(name = "jobId", value = "Job ID of submitted job", required = true) @PathVariable String jobId, @ApiParam(name = "page", value = "Page number", required = true) @RequestParam Integer page) throws RestException
{    Pdml pdml = pcapQueryService.getPdml(SecurityUtils.getCurrentUser(), jobId, page);    if (pdml != null) {        return new ResponseEntity<>(pdml, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<PcapStatus> killJob(@ApiParam(name = "jobId", value = "Job ID of submitted job", required = true) @PathVariable String jobId) throws RestException
{    PcapStatus jobStatus = pcapQueryService.killJob(SecurityUtils.getCurrentUser(), jobId);    if (jobStatus != null) {        return new ResponseEntity<>(jobStatus, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 void raw(@ApiParam(name = "jobId", value = "Job ID of submitted job", required = true) @PathVariable String jobId, @ApiParam(name = "page", value = "Page number", required = true) @RequestParam Integer page, @RequestParam(defaultValue = "", required = false) String fileName, final HttpServletRequest request, final HttpServletResponse response) throws RestException
{    try (InputStream inputStream = pcapQueryService.getRawPcap(SecurityUtils.getCurrentUser(), jobId, page);        OutputStream output = response.getOutputStream()) {        response.reset();        if (inputStream == null) {            response.setStatus(HttpStatus.NOT_FOUND.value());        } else {            response.setContentType("application/octet-stream");            if (fileName.isEmpty()) {                fileName = String.format(PCAP_FILENAME_FORMAT, jobId, page);            }            response.setHeader("Content-Disposition", "attachment; filename=\"" + fileName + "\"");            int size = IOUtils.copy(inputStream, output);            response.setContentLength(size);            output.flush();        }    } catch (IOException e) {        throw new RestException(e);    }}
0
 ResponseEntity<Map<String, Object>> getConfiguration(@ApiParam(name = "jobId", value = "Job ID of submitted job", required = true) @PathVariable String jobId) throws RestException
{    Map<String, Object> configuration = pcapQueryService.getConfiguration(SecurityUtils.getCurrentUser(), jobId);    if (configuration != null) {        return new ResponseEntity<>(configuration, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<?> handleControllerException(HttpServletRequest request, Throwable ex)
{    HttpStatus status = getStatus(request);        return new ResponseEntity<>(new RestError(status.value(), ex.getMessage(), ExceptionUtils.getRootCauseMessage(ex)), status);}
1
private HttpStatus getStatus(HttpServletRequest request)
{    Integer statusCode = (Integer) request.getAttribute("javax.servlet.error.status_code");    if (statusCode == null) {        return HttpStatus.INTERNAL_SERVER_ERROR;    }    return HttpStatus.valueOf(statusCode);}
0
 ResponseEntity<SearchResponse> search(@ApiParam(name = "searchRequest", value = "Search request", required = true) @RequestBody final SearchRequest searchRequest) throws RestException
{    return new ResponseEntity<>(searchService.search(searchRequest), HttpStatus.OK);}
0
 ResponseEntity<GroupResponse> group(@ApiParam(name = "groupRequest", value = "Group request", required = true) @RequestBody final GroupRequest groupRequest) throws RestException
{    return new ResponseEntity<>(searchService.group(groupRequest), HttpStatus.OK);}
0
 ResponseEntity<Map<String, Object>> getLatest(@ApiParam(name = "getRequest", value = "Get Request", required = true) @RequestBody final GetRequest request) throws RestException
{    Optional<Map<String, Object>> latest = searchService.getLatest(request);    if (latest.isPresent()) {        return new ResponseEntity<>(latest.get(), HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Map<String, FieldType>> getColumnMetadata(@ApiParam(name = "sensorTypes", value = "Sensor Types", required = true) @RequestBody final List<String> sensorTypes) throws RestException
{    return new ResponseEntity<>(searchService.getColumnMetadata(sensorTypes), HttpStatus.OK);}
0
 ResponseEntity<SensorEnrichmentConfig> save(@ApiParam(name = "name", value = "SensorEnrichmentConfig name", required = true) @PathVariable String name, @ApiParam(name = "sensorEnrichmentConfig", value = "SensorEnrichmentConfig", required = true) @RequestBody SensorEnrichmentConfig sensorEnrichmentConfig) throws RestException
{    if (sensorEnrichmentConfigService.findOne(name) == null) {        return new ResponseEntity<>(sensorEnrichmentConfigService.save(name, sensorEnrichmentConfig), HttpStatus.CREATED);    } else {        return new ResponseEntity<>(sensorEnrichmentConfigService.save(name, sensorEnrichmentConfig), HttpStatus.OK);    }}
0
 ResponseEntity<SensorEnrichmentConfig> findOne(@ApiParam(name = "name", value = "SensorEnrichmentConfig name", required = true) @PathVariable String name) throws RestException
{    SensorEnrichmentConfig sensorEnrichmentConfig = sensorEnrichmentConfigService.findOne(name);    if (sensorEnrichmentConfig != null) {        return new ResponseEntity<>(sensorEnrichmentConfig, HttpStatus.OK);    }    return new ResponseEntity<>(HttpStatus.NOT_FOUND);}
0
 ResponseEntity<Map<String, SensorEnrichmentConfig>> getAll() throws Exception
{    return new ResponseEntity<>(sensorEnrichmentConfigService.getAll(), HttpStatus.OK);}
0
 ResponseEntity<Void> delete(@ApiParam(name = "name", value = "SensorEnrichmentConfig name", required = true) @PathVariable String name) throws RestException
{    if (sensorEnrichmentConfigService.delete(name)) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<List<String>> getAvailableEnrichments() throws RestException
{    return new ResponseEntity<>(sensorEnrichmentConfigService.getAvailableEnrichments(), HttpStatus.OK);}
0
 ResponseEntity<List<String>> getAvailableThreatTriageAggregators() throws RestException
{    return new ResponseEntity<>(sensorEnrichmentConfigService.getAvailableThreatTriageAggregators(), HttpStatus.OK);}
0
 ResponseEntity<Map<String, Object>> save(@ApiParam(name = "name", value = "SensorIndexingConfig name", required = true) @PathVariable String name, @ApiParam(name = "sensorIndexingConfig", value = "SensorIndexingConfig", required = true) @RequestBody Map<String, Object> sensorIndexingConfig) throws RestException
{    if (sensorIndexingConfigService.findOne(name) == null) {        return new ResponseEntity<>(sensorIndexingConfigService.save(name, sensorIndexingConfig), HttpStatus.CREATED);    } else {        return new ResponseEntity<>(sensorIndexingConfigService.save(name, sensorIndexingConfig), HttpStatus.OK);    }}
0
 ResponseEntity<Map<String, Object>> findOne(@ApiParam(name = "name", value = "SensorIndexingConfig name", required = true) @PathVariable String name) throws RestException
{    Map<String, Object> sensorIndexingConfig = sensorIndexingConfigService.findOne(name);    if (sensorIndexingConfig != null) {        return new ResponseEntity<>(sensorIndexingConfig, HttpStatus.OK);    }    return new ResponseEntity<>(HttpStatus.NOT_FOUND);}
0
 ResponseEntity<Map<String, Map<String, Object>>> getAll() throws Exception
{    return new ResponseEntity<>(sensorIndexingConfigService.getAll(), HttpStatus.OK);}
0
 ResponseEntity<Iterable<String>> getAllIndices(@ApiParam(name = "writerName", value = "Writer name.  One of solr, elasticsearch or hdfs", required = true) @PathVariable String writerName) throws Exception
{    return new ResponseEntity<>(sensorIndexingConfigService.getAllIndices(writerName), HttpStatus.OK);}
0
 ResponseEntity<Void> delete(@ApiParam(name = "name", value = "SensorIndexingConfig name", required = true) @PathVariable String name) throws RestException
{    if (sensorIndexingConfigService.delete(name)) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<SensorParserConfig> save(@ApiParam(name = "name", value = "SensorParserConfig name", required = true) @PathVariable String name, @ApiParam(name = "sensorParserConfig", value = "SensorParserConfig", required = true) @RequestBody SensorParserConfig sensorParserConfig) throws RestException
{    if (sensorParserConfigService.findOne(name) == null) {        return new ResponseEntity<>(sensorParserConfigService.save(name, sensorParserConfig), HttpStatus.CREATED);    } else {        return new ResponseEntity<>(sensorParserConfigService.save(name, sensorParserConfig), HttpStatus.OK);    }}
0
 ResponseEntity<SensorParserConfig> findOne(@ApiParam(name = "name", value = "SensorParserConfig name", required = true) @PathVariable String name) throws RestException
{    SensorParserConfig sensorParserConfig = sensorParserConfigService.findOne(name);    if (sensorParserConfig != null) {        return new ResponseEntity<>(sensorParserConfig, HttpStatus.OK);    }    return new ResponseEntity<>(HttpStatus.NOT_FOUND);}
0
 ResponseEntity<Map<String, SensorParserConfig>> findAll() throws RestException
{    return new ResponseEntity<>(sensorParserConfigService.getAll(), HttpStatus.OK);}
0
 ResponseEntity<Void> delete(@ApiParam(name = "name", value = "SensorParserConfig name", required = true) @PathVariable String name) throws RestException
{    if (sensorParserConfigService.delete(name)) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Map<String, String>> getAvailable() throws RestException
{    return new ResponseEntity<>(sensorParserConfigService.getAvailableParsers(), HttpStatus.OK);}
0
 ResponseEntity<Map<String, String>> reloadAvailable() throws RestException
{    return new ResponseEntity<>(sensorParserConfigService.reloadAvailableParsers(), HttpStatus.OK);}
0
 ResponseEntity<JSONObject> parseMessage(@ApiParam(name = "parseMessageRequest", value = "Object containing a sample message and SensorParserConfig", required = true) @RequestBody ParseMessageRequest parseMessageRequest) throws RestException
{    return new ResponseEntity<>(sensorParserConfigService.parseMessage(parseMessageRequest), HttpStatus.OK);}
0
 ResponseEntity<SensorParserGroup> save(@ApiParam(name = "sensorParserGroup", value = "SensorParserGroup", required = true) @RequestBody SensorParserGroup sensorParserGroup) throws RestException
{    if (sensorParserGroupService.findOne(sensorParserGroup.getName()) == null) {        return new ResponseEntity<>(sensorParserGroupService.save(sensorParserGroup), HttpStatus.CREATED);    } else {        return new ResponseEntity<>(sensorParserGroupService.save(sensorParserGroup), HttpStatus.OK);    }}
0
 ResponseEntity<SensorParserGroup> findOne(@ApiParam(name = "name", value = "SensorParserGroup name", required = true) @PathVariable String name) throws RestException
{    SensorParserGroup sensorParserGroup = sensorParserGroupService.findOne(name);    if (sensorParserGroup != null) {        return new ResponseEntity<>(sensorParserGroup, HttpStatus.OK);    }    return new ResponseEntity<>(HttpStatus.NOT_FOUND);}
0
 ResponseEntity<Map<String, SensorParserGroup>> findAll() throws RestException
{    return new ResponseEntity<>(sensorParserGroupService.getAll(), HttpStatus.OK);}
0
 ResponseEntity<Void> delete(@ApiParam(name = "name", value = "SensorParserGroup name", required = true) @PathVariable String name) throws RestException
{    if (sensorParserGroupService.delete(name)) {        return new ResponseEntity<>(HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Map<String, Boolean>> validateRules(@ApiParam(name = "statements", value = "List of statements to validate", required = true) @RequestBody List<String> statements) throws RestException
{    return new ResponseEntity<>(stellarService.validateRules(statements), HttpStatus.OK);}
0
 ResponseEntity<Map<String, Object>> applyTransformations(@ApiParam(name = "transformationValidation", value = "Object containing SensorParserConfig and sample message", required = true) @RequestBody SensorParserContext sensorParserContext) throws RestException
{    return new ResponseEntity<>(stellarService.applyTransformations(sensorParserContext), HttpStatus.OK);}
0
 ResponseEntity<FieldTransformations[]> list() throws RestException
{    return new ResponseEntity<>(stellarService.getTransformations(), HttpStatus.OK);}
0
 ResponseEntity<List<StellarFunctionDescription>> listFunctions() throws RestException
{    return new ResponseEntity<>(stellarService.getStellarFunctions(), HttpStatus.OK);}
0
 ResponseEntity<List<StellarFunctionDescription>> listSimpleFunctions() throws RestException
{    return new ResponseEntity<>(stellarService.getSimpleStellarFunctions(), HttpStatus.OK);}
0
 ResponseEntity<SupervisorSummary> getSupervisorSummary() throws RestException
{    return new ResponseEntity<>(stormStatusService.getSupervisorSummary(), HttpStatus.OK);}
0
 ResponseEntity<List<TopologyStatus>> getAll() throws RestException
{    return new ResponseEntity<>(stormStatusService.getAllTopologyStatus(), HttpStatus.OK);}
0
 ResponseEntity<TopologyStatus> get(@ApiParam(name = "name", value = "Topology name", required = true) @PathVariable String name) throws RestException
{    TopologyStatus topologyStatus = stormStatusService.getTopologyStatus(name);    if (topologyStatus != null) {        return new ResponseEntity<>(topologyStatus, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<TopologyResponse> start(@ApiParam(name = "name", value = "Parser name", required = true) @PathVariable String name) throws RestException
{    return new ResponseEntity<>(stormAdminService.startParserTopology(name), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> stop(@ApiParam(name = "name", value = "Parser name", required = true) @PathVariable String name, @ApiParam(name = "stopNow", value = "Stop the topology immediately") @RequestParam(required = false, defaultValue = "false") boolean stopNow) throws RestException
{    return new ResponseEntity<>(stormAdminService.stopParserTopology(name, stopNow), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> activate(@ApiParam(name = "name", value = "Parser name", required = true) @PathVariable String name) throws RestException
{    return new ResponseEntity<>(stormStatusService.activateTopology(name), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> deactivate(@ApiParam(name = "name", value = "Parser name", required = true) @PathVariable String name) throws RestException
{    return new ResponseEntity<>(stormStatusService.deactivateTopology(name), HttpStatus.OK);}
0
 ResponseEntity<TopologyStatus> getEnrichment() throws RestException
{    TopologyStatus sensorParserStatus = stormStatusService.getTopologyStatus(MetronRestConstants.ENRICHMENT_TOPOLOGY_NAME);    if (sensorParserStatus != null) {        return new ResponseEntity<>(sensorParserStatus, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<TopologyResponse> startEnrichment() throws RestException
{    return new ResponseEntity<>(stormAdminService.startEnrichmentTopology(), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> stopEnrichment(@ApiParam(name = "stopNow", value = "Stop the topology immediately") @RequestParam(required = false, defaultValue = "false") boolean stopNow) throws RestException
{    return new ResponseEntity<>(stormAdminService.stopEnrichmentTopology(stopNow), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> activateEnrichment() throws RestException
{    return new ResponseEntity<>(stormStatusService.activateTopology(MetronRestConstants.ENRICHMENT_TOPOLOGY_NAME), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> deactivateEnrichment() throws RestException
{    return new ResponseEntity<>(stormStatusService.deactivateTopology(MetronRestConstants.ENRICHMENT_TOPOLOGY_NAME), HttpStatus.OK);}
0
 ResponseEntity<TopologyStatus> getRandomAccessIndexing() throws RestException
{    TopologyStatus topologyStatus = stormStatusService.getTopologyStatus(MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME);    if (topologyStatus != null) {        return new ResponseEntity<>(topologyStatus, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<TopologyResponse> startRandomAccessIndexing() throws RestException
{    return new ResponseEntity<>(stormAdminService.startIndexingTopology(MetronRestConstants.RANDOM_ACCESS_INDEXING_SCRIPT_PATH_SPRING_PROPERTY), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> stopRandomAccessIndexing(@ApiParam(name = "stopNow", value = "Stop the topology immediately") @RequestParam(required = false, defaultValue = "false") boolean stopNow) throws RestException
{    return new ResponseEntity<>(stormAdminService.stopIndexingTopology(MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME, stopNow), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> activateRandomAccessIndexing() throws RestException
{    return new ResponseEntity<>(stormStatusService.activateTopology(MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> deactivateRandomAccessIndexing() throws RestException
{    return new ResponseEntity<>(stormStatusService.deactivateTopology(MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME), HttpStatus.OK);}
0
 ResponseEntity<Map<String, String>> clientStatus() throws RestException
{    return new ResponseEntity<>(stormAdminService.getStormClientStatus(), HttpStatus.OK);}
0
 ResponseEntity<TopologyStatus> getBatchIndexing() throws RestException
{    TopologyStatus topologyStatus = stormStatusService.getTopologyStatus(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME);    if (topologyStatus != null) {        return new ResponseEntity<>(topologyStatus, HttpStatus.OK);    } else {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<TopologyResponse> startBatchIndexing() throws RestException
{    return new ResponseEntity<>(stormAdminService.startIndexingTopology(MetronRestConstants.BATCH_INDEXING_SCRIPT_PATH_SPRING_PROPERTY), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> stopBatchIndexing(@ApiParam(name = "stopNow", value = "Stop the topology immediately") @RequestParam(required = false, defaultValue = "false") boolean stopNow) throws RestException
{    return new ResponseEntity<>(stormAdminService.stopIndexingTopology(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME, stopNow), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> activateBatchIndexing() throws RestException
{    return new ResponseEntity<>(stormStatusService.activateTopology(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME), HttpStatus.OK);}
0
 ResponseEntity<TopologyResponse> deactivateBatchIndexing() throws RestException
{    return new ResponseEntity<>(stormStatusService.deactivateTopology(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME), HttpStatus.OK);}
0
 ResponseEntity<Document> patch(@ApiParam(name = "request", value = "Patch request", required = true) @RequestBody final PatchRequest request) throws RestException
{    try {        return new ResponseEntity<>(service.patch(request), HttpStatus.OK);    } catch (OriginalNotFoundException e) {        return new ResponseEntity<>(HttpStatus.NOT_FOUND);    }}
0
 ResponseEntity<Document> addCommentToAlert(@RequestBody @ApiParam(name = "request", value = "Comment add request", required = true) final CommentAddRemoveRequest request) throws RestException
{    return new ResponseEntity<>(service.addComment(request), HttpStatus.OK);}
0
 ResponseEntity<Document> removeCommentFromAlert(@RequestBody @ApiParam(name = "request", value = "Comment remove request", required = true) final CommentAddRemoveRequest request) throws RestException
{    return new ResponseEntity<>(service.removeComment(request), HttpStatus.OK);}
0
public String user(Principal user)
{    return user.getName();}
0
public List<String> user()
{    UserDetails userDetails = (UserDetails) SecurityContextHolder.getContext().getAuthentication().getPrincipal();    return userDetails.getAuthorities().stream().map(ga -> ga.getAuthority()).collect(Collectors.toList());}
0
protected ResponseEntity<Object> handleHttpMessageNotReadable(HttpMessageNotReadableException ex, HttpHeaders headers, HttpStatus status, WebRequest request)
{        return super.handleHttpMessageNotReadable(ex, headers, status, request);}
1
public static void main(String[] args)
{    ParserIndex.reload();    SpringApplication.run(MetronRestApplication.class, args);}
0
public String getFullMessage()
{    return this.fullMessage;}
0
public static String getCurrentUser()
{    Object principal = SecurityContextHolder.getContext().getAuthentication().getPrincipal();    String user;    if (principal instanceof UserDetails) {        user = ((UserDetails) principal).getUsername();    } else {        user = principal.toString();    }    return user;}
0
public static RSAPublicKey parseRSAPublicKey(String pem) throws CertificateException, UnsupportedEncodingException
{    String PEM_HEADER = "-----BEGIN CERTIFICATE-----\n";    String PEM_FOOTER = "\n-----END CERTIFICATE-----";    String fullPem = (pem.startsWith(PEM_HEADER) && pem.endsWith(PEM_FOOTER)) ? pem : PEM_HEADER + pem + PEM_FOOTER;    PublicKey key = null;    try {        CertificateFactory fact = CertificateFactory.getInstance("X.509");        ByteArrayInputStream is = new ByteArrayInputStream(fullPem.getBytes(StandardCharsets.UTF_8));        X509Certificate cer = (X509Certificate) fact.generateCertificate(is);        key = cer.getPublicKey();    } catch (CertificateException ce) {        String message = null;        if (pem.startsWith(PEM_HEADER)) {            message = "CertificateException - be sure not to include PEM header " + "and footer in the PEM configuration element.";        } else {            message = "CertificateException - PEM may be corrupt";        }        throw new CertificateException(message, ce);    }    return (RSAPublicKey) key;}
0
public void escalateAlerts(List<Map<String, Object>> alerts) throws RestException
{    String user = SecurityUtils.getCurrentUser();    String topic = environment.getProperty(KAFKA_TOPICS_ESCALATION_PROPERTY);    Long now = clock.currentTimeMillis();        try {        for (Map<String, Object> alert : alerts) {                        alert.put(METRON_ESCALATION_USER_FIELD, user);            alert.put(METRON_ESCALATION_TIMESTAMP_FIELD, now);                        String message = JSONUtils.INSTANCE.toJSON(alert, false);            kafkaService.produceMessage(topic, message);        }    } catch (JsonProcessingException e) {        throw new RestException(e);    }}
1
public Optional<AlertsUIUserSettings> getAlertsUIUserSettings() throws RestException
{    try {        Optional<String> alertUserSettings = userSettingsClient.findOne(SecurityUtils.getCurrentUser(), ALERT_USER_SETTING_TYPE);        if (alertUserSettings.isPresent()) {            return Optional.of(_mapper.get().readValue(alertUserSettings.get(), AlertsUIUserSettings.class));        } else {            return Optional.empty();        }    } catch (IOException e) {        throw new RestException(e);    }}
0
public Map<String, AlertsUIUserSettings> findAllAlertsUIUserSettings() throws RestException
{    Map<String, AlertsUIUserSettings> allAlertUserSettings = new HashMap<>();    try {        Map<String, Optional<String>> alertUserSettingsStrings = userSettingsClient.findAll(ALERT_USER_SETTING_TYPE);        for (Map.Entry<String, Optional<String>> entry : alertUserSettingsStrings.entrySet()) {            Optional<String> alertUserSettings = entry.getValue();            if (alertUserSettings.isPresent()) {                allAlertUserSettings.put(entry.getKey(), _mapper.get().readValue(alertUserSettings.get(), AlertsUIUserSettings.class));            }        }    } catch (IOException e) {        throw new RestException(e);    }    return allAlertUserSettings;}
0
public void saveAlertsUIUserSettings(AlertsUIUserSettings alertsUIUserSettings) throws RestException
{    String user = SecurityUtils.getCurrentUser();    try {        userSettingsClient.save(user, ALERT_USER_SETTING_TYPE, _mapper.get().writeValueAsString(alertsUIUserSettings));    } catch (IOException e) {        throw new RestException(e);    }}
0
public boolean deleteAlertsUIUserSettings(String user)
{    boolean success = true;    try {        userSettingsClient.delete(user, ALERT_USER_SETTING_TYPE);    } catch (IOException e) {        success = false;    }    return success;}
0
public void setClock(Clock clock)
{    this.clock = clock;}
0
public SupervisorSummary getSupervisorSummary()
{    return (SupervisorSummary) statusCache.get(CacheKey.SUPERVISOR_SUMMARY, cacheKey -> {                return stormService.getSupervisorSummary();    });}
1
public TopologySummary getTopologySummary()
{    return (TopologySummary) statusCache.get(CacheKey.TOPOLOGY_SUMMARY, cacheKey -> {                return stormService.getTopologySummary();    });}
1
public TopologyStatus getTopologyStatus(String name)
{    return (TopologyStatus) statusCache.get(CacheKey.TOPOLOGY_STATUS + name, cacheKey -> {                return stormService.getTopologyStatus(name);    });}
1
public List<TopologyStatus> getAllTopologyStatus()
{    return (List<TopologyStatus>) statusCache.get(CacheKey.ALL_TOPOLOGY_STATUS, cacheKey -> {                return stormService.getAllTopologyStatus();    });}
1
public TopologyResponse activateTopology(String name)
{    return stormService.activateTopology(name);}
0
public TopologyResponse deactivateTopology(String name)
{    return stormService.deactivateTopology(name);}
0
public void reset()
{    statusCache.invalidateAll();}
0
protected ProcessBuilder getProcessBuilder(final String... command)
{    final String[] dockerCommand = { "docker-compose", "-f", environment.getProperty("docker.compose.path"), "-p", "metron", "exec", "storm" };    final ProcessBuilder pb = new ProcessBuilder(ArrayUtils.addAll(dockerCommand, command));    final Map<String, String> pbEnvironment = pb.environment();    pbEnvironment.put("METRON_VERSION", environment.getProperty("metron.version"));    setDockerEnvironment(pbEnvironment);    return pb;}
0
private void setDockerEnvironment(final Map<String, String> environmentVariables)
{    final ProcessBuilder pb = getDockerEnvironmentProcessBuilder();    try {        final Process process = pb.start();        final BufferedReader inputStream = new BufferedReader(new InputStreamReader(process.getInputStream(), StandardCharsets.UTF_8));        String line;        while ((line = inputStream.readLine()) != null) {            if (line.startsWith("export")) {                final String[] parts = line.replaceFirst("export ", "").split("=");                environmentVariables.put(parts[0], parts[1].replaceAll("\"", ""));            }        }        process.waitFor();    } catch (IOException | InterruptedException e) {            }}
1
private ProcessBuilder getDockerEnvironmentProcessBuilder()
{    String[] command = { "docker-machine", "env", "metron-machine" };    return new ProcessBuilder(command);}
0
public void setCache(ConfigurationsCache cache)
{    this.cache = cache;}
0
public Map<String, Object> save(Map<String, Object> globalConfig) throws RestException
{    try {        ConfigurationsUtils.writeGlobalConfigToZookeeper(globalConfig, client);    } catch (Exception e) {        throw new RestException(e);    }    return globalConfig;}
0
public Map<String, Object> get() throws RestException
{    Map<String, Object> globalConfig;    try {        EnrichmentConfigurations configs = cache.get(EnrichmentConfigurations.class);        globalConfig = configs.getGlobalConfig(false);    } catch (Exception e) {        throw new RestException(e.getMessage(), e);    }    return globalConfig;}
0
public boolean delete() throws RestException
{    try {        client.delete().forPath(ConfigurationType.GLOBAL.getZookeeperRoot());    } catch (KeeperException.NoNodeException e) {        return false;    } catch (Exception e) {        throw new RestException(e);    }    return true;}
0
public Map<String, String> getCommonGrokPatterns()
{    return commonGrok.getPatterns();}
0
public GrokValidation validateGrokStatement(GrokValidation grokValidation) throws RestException
{    Map<String, Object> results;    try {        if (grokValidation.getPatternLabel() == null) {            throw new RestException("Pattern label is required");        }        if (Strings.isEmpty(grokValidation.getStatement())) {            throw new RestException("Grok statement is required");        }        Grok grok = new Grok();        grok.addPatternFromReader(new InputStreamReader(getClass().getResourceAsStream("/patterns/common"), StandardCharsets.UTF_8));        grok.addPatternFromReader(new StringReader(grokValidation.getStatement()));        String grokPattern = "%{" + grokValidation.getPatternLabel() + "}";        grok.compile(grokPattern);        Match gm = grok.match(grokValidation.getSampleData());        gm.captures();        results = gm.toMap();        results.remove(grokValidation.getPatternLabel());    } catch (Exception e) {        throw new RestException(e);    }    grokValidation.setResults(results);    return grokValidation;}
0
public Path saveTemporary(String statement, String name) throws RestException
{    if (statement != null) {        Path path = getTemporaryGrokRootPath();        hdfsService.mkdirs(path);        hdfsService.write(new Path(path, name), statement.getBytes(StandardCharsets.UTF_8), null, null, null);        return path;    } else {        throw new RestException("A grokStatement must be provided");    }}
0
public void deleteTemporary() throws RestException
{    hdfsService.delete(getTemporaryGrokRootPath(), true);}
0
private Path getTemporaryGrokRootPath()
{    String grokTempPath = environment.getProperty(GROK_TEMP_PATH_SPRING_PROPERTY);    Authentication authentication = SecurityContextHolder.getContext().getAuthentication();    return new Path(grokTempPath, authentication.getName());}
0
public String getStatementFromClasspath(String path) throws RestException
{    try {        return IOUtils.toString(getClass().getResourceAsStream(path));    } catch (Exception e) {        throw new RestException("Could not find a statement at path " + path);    }}
0
public List<String> list(Path path) throws RestException
{    try {        return Arrays.asList(FileSystem.get(configuration).listStatus(path)).stream().map(fileStatus -> fileStatus.getPath().getName()).collect(Collectors.toList());    } catch (IOException e) {        throw new RestException(e);    }}
0
public String read(Path path) throws RestException
{    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();    try {        IOUtils.copyBytes(FileSystem.get(configuration).open(path), byteArrayOutputStream, configuration);    } catch (FileNotFoundException e) {        return null;    } catch (IOException e) {        throw new RestException(e);    }    return new String(byteArrayOutputStream.toByteArray(), UTF_8);}
0
public void write(Path path, byte[] contents, String userMode, String groupMode, String otherMode) throws RestException
{    FSDataOutputStream fsDataOutputStream;    try {        FsPermission permission = null;        boolean setPermissions = false;        if (StringUtils.isNotEmpty(userMode) && StringUtils.isNotEmpty(groupMode) && StringUtils.isNotEmpty(otherMode)) {                        FsAction userAction = FsAction.getFsAction(userMode);            FsAction groupAction = FsAction.getFsAction(groupMode);            FsAction otherAction = FsAction.getFsAction(otherMode);            if (userAction == null || groupAction == null || otherAction == null) {                throw new RestException(String.format("Invalid permission set: user[%s] " + "group[%s] other[%s]", userAction, groupAction, otherAction));            }            permission = new FsPermission(userAction, groupAction, otherAction);            setPermissions = true;        }        fsDataOutputStream = FileSystem.get(configuration).create(path, true);        fsDataOutputStream.write(contents);        fsDataOutputStream.close();        if (setPermissions) {            FileSystem.get(configuration).setPermission(path, permission);        }    } catch (IOException e) {        throw new RestException(e);    }}
0
public boolean delete(Path path, boolean recursive) throws RestException
{    try {        return FileSystem.get(configuration).delete(path, recursive);    } catch (IOException e) {        throw new RestException(e);    }}
0
public boolean mkdirs(Path path) throws RestException
{    try {        return FileSystem.get(configuration).mkdirs(path);    } catch (IOException e) {        throw new RestException(e);    }}
0
public KafkaTopic createTopic(final KafkaTopic topic) throws RestException
{    if (!listTopics().contains(topic.getName())) {        try {            adminUtils.createTopic(zkUtils, topic.getName(), topic.getNumPartitions(), topic.getReplicationFactor(), topic.getProperties(), RackAwareMode.Disabled$.MODULE$);            if (environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)) {                addACLToCurrentUser(topic.getName());            }        } catch (AdminOperationException e) {            throw new RestException(e);        }    }    return topic;}
0
public boolean deleteTopic(final String name)
{    final Set<String> topics = listTopics();    if (topics != null && topics.contains(name)) {        adminUtils.deleteTopic(zkUtils, name);        return true;    } else {        return false;    }}
0
public KafkaTopic getTopic(final String name)
{    KafkaTopic kafkaTopic = null;    if (listTopics().contains(name)) {        try (Consumer<String, String> consumer = kafkaConsumerFactory.createConsumer()) {            final List<PartitionInfo> partitionInfos = consumer.partitionsFor(name);            if (partitionInfos.size() > 0) {                final PartitionInfo partitionInfo = partitionInfos.get(0);                kafkaTopic = new KafkaTopic();                kafkaTopic.setName(name);                kafkaTopic.setNumPartitions(partitionInfos.size());                kafkaTopic.setReplicationFactor(partitionInfo.replicas().length);            }        }    }    return kafkaTopic;}
0
public Set<String> listTopics()
{    try (Consumer<String, String> consumer = kafkaConsumerFactory.createConsumer()) {        final Map<String, List<PartitionInfo>> topicsInfo = consumer.listTopics();        final Set<String> topics = topicsInfo == null ? new HashSet<>() : topicsInfo.keySet();        topics.remove(CONSUMER_OFFSETS_TOPIC);        return topics;    }}
0
public String getSampleMessage(final String topic)
{    String message = null;    if (listTopics().contains(topic)) {        try (Consumer<String, String> kafkaConsumer = kafkaConsumerFactory.createConsumer()) {            kafkaConsumer.assign(kafkaConsumer.partitionsFor(topic).stream().map(partitionInfo -> new TopicPartition(topic, partitionInfo.partition())).collect(Collectors.toList()));            kafkaConsumer.assignment().stream().filter(p -> (kafkaConsumer.position(p) - 1) >= 0).forEach(p -> kafkaConsumer.seek(p, kafkaConsumer.position(p) - 1));            final ConsumerRecords<String, String> records = kafkaConsumer.poll(KAFKA_CONSUMER_TIMEOUT);            message = records.isEmpty() ? null : records.iterator().next().value();            kafkaConsumer.unsubscribe();        }    }    return message;}
0
public void produceMessage(String topic, String message) throws RestException
{    kafkaProducer.send(new ProducerRecord<>(topic, message));}
0
public boolean addACLToCurrentUser(String name)
{    if (listTopics().contains(name)) {        String zkServers = environment.getProperty(MetronRestConstants.ZK_URL_SPRING_PROPERTY);        User principal = (User) SecurityContextHolder.getContext().getAuthentication().getPrincipal();        String user = principal.getUsername();        List<String> cmd = new ArrayList<>();        cmd.add("--add");        cmd.add("--allow-principal");        cmd.add("User:" + user);        cmd.add("--topic");        cmd.add(name);        cmd.add("--authorizer-properties");        cmd.add("zookeeper.connect=" + String.join(",", zkServers));        AclCommand.main(cmd.toArray(new String[cmd.size()]));    } else {        return false;    }    return true;}
0
public Document create(MetaAlertCreateRequest createRequest) throws RestException
{    try {        return dao.createMetaAlert(createRequest);    } catch (InvalidCreateException | IOException e) {        throw new RestException(e.getMessage(), e);    }}
0
public SearchResponse getAllMetaAlertsForAlert(String guid) throws RestException
{    try {        return dao.getAllMetaAlertsForAlert(guid);    } catch (IOException | InvalidSearchException ise) {        throw new RestException(ise.getMessage(), ise);    }}
0
public Document addAlertsToMetaAlert(MetaAlertAddRemoveRequest metaAlertAddRemoveRequest) throws RestException
{    try {        return dao.addAlertsToMetaAlert(metaAlertAddRemoveRequest.getMetaAlertGuid(), metaAlertAddRemoveRequest.getAlerts());    } catch (IOException | IllegalStateException e) {        throw new RestException(e.getMessage(), e);    }}
0
public Document removeAlertsFromMetaAlert(MetaAlertAddRemoveRequest metaAlertAddRemoveRequest) throws RestException
{    try {        return dao.removeAlertsFromMetaAlert(metaAlertAddRemoveRequest.getMetaAlertGuid(), metaAlertAddRemoveRequest.getAlerts());    } catch (IOException | IllegalStateException e) {        throw new RestException(e.getMessage(), e);    }}
0
public Document updateMetaAlertStatus(String metaAlertGuid, MetaAlertStatus status) throws RestException
{    try {        return dao.updateMetaAlertStatus(metaAlertGuid, status);    } catch (IOException ioe) {        throw new RestException(ioe.getMessage(), ioe);    }}
0
public PcapStatus submit(String username, PcapRequest pcapRequest) throws RestException
{    List<PcapStatus> runningJobs = getJobStatus(username, JobStatus.State.RUNNING);    Integer userJobLimit = environment.getProperty(MetronRestConstants.USER_JOB_LIMIT_SPRING_PROPERTY, Integer.class, 1);    if (runningJobs != null && runningJobs.size() >= userJobLimit) {        String jobIds = runningJobs.stream().map(PcapStatus::getJobId).collect(Collectors.joining(", "));        String message = String.format("Cannot submit job because a job is already running.  " + "Please contact the administrator to cancel job(s) with id(s) %s", jobIds);        throw new RestException(message);    }    try {        setPcapOptions(username, pcapRequest);        pcapRequest.setFields();        pcapJobSupplier.setPcapRequest(pcapRequest);        JobStatus jobStatus = jobManager.submit(pcapJobSupplier, username);        return jobStatusToPcapStatus(jobStatus);    } catch (IOException | JobException e) {        throw new RestException(e);    }}
0
public PcapStatus getJobStatus(String username, String jobId) throws RestException
{    PcapStatus pcapStatus = null;    try {        Statusable<Path> statusable = jobManager.getJob(username, jobId);        if (statusable != null) {            pcapStatus = statusableToPcapStatus(statusable);        }    } catch (JobNotFoundException | InterruptedException e) {            } catch (JobException e) {        throw new RestException(e);    }    return pcapStatus;}
1
public List<PcapStatus> getJobStatus(String username, JobStatus.State state) throws RestException
{    List<PcapStatus> pcapStatuses = new ArrayList<>();    try {        List<Statusable<Path>> statusables = jobManager.getJobs(username);        if (statusables != null) {            pcapStatuses = statusables.stream().filter(statusable -> {                try {                    return statusable.getStatus().getState() == state;                } catch (JobException e) {                    return JobStatus.State.FAILED == state;                }            }).map(statusable -> {                try {                    return statusableToPcapStatus(statusable);                } catch (JobException | InterruptedException e) {                    PcapStatus pcapStatus = new PcapStatus();                    pcapStatus.setJobStatus(JobStatus.State.FAILED.toString());                    pcapStatus.setDescription(e.getMessage());                    return pcapStatus;                }            }).collect(Collectors.toList());        }    } catch (JobNotFoundException e) {        } catch (JobException e) {        throw new RestException(e);    }    return pcapStatuses;}
0
public PcapStatus killJob(String username, String jobId) throws RestException
{    try {        jobManager.killJob(username, jobId);    } catch (JobNotFoundException e) {                return null;    } catch (JobException e) {        throw new RestException(e);    }    return getJobStatus(username, jobId);}
1
public Path getPath(String username, String jobId, Integer page) throws RestException
{    Path path = null;    try {        Statusable<Path> statusable = jobManager.getJob(username, jobId);        if (statusable != null && statusable.isDone()) {            Pageable<Path> pageable = statusable.get();            if (pageable != null && page <= pageable.getSize() && page > 0) {                path = pageable.getPage(page - 1);            }        }    } catch (JobNotFoundException e) {            } catch (JobException | InterruptedException e) {        throw new RestException(e);    }    return path;}
1
public Pdml getPdml(String username, String jobId, Integer page) throws RestException
{    Pdml pdml = null;    Path path = getPath(username, jobId, page);    try {        FileSystem fileSystem = getFileSystem();        if (path != null && fileSystem.exists(path)) {            String scriptPath = environment.getProperty(MetronRestConstants.PCAP_PDML_SCRIPT_PATH_SPRING_PROPERTY);            InputStream processInputStream = pcapToPdmlScriptWrapper.execute(scriptPath, fileSystem, path);            pdml = new XmlMapper().readValue(processInputStream, Pdml.class);            processInputStream.close();        }    } catch (IOException e) {        throw new RestException(e);    }    return pdml;}
0
public InputStream getRawPcap(String username, String jobId, Integer page) throws RestException
{    InputStream inputStream = null;    Path path = getPath(username, jobId, page);    try {        FileSystem fileSystem = getFileSystem();        if (path != null && fileSystem.exists(path)) {            inputStream = fileSystem.open(path);        }    } catch (IOException e) {        throw new RestException(e);    }    return inputStream;}
0
public Map<String, Object> getConfiguration(String username, String jobId) throws RestException
{    Map<String, Object> configuration = new HashMap<>();    try {        Statusable<Path> statusable = jobManager.getJob(username, jobId);        if (statusable != null) {            Map<String, Object> jobConfiguration = statusable.getConfiguration();            configuration.put(PcapOptions.BASE_PATH.getKey(), PcapOptions.BASE_PATH.get(jobConfiguration, String.class));            configuration.put(PcapOptions.FINAL_OUTPUT_PATH.getKey(), PcapOptions.FINAL_OUTPUT_PATH.get(jobConfiguration, String.class));            configuration.put(PcapOptions.START_TIME_MS.getKey(), PcapOptions.START_TIME_MS.get(jobConfiguration, Long.class));            configuration.put(PcapOptions.END_TIME_MS.getKey(), PcapOptions.END_TIME_MS.get(jobConfiguration, Long.class));            configuration.put(PcapOptions.NUM_REDUCERS.getKey(), PcapOptions.NUM_REDUCERS.get(jobConfiguration, Integer.class));            boolean isFixedFilter = PcapOptions.FILTER_IMPL.get(jobConfiguration, PcapFilterConfigurator.class) instanceof FixedPcapFilter.Configurator;            if (isFixedFilter) {                configuration.put(FixedPcapOptions.IP_SRC_ADDR.getKey(), FixedPcapOptions.IP_SRC_ADDR.get(jobConfiguration, String.class));                configuration.put(FixedPcapOptions.IP_DST_ADDR.getKey(), FixedPcapOptions.IP_DST_ADDR.get(jobConfiguration, String.class));                configuration.put(FixedPcapOptions.IP_SRC_PORT.getKey(), FixedPcapOptions.IP_SRC_PORT.get(jobConfiguration, Integer.class));                configuration.put(FixedPcapOptions.IP_DST_PORT.getKey(), FixedPcapOptions.IP_DST_PORT.get(jobConfiguration, Integer.class));                configuration.put(FixedPcapOptions.PROTOCOL.getKey(), FixedPcapOptions.PROTOCOL.get(jobConfiguration, String.class));                configuration.put(FixedPcapOptions.PACKET_FILTER.getKey(), FixedPcapOptions.PACKET_FILTER.get(jobConfiguration, String.class));                configuration.put(FixedPcapOptions.INCLUDE_REVERSE.getKey(), FixedPcapOptions.INCLUDE_REVERSE.get(jobConfiguration, Boolean.class));            } else {                configuration.put(QueryPcapOptions.QUERY.getKey(), QueryPcapOptions.QUERY.get(jobConfiguration, String.class));            }        }    } catch (JobNotFoundException e) {            } catch (JobException e) {        throw new RestException(e);    }    return configuration;}
1
protected void setPcapOptions(String username, PcapRequest pcapRequest) throws IOException
{    PcapOptions.JOB_NAME.put(pcapRequest, "jobName");    PcapOptions.USERNAME.put(pcapRequest, username);    Configuration hadoopConf = new Configuration(configuration);    if (environment.containsProperty(PCAP_YARN_QUEUE_SPRING_PROPERTY)) {        String queue = environment.getProperty(PCAP_YARN_QUEUE_SPRING_PROPERTY);        if (queue != null && !queue.isEmpty()) {            hadoopConf.set(MRJobConfig.QUEUE_NAME, environment.getProperty(PCAP_YARN_QUEUE_SPRING_PROPERTY));        }    }    PcapOptions.HADOOP_CONF.put(pcapRequest, hadoopConf);    PcapOptions.FILESYSTEM.put(pcapRequest, getFileSystem());    if (pcapRequest.getBasePath() == null) {        pcapRequest.setBasePath(environment.getProperty(MetronRestConstants.PCAP_BASE_PATH_SPRING_PROPERTY));    }    if (pcapRequest.getBaseInterimResultPath() == null) {        pcapRequest.setBaseInterimResultPath(environment.getProperty(MetronRestConstants.PCAP_BASE_INTERIM_RESULT_PATH_SPRING_PROPERTY));    }    if (pcapRequest.getFinalOutputPath() == null) {        pcapRequest.setFinalOutputPath(environment.getProperty(MetronRestConstants.PCAP_FINAL_OUTPUT_PATH_SPRING_PROPERTY));    }    PcapOptions.NUM_RECORDS_PER_FILE.put(pcapRequest, Integer.parseInt(environment.getProperty(MetronRestConstants.PCAP_PAGE_SIZE_SPRING_PROPERTY)));    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(pcapRequest, environment.getProperty(MetronRestConstants.PCAP_FINALIZER_THREADPOOL_SIZE_SPRING_PROPERTY));}
0
protected FileSystem getFileSystem() throws IOException
{    return FileSystem.get(configuration);}
0
protected PcapStatus statusableToPcapStatus(Statusable<Path> statusable) throws JobException, InterruptedException
{    PcapStatus pcapStatus = jobStatusToPcapStatus(statusable.getStatus());    if (statusable.isDone()) {        Pageable<Path> pageable = statusable.get();        if (pageable != null) {            pcapStatus.setPageTotal(pageable.getSize());        }    }    return pcapStatus;}
0
protected PcapStatus jobStatusToPcapStatus(JobStatus jobStatus)
{    PcapStatus pcapStatus = new PcapStatus();    pcapStatus.setJobId(jobStatus.getJobId());    pcapStatus.setJobStatus(jobStatus.getState().toString());    pcapStatus.setDescription(jobStatus.getDescription());    pcapStatus.setPercentComplete(jobStatus.getPercentComplete());    return pcapStatus;}
0
public InputStream execute(String scriptPath, FileSystem fileSystem, Path pcapPath) throws IOException
{    ProcessBuilder processBuilder = getProcessBuilder(scriptPath, pcapPath.toUri().getPath());    Process process = processBuilder.start();    InputStream rawInputStream = getRawInputStream(fileSystem, pcapPath);    OutputStream processOutputStream = process.getOutputStream();    IOUtils.copy(rawInputStream, processOutputStream);    rawInputStream.close();    if (process.isAlive()) {                processOutputStream.close();        return process.getInputStream();    } else {        String errorMessage = IOUtils.toString(process.getErrorStream(), StandardCharsets.UTF_8);        throw new IOException(errorMessage);    }}
0
protected InputStream getRawInputStream(FileSystem fileSystem, Path path) throws IOException
{    return fileSystem.open(path);}
0
protected ProcessBuilder getProcessBuilder(String... command)
{    return new ProcessBuilder(command);}
0
public SearchResponse search(SearchRequest searchRequest) throws RestException
{    try {        if (searchRequest.getIndices() == null || searchRequest.getIndices().isEmpty()) {            List<String> indices = getDefaultIndices();                        indices.add(METAALERT_TYPE);            searchRequest.setIndices(indices);        }        if (searchRequest.getFacetFields() != null && searchRequest.getFacetFields().isEmpty()) {            searchRequest.setFacetFields(getDefaultFacetFields());        }        return dao.search(searchRequest);    } catch (InvalidSearchException ise) {        throw new RestException(ise.getMessage(), ise);    }}
0
public GroupResponse group(GroupRequest groupRequest) throws RestException
{    try {        if (groupRequest.getIndices() == null || groupRequest.getIndices().isEmpty()) {            groupRequest.setIndices(getDefaultIndices());        }        return dao.group(groupRequest);    } catch (InvalidSearchException ise) {        throw new RestException(ise.getMessage(), ise);    }}
0
public Optional<Map<String, Object>> getLatest(GetRequest request) throws RestException
{    try {        return dao.getLatestResult(request);    } catch (IOException e) {        throw new RestException(e.getMessage(), e);    }}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws RestException
{    try {        if (indices == null || indices.isEmpty()) {            indices = getDefaultIndices();                        indices.add(METAALERT_TYPE);                    }        return dao.getColumnMetadata(indices);    } catch (IOException ioe) {        throw new RestException(ioe.getMessage(), ioe);    }}
1
private List<String> getDefaultIndices() throws RestException
{        List<String> indices = Lists.newArrayList((sensorIndexingConfigService.getAllIndices(environment.getProperty(INDEX_WRITER_NAME))));        indices.remove(ERROR_TYPE);    return indices;}
0
public List<String> getDefaultFacetFields() throws RestException
{    Optional<AlertsUIUserSettings> alertUserSettings = alertsUIService.getAlertsUIUserSettings();    if (!alertUserSettings.isPresent() || alertUserSettings.get().getFacetFields() == null) {        String facetFieldsProperty = environment.getProperty(SEARCH_FACET_FIELDS_SPRING_PROPERTY, String.class, "");        String sourceTypeField = ConfigurationsUtils.getFieldName(globalConfigService.get(), SENSOR_TYPE_FIELD_PROPERTY, Constants.SENSOR_TYPE.replace('.', ':'));        List<String> facetFields = new ArrayList<>();        facetFields.add(sourceTypeField);        if (facetFieldsProperty != null) {            facetFields.addAll(Arrays.asList(facetFieldsProperty.split(",")));        }        return facetFields;    } else {        return alertUserSettings.get().getFacetFields();    }}
0
public SensorEnrichmentConfig save(String name, SensorEnrichmentConfig sensorEnrichmentConfig) throws RestException
{    try {        ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(name, objectMapper.writeValueAsString(sensorEnrichmentConfig).getBytes(StandardCharsets.UTF_8), client);    } catch (Exception e) {        throw new RestException(e);    }    return sensorEnrichmentConfig;}
0
public SensorEnrichmentConfig findOne(String name) throws RestException
{    EnrichmentConfigurations configs = cache.get(EnrichmentConfigurations.class);    return configs.getSensorEnrichmentConfig(name);}
0
public Map<String, SensorEnrichmentConfig> getAll() throws RestException
{    Map<String, SensorEnrichmentConfig> sensorEnrichmentConfigs = new HashMap<>();    List<String> sensorNames = getAllTypes();    for (String name : sensorNames) {        SensorEnrichmentConfig config = findOne(name);        if (config != null) {            sensorEnrichmentConfigs.put(name, config);        }    }    return sensorEnrichmentConfigs;}
0
public List<String> getAllTypes() throws RestException
{    EnrichmentConfigurations configs = cache.get(EnrichmentConfigurations.class);    return configs.getTypes();}
0
public boolean delete(String name) throws RestException
{    try {        client.delete().forPath(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/" + name);    } catch (KeeperException.NoNodeException e) {        return false;    } catch (Exception e) {        throw new RestException(e);    }    return true;}
0
public List<String> getAvailableEnrichments() throws RestException
{    try {        List<String> enrichments = hBaseClient.readRecords();        enrichments.sort(Comparator.naturalOrder());        return enrichments;    } catch (IOException e) {        throw new RestException("Unable to retrieve enrichments", e);    }}
0
public List<String> getAvailableThreatTriageAggregators()
{    return Arrays.asList(Aggregators.values()).stream().map(Enum::toString).collect(Collectors.toList());}
0
public Map<String, Object> save(String name, Map<String, Object> sensorIndexingConfig) throws RestException
{    try {        ConfigurationsUtils.writeSensorIndexingConfigToZookeeper(name, objectMapper.writeValueAsString(sensorIndexingConfig).getBytes(StandardCharsets.UTF_8), client);    } catch (Exception e) {        throw new RestException(e);    }    return sensorIndexingConfig;}
0
public Map<String, Object> findOne(String name) throws RestException
{    IndexingConfigurations configs = cache.get(IndexingConfigurations.class);    return configs.getSensorIndexingConfig(name, false);}
0
public Map<String, Map<String, Object>> getAll() throws RestException
{    Map<String, Map<String, Object>> sensorIndexingConfigs = new HashMap<>();    List<String> sensorNames = getAllTypes();    for (String name : sensorNames) {        Map<String, Object> config = findOne(name);        if (config != null) {            sensorIndexingConfigs.put(name, config);        }    }    return sensorIndexingConfigs;}
0
public List<String> getAllTypes() throws RestException
{    IndexingConfigurations configs = cache.get(IndexingConfigurations.class);    return configs.getTypes();}
0
public Iterable<String> getAllIndices(String writerName) throws RestException
{    if (StringUtils.isEmpty(writerName)) {        return Collections.emptyList();    }    IndexingConfigurations indexingConfigs = cache.get(IndexingConfigurations.class);    ParserConfigurations parserConfigs = cache.get(ParserConfigurations.class);    Set<String> ret = new HashSet<>();    for (String sensorName : Iterables.concat(parserConfigs.getTypes(), indexingConfigs.getTypes())) {        if (indexingConfigs.isEnabled(sensorName, writerName)) {            String indexName = indexingConfigs.getIndex(sensorName, writerName);            ret.add(indexName == null ? sensorName : indexName);        }    }    return ret;}
0
public boolean delete(String name) throws RestException
{    try {        client.delete().forPath(ConfigurationType.INDEXING.getZookeeperRoot() + "/" + name);    } catch (KeeperException.NoNodeException e) {        return false;    } catch (Exception e) {        throw new RestException(e);    }    return true;}
0
public SensorParserConfig save(String name, SensorParserConfig sensorParserConfig) throws RestException
{    try {        ConfigurationsUtils.writeSensorParserConfigToZookeeper(name, objectMapper.writeValueAsString(sensorParserConfig).getBytes(StandardCharsets.UTF_8), client);    } catch (Exception e) {        throw new RestException(e);    }    return sensorParserConfig;}
0
public SensorParserConfig findOne(String name) throws RestException
{    ParserConfigurations configs = cache.get(ParserConfigurations.class);    return configs.getSensorParserConfig(name);}
0
public Map<String, SensorParserConfig> getAll() throws RestException
{    Map<String, SensorParserConfig> sensorParserConfigs = new HashMap<>();    List<String> sensorNames = getAllTypes();    for (String name : sensorNames) {        SensorParserConfig config = findOne(name);        if (config != null) {            sensorParserConfigs.put(name, config);        }    }    return sensorParserConfigs;}
0
public boolean delete(String name) throws RestException
{    try {        client.delete().forPath(ConfigurationType.PARSER.getZookeeperRoot() + "/" + name);    } catch (KeeperException.NoNodeException e) {        return false;    } catch (Exception e) {        throw new RestException(e);    }    return true;}
0
public List<String> getAllTypes() throws RestException
{    ParserConfigurations configs = cache.get(ParserConfigurations.class);    return configs.getTypes();}
0
public Map<String, String> getAvailableParsers()
{    return ParserIndex.INSTANCE.getIndex();}
0
public Map<String, String> reloadAvailableParsers()
{    ParserIndex.INSTANCE.reload();    return getAvailableParsers();}
0
public JSONObject parseMessage(ParseMessageRequest parseMessageRequest) throws RestException
{    SensorParserConfig sensorParserConfig = parseMessageRequest.getSensorParserConfig();    if (sensorParserConfig == null) {        throw new RestException("SensorParserConfig is missing from ParseMessageRequest");    } else if (sensorParserConfig.getParserClassName() == null) {        throw new RestException("SensorParserConfig must have a parserClassName");    } else {        MessageParser<JSONObject> parser;        try {            parser = (MessageParser<JSONObject>) Class.forName(sensorParserConfig.getParserClassName()).newInstance();        } catch (Exception e) {            throw new RestException(e.toString(), e.getCause());        }        Path temporaryGrokPath = null;        if (isGrokConfig(sensorParserConfig)) {            String name = parseMessageRequest.getSensorParserConfig().getSensorTopic();            temporaryGrokPath = grokService.saveTemporary(parseMessageRequest.getGrokStatement(), name);            sensorParserConfig.getParserConfig().put(MetronRestConstants.GROK_PATH_KEY, new Path(temporaryGrokPath, name).toString());        }        parser.configure(sensorParserConfig.getParserConfig());        parser.init();        Optional<MessageParserResult<JSONObject>> result = parser.parseOptionalResult(parseMessageRequest.getSampleData().getBytes(StandardCharsets.UTF_8));        if (!result.isPresent()) {            throw new RestException("Unknown error parsing sample data");        }        if (result.get().getMasterThrowable().isPresent()) {            throw new RestException("Error parsing sample data", result.get().getMasterThrowable().get());        }        if (result.get().getMessages().isEmpty()) {            throw new RestException("No results from parsing sample data");        }        if (isGrokConfig(sensorParserConfig) && temporaryGrokPath != null) {            grokService.deleteTemporary();        }        return result.get().getMessages().get(0);    }}
0
private boolean isGrokConfig(SensorParserConfig sensorParserConfig)
{    return GROK_CLASS_NAME.equals(sensorParserConfig.getParserClassName());}
0
public SensorParserGroup save(SensorParserGroup sensorParserGroup) throws RestException
{    ParserConfigurations parserConfigurations = cache.get(ParserConfigurations.class);    Map<String, SensorParserGroup> groups = new HashMap<>(parserConfigurations.getSensorParserGroups());    groups.remove(sensorParserGroup.getName());    if (sensorParserGroup.getSensors().size() == 0) {        throw new RestException("A parser group must contain sensors");    }    for (String sensor : sensorParserGroup.getSensors()) {                if (sensorParserConfigService.findOne(sensor) == null) {            throw new RestException(String.format("Could not find config for sensor %s", sensor));        }                for (SensorParserGroup group : groups.values()) {            Set<String> groupSensors = group.getSensors();            if (groupSensors.contains(sensor)) {                throw new RestException(String.format("Sensor %s is already in group %s", sensor, group.getName()));            }        }    }    groups.put(sensorParserGroup.getName(), sensorParserGroup);    saveGroups(parserConfigurations, new HashSet<>(groups.values()));    return sensorParserGroup;}
0
public SensorParserGroup findOne(String name)
{    return getAll().get(name);}
0
public Map<String, SensorParserGroup> getAll()
{    ParserConfigurations configs = cache.get(ParserConfigurations.class);    return configs.getSensorParserGroups();}
0
public boolean delete(String name) throws RestException
{    ParserConfigurations parserConfigurations = cache.get(ParserConfigurations.class);    Map<String, SensorParserGroup> groups = parserConfigurations.getSensorParserGroups();    boolean deleted = false;    if (groups.containsKey(name)) {        groups.remove(name);        saveGroups(parserConfigurations, new HashSet<>(groups.values()));        deleted = true;    }    return deleted;}
0
private void saveGroups(ParserConfigurations parserConfigurations, Collection<SensorParserGroup> groups) throws RestException
{    Map<String, Object> globalConfig = parserConfigurations.getGlobalConfig(true);    globalConfig.put(ParserConfigurations.PARSER_GROUPS_CONF, groups);    globalConfigService.save(globalConfig);}
0
public Map<String, Boolean> validateRules(List<String> rules)
{    Map<String, Boolean> results = new HashMap<>();    StellarProcessor stellarProcessor = new StellarProcessor();    for (String rule : rules) {        try {            boolean result = stellarProcessor.validate(rule, Context.EMPTY_CONTEXT());            results.put(rule, result);        } catch (ParseException e) {            results.put(rule, false);        }    }    return results;}
0
public Map<String, Object> applyTransformations(SensorParserContext sensorParserContext)
{    JSONObject sampleJson = new JSONObject(sensorParserContext.getSampleData());    sensorParserContext.getSensorParserConfig().getFieldTransformations().forEach(fieldTransformer -> {        fieldTransformer.transformAndUpdate(sampleJson, Context.EMPTY_CONTEXT(), sensorParserContext.getSensorParserConfig().getParserConfig());    });    return sampleJson;}
0
public FieldTransformations[] getTransformations()
{    return FieldTransformations.values();}
0
public List<StellarFunctionDescription> getStellarFunctions()
{    List<StellarFunctionDescription> stellarFunctionDescriptions = new ArrayList<>();    Iterable<StellarFunctionInfo> stellarFunctionsInfo = StellarFunctions.FUNCTION_RESOLVER().getFunctionInfo();    stellarFunctionsInfo.forEach(stellarFunctionInfo -> {        stellarFunctionDescriptions.add(new StellarFunctionDescription(stellarFunctionInfo.getName(), stellarFunctionInfo.getDescription(), stellarFunctionInfo.getParams(), stellarFunctionInfo.getReturns()));    });    return stellarFunctionDescriptions;}
0
public List<StellarFunctionDescription> getSimpleStellarFunctions()
{    List<StellarFunctionDescription> stellarFunctionDescriptions = getStellarFunctions();    return stellarFunctionDescriptions.stream().filter(stellarFunctionDescription -> stellarFunctionDescription.getParams().length == 1).sorted((o1, o2) -> o1.getName().compareTo(o2.getName())).collect(Collectors.toList());}
0
public TopologyResponse startParserTopology(String name) throws RestException
{    TopologyResponse topologyResponse = new TopologyResponse();    if (globalConfigService.get() == null) {        topologyResponse.setErrorMessage(TopologyStatusCode.GLOBAL_CONFIG_MISSING.toString());        return topologyResponse;    }    List<String> sensorTypes = Collections.singletonList(name);        SensorParserGroup sensorParserGroup = sensorParserGroupService.findOne(name);    if (sensorParserGroup != null) {        sensorTypes = new ArrayList<>(sensorParserGroup.getSensors());    }    for (String sensorType : sensorTypes) {        if (sensorParserConfigService.findOne(sensorType.trim()) == null) {            topologyResponse.setErrorMessage(TopologyStatusCode.SENSOR_PARSER_CONFIG_MISSING.toString());            return topologyResponse;        }    }        Collections.sort(sensorTypes);    return createResponse(stormCLIClientWrapper.startParserTopology(String.join(ParserTopologyCLI.TOPOLOGY_OPTION_SEPARATOR, sensorTypes)), TopologyStatusCode.STARTED, TopologyStatusCode.START_ERROR);}
0
public TopologyResponse stopParserTopology(String name, boolean stopNow) throws RestException
{        TopologyStatus topologyStatus = stormStatusService.getTopologyStatus(name);    String jobName = topologyStatus != null ? topologyStatus.getName() : name;    return createResponse(stormCLIClientWrapper.stopParserTopology(jobName, stopNow), TopologyStatusCode.STOPPED, TopologyStatusCode.STOP_ERROR);}
0
public TopologyResponse startEnrichmentTopology() throws RestException
{    return createResponse(stormCLIClientWrapper.startEnrichmentTopology(), TopologyStatusCode.STARTED, TopologyStatusCode.START_ERROR);}
0
public TopologyResponse stopEnrichmentTopology(boolean stopNow) throws RestException
{    return createResponse(stormCLIClientWrapper.stopEnrichmentTopology(stopNow), TopologyStatusCode.STOPPED, TopologyStatusCode.STOP_ERROR);}
0
public TopologyResponse startIndexingTopology(String scriptPath) throws RestException
{    return createResponse(stormCLIClientWrapper.startIndexingTopology(scriptPath), TopologyStatusCode.STARTED, TopologyStatusCode.START_ERROR);}
0
public TopologyResponse stopIndexingTopology(String name, boolean stopNow) throws RestException
{    return createResponse(stormCLIClientWrapper.stopIndexingTopology(name, stopNow), TopologyStatusCode.STOPPED, TopologyStatusCode.STOP_ERROR);}
0
private TopologyResponse createResponse(int responseCode, TopologyStatusCode successMessage, TopologyStatusCode errorMessage)
{    TopologyResponse topologyResponse = new TopologyResponse();    if (responseCode == 0) {        topologyResponse.setSuccessMessage(successMessage.toString());    } else {        topologyResponse.setErrorMessage(errorMessage.toString());    }    return topologyResponse;}
0
public Map<String, String> getStormClientStatus() throws RestException
{    return stormCLIClientWrapper.getStormClientStatus();}
0
public void setEnvironment(final Environment environment)
{    this.environment = environment;}
0
public int startParserTopology(String name) throws RestException
{    kinit();    return runCommand(getParserStartCommand(name));}
0
public int stopParserTopology(String name, boolean stopNow) throws RestException
{    kinit();    return runCommand(getStopCommand(name, stopNow));}
0
public int startEnrichmentTopology() throws RestException
{    kinit();    return runCommand(getEnrichmentStartCommand());}
0
public int stopEnrichmentTopology(boolean stopNow) throws RestException
{    kinit();    return runCommand(getStopCommand(ENRICHMENT_TOPOLOGY_NAME, stopNow));}
0
public int startIndexingTopology(String scriptPath) throws RestException
{    kinit();    return runCommand(getIndexingStartCommand(scriptPath));}
0
public int stopIndexingTopology(String name, boolean stopNow) throws RestException
{    kinit();    return runCommand(getStopCommand(name, stopNow));}
0
protected int runCommand(String[] command) throws RestException
{    ProcessBuilder pb = getProcessBuilder(command);    pb.inheritIO();        Process process;    try {        process = pb.start();        process.waitFor();    } catch (Exception e) {        throw new RestException(e);    }    int exitValue = process.exitValue();        return exitValue;}
1
protected String[] getParserStartCommand(String names)
{    List<String> command = new ArrayList<>();    command.add(environment.getProperty(MetronRestConstants.PARSER_SCRIPT_PATH_SPRING_PROPERTY));        command.add("-s");    command.add(names);        command.add("-z");    command.add(environment.getProperty(MetronRestConstants.ZK_URL_SPRING_PROPERTY));        command.add("-k");    command.add(environment.getProperty(MetronRestConstants.KAFKA_BROKER_URL_SPRING_PROPERTY));        command.add("-ksp");    command.add(KafkaUtils.INSTANCE.normalizeProtocol(environment.getProperty(MetronRestConstants.KAFKA_SECURITY_PROTOCOL_SPRING_PROPERTY)));        boolean kerberosEnabled = environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false);    boolean topologyOptionsDefined = StringUtils.isNotBlank(environment.getProperty(MetronRestConstants.PARSER_TOPOLOGY_OPTIONS_SPRING_PROPERTY));    if (kerberosEnabled && topologyOptionsDefined) {        command.add("-e");        command.add(environment.getProperty(MetronRestConstants.PARSER_TOPOLOGY_OPTIONS_SPRING_PROPERTY));    }    return command.toArray(new String[0]);}
0
protected String[] getEnrichmentStartCommand()
{    String[] command = new String[1];    command[0] = environment.getProperty(MetronRestConstants.ENRICHMENT_SCRIPT_PATH_SPRING_PROPERTY);    return command;}
0
protected String[] getIndexingStartCommand(String scriptPath)
{    String[] command = new String[1];    command[0] = environment.getProperty(scriptPath);    return command;}
0
protected String[] getStopCommand(String name, boolean stopNow)
{    String[] command;    if (stopNow) {        command = new String[5];        command[3] = "-w";        command[4] = "0";    } else {        command = new String[3];    }    command[0] = "storm";    command[1] = "kill";    command[2] = name;    return command;}
0
protected ProcessBuilder getProcessBuilder(String... command)
{    return new ProcessBuilder(command);}
0
public Map<String, String> getStormClientStatus() throws RestException
{    Map<String, String> status = new HashMap<>();    status.put("parserScriptPath", environment.getProperty(MetronRestConstants.PARSER_SCRIPT_PATH_SPRING_PROPERTY));    status.put("enrichmentScriptPath", environment.getProperty(MetronRestConstants.ENRICHMENT_SCRIPT_PATH_SPRING_PROPERTY));    status.put("randomAccessIndexingScriptPath", environment.getProperty(MetronRestConstants.RANDOM_ACCESS_INDEXING_SCRIPT_PATH_SPRING_PROPERTY));    status.put("batchIndexingScriptPath", environment.getProperty(MetronRestConstants.BATCH_INDEXING_SCRIPT_PATH_SPRING_PROPERTY));    status.put("stormClientVersionInstalled", stormClientVersionInstalled());    return status;}
0
protected String stormClientVersionInstalled() throws RestException
{    String stormClientVersionInstalled = "Storm client is not installed";    ProcessBuilder pb = getProcessBuilder("storm", "version");    pb.redirectErrorStream(true);    Process p;    try {        p = pb.start();    } catch (IOException e) {        throw new RestException(e);    }    BufferedReader reader = new BufferedReader(new InputStreamReader(p.getInputStream(), StandardCharsets.UTF_8));    List<String> lines = reader.lines().collect(toList());    lines.forEach(System.out::println);    if (lines.size() > 1) {        stormClientVersionInstalled = lines.get(1).replaceFirst("Storm ", "");    }    return stormClientVersionInstalled;}
0
protected void kinit() throws RestException
{    if (environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)) {        String keyTabLocation = environment.getProperty(MetronRestConstants.KERBEROS_KEYTAB_SPRING_PROPERTY);        String userPrincipal = environment.getProperty(MetronRestConstants.KERBEROS_PRINCIPLE_SPRING_PROPERTY);        String[] kinitCommand = { "kinit", "-kt", keyTabLocation, userPrincipal };        runCommand(kinitCommand);    }}
0
public SupervisorSummary getSupervisorSummary()
{    return restTemplate.getForObject(getStormUiProperty() + SUPERVISOR_SUMMARY_URL, SupervisorSummary.class);}
0
public TopologySummary getTopologySummary()
{    return restTemplate.getForObject(getStormUiProperty() + TOPOLOGY_SUMMARY_URL, TopologySummary.class);}
0
public TopologyStatus getTopologyStatus(String name)
{    TopologyStatus topologyResponse = null;    String id = getTopologyId(name);    if (id != null) {        topologyResponse = restTemplate.getForObject(getStormUiProperty() + TOPOLOGY_URL + "/" + id, TopologyStatus.class);    }    return topologyResponse;}
0
public List<TopologyStatus> getAllTopologyStatus()
{    List<TopologyStatus> topologyStatus = new ArrayList<>();    for (TopologyStatus topology : getTopologySummary().getTopologies()) {        topologyStatus.add(restTemplate.getForObject(getStormUiProperty() + TOPOLOGY_URL + "/" + topology.getId(), TopologyStatus.class));    }    return topologyStatus;}
0
public TopologyResponse activateTopology(String name)
{    TopologyResponse topologyResponse = new TopologyResponse();    String id = getTopologyId(name);    if (id != null) {        Map result = restTemplate.postForObject(getStormUiProperty() + TOPOLOGY_URL + "/" + id + "/activate", null, Map.class);        if ("success".equals(result.get("status"))) {            topologyResponse.setSuccessMessage(TopologyStatusCode.ACTIVE.toString());        } else {            topologyResponse.setErrorMessage((String) result.get("status"));        }    } else {        topologyResponse.setErrorMessage(TopologyStatusCode.TOPOLOGY_NOT_FOUND.toString());    }    return topologyResponse;}
0
public TopologyResponse deactivateTopology(String name)
{    TopologyResponse topologyResponse = new TopologyResponse();    String id = getTopologyId(name);    if (id != null) {        Map result = restTemplate.postForObject(getStormUiProperty() + TOPOLOGY_URL + "/" + id + "/deactivate", null, Map.class);        if ("success".equals(result.get("status"))) {            topologyResponse.setSuccessMessage(TopologyStatusCode.INACTIVE.toString());        } else {            topologyResponse.setErrorMessage((String) result.get("status"));        }    } else {        topologyResponse.setErrorMessage(TopologyStatusCode.TOPOLOGY_NOT_FOUND.toString());    }    return topologyResponse;}
0
protected String getStormUiProperty()
{    String baseValue = environment.getProperty(STORM_UI_SPRING_PROPERTY);    if (!(baseValue.contains("://"))) {        return "http://" + baseValue;    }    return baseValue;}
0
protected String getTopologyId(String name)
{    String id = null;    for (TopologyStatus topology : getTopologySummary().getTopologies()) {        String topologyName = topology.getName();                if (topologyName.contains(ParserTopologyCLI.STORM_JOB_SEPARATOR)) {            Set<String> sensors = new HashSet<>(Arrays.asList(topologyName.split(ParserTopologyCLI.STORM_JOB_SEPARATOR)));            SensorParserGroup group = sensorParserGroupService.findOne(name);            if (group == null) {                break;            } else if (sensors.equals(group.getSensors())) {                id = topology.getId();                break;            }        }        if (topologyName.equals(name)) {            id = topology.getId();            break;        }    }    return id;}
0
public Document patch(PatchRequest request) throws RestException, OriginalNotFoundException
{    try {        return dao.patch(dao, request, Optional.of(System.currentTimeMillis()));    } catch (Exception e) {        throw new RestException(e.getMessage(), e);    }}
0
public Document addComment(CommentAddRemoveRequest request) throws RestException
{    try {        return dao.addCommentToAlert(request);    } catch (Exception e) {        throw new RestException(e.getMessage(), e);    }}
0
public Document removeComment(CommentAddRemoveRequest request) throws RestException
{    try {        return dao.removeCommentFromAlert(request);    } catch (Exception e) {        throw new RestException(e.getMessage(), e);    }}
0
public synchronized void init(Supplier<Map<String, Object>> globalConfigSupplier, TableProvider tableProvider)
{    if (this.userSettingsTable == null) {        Map<String, Object> globalConfig = globalConfigSupplier.get();        if (globalConfig == null) {            throw new IllegalStateException("Cannot find the global config.");        }        String table = (String) globalConfig.get(USER_SETTINGS_HBASE_TABLE);        String cf = (String) globalConfigSupplier.get().get(USER_SETTINGS_HBASE_CF);        if (table == null || cf == null) {            throw new IllegalStateException("You must configure " + USER_SETTINGS_HBASE_TABLE + " and " + USER_SETTINGS_HBASE_CF + " in the global config.");        }        try {            userSettingsTable = tableProvider.getTable(HBaseConfiguration.create(), table);            this.cf = cf.getBytes(StandardCharsets.UTF_8);        } catch (IOException e) {            throw new IllegalStateException("Unable to initialize HBaseDao: " + e.getMessage(), e);        }    }}
0
public Table getTableInterface()
{    if (userSettingsTable == null) {        init(globalConfigSupplier, tableProvider);    }    return userSettingsTable;}
0
public Map<String, String> findOne(String user) throws IOException
{    Result result = getResult(user);    return getAllUserSettings(result);}
0
public Optional<String> findOne(String user, String type) throws IOException
{    Result result = getResult(user);    return getUserSettings(result, type);}
0
public Map<String, Map<String, String>> findAll() throws IOException
{    Scan scan = new Scan();    ResultScanner results = getTableInterface().getScanner(scan);    Map<String, Map<String, String>> allUserSettings = new HashMap<>();    for (Result result : results) {        allUserSettings.put(new String(result.getRow(), StandardCharsets.UTF_8), getAllUserSettings(result));    }    return allUserSettings;}
0
public Map<String, Optional<String>> findAll(String type) throws IOException
{    Scan scan = new Scan();    ResultScanner results = getTableInterface().getScanner(scan);    Map<String, Optional<String>> allUserSettings = new HashMap<>();    for (Result result : results) {        allUserSettings.put(new String(result.getRow(), StandardCharsets.UTF_8), getUserSettings(result, type));    }    return allUserSettings;}
0
public void save(String user, String type, String userSettings) throws IOException
{    byte[] rowKey = Bytes.toBytes(user);    Put put = new Put(rowKey);    put.addColumn(cf, Bytes.toBytes(type), Bytes.toBytes(userSettings));    getTableInterface().put(put);}
0
public void delete(String user) throws IOException
{    Delete delete = new Delete(Bytes.toBytes(user));    getTableInterface().delete(delete);}
0
public void delete(String user, String type) throws IOException
{    Delete delete = new Delete(Bytes.toBytes(user));    delete.addColumn(cf, Bytes.toBytes(type));    getTableInterface().delete(delete);}
0
private Result getResult(String user) throws IOException
{    byte[] rowKey = Bytes.toBytes(user);    Get get = new Get(rowKey);    get.addFamily(cf);    return getTableInterface().get(get);}
0
private Optional<String> getUserSettings(Result result, String type) throws IOException
{    Optional<String> userSettings = Optional.empty();    if (result != null) {        byte[] value = result.getValue(cf, Bytes.toBytes(type));        if (value != null) {            userSettings = Optional.of(new String(value, StandardCharsets.UTF_8));        }    }    return userSettings;}
0
public Map<String, String> getAllUserSettings(Result result)
{    if (result == null) {        return new HashMap<>();    }    NavigableMap<byte[], byte[]> columns = result.getFamilyMap(cf);    if (columns == null || columns.size() == 0) {        return new HashMap<>();    }    Map<String, String> userSettingsMap = new HashMap<>();    for (Map.Entry<byte[], byte[]> column : columns.entrySet()) {        userSettingsMap.put(new String(column.getKey(), StandardCharsets.UTF_8), new String(column.getValue(), StandardCharsets.UTF_8));    }    return userSettingsMap;}
0
public synchronized Map<String, String> getIndex()
{    if (availableParsers == null) {        load();    }    return availableParsers;}
0
public synchronized Set<Class<? extends MessageParser>> getClasses()
{    if (index == null) {        load();    }    return index;}
0
public static void reload()
{    load();}
0
private static Collection<URL> effectiveClassPathUrls(ClassLoader... classLoaders)
{    return ClasspathHelper.forManifest(ClasspathHelper.forClassLoader(classLoaders));}
0
public void init(FilterConfig filterConfig) throws ServletException
{}
0
public void destroy()
{}
0
public void setUp() throws Exception
{    environment = mock(Environment.class);    hadoopConfig = new HadoopConfig(environment);    mockStatic(UserGroupInformation.class);}
0
public void configurationShouldReturnProperKerberosConfiguration() throws IOException
{    when(environment.getProperty(MetronRestConstants.KERBEROS_KEYTAB_SPRING_PROPERTY)).thenReturn("metron keytabLocation");    when(environment.getProperty(MetronRestConstants.KERBEROS_PRINCIPLE_SPRING_PROPERTY)).thenReturn("metron principal");    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(true);    Configuration configuration = hadoopConfig.configuration();    verifyStatic();    UserGroupInformation.setConfiguration(any(Configuration.class));    UserGroupInformation.loginUserFromKeytab("metron keytabLocation", "metron principal");}
0
public void configurationShouldReturnProperConfiguration() throws IOException
{    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    Configuration configuration = hadoopConfig.configuration();    verifyStatic(never());    UserGroupInformation.setConfiguration(any(Configuration.class));    UserGroupInformation.loginUserFromKeytab(anyString(), anyString());    assertEquals("simple", configuration.get("hadoop.security.authentication"));}
0
public void setUp() throws Exception
{    globalConfigService = mock(GlobalConfigService.class);    hBaseConfig = new HBaseConfig(globalConfigService);    mockStatic(HBaseConfiguration.class);}
0
public void userSettingsTableShouldBeReturnedFromGlobalConfigByDefault() throws Exception
{    when(globalConfigService.get()).thenReturn(new HashMap<String, Object>() {        {            put(USER_SETTINGS_HBASE_TABLE, "global_config_user_settings_table");            put(USER_SETTINGS_HBASE_CF, "global_config_user_settings_cf");        }    });    HTableProvider htableProvider = mock(HTableProvider.class);    whenNew(HTableProvider.class).withNoArguments().thenReturn(htableProvider);    Configuration configuration = mock(Configuration.class);    when(HBaseConfiguration.create()).thenReturn(configuration);    hBaseConfig.userSettingsClient();    verify(htableProvider).getTable(configuration, "global_config_user_settings_table");    verifyZeroInteractions(htableProvider);}
0
public void hBaseClientShouldBeCreatedWithSpecifiedProvider() throws Exception
{    when(globalConfigService.get()).thenReturn(new HashMap<String, Object>() {        {            put(EnrichmentConfigurations.TABLE_PROVIDER, MockHBaseTableProvider.class.getName());            put(EnrichmentConfigurations.TABLE_NAME, "enrichment_list_hbase_table_name");        }    });    Assert.assertNotNull(hBaseConfig.hBaseClient());}
0
public void setUp() throws Exception
{    environment = mock(Environment.class);    kafkaConfig = new KafkaConfig(environment);}
0
public void kafkaConfigShouldProperlyReturnConsumerProperties() throws Exception
{    when(environment.getProperty(MetronRestConstants.KAFKA_BROKER_URL_SPRING_PROPERTY)).thenReturn("broker urls");    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    Map<String, Object> consumerProperties = kafkaConfig.consumerProperties();    assertEquals("broker urls", consumerProperties.get("bootstrap.servers"));    assertNull(consumerProperties.get("security.protocol"));    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(true);    when(environment.getProperty(MetronRestConstants.KAFKA_SECURITY_PROTOCOL_SPRING_PROPERTY)).thenReturn("kafka security protocol");    consumerProperties = kafkaConfig.consumerProperties();    assertEquals("kafka security protocol", consumerProperties.get("security.protocol"));}
0
public void kafkaConfigShouldProperlyReturnProducerProperties() throws Exception
{    when(environment.getProperty(MetronRestConstants.KAFKA_BROKER_URL_SPRING_PROPERTY)).thenReturn("broker urls");    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    Map<String, Object> producerProperties = kafkaConfig.producerProperties();    assertEquals("broker urls", producerProperties.get("bootstrap.servers"));    assertNull(producerProperties.get("security.protocol"));    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(true);    when(environment.getProperty(MetronRestConstants.KAFKA_SECURITY_PROTOCOL_SPRING_PROPERTY)).thenReturn("kafka security protocol");    producerProperties = kafkaConfig.consumerProperties();    assertEquals("kafka security protocol", producerProperties.get("security.protocol"));}
0
public void shouldThrowExceptionOnMissingLdapTemplate()
{    exception.expect(IllegalStateException.class);    exception.expectMessage("KnoxSSO requires LDAP. You must add 'ldap' to the active profiles.");    new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", null);}
0
public void doFilterShouldProperlySetAuthentication() throws Exception
{    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));    HttpServletRequest request = mock(HttpServletRequest.class);    ServletResponse response = mock(ServletResponse.class);    FilterChain chain = mock(FilterChain.class);    SignedJWT signedJWT = mock(SignedJWT.class);    mockStatic(SignedJWT.class);    JWTClaimsSet jwtClaimsSet = new JWTClaimsSet.Builder().subject("userName").build();    Authentication authentication = mock(Authentication.class);    SecurityContext securityContext = mock(SecurityContext.class);    mockStatic(SecurityContextHolder.class);    when(request.getHeader("Authorization")).thenReturn(null);    doReturn("serializedJWT").when(knoxSSOAuthenticationFilter).getJWTFromCookie(request);    when(SignedJWT.parse("serializedJWT")).thenReturn(signedJWT);    when(signedJWT.getJWTClaimsSet()).thenReturn(jwtClaimsSet);    doReturn(true).when(knoxSSOAuthenticationFilter).isValid(signedJWT, "userName");    doReturn(authentication).when(knoxSSOAuthenticationFilter).getAuthentication("userName", request);    when(SecurityContextHolder.getContext()).thenReturn(securityContext);    knoxSSOAuthenticationFilter.doFilter(request, response, chain);    verify(securityContext).setAuthentication(authentication);    verify(chain).doFilter(request, response);    verifyNoMoreInteractions(chain, securityContext);}
0
public void doFilterShouldContinueOnBasicAuthenticationHeader() throws Exception
{    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));    HttpServletRequest request = mock(HttpServletRequest.class);    ServletResponse response = mock(ServletResponse.class);    FilterChain chain = mock(FilterChain.class);    when(request.getHeader("Authorization")).thenReturn("Basic ");    knoxSSOAuthenticationFilter.doFilter(request, response, chain);    verify(knoxSSOAuthenticationFilter, times(0)).getJWTFromCookie(request);    verify(chain).doFilter(request, response);    verifyNoMoreInteractions(chain);}
0
public void doFilterShouldContinueOnParseException() throws Exception
{    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));    HttpServletRequest request = mock(HttpServletRequest.class);    ServletResponse response = mock(ServletResponse.class);    FilterChain chain = mock(FilterChain.class);    SignedJWT signedJWT = mock(SignedJWT.class);    mockStatic(SignedJWT.class);    when(request.getHeader("Authorization")).thenReturn(null);    doReturn("serializedJWT").when(knoxSSOAuthenticationFilter).getJWTFromCookie(request);    when(SignedJWT.parse("serializedJWT")).thenThrow(new ParseException("parse exception", 0));    knoxSSOAuthenticationFilter.doFilter(request, response, chain);    verify(knoxSSOAuthenticationFilter, times(0)).getAuthentication("userName", request);    verify(chain).doFilter(request, response);    verifyNoMoreInteractions(chain);}
0
public void doFilterShouldContinueOnInvalidToken() throws Exception
{    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));    HttpServletRequest request = mock(HttpServletRequest.class);    ServletResponse response = mock(ServletResponse.class);    FilterChain chain = mock(FilterChain.class);    SignedJWT signedJWT = mock(SignedJWT.class);    mockStatic(SignedJWT.class);    JWTClaimsSet jwtClaimsSet = new JWTClaimsSet.Builder().subject("userName").build();    when(request.getHeader("Authorization")).thenReturn(null);    doReturn("serializedJWT").when(knoxSSOAuthenticationFilter).getJWTFromCookie(request);    when(SignedJWT.parse("serializedJWT")).thenReturn(signedJWT);    when(signedJWT.getJWTClaimsSet()).thenReturn(jwtClaimsSet);    doReturn(false).when(knoxSSOAuthenticationFilter).isValid(signedJWT, "userName");    knoxSSOAuthenticationFilter.doFilter(request, response, chain);    verify(knoxSSOAuthenticationFilter, times(0)).getAuthentication("userName", request);    verify(chain).doFilter(request, response);    verifyNoMoreInteractions(chain);}
0
public void isValidShouldProperlyValidateToken() throws Exception
{    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));    SignedJWT jwtToken = mock(SignedJWT.class);    {                assertFalse(knoxSSOAuthenticationFilter.isValid(jwtToken, null));    }    {                Date expiredDate = new Date(System.currentTimeMillis() - 10000);        JWTClaimsSet jwtClaimsSet = new JWTClaimsSet.Builder().expirationTime(expiredDate).build();        when(jwtToken.getJWTClaimsSet()).thenReturn(jwtClaimsSet);        assertFalse(knoxSSOAuthenticationFilter.isValid(jwtToken, "userName"));    }    {                Date notBeforeDate = new Date(System.currentTimeMillis() + 10000);        JWTClaimsSet jwtClaimsSet = new JWTClaimsSet.Builder().notBeforeTime(notBeforeDate).build();        when(jwtToken.getJWTClaimsSet()).thenReturn(jwtClaimsSet);        assertFalse(knoxSSOAuthenticationFilter.isValid(jwtToken, "userName"));    }    {                Date expiredDate = new Date(System.currentTimeMillis() + 10000);        Date notBeforeDate = new Date(System.currentTimeMillis() - 10000);        JWTClaimsSet jwtClaimsSet = new JWTClaimsSet.Builder().expirationTime(expiredDate).notBeforeTime(notBeforeDate).build();        when(jwtToken.getJWTClaimsSet()).thenReturn(jwtClaimsSet);        doReturn(true).when(knoxSSOAuthenticationFilter).validateSignature(jwtToken);        assertTrue(knoxSSOAuthenticationFilter.isValid(jwtToken, "userName"));    }}
0
public void validateSignatureShouldProperlyValidateToken() throws Exception
{    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));    SignedJWT jwtToken = mock(SignedJWT.class);    {                JWSHeader jwsHeader = new JWSHeader(JWSAlgorithm.ES384);        when(jwtToken.getHeader()).thenReturn(jwsHeader);        assertFalse(knoxSSOAuthenticationFilter.validateSignature(jwtToken));    }    {                JWSHeader jwsHeader = new JWSHeader(JWSAlgorithm.RS256);        when(jwtToken.getHeader()).thenReturn(jwsHeader);        when(jwtToken.getState()).thenReturn(JWSObject.State.UNSIGNED);        assertFalse(knoxSSOAuthenticationFilter.validateSignature(jwtToken));    }    {                JWSHeader jwsHeader = new JWSHeader(JWSAlgorithm.RS256);        when(jwtToken.getHeader()).thenReturn(jwsHeader);        when(jwtToken.getState()).thenReturn(JWSObject.State.SIGNED);        assertFalse(knoxSSOAuthenticationFilter.validateSignature(jwtToken));    }    {        Base64URL signature = mock(Base64URL.class);        when(jwtToken.getSignature()).thenReturn(signature);        RSAPublicKey rsaPublicKey = mock(RSAPublicKey.class);        RSASSAVerifier rsaSSAVerifier = mock(RSASSAVerifier.class);        mockStatic(SecurityUtils.class);        when(SecurityUtils.parseRSAPublicKey("knoxKeyString")).thenReturn(rsaPublicKey);        whenNew(RSASSAVerifier.class).withArguments(rsaPublicKey).thenReturn(rsaSSAVerifier);        {                        when(jwtToken.verify(rsaSSAVerifier)).thenThrow(new JOSEException("verify exception"));            assertFalse(knoxSSOAuthenticationFilter.validateSignature(jwtToken));        }        {                        doReturn(false).when(jwtToken).verify(rsaSSAVerifier);            assertFalse(knoxSSOAuthenticationFilter.validateSignature(jwtToken));        }        {                        doReturn(true).when(jwtToken).verify(rsaSSAVerifier);            assertTrue(knoxSSOAuthenticationFilter.validateSignature(jwtToken));        }    }}
0
public void getJWTFromCookieShouldProperlyReturnToken()
{    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));    HttpServletRequest request = mock(HttpServletRequest.class);    {                assertNull(knoxSSOAuthenticationFilter.getJWTFromCookie(request));    }    {                Cookie cookie = new Cookie("someCookie", "someValue");        when(request.getCookies()).thenReturn(new Cookie[] { cookie });        assertNull(knoxSSOAuthenticationFilter.getJWTFromCookie(request));    }    {                Cookie cookie = new Cookie("knoxCookie", "token");        when(request.getCookies()).thenReturn(new Cookie[] { cookie });        assertEquals("token", knoxSSOAuthenticationFilter.getJWTFromCookie(request));    }}
0
public void getKnoxKeyShouldProperlyReturnKnoxKey() throws Exception
{    {        KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", mock(Path.class), "knoxKeyString", "knoxCookie", mock(LdapTemplate.class)));        assertEquals("knoxKeyString", knoxSSOAuthenticationFilter.getKnoxKey());    }    {        FileUtils.writeStringToFile(new File("./target/knoxKeyFile"), "knoxKeyFileKeyString", StandardCharsets.UTF_8);        KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("userSearchBase", Paths.get("./target/knoxKeyFile"), null, "knoxCookie", mock(LdapTemplate.class)));        assertEquals("knoxKeyFileKeyString", knoxSSOAuthenticationFilter.getKnoxKey());    }}
0
public void getAuthenticationShouldProperlyPopulateAuthentication() throws Exception
{    LdapTemplate ldapTemplate = mock(LdapTemplate.class);    KnoxSSOAuthenticationFilter knoxSSOAuthenticationFilter = spy(new KnoxSSOAuthenticationFilter("ou=people,dc=hadoop,dc=apache,dc=org", mock(Path.class), "knoxKeyString", "knoxCookie", ldapTemplate));    HttpServletRequest request = mock(HttpServletRequest.class);    when(ldapTemplate.search(any(LdapQuery.class), any(AttributesMapper.class))).thenReturn(Arrays.asList("USER", "ADMIN"));    Authentication authentication = knoxSSOAuthenticationFilter.getAuthentication("userName", request);    Object[] grantedAuthorities = authentication.getAuthorities().toArray();    assertEquals("ROLE_USER", grantedAuthorities[0].toString());    assertEquals("ROLE_ADMIN", grantedAuthorities[1].toString());    assertEquals("userName", authentication.getName());}
0
public void shouldMapUserRole()
{    mapper = new MetronAuthoritiesMapper();    mapper.setUserRole("ACME_USER");    mapper.setAdminRole("ACME_ADMIN");    mapper.setPrefix("ROLE_");        List<GrantedAuthority> input = new ArrayList<>();    input.add(new SimpleGrantedAuthority("ROLE_" + "ACME_USER"));        Collection<? extends GrantedAuthority> actuals = mapper.mapAuthorities(input);    Assert.assertEquals(1, actuals.size());    Assert.assertEquals(SECURITY_ROLE_PREFIX + SECURITY_ROLE_USER, actuals.iterator().next().getAuthority());}
0
public void shouldMapAdminRole()
{    mapper = new MetronAuthoritiesMapper();    mapper.setUserRole("ACME_USER");    mapper.setAdminRole("ACME_ADMIN");    mapper.setPrefix("ROLE_");    List<GrantedAuthority> input = new ArrayList<>();    input.add(new SimpleGrantedAuthority("ROLE_" + "ACME_ADMIN"));        Collection<? extends GrantedAuthority> actuals = mapper.mapAuthorities(input);    Assert.assertEquals(1, actuals.size());    Assert.assertEquals(SECURITY_ROLE_PREFIX + SECURITY_ROLE_ADMIN, actuals.iterator().next().getAuthority());}
0
public void shouldIgnoreOtherRoles()
{    mapper = new MetronAuthoritiesMapper();    mapper.setUserRole("ACME_USER");    mapper.setAdminRole("ACME_ADMIN");    mapper.setPrefix("ROLE_");    List<GrantedAuthority> input = new ArrayList<>();    input.add(new SimpleGrantedAuthority("ROLE_" + "ANOTHER_ROLE"));    input.add(new SimpleGrantedAuthority("ROLE_" + "YET_ANOTHER_ROLE"));    Collection<? extends GrantedAuthority> actuals = mapper.mapAuthorities(input);    Assert.assertEquals(0, actuals.size());}
0
public void shouldMapRolesWithNoPrefix()
{        mapper = new MetronAuthoritiesMapper();    mapper.setUserRole("ACME_USER");    mapper.setAdminRole("ACME_ADMIN");    mapper.setPrefix("");    List<GrantedAuthority> input = new ArrayList<>();    input.add(new SimpleGrantedAuthority("ACME_ADMIN"));        Collection<? extends GrantedAuthority> actuals = mapper.mapAuthorities(input);    Assert.assertEquals(1, actuals.size());    Assert.assertEquals(SECURITY_ROLE_PREFIX + SECURITY_ROLE_ADMIN, actuals.iterator().next().getAuthority());}
0
public void setUp() throws Exception
{    environment = mock(Environment.class);    restTemplateConfig = new RestTemplateConfig(environment);}
0
public void restTemplateShouldReturnProperTemplate() throws Exception
{    when(environment.getProperty(MetronRestConstants.KERBEROS_KEYTAB_SPRING_PROPERTY)).thenReturn("metron keytabLocation");    when(environment.getProperty(MetronRestConstants.KERBEROS_PRINCIPLE_SPRING_PROPERTY)).thenReturn("metron principal");    whenNew(KerberosRestTemplate.class).withParameterTypes(String.class, String.class).withArguments("metron keytabLocation", "metron principal").thenReturn(null);    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(true);    restTemplateConfig.restTemplate();    verifyNew(KerberosRestTemplate.class).withArguments("metron keytabLocation", "metron principal");    whenNew(RestTemplate.class).withNoArguments().thenReturn(null);    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    restTemplateConfig.restTemplate();    verifyNew(RestTemplate.class).withNoArguments();}
0
public Properties zkProperties()
{    return new Properties();}
0
public ZKServerComponent zkServerComponent(Properties zkProperties)
{    return new ZKServerComponent().withPostStartCallback((zkComponent) -> zkProperties.setProperty(ZKServerComponent.ZOOKEEPER_PROPERTY, zkComponent.getConnectionString()));}
0
public KafkaComponent kafkaWithZKComponent(Properties zkProperties)
{    return new KafkaComponent().withTopologyProperties(zkProperties);}
0
public ConfigurationsCache cache(CuratorFramework client)
{    return new ZKConfigurationsCache(client, ZKConfigurationsCache.ConfiguredTypes.ENRICHMENT, ZKConfigurationsCache.ConfiguredTypes.PARSER, ZKConfigurationsCache.ConfiguredTypes.INDEXING);}
0
public ComponentRunner componentRunner(ZKServerComponent zkServerComponent, KafkaComponent kafkaWithZKComponent)
{    ComponentRunner runner = new ComponentRunner.Builder().withComponent("zk", zkServerComponent).withCustomShutdownOrder(new String[] { "search", "zk" }).build();    try {        runner.start();        File globalConfigFile = new File("src/test/resources/zookeeper/global.json");        try (BufferedReader r = new BufferedReader(new InputStreamReader(new FileInputStream(globalConfigFile), StandardCharsets.UTF_8))) {            String globalConfig = IOUtils.toString(r);            ConfigurationsUtils.writeGlobalConfigToZookeeper(globalConfig.getBytes(StandardCharsets.UTF_8), zkServerComponent.getConnectionString());        } catch (Exception e) {            throw new IllegalStateException("Unable to upload global config", e);        }    } catch (UnableToStartException e) {        e.printStackTrace();    }    return runner;}
0
public CuratorFramework client(ComponentRunner componentRunner)
{    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    ZKServerComponent zkServerComponent = componentRunner.getComponent("zk", ZKServerComponent.class);    return CuratorFrameworkFactory.newClient(zkServerComponent.getConnectionString(), retryPolicy);}
0
public ZkClient zkClient(ComponentRunner componentRunner)
{    ZKServerComponent zkServerComponent = componentRunner.getComponent("zk", ZKServerComponent.class);    return new ZkClient(zkServerComponent.getConnectionString(), 10000, 10000, ZKStringSerializer$.MODULE$);}
0
public ZkUtils zkUtils(ZkClient zkClient)
{    return ZkUtils.apply(zkClient, false);}
0
public Map<String, Object> kafkaConsumer(KafkaComponent kafkaWithZKComponent)
{    Map<String, Object> props = new HashMap<>();    props.put("bootstrap.servers", kafkaWithZKComponent.getBrokerList());    props.put("group.id", "metron-config");    props.put("enable.auto.commit", "false");    props.put("auto.commit.interval.ms", "1000");    props.put("session.timeout.ms", "30000");    props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");    props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");    return props;}
0
public ConsumerFactory<String, String> createConsumerFactory()
{    return new DefaultKafkaConsumerFactory<>(kafkaConsumer(kafkaWithZKComponent(zkProperties())));}
0
public Map<String, Object> producerProperties(KafkaComponent kafkaWithZKComponent)
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", kafkaWithZKComponent.getBrokerList());    producerConfig.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");    producerConfig.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");    producerConfig.put("request.required.acks", 1);    return producerConfig;}
0
public KafkaProducer kafkaProducer(KafkaComponent kafkaWithZKComponent)
{    return new KafkaProducer<>(producerProperties(kafkaWithZKComponent));}
0
public StormCLIWrapper stormCLIClientWrapper()
{    return new MockStormCLIClientWrapper();}
0
public RestTemplate restTemplate(StormCLIWrapper stormCLIClientWrapper)
{    MockStormRestTemplate restTemplate = new MockStormRestTemplate();    restTemplate.setMockStormCLIClientWrapper((MockStormCLIClientWrapper) stormCLIClientWrapper);    return restTemplate;}
0
public AdminUtils$ adminUtils()
{    return AdminUtils$.MODULE$;}
0
public UserSettingsClient userSettingsClient() throws RestException, IOException
{    return new UserSettingsClient(new MockHBaseTableProvider().addToCache("user_settings", "cf"), Bytes.toBytes("cf"));}
0
public HBaseClient hBaseClient() throws RestException, IOException
{    final String cf = "t";    final String cq = "v";    Table table = MockHBaseTableProvider.addToCache("enrichment_list", cf);    List<String> enrichmentTypes = new ArrayList<String>() {        {            add("foo");            add("bar");            add("baz");        }    };    for (String type : enrichmentTypes) {        Put put = new Put(Bytes.toBytes(type));        put.addColumn(Bytes.toBytes(cf), Bytes.toBytes(cq), "{}".getBytes(StandardCharsets.UTF_8));        table.put(put);    }    return new HBaseClient(new MockHBaseTableProvider(), HBaseConfiguration.create(), "enrichment_list");}
0
public JobManager jobManager()
{    return new InMemoryJobManager();}
0
public MockPcapJob mockPcapJob()
{    return new MockPcapJob();}
0
public PcapJobSupplier pcapJobSupplier(MockPcapJob mockPcapJob)
{    MockPcapJobSupplier mockPcapJobSupplier = new MockPcapJobSupplier();    mockPcapJobSupplier.setMockPcapJob(mockPcapJob);    return mockPcapJobSupplier;}
0
public PcapToPdmlScriptWrapper pcapToPdmlScriptWrapper()
{    return new MockPcapToPdmlScriptWrapper();}
0
public StormStatusService stormStatusService(@Autowired @Qualifier("StormStatusServiceImpl") StormStatusService wrappedService)
{    long maxCacheSize = 0L;    long maxCacheTimeoutSeconds = 0L;    return new CachedStormStatusServiceImpl(wrappedService, maxCacheSize, maxCacheTimeoutSeconds);}
0
public void setup() throws Exception
{    for (String user : alertsUIService.findAllAlertsUIUserSettings().keySet()) {        alertsUIService.deleteAlertsUIUserSettings(user);    }    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(alertUrl + "/escalate").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(alerts)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(alertUrl + "/settings")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(alertUrl + "/settings/all")).andExpect(status().isUnauthorized());    this.mockMvc.perform(post(alertUrl + "/settings").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(user1AlertUserSettingsJson)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(alertUrl + "/settings/all").with(httpBasic(user1, password)).with(csrf())).andExpect(status().isForbidden());    this.mockMvc.perform(delete(alertUrl + "/settings/user1").with(httpBasic(user1, password)).with(csrf())).andExpect(status().isForbidden());}
0
public void escalateShouldEscalateAlerts() throws Exception
{    startKafka();    this.mockMvc.perform(post(alertUrl + "/escalate").with(httpBasic(user1, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(alerts)).andExpect(status().isOk());    stopKafka();}
0
public void testAlertProfiles() throws Exception
{    emptyProfileShouldReturnNotFound();    alertsProfilesShouldBeCreatedOrUpdated();    alertsProfilesShouldBeProperlyDeleted();}
0
private void emptyProfileShouldReturnNotFound() throws Exception
{        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user1, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user2, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(alertUrl + "/settings/all").with(httpBasic(admin, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(0)));}
0
private void alertsProfilesShouldBeCreatedOrUpdated() throws Exception
{        this.mockMvc.perform(post(alertUrl + "/settings").with(httpBasic(user1, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(user1AlertUserSettingsJson)).andExpect(status().isCreated());        this.mockMvc.perform(post(alertUrl + "/settings").with(httpBasic(user1, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(user1AlertUserSettingsJson)).andExpect(status().isOk());        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user1, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json(user1AlertUserSettingsJson));        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user2, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(alertUrl + "/settings/all").with(httpBasic(admin, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json("{\"" + user1 + "\": " + user1AlertUserSettingsJson + "}"));        this.mockMvc.perform(post(alertUrl + "/settings").with(httpBasic(user2, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(user2AlertUserSettingsJson)).andExpect(status().isCreated());        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user1, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json(user1AlertUserSettingsJson));        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user2, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json(user2AlertUserSettingsJson));        this.mockMvc.perform(get(alertUrl + "/settings/all").with(httpBasic(admin, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json("{\"" + user1 + "\": " + user1AlertUserSettingsJson + ",\"" + user2 + "\": " + user2AlertUserSettingsJson + "}"));}
0
private void alertsProfilesShouldBeProperlyDeleted() throws Exception
{        this.mockMvc.perform(delete(alertUrl + "/settings/user1").with(httpBasic(admin, password))).andExpect(status().isOk());        this.mockMvc.perform(delete(alertUrl + "/settings/user1").with(httpBasic(admin, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user1, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user2, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json(user2AlertUserSettingsJson));        this.mockMvc.perform(get(alertUrl + "/settings/all").with(httpBasic(admin, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json("{\"" + user2 + "\": " + user2AlertUserSettingsJson + "}"));        this.mockMvc.perform(delete(alertUrl + "/settings/user2").with(httpBasic(admin, password))).andExpect(status().isOk());        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user1, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(alertUrl + "/settings").with(httpBasic(user2, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(alertUrl + "/settings/all").with(httpBasic(admin, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(0)));}
0
private void startKafka()
{    runner = new ComponentRunner.Builder().withComponent("kafka", kafkaWithZKComponent).withCustomShutdownOrder(new String[] { "kafka" }).build();    try {        runner.start();    } catch (UnableToStartException e) {        e.printStackTrace();    }}
0
private void stopKafka()
{    runner.stop();}
0
public void loadTestData(Map<String, String> indicesToDataMap) throws ParseException
{    Map<String, List<String>> backingStore = new HashMap<>();    for (Map.Entry<String, String> indices : indicesToDataMap.entrySet()) {        List<String> results = new ArrayList<>();        backingStore.put(indices.getKey(), results);        JSONArray docArray = (JSONArray) new JSONParser().parse(indices.getValue());        int i = 0;        for (Object o : docArray) {            JSONObject jsonObject = (JSONObject) o;                        if (!jsonObject.containsKey(Constants.GUID)) {                jsonObject.put(Constants.GUID, indices.getKey() + ":" + i++);            }            results.add(jsonObject.toJSONString());        }    }    InMemoryDao.load(backingStore);}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(globalConfigUrl).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(globalJson)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(globalConfigUrl)).andExpect(status().isUnauthorized());    this.mockMvc.perform(delete(globalConfigUrl).with(csrf())).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    this.globalConfigService.delete();    assertEventually(() -> this.mockMvc.perform(get(globalConfigUrl).with(httpBasic(user, password))).andExpect(status().isNotFound()));    this.mockMvc.perform(post(globalConfigUrl).with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(globalJson)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8")));    assertEventually(() -> this.mockMvc.perform(post(globalConfigUrl).with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(globalJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))));    this.mockMvc.perform(get(globalConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk());    this.mockMvc.perform(delete(globalConfigUrl).with(httpBasic(user, password)).with(csrf())).andExpect(status().isOk());    assertEventually(() -> this.mockMvc.perform(delete(globalConfigUrl).with(httpBasic(user, password)).with(csrf())).andExpect(status().isNotFound()));    this.globalConfigService.delete();}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(grokUrl + "/validate").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(grokValidationJson)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(grokUrl + "/list")).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    this.mockMvc.perform(post(grokUrl + "/validate").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(grokValidationJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.results.action").value("TCP_MISS")).andExpect(jsonPath("$.results.bytes").value(337891)).andExpect(jsonPath("$.results.code").value(200)).andExpect(jsonPath("$.results.elapsed").value(415)).andExpect(jsonPath("$.results.ip_dst_addr").value("207.109.73.154")).andExpect(jsonPath("$.results.ip_src_addr").value("127.0.0.1")).andExpect(jsonPath("$.results.method").value("GET")).andExpect(jsonPath("$.results.timestamp").value("1467011157.401")).andExpect(jsonPath("$.results.url").value("http://www.aliexpress.com/af/shoes.html?"));    this.mockMvc.perform(post(grokUrl + "/validate").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(missingPatternLabelGrokValidationJson)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("Pattern label is required"));    this.mockMvc.perform(post(grokUrl + "/validate").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(missingStatementGrokValidationJson)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("Grok statement is required"));    this.mockMvc.perform(get(grokUrl + "/list").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$").isNotEmpty());    String statement = FileUtils.readFileToString(new File("../../metron-platform/metron-parsing/metron-parsers/src/main/resources/patterns/squid"));    this.mockMvc.perform(get(grokUrl + "/get/statement?path=/patterns/squid").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("text/plain;charset=UTF-8"))).andExpect(content().bytes(statement.getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(get(grokUrl + "/get/statement?path=/bad/path").with(httpBasic(user, password))).andExpect(status().isInternalServerError()).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("Could not find a statement at path /bad/path"));}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(hdfsUrl).with(csrf()).contentType(MediaType.parseMediaType("text/plain;charset=UTF-8")).content(fileContents)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(hdfsUrl)).andExpect(status().isUnauthorized());    this.mockMvc.perform(delete(hdfsUrl).with(csrf())).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    this.hdfsService.delete(new Path(path), false);    this.mockMvc.perform(get(hdfsUrl + "?path=" + path).with(httpBasic(user, password))).andExpect(status().isNotFound());    this.mockMvc.perform(post(hdfsUrl + "?path=" + path).with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("text/plain;charset=UTF-8")).content(fileContents)).andExpect(status().isOk());    this.mockMvc.perform(get(hdfsUrl + "?path=" + path).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("text/plain;charset=UTF-8"))).andExpect(content().bytes(fileContents.getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(delete(hdfsUrl + "?path=" + path).with(httpBasic(user, password)).with(csrf())).andExpect(status().isOk());    this.mockMvc.perform(delete(hdfsUrl + "?path=" + path).with(httpBasic(user, password)).with(csrf())).andExpect(status().isNotFound());}
0
private void testAndRetry(Evaluation evaluation) throws Exception
{    testAndRetry(KAFKA_RETRY, evaluation);}
0
private void testAndRetry(int numRetries, Evaluation evaluation) throws Exception
{    AssertionError lastError = null;    for (int i = 0; i < numRetries; ++i) {        try {            evaluation.tryTest();            return;        } catch (AssertionError error) {            if (error.getMessage().contains("but was:<404>")) {                lastError = error;                Thread.sleep(1000);                continue;            } else {                throw error;            }        }    }    if (lastError != null) {        throw lastError;    }}
0
public void setup() throws Exception
{    runner = new ComponentRunner.Builder().withComponent("kafka", kafkaWithZKComponent).withCustomShutdownOrder(new String[] { "kafka" }).build();    try {        runner.start();    } catch (UnableToStartException e) {        e.printStackTrace();    }    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(kafkaUrl + "/topic").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broTopic)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(kafkaUrl + "/topic/bro")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(kafkaUrl + "/topic")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(kafkaUrl + "/topic/bro/sample")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(kafkaUrl + "/topic/bro/produce")).andExpect(status().isUnauthorized());    this.mockMvc.perform(delete(kafkaUrl + "/topic/bro").with(csrf())).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    this.kafkaService.deleteTopic("bro");    this.kafkaService.deleteTopic("someTopic");    Thread.sleep(1000);    testAndRetry(() -> this.mockMvc.perform(delete(kafkaUrl + "/topic/bro").with(httpBasic(user, password)).with(csrf())).andExpect(status().isNotFound()));    testAndRetry(() -> this.mockMvc.perform(post(kafkaUrl + "/topic").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broTopic)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.name").value("bro")).andExpect(jsonPath("$.numPartitions").value(1)).andExpect(jsonPath("$.replicationFactor").value(1)));    Thread.sleep(1000);    testAndRetry(() -> this.mockMvc.perform(get(kafkaUrl + "/topic/bro").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.name").value("bro")).andExpect(jsonPath("$.numPartitions").value(1)).andExpect(jsonPath("$.replicationFactor").value(1)));    this.mockMvc.perform(get(kafkaUrl + "/topic/someTopic").with(httpBasic(user, password))).andExpect(status().isNotFound());    testAndRetry(() -> this.mockMvc.perform(get(kafkaUrl + "/topic").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$", Matchers.hasItem("bro"))));    testAndRetry(() -> this.mockMvc.perform(post(kafkaUrl + "/topic/bro/produce").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(message1)).andExpect(status().isOk()));    testAndRetry(() -> this.mockMvc.perform(get(kafkaUrl + "/topic/bro/sample").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("text/plain;charset=UTF-8"))).andExpect(jsonPath("$.type").value("message1")));    testAndRetry(() -> this.mockMvc.perform(post(kafkaUrl + "/topic/bro/produce").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(message2)).andExpect(status().isOk()));    testAndRetry(() -> this.mockMvc.perform(get(kafkaUrl + "/topic/bro/sample").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("text/plain;charset=UTF-8"))).andExpect(jsonPath("$.type").value("message2")));    testAndRetry(() -> this.mockMvc.perform(post(kafkaUrl + "/topic/bro/produce").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(message3)).andExpect(status().isOk()));    testAndRetry(() -> this.mockMvc.perform(get(kafkaUrl + "/topic/bro/sample").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("text/plain;charset=UTF-8"))).andExpect(jsonPath("$.type").value("message3")));    this.mockMvc.perform(get(kafkaUrl + "/topic/someTopic/sample").with(httpBasic(user, password))).andExpect(status().isNotFound());    boolean deleted = false;    for (int i = 0; i < KAFKA_RETRY; ++i) {        try {            MvcResult result = this.mockMvc.perform(delete(kafkaUrl + "/topic/bro").with(httpBasic(user, password)).with(csrf())).andReturn();            if (result.getResponse().getStatus() == 200) {                deleted = true;                break;            }            Thread.sleep(1000);        } catch (NestedServletException nse) {            Throwable t = nse.getRootCause();            if (t instanceof TopicAlreadyMarkedForDeletionException) {                continue;            } else {                throw nse;            }        } catch (Throwable t) {            throw t;        }    }    if (!deleted) {        throw new IllegalStateException("Unable to delete kafka topic \"bro\"");    }}
0
public void tearDown()
{    runner.stop();}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();    ImmutableMap<String, String> testData = ImmutableMap.of("bro_index_2017.01.01.01", SearchIntegrationTest.broData, "snort_index_2017.01.01.01", SearchIntegrationTest.snortData, metaAlertIndex, metaAlertData);    loadTestData(testData);}
0
public void cleanup()
{    InMemoryMetaAlertDao.clear();}
0
public void test() throws Exception
{            String guid = "missing_1";    ResultActions result = this.mockMvc.perform(post(metaalertUrl + "/searchByAlert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("text/plain;charset=UTF-8")).content(guid));    result.andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(0));        guid = "snort_1";    result = this.mockMvc.perform(post(metaalertUrl + "/searchByAlert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("text/plain;charset=UTF-8")).content(guid));    result.andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(1)).andExpect(jsonPath("$.results[0].source.guid").value("meta_2")).andExpect(jsonPath("$.results[0].source.count").value(3.0));        guid = "bro_1";    result = this.mockMvc.perform(post(metaalertUrl + "/searchByAlert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("text/plain;charset=UTF-8")).content(guid));    result.andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(2)).andExpect(jsonPath("$.results[0].source.guid").value("meta_2")).andExpect(jsonPath("$.results[0].source.count").value(3.0)).andExpect(jsonPath("$.results[1].source.guid").value("meta_1")).andExpect(jsonPath("$.results[1].source.count").value(1.0));}
0
public void shouldCreateMetaAlert() throws Exception
{    ResultActions result = this.mockMvc.perform(post(metaalertUrl + "/create").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(create));    result.andExpect(status().isOk()).andExpect(jsonPath("$.guid", notNullValue())).andExpect(jsonPath("$.timestamp", greaterThan(0L))).andExpect(jsonPath("$.sensorType").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.timestamp", greaterThan(0L))).andExpect(jsonPath("$.document['source.type']").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.status").value("active")).andExpect(jsonPath("$.document.groups[0]").value("group_one")).andExpect(jsonPath("$.document.groups[1]").value("group_two")).andExpect(jsonPath("$.document.metron_alert[0].guid").value("bro_1")).andExpect(jsonPath("$.document.metron_alert[1].guid").value("snort_2"));}
0
public void shouldAddRemoveAlerts() throws Exception
{    MetaAlertAddRemoveRequest addRequest = new MetaAlertAddRemoveRequest();    addRequest.setMetaAlertGuid("meta_1");    addRequest.setAlerts(new ArrayList<GetRequest>() {        {            add(new GetRequest("bro_2", "bro", "bro_index_2017.01.01.01"));            add(new GetRequest("bro_3", "bro", "bro_index_2017.01.01.01"));        }    });    ResultActions result = this.mockMvc.perform(post(metaalertUrl + "/add/alert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(JSONUtils.INSTANCE.toJSON(addRequest, false)));    result.andExpect(status().isOk()).andExpect(jsonPath("$.guid").value("meta_1")).andExpect(jsonPath("$.sensorType").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.metron_alert[0].guid").value("bro_1")).andExpect(jsonPath("$.document.metron_alert[1].guid").value("bro_2")).andExpect(jsonPath("$.document.metron_alert[2].metaalerts").value("meta_1")).andExpect(jsonPath("$.document.metron_alert[2].guid").value("bro_3")).andExpect(jsonPath("$.document.metron_alert[2].metaalerts").value("meta_1"));    MetaAlertAddRemoveRequest addDuplicateRequest = new MetaAlertAddRemoveRequest();    addDuplicateRequest.setMetaAlertGuid("meta_1");    addDuplicateRequest.setAlerts(new ArrayList<GetRequest>() {        {            add(new GetRequest("bro_1", "bro"));        }    });    result = this.mockMvc.perform(post(metaalertUrl + "/add/alert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(JSONUtils.INSTANCE.toJSON(addDuplicateRequest, false)));    result.andExpect(status().isOk()).andExpect(jsonPath("$.guid").value("meta_1")).andExpect(jsonPath("$.sensorType").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.metron_alert[0].guid").value("bro_1")).andExpect(jsonPath("$.document.metron_alert[1].guid").value("bro_2")).andExpect(jsonPath("$.document.metron_alert[2].metaalerts").value("meta_1")).andExpect(jsonPath("$.document.metron_alert[2].guid").value("bro_3")).andExpect(jsonPath("$.document.metron_alert[2].metaalerts").value("meta_1"));    MetaAlertAddRemoveRequest removeRequest = new MetaAlertAddRemoveRequest();    removeRequest.setMetaAlertGuid("meta_1");    removeRequest.setAlerts(new ArrayList<GetRequest>() {        {            add(new GetRequest("bro_2", "bro"));            add(new GetRequest("bro_3", "bro"));        }    });    result = this.mockMvc.perform(post(metaalertUrl + "/remove/alert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(JSONUtils.INSTANCE.toJSON(removeRequest, false)));    result.andExpect(status().isOk()).andExpect(jsonPath("$.guid").value("meta_1")).andExpect(jsonPath("$.sensorType").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.metron_alert.*", hasSize(equalTo(1)))).andExpect(jsonPath("$.document.metron_alert[0].guid").value("bro_1"));    MetaAlertAddRemoveRequest removeMissingRequest = new MetaAlertAddRemoveRequest();    removeMissingRequest.setMetaAlertGuid("meta_1");    removeMissingRequest.setAlerts(new ArrayList<GetRequest>() {        {            add(new GetRequest("bro_2", "bro"));        }    });    result = this.mockMvc.perform(post(metaalertUrl + "/remove/alert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(JSONUtils.INSTANCE.toJSON(removeMissingRequest, false)));    result.andExpect(status().isOk()).andExpect(jsonPath("$.guid").value("meta_1")).andExpect(jsonPath("$.sensorType").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.metron_alert.*", hasSize(equalTo(1)))).andExpect(jsonPath("$.document.metron_alert[0].guid").value("bro_1"));    MetaAlertAddRemoveRequest emptyMetaAlertRequest = new MetaAlertAddRemoveRequest();    emptyMetaAlertRequest.setMetaAlertGuid("meta_1");    emptyMetaAlertRequest.setAlerts(new ArrayList<GetRequest>() {        {            add(new GetRequest("bro_1", "bro"));        }    });    result = this.mockMvc.perform(post(metaalertUrl + "/remove/alert").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(JSONUtils.INSTANCE.toJSON(emptyMetaAlertRequest, false)));    result.andExpect(status().isInternalServerError()).andExpect(jsonPath("$.message").value("Removing these alerts will result in an empty meta alert.  Empty meta alerts are not allowed.")).andExpect(jsonPath("$.fullMessage").value("IllegalStateException: Removing these alerts will result in an empty meta alert.  Empty meta alerts are not allowed."));}
0
public void shouldUpdateStatus() throws Exception
{    ResultActions result = this.mockMvc.perform(post(metaalertUrl + "/update/status/meta_2/inactive").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")));    result.andExpect(status().isOk()).andExpect(jsonPath("$.guid").value("meta_2")).andExpect(jsonPath("$.sensorType").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.status").value("inactive"));    result = this.mockMvc.perform(post(metaalertUrl + "/update/status/meta_2/active").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")));    result.andExpect(status().isOk()).andExpect(jsonPath("$.guid").value("meta_2")).andExpect(jsonPath("$.sensorType").value(MetaAlertConstants.METAALERT_TYPE)).andExpect(jsonPath("$.document.status").value("active"));}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();    InMemoryJobManager jobManager = (InMemoryJobManager) wac.getBean("jobManager");    jobManager.clear();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(pcapUrl + "/fixed").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isUnauthorized());    this.mockMvc.perform(post(pcapUrl + "/query").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(queryJson)).andExpect(status().isUnauthorized());}
0
public void testFixedRequest() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    Assert.assertEquals("/base/path", mockPcapJob.getBasePath());    Assert.assertEquals("/base/interim/result/path", mockPcapJob.getBaseInterrimResultPath());    Assert.assertEquals("/final/output/path", mockPcapJob.getFinalOutputPath());    Assert.assertEquals(10000000, mockPcapJob.getStartTimeNs());    Assert.assertEquals(20000000, mockPcapJob.getEndTimeNs());    Assert.assertEquals(2, mockPcapJob.getNumReducers());    Assert.assertTrue(mockPcapJob.getFilterImpl() instanceof FixedPcapFilter.Configurator);    Map<String, String> actualFixedFields = mockPcapJob.getFixedFields();    Assert.assertEquals("192.168.1.2", actualFixedFields.get(Constants.Fields.SRC_ADDR.getName()));    Assert.assertEquals("2000", actualFixedFields.get(Constants.Fields.SRC_PORT.getName()));    Assert.assertEquals("192.168.1.1", actualFixedFields.get(Constants.Fields.DST_ADDR.getName()));    Assert.assertEquals("1000", actualFixedFields.get(Constants.Fields.DST_PORT.getName()));    Assert.assertEquals("true", actualFixedFields.get(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName()));    Assert.assertEquals("TCP", actualFixedFields.get(Constants.Fields.PROTOCOL.getName()));    Assert.assertEquals("filter", actualFixedFields.get(PcapHelper.PacketFields.PACKET_FILTER.getName()));}
0
public void testFixedRequestDefaults() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withState(JobStatus.State.RUNNING));    long beforeJobTime = System.currentTimeMillis();    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedWithDefaultsJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    Assert.assertEquals("/apps/metron/pcap/input", mockPcapJob.getBasePath());    Assert.assertEquals("/apps/metron/pcap/interim", mockPcapJob.getBaseInterrimResultPath());    Assert.assertEquals("/apps/metron/pcap/output", mockPcapJob.getFinalOutputPath());    Assert.assertEquals(0, mockPcapJob.getStartTimeNs());    Assert.assertTrue(beforeJobTime < mockPcapJob.getEndTimeNs() / 1000000);    Assert.assertTrue(System.currentTimeMillis() > mockPcapJob.getEndTimeNs() / 1000000);    Assert.assertEquals(10, mockPcapJob.getNumReducers());    Assert.assertTrue(mockPcapJob.getFilterImpl() instanceof FixedPcapFilter.Configurator);    Map<String, String> actualFixedFields = mockPcapJob.getFixedFields();    Assert.assertEquals("192.168.1.2", actualFixedFields.get(Constants.Fields.SRC_ADDR.getName()));    Assert.assertEquals("2000", actualFixedFields.get(Constants.Fields.SRC_PORT.getName()));    Assert.assertEquals("192.168.1.1", actualFixedFields.get(Constants.Fields.DST_ADDR.getName()));    Assert.assertEquals("1000", actualFixedFields.get(Constants.Fields.DST_PORT.getName()));    Assert.assertEquals("true", actualFixedFields.get(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName()));    Assert.assertEquals("TCP", actualFixedFields.get(Constants.Fields.PROTOCOL.getName()));    Assert.assertEquals("filter", actualFixedFields.get(PcapHelper.PacketFields.PACKET_FILTER.getName()));}
0
public void testQueryRequest() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/query").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(queryJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    Assert.assertEquals("/base/path", mockPcapJob.getBasePath());    Assert.assertEquals("/base/interim/result/path", mockPcapJob.getBaseInterrimResultPath());    Assert.assertEquals("/final/output/path", mockPcapJob.getFinalOutputPath());    Assert.assertEquals(10000000, mockPcapJob.getStartTimeNs());    Assert.assertEquals(20000000, mockPcapJob.getEndTimeNs());    Assert.assertEquals(2, mockPcapJob.getNumReducers());    Assert.assertTrue(mockPcapJob.getFilterImpl() instanceof QueryPcapFilter.Configurator);    Assert.assertEquals("query", mockPcapJob.getQuery());}
0
public void testTooManyJobs() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.message").value("Cannot submit job because a job is already running.  Please contact the administrator to cancel job(s) with id(s) jobId"));}
0
public void testGetStatus() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.SUCCEEDED));    Pageable<Path> pageable = new PcapPages(Arrays.asList(new Path("path1"), new Path("path1")));    mockPcapJob.setIsDone(true);    mockPcapJob.setPageable(pageable);    this.mockMvc.perform(get(pcapUrl + "/jobId").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobStatus").value("SUCCEEDED")).andExpect(jsonPath("$.pageTotal").value(2));    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.FINALIZING));    this.mockMvc.perform(get(pcapUrl + "/jobId").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobStatus").value("FINALIZING"));    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.FAILED));    this.mockMvc.perform(get(pcapUrl + "/jobId").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobStatus").value("FAILED"));    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.KILLED));    this.mockMvc.perform(get(pcapUrl + "/jobId").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobStatus").value("KILLED"));    this.mockMvc.perform(get(pcapUrl + "/someJobId").with(httpBasic(user, password))).andExpect(status().isNotFound());}
0
public void testGetStatusList() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    this.mockMvc.perform(get(pcapUrl + "?state=RUNNING").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[0].jobId").value("jobId")).andExpect(jsonPath("$[0].jobStatus").value("RUNNING"));    this.mockMvc.perform(get(pcapUrl + "?state=SUCCEEDED").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().json("[]"));}
0
public void testKillJob() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    this.mockMvc.perform(get(pcapUrl + "/jobId123").with(httpBasic(user, password))).andExpect(status().isNotFound());    mockPcapJob.setStatus(new JobStatus().withJobId("jobId123").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId123")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    mockPcapJob.setStatus(new JobStatus().withJobId("jobId123").withState(JobStatus.State.KILLED));    this.mockMvc.perform(delete(pcapUrl + "/kill/{id}", "jobId123").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId123")).andExpect(jsonPath("$.jobStatus").value("KILLED"));    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.KILLED));}
0
public void testKillNonExistentJobReturns404() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    this.mockMvc.perform(get(pcapUrl + "/jobId123").with(httpBasic(user, password))).andExpect(status().isNotFound());    this.mockMvc.perform(delete(pcapUrl + "/kill/{id}", "jobId123").with(httpBasic(user, password))).andExpect(status().isNotFound());}
0
public void testGetPdml() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    Pageable<Path> pageable = new PcapPages(Arrays.asList(new Path("./target")));    mockPcapJob.setIsDone(true);    mockPcapJob.setPageable(pageable);    this.mockMvc.perform(get(pcapUrl + "/jobId/pdml?page=1").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.version").value("0")).andExpect(jsonPath("$.creator").value("wireshark/2.6.1")).andExpect(jsonPath("$.time").value("Thu Jun 28 14:14:38 2018")).andExpect(jsonPath("$.captureFile").value("/tmp/pcap-data-201806272004-289365c53112438ca55ea047e13a12a5+0001.pcap")).andExpect(jsonPath("$.packets[0].protos[0].name").value("geninfo")).andExpect(jsonPath("$.packets[0].protos[0].fields[0].name").value("num")).andExpect(jsonPath("$.packets[0].protos[1].name").value("ip")).andExpect(jsonPath("$.packets[0].protos[1].fields[0].name").value("ip.addr"));    this.mockMvc.perform(get(pcapUrl + "/jobId/pdml?page=0").with(httpBasic(user, password))).andExpect(status().isNotFound());    this.mockMvc.perform(get(pcapUrl + "/jobId/pdml?page=2").with(httpBasic(user, password))).andExpect(status().isNotFound());}
0
public void testRawDownload() throws Exception
{    String pcapFileContents = "pcap file contents";    FileUtils.write(new File("./target/pcapFile"), pcapFileContents, "UTF8");    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    Pageable<Path> pageable = new PcapPages(Arrays.asList(new Path("./target/pcapFile")));    mockPcapJob.setIsDone(true);    mockPcapJob.setPageable(pageable);    this.mockMvc.perform(get(pcapUrl + "/jobId/raw?page=1").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(header().string("Content-Disposition", "attachment; filename=\"pcap_jobId_1.pcap\"")).andExpect(header().string("Content-Length", Integer.toString(pcapFileContents.length()))).andExpect(content().contentType(MediaType.parseMediaType("application/octet-stream"))).andExpect(content().bytes(pcapFileContents.getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(get(pcapUrl + "/jobId/raw?page=1&fileName=pcapFile.pcap").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(header().string("Content-Disposition", "attachment; filename=\"pcapFile.pcap\"")).andExpect(header().string("Content-Length", Integer.toString(pcapFileContents.length()))).andExpect(content().contentType(MediaType.parseMediaType("application/octet-stream"))).andExpect(content().bytes(pcapFileContents.getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(get(pcapUrl + "/jobId/raw?page=2").with(httpBasic(user, password))).andExpect(status().isNotFound());}
0
public void testGetFixedFilterConfiguration() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/fixed").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(fixedJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    this.mockMvc.perform(get(pcapUrl + "/jobId/config").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.basePath").value("/base/path")).andExpect(jsonPath("$.finalOutputPath").value("/final/output/path")).andExpect(jsonPath("$.startTimeMs").value(10)).andExpect(jsonPath("$.endTimeMs").value(20)).andExpect(jsonPath("$.numReducers").value(2)).andExpect(jsonPath("$.ipSrcAddr").value("192.168.1.2")).andExpect(jsonPath("$.ipDstAddr").value("192.168.1.1")).andExpect(jsonPath("$.ipSrcPort").value("2000")).andExpect(jsonPath("$.ipDstPort").value("1000")).andExpect(jsonPath("$.protocol").value("TCP")).andExpect(jsonPath("$.packetFilter").value("filter")).andExpect(jsonPath("$.includeReverse").value("true"));}
0
public void testGetQueryFilterConfiguration() throws Exception
{    MockPcapJob mockPcapJob = (MockPcapJob) wac.getBean("mockPcapJob");    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withState(JobStatus.State.RUNNING));    this.mockMvc.perform(post(pcapUrl + "/query").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(queryJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.jobId").value("jobId")).andExpect(jsonPath("$.jobStatus").value("RUNNING"));    this.mockMvc.perform(get(pcapUrl + "/jobId/config").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.basePath").value("/base/path")).andExpect(jsonPath("$.finalOutputPath").value("/final/output/path")).andExpect(jsonPath("$.startTimeMs").value(10)).andExpect(jsonPath("$.endTimeMs").value(20)).andExpect(jsonPath("$.numReducers").value(2)).andExpect(jsonPath("$.query").value("query"));}
0
public void setUp() throws Exception
{    restExceptionHandler = new RestExceptionHandler();    request = mock(HttpServletRequest.class);}
0
public void handleControllerExceptionShouldProperlyReturnRestError() throws Exception
{    when(request.getAttribute("javax.servlet.error.status_code")).thenReturn(401);    Throwable throwable = new RuntimeException("unauthorized");    ResponseEntity responseEntity = restExceptionHandler.handleControllerException(request, throwable);    assertEquals(HttpStatus.UNAUTHORIZED, responseEntity.getStatusCode());    RestError actualRestError = (RestError) responseEntity.getBody();    assertEquals("unauthorized", actualRestError.getMessage());    assertEquals("RuntimeException: unauthorized", actualRestError.getFullMessage());    assertEquals(401, actualRestError.getResponseCode());}
0
public void handleControllerExceptionShouldDefaultTo500() throws Exception
{    when(request.getAttribute("javax.servlet.error.status_code")).thenReturn(null);    Throwable throwable = new RuntimeException("some error");    ResponseEntity responseEntity = restExceptionHandler.handleControllerException(request, throwable);    assertEquals(HttpStatus.INTERNAL_SERVER_ERROR, responseEntity.getStatusCode());}
0
public void handleControllerExceptionShouldReturnRootCause() throws Exception
{    when(request.getAttribute("javax.servlet.error.status_code")).thenReturn(500);    Throwable throwable = new RuntimeException("some error", new RuntimeException("some root cause"));    ResponseEntity responseEntity = restExceptionHandler.handleControllerException(request, throwable);    assertEquals(HttpStatus.INTERNAL_SERVER_ERROR, responseEntity.getStatusCode());    RestError actualRestError = (RestError) responseEntity.getBody();    assertEquals("some error", actualRestError.getMessage());    assertEquals("RuntimeException: some root cause", actualRestError.getFullMessage());    assertEquals(500, actualRestError.getResponseCode());}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();    ImmutableMap<String, String> testData = ImmutableMap.of("bro_index_2017.01.01.01", SearchIntegrationTest.broData, "snort_index_2017.01.01.01", SearchIntegrationTest.snortData);    loadTestData(testData);    loadColumnTypes();    loadFacetCounts();}
0
public void cleanup() throws Exception
{    InMemoryDao.clear();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(searchUrl + "/search").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.allQuery)).andExpect(status().isUnauthorized());}
0
public void testSearchWithDefaults() throws Exception
{    sensorIndexingConfigService.save("bro", new HashMap<String, Object>() {        {            put("index", "bro");        }    });    assertEventually(() -> this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(defaultQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(5)).andExpect(jsonPath("$.results[0].source.source:type").value("bro")).andExpect(jsonPath("$.results[0].source.timestamp").value(5)).andExpect(jsonPath("$.results[1].source.source:type").value("bro")).andExpect(jsonPath("$.results[1].source.timestamp").value(4)).andExpect(jsonPath("$.results[2].source.source:type").value("bro")).andExpect(jsonPath("$.results[2].source.timestamp").value(3)).andExpect(jsonPath("$.results[3].source.source:type").value("bro")).andExpect(jsonPath("$.results[3].source.timestamp").value(2)).andExpect(jsonPath("$.results[4].source.source:type").value("bro")).andExpect(jsonPath("$.results[4].source.timestamp").value(1)).andExpect(jsonPath("$.facetCounts.*", hasSize(2))).andExpect(jsonPath("$.facetCounts.source:type.*", hasSize(1))).andExpect(jsonPath("$.facetCounts.source:type['bro']").value(5)).andExpect(jsonPath("$.facetCounts.ip_src_addr.*", hasSize(2))).andExpect(jsonPath("$.facetCounts.ip_src_addr['192.168.1.1']").value(3)).andExpect(jsonPath("$.facetCounts.ip_src_addr['192.168.1.2']").value(1)));    sensorIndexingConfigService.delete("bro");}
0
public void testSearchWithAlertProfileFacetFields() throws Exception
{    assertEventually(() -> this.mockMvc.perform(post("/api/v1/alerts/ui/settings").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(alertProfile)).andExpect(status().isOk()));    assertEventually(() -> this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(defaultQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.facetCounts.*", hasSize(1))).andExpect(jsonPath("$.facetCounts.ip_src_port.*", hasSize(2))).andExpect(jsonPath("$.facetCounts.ip_src_port['8010']").value(1)).andExpect(jsonPath("$.facetCounts.ip_src_port['8009']").value(2)));    alertsUIService.deleteAlertsUIUserSettings(user);}
0
public void testColumnMetadataUsingDefaultIndices() throws Exception
{        sensorIndexingConfigService.save("bro", new HashMap<String, Object>() {        {            put("index", "bro");        }    });    sensorIndexingConfigService.save("snort", new HashMap<String, Object>() {        {            put("index", "snort");        }    });        assertEventually(() -> this.mockMvc.perform(post(searchUrl + "/column/metadata").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content("[]")).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(5))).andExpect(jsonPath("$.common_string_field").value("text")).andExpect(jsonPath("$.common_integer_field").value("integer")).andExpect(jsonPath("$.bro_field").value("boolean")).andExpect(jsonPath("$.snort_field").value("double")).andExpect(jsonPath("$.duplicate_field").value("other")));    sensorIndexingConfigService.delete("bro");    sensorIndexingConfigService.delete("snort");}
0
public void test() throws Exception
{    this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.allQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(10)).andExpect(jsonPath("$.results[0].source.source:type").value("snort")).andExpect(jsonPath("$.results[0].source.timestamp").value(10)).andExpect(jsonPath("$.results[1].source.source:type").value("snort")).andExpect(jsonPath("$.results[1].source.timestamp").value(9)).andExpect(jsonPath("$.results[2].source.source:type").value("snort")).andExpect(jsonPath("$.results[2].source.timestamp").value(8)).andExpect(jsonPath("$.results[3].source.source:type").value("snort")).andExpect(jsonPath("$.results[3].source.timestamp").value(7)).andExpect(jsonPath("$.results[4].source.source:type").value("snort")).andExpect(jsonPath("$.results[4].source.timestamp").value(6)).andExpect(jsonPath("$.results[5].source.source:type").value("bro")).andExpect(jsonPath("$.results[5].source.timestamp").value(5)).andExpect(jsonPath("$.results[6].source.source:type").value("bro")).andExpect(jsonPath("$.results[6].source.timestamp").value(4)).andExpect(jsonPath("$.results[7].source.source:type").value("bro")).andExpect(jsonPath("$.results[7].source.timestamp").value(3)).andExpect(jsonPath("$.results[8].source.source:type").value("bro")).andExpect(jsonPath("$.results[8].source.timestamp").value(2)).andExpect(jsonPath("$.results[9].source.source:type").value("bro")).andExpect(jsonPath("$.results[9].source.timestamp").value(1));    this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.filterQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(3)).andExpect(jsonPath("$.results[0].source.source:type").value("snort")).andExpect(jsonPath("$.results[0].source.timestamp").value(9)).andExpect(jsonPath("$.results[1].source.source:type").value("snort")).andExpect(jsonPath("$.results[1].source.timestamp").value(7)).andExpect(jsonPath("$.results[2].source.source:type").value("bro")).andExpect(jsonPath("$.results[2].source.timestamp").value(1));    this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.sortQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(10)).andExpect(jsonPath("$.results[0].source.ip_src_port").value(8001)).andExpect(jsonPath("$.results[1].source.ip_src_port").value(8002)).andExpect(jsonPath("$.results[2].source.ip_src_port").value(8003)).andExpect(jsonPath("$.results[3].source.ip_src_port").value(8004)).andExpect(jsonPath("$.results[4].source.ip_src_port").value(8005)).andExpect(jsonPath("$.results[5].source.ip_src_port").value(8006)).andExpect(jsonPath("$.results[6].source.ip_src_port").value(8007)).andExpect(jsonPath("$.results[7].source.ip_src_port").value(8008)).andExpect(jsonPath("$.results[8].source.ip_src_port").value(8009)).andExpect(jsonPath("$.results[9].source.ip_src_port").value(8010));    this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.paginationQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(10)).andExpect(jsonPath("$.results[0].source.source:type").value("snort")).andExpect(jsonPath("$.results[0].source.timestamp").value(6)).andExpect(jsonPath("$.results[1].source.source:type").value("bro")).andExpect(jsonPath("$.results[1].source.timestamp").value(5)).andExpect(jsonPath("$.results[2].source.source:type").value("bro")).andExpect(jsonPath("$.results[2].source.timestamp").value(4));    this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.indexQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.total").value(5)).andExpect(jsonPath("$.results[0].source.source:type").value("bro")).andExpect(jsonPath("$.results[0].source.timestamp").value(5)).andExpect(jsonPath("$.results[1].source.source:type").value("bro")).andExpect(jsonPath("$.results[1].source.timestamp").value(4)).andExpect(jsonPath("$.results[2].source.source:type").value("bro")).andExpect(jsonPath("$.results[2].source.timestamp").value(3)).andExpect(jsonPath("$.results[3].source.source:type").value("bro")).andExpect(jsonPath("$.results[3].source.timestamp").value(2)).andExpect(jsonPath("$.results[4].source.source:type").value("bro")).andExpect(jsonPath("$.results[4].source.timestamp").value(1));    this.mockMvc.perform(post(searchUrl + "/search").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.exceededMaxResultsQuery)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("Search result size must be less than 100"));    this.mockMvc.perform(post(searchUrl + "/group").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(SearchIntegrationTest.groupByQuery)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(2))).andExpect(jsonPath("$.groupedBy").value("is_alert")).andExpect(jsonPath("$.groupResults.*", hasSize(1))).andExpect(jsonPath("$.groupResults[0].*", hasSize(5))).andExpect(jsonPath("$.groupResults[0].key").value("is_alert_value")).andExpect(jsonPath("$.groupResults[0].total").value(10)).andExpect(jsonPath("$.groupResults[0].groupedBy").value("latitude")).andExpect(jsonPath("$.groupResults[0].groupResults.*", hasSize(1))).andExpect(jsonPath("$.groupResults[0].groupResults[0].*", hasSize(3))).andExpect(jsonPath("$.groupResults[0].groupResults[0].key").value("latitude_value")).andExpect(jsonPath("$.groupResults[0].groupResults[0].total").value(10)).andExpect(jsonPath("$.groupResults[0].groupResults[0].score").value(50));    this.mockMvc.perform(post(searchUrl + "/column/metadata").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content("[\"bro\",\"snort\"]")).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(5))).andExpect(jsonPath("$.common_string_field").value("text")).andExpect(jsonPath("$.common_integer_field").value("integer")).andExpect(jsonPath("$.bro_field").value("boolean")).andExpect(jsonPath("$.snort_field").value("double")).andExpect(jsonPath("$.duplicate_field").value("other"));    this.mockMvc.perform(post(searchUrl + "/column/metadata").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content("[\"bro\"]")).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(4))).andExpect(jsonPath("$.common_string_field").value("text")).andExpect(jsonPath("$.common_integer_field").value("integer")).andExpect(jsonPath("$.bro_field").value("boolean")).andExpect(jsonPath("$.duplicate_field").value("date"));    this.mockMvc.perform(post(searchUrl + "/column/metadata").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content("[\"snort\"]")).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(4))).andExpect(jsonPath("$.common_string_field").value("text")).andExpect(jsonPath("$.common_integer_field").value("integer")).andExpect(jsonPath("$.snort_field").value("double")).andExpect(jsonPath("$.duplicate_field").value("long"));    this.mockMvc.perform(post(searchUrl + "/column/metadata").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content("[\"someindex\"]")).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(0)));}
0
private void loadColumnTypes() throws ParseException
{    Map<String, Map<String, FieldType>> columnTypes = new HashMap<>();    Map<String, FieldType> broTypes = new HashMap<>();    broTypes.put("common_string_field", FieldType.TEXT);    broTypes.put("common_integer_field", FieldType.INTEGER);    broTypes.put("bro_field", FieldType.BOOLEAN);    broTypes.put("duplicate_field", FieldType.DATE);    Map<String, FieldType> snortTypes = new HashMap<>();    snortTypes.put("common_string_field", FieldType.TEXT);    snortTypes.put("common_integer_field", FieldType.INTEGER);    snortTypes.put("snort_field", FieldType.DOUBLE);    snortTypes.put("duplicate_field", FieldType.LONG);    columnTypes.put("bro", broTypes);    columnTypes.put("snort", snortTypes);    InMemoryDao.setColumnMetadata(columnTypes);}
0
private void loadFacetCounts()
{    Map<String, Map<String, Long>> facetCounts = new HashMap<>();    Map<String, Long> ipSrcAddrCounts = new HashMap<>();    ipSrcAddrCounts.put("192.168.1.1", 3L);    ipSrcAddrCounts.put("192.168.1.2", 1L);    Map<String, Long> ipSrcPortCounts = new HashMap<>();    ipSrcPortCounts.put("8010", 1L);    ipSrcPortCounts.put("8009", 2L);    Map<String, Long> sourceTypeCounts = new HashMap<>();    sourceTypeCounts.put("bro", 5L);    facetCounts.put("ip_src_addr", ipSrcAddrCounts);    facetCounts.put("ip_src_port", ipSrcPortCounts);    facetCounts.put("source:type", sourceTypeCounts);    InMemoryDao.setFacetCounts(facetCounts);}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(sensorEnrichmentConfigUrl).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(sensorEnrichmentConfigUrl + "/broTest")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(sensorEnrichmentConfigUrl)).andExpect(status().isUnauthorized());    this.mockMvc.perform(delete(sensorEnrichmentConfigUrl + "/broTest").with(csrf())).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    sensorEnrichmentConfigService.delete("broTest");    this.mockMvc.perform(get(sensorEnrichmentConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().bytes("{}".getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(post(sensorEnrichmentConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.enrichment.fieldMap.geo[0]").value("ip_dst_addr")).andExpect(jsonPath("$.enrichment.fieldMap.host[0]").value("ip_dst_addr")).andExpect(jsonPath("$.enrichment.fieldMap.hbaseEnrichment[0]").value("ip_src_addr")).andExpect(jsonPath("$.enrichment.fieldToTypeMap.ip_src_addr[0]").value("sample")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group1.foo").value("1 + 1")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group1.bar").value("foo")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group2.ALL_CAPS").value("TO_UPPER(source.type)")).andExpect(jsonPath("$.threatIntel.fieldMap.hbaseThreatIntel[0]").value("ip_src_addr")).andExpect(jsonPath("$.threatIntel.fieldMap.hbaseThreatIntel[1]").value("ip_dst_addr")).andExpect(jsonPath("$.threatIntel.fieldToTypeMap.ip_src_addr[0]").value("malicious_ip")).andExpect(jsonPath("$.threatIntel.fieldToTypeMap.ip_dst_addr[0]").value("malicious_ip")).andExpect(jsonPath("$.threatIntel.triageConfig.riskLevelRules[0].rule").value("ip_src_addr == '10.122.196.204' or ip_dst_addr == '10.122.196.204'")).andExpect(jsonPath("$.threatIntel.triageConfig.riskLevelRules[0].score").value(10)).andExpect(jsonPath("$.threatIntel.triageConfig.aggregator").value("MAX"));    assertEventually(() -> this.mockMvc.perform(post(sensorEnrichmentConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.enrichment.fieldMap.geo[0]").value("ip_dst_addr")).andExpect(jsonPath("$.enrichment.fieldMap.host[0]").value("ip_dst_addr")).andExpect(jsonPath("$.enrichment.fieldMap.hbaseEnrichment[0]").value("ip_src_addr")).andExpect(jsonPath("$.enrichment.fieldToTypeMap.ip_src_addr[0]").value("sample")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group1.foo").value("1 + 1")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group1.bar").value("foo")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group2.ALL_CAPS").value("TO_UPPER(source.type)")).andExpect(jsonPath("$.threatIntel.fieldMap.hbaseThreatIntel[0]").value("ip_src_addr")).andExpect(jsonPath("$.threatIntel.fieldMap.hbaseThreatIntel[1]").value("ip_dst_addr")).andExpect(jsonPath("$.threatIntel.fieldToTypeMap.ip_src_addr[0]").value("malicious_ip")).andExpect(jsonPath("$.threatIntel.fieldToTypeMap.ip_dst_addr[0]").value("malicious_ip")).andExpect(jsonPath("$.threatIntel.triageConfig.riskLevelRules[0].rule").value("ip_src_addr == '10.122.196.204' or ip_dst_addr == '10.122.196.204'")).andExpect(jsonPath("$.threatIntel.triageConfig.riskLevelRules[0].score").value(10)).andExpect(jsonPath("$.threatIntel.triageConfig.aggregator").value("MAX")));    this.mockMvc.perform(get(sensorEnrichmentConfigUrl + "/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.enrichment.fieldMap.geo[0]").value("ip_dst_addr")).andExpect(jsonPath("$.enrichment.fieldMap.host[0]").value("ip_dst_addr")).andExpect(jsonPath("$.enrichment.fieldMap.hbaseEnrichment[0]").value("ip_src_addr")).andExpect(jsonPath("$.enrichment.fieldToTypeMap.ip_src_addr[0]").value("sample")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group1.foo").value("1 + 1")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group1.bar").value("foo")).andExpect(jsonPath("$.enrichment.fieldMap.stellar.config.group2.ALL_CAPS").value("TO_UPPER(source.type)")).andExpect(jsonPath("$.threatIntel.fieldMap.hbaseThreatIntel[0]").value("ip_src_addr")).andExpect(jsonPath("$.threatIntel.fieldMap.hbaseThreatIntel[1]").value("ip_dst_addr")).andExpect(jsonPath("$.threatIntel.fieldToTypeMap.ip_src_addr[0]").value("malicious_ip")).andExpect(jsonPath("$.threatIntel.fieldToTypeMap.ip_dst_addr[0]").value("malicious_ip")).andExpect(jsonPath("$.threatIntel.triageConfig.riskLevelRules[0].rule").value("ip_src_addr == '10.122.196.204' or ip_dst_addr == '10.122.196.204'")).andExpect(jsonPath("$.threatIntel.triageConfig.riskLevelRules[0].score").value(10)).andExpect(jsonPath("$.threatIntel.triageConfig.aggregator").value("MAX"));    this.mockMvc.perform(get(sensorEnrichmentConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[?(@.broTest.enrichment.fieldMap.geo[0] == 'ip_dst_addr' &&" + "@.broTest.enrichment.fieldMap.host[0] == 'ip_dst_addr' &&" + "@.broTest.enrichment.fieldMap.hbaseEnrichment[0] == 'ip_src_addr' &&" + "@.broTest.enrichment.fieldToTypeMap.ip_src_addr[0] == 'sample' &&" + "@.broTest.enrichment.fieldMap.stellar.config.group1.foo == '1 + 1' &&" + "@.broTest.enrichment.fieldMap.stellar.config.group1.bar == 'foo' &&" + "@.broTest.enrichment.fieldMap.stellar.config.group2.ALL_CAPS == 'TO_UPPER(source.type)' &&" + "@.broTest.threatIntel.fieldMap.hbaseThreatIntel[0] == 'ip_src_addr' &&" + "@.broTest.threatIntel.fieldMap.hbaseThreatIntel[1] == 'ip_dst_addr' &&" + "@.broTest.threatIntel.fieldToTypeMap.ip_src_addr[0] == 'malicious_ip' &&" + "@.broTest.threatIntel.fieldToTypeMap.ip_dst_addr[0] == 'malicious_ip' &&" + "@.broTest.threatIntel.triageConfig.riskLevelRules[0].rule == \"ip_src_addr == '10.122.196.204' or ip_dst_addr == '10.122.196.204'\" &&" + "@.broTest.threatIntel.triageConfig.riskLevelRules[0].score == 10 &&" + "@.broTest.threatIntel.triageConfig.aggregator == 'MAX'" + ")]").exists());    this.mockMvc.perform(delete(sensorEnrichmentConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isOk());    this.mockMvc.perform(get(sensorEnrichmentConfigUrl + "/broTest").with(httpBasic(user, password))).andExpect(status().isNotFound());    this.mockMvc.perform(delete(sensorEnrichmentConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isNotFound());    this.mockMvc.perform(get(sensorEnrichmentConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[?(@.sensorTopic == 'broTest')]").doesNotExist());    this.mockMvc.perform(get(sensorEnrichmentConfigUrl + "/list/available/enrichments").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.length()").value("3")).andExpect(jsonPath("$.*").value(IsCollectionContaining.hasItems("foo", "bar", "baz")));    this.mockMvc.perform(get(sensorEnrichmentConfigUrl + "/list/available/threat/triage/aggregators").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[0]").value("MAX")).andExpect(jsonPath("$[1]").value("MIN")).andExpect(jsonPath("$[2]").value("SUM")).andExpect(jsonPath("$[3]").value("MEAN")).andExpect(jsonPath("$[4]").value("POSITIVE_MEAN"));    sensorEnrichmentConfigService.delete("broTest");}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(sensorIndexingConfigUrl).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isUnauthorized());    assertEventually(() -> this.mockMvc.perform(get(sensorIndexingConfigUrl + "/broTest")).andExpect(status().isUnauthorized()));    assertEventually(() -> this.mockMvc.perform(get(sensorIndexingConfigUrl)).andExpect(status().isUnauthorized()));    assertEventually(() -> this.mockMvc.perform(delete(sensorIndexingConfigUrl + "/broTest").with(csrf())).andExpect(status().isUnauthorized()));}
0
public void test() throws Exception
{    sensorIndexingConfigService.delete("broTest");    this.mockMvc.perform(get(sensorIndexingConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().bytes("{}".getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(get(sensorIndexingConfigUrl + "/list/indices/elasticsearch").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().bytes("[]".getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(get(sensorIndexingConfigUrl + "/list/indices/blah").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().bytes("[]".getBytes(StandardCharsets.UTF_8)));    this.mockMvc.perform(post(sensorIndexingConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.index").value("broTest")).andExpect(jsonPath("$.batchSize").value(1));    assertEventually(() -> this.mockMvc.perform(get(sensorIndexingConfigUrl + "/list/indices/elasticsearch").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(content().bytes("[\"broTest\"]".getBytes(StandardCharsets.UTF_8))));    assertEventually(() -> this.mockMvc.perform(post(sensorIndexingConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.index").value("broTest")).andExpect(jsonPath("$.batchSize").value(1)));    this.mockMvc.perform(get(sensorIndexingConfigUrl + "/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.index").value("broTest")).andExpect(jsonPath("$.batchSize").value(1));    this.mockMvc.perform(get(sensorIndexingConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[?(@.broTest.index == 'broTest' &&" + "@.broTest.batchSize == 1" + ")]").exists());    this.mockMvc.perform(delete(sensorIndexingConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isOk());    assertEventually(() -> this.mockMvc.perform(get(sensorIndexingConfigUrl + "/broTest").with(httpBasic(user, password))).andExpect(status().isNotFound()));    this.mockMvc.perform(delete(sensorIndexingConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isNotFound());    assertEventually(() -> this.mockMvc.perform(get(sensorIndexingConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[?(@.sensorTopic == 'broTest')]").doesNotExist()));    sensorIndexingConfigService.delete("broTest");}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(sensorParserConfigUrl).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(squidJson)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(sensorParserConfigUrl + "/squidTest")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(sensorParserConfigUrl)).andExpect(status().isUnauthorized());    this.mockMvc.perform(delete(sensorParserConfigUrl + "/squidTest").with(csrf())).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    cleanFileSystem();    this.sensorParserConfigService.delete("broTest");    this.sensorParserConfigService.delete("squidTest");    Method[] method = SensorParserConfig.class.getMethods();    final AtomicInteger numFields = new AtomicInteger(0);    for (Method m : method) {        if (m.getName().startsWith("set")) {            numFields.set(numFields.get() + 1);        }    }    this.mockMvc.perform(post(sensorParserConfigUrl + "/squidTest").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(squidJson)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.parserClassName").value("org.apache.metron.parsers.GrokParser")).andExpect(jsonPath("$.sensorTopic").value("squidTest")).andExpect(jsonPath("$.parserConfig.grokPath").value("target/patterns/squidTest")).andExpect(jsonPath("$.parserConfig.patternLabel").value("SQUIDTEST")).andExpect(jsonPath("$.parserConfig.timestampField").value("timestamp")).andExpect(jsonPath("$.fieldTransformations[0].transformation").value("STELLAR")).andExpect(jsonPath("$.fieldTransformations[0].output[0]").value("full_hostname")).andExpect(jsonPath("$.fieldTransformations[0].output[1]").value("domain_without_subdomains")).andExpect(jsonPath("$.fieldTransformations[0].config.full_hostname").value("URL_TO_HOST(url)")).andExpect(jsonPath("$.fieldTransformations[0].config.domain_without_subdomains").value("DOMAIN_REMOVE_SUBDOMAINS(full_hostname)"));    assertEventually(() -> this.mockMvc.perform(get(sensorParserConfigUrl + "/squidTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.parserClassName").value("org.apache.metron.parsers.GrokParser")).andExpect(jsonPath("$.sensorTopic").value("squidTest")).andExpect(jsonPath("$.parserConfig.grokPath").value("target/patterns/squidTest")).andExpect(jsonPath("$.parserConfig.patternLabel").value("SQUIDTEST")).andExpect(jsonPath("$.parserConfig.timestampField").value("timestamp")).andExpect(jsonPath("$.fieldTransformations[0].transformation").value("STELLAR")).andExpect(jsonPath("$.fieldTransformations[0].output[0]").value("full_hostname")).andExpect(jsonPath("$.fieldTransformations[0].output[1]").value("domain_without_subdomains")).andExpect(jsonPath("$.fieldTransformations[0].config.full_hostname").value("URL_TO_HOST(url)")).andExpect(jsonPath("$.fieldTransformations[0].config.domain_without_subdomains").value("DOMAIN_REMOVE_SUBDOMAINS(full_hostname)")));    this.mockMvc.perform(get(sensorParserConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.squidTest.*", hasSize(numFields.get()))).andExpect(jsonPath("$.squidTest.parserClassName").value("org.apache.metron.parsers.GrokParser")).andExpect(jsonPath("$.squidTest.sensorTopic").value("squidTest")).andExpect(jsonPath("$.squidTest.parserConfig.grokPath").value("target/patterns/squidTest")).andExpect(jsonPath("$.squidTest.parserConfig.patternLabel").value("SQUIDTEST")).andExpect(jsonPath("$.squidTest.parserConfig.timestampField").value("timestamp")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].transformation").value("STELLAR")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].output[0]").value("full_hostname")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].output[1]").value("domain_without_subdomains")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].config.full_hostname").value("URL_TO_HOST(url)")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].config.domain_without_subdomains").value("DOMAIN_REMOVE_SUBDOMAINS(full_hostname)"));    this.mockMvc.perform(post(sensorParserConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.parserClassName").value("org.apache.metron.parsers.bro.BasicBroParser")).andExpect(jsonPath("$.sensorTopic").value("broTest")).andExpect(jsonPath("$.readMetadata").value("true")).andExpect(jsonPath("$.mergeMetadata").value("true")).andExpect(jsonPath("$.parserConfig").isEmpty());    assertEventually(() -> this.mockMvc.perform(post(sensorParserConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(broJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.parserClassName").value("org.apache.metron.parsers.bro.BasicBroParser")).andExpect(jsonPath("$.sensorTopic").value("broTest")).andExpect(jsonPath("$.readMetadata").value("true")).andExpect(jsonPath("$.mergeMetadata").value("true")).andExpect(jsonPath("$.parserConfig").isEmpty()));    this.mockMvc.perform(get(sensorParserConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(2))).andExpect(jsonPath("$.squidTest.*", hasSize(numFields.get()))).andExpect(jsonPath("$.squidTest.parserClassName").value("org.apache.metron.parsers.GrokParser")).andExpect(jsonPath("$.squidTest.sensorTopic").value("squidTest")).andExpect(jsonPath("$.squidTest.parserConfig.grokPath").value("target/patterns/squidTest")).andExpect(jsonPath("$.squidTest.parserConfig.patternLabel").value("SQUIDTEST")).andExpect(jsonPath("$.squidTest.parserConfig.timestampField").value("timestamp")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].transformation").value("STELLAR")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].output[0]").value("full_hostname")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].output[1]").value("domain_without_subdomains")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].config.full_hostname").value("URL_TO_HOST(url)")).andExpect(jsonPath("$.squidTest.fieldTransformations[0].config.domain_without_subdomains").value("DOMAIN_REMOVE_SUBDOMAINS(full_hostname)")).andExpect(jsonPath("$.broTest.parserClassName").value("org.apache.metron.parsers.bro.BasicBroParser")).andExpect(jsonPath("$.broTest.*", hasSize(numFields.get()))).andExpect(jsonPath("$.broTest.sensorTopic").value("broTest")).andExpect(jsonPath("$.broTest.readMetadata").value("true")).andExpect(jsonPath("$.broTest.mergeMetadata").value("true")).andExpect(jsonPath("$.broTest.parserConfig").isEmpty());    this.mockMvc.perform(delete(sensorParserConfigUrl + "/squidTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isOk());    {                TestUtils.assertEventually(() -> Assert.assertNull(sensorParserConfigService.findOne("squidTest")));    }    this.mockMvc.perform(get(sensorParserConfigUrl + "/squidTest").with(httpBasic(user, password))).andExpect(status().isNotFound());    this.mockMvc.perform(delete(sensorParserConfigUrl + "/squidTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isNotFound());    this.mockMvc.perform(get(sensorParserConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.squidTest").doesNotExist()).andExpect(jsonPath("$.broTest").exists());    this.mockMvc.perform(delete(sensorParserConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isOk());    this.mockMvc.perform(delete(sensorParserConfigUrl + "/broTest").with(httpBasic(user, password)).with(csrf())).andExpect(status().isNotFound());    this.mockMvc.perform(get(sensorParserConfigUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.squidTest").doesNotExist()).andExpect(jsonPath("$.broTest").doesNotExist());    this.mockMvc.perform(get(sensorParserConfigUrl + "/list/available").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.Bro").value("org.apache.metron.parsers.bro.BasicBroParser")).andExpect(jsonPath("$.Grok").value("org.apache.metron.parsers.GrokParser"));    this.mockMvc.perform(get(sensorParserConfigUrl + "/reload/available").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.Bro").value("org.apache.metron.parsers.bro.BasicBroParser")).andExpect(jsonPath("$.Grok").value("org.apache.metron.parsers.GrokParser"));    this.mockMvc.perform(post(sensorParserConfigUrl + "/parseMessage").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(parseRequest)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.elapsed").value(415)).andExpect(jsonPath("$.code").value(200)).andExpect(jsonPath("$.ip_dst_addr").value("207.109.73.154")).andExpect(jsonPath("$.method").value("GET")).andExpect(jsonPath("$.bytes").value(337891)).andExpect(jsonPath("$.action").value("TCP_MISS")).andExpect(jsonPath("$.ip_src_addr").value("127.0.0.1")).andExpect(jsonPath("$.url").value("http://www.aliexpress.com/af/shoes.html?")).andExpect(jsonPath("$.timestamp").value(1467011157401L));    this.mockMvc.perform(post(sensorParserConfigUrl + "/parseMessage").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(missingConfigParseRequest)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("SensorParserConfig is missing from ParseMessageRequest"));    this.mockMvc.perform(post(sensorParserConfigUrl + "/parseMessage").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(missingClassParseRequest)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("SensorParserConfig must have a parserClassName"));    this.mockMvc.perform(post(sensorParserConfigUrl + "/parseMessage").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(badClassParseRequest)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("java.lang.ClassNotFoundException: badClass"));    this.sensorParserConfigService.delete("broTest");    this.sensorParserConfigService.delete("squidTest");}
0
private void cleanFileSystem() throws IOException
{    File grokTempPath = new File(environment.getProperty(MetronRestConstants.GROK_TEMP_PATH_SPRING_PROPERTY));    if (grokTempPath.exists()) {        FileUtils.cleanDirectory(grokTempPath);        FileUtils.deleteDirectory(grokTempPath);    }}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();    Method[] method = SensorParserGroup.class.getMethods();    numFields = new AtomicInteger(0);    for (Method m : method) {        if (m.getName().startsWith("set")) {            numFields.set(numFields.get() + 1);        }    }    this.globalConfigService.save(new HashMap<>());    this.sensorParserConfigService.save("bro", new SensorParserConfig());    this.sensorParserConfigService.save("snort", new SensorParserConfig());    this.sensorParserConfigService.save("squid", new SensorParserConfig());    this.sensorParserConfigService.save("yaf", new SensorParserConfig());    this.sensorParserConfigService.save("jsonMap", new SensorParserConfig());    TestUtils.assertEventually(() -> Assert.assertNotNull(sensorParserConfigService.findOne("bro")));    TestUtils.assertEventually(() -> Assert.assertNotNull(sensorParserConfigService.findOne("snort")));    TestUtils.assertEventually(() -> Assert.assertNotNull(sensorParserConfigService.findOne("squid")));    TestUtils.assertEventually(() -> Assert.assertNotNull(sensorParserConfigService.findOne("yaf")));    TestUtils.assertEventually(() -> Assert.assertNotNull(sensorParserConfigService.findOne("jsonMap")));}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(sensorParserGroupUrl).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(group1BroSnort)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(sensorParserGroupUrl + "/group1")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(sensorParserGroupUrl)).andExpect(status().isUnauthorized());    this.mockMvc.perform(delete(sensorParserGroupUrl + "/group1").with(csrf())).andExpect(status().isUnauthorized());}
0
public void testCreate() throws Exception
{    this.mockMvc.perform(post(sensorParserGroupUrl).with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(group1BroSnort)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.name").value("group1")).andExpect(jsonPath("$.description").value("group1 description")).andExpect(jsonPath("$.sensors[0]").value("bro")).andExpect(jsonPath("$.sensors[1]").value("snort"));    this.mockMvc.perform(post(sensorParserGroupUrl).with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(group2YafJsonMap)).andExpect(status().isCreated()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.name").value("group2")).andExpect(jsonPath("$.description").value("group2 description")).andExpect(jsonPath("$.sensors[0]").value("jsonMap")).andExpect(jsonPath("$.sensors[1]").value("yaf"));}
0
public void testUpdate() throws Exception
{    SensorParserGroup group1 = JSONUtils.INSTANCE.load(group1BroSquid, SensorParserGroup.class);    this.sensorParserGroupService.save(group1);    TestUtils.assertEventually(() -> Assert.assertEquals(group1, this.sensorParserGroupService.findOne("group1")));    this.mockMvc.perform(post(sensorParserGroupUrl).with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(group1BroSquid)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.name").value("group1")).andExpect(jsonPath("$.description").value("group1 description")).andExpect(jsonPath("$.sensors[0]").value("squid")).andExpect(jsonPath("$.sensors[1]").value("bro"));}
0
public void testFindOne() throws Exception
{    SensorParserGroup group1 = JSONUtils.INSTANCE.load(group1BroSquid, SensorParserGroup.class);    this.sensorParserGroupService.save(group1);    TestUtils.assertEventually(() -> Assert.assertEquals(group1, this.sensorParserGroupService.findOne("group1")));    this.mockMvc.perform(get(sensorParserGroupUrl + "/group1").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(numFields.get()))).andExpect(jsonPath("$.name").value("group1")).andExpect(jsonPath("$.description").value("group1 description")).andExpect(jsonPath("$.sensors[0]").value("squid")).andExpect(jsonPath("$.sensors[1]").value("bro"));    this.mockMvc.perform(get(sensorParserGroupUrl + "/missingGroup").with(httpBasic(user, password))).andExpect(status().isNotFound());}
0
public void testGetAll() throws Exception
{    SensorParserGroup group1 = JSONUtils.INSTANCE.load(group1BroSquid, SensorParserGroup.class);    this.sensorParserGroupService.save(group1);    TestUtils.assertEventually(() -> Assert.assertEquals(group1, this.sensorParserGroupService.findOne("group1")));    SensorParserGroup group2 = JSONUtils.INSTANCE.load(group2YafJsonMap, SensorParserGroup.class);    this.sensorParserGroupService.save(group2);    TestUtils.assertEventually(() -> Assert.assertEquals(group2, this.sensorParserGroupService.findOne("group2")));    this.mockMvc.perform(get(sensorParserGroupUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.*", hasSize(2))).andExpect(jsonPath("$.group1.*", hasSize(numFields.get()))).andExpect(jsonPath("$.group1.name").value("group1")).andExpect(jsonPath("$.group1.description").value("group1 description")).andExpect(jsonPath("$.group1.sensors[0]").value("squid")).andExpect(jsonPath("$.group1.sensors[1]").value("bro")).andExpect(jsonPath("$.group2.*", hasSize(numFields.get()))).andExpect(jsonPath("$.group2.name").value("group2")).andExpect(jsonPath("$.group2.description").value("group2 description")).andExpect(jsonPath("$.group2.sensors[0]").value("jsonMap")).andExpect(jsonPath("$.group2.sensors[1]").value("yaf"));}
0
public void testError() throws Exception
{    SensorParserGroup group1 = JSONUtils.INSTANCE.load(group1BroSquid, SensorParserGroup.class);    this.sensorParserGroupService.save(group1);    TestUtils.assertEventually(() -> Assert.assertEquals(group1, this.sensorParserGroupService.findOne("group1")));    this.mockMvc.perform(post(sensorParserGroupUrl).with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(errorGroup)).andExpect(status().isInternalServerError()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.responseCode").value(500)).andExpect(jsonPath("$.message").value("Sensor bro is already in group group1")).andExpect(jsonPath("$.fullMessage").value("RestException: Sensor bro is already in group group1"));}
0
public void testDelete() throws Exception
{    SensorParserGroup group1 = JSONUtils.INSTANCE.load(group1BroSquid, SensorParserGroup.class);    this.sensorParserGroupService.save(group1);    TestUtils.assertEventually(() -> Assert.assertEquals(group1, this.sensorParserGroupService.findOne("group1")));    this.mockMvc.perform(delete(sensorParserGroupUrl + "/group1").with(httpBasic(user, password)).with(csrf())).andExpect(status().isOk());    this.mockMvc.perform(delete(sensorParserGroupUrl + "/missingGroup").with(httpBasic(user, password))).andExpect(status().isNotFound());    {                TestUtils.assertEventually(() -> Assert.assertNull(sensorParserGroupService.findOne("group1")));    }}
0
public void tearDown() throws Exception
{    this.globalConfigService.delete();    this.sensorParserConfigService.delete("bro");    this.sensorParserConfigService.delete("snort");    this.sensorParserConfigService.delete("squid");    this.sensorParserConfigService.delete("yaf");    this.sensorParserConfigService.delete("jsonMap");}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(post(stellarUrl + "/validate/rules").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(rulesJson)).andExpect(status().isUnauthorized());    this.mockMvc.perform(post(stellarUrl + "/apply/transformations").with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(sensorParseContext)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stellarUrl + "/list")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stellarUrl + "/list/functions")).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    this.mockMvc.perform(post(stellarUrl + "/validate/rules").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(rulesJson)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.['" + valid + "']").value(Boolean.TRUE)).andExpect(jsonPath("$.['" + invalid + "']").value(Boolean.FALSE));    this.mockMvc.perform(post(stellarUrl + "/apply/transformations").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(sensorParseContext)).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.url").value("https://caseystella.com/blog")).andExpect(jsonPath("$.url_host").value("caseystella.com"));    this.mockMvc.perform(get(stellarUrl + "/list").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$", hasSize(greaterThan(0))));    this.mockMvc.perform(get(stellarUrl + "/list/functions").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$", hasSize(greaterThan(0))));    this.mockMvc.perform(get(stellarUrl + "/list/simple/functions").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$", hasSize(greaterThan(0))));}
0
public void setup() throws Exception
{    this.metronVersion = this.environment.getProperty("metron.version");    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(get(stormUrl)).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/supervisors")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/broTest")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/parser/start/broTest")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/parser/stop/broTest")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/parser/activate/broTest")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/parser/deactivate/broTest")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get("/enrichment")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/enrichment/start")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/enrichment/stop")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/enrichment/activate")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/enrichment/deactivate")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get("/indexing")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/indexing/start")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/indexing/stop")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/indexing/activate")).andExpect(status().isUnauthorized());    this.mockMvc.perform(get(stormUrl + "/indexing/deactivate")).andExpect(status().isUnauthorized());}
0
public void test() throws Exception
{    this.mockMvc.perform(get(stormUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$", hasSize(0)));    this.mockMvc.perform(get(stormUrl + "/broTest").with(httpBasic(user, password))).andExpect(status().isNotFound());    Map<String, Object> globalConfig = globalConfigService.get();    if (globalConfig == null) {        globalConfig = new HashMap<>();    }    globalConfigService.delete();    sensorParserConfigService.delete("broTest");    this.mockMvc.perform(get(stormUrl + "/parser/stop/broTest?stopNow=true").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STOP_ERROR.toString()));    this.mockMvc.perform(get(stormUrl + "/parser/activate/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.TOPOLOGY_NOT_FOUND.name()));    this.mockMvc.perform(get(stormUrl + "/parser/deactivate/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.TOPOLOGY_NOT_FOUND.name()));    this.mockMvc.perform(get(stormUrl + "/parser/start/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.GLOBAL_CONFIG_MISSING.name()));    globalConfigService.save(globalConfig);    {        final Map<String, Object> expectedGlobalConfig = globalConfig;                TestUtils.assertEventually(() -> Assert.assertEquals(expectedGlobalConfig, globalConfigService.get()));    }    this.mockMvc.perform(get(stormUrl + "/parser/start/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.SENSOR_PARSER_CONFIG_MISSING.name()));    SensorParserConfig sensorParserConfig = new SensorParserConfig();    sensorParserConfig.setParserClassName("org.apache.metron.parsers.bro.BasicBroParser");    sensorParserConfig.setSensorTopic("broTest");    sensorParserConfigService.save("broTest", sensorParserConfig);    {        final SensorParserConfig expectedSensorParserConfig = sensorParserConfig;                TestUtils.assertEventually(() -> Assert.assertEquals(expectedSensorParserConfig, sensorParserConfigService.findOne("broTest")));    }    this.mockMvc.perform(get(stormUrl + "/parser/start/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STARTED.name()));    this.mockMvc.perform(get(stormUrl + "/supervisors").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.supervisors[0]").exists()).andExpect(jsonPath("$.supervisors[0].id").exists()).andExpect(jsonPath("$.supervisors[0].host").exists()).andExpect(jsonPath("$.supervisors[0].uptime").exists()).andExpect(jsonPath("$.supervisors[0].slotsTotal").exists()).andExpect(jsonPath("$.supervisors[0].slotsUsed").exists());    this.mockMvc.perform(get(stormUrl + "/broTest").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.name").value("broTest")).andExpect(jsonPath("$.id", containsString("broTest"))).andExpect(jsonPath("$.status").value("ACTIVE")).andExpect(jsonPath("$.latency").exists()).andExpect(jsonPath("$.throughput").exists()).andExpect(jsonPath("$.emitted").exists()).andExpect(jsonPath("$.acked").exists());    this.mockMvc.perform(get(stormUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[?(@.name == 'broTest' && @.status == 'ACTIVE')]").exists());    this.mockMvc.perform(get(stormUrl + "/parser/stop/broTest?stopNow=true").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STOPPED.name()));    this.mockMvc.perform(get(stormUrl + "/enrichment").with(httpBasic(user, password))).andExpect(status().isNotFound());    this.mockMvc.perform(get(stormUrl + "/enrichment/activate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.TOPOLOGY_NOT_FOUND.name()));    this.mockMvc.perform(get(stormUrl + "/enrichment/deactivate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.TOPOLOGY_NOT_FOUND.name()));    this.mockMvc.perform(get(stormUrl + "/enrichment/stop?stopNow=true").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STOP_ERROR.toString()));    this.mockMvc.perform(get(stormUrl + "/enrichment/start").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STARTED.toString()));    this.mockMvc.perform(get(stormUrl + "/enrichment/deactivate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.INACTIVE.name()));    this.mockMvc.perform(get(stormUrl + "/enrichment/deactivate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.INACTIVE.name()));    this.mockMvc.perform(get(stormUrl + "/enrichment/activate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.ACTIVE.name()));    this.mockMvc.perform(get(stormUrl + "/enrichment").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.name").value("enrichment")).andExpect(jsonPath("$.id", containsString("enrichment"))).andExpect(jsonPath("$.status").value("ACTIVE")).andExpect(jsonPath("$.latency").exists()).andExpect(jsonPath("$.throughput").exists()).andExpect(jsonPath("$.emitted").exists()).andExpect(jsonPath("$.acked").exists());    this.mockMvc.perform(get(stormUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[?(@.name == 'enrichment' && @.status == 'ACTIVE')]").exists());    this.mockMvc.perform(get(stormUrl + "/enrichment/stop").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STOPPED.name()));    for (String type : ImmutableList.of("randomaccess", "batch")) {        this.mockMvc.perform(get(stormUrl + "/indexing/" + type).with(httpBasic(user, password))).andExpect(status().isNotFound());        this.mockMvc.perform(get(stormUrl + "/indexing/" + type + "/activate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.TOPOLOGY_NOT_FOUND.name()));        this.mockMvc.perform(get(stormUrl + "/indexing/" + type + "/deactivate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.TOPOLOGY_NOT_FOUND.name()));        this.mockMvc.perform(get(stormUrl + "/indexing/" + type + "/stop?stopNow=true").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("ERROR")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STOP_ERROR.toString()));        this.mockMvc.perform(get(stormUrl + "/indexing/" + type + "/start").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STARTED.toString()));        ResultActions actions = this.mockMvc.perform(get(stormUrl + "/indexing/" + type + "/deactivate").with(httpBasic(user, password)));        actions.andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.INACTIVE.name()));        this.mockMvc.perform(get(stormUrl + "/indexing/" + type + "/activate").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.ACTIVE.name()));        String topologyName = type.equals("randomaccess") ? MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME : MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME;        this.mockMvc.perform(get(stormUrl + "/indexing/" + type).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.name").value(topologyName)).andExpect(jsonPath("$.id", containsString("indexing"))).andExpect(jsonPath("$.status").value("ACTIVE")).andExpect(jsonPath("$.latency").exists()).andExpect(jsonPath("$.throughput").exists()).andExpect(jsonPath("$.emitted").exists()).andExpect(jsonPath("$.acked").exists());        this.mockMvc.perform(get(stormUrl).with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$[?(@.name == '" + topologyName + "' && @.status == 'ACTIVE')]").exists());        this.mockMvc.perform(get(stormUrl + "/indexing/" + type + "/stop").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.status").value("SUCCESS")).andExpect(jsonPath("$.message").value(TopologyStatusCode.STOPPED.name()));    }    this.mockMvc.perform(get(stormUrl + "/client/status").with(httpBasic(user, password))).andExpect(status().isOk()).andExpect(jsonPath("$.stormClientVersionInstalled").value("1.0.1")).andExpect(jsonPath("$.parserScriptPath").value("/usr/metron/" + metronVersion + "/bin/start_parser_topology.sh")).andExpect(jsonPath("$.enrichmentScriptPath").value("/usr/metron/" + metronVersion + "/bin/start_enrichment_topology.sh")).andExpect(jsonPath("$.randomAccessIndexingScriptPath").value("/usr/metron/" + metronVersion + "/bin/start_elasticsearch_topology.sh")).andExpect(jsonPath("$.batchIndexingScriptPath").value("/usr/metron/" + metronVersion + "/bin/start_hdfs_topology.sh"));    globalConfigService.delete();    sensorParserConfigService.delete("broTest");}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();    ImmutableMap<String, String> testData = ImmutableMap.of("bro_index_2017.01.01.01", SearchIntegrationTest.broData, "snort_index_2017.01.01.01", SearchIntegrationTest.snortData, metaAlertIndex, MetaAlertControllerIntegrationTest.metaAlertData);    loadTestData(testData);}
0
public void shouldPatchDocument() throws Exception
{    String guid = "bro_2";        MockHttpServletRequestBuilder findOneRequest = post(searchUrl + "/findOne").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(findMessage0);        MockHttpServletRequestBuilder patchRequest = patch(updateUrl + "/patch").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(patch);        this.mockMvc.perform(findOneRequest).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.source:type").value("bro")).andExpect(jsonPath("$.guid").value(guid)).andExpect(jsonPath("$.project").doesNotExist()).andExpect(jsonPath("$.timestamp").value(2));        MockHTable table = (MockHTable) MockHBaseTableProvider.getFromCache(TABLE);    Assert.assertEquals(0, table.size());        this.mockMvc.perform(patchRequest).andExpect(status().isOk());        this.mockMvc.perform(findOneRequest).andExpect(status().isOk()).andExpect(content().contentType(MediaType.parseMediaType("application/json;charset=UTF-8"))).andExpect(jsonPath("$.source:type").value("bro")).andExpect(jsonPath("$.guid").value(guid)).andExpect(jsonPath("$.project").value("metron")).andExpect(jsonPath("$.timestamp").value(2));        Assert.assertEquals(1, table.size());    {                Get g = new Get(new HBaseDao.Key(guid, "bro").toBytes());        Result r = table.get(g);        NavigableMap<byte[], byte[]> columns = r.getFamilyMap(CF.getBytes(StandardCharsets.UTF_8));        Assert.assertEquals(1, columns.size());    }}
0
public void shouldAddComment() throws Exception
{    CommentAddRemoveRequest commentAddRemoveRequest = new CommentAddRemoveRequest();    commentAddRemoveRequest.setGuid("bro_1");    commentAddRemoveRequest.setSensorType("bro");    commentAddRemoveRequest.setComment("test_comment");    commentAddRemoveRequest.setUsername("test_username");    commentAddRemoveRequest.setTimestamp(0L);    updateService.addComment(commentAddRemoveRequest);    ResultActions result = this.mockMvc.perform(post(updateUrl + "/add/comment").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(addComment));    result.andExpect(status().isOk());}
0
public void shouldRemoveComment() throws Exception
{    CommentAddRemoveRequest commentAddRemoveRequest = new CommentAddRemoveRequest();    commentAddRemoveRequest.setGuid("bro_1");    commentAddRemoveRequest.setSensorType("bro");    commentAddRemoveRequest.setComment("test_comment");    commentAddRemoveRequest.setUsername("test_username");    commentAddRemoveRequest.setTimestamp(0L);    updateService.removeComment(commentAddRemoveRequest);    ResultActions result = this.mockMvc.perform(post(updateUrl + "/remove/comment").with(httpBasic(user, password)).with(csrf()).contentType(MediaType.parseMediaType("application/json;charset=UTF-8")).content(removeComment));    result.andExpect(status().isOk());}
0
public void setup() throws Exception
{    this.mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity()).build();}
0
public void testSecurity() throws Exception
{    this.mockMvc.perform(get(userUrl)).andExpect(status().isUnauthorized());}
0
public void testGetUser() throws Exception
{    this.mockMvc.perform(get(userUrl).with(httpBasic(user1, password))).andExpect(status().isOk()).andExpect(content().string(user1));}
0
public void setBrokerUrl(String brokerUrl)
{    this.brokerUrl = brokerUrl;}
0
public void setNum(Integer num)
{    this.num = num;}
0
public void setSelectedSensorType(String selectedSensorType)
{    this.selectedSensorType = selectedSensorType;}
0
public void setDelay(Integer delay)
{    this.delay = delay;}
0
public static void main(String[] args) throws org.apache.commons.cli.ParseException, IOException, ParseException
{    CommandLineParser parser = new PosixParser();    CommandLine cli = parser.parse(getOptions(), args);    Integer num = Integer.parseInt(cli.getOptionValue("n", "-1"));    String selectedSensorType = cli.getOptionValue("s");    Integer delay = Integer.parseInt(cli.getOptionValue("d", "1000"));    String path = cli.getOptionValue("p");    if (selectedSensorType == null || path == null) {        HelpFormatter formatter = new HelpFormatter();        formatter.printHelp("sample_data_generator", getOptions());    } else {        SampleDataGenerator sampleDataGenerator = new SampleDataGenerator();        sampleDataGenerator.setNum(num);        sampleDataGenerator.setSelectedSensorType(selectedSensorType);        sampleDataGenerator.setDelay(delay);        sampleDataGenerator.generateSampleData(path);    }}
0
private static Options getOptions()
{    Options options = new Options();    options.addOption("b", "brokerUrl", true, "Kafka Broker Url");    options.addOption("n", "num", false, "Number of messages to emit");    options.addOption("s", "sensorType", true, "Emit messages to this topic");    options.addOption("d", "delay", false, "Number of milliseconds to wait between each message.  Defaults to 1 second");    options.addOption("p", "path", true, "Local path to data file");    return options;}
0
public void generateSampleData(String path) throws IOException, ParseException
{    loadData(path);    startClients();    try {        emitData(num, selectedSensorType, delay);    } finally {        stopClients();    }}
0
private void loadData(String sampleDataPath) throws IOException, ParseException
{    sampleData.put(selectedSensorType, FileUtils.readLines(new File(sampleDataPath)));    indexes.put(selectedSensorType, 0);}
0
private void emitData(int num, String selectedSensorType, int delay)
{    int count = 0;    boolean continueEmitting = false;    do {        for (String sensorType : sampleData.keySet()) {            if (selectedSensorType == null || selectedSensorType.equals(sensorType)) {                List<String> sensorData = sampleData.get(sensorType);                int index = indexes.get(sensorType);                String message = sensorData.get(index++);                emitSensorData(sensorType, message, delay);                if (num != -1 && ++count >= num) {                    continueEmitting = false;                    break;                }                continueEmitting = true;                if (index == sensorData.size()) {                    index = 0;                }                indexes.put(sensorType, index);            }        }    } while (continueEmitting);}
0
private void emitSensorData(String sensorType, String message, int delay)
{    try {        Thread.sleep(delay);    } catch (InterruptedException e) {        e.printStackTrace();    }        emitToKafka(sensorType, message);}
1
private void startClients()
{    startKafka();}
0
private void startKafka()
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", brokerUrl);    producerConfig.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");    producerConfig.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");    kafkaProducer = new KafkaProducer<>(producerConfig);}
0
private void stopClients()
{    stopKafka();}
0
private void stopKafka()
{        kafkaProducer.close();}
1
private void emitToKafka(String topic, String message)
{    kafkaProducer.send(new ProducerRecord<String, String>(topic, message));}
0
public void test()
{    mockStatic(SpringApplication.class);    String[] args = { "arg1", "arg2" };    MetronRestApplication.main(args);    verifyStatic(times(1));    SpringApplication.run(MetronRestApplication.class, args);}
0
public Statusable<Path> submit(Finalizer<Path> finalizer, Map<String, Object> configuration) throws JobException
{    when(statusable.getConfiguration()).thenReturn(new HashMap<>(configuration));    this.basePath = PcapOptions.BASE_PATH.get(configuration, String.class);    this.baseInterrimResultPath = PcapOptions.BASE_INTERIM_RESULT_PATH.get(configuration, String.class);    this.finalOutputPath = PcapOptions.FINAL_OUTPUT_PATH.get(configuration, String.class);    this.startTimeNs = PcapOptions.START_TIME_MS.get(configuration, Long.class) * 1000000;    this.endTimeNs = PcapOptions.END_TIME_MS.get(configuration, Long.class) * 1000000;    this.numReducers = PcapOptions.NUM_REDUCERS.get(configuration, Integer.class);    Object fields = PcapOptions.FIELDS.get(configuration, Object.class);    if (fields instanceof Map) {        this.fixedFields = (Map<String, String>) fields;    } else {        this.query = (String) fields;    }    this.filterImpl = PcapOptions.FILTER_IMPL.get(configuration, PcapFilterConfigurator.class);    this.recPerFile = PcapOptions.NUM_RECORDS_PER_FILE.get(configuration, Integer.class);    this.yarnQueue = PcapOptions.HADOOP_CONF.get(configuration, Configuration.class).get(MRJobConfig.QUEUE_NAME);    this.finalizerThreadpoolSize = PcapOptions.FINALIZER_THREADPOOL_SIZE.get(configuration, String.class);    return statusable;}
0
public JobStatus getStatus() throws JobException
{    return statusable.getStatus();}
0
public Pageable<Path> get() throws JobException, InterruptedException
{    return statusable.get();}
0
public void setStatus(JobStatus jobStatus) throws JobException
{    when(statusable.getStatus()).thenReturn(jobStatus);}
0
public void setPageable(Pageable<Path> pageable) throws JobException, InterruptedException
{    when(statusable.get()).thenReturn(pageable);}
0
public void setIsDone(boolean isDone)
{    when(statusable.isDone()).thenReturn(isDone);}
0
public String getBasePath()
{    return basePath;}
0
public void setBasePath(String basePath)
{    this.basePath = basePath;}
0
public String getBaseInterrimResultPath()
{    return baseInterrimResultPath;}
0
public void setBaseInterrimResultPath(String baseInterrimResultPath)
{    this.baseInterrimResultPath = baseInterrimResultPath;}
0
public String getFinalOutputPath()
{    return finalOutputPath;}
0
public void setFinalOutputPath(String finalOutputPath)
{    this.finalOutputPath = finalOutputPath;}
0
public long getStartTimeNs()
{    return startTimeNs;}
0
public long getEndTimeNs()
{    return endTimeNs;}
0
public int getNumReducers()
{    return numReducers;}
0
public Map<String, String> getFixedFields()
{    return fixedFields;}
0
public String getQuery()
{    return query;}
0
public PcapFilterConfigurator getFilterImpl()
{    return filterImpl;}
0
public int getRecPerFile()
{    return recPerFile;}
0
public String getYarnQueue()
{    return yarnQueue;}
0
public String getFinalizerThreadpoolSize()
{    return finalizerThreadpoolSize;}
0
protected PcapJob createPcapJob()
{    return mockPcapJob;}
0
public void setMockPcapJob(MockPcapJob mockPcapJob)
{    this.mockPcapJob = mockPcapJob;}
0
public InputStream execute(String scriptPath, FileSystem fileSystem, Path pcapPath) throws IOException
{    return new ByteArrayInputStream(pdmlXml.getBytes(StandardCharsets.UTF_8));}
0
public Set<String> getParserTopologyNames()
{    return parsersStatus.keySet();}
0
public TopologyStatusCode getParserStatus(String name)
{    TopologyStatusCode parserStatus = parsersStatus.get(name);    if (parserStatus == null) {        return TopologyStatusCode.TOPOLOGY_NOT_FOUND;    } else {        return parserStatus;    }}
0
public int startParserTopology(String name) throws RestException
{    TopologyStatusCode parserStatus = parsersStatus.get(name);    if (parserStatus == null || parserStatus == TopologyStatusCode.TOPOLOGY_NOT_FOUND) {        parsersStatus.put(name, TopologyStatusCode.ACTIVE);        return 0;    } else {        return 1;    }}
0
public int stopParserTopology(String name, boolean stopNow) throws RestException
{    TopologyStatusCode parserStatus = parsersStatus.get(name);    if (parserStatus == TopologyStatusCode.ACTIVE) {        parsersStatus.put(name, TopologyStatusCode.TOPOLOGY_NOT_FOUND);        return 0;    } else {        return 1;    }}
0
public int activateParserTopology(String name)
{    TopologyStatusCode parserStatus = parsersStatus.get(name);    if (parserStatus == TopologyStatusCode.INACTIVE || parserStatus == TopologyStatusCode.ACTIVE) {        parsersStatus.put(name, TopologyStatusCode.ACTIVE);        return 0;    } else {        return 1;    }}
0
public int deactivateParserTopology(String name)
{    TopologyStatusCode parserStatus = parsersStatus.get(name);    if (parserStatus == TopologyStatusCode.INACTIVE || parserStatus == TopologyStatusCode.ACTIVE) {        parsersStatus.put(name, TopologyStatusCode.INACTIVE);        return 0;    } else {        return 1;    }}
0
public TopologyStatusCode getEnrichmentStatus()
{    return enrichmentStatus;}
0
public int startEnrichmentTopology() throws RestException
{    if (enrichmentStatus == TopologyStatusCode.TOPOLOGY_NOT_FOUND) {        enrichmentStatus = TopologyStatusCode.ACTIVE;        return 0;    } else {        return 1;    }}
0
public int stopEnrichmentTopology(boolean stopNow) throws RestException
{    if (enrichmentStatus == TopologyStatusCode.ACTIVE) {        enrichmentStatus = TopologyStatusCode.TOPOLOGY_NOT_FOUND;        return 0;    } else {        return 1;    }}
0
public int activateEnrichmentTopology()
{    if (enrichmentStatus == TopologyStatusCode.INACTIVE || enrichmentStatus == TopologyStatusCode.ACTIVE) {        enrichmentStatus = TopologyStatusCode.ACTIVE;        return 0;    } else {        return 1;    }}
0
public int deactivateEnrichmentTopology()
{    if (enrichmentStatus == TopologyStatusCode.INACTIVE || enrichmentStatus == TopologyStatusCode.ACTIVE) {        enrichmentStatus = TopologyStatusCode.INACTIVE;        return 0;    } else {        return 1;    }}
0
public TopologyStatusCode getIndexingStatus(String name)
{    return name.equals(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME) ? batchIndexingStatus : randomAccessIndexingStatus;}
0
public int startIndexingTopology(String scriptPath) throws RestException
{    if (scriptPath.equals(MetronRestConstants.BATCH_INDEXING_SCRIPT_PATH_SPRING_PROPERTY)) {        if (batchIndexingStatus == TopologyStatusCode.TOPOLOGY_NOT_FOUND) {            batchIndexingStatus = TopologyStatusCode.ACTIVE;            return 0;        } else {            return 1;        }    } else {        if (randomAccessIndexingStatus == TopologyStatusCode.TOPOLOGY_NOT_FOUND) {            randomAccessIndexingStatus = TopologyStatusCode.ACTIVE;            return 0;        } else {            return 1;        }    }}
0
public int stopIndexingTopology(String name, boolean stopNow) throws RestException
{    if (name.equals(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME)) {        if (batchIndexingStatus == TopologyStatusCode.ACTIVE) {            batchIndexingStatus = TopologyStatusCode.TOPOLOGY_NOT_FOUND;            return 0;        } else {            return 1;        }    } else {        if (randomAccessIndexingStatus == TopologyStatusCode.ACTIVE) {            randomAccessIndexingStatus = TopologyStatusCode.TOPOLOGY_NOT_FOUND;            return 0;        } else {            return 1;        }    }}
0
public int activateIndexingTopology(String name)
{    if (name.equals(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME)) {        if (batchIndexingStatus == TopologyStatusCode.INACTIVE || batchIndexingStatus == TopologyStatusCode.ACTIVE) {            batchIndexingStatus = TopologyStatusCode.ACTIVE;            return 0;        } else {            return 1;        }    } else {        if (randomAccessIndexingStatus == TopologyStatusCode.INACTIVE || randomAccessIndexingStatus == TopologyStatusCode.ACTIVE) {            randomAccessIndexingStatus = TopologyStatusCode.ACTIVE;            return 0;        } else {            return 1;        }    }}
0
public int deactivateIndexingTopology(String name)
{    if (name.equals(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME)) {        if (batchIndexingStatus == TopologyStatusCode.INACTIVE || batchIndexingStatus == TopologyStatusCode.ACTIVE) {            batchIndexingStatus = TopologyStatusCode.INACTIVE;            return 0;        } else {            return 1;        }    } else {        if (randomAccessIndexingStatus == TopologyStatusCode.INACTIVE || randomAccessIndexingStatus == TopologyStatusCode.ACTIVE) {            randomAccessIndexingStatus = TopologyStatusCode.INACTIVE;            return 0;        } else {            return 1;        }    }}
0
protected String stormClientVersionInstalled() throws RestException
{    return "1.0.1";}
0
public void setMockStormCLIClientWrapper(MockStormCLIClientWrapper mockStormCLIClientWrapper)
{    this.mockStormCLIClientWrapper = mockStormCLIClientWrapper;}
0
public Object getForObject(String url, Class responseType, Object... urlVariables) throws RestClientException
{    Object response = null;    if (url.equals(getStormUiProperty() + MetronRestConstants.TOPOLOGY_SUMMARY_URL)) {        TopologySummary topologySummary = new TopologySummary();        List<TopologyStatus> topologyStatusList = new ArrayList<>();        for (String name : mockStormCLIClientWrapper.getParserTopologyNames()) {            topologyStatusList.add(getTopologyStatus(name));        }        TopologyStatusCode enrichmentStatus = mockStormCLIClientWrapper.getEnrichmentStatus();        if (enrichmentStatus != TopologyStatusCode.TOPOLOGY_NOT_FOUND) {            topologyStatusList.add(getTopologyStatus("enrichment"));        }        TopologyStatusCode batchIndexingStatus = mockStormCLIClientWrapper.getIndexingStatus(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME);        if (batchIndexingStatus != TopologyStatusCode.TOPOLOGY_NOT_FOUND) {            topologyStatusList.add(getTopologyStatus(MetronRestConstants.BATCH_INDEXING_TOPOLOGY_NAME));        }        TopologyStatusCode randomIndexingStatus = mockStormCLIClientWrapper.getIndexingStatus(MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME);        if (randomIndexingStatus != TopologyStatusCode.TOPOLOGY_NOT_FOUND) {            topologyStatusList.add(getTopologyStatus(MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME));        }        topologySummary.setTopologies(topologyStatusList.toArray(new TopologyStatus[topologyStatusList.size()]));        response = topologySummary;    } else if (url.startsWith(getStormUiProperty() + MetronRestConstants.TOPOLOGY_URL + "/")) {        String name = url.substring(url.lastIndexOf('/') + 1, url.length()).replaceFirst("-id", "");        response = getTopologyStatus(name);    } else if (url.startsWith("http://" + environment.getProperty(MetronRestConstants.STORM_UI_SPRING_PROPERTY) + MetronRestConstants.SUPERVISOR_SUMMARY_URL)) {        SupervisorSummary supervisorSummary = new SupervisorSummary();        List<SupervisorStatus> supervisorStatusList = new ArrayList<>();        SupervisorStatus status = new SupervisorStatus("sup1", "localhost", "1m 2s", 1, 1);        supervisorStatusList.add(status);        supervisorSummary.setSupervisors(supervisorStatusList.toArray(new SupervisorStatus[1]));        response = supervisorSummary;    }    return response;}
0
private TopologyStatus getTopologyStatus(String name)
{    TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setName(name);    topologyStatus.setId(name + "-id");    if ("enrichment".equals(name)) {        topologyStatus.setStatus(mockStormCLIClientWrapper.getEnrichmentStatus());    } else if (name.contains("indexing")) {        topologyStatus.setStatus(mockStormCLIClientWrapper.getIndexingStatus(name));    } else {        topologyStatus.setStatus(mockStormCLIClientWrapper.getParserStatus(name));    }    return topologyStatus;}
0
public Object postForObject(String url, Object request, Class responseType, Object... uriVariables) throws RestClientException
{    Map<String, String> result = new HashMap<>();    String[] urlParts = url.split("/");    String name = urlParts[urlParts.length - 2].replaceFirst("-id", "");    String action = urlParts[urlParts.length - 1];    int returnCode = 0;    if (action.equals("activate")) {        if (name.equals("enrichment")) {            returnCode = mockStormCLIClientWrapper.activateEnrichmentTopology();        } else if (name.contains("indexing")) {            returnCode = mockStormCLIClientWrapper.activateIndexingTopology(name);        } else {            returnCode = mockStormCLIClientWrapper.activateParserTopology(name);        }    } else if (action.equals("deactivate")) {        if (name.equals("enrichment")) {            returnCode = mockStormCLIClientWrapper.deactivateEnrichmentTopology();        } else if (name.contains("indexing")) {            returnCode = mockStormCLIClientWrapper.deactivateIndexingTopology(name);        } else {            returnCode = mockStormCLIClientWrapper.deactivateParserTopology(name);        }    }    if (returnCode == 0) {        result.put("status", "success");    } else {        result.put("status", "error");    }    return result;}
0
protected String getStormUiProperty()
{    String baseValue = environment.getProperty(MetronRestConstants.STORM_UI_SPRING_PROPERTY);    if (!(baseValue.contains("://"))) {        return "http://" + baseValue;    }    return baseValue;}
0
public void setUp() throws Exception
{    kafkaService = mock(KafkaService.class);    environment = mock(Environment.class);    userSettingsClient = mock(UserSettingsClient.class);    alertsUIService = new AlertsUIServiceImpl(kafkaService, environment, userSettingsClient);        clock = new FakeClock();    clock.elapseSeconds(1000);    alertsUIService.setClock(clock);        Authentication authentication = Mockito.mock(Authentication.class);    UserDetails userDetails = Mockito.mock(UserDetails.class);    when(authentication.getPrincipal()).thenReturn(userDetails);    when(userDetails.getUsername()).thenReturn(user1);    SecurityContextHolder.getContext().setAuthentication(authentication);}
0
public void escalateAlertShouldSendMessageToKafka() throws Exception
{    final String field = "field";    final String value1 = "value1";    final String value2 = "value2";        final String escalationTopic = "escalation";    when(environment.getProperty(MetronRestConstants.KAFKA_TOPICS_ESCALATION_PROPERTY)).thenReturn(escalationTopic);        final Map<String, Object> alert1 = mapOf(field, value1);    String escalationMessage1 = escalationMessage(field, value1, user1, clock.currentTimeMillis());    final Map<String, Object> alert2 = mapOf(field, value2);    String escalationMessage2 = escalationMessage(field, value2, user1, clock.currentTimeMillis());        alertsUIService.escalateAlerts(Arrays.asList(alert1, alert2));    verify(kafkaService).produceMessage(escalationTopic, escalationMessage1);    verify(kafkaService).produceMessage(escalationTopic, escalationMessage2);    verifyZeroInteractions(kafkaService);}
0
public void getShouldProperlyReturnActiveProfile() throws Exception
{    when(userSettingsClient.findOne(user1, AlertsUIServiceImpl.ALERT_USER_SETTING_TYPE)).thenReturn(Optional.of(user1AlertUserSettings));    AlertsUIUserSettings expectedAlertsUIUserSettings = new AlertsUIUserSettings();    expectedAlertsUIUserSettings.setTableColumns(Collections.singletonList("user1_field"));    assertEquals(expectedAlertsUIUserSettings, alertsUIService.getAlertsUIUserSettings().get());    verify(userSettingsClient, times(1)).findOne(user1, AlertsUIServiceImpl.ALERT_USER_SETTING_TYPE);    verifyNoMoreInteractions(userSettingsClient);}
0
public void findAllShouldProperlyReturnActiveProfiles() throws Exception
{    AlertsUIUserSettings alertsProfile1 = new AlertsUIUserSettings();    alertsProfile1.setUser(user1);    AlertsUIUserSettings alertsProfile2 = new AlertsUIUserSettings();    alertsProfile2.setUser(user1);    when(userSettingsClient.findAll(AlertsUIServiceImpl.ALERT_USER_SETTING_TYPE)).thenReturn(new HashMap<String, Optional<String>>() {        {            put(user1, Optional.of(user1AlertUserSettings));            put(user2, Optional.of(user2AlertUserSettings));        }    });    AlertsUIUserSettings expectedAlertsUIUserSettings1 = new AlertsUIUserSettings();    expectedAlertsUIUserSettings1.setTableColumns(Collections.singletonList("user1_field"));    AlertsUIUserSettings expectedAlertsUIUserSettings2 = new AlertsUIUserSettings();    expectedAlertsUIUserSettings2.setTableColumns(Collections.singletonList("user2_field"));    Map<String, AlertsUIUserSettings> actualAlertsProfiles = alertsUIService.findAllAlertsUIUserSettings();    assertEquals(2, actualAlertsProfiles.size());    assertEquals(expectedAlertsUIUserSettings1, actualAlertsProfiles.get(user1));    assertEquals(expectedAlertsUIUserSettings2, actualAlertsProfiles.get(user2));    verify(userSettingsClient, times(1)).findAll(AlertsUIServiceImpl.ALERT_USER_SETTING_TYPE);    verifyNoMoreInteractions(userSettingsClient);}
0
public void saveShouldProperlySaveActiveProfile() throws Exception
{    AlertsUIUserSettings alertsUIUserSettings = new AlertsUIUserSettings();    alertsUIUserSettings.setTableColumns(Collections.singletonList("user1_field"));    alertsUIService.saveAlertsUIUserSettings(alertsUIUserSettings);    String expectedAlertUserSettings = _mapper.get().writeValueAsString(alertsUIUserSettings);    verify(userSettingsClient, times(1)).save(user1, AlertsUIServiceImpl.ALERT_USER_SETTING_TYPE, expectedAlertUserSettings);    verifyNoMoreInteractions(userSettingsClient);}
0
public void deleteShouldProperlyDeleteActiveProfile() throws Exception
{    assertTrue(alertsUIService.deleteAlertsUIUserSettings(user1));    doThrow(new IOException()).when(userSettingsClient).delete(user1, AlertsUIServiceImpl.ALERT_USER_SETTING_TYPE);    assertFalse(alertsUIService.deleteAlertsUIUserSettings(user1));    verify(userSettingsClient, times(2)).delete(user1, AlertsUIServiceImpl.ALERT_USER_SETTING_TYPE);    verifyNoMoreInteractions(userSettingsClient);}
0
private String escalationMessage(String field, String value, String user, Long timestamp)
{    return String.format("{\"%s\":\"%s\",\"%s\":\"%s\",\"%s\":%d}", field, value, MetronRestConstants.METRON_ESCALATION_USER_FIELD, user, MetronRestConstants.METRON_ESCALATION_TIMESTAMP_FIELD, timestamp);}
0
private Map<String, Object> mapOf(String key, Object value)
{    Map<String, Object> map = new HashMap<>();    map.put(key, value);    return map;}
0
public void setup()
{    MockitoAnnotations.initMocks(this);    cachedStormStatusService = new CachedStormStatusServiceImpl(stormService, 150, 30);}
0
public void caches_supervisor_summary()
{    SupervisorStatus supervisorStatus1 = new SupervisorStatus();    SupervisorStatus supervisorStatus2 = new SupervisorStatus();    SupervisorSummary supervisorSummary = new SupervisorSummary(new SupervisorStatus[] { supervisorStatus1, supervisorStatus2 });    when(stormService.getSupervisorSummary()).thenReturn(supervisorSummary);        for (int i = 0; i < 100; i++) {        cachedStormStatusService.getSupervisorSummary();    }    SupervisorSummary summary = cachedStormStatusService.getSupervisorSummary();    assertThat("Number of supervisors did not match.", summary.getSupervisors().length, CoreMatchers.equalTo(2));    verify(stormService, times(1)).getSupervisorSummary();    cachedStormStatusService.reset();    summary = cachedStormStatusService.getSupervisorSummary();    assertThat("Number of supervisors did not match.", summary.getSupervisors().length, CoreMatchers.equalTo(2));    verify(stormService, times(2)).getSupervisorSummary();}
0
public void caches_topology_summary()
{    TopologyStatus topologyStatus1 = new TopologyStatus();    TopologyStatus topologyStatus2 = new TopologyStatus();    TopologySummary topologySummary = new TopologySummary(new TopologyStatus[] { topologyStatus1, topologyStatus2 });    when(stormService.getTopologySummary()).thenReturn(topologySummary);        for (int i = 0; i < 100; i++) {        cachedStormStatusService.getTopologySummary();    }    TopologySummary summary = cachedStormStatusService.getTopologySummary();    assertThat("Number of topologies did not match.", summary.getTopologies().length, CoreMatchers.equalTo(2));    verify(stormService, times(1)).getTopologySummary();    cachedStormStatusService.reset();    summary = cachedStormStatusService.getTopologySummary();    assertThat("Number of topologies did not match.", summary.getTopologies().length, CoreMatchers.equalTo(2));    verify(stormService, times(2)).getTopologySummary();}
0
public void caches_topology_status_by_name()
{    String topologyName1 = "topology-1";    String topologyName2 = "topology-2";    TopologyStatus topologyStatus1 = new TopologyStatus();    topologyStatus1.setName(topologyName1);    TopologyStatus topologyStatus2 = new TopologyStatus();    topologyStatus2.setName(topologyName2);    when(stormService.getTopologyStatus(topologyName1)).thenReturn(topologyStatus1);    when(stormService.getTopologyStatus(topologyName2)).thenReturn(topologyStatus2);        for (int i = 0; i < 100; i++) {        cachedStormStatusService.getTopologyStatus(topologyName1);        cachedStormStatusService.getTopologyStatus(topologyName2);    }    TopologyStatus status1 = cachedStormStatusService.getTopologyStatus(topologyName1);    TopologyStatus status2 = cachedStormStatusService.getTopologyStatus(topologyName2);    assertThat("Name did not match for topology 1.", status1.getName(), CoreMatchers.equalTo(topologyName1));    assertThat("Name did not match for topology 2.", status2.getName(), CoreMatchers.equalTo(topologyName2));    verify(stormService, times(1)).getTopologyStatus(topologyName1);    verify(stormService, times(1)).getTopologyStatus(topologyName2);    cachedStormStatusService.reset();    cachedStormStatusService.getTopologyStatus(topologyName1);    cachedStormStatusService.getTopologyStatus(topologyName2);    verify(stormService, times(2)).getTopologyStatus(topologyName1);    verify(stormService, times(2)).getTopologyStatus(topologyName2);}
0
public void caches_all_topology_status()
{    TopologyStatus topologyStatus1 = new TopologyStatus();    TopologyStatus topologyStatus2 = new TopologyStatus();    List<TopologyStatus> allTopologyStatus = ImmutableList.of(topologyStatus1, topologyStatus2);    when(stormService.getAllTopologyStatus()).thenReturn(allTopologyStatus);        for (int i = 0; i < 100; i++) {        cachedStormStatusService.getAllTopologyStatus();    }    List<TopologyStatus> allStatus = cachedStormStatusService.getAllTopologyStatus();    assertThat("Number of topologies returned by all topology status check did not match.", allStatus.size(), CoreMatchers.equalTo(2));    verify(stormService, times(1)).getAllTopologyStatus();    cachedStormStatusService.reset();    cachedStormStatusService.getAllTopologyStatus();    verify(stormService, times(2)).getAllTopologyStatus();}
0
public void admin_functions_act_as_simple_passthroughs_to_storm_service()
{    TopologyResponse topologyResponse = new TopologyResponse();    when(stormService.activateTopology(anyString())).thenReturn(topologyResponse);    when(stormService.deactivateTopology(anyString())).thenReturn(topologyResponse);    for (int i = 0; i < 100; i++) {        cachedStormStatusService.activateTopology("foo");        cachedStormStatusService.deactivateTopology("foo");    }    verify(stormService, times(100)).activateTopology(anyString());    verify(stormService, times(100)).deactivateTopology(anyString());}
0
public void setUp() throws Exception
{    processBuilder = mock(ProcessBuilder.class);    environment = mock(Environment.class);    dockerStormCLIWrapper = new DockerStormCLIWrapper(environment);}
0
public void getProcessBuilderShouldProperlyGenerateProcessorBuilder() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.environment()).thenReturn(new HashMap<>());    when(processBuilder.command()).thenReturn(new ArrayList<>());    Process process = mock(Process.class);    InputStream inputStream = new ByteArrayInputStream("export DOCKER_HOST=\"tcp://192.168.99.100:2376\"".getBytes(StandardCharsets.UTF_8));    when(processBuilder.start()).thenReturn(process);    when(process.getInputStream()).thenReturn(inputStream);    when(environment.getProperty("docker.compose.path")).thenReturn("/test");    when(environment.getProperty("metron.version")).thenReturn("1");    ProcessBuilder actualBuilder = dockerStormCLIWrapper.getProcessBuilder("oo", "ooo");    assertEquals(new HashMap<String, String>() {        {            put("METRON_VERSION", "1");            put("DOCKER_HOST", "tcp://192.168.99.100:2376");        }    }, actualBuilder.environment());    assertEquals(new ArrayList<>(), actualBuilder.command());    verify(process).waitFor();}
0
public void setUp() throws Exception
{    curatorFramework = mock(CuratorFramework.class);    cache = mock(ConfigurationsCache.class);    globalConfigService = new GlobalConfigServiceImpl(curatorFramework, cache);}
0
public void deleteShouldProperlyCatchNoNodeExceptionAndReturnFalse() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.GLOBAL.getZookeeperRoot())).thenThrow(KeeperException.NoNodeException.class);    assertFalse(globalConfigService.delete());}
0
public void deleteShouldProperlyCatchNonNoNodeExceptionAndThrowRestException() throws Exception
{    exception.expect(RestException.class);    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.GLOBAL.getZookeeperRoot())).thenThrow(Exception.class);    assertFalse(globalConfigService.delete());}
0
public void deleteShouldReturnTrueWhenClientSuccessfullyCallsDelete() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.GLOBAL.getZookeeperRoot())).thenReturn(null);    assertTrue(globalConfigService.delete());    verify(curatorFramework).delete();}
0
public void getShouldProperlyReturnGlobalConfig() throws Exception
{    final String config = "{\"k\":\"v\"}";    final Map<String, Object> configMap = new HashMap<String, Object>() {        {            put("k", "v");        }    };    EnrichmentConfigurations configs = new EnrichmentConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(ConfigurationType.GLOBAL.getTypeName(), configMap);        }    };    when(cache.get(eq(EnrichmentConfigurations.class))).thenReturn(configs);    assertEquals(configMap, globalConfigService.get());}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(ConfigurationType.GLOBAL.getTypeName(), configMap);}
0
public void getShouldWrapNonNoNodeExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    GetDataBuilder getDataBuilder = mock(GetDataBuilder.class);    when(getDataBuilder.forPath(ConfigurationType.GLOBAL.getZookeeperRoot())).thenThrow(Exception.class);    when(curatorFramework.getData()).thenReturn(getDataBuilder);    globalConfigService.get();}
0
public void saveShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.GLOBAL.getZookeeperRoot(), "{ }".getBytes(StandardCharsets.UTF_8))).thenThrow(Exception.class);    when(curatorFramework.setData()).thenReturn(setDataBuilder);    globalConfigService.save(new HashMap<>());}
0
public void saveShouldReturnSameConfigThatIsPassedOnSuccessfulSave() throws Exception
{    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.GLOBAL.getZookeeperRoot(), "{ }".getBytes(StandardCharsets.UTF_8))).thenReturn(new Stat());    when(curatorFramework.setData()).thenReturn(setDataBuilder);    assertEquals(new HashMap<>(), globalConfigService.save(new HashMap<>()));    verify(setDataBuilder).forPath(eq(ConfigurationType.GLOBAL.getZookeeperRoot()), eq("{ }".getBytes(StandardCharsets.UTF_8)));}
0
public void setUp() throws Exception
{    environment = mock(Environment.class);    grok = mock(Grok.class);    hdfsService = new HdfsServiceImpl(new Configuration());    grokService = new GrokServiceImpl(environment, grok, hdfsService);}
0
public void getCommonGrokPattersShouldCallGrokToGetPatterns() throws Exception
{    grokService.getCommonGrokPatterns();    verify(grok).getPatterns();}
0
public void getCommonGrokPattersShouldCallGrokToGetPatternsAndNotAlterValue() throws Exception
{    final Map<String, String> actual = new HashMap<String, String>() {        {            put("k", "v");            put("k1", "v1");        }    };    when(grok.getPatterns()).thenReturn(actual);    Map<String, String> expected = new HashMap<String, String>() {        {            put("k", "v");            put("k1", "v1");        }    };    assertEquals(expected, grokService.getCommonGrokPatterns());}
0
public void validateGrokStatementShouldThrowExceptionWithNullStringAsPatternLabel() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("Pattern label is required");    GrokValidation grokValidation = new GrokValidation();    grokValidation.setResults(new HashMap<>());    grokValidation.setSampleData("asdf asdf");    grokValidation.setStatement("LABEL %{WORD:word1} %{WORD:word2}");    grokService.validateGrokStatement(grokValidation);}
0
public void validateGrokStatementShouldThrowExceptionWithEmptyStringAsStatement() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("Grok statement is required");    GrokValidation grokValidation = new GrokValidation();    grokValidation.setResults(new HashMap<>());    grokValidation.setSampleData("asdf asdf");    grokValidation.setPatternLabel("LABEL");    grokValidation.setStatement("");    grokService.validateGrokStatement(grokValidation);}
0
public void validateGrokStatementShouldThrowExceptionWithNullStringAsStatement() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("Grok statement is required");    GrokValidation grokValidation = new GrokValidation();    grokValidation.setResults(new HashMap<>());    grokValidation.setSampleData("asdf asdf");    grokValidation.setPatternLabel("LABEL");    grokValidation.setStatement(null);    grokService.validateGrokStatement(grokValidation);}
0
public void validateGrokStatementShouldProperlyMatchSampleDataAgainstGivenStatement() throws Exception
{    final GrokValidation grokValidation = new GrokValidation();    grokValidation.setResults(new HashMap<>());    grokValidation.setSampleData("asdf asdf");    grokValidation.setStatement("LABEL %{WORD:word1} %{WORD:word2}");    grokValidation.setPatternLabel("LABEL");    GrokValidation expected = new GrokValidation();    expected.setResults(new HashMap<String, Object>() {        {            put("word1", "asdf");            put("word2", "asdf");        }    });    expected.setSampleData("asdf asdf");    expected.setStatement("LABEL %{WORD:word1} %{WORD:word2}");    expected.setPatternLabel("LABEL");    GrokValidation actual = grokService.validateGrokStatement(grokValidation);    assertEquals(expected, actual);    assertEquals(expected.hashCode(), actual.hashCode());}
0
public void validateGrokStatementShouldProperlyMatchNothingAgainstEmptyString() throws Exception
{    final GrokValidation grokValidation = new GrokValidation();    grokValidation.setResults(new HashMap<>());    grokValidation.setSampleData("");    grokValidation.setPatternLabel("LABEL");    grokValidation.setStatement("LABEL %{WORD:word1} %{WORD:word2}");    GrokValidation expected = new GrokValidation();    expected.setResults(new HashMap<>());    expected.setSampleData("");    expected.setPatternLabel("LABEL");    expected.setStatement("LABEL %{WORD:word1} %{WORD:word2}");    assertEquals(expected, grokService.validateGrokStatement(grokValidation));}
0
public void validateGrokStatementShouldProperlyMatchNothingAgainstNullString() throws Exception
{    final GrokValidation grokValidation = new GrokValidation();    grokValidation.setResults(new HashMap<>());    grokValidation.setSampleData(null);    grokValidation.setStatement("LABEL %{WORD:word1} %{WORD:word2}");    grokValidation.setPatternLabel("LABEL");    GrokValidation expected = new GrokValidation();    expected.setResults(new HashMap<>());    expected.setSampleData(null);    expected.setStatement("LABEL %{WORD:word1} %{WORD:word2}");    expected.setPatternLabel("LABEL");    assertEquals(expected, grokService.validateGrokStatement(grokValidation));}
0
public void invalidGrokStatementShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    GrokValidation grokValidation = new GrokValidation();    grokValidation.setResults(new HashMap<>());    grokValidation.setSampleData(null);    grokValidation.setStatement("LABEL %{WORD:word1} %{WORD:word2");    grokService.validateGrokStatement(grokValidation);}
0
public void saveTemporaryShouldProperlySaveFile() throws Exception
{    new File("./target/user1").delete();    String statement = "grok statement";    Authentication authentication = mock(Authentication.class);    when(authentication.getName()).thenReturn("user1");    SecurityContextHolder.getContext().setAuthentication(authentication);    when(environment.getProperty(GROK_TEMP_PATH_SPRING_PROPERTY)).thenReturn("./target");    grokService.saveTemporary(statement, "squid");    File testRoot = new File("./target/user1");    assertEquals(statement, FileUtils.readFileToString(new File(testRoot, "squid"), StandardCharsets.UTF_8));    testRoot.delete();}
0
public void missingGrokStatementShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("A grokStatement must be provided");    grokService.saveTemporary(null, "squid");}
0
public void getStatementFromClasspathShouldReturnStatement() throws Exception
{    String expected = FileUtils.readFileToString(new File("../../metron-platform/metron-parsing/metron-parsers/src/main/resources/patterns/squid"));    assertEquals(expected, grokService.getStatementFromClasspath("/patterns/squid"));}
0
public void getStatementFromClasspathShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("Could not find a statement at path /bad/path");    grokService.getStatementFromClasspath("/bad/path");}
0
public void setup() throws IOException
{    configuration = new Configuration();    hdfsService = new HdfsServiceImpl(configuration);    mockStatic(FileSystem.class);}
0
public void listShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    FileSystem fileSystem = mock(FileSystem.class);    when(FileSystem.get(configuration)).thenReturn(fileSystem);    when(fileSystem.listStatus(new Path(testDir))).thenThrow(new IOException());    hdfsService.list(new Path(testDir));}
0
public void readShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    FileSystem fileSystem = mock(FileSystem.class);    when(FileSystem.get(configuration)).thenReturn(fileSystem);    when(fileSystem.open(new Path(testDir))).thenThrow(new IOException());    hdfsService.read(new Path(testDir));}
0
public void writeShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    FileSystem fileSystem = mock(FileSystem.class);    when(FileSystem.get(configuration)).thenReturn(fileSystem);    when(fileSystem.create(new Path(testDir), true)).thenThrow(new IOException());    hdfsService.write(new Path(testDir), "contents".getBytes(UTF_8), null, null, null);}
0
public void writeShouldThrowIfInvalidPermissions() throws Exception
{    exception.expect(RestException.class);    FileSystem fileSystem = mock(FileSystem.class);    when(FileSystem.get(configuration)).thenReturn(fileSystem);    hdfsService.write(new Path(testDir, "test"), "oops".getBytes(UTF_8), "foo", "r-x", "r--");}
0
public void deleteShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    FileSystem fileSystem = mock(FileSystem.class);    when(FileSystem.get(configuration)).thenReturn(fileSystem);    when(fileSystem.delete(new Path(testDir), false)).thenThrow(new IOException());    hdfsService.delete(new Path(testDir), false);}
0
public void setup() throws IOException
{    configuration = new Configuration();    hdfsService = new HdfsServiceImpl(configuration);    File file = new File(testDir);    if (!file.exists()) {        file.mkdirs();    }    FileUtils.cleanDirectory(file);}
0
public void teardown() throws IOException
{    File file = new File(testDir);    FileUtils.cleanDirectory(file);}
0
public void listShouldListFiles() throws Exception
{    FileUtils.writeStringToFile(new File(testDir, "file1.txt"), "value1");    FileUtils.writeStringToFile(new File(testDir, "file2.txt"), "value2");    List<String> paths = hdfsService.list(new Path(testDir));    Collections.sort(paths);    assertEquals(2, paths.size());    assertEquals("file1.txt", paths.get(0));    assertEquals("file2.txt", paths.get(1));}
0
public void readShouldProperlyReadContents() throws Exception
{    String contents = "contents";    FileUtils.writeStringToFile(new File(testDir, "readTest.txt"), contents);    assertEquals("contents", hdfsService.read(new Path(testDir, "readTest.txt")));}
0
public void writeShouldProperlyWriteContents() throws Exception
{    String contents = "contents";    hdfsService.write(new Path(testDir, "writeTest.txt"), contents.getBytes(UTF_8), null, null, null);    assertEquals("contents", FileUtils.readFileToString(new File(testDir, "writeTest.txt")));}
0
public void writeShouldProperlyWriteContentsWithPermissions() throws Exception
{    String contents = "contents";    Path thePath = new Path(testDir, "writeTest2.txt");    hdfsService.write(thePath, contents.getBytes(UTF_8), "rw-", "r-x", "r--");    assertEquals("contents", FileUtils.readFileToString(new File(testDir, "writeTest2.txt")));    assertEquals(FileSystem.get(configuration).listStatus(thePath)[0].getPermission().toShort(), new FsPermission(FsAction.READ_WRITE, FsAction.READ_EXECUTE, FsAction.READ).toShort());}
0
public void deleteShouldProperlyDeleteFile() throws Exception
{    String contents = "contents";    FileUtils.writeStringToFile(new File(testDir, "deleteTest.txt"), contents);    List<String> paths = hdfsService.list(new Path(testDir));    assertEquals(1, paths.size());    assertEquals("deleteTest.txt", paths.get(0));    hdfsService.delete(new Path(testDir, "deleteTest.txt"), false);    paths = hdfsService.list(new Path(testDir));    assertEquals(0, paths.size());}
0
public void setUp() throws Exception
{    zkUtils = mock(ZkUtils.class);    kafkaConsumerFactory = mock(ConsumerFactory.class);    kafkaConsumer = mock(KafkaConsumer.class);    kafkaProducer = mock(KafkaProducer.class);    adminUtils = mock(AdminUtils$.class);    when(kafkaConsumerFactory.createConsumer()).thenReturn(kafkaConsumer);    kafkaService = new KafkaServiceImpl(zkUtils, kafkaConsumerFactory, kafkaProducer, adminUtils);}
0
public void listTopicsHappyPathWithListTopicsReturningNull() throws Exception
{    final Map<String, List<PartitionInfo>> topics = null;    when(kafkaConsumer.listTopics()).thenReturn(topics);    final Set<String> listedTopics = kafkaService.listTopics();    assertEquals(Sets.newHashSet(), listedTopics);    verifyZeroInteractions(zkUtils);    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer).close();    verifyNoMoreInteractions(kafkaConsumer, zkUtils, adminUtils);}
0
public void listTopicsHappyPathWithListTopicsReturningEmptyMap() throws Exception
{    final Map<String, List<PartitionInfo>> topics = new HashMap<>();    when(kafkaConsumer.listTopics()).thenReturn(topics);    final Set<String> listedTopics = kafkaService.listTopics();    assertEquals(Sets.newHashSet(), listedTopics);    verifyZeroInteractions(zkUtils);    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer).close();    verifyNoMoreInteractions(kafkaConsumer, zkUtils);}
0
public void listTopicsHappyPath() throws Exception
{    final Map<String, List<PartitionInfo>> topics = new HashMap<>();    topics.put("topic1", Lists.newArrayList());    topics.put("topic2", Lists.newArrayList());    topics.put("topic3", Lists.newArrayList());    when(kafkaConsumer.listTopics()).thenReturn(topics);    final Set<String> listedTopics = kafkaService.listTopics();    assertEquals(Sets.newHashSet("topic1", "topic2", "topic3"), listedTopics);    verifyZeroInteractions(zkUtils);    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer).close();    verifyNoMoreInteractions(kafkaConsumer, zkUtils);}
0
public void listTopicsShouldProperlyRemoveOffsetTopic() throws Exception
{    final Map<String, List<PartitionInfo>> topics = new HashMap<>();    topics.put("topic1", Lists.newArrayList());    topics.put("topic2", Lists.newArrayList());    topics.put("topic3", Lists.newArrayList());    topics.put("__consumer_offsets", Lists.newArrayList());    when(kafkaConsumer.listTopics()).thenReturn(topics);    final Set<String> listedTopics = kafkaService.listTopics();    assertEquals(Sets.newHashSet("topic1", "topic2", "topic3"), listedTopics);    verifyZeroInteractions(zkUtils);    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer).close();    verifyNoMoreInteractions(kafkaConsumer, zkUtils);}
0
public void deletingTopicThatDoesNotExistShouldReturnFalse() throws Exception
{    when(kafkaConsumer.listTopics()).thenReturn(Maps.newHashMap());    assertFalse(kafkaService.deleteTopic("non_existent_topic"));    verifyZeroInteractions(zkUtils);    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer).close();    verifyNoMoreInteractions(kafkaConsumer, zkUtils);}
0
public void deletingTopicThatExistShouldReturnTrue() throws Exception
{    final Map<String, List<PartitionInfo>> topics = new HashMap<>();    topics.put("non_existent_topic", Lists.newArrayList());    when(kafkaConsumer.listTopics()).thenReturn(topics);    assertTrue(kafkaService.deleteTopic("non_existent_topic"));    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer).close();    verify(adminUtils).deleteTopic(zkUtils, "non_existent_topic");    verifyNoMoreInteractions(kafkaConsumer);}
0
public void makeSureDeletingTopicReturnsFalseWhenNoTopicsExist() throws Exception
{    final Map<String, List<PartitionInfo>> topics = null;    when(kafkaConsumer.listTopics()).thenReturn(topics);    assertFalse(kafkaService.deleteTopic("non_existent_topic"));    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer).close();    verifyNoMoreInteractions(kafkaConsumer);}
0
public void getTopicShouldProperlyMapTopicToKafkaTopic() throws Exception
{    final PartitionInfo partitionInfo = mock(PartitionInfo.class);    when(partitionInfo.replicas()).thenReturn(new Node[] { new Node(1, "host", 8080) });    final Map<String, List<PartitionInfo>> topics = new HashMap<>();    topics.put("t", Lists.newArrayList(partitionInfo));    topics.put("t1", Lists.newArrayList());    final KafkaTopic expected = new KafkaTopic();    expected.setName("t");    expected.setNumPartitions(1);    expected.setReplicationFactor(1);    when(kafkaConsumer.listTopics()).thenReturn(topics);    when(kafkaConsumer.partitionsFor("t")).thenReturn(Lists.newArrayList(partitionInfo));    KafkaTopic actual = kafkaService.getTopic("t");    assertEquals(expected, actual);    assertEquals(expected.hashCode(), actual.hashCode());}
0
public void getTopicShouldProperlyHandleTopicsThatDontExist() throws Exception
{    final Map<String, List<PartitionInfo>> topics = new HashMap<>();    topics.put("t1", Lists.newArrayList());    when(kafkaConsumer.listTopics()).thenReturn(topics);    when(kafkaConsumer.partitionsFor("t")).thenReturn(Lists.newArrayList());    assertEquals(null, kafkaService.getTopic("t"));    verify(kafkaConsumer).listTopics();    verify(kafkaConsumer, times(0)).partitionsFor("t");    verify(kafkaConsumer).close();    verifyZeroInteractions(zkUtils);    verifyNoMoreInteractions(kafkaConsumer);}
0
public void createTopicShouldFailIfReplicationFactorIsGreaterThanAvailableBrokers() throws Exception
{    exception.expect(RestException.class);    doThrow(AdminOperationException.class).when(adminUtils).createTopic(eq(zkUtils), eq("t"), eq(1), eq(2), eq(new Properties()), eq(RackAwareMode.Disabled$.MODULE$));    kafkaService.createTopic(VALID_KAFKA_TOPIC);}
0
public void whenAdminUtilsThrowsAdminOperationExceptionCreateTopicShouldProperlyWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    final Map<String, List<PartitionInfo>> topics = new HashMap<>();    topics.put("1", new ArrayList<>());    when(kafkaConsumer.listTopics()).thenReturn(topics);    doThrow(AdminOperationException.class).when(adminUtils).createTopic(eq(zkUtils), eq("t"), eq(1), eq(2), eq(new Properties()), eq(RackAwareMode.Disabled$.MODULE$));    kafkaService.createTopic(VALID_KAFKA_TOPIC);}
0
public void getSampleMessageProperlyReturnsAMessageFromAGivenKafkaTopic() throws Exception
{    final String topicName = "t";    final Node host = new Node(1, "host", 8080);    final Node[] replicas = { host };    final List<PartitionInfo> partitionInfo = Lists.newArrayList(new PartitionInfo(topicName, 1, host, replicas, replicas));    final TopicPartition topicPartition = new TopicPartition(topicName, 1);    final List<TopicPartition> topicPartitions = Lists.newArrayList(topicPartition);    final Set<TopicPartition> topicPartitionsSet = Sets.newHashSet(topicPartitions);    final ConsumerRecords<String, String> records = new ConsumerRecords<>(new HashMap<TopicPartition, List<ConsumerRecord<String, String>>>() {        {            put(topicPartition, Lists.newArrayList(new ConsumerRecord<>(topicName, 1, 1, "k", "message")));        }    });    when(kafkaConsumer.listTopics()).thenReturn(new HashMap<String, List<PartitionInfo>>() {        {            put(topicName, Lists.newArrayList());        }    });    when(kafkaConsumer.partitionsFor(eq(topicName))).thenReturn(partitionInfo);    when(kafkaConsumer.assignment()).thenReturn(topicPartitionsSet);    when(kafkaConsumer.position(topicPartition)).thenReturn(1L);    when(kafkaConsumer.poll(100)).thenReturn(records);    assertEquals("message", kafkaService.getSampleMessage(topicName));    verify(kafkaConsumer).assign(eq(topicPartitions));    verify(kafkaConsumer).assignment();    verify(kafkaConsumer).poll(100);    verify(kafkaConsumer).unsubscribe();    verify(kafkaConsumer, times(2)).position(topicPartition);    verify(kafkaConsumer).seek(topicPartition, 0);    verifyZeroInteractions(zkUtils, adminUtils);}
0
public void produceMessageShouldProperlyProduceMessage() throws Exception
{    final String topicName = "t";    final String message = "{\"field\":\"value\"}";    kafkaService.produceMessage(topicName, message);    String expectedMessage = "{\"field\":\"value\"}";    verify(kafkaProducer).send(new ProducerRecord<>(topicName, expectedMessage));    verifyZeroInteractions(kafkaProducer);}
0
public void addACLtoNonExistingTopicShouldReturnFalse() throws Exception
{    when(kafkaConsumer.listTopics()).thenReturn(Maps.newHashMap());    assertFalse(kafkaService.addACLToCurrentUser("non_existent_topic"));}
0
public void setUp() throws Exception
{    environment = mock(Environment.class);    configuration = new Configuration();    mockPcapJobSupplier = new MockPcapJobSupplier();    pcapToPdmlScriptWrapper = new PcapToPdmlScriptWrapper();    when(environment.getProperty(MetronRestConstants.PCAP_BASE_PATH_SPRING_PROPERTY)).thenReturn("/base/path");    when(environment.getProperty(MetronRestConstants.PCAP_BASE_INTERIM_RESULT_PATH_SPRING_PROPERTY)).thenReturn("/base/interim/result/path");    when(environment.getProperty(MetronRestConstants.PCAP_FINAL_OUTPUT_PATH_SPRING_PROPERTY)).thenReturn("/final/output/path");    when(environment.getProperty(MetronRestConstants.PCAP_PAGE_SIZE_SPRING_PROPERTY)).thenReturn("100");    when(environment.getProperty(MetronRestConstants.PCAP_FINALIZER_THREADPOOL_SIZE_SPRING_PROPERTY)).thenReturn("2C");    when(environment.getProperty(MetronRestConstants.PCAP_PDML_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/path/to/pdml/script");    when(environment.getProperty(MetronRestConstants.USER_JOB_LIMIT_SPRING_PROPERTY, Integer.class, 1)).thenReturn(1);}
0
public void submitShouldProperlySubmitFixedPcapRequest() throws Exception
{    when(environment.containsProperty(MetronRestConstants.PCAP_YARN_QUEUE_SPRING_PROPERTY)).thenReturn(true);    when(environment.getProperty(MetronRestConstants.PCAP_YARN_QUEUE_SPRING_PROPERTY)).thenReturn("pcap");    FixedPcapRequest fixedPcapRequest = new FixedPcapRequest();    fixedPcapRequest.setBasePath("basePath");    fixedPcapRequest.setBaseInterimResultPath("baseOutputPath");    fixedPcapRequest.setFinalOutputPath("finalOutputPath");    fixedPcapRequest.setStartTimeMs(1L);    fixedPcapRequest.setEndTimeMs(2L);    fixedPcapRequest.setNumReducers(2);    fixedPcapRequest.setIpSrcAddr("ip_src_addr");    fixedPcapRequest.setIpDstAddr("ip_dst_addr");    fixedPcapRequest.setIpSrcPort(1000);    fixedPcapRequest.setIpDstPort(2000);    fixedPcapRequest.setProtocol("tcp");    fixedPcapRequest.setPacketFilter("filter");    fixedPcapRequest.setIncludeReverse(true);    MockPcapJob mockPcapJob = new MockPcapJob();    mockPcapJobSupplier.setMockPcapJob(mockPcapJob);    JobManager jobManager = new InMemoryJobManager<>();    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withDescription("description").withPercentComplete(0L).withState(JobStatus.State.RUNNING));    Map<String, String> expectedFields = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "ip_src_addr");            put(Constants.Fields.DST_ADDR.getName(), "ip_dst_addr");            put(Constants.Fields.SRC_PORT.getName(), "1000");            put(Constants.Fields.DST_PORT.getName(), "2000");            put(Constants.Fields.PROTOCOL.getName(), "tcp");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "true");            put(PcapHelper.PacketFields.PACKET_FILTER.getName(), "filter");        }    };    PcapStatus expectedPcapStatus = new PcapStatus();    expectedPcapStatus.setJobId("jobId");    expectedPcapStatus.setJobStatus(JobStatus.State.RUNNING.name());    expectedPcapStatus.setDescription("description");    Assert.assertEquals(expectedPcapStatus, pcapService.submit("user", fixedPcapRequest));    Assert.assertEquals(expectedPcapStatus, pcapService.jobStatusToPcapStatus(jobManager.getJob("user", "jobId").getStatus()));    Assert.assertEquals("basePath", mockPcapJob.getBasePath());    Assert.assertEquals("baseOutputPath", mockPcapJob.getBaseInterrimResultPath());    Assert.assertEquals("finalOutputPath", mockPcapJob.getFinalOutputPath());    Assert.assertEquals(1000000, mockPcapJob.getStartTimeNs());    Assert.assertEquals(2000000, mockPcapJob.getEndTimeNs());    Assert.assertEquals(2, mockPcapJob.getNumReducers());    Assert.assertEquals(100, mockPcapJob.getRecPerFile());    Assert.assertEquals("pcap", mockPcapJob.getYarnQueue());    Assert.assertEquals("2C", mockPcapJob.getFinalizerThreadpoolSize());    Assert.assertTrue(mockPcapJob.getFilterImpl() instanceof FixedPcapFilter.Configurator);    Map<String, String> actualFixedFields = mockPcapJob.getFixedFields();    Assert.assertEquals("ip_src_addr", actualFixedFields.get(Constants.Fields.SRC_ADDR.getName()));    Assert.assertEquals("1000", actualFixedFields.get(Constants.Fields.SRC_PORT.getName()));    Assert.assertEquals("ip_dst_addr", actualFixedFields.get(Constants.Fields.DST_ADDR.getName()));    Assert.assertEquals("2000", actualFixedFields.get(Constants.Fields.DST_PORT.getName()));    Assert.assertEquals("true", actualFixedFields.get(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName()));    Assert.assertEquals("tcp", actualFixedFields.get(Constants.Fields.PROTOCOL.getName()));    Assert.assertEquals("filter", actualFixedFields.get(PcapHelper.PacketFields.PACKET_FILTER.getName()));}
0
public void submitShouldProperlySubmitWithDefaults() throws Exception
{    long beforeJobTime = System.currentTimeMillis();    FixedPcapRequest fixedPcapRequest = new FixedPcapRequest();    MockPcapJob mockPcapJob = new MockPcapJob();    mockPcapJobSupplier.setMockPcapJob(mockPcapJob);    JobManager jobManager = new InMemoryJobManager<>();    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withDescription("description").withPercentComplete(0L).withState(JobStatus.State.RUNNING));    PcapStatus expectedPcapStatus = new PcapStatus();    expectedPcapStatus.setJobId("jobId");    expectedPcapStatus.setJobStatus(JobStatus.State.RUNNING.name());    expectedPcapStatus.setDescription("description");    Assert.assertEquals(expectedPcapStatus, pcapService.submit("user", fixedPcapRequest));    Assert.assertEquals("/base/path", mockPcapJob.getBasePath());    Assert.assertEquals("/base/interim/result/path", mockPcapJob.getBaseInterrimResultPath());    Assert.assertEquals("/final/output/path", mockPcapJob.getFinalOutputPath());    Assert.assertEquals(0, mockPcapJob.getStartTimeNs());    Assert.assertTrue(beforeJobTime <= mockPcapJob.getEndTimeNs() / 1000000);    Assert.assertTrue(System.currentTimeMillis() >= mockPcapJob.getEndTimeNs() / 1000000);    Assert.assertEquals(10, mockPcapJob.getNumReducers());    Assert.assertEquals(100, mockPcapJob.getRecPerFile());    Assert.assertTrue(mockPcapJob.getFilterImpl() instanceof FixedPcapFilter.Configurator);    Assert.assertEquals(new HashMap<>(), mockPcapJob.getFixedFields());}
0
public void submitShouldProperlySubmitQueryPcapRequest() throws Exception
{    QueryPcapRequest queryPcapRequest = new QueryPcapRequest();    queryPcapRequest.setBasePath("basePath");    queryPcapRequest.setBaseInterimResultPath("baseOutputPath");    queryPcapRequest.setFinalOutputPath("finalOutputPath");    queryPcapRequest.setStartTimeMs(1L);    queryPcapRequest.setEndTimeMs(2L);    queryPcapRequest.setNumReducers(2);    queryPcapRequest.setQuery("query");    MockPcapJob mockPcapJob = new MockPcapJob();    mockPcapJobSupplier.setMockPcapJob(mockPcapJob);    JobManager jobManager = new InMemoryJobManager<>();    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    mockPcapJob.setStatus(new JobStatus().withJobId("jobId").withDescription("description").withPercentComplete(0L).withState(JobStatus.State.RUNNING));    String expectedFields = "query";    PcapStatus expectedPcapStatus = new PcapStatus();    expectedPcapStatus.setJobId("jobId");    expectedPcapStatus.setJobStatus(JobStatus.State.RUNNING.name());    expectedPcapStatus.setDescription("description");    Assert.assertEquals(expectedPcapStatus, pcapService.submit("user", queryPcapRequest));    Assert.assertEquals(expectedPcapStatus, pcapService.jobStatusToPcapStatus(jobManager.getJob("user", "jobId").getStatus()));    Assert.assertEquals("basePath", mockPcapJob.getBasePath());    Assert.assertEquals("baseOutputPath", mockPcapJob.getBaseInterrimResultPath());    Assert.assertEquals("finalOutputPath", mockPcapJob.getFinalOutputPath());    Assert.assertEquals(1000000, mockPcapJob.getStartTimeNs());    Assert.assertEquals(2000000, mockPcapJob.getEndTimeNs());    Assert.assertEquals(2, mockPcapJob.getNumReducers());    Assert.assertEquals(100, mockPcapJob.getRecPerFile());    Assert.assertTrue(mockPcapJob.getFilterImpl() instanceof QueryPcapFilter.Configurator);    Map<String, String> actualFixedFields = mockPcapJob.getFixedFields();    Assert.assertEquals("query", mockPcapJob.getQuery());}
0
public void submitShouldThrowExceptionOnRunningJobFound() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("Cannot submit job because a job is already running.  Please contact the administrator to cancel job(s) with id(s) jobId");    PcapStatus runningStatus1 = new PcapStatus();    runningStatus1.setJobStatus("RUNNING");    runningStatus1.setJobId("jobId1");    PcapStatus runningStatus2 = new PcapStatus();    runningStatus2.setJobStatus("RUNNING");    runningStatus2.setJobId("jobId2");    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, new InMemoryJobManager<>(), pcapToPdmlScriptWrapper));    doReturn(Arrays.asList(runningStatus1, runningStatus2)).when(pcapService).getJobStatus("user", JobStatus.State.RUNNING);    when(environment.getProperty(MetronRestConstants.USER_JOB_LIMIT_SPRING_PROPERTY, Integer.class, 1)).thenReturn(2);    pcapService.submit("user", new FixedPcapRequest());}
0
public void fixedShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("some job exception");    FixedPcapRequest fixedPcapRequest = new FixedPcapRequest();    JobManager jobManager = mock(JobManager.class);    PcapJobSupplier pcapJobSupplier = new PcapJobSupplier();    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, pcapJobSupplier, jobManager, pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    when(jobManager.submit(pcapJobSupplier, "user")).thenThrow(new JobException("some job exception"));    pcapService.submit("user", fixedPcapRequest);}
0
public void getStatusShouldProperlyReturnStatus() throws Exception
{    MockPcapJob mockPcapJob = mock(MockPcapJob.class);    JobManager jobManager = mock(JobManager.class);    JobStatus actualJobStatus = new JobStatus().withJobId("jobId").withState(JobStatus.State.SUCCEEDED).withDescription("description").withPercentComplete(100.0);    Pageable pageable = mock(Pageable.class);    when(pageable.getSize()).thenReturn(2);    when(mockPcapJob.getStatus()).thenReturn(actualJobStatus);    when(mockPcapJob.isDone()).thenReturn(true);    when(mockPcapJob.get()).thenReturn(pageable);    when(jobManager.getJob("user", "jobId")).thenReturn(mockPcapJob);    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper);    PcapStatus expectedPcapStatus = new PcapStatus();    expectedPcapStatus.setJobId("jobId");    expectedPcapStatus.setJobStatus(JobStatus.State.SUCCEEDED.name());    expectedPcapStatus.setDescription("description");    expectedPcapStatus.setPercentComplete(100.0);    expectedPcapStatus.setPageTotal(2);    Assert.assertEquals(expectedPcapStatus, pcapService.getJobStatus("user", "jobId"));}
0
public void getStatusShouldReturnNullOnMissingStatus() throws Exception
{    JobManager jobManager = new InMemoryJobManager();    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), jobManager, pcapToPdmlScriptWrapper);    Assert.assertNull(pcapService.getJobStatus("user", "jobId"));}
0
public void getStatusShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("some job exception");    JobManager jobManager = mock(JobManager.class);    when(jobManager.getJob("user", "jobId")).thenThrow(new JobException("some job exception"));    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), jobManager, pcapToPdmlScriptWrapper);    pcapService.getJobStatus("user", "jobId");}
0
public void getStatusForStateShouldProperlyReturnJobs() throws Exception
{    MockPcapJob mockPcapJob = mock(MockPcapJob.class);    JobManager jobManager = mock(JobManager.class);    Statusable<Path> runningJob = mock(Statusable.class);    JobStatus runningStatus = mock(JobStatus.class);    when(runningStatus.getJobId()).thenReturn("runningJob");    when(runningStatus.getState()).thenReturn(JobStatus.State.RUNNING);    when(runningJob.getStatus()).thenReturn(runningStatus);    Statusable<Path> failedJob = mock(Statusable.class);    when(failedJob.getStatus()).thenThrow(new JobException("job exception"));    Statusable<Path> succeededJob = mock(Statusable.class);    JobStatus succeededStatus = mock(JobStatus.class);    when(succeededStatus.getJobId()).thenReturn("succeededJob");    when(succeededStatus.getState()).thenReturn(JobStatus.State.SUCCEEDED);    when(succeededJob.isDone()).thenReturn(true);    when(succeededJob.getStatus()).thenReturn(succeededStatus);    Pageable<Path> succeededPageable = mock(Pageable.class);    when(succeededPageable.getSize()).thenReturn(5);    when(succeededJob.get()).thenReturn(succeededPageable);    when(jobManager.getJobs("user")).thenReturn(Arrays.asList(runningJob, failedJob, succeededJob));    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper);    PcapStatus expectedRunningPcapStatus = new PcapStatus();    expectedRunningPcapStatus.setJobId("runningJob");    expectedRunningPcapStatus.setJobStatus(JobStatus.State.RUNNING.name());    Assert.assertEquals(expectedRunningPcapStatus, pcapService.getJobStatus("user", JobStatus.State.RUNNING).get(0));    PcapStatus expectedFailedPcapStatus = new PcapStatus();    expectedFailedPcapStatus.setJobStatus(JobStatus.State.FAILED.name());    expectedFailedPcapStatus.setDescription("job exception");    Assert.assertEquals(expectedFailedPcapStatus, pcapService.getJobStatus("user", JobStatus.State.FAILED).get(0));    PcapStatus expectedSucceededPcapStatus = new PcapStatus();    expectedSucceededPcapStatus.setJobId("succeededJob");    expectedSucceededPcapStatus.setJobStatus(JobStatus.State.SUCCEEDED.name());    expectedSucceededPcapStatus.setPageTotal(5);    Assert.assertEquals(expectedSucceededPcapStatus, pcapService.getJobStatus("user", JobStatus.State.SUCCEEDED).get(0));}
0
public void killJobShouldKillJobAndReportStatus() throws Exception
{    MockPcapJob mockPcapJob = mock(MockPcapJob.class);    JobManager jobManager = mock(JobManager.class);    JobStatus actualJobStatus = new JobStatus().withJobId("jobId").withState(JobStatus.State.KILLED).withDescription("description").withPercentComplete(100.0);    Pageable pageable = mock(Pageable.class);    when(pageable.getSize()).thenReturn(0);    when(mockPcapJob.getStatus()).thenReturn(actualJobStatus);    when(mockPcapJob.isDone()).thenReturn(true);    when(mockPcapJob.get()).thenReturn(pageable);    when(jobManager.getJob("user", "jobId")).thenReturn(mockPcapJob);    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper);    PcapStatus status = pcapService.killJob("user", "jobId");    verify(jobManager, times(1)).killJob("user", "jobId");    assertThat(status.getJobStatus(), CoreMatchers.equalTo(JobStatus.State.KILLED.toString()));}
0
public void killNonExistentJobShouldReturnNull() throws Exception
{    MockPcapJob mockPcapJob = mock(MockPcapJob.class);    JobManager jobManager = mock(JobManager.class);    doThrow(new JobNotFoundException("Not found test exception.")).when(jobManager).killJob("user", "jobId");    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper);    PcapStatus status = pcapService.killJob("user", "jobId");    verify(jobManager, times(1)).killJob("user", "jobId");    assertNull(status);}
0
public void getPathShouldProperlyReturnPath() throws Exception
{    Path actualPath = new Path("/path");    MockPcapJob mockPcapJob = mock(MockPcapJob.class);    JobManager jobManager = mock(JobManager.class);    Pageable pageable = mock(Pageable.class);    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), jobManager, pcapToPdmlScriptWrapper);    when(pageable.getSize()).thenReturn(2);    when(mockPcapJob.isDone()).thenReturn(true);    when(mockPcapJob.get()).thenReturn(pageable);    when(pageable.getPage(0)).thenReturn(actualPath);    when(jobManager.getJob("user", "jobId")).thenReturn(mockPcapJob);    Assert.assertEquals("/path", pcapService.getPath("user", "jobId", 1).toUri().getPath());}
0
public void getPathShouldReturnNullOnInvalidPageSize() throws Exception
{    MockPcapJob mockPcapJob = mock(MockPcapJob.class);    JobManager jobManager = mock(JobManager.class);    Pageable pageable = mock(Pageable.class);    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), jobManager, pcapToPdmlScriptWrapper);    when(pageable.getSize()).thenReturn(2);    when(mockPcapJob.isDone()).thenReturn(true);    when(mockPcapJob.get()).thenReturn(pageable);    when(jobManager.getJob("user", "jobId")).thenReturn(mockPcapJob);    Assert.assertNull(pcapService.getPath("user", "jobId", 0));    Assert.assertNull(pcapService.getPath("user", "jobId", 3));}
0
public void getPdmlShouldGetPdml() throws Exception
{    Path path = new Path("./target");    PcapToPdmlScriptWrapper pcapToPdmlScriptWrapper = spy(new PcapToPdmlScriptWrapper());    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), new InMemoryJobManager<>(), pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    when(fileSystem.exists(path)).thenReturn(true);    doReturn(path).when(pcapService).getPath("user", "jobId", 1);    doReturn(new ByteArrayInputStream(pdmlXml.getBytes(StandardCharsets.UTF_8))).when(pcapToPdmlScriptWrapper).getRawInputStream(fileSystem, path);    ProcessBuilder pb = PowerMockito.mock(ProcessBuilder.class);    Process p = PowerMockito.mock(Process.class);    OutputStream outputStream = new ByteArrayOutputStream();    when(p.getOutputStream()).thenReturn(outputStream);    when(p.isAlive()).thenReturn(true);    when(p.getInputStream()).thenReturn(new ByteArrayInputStream(pdmlXml.getBytes(StandardCharsets.UTF_8)));    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(pb);    PowerMockito.when(pb.start()).thenReturn(p);    assertEquals(JSONUtils.INSTANCE.load(expectedPdml, Pdml.class), pcapService.getPdml("user", "jobId", 1));}
0
public void getPdmlShouldReturnNullOnNonexistentPath() throws Exception
{    Path path = new Path("/some/path");    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), new InMemoryJobManager<>(), pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    when(fileSystem.exists(path)).thenReturn(false);    doReturn(path).when(pcapService).getPath("user", "jobId", 1);    assertNull(pcapService.getPdml("user", "jobId", 1));}
0
public void getPdmlShouldThrowException() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("some exception");    Path path = new Path("./target");    PcapToPdmlScriptWrapper pcapToPdmlScriptWrapper = spy(new PcapToPdmlScriptWrapper());    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), new InMemoryJobManager<>(), pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    when(fileSystem.exists(path)).thenReturn(true);    doReturn(path).when(pcapService).getPath("user", "jobId", 1);    ProcessBuilder pb = PowerMockito.mock(ProcessBuilder.class);    doReturn(pb).when(pcapToPdmlScriptWrapper).getProcessBuilder("/path/to/pdml/script", "target");    PowerMockito.when(pb.start()).thenThrow(new IOException("some exception"));    pcapService.getPdml("user", "jobId", 1);}
0
public void getRawShouldProperlyReturnInputStream() throws Exception
{    FSDataInputStream inputStream = mock(FSDataInputStream.class);    Path path = new Path("./target");    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), new InMemoryJobManager<>(), new PcapToPdmlScriptWrapper()));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    when(fileSystem.exists(path)).thenReturn(true);    doReturn(path).when(pcapService).getPath("user", "jobId", 1);    when(fileSystem.open(path)).thenReturn(inputStream);    Assert.assertEquals(inputStream, pcapService.getRawPcap("user", "jobId", 1));}
0
public void getRawShouldReturnNullOnInvalidPage() throws Exception
{    Path path = new Path("/some/path");    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), new InMemoryJobManager<>(), pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    assertNull(pcapService.getRawPcap("user", "jobId", 1));}
0
public void getRawShouldReturnNullOnNonexistentPath() throws Exception
{    Path path = new Path("/some/path");    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), new InMemoryJobManager<>(), pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    when(fileSystem.exists(path)).thenReturn(false);    doReturn(path).when(pcapService).getPath("user", "jobId", 1);    assertNull(pcapService.getRawPcap("user", "jobId", 1));}
0
public void getRawShouldThrowException() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("some exception");    Path path = new Path("./target");    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), new InMemoryJobManager<>(), pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    when(fileSystem.exists(path)).thenReturn(true);    doReturn(path).when(pcapService).getPath("user", "jobId", 1);    when(fileSystem.open(path)).thenThrow(new IOException("some exception"));    pcapService.getRawPcap("user", "jobId", 1);}
0
public void getConfigurationShouldProperlyReturnFixedFilterConfiguration() throws Exception
{    FixedPcapRequest fixedPcapRequest = new FixedPcapRequest();    fixedPcapRequest.setBasePath("basePath");    fixedPcapRequest.setBaseInterimResultPath("baseOutputPath");    fixedPcapRequest.setFinalOutputPath("finalOutputPath");    fixedPcapRequest.setStartTimeMs(1L);    fixedPcapRequest.setEndTimeMs(2L);    fixedPcapRequest.setNumReducers(2);    fixedPcapRequest.setIpSrcAddr("ip_src_addr");    fixedPcapRequest.setIpDstAddr("ip_dst_addr");    fixedPcapRequest.setIpSrcPort(1000);    fixedPcapRequest.setIpDstPort(2000);    fixedPcapRequest.setProtocol("tcp");    fixedPcapRequest.setPacketFilter("filter");    fixedPcapRequest.setIncludeReverse(true);    MockPcapJob mockPcapJob = new MockPcapJob();    mockPcapJobSupplier.setMockPcapJob(mockPcapJob);    JobManager jobManager = new InMemoryJobManager<>();    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    mockPcapJob.setStatus(new JobStatus().withJobId("jobId"));    pcapService.submit("user", fixedPcapRequest);    Map<String, Object> configuration = pcapService.getConfiguration("user", "jobId");    Assert.assertEquals("basePath", configuration.get(PcapOptions.BASE_PATH.getKey()));    Assert.assertEquals("finalOutputPath", configuration.get(PcapOptions.FINAL_OUTPUT_PATH.getKey()));    Assert.assertEquals(1L, configuration.get(PcapOptions.START_TIME_MS.getKey()));    Assert.assertEquals(2L, configuration.get(PcapOptions.END_TIME_MS.getKey()));    Assert.assertEquals(2, configuration.get(PcapOptions.NUM_REDUCERS.getKey()));    Assert.assertEquals("ip_src_addr", configuration.get(FixedPcapOptions.IP_SRC_ADDR.getKey()));    Assert.assertEquals("ip_dst_addr", configuration.get(FixedPcapOptions.IP_DST_ADDR.getKey()));    Assert.assertEquals(1000, configuration.get(FixedPcapOptions.IP_SRC_PORT.getKey()));    Assert.assertEquals(2000, configuration.get(FixedPcapOptions.IP_DST_PORT.getKey()));    Assert.assertEquals("tcp", configuration.get(FixedPcapOptions.PROTOCOL.getKey()));    Assert.assertEquals("filter", configuration.get(FixedPcapOptions.PACKET_FILTER.getKey()));    Assert.assertEquals(true, configuration.get(FixedPcapOptions.INCLUDE_REVERSE.getKey()));}
0
public void getConfigurationShouldProperlyReturnQueryFilterConfiguration() throws Exception
{    QueryPcapRequest queryPcapRequest = new QueryPcapRequest();    queryPcapRequest.setBasePath("basePath");    queryPcapRequest.setBaseInterimResultPath("baseOutputPath");    queryPcapRequest.setFinalOutputPath("finalOutputPath");    queryPcapRequest.setStartTimeMs(1L);    queryPcapRequest.setEndTimeMs(2L);    queryPcapRequest.setNumReducers(2);    queryPcapRequest.setQuery("query");    MockPcapJob mockPcapJob = new MockPcapJob();    mockPcapJobSupplier.setMockPcapJob(mockPcapJob);    JobManager jobManager = new InMemoryJobManager<>();    PcapServiceImpl pcapService = spy(new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper));    FileSystem fileSystem = mock(FileSystem.class);    doReturn(fileSystem).when(pcapService).getFileSystem();    mockPcapJob.setStatus(new JobStatus().withJobId("jobId"));    pcapService.submit("user", queryPcapRequest);    Map<String, Object> configuration = pcapService.getConfiguration("user", "jobId");    Assert.assertEquals("basePath", configuration.get(PcapOptions.BASE_PATH.getKey()));    Assert.assertEquals("finalOutputPath", configuration.get(PcapOptions.FINAL_OUTPUT_PATH.getKey()));    Assert.assertEquals(1L, configuration.get(PcapOptions.START_TIME_MS.getKey()));    Assert.assertEquals(2L, configuration.get(PcapOptions.END_TIME_MS.getKey()));    Assert.assertEquals(2, configuration.get(PcapOptions.NUM_REDUCERS.getKey()));    Assert.assertEquals("query", configuration.get(QueryPcapOptions.QUERY.getKey()));}
0
public void getConfigurationShouldReturnEmptyMapOnMissingJob() throws Exception
{    MockPcapJob mockPcapJob = mock(MockPcapJob.class);    JobManager jobManager = mock(JobManager.class);    doThrow(new JobNotFoundException("Not found test exception.")).when(jobManager).getJob("user", "jobId");    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, mockPcapJobSupplier, jobManager, pcapToPdmlScriptWrapper);    Map<String, Object> configuration = pcapService.getConfiguration("user", "jobId");    Assert.assertEquals(new HashMap<>(), configuration);}
0
public void getConfigurationShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("some job exception");    JobManager jobManager = mock(JobManager.class);    when(jobManager.getJob("user", "jobId")).thenThrow(new JobException("some job exception"));    PcapServiceImpl pcapService = new PcapServiceImpl(environment, configuration, new PcapJobSupplier(), jobManager, pcapToPdmlScriptWrapper);    pcapService.getConfiguration("user", "jobId");}
0
public void setUp() throws Exception
{    dao = mock(IndexDao.class);    environment = mock(Environment.class);    sensorIndexingConfigService = mock(SensorIndexingConfigService.class);    globalConfigService = mock(GlobalConfigService.class);    alertsUIService = mock(AlertsUIService.class);    searchService = new SearchServiceImpl(dao, environment, sensorIndexingConfigService, globalConfigService, alertsUIService);}
0
public void searchShouldProperlySearchDefaultIndices() throws Exception
{    when(environment.getProperty(INDEX_WRITER_NAME)).thenReturn("elasticsearch");    when(sensorIndexingConfigService.getAllIndices("elasticsearch")).thenReturn(Arrays.asList("bro", "snort", "error"));    SearchRequest searchRequest = new SearchRequest();    searchService.search(searchRequest);    SearchRequest expectedSearchRequest = new SearchRequest();    expectedSearchRequest.setIndices(Arrays.asList("bro", "snort", "metaalert"));    verify(dao).search(eq(expectedSearchRequest));    verifyNoMoreInteractions(dao);}
0
public void searchShouldProperlySearchWithEmptyDefaultFacetFields() throws Exception
{    when(environment.getProperty(SEARCH_FACET_FIELDS_SPRING_PROPERTY, String.class, "")).thenReturn("");    SearchRequest searchRequest = new SearchRequest();    searchRequest.setIndices(Arrays.asList("bro", "snort", "metaalert"));    searchService.search(searchRequest);    SearchRequest expectedSearchRequest = new SearchRequest();    expectedSearchRequest.setIndices(Arrays.asList("bro", "snort", "metaalert"));    verify(dao).search(eq(expectedSearchRequest));}
0
public void searchShouldProperlySearchDefaultFacetFields() throws Exception
{    when(environment.getProperty(SEARCH_FACET_FIELDS_SPRING_PROPERTY, String.class, "")).thenReturn("ip_src_addr,ip_dst_addr");    when(alertsUIService.getAlertsUIUserSettings()).thenReturn(Optional.empty());    SearchRequest searchRequest = new SearchRequest();    searchRequest.setIndices(Arrays.asList("bro", "snort", "metaalert"));    searchRequest.setFacetFields(new ArrayList<>());    searchService.search(searchRequest);    SearchRequest expectedSearchRequest = new SearchRequest();    expectedSearchRequest.setIndices(Arrays.asList("bro", "snort", "metaalert"));    expectedSearchRequest.setFacetFields(Arrays.asList("source:type", "ip_src_addr", "ip_dst_addr"));    verify(dao).search(eq(expectedSearchRequest));}
0
public void searchShouldProperlySearchWithUserSettingsFacetFields() throws Exception
{    AlertsUIUserSettings alertsUIUserSettings = new AlertsUIUserSettings();    alertsUIUserSettings.setFacetFields(Arrays.asList("ip_src_addr", "ip_dst_addr"));    when(alertsUIService.getAlertsUIUserSettings()).thenReturn(Optional.of(alertsUIUserSettings));    SearchRequest searchRequest = new SearchRequest();    searchRequest.setIndices(Arrays.asList("bro", "snort", "metaalert"));    searchRequest.setFacetFields(new ArrayList<>());    searchService.search(searchRequest);    SearchRequest expectedSearchRequest = new SearchRequest();    expectedSearchRequest.setIndices(Arrays.asList("bro", "snort", "metaalert"));    expectedSearchRequest.setFacetFields(Arrays.asList("ip_src_addr", "ip_dst_addr"));    verify(dao).search(eq(expectedSearchRequest));}
0
public void searchShouldProperlySearch() throws Exception
{    SearchRequest searchRequest = new SearchRequest();    searchRequest.setIndices(Arrays.asList("bro"));    searchRequest.setFacetFields(Arrays.asList("ip_src_addr"));    searchService.search(searchRequest);    SearchRequest expectedSearchRequest = new SearchRequest();    expectedSearchRequest.setIndices(Arrays.asList("bro"));    expectedSearchRequest.setFacetFields(Arrays.asList("ip_src_addr"));    verify(dao).search(eq(expectedSearchRequest));    verifyNoMoreInteractions(dao);}
0
public void saveShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    when(dao.search(any(SearchRequest.class))).thenThrow(InvalidSearchException.class);    SearchRequest searchRequest = new SearchRequest();    searchRequest.setIndices(Arrays.asList("bro"));    searchRequest.setFacetFields(Arrays.asList("ip_src_addr"));    searchService.search(searchRequest);}
0
public void getColumnMetadataShouldProperlyGetDefaultIndices() throws Exception
{    when(environment.getProperty(INDEX_WRITER_NAME)).thenReturn("elasticsearch");    when(sensorIndexingConfigService.getAllIndices("elasticsearch")).thenReturn(Arrays.asList("bro", "snort", "error"));    searchService.getColumnMetadata(new ArrayList<>());    verify(dao).getColumnMetadata(eq(Arrays.asList("bro", "snort", "metaalert")));    verifyNoMoreInteractions(dao);}
0
public void testGetDefaultFacetFieldsGlobalConfig() throws RestException
{    when(environment.getProperty(SEARCH_FACET_FIELDS_SPRING_PROPERTY, String.class, "")).thenReturn("ip_src_addr");    Map<String, Object> globalConfig = new HashMap<>();    globalConfig.put(SENSOR_TYPE_FIELD_PROPERTY, "source.type");    when(globalConfigService.get()).thenReturn(globalConfig);    when(alertsUIService.getAlertsUIUserSettings()).thenReturn(Optional.empty());    List<String> defaultFields = searchService.getDefaultFacetFields();    List<String> expectedFields = new ArrayList<>();    expectedFields.add("source.type");    expectedFields.add("ip_src_addr");    assertEquals(expectedFields, defaultFields);}
0
public void testGetDefaultFacetFieldsEmptyGlobalConfig() throws RestException
{    when(environment.getProperty(SEARCH_FACET_FIELDS_SPRING_PROPERTY, String.class, "")).thenReturn("ip_src_addr");    Map<String, Object> globalConfig = new HashMap<>();    when(globalConfigService.get()).thenReturn(globalConfig);    when(alertsUIService.getAlertsUIUserSettings()).thenReturn(Optional.empty());    List<String> defaultFields = searchService.getDefaultFacetFields();    List<String> expectedFields = new ArrayList<>();    expectedFields.add("source:type");    expectedFields.add("ip_src_addr");    assertEquals(expectedFields, defaultFields);}
0
public void setUp() throws Exception
{    objectMapper = mock(ObjectMapper.class);    curatorFramework = mock(CuratorFramework.class);    cache = mock(ConfigurationsCache.class);    hBaseClient = mock(HBaseClient.class);    sensorEnrichmentConfigService = new SensorEnrichmentConfigServiceImpl(objectMapper, curatorFramework, cache, hBaseClient);}
0
public void deleteShouldProperlyCatchNoNodeExceptionAndReturnFalse() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/bro")).thenThrow(KeeperException.NoNodeException.class);    assertFalse(sensorEnrichmentConfigService.delete("bro"));}
0
public void deleteShouldProperlyCatchNonNoNodeExceptionAndThrowRestException() throws Exception
{    exception.expect(RestException.class);    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/bro")).thenThrow(Exception.class);    assertFalse(sensorEnrichmentConfigService.delete("bro"));}
0
public void deleteShouldReturnTrueWhenClientSuccessfullyCallsDelete() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/bro")).thenReturn(null);    assertTrue(sensorEnrichmentConfigService.delete("bro"));    verify(curatorFramework).delete();}
0
public void findOneShouldProperlyReturnSensorEnrichmentConfig() throws Exception
{    final SensorEnrichmentConfig sensorEnrichmentConfig = getTestSensorEnrichmentConfig();    EnrichmentConfigurations configs = new EnrichmentConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(EnrichmentConfigurations.getKey("bro"), sensorEnrichmentConfig);        }    };    when(cache.get(eq(EnrichmentConfigurations.class))).thenReturn(configs);        assertEquals(getTestSensorEnrichmentConfig(), sensorEnrichmentConfigService.findOne("bro"));        assertNull(sensorEnrichmentConfigService.findOne("blah"));}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(EnrichmentConfigurations.getKey("bro"), sensorEnrichmentConfig);}
0
public void getAllTypesShouldProperlyReturnTypes() throws Exception
{    EnrichmentConfigurations configs = new EnrichmentConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(EnrichmentConfigurations.getKey("bro"), new HashMap<>(), EnrichmentConfigurations.getKey("squid"), new HashMap<>());        }    };    when(cache.get(eq(EnrichmentConfigurations.class))).thenReturn(configs);    assertEquals(new ArrayList() {        {            add("bro");            add("squid");        }    }, sensorEnrichmentConfigService.getAllTypes());}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(EnrichmentConfigurations.getKey("bro"), new HashMap<>(), EnrichmentConfigurations.getKey("squid"), new HashMap<>());}
0
public void getAllShouldProperlyReturnSensorEnrichmentConfigs() throws Exception
{    final SensorEnrichmentConfig sensorEnrichmentConfig = getTestSensorEnrichmentConfig();    EnrichmentConfigurations configs = new EnrichmentConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(EnrichmentConfigurations.getKey("bro"), sensorEnrichmentConfig);        }    };    when(cache.get(eq(EnrichmentConfigurations.class))).thenReturn(configs);    assertEquals(new HashMap() {        {            put("bro", sensorEnrichmentConfig);        }    }, sensorEnrichmentConfigService.getAll());}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(EnrichmentConfigurations.getKey("bro"), sensorEnrichmentConfig);}
0
public void saveShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/bro", broJson.getBytes(StandardCharsets.UTF_8))).thenThrow(Exception.class);    when(curatorFramework.setData()).thenReturn(setDataBuilder);    sensorEnrichmentConfigService.save("bro", new SensorEnrichmentConfig());}
0
public void saveShouldReturnSameConfigThatIsPassedOnSuccessfulSave() throws Exception
{    final SensorEnrichmentConfig sensorEnrichmentConfig = getTestSensorEnrichmentConfig();    when(objectMapper.writeValueAsString(sensorEnrichmentConfig)).thenReturn(broJson);    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/bro", broJson.getBytes(StandardCharsets.UTF_8))).thenReturn(new Stat());    when(curatorFramework.setData()).thenReturn(setDataBuilder);    assertEquals(sensorEnrichmentConfig, sensorEnrichmentConfigService.save("bro", sensorEnrichmentConfig));    verify(setDataBuilder).forPath(eq(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/bro"), eq(broJson.getBytes(StandardCharsets.UTF_8)));}
0
public void getAvailableEnrichmentsShouldReturnEnrichmentsSorted() throws Exception
{    when(hBaseClient.readRecords()).thenReturn(new ArrayList<String>() {        {            add("geo");            add("whois");            add("host");            add("a-new-one");        }    });    assertEquals(new ArrayList<String>() {        {            add("a-new-one");            add("geo");            add("host");            add("whois");        }    }, sensorEnrichmentConfigService.getAvailableEnrichments());}
0
public void getAvailableThreatTriageAggregatorsShouldReturnAggregators() throws Exception
{    assertEquals(new ArrayList<String>() {        {            add("MAX");            add("MIN");            add("SUM");            add("MEAN");            add("POSITIVE_MEAN");        }    }, sensorEnrichmentConfigService.getAvailableThreatTriageAggregators());}
0
private SensorEnrichmentConfig getTestSensorEnrichmentConfig()
{    SensorEnrichmentConfig sensorEnrichmentConfig = new SensorEnrichmentConfig();    EnrichmentConfig enrichmentConfig = new EnrichmentConfig();    enrichmentConfig.setFieldMap(new HashMap() {        {            put("geo", Arrays.asList("ip_dst_addr"));        }    });    sensorEnrichmentConfig.setEnrichment(enrichmentConfig);    ThreatIntelConfig threatIntelConfig = new ThreatIntelConfig();    threatIntelConfig.setFieldMap(new HashMap() {        {            put("hbaseThreatIntel", Arrays.asList("ip_src_addr"));        }    });    threatIntelConfig.setFieldToTypeMap(new HashMap() {        {            put("ip_src_addr", Arrays.asList("malicious_ip"));        }    });    sensorEnrichmentConfig.setThreatIntel(threatIntelConfig);    return sensorEnrichmentConfig;}
0
public void setUp() throws Exception
{    objectMapper = mock(ObjectMapper.class);    curatorFramework = mock(CuratorFramework.class);    cache = mock(ConfigurationsCache.class);    sensorIndexingConfigService = new SensorIndexingConfigServiceImpl(objectMapper, curatorFramework, cache);}
0
public void deleteShouldProperlyCatchNoNodeExceptionAndReturnFalse() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.INDEXING.getZookeeperRoot() + "/bro")).thenThrow(KeeperException.NoNodeException.class);    assertFalse(sensorIndexingConfigService.delete("bro"));}
0
public void deleteShouldProperlyCatchNonNoNodeExceptionAndThrowRestException() throws Exception
{    exception.expect(RestException.class);    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.INDEXING.getZookeeperRoot() + "/bro")).thenThrow(Exception.class);    assertFalse(sensorIndexingConfigService.delete("bro"));}
0
public void deleteShouldReturnTrueWhenClientSuccessfullyCallsDelete() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.INDEXING.getZookeeperRoot() + "/bro")).thenReturn(null);    assertTrue(sensorIndexingConfigService.delete("bro"));    verify(curatorFramework).delete();}
0
public void findOneShouldProperlyReturnSensorEnrichmentConfig() throws Exception
{    final Map<String, Object> sensorIndexingConfig = getTestSensorIndexingConfig();    IndexingConfigurations configs = new IndexingConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(IndexingConfigurations.getKey("bro"), sensorIndexingConfig);        }    };    when(cache.get(eq(IndexingConfigurations.class))).thenReturn(configs);        assertEquals(getTestSensorIndexingConfig(), sensorIndexingConfigService.findOne("bro"));        assertNull(sensorIndexingConfigService.findOne("blah"));}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(IndexingConfigurations.getKey("bro"), sensorIndexingConfig);}
0
public void getAllIndicesWithOnlyParsers() throws RestException
{    ParserConfigurations parserConfiguration = mock(ParserConfigurations.class);    when(parserConfiguration.getTypes()).thenReturn(ImmutableList.of("bro", "snort"));    IndexingConfigurations indexingConfiguration = mock(IndexingConfigurations.class);    when(indexingConfiguration.getTypes()).thenReturn(Collections.emptyList());    when(indexingConfiguration.getIndex(eq("bro"), eq("elasticsearch"))).thenReturn(null);    when(indexingConfiguration.getIndex(eq("snort"), eq("elasticsearch"))).thenReturn(null);    when(indexingConfiguration.isEnabled(eq("snort"), eq("elasticsearch"))).thenReturn(true);    when(indexingConfiguration.isEnabled(eq("bro"), eq("elasticsearch"))).thenReturn(true);    when(cache.get(eq(ParserConfigurations.class))).thenReturn(parserConfiguration);    when(cache.get(eq(IndexingConfigurations.class))).thenReturn(indexingConfiguration);    List<String> indices = new ArrayList<String>();    Iterables.addAll(indices, sensorIndexingConfigService.getAllIndices("elasticsearch"));    Assert.assertEquals(2, indices.size());    Assert.assertTrue(indices.contains("bro"));    Assert.assertTrue(indices.contains("snort"));}
0
public void getAllIndicesWithOnlyIndexing() throws RestException
{    ParserConfigurations parserConfiguration = mock(ParserConfigurations.class);    when(parserConfiguration.getTypes()).thenReturn(Collections.emptyList());    IndexingConfigurations indexingConfiguration = mock(IndexingConfigurations.class);        when(indexingConfiguration.getTypes()).thenReturn(ImmutableList.of("bro", "snort", "yaf"));    when(indexingConfiguration.getIndex(eq("bro"), eq("elasticsearch"))).thenReturn("renamed_bro");    when(indexingConfiguration.getIndex(eq("snort"), eq("elasticsearch"))).thenReturn(null);    when(indexingConfiguration.isEnabled(eq("snort"), eq("elasticsearch"))).thenReturn(true);    when(indexingConfiguration.isEnabled(eq("bro"), eq("elasticsearch"))).thenReturn(true);    when(indexingConfiguration.isEnabled(eq("yaf"), eq("elasticsearch"))).thenReturn(false);    when(cache.get(eq(ParserConfigurations.class))).thenReturn(parserConfiguration);    when(cache.get(eq(IndexingConfigurations.class))).thenReturn(indexingConfiguration);    List<String> indices = new ArrayList<String>();    Iterables.addAll(indices, sensorIndexingConfigService.getAllIndices("elasticsearch"));    Assert.assertEquals(2, indices.size());    Assert.assertTrue(indices.contains("renamed_bro"));    Assert.assertTrue(indices.contains("snort"));}
0
public void getAllIndicesWithParsersAndIndexConfigs() throws RestException
{    ParserConfigurations parserConfiguration = mock(ParserConfigurations.class);    when(parserConfiguration.getTypes()).thenReturn(ImmutableList.of("bro", "yaf"));    IndexingConfigurations indexingConfiguration = mock(IndexingConfigurations.class);    when(indexingConfiguration.getTypes()).thenReturn(ImmutableList.of("bro", "snort", "squid"));    when(indexingConfiguration.getIndex(eq("bro"), eq("elasticsearch"))).thenReturn("renamed_bro");    when(indexingConfiguration.getIndex(eq("snort"), eq("elasticsearch"))).thenReturn("snort");    when(indexingConfiguration.getIndex(eq("yaf"), eq("elasticsearch"))).thenReturn(null);    when(indexingConfiguration.isEnabled(eq("snort"), eq("elasticsearch"))).thenReturn(true);    when(indexingConfiguration.isEnabled(eq("bro"), eq("elasticsearch"))).thenReturn(true);    when(indexingConfiguration.isEnabled(eq("yaf"), eq("elasticsearch"))).thenReturn(true);    when(indexingConfiguration.isEnabled(eq("squid"), eq("elasticsearch"))).thenReturn(false);    when(cache.get(eq(ParserConfigurations.class))).thenReturn(parserConfiguration);    when(cache.get(eq(IndexingConfigurations.class))).thenReturn(indexingConfiguration);    List<String> indices = new ArrayList<String>();    Iterables.addAll(indices, sensorIndexingConfigService.getAllIndices("elasticsearch"));    Assert.assertEquals(3, indices.size());    Assert.assertTrue(indices.contains("renamed_bro"));    Assert.assertTrue(indices.contains("snort"));    Assert.assertTrue(indices.contains("yaf"));}
0
public void getAllIndicesWithNoConfigs() throws RestException
{    ParserConfigurations parserConfiguration = mock(ParserConfigurations.class);    when(parserConfiguration.getTypes()).thenReturn(Collections.emptyList());    IndexingConfigurations indexingConfiguration = mock(IndexingConfigurations.class);    when(indexingConfiguration.getTypes()).thenReturn(Collections.emptyList());    when(cache.get(eq(ParserConfigurations.class))).thenReturn(parserConfiguration);    when(cache.get(eq(IndexingConfigurations.class))).thenReturn(indexingConfiguration);    List<String> indices = new ArrayList<String>();    Iterables.addAll(indices, sensorIndexingConfigService.getAllIndices("elasticsearch"));    Assert.assertEquals(0, indices.size());}
0
public void getAllTypesShouldProperlyReturnTypes() throws Exception
{    IndexingConfigurations configs = new IndexingConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(IndexingConfigurations.getKey("bro"), new HashMap<>(), IndexingConfigurations.getKey("squid"), new HashMap<>());        }    };    when(cache.get(eq(IndexingConfigurations.class))).thenReturn(configs);    assertEquals(new ArrayList() {        {            add("bro");            add("squid");        }    }, sensorIndexingConfigService.getAllTypes());}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(IndexingConfigurations.getKey("bro"), new HashMap<>(), IndexingConfigurations.getKey("squid"), new HashMap<>());}
0
public void getAllShouldProperlyReturnIndexingConfigs() throws Exception
{    final Map<String, Object> sensorIndexingConfig = getTestSensorIndexingConfig();    IndexingConfigurations configs = new IndexingConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(IndexingConfigurations.getKey("bro"), sensorIndexingConfig);        }    };    when(cache.get(eq(IndexingConfigurations.class))).thenReturn(configs);    assertEquals(new HashMap() {        {            put("bro", sensorIndexingConfig);        }    }, sensorIndexingConfigService.getAll());}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(IndexingConfigurations.getKey("bro"), sensorIndexingConfig);}
0
public void saveShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.INDEXING.getZookeeperRoot() + "/bro", broJson.getBytes(StandardCharsets.UTF_8))).thenThrow(Exception.class);    when(curatorFramework.setData()).thenReturn(setDataBuilder);    sensorIndexingConfigService.save("bro", new HashMap<>());}
0
public void saveShouldReturnSameConfigThatIsPassedOnSuccessfulSave() throws Exception
{    final Map<String, Object> sensorIndexingConfig = getTestSensorIndexingConfig();    when(objectMapper.writeValueAsString(sensorIndexingConfig)).thenReturn(broJson);    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.INDEXING.getZookeeperRoot() + "/bro", broJson.getBytes(StandardCharsets.UTF_8))).thenReturn(new Stat());    when(curatorFramework.setData()).thenReturn(setDataBuilder);    assertEquals(sensorIndexingConfig, sensorIndexingConfigService.save("bro", sensorIndexingConfig));    verify(setDataBuilder).forPath(eq(ConfigurationType.INDEXING.getZookeeperRoot() + "/bro"), eq(broJson.getBytes(StandardCharsets.UTF_8)));}
0
private Map<String, Object> getTestSensorIndexingConfig()
{    Map<String, Object> sensorIndexingConfig = new HashMap<>();    sensorIndexingConfig.put("hdfs", new HashMap() {        {            put("index", "bro");            put("batchSize", 5);            put("enabled", true);        }    });    return sensorIndexingConfig;}
0
public void setUp() throws Exception
{    objectMapper = mock(ObjectMapper.class);    curatorFramework = mock(CuratorFramework.class);    Environment environment = mock(Environment.class);    Authentication authentication = mock(Authentication.class);    when(authentication.getName()).thenReturn(user);    SecurityContextHolder.getContext().setAuthentication(authentication);    when(environment.getProperty(GROK_TEMP_PATH_SPRING_PROPERTY)).thenReturn("./target");    grokService = new GrokServiceImpl(environment, mock(Grok.class), new HdfsServiceImpl(new Configuration()));    cache = mock(ConfigurationsCache.class);    sensorParserConfigService = new SensorParserConfigServiceImpl(objectMapper, curatorFramework, grokService, cache);}
0
public void deleteShouldProperlyCatchNoNodeExceptionAndReturnFalse() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.PARSER.getZookeeperRoot() + "/bro")).thenThrow(KeeperException.NoNodeException.class);    assertFalse(sensorParserConfigService.delete("bro"));}
0
public void deleteShouldProperlyCatchNonNoNodeExceptionAndThrowRestException() throws Exception
{    exception.expect(RestException.class);    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.PARSER.getZookeeperRoot() + "/bro")).thenThrow(Exception.class);    assertFalse(sensorParserConfigService.delete("bro"));}
0
public void deleteShouldReturnTrueWhenClientSuccessfullyCallsDelete() throws Exception
{    DeleteBuilder builder = mock(DeleteBuilder.class);    when(curatorFramework.delete()).thenReturn(builder);    when(builder.forPath(ConfigurationType.PARSER.getZookeeperRoot() + "/bro")).thenReturn(null);    assertTrue(sensorParserConfigService.delete("bro"));    verify(curatorFramework).delete();}
0
public void findOneShouldProperlyReturnSensorParserConfig() throws Exception
{    final SensorParserConfig sensorParserConfig = getTestBroSensorParserConfig();    ParserConfigurations configs = new ParserConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(ParserConfigurations.getKey("bro"), sensorParserConfig);        }    };    when(cache.get(eq(ParserConfigurations.class))).thenReturn(configs);        assertEquals(getTestBroSensorParserConfig(), sensorParserConfigService.findOne("bro"));        assertNull(sensorParserConfigService.findOne("blah"));}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(ParserConfigurations.getKey("bro"), sensorParserConfig);}
0
public void getAllTypesShouldProperlyReturnTypes() throws Exception
{    ParserConfigurations configs = new ParserConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(ParserConfigurations.getKey("bro"), new HashMap<>(), ParserConfigurations.getKey("squid"), new HashMap<>());        }    };    when(cache.get(eq(ParserConfigurations.class))).thenReturn(configs);    assertEquals(new ArrayList() {        {            add("bro");            add("squid");        }    }, sensorParserConfigService.getAllTypes());}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(ParserConfigurations.getKey("bro"), new HashMap<>(), ParserConfigurations.getKey("squid"), new HashMap<>());}
0
public void getAllShouldProperlyReturnSensorParserConfigs() throws Exception
{    final SensorParserConfig broSensorParserConfig = getTestBroSensorParserConfig();    final SensorParserConfig squidSensorParserConfig = getTestSquidSensorParserConfig();    ParserConfigurations configs = new ParserConfigurations() {        @Override        public Map<String, Object> getConfigurations() {            return ImmutableMap.of(ParserConfigurations.getKey("bro"), broSensorParserConfig, ParserConfigurations.getKey("squid"), squidSensorParserConfig);        }    };    when(cache.get(eq(ParserConfigurations.class))).thenReturn(configs);    assertEquals(new HashMap() {        {            put("bro", getTestBroSensorParserConfig());            put("squid", getTestSquidSensorParserConfig());        }    }, sensorParserConfigService.getAll());}
0
public Map<String, Object> getConfigurations()
{    return ImmutableMap.of(ParserConfigurations.getKey("bro"), broSensorParserConfig, ParserConfigurations.getKey("squid"), squidSensorParserConfig);}
0
public void saveShouldWrapExceptionInRestException() throws Exception
{    exception.expect(RestException.class);    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.PARSER.getZookeeperRoot() + "/bro", broJson.getBytes(StandardCharsets.UTF_8))).thenThrow(Exception.class);    when(curatorFramework.setData()).thenReturn(setDataBuilder);    final SensorParserConfig sensorParserConfig = new SensorParserConfig();    sensorParserConfig.setSensorTopic("bro");    sensorParserConfigService.save("bro", sensorParserConfig);}
0
public void saveShouldReturnSameConfigThatIsPassedOnSuccessfulSave() throws Exception
{    final SensorParserConfig sensorParserConfig = getTestBroSensorParserConfig();    when(objectMapper.writeValueAsString(sensorParserConfig)).thenReturn(broJson);    SetDataBuilder setDataBuilder = mock(SetDataBuilder.class);    when(setDataBuilder.forPath(ConfigurationType.PARSER.getZookeeperRoot() + "/bro", broJson.getBytes(StandardCharsets.UTF_8))).thenReturn(new Stat());    when(curatorFramework.setData()).thenReturn(setDataBuilder);    assertEquals(getTestBroSensorParserConfig(), sensorParserConfigService.save("bro", sensorParserConfig));    verify(setDataBuilder).forPath(eq(ConfigurationType.PARSER.getZookeeperRoot() + "/bro"), eq(broJson.getBytes(StandardCharsets.UTF_8)));}
0
public void reloadAvailableParsersShouldReturnParserClasses() throws Exception
{    Map<String, String> availableParsers = sensorParserConfigService.reloadAvailableParsers();    assertTrue(availableParsers.size() > 0);    assertEquals("org.apache.metron.parsers.GrokParser", availableParsers.get("Grok"));    assertEquals("org.apache.metron.parsers.bro.BasicBroParser", availableParsers.get("Bro"));}
0
public void parseMessageShouldProperlyReturnParsedResults() throws Exception
{    final SensorParserConfig sensorParserConfig = getTestSquidSensorParserConfig();    String grokStatement = "SQUID_DELIMITED %{NUMBER:timestamp}[^0-9]*%{INT:elapsed} %{IP:ip_src_addr} %{WORD:action}/%{NUMBER:code} %{NUMBER:bytes} %{WORD:method} %{NOTSPACE:url}[^0-9]*(%{IP:ip_dst_addr})?";    String sampleData = "1461576382.642    161 127.0.0.1 TCP_MISS/200 103701 GET http://www.cnn.com/ - DIRECT/199.27.79.73 text/html";    ParseMessageRequest parseMessageRequest = new ParseMessageRequest();    parseMessageRequest.setSensorParserConfig(sensorParserConfig);    parseMessageRequest.setGrokStatement(grokStatement);    parseMessageRequest.setSampleData(sampleData);    File grokRoot = new File("./target", user);    grokRoot.mkdir();    File patternFile = new File(grokRoot, "squid");    Writer writer = new OutputStreamWriter(new FileOutputStream(patternFile), StandardCharsets.UTF_8);    writer.write(grokStatement);    writer.close();    assertEquals(new HashMap() {        {            put("elapsed", 161);            put("code", 200);            put("ip_dst_addr", "199.27.79.73");            put("ip_src_addr", "127.0.0.1");            put("action", "TCP_MISS");            put("bytes", 103701);            put("method", "GET");            put("url", "http://www.cnn.com/");            put("timestamp", 1461576382642L);            put("original_string", "1461576382.642    161 127.0.0.1 TCP_MISS/200 103701 GET http://www.cnn.com/ - DIRECT/199.27.79.73 text/html");        }    }, sensorParserConfigService.parseMessage(parseMessageRequest));}
0
public void missingSensorParserConfigShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    ParseMessageRequest parseMessageRequest = new ParseMessageRequest();    sensorParserConfigService.parseMessage(parseMessageRequest);}
0
public void missingParserClassShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    final SensorParserConfig sensorParserConfig = new SensorParserConfig();    sensorParserConfig.setSensorTopic("squid");    ParseMessageRequest parseMessageRequest = new ParseMessageRequest();    parseMessageRequest.setSensorParserConfig(sensorParserConfig);    sensorParserConfigService.parseMessage(parseMessageRequest);}
0
public void invalidParserClassShouldThrowRestException() throws Exception
{    exception.expect(RestException.class);    final SensorParserConfig sensorParserConfig = new SensorParserConfig();    sensorParserConfig.setSensorTopic("squid");    sensorParserConfig.setParserClassName("bad.class.package.BadClassName");    ParseMessageRequest parseMessageRequest = new ParseMessageRequest();    parseMessageRequest.setSensorParserConfig(sensorParserConfig);    sensorParserConfigService.parseMessage(parseMessageRequest);}
0
private SensorParserConfig getTestBroSensorParserConfig()
{    SensorParserConfig sensorParserConfig = new SensorParserConfig();    sensorParserConfig.setSensorTopic("bro");    sensorParserConfig.setParserClassName("org.apache.metron.parsers.bro.BasicBroParser");    return sensorParserConfig;}
0
private SensorParserConfig getTestSquidSensorParserConfig()
{    SensorParserConfig sensorParserConfig = new SensorParserConfig();    sensorParserConfig.setSensorTopic("squid");    sensorParserConfig.setParserClassName("org.apache.metron.parsers.GrokParser");    sensorParserConfig.setParserConfig(new HashMap() {        {            put("grokPath", "/patterns/squid");            put("patternLabel", "SQUID_DELIMITED");            put("timestampField", "timestamp");        }    });    return sensorParserConfig;}
0
public void setUp() throws Exception
{    cache = mock(ConfigurationsCache.class);    globalConfigService = mock(GlobalConfigService.class);    sensorParserConfigService = mock(SensorParserConfigService.class);    sensorParserGroupService = new SensorParserGroupServiceImpl(cache, globalConfigService, sensorParserConfigService);}
0
public void shouldSaveNewGroup() throws Exception
{    when(cache.get(ParserConfigurations.class)).thenReturn(new ParserConfigurations());    when(sensorParserConfigService.findOne("bro")).thenReturn(new SensorParserConfig());    SensorParserGroup sensorParserGroup = new SensorParserGroup();    sensorParserGroup.setName("group1");    sensorParserGroup.setDescription("description 1");    sensorParserGroup.setSensors(Collections.singleton("bro"));    Map<String, Object> expectedGlobalConfig = new HashMap<>();    Collection<SensorParserGroup> expectedGroup = Collections.singleton(sensorParserGroup);    expectedGlobalConfig.put(PARSER_GROUPS_CONF, expectedGroup);    assertEquals(sensorParserGroup, sensorParserGroupService.save(sensorParserGroup));    verify(globalConfigService, times(1)).save(expectedGlobalConfig);    verifyNoMoreInteractions(globalConfigService);}
0
public void shouldSaveExistingGroup() throws Exception
{    SensorParserGroup oldGroup = new SensorParserGroup();    oldGroup.setName("oldGroup");    oldGroup.setDescription("old description");    oldGroup.setSensors(Collections.singleton("oldSensor"));    ParserConfigurations parserConfigurations = mock(ParserConfigurations.class);    when(cache.get(ParserConfigurations.class)).thenReturn(new ParserConfigurations());    when(parserConfigurations.getSensorParserGroups()).thenReturn(new HashMap<String, SensorParserGroup>() {        {            put("newSensor", oldGroup);        }    });    when(sensorParserConfigService.findOne("newSensor")).thenReturn(new SensorParserConfig());    SensorParserGroup newGroup = new SensorParserGroup();    newGroup.setName("newGroup");    newGroup.setDescription("new description");    newGroup.setSensors(Collections.singleton("newSensor"));    Map<String, Object> expectedGlobalConfig = new HashMap<>();    Collection<SensorParserGroup> expectedGroup = Collections.singleton(newGroup);    expectedGlobalConfig.put(PARSER_GROUPS_CONF, expectedGroup);    assertEquals(newGroup, sensorParserGroupService.save(newGroup));    verify(globalConfigService, times(1)).save(expectedGlobalConfig);    verifyNoMoreInteractions(globalConfigService);}
0
public void saveShouldThrowExceptionOnMissingSensor() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("A parser group must contain sensors");    when(cache.get(ParserConfigurations.class)).thenReturn(new ParserConfigurations());    sensorParserGroupService.save(new SensorParserGroup());}
0
public void saveShouldThrowExceptionOnMissingConfig() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("Could not find config for sensor bro");    when(cache.get(ParserConfigurations.class)).thenReturn(new ParserConfigurations());    SensorParserGroup sensorParserGroup = new SensorParserGroup();    sensorParserGroup.setSensors(Collections.singleton("bro"));    sensorParserGroupService.save(sensorParserGroup);}
0
public void saveShouldThrowExceptionOnSensorInAnotherGroup() throws Exception
{    exception.expect(RestException.class);    exception.expectMessage("Sensor bro is already in group existingGroup");    SensorParserGroup existingGroup = new SensorParserGroup();    existingGroup.setName("existingGroup");    existingGroup.setSensors(Collections.singleton("bro"));    ParserConfigurations parserConfigurations = mock(ParserConfigurations.class);    when(parserConfigurations.getSensorParserGroups()).thenReturn(new HashMap<String, SensorParserGroup>() {        {            put("existingGroup", existingGroup);        }    });    when(cache.get(ParserConfigurations.class)).thenReturn(parserConfigurations);    when(sensorParserConfigService.findOne("bro")).thenReturn(new SensorParserConfig());    SensorParserGroup newGroup = new SensorParserGroup();    newGroup.setName("newGroup");    newGroup.setSensors(Collections.singleton("bro"));    sensorParserGroupService.save(newGroup);}
0
public void shouldFindSensorParserGroup() throws Exception
{    ParserConfigurations parserConfigurations = mock(ParserConfigurations.class);    SensorParserGroup group1 = new SensorParserGroup();    group1.setName("group1");    group1.setDescription("group1 description");    group1.setSensors(Collections.singleton("group1Sensor"));    SensorParserGroup group2 = new SensorParserGroup();    group2.setName("group2");    group2.setDescription("group2 description");    group2.setSensors(Collections.singleton("group2Sensor"));    when(parserConfigurations.getSensorParserGroups()).thenReturn(new HashMap<String, SensorParserGroup>() {        {            put("group1", group1);            put("group2", group2);        }    });    when(cache.get(ParserConfigurations.class)).thenReturn(parserConfigurations);    assertEquals(group2, sensorParserGroupService.findOne("group2"));}
0
public void shouldDeleteSensorParserGroup() throws Exception
{    ParserConfigurations parserConfigurations = mock(ParserConfigurations.class);    SensorParserGroup group1 = new SensorParserGroup();    group1.setName("group1");    group1.setDescription("group1 description");    group1.setSensors(Collections.singleton("group1Sensor"));    when(parserConfigurations.getSensorParserGroups()).thenReturn(new HashMap<String, SensorParserGroup>() {        {            put("group1", group1);        }    });    when(cache.get(ParserConfigurations.class)).thenReturn(parserConfigurations);    Map<String, Object> expectedGlobalConfig = new HashMap<>();    expectedGlobalConfig.put(PARSER_GROUPS_CONF, new HashSet<>());    assertEquals(true, sensorParserGroupService.delete("group1"));    assertEquals(false, sensorParserGroupService.delete("group2"));    verify(globalConfigService, times(1)).save(expectedGlobalConfig);    verifyNoMoreInteractions(globalConfigService);}
0
public void setUp() throws Exception
{    curatorFramework = mock(CuratorFramework.class);    stellarService = new StellarServiceImpl(curatorFramework);}
0
public void validateRulesShouldProperlyValidateRules()
{    List<String> rules = Arrays.asList("TO_LOWER(test)", "BAD_FUNCTION(test)");    Map<String, Boolean> results = stellarService.validateRules(rules);    assertEquals(2, results.size());    assertEquals(true, results.get("TO_LOWER(test)"));    assertEquals(false, results.get("BAD_FUNCTION(test)"));}
0
public void applyTransformationsShouldProperlyTransformData()
{    SensorParserConfig sensorParserConfig = new SensorParserConfig();    FieldTransformer fieldTransformater = new FieldTransformer();    fieldTransformater.setOutput("url_host");    fieldTransformater.setTransformation("STELLAR");    fieldTransformater.setConfig(new LinkedHashMap<String, Object>() {        {            put("url_host", "TO_LOWER(URL_TO_HOST(url))");        }    });    sensorParserConfig.setFieldTransformations(ImmutableList.of(fieldTransformater));    SensorParserContext sensorParserContext = new SensorParserContext();    sensorParserContext.setSensorParserConfig(sensorParserConfig);    sensorParserContext.setSampleData(new HashMap<String, Object>() {        {            put("url", "https://caseystella.com/blog");        }    });    Map<String, Object> results = stellarService.applyTransformations(sensorParserContext);    assertEquals(2, results.size());    assertEquals("https://caseystella.com/blog", results.get("url"));    assertEquals("caseystella.com", results.get("url_host"));}
0
public void getTransformationsShouldReturnTransformation()
{    assertTrue(stellarService.getTransformations().length > 0);}
0
public void getStellarFunctionsShouldReturnFunctions()
{    assertTrue(stellarService.getStellarFunctions().size() > 0);}
0
public void getSimpleStellarFunctionsShouldReturnFunctions()
{    assertEquals(1, stellarService.getSimpleStellarFunctions().stream().filter(stellarFunctionDescription -> stellarFunctionDescription.getName().equals("TO_LOWER")).count());}
0
public void setUp() throws Exception
{    stormCLIClientWrapper = mock(StormCLIWrapper.class);    globalConfigService = mock(GlobalConfigService.class);    sensorParserConfigService = mock(SensorParserConfigService.class);    sensorParserGroupService = mock(SensorParserGroupService.class);    stormStatusService = mock(StormStatusService.class);    stormAdminService = new StormAdminServiceImpl(stormCLIClientWrapper, globalConfigService, sensorParserConfigService, sensorParserGroupService, stormStatusService);}
0
public void startParserTopologyShouldProperlyReturnSuccessTopologyResponse() throws Exception
{    when(stormCLIClientWrapper.startParserTopology("bro")).thenReturn(0);    when(globalConfigService.get()).thenReturn(new HashMap<String, Object>());    when(sensorParserConfigService.findOne("bro")).thenReturn(new SensorParserConfig());    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.STARTED.toString());    TopologyResponse actual = stormAdminService.startParserTopology("bro");    assertEquals(expected, actual);    assertEquals(expected.hashCode(), actual.hashCode());}
0
public void startParserTopologyByGroupShouldProperlyReturnSuccessTopologyResponse() throws Exception
{    SensorParserGroup group = new SensorParserGroup();    group.setName("group");    group.setSensors(new HashSet<String>() {        {            add("bro");            add("snort");        }    });    when(sensorParserGroupService.findOne("group")).thenReturn(group);    when(stormCLIClientWrapper.startParserTopology("bro,snort")).thenReturn(0);    when(globalConfigService.get()).thenReturn(new HashMap<String, Object>());    when(sensorParserConfigService.findOne("bro")).thenReturn(new SensorParserConfig());    when(sensorParserConfigService.findOne("snort")).thenReturn(new SensorParserConfig());    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.STARTED.toString());    TopologyResponse actual = stormAdminService.startParserTopology("group");    assertEquals(expected, actual);    assertEquals(expected.hashCode(), actual.hashCode());}
0
public void startParserTopologyShouldReturnGlobalConfigMissingError() throws Exception
{    when(globalConfigService.get()).thenReturn(null);    TopologyResponse expected = new TopologyResponse();    expected.setErrorMessage(TopologyStatusCode.GLOBAL_CONFIG_MISSING.toString());    assertEquals(expected, stormAdminService.startParserTopology("bro"));}
0
public void startParserTopologyShouldReturnSensorParserConfigMissingError() throws Exception
{    when(globalConfigService.get()).thenReturn(new HashMap<String, Object>());    when(sensorParserConfigService.findOne("bro")).thenReturn(null);    TopologyResponse expected = new TopologyResponse();    expected.setErrorMessage(TopologyStatusCode.SENSOR_PARSER_CONFIG_MISSING.toString());    assertEquals(expected, stormAdminService.startParserTopology("bro"));}
0
public void stopParserTopologyShouldProperlyReturnErrorTopologyResponse() throws Exception
{    TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setName("bro");    when(stormCLIClientWrapper.stopParserTopology("bro", false)).thenReturn(1);    when(stormStatusService.getTopologyStatus("bro")).thenReturn(topologyStatus);    TopologyResponse expected = new TopologyResponse();    expected.setErrorMessage(TopologyStatusCode.STOP_ERROR.toString());    assertEquals(expected, stormAdminService.stopParserTopology("bro", false));}
0
public void startEnrichmentTopologyShouldProperlyReturnSuccessTopologyResponse() throws Exception
{    when(stormCLIClientWrapper.startEnrichmentTopology()).thenReturn(0);    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.STARTED.toString());    assertEquals(expected, stormAdminService.startEnrichmentTopology());}
0
public void stopEnrichmentTopologyShouldProperlyReturnSuccessTopologyResponse() throws Exception
{    when(stormCLIClientWrapper.stopEnrichmentTopology(false)).thenReturn(0);    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.STOPPED.toString());    assertEquals(expected, stormAdminService.stopEnrichmentTopology(false));}
0
public void startIndexingTopologyShouldProperlyReturnSuccessTopologyResponse() throws Exception
{    when(stormCLIClientWrapper.startIndexingTopology("random_access_indexing_script_path")).thenReturn(0);    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.STARTED.toString());    assertEquals(expected, stormAdminService.startIndexingTopology("random_access_indexing_script_path"));}
0
public void stopIndexingTopologyShouldProperlyReturnSuccessTopologyResponse() throws Exception
{    when(stormCLIClientWrapper.stopIndexingTopology("random_access_indexing", false)).thenReturn(0);    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.STOPPED.toString());    assertEquals(expected, stormAdminService.stopIndexingTopology("random_access_indexing", false));}
0
public void getStormClientStatusShouldProperlyReturnStatus() throws Exception
{    final Map<String, String> status = new HashMap() {        {            put("status", "statusValue");        }    };    when(stormCLIClientWrapper.getStormClientStatus()).thenReturn(status);    assertEquals(new HashMap() {        {            put("status", "statusValue");        }    }, stormAdminService.getStormClientStatus());}
0
public void setUp() throws Exception
{    processBuilder = mock(ProcessBuilder.class);    environment = mock(Environment.class);    process = mock(Process.class);    stormCLIWrapper = new StormCLIWrapper();    stormCLIWrapper.setEnvironment(environment);}
0
public void startParserTopologyShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.PARSER_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_parser");    when(environment.getProperty(MetronRestConstants.KAFKA_BROKER_URL_SPRING_PROPERTY)).thenReturn("kafka_broker_url");    when(environment.getProperty(MetronRestConstants.ZK_URL_SPRING_PROPERTY)).thenReturn("zookeeper_url");    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    when(environment.getProperty(MetronRestConstants.KAFKA_SECURITY_PROTOCOL_SPRING_PROPERTY)).thenReturn("kafka_security_protocol");    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.startParserTopology("bro"));    verify(process).waitFor();    verifyNew(ProcessBuilder.class).withArguments("/start_parser", "-s", "bro", "-z", "zookeeper_url", "-k", "kafka_broker_url", "-ksp", "kafka_security_protocol");}
0
public void startParserTopologyWithExtraTopologyOptions() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.PARSER_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_parser");    when(environment.getProperty(MetronRestConstants.KAFKA_BROKER_URL_SPRING_PROPERTY)).thenReturn("kafka_broker_url");    when(environment.getProperty(MetronRestConstants.ZK_URL_SPRING_PROPERTY)).thenReturn("zookeeper_url");    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(true);    when(environment.getProperty(MetronRestConstants.KAFKA_SECURITY_PROTOCOL_SPRING_PROPERTY)).thenReturn("kafka_security_protocol");    when(environment.getProperty(MetronRestConstants.PARSER_TOPOLOGY_OPTIONS_SPRING_PROPERTY)).thenReturn("parser_topology_options");    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.startParserTopology("bro"));    verify(process, times(2)).waitFor();    verifyNew(ProcessBuilder.class).withArguments("/start_parser", "-s", "bro", "-z", "zookeeper_url", "-k", "kafka_broker_url", "-ksp", "kafka_security_protocol", "-e", "parser_topology_options");}
0
public void stopParserTopologyShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.stopParserTopology("bro", false));    verify(process).waitFor();    verifyNew(ProcessBuilder.class).withArguments("storm", "kill", "bro");}
0
public void stopParserTopologyNowShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.stopParserTopology("bro", true));    verify(process).waitFor();    verifyNew(ProcessBuilder.class).withArguments("storm", "kill", "bro", "-w", "0");}
0
public void startEnrichmentTopologyShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.ENRICHMENT_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_enrichment");    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.startEnrichmentTopology());    verify(process).waitFor();    verifyNew(ProcessBuilder.class).withArguments("/start_enrichment");}
0
public void stopEnrichmentTopologyShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.stopEnrichmentTopology(false));    verify(process).waitFor();    verifyNew(ProcessBuilder.class).withArguments("storm", "kill", MetronRestConstants.ENRICHMENT_TOPOLOGY_NAME);}
0
public void startIndexingTopologyShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.RANDOM_ACCESS_INDEXING_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_indexing");    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.startIndexingTopology(MetronRestConstants.RANDOM_ACCESS_INDEXING_SCRIPT_PATH_SPRING_PROPERTY));    verify(process).waitFor();    verifyNew(ProcessBuilder.class).withArguments("/start_indexing");}
0
public void stopIndexingTopologyShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(false);    when(process.exitValue()).thenReturn(0);    assertEquals(0, stormCLIWrapper.stopIndexingTopology("random_access_indexing", false));    verify(process).waitFor();    verifyNew(ProcessBuilder.class).withArguments("storm", "kill", MetronRestConstants.RANDOM_ACCESS_INDEXING_TOPOLOGY_NAME);}
0
public void getStormClientStatusShouldReturnCorrectStatus() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    Process process = mock(Process.class);    InputStream inputStream = new ByteArrayInputStream("\nStorm 1.1".getBytes(UTF_8));    when(processBuilder.start()).thenReturn(process);    when(process.getInputStream()).thenReturn(inputStream);    when(environment.getProperty(MetronRestConstants.PARSER_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_parser");    when(environment.getProperty(MetronRestConstants.ENRICHMENT_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_enrichment");    when(environment.getProperty(MetronRestConstants.RANDOM_ACCESS_INDEXING_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_elasticsearch");    when(environment.getProperty(MetronRestConstants.BATCH_INDEXING_SCRIPT_PATH_SPRING_PROPERTY)).thenReturn("/start_hdfs");    Map<String, String> actual = stormCLIWrapper.getStormClientStatus();    assertEquals(new HashMap<String, String>() {        {            put("randomAccessIndexingScriptPath", "/start_elasticsearch");            put("enrichmentScriptPath", "/start_enrichment");            put("stormClientVersionInstalled", "1.1");            put("parserScriptPath", "/start_parser");            put("batchIndexingScriptPath", "/start_hdfs");        }    }, actual);    verifyNew(ProcessBuilder.class).withArguments("storm", "version");}
0
public void stormClientVersionInstalledShouldReturnDefault() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    Process process = mock(Process.class);    InputStream inputStream = new ByteArrayInputStream("".getBytes(UTF_8));    when(processBuilder.start()).thenReturn(process);    when(process.getInputStream()).thenReturn(inputStream);    assertEquals("Storm client is not installed", stormCLIWrapper.stormClientVersionInstalled());}
0
public void runCommandShouldReturnRestExceptionOnError() throws Exception
{    exception.expect(RestException.class);    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenThrow(new IOException());    stormCLIWrapper.runCommand(new String[] { "storm", "kill" });}
0
public void stormClientVersionInstalledShouldReturnRestExceptionOnError() throws Exception
{    exception.expect(RestException.class);    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenThrow(new IOException());    stormCLIWrapper.stormClientVersionInstalled();}
0
public void kinitShouldRunCommandProperly() throws Exception
{    whenNew(ProcessBuilder.class).withParameterTypes(String[].class).withArguments(anyVararg()).thenReturn(processBuilder);    when(processBuilder.start()).thenReturn(process);    when(environment.getProperty(MetronRestConstants.KERBEROS_ENABLED_SPRING_PROPERTY, Boolean.class, false)).thenReturn(true);    when(environment.getProperty(MetronRestConstants.KERBEROS_KEYTAB_SPRING_PROPERTY)).thenReturn("metron keytabLocation");    when(environment.getProperty(MetronRestConstants.KERBEROS_PRINCIPLE_SPRING_PROPERTY)).thenReturn("metron principal");    when(process.exitValue()).thenReturn(0);    stormCLIWrapper.kinit();    verify(process, times(1)).waitFor();    verifyNew(ProcessBuilder.class).withArguments("kinit", "-kt", "metron keytabLocation", "metron principal");}
0
public void setUp() throws Exception
{    environment = mock(Environment.class);    restTemplate = mock(RestTemplate.class);    sensorParserGroupService = mock(SensorParserGroupService.class);    stormStatusService = new StormStatusServiceImpl(environment, restTemplate, sensorParserGroupService);}
0
public void testgetStormUiPropertyHttp()
{    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    StormStatusServiceImpl serviceImpl = (StormStatusServiceImpl) stormStatusService;    assertEquals(HTTP_STORM_UI, serviceImpl.getStormUiProperty());}
0
public void testgetStormUiPropertyHttps()
{    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTPS_STORM_UI);    StormStatusServiceImpl serviceImpl = (StormStatusServiceImpl) stormStatusService;    assertEquals(HTTPS_STORM_UI, serviceImpl.getStormUiProperty());}
0
public void testgetStormUiPropertyNoProtocol()
{    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(NO_PROTOCOL_STORM_UI);    StormStatusServiceImpl serviceImpl = (StormStatusServiceImpl) stormStatusService;    assertEquals(HTTP_STORM_UI, serviceImpl.getStormUiProperty());}
0
public void getTopologySummaryShouldReturnTopologySummary() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setStatus(TopologyStatusCode.STARTED);    topologyStatus.setName("bro");    topologyStatus.setId("bro_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    TopologyStatus expectedStatus = new TopologyStatus();    expectedStatus.setStatus(TopologyStatusCode.STARTED);    expectedStatus.setName("bro");    expectedStatus.setId("bro_id");    TopologySummary expected = new TopologySummary();    expected.setTopologies(new TopologyStatus[] { expectedStatus });    TopologySummary actual = stormStatusService.getTopologySummary();    assertEquals(expected, actual);    assertEquals(expected.hashCode(), actual.hashCode());}
0
public void getTopologyStatusShouldReturnTopologyStatus() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setStatus(TopologyStatusCode.STARTED);    topologyStatus.setName("bro");    topologyStatus.setId("bro_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_URL + "/bro_id", TopologyStatus.class)).thenReturn(topologyStatus);    TopologyStatus expected = new TopologyStatus();    expected.setStatus(TopologyStatusCode.STARTED);    expected.setName("bro");    expected.setId("bro_id");    TopologyStatus actual = stormStatusService.getTopologyStatus("bro");    assertEquals(expected, actual);    assertEquals(expected.hashCode(), actual.hashCode());}
0
public void getTopologyStatusByGroupShouldReturnTopologyStatus() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setStatus(TopologyStatusCode.STARTED);    topologyStatus.setName("bro__snort");    topologyStatus.setId("bro_snort_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    SensorParserGroup group = new SensorParserGroup();    group.setName("group");    group.setSensors(new HashSet<String>() {        {            add("bro");            add("snort");        }    });    when(sensorParserGroupService.findOne("group")).thenReturn(group);    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_URL + "/bro_snort_id", TopologyStatus.class)).thenReturn(topologyStatus);    TopologyStatus expected = new TopologyStatus();    expected.setStatus(TopologyStatusCode.STARTED);    expected.setName("bro__snort");    expected.setId("bro_snort_id");    TopologyStatus actual = stormStatusService.getTopologyStatus("group");    assertEquals(expected, actual);    assertEquals(expected.hashCode(), actual.hashCode());}
0
public void getAllTopologyStatusShouldReturnAllTopologyStatus() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setStatus(TopologyStatusCode.STARTED);    topologyStatus.setName("bro");    topologyStatus.setId("bro_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_URL + "/bro_id", TopologyStatus.class)).thenReturn(topologyStatus);    TopologyStatus expected = new TopologyStatus();    expected.setStatus(TopologyStatusCode.STARTED);    expected.setName("bro");    expected.setId("bro_id");    assertEquals(new ArrayList() {        {            add(expected);        }    }, stormStatusService.getAllTopologyStatus());}
0
public void activateTopologyShouldReturnActiveTopologyResponse() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setName("bro");    topologyStatus.setId("bro_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    when(restTemplate.postForObject(HTTP_STORM_UI + TOPOLOGY_URL + "/bro_id/activate", null, Map.class)).thenReturn(new HashMap() {        {            put("status", "success");        }    });    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.ACTIVE.toString());    assertEquals(expected, stormStatusService.activateTopology("bro"));}
0
public void activateTopologyShouldReturnErrorTopologyResponse() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setName("bro");    topologyStatus.setId("bro_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    when(restTemplate.postForObject(HTTP_STORM_UI + TOPOLOGY_URL + "/bro_id/activate", null, Map.class)).thenReturn(new HashMap() {        {            put("status", "error message");        }    });    TopologyResponse expected = new TopologyResponse();    expected.setErrorMessage("error message");    assertEquals(expected, stormStatusService.activateTopology("bro"));}
0
public void activateTopologyShouldReturnTopologyNotFoundTopologyResponse() throws Exception
{    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(new TopologySummary());    TopologyResponse expected = new TopologyResponse();    expected.setErrorMessage(TopologyStatusCode.TOPOLOGY_NOT_FOUND.toString());    assertEquals(expected, stormStatusService.activateTopology("bro"));}
0
public void deactivateTopologyShouldReturnActiveTopologyResponse() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setName("bro");    topologyStatus.setId("bro_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    when(restTemplate.postForObject(HTTP_STORM_UI + TOPOLOGY_URL + "/bro_id/deactivate", null, Map.class)).thenReturn(new HashMap() {        {            put("status", "success");        }    });    TopologyResponse expected = new TopologyResponse();    expected.setSuccessMessage(TopologyStatusCode.INACTIVE.toString());    assertEquals(expected, stormStatusService.deactivateTopology("bro"));}
0
public void deactivateTopologyShouldReturnErrorTopologyResponse() throws Exception
{    final TopologyStatus topologyStatus = new TopologyStatus();    topologyStatus.setName("bro");    topologyStatus.setId("bro_id");    final TopologySummary topologySummary = new TopologySummary();    topologySummary.setTopologies(new TopologyStatus[] { topologyStatus });    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(topologySummary);    when(restTemplate.postForObject(HTTP_STORM_UI + TOPOLOGY_URL + "/bro_id/deactivate", null, Map.class)).thenReturn(new HashMap() {        {            put("status", "error message");        }    });    TopologyResponse expected = new TopologyResponse();    expected.setErrorMessage("error message");    assertEquals(expected, stormStatusService.deactivateTopology("bro"));}
0
public void deactivateTopologyShouldReturnTopologyNotFoundTopologyResponse() throws Exception
{    when(environment.getProperty(STORM_UI_SPRING_PROPERTY)).thenReturn(HTTP_STORM_UI);    when(restTemplate.getForObject(HTTP_STORM_UI + TOPOLOGY_SUMMARY_URL, TopologySummary.class)).thenReturn(new TopologySummary());    TopologyResponse expected = new TopologyResponse();    expected.setErrorMessage(TopologyStatusCode.TOPOLOGY_NOT_FOUND.toString());    assertEquals(expected, stormStatusService.deactivateTopology("bro"));}
0
public void setUp() throws Exception
{    userSettingsTable = mock(Table.class);    globalConfigSupplier = () -> new HashMap<String, Object>() {        {            put(USER_SETTINGS_HBASE_CF, "cf");        }    };}
0
public void shouldFindOne() throws Exception
{    Result result = mock(Result.class);    when(result.getValue(cf, Bytes.toBytes("type"))).thenReturn("userSettings1String".getBytes(StandardCharsets.UTF_8));    Get get = new Get("user1".getBytes(StandardCharsets.UTF_8));    get.addFamily(cf);    when(userSettingsTable.get(get)).thenReturn(result);    UserSettingsClient userSettingsClient = new UserSettingsClient(userSettingsTable, cf);    assertEquals("userSettings1String", userSettingsClient.findOne("user1", "type").get());    assertFalse(userSettingsClient.findOne("missingUser", "type").isPresent());}
0
public void shouldFindAll() throws Exception
{    ResultScanner resultScanner = mock(ResultScanner.class);    Result result1 = mock(Result.class);    Result result2 = mock(Result.class);    when(result1.getRow()).thenReturn("user1".getBytes(StandardCharsets.UTF_8));    when(result2.getRow()).thenReturn("user2".getBytes(StandardCharsets.UTF_8));    when(result1.getValue(cf, Bytes.toBytes("type"))).thenReturn("userSettings1String".getBytes(StandardCharsets.UTF_8));    when(result2.getValue(cf, Bytes.toBytes("type"))).thenReturn("userSettings2String".getBytes(StandardCharsets.UTF_8));    when(resultScanner.iterator()).thenReturn(Arrays.asList(result1, result2).iterator());    when(userSettingsTable.getScanner(any(Scan.class))).thenReturn(resultScanner);    UserSettingsClient userSettingsClient = new UserSettingsClient(userSettingsTable, cf);    assertEquals(new HashMap<String, Optional<String>>() {        {            put("user1", Optional.of("userSettings1String"));            put("user2", Optional.of("userSettings2String"));        }    }, userSettingsClient.findAll("type"));}
0
public String getMessage()
{    return message;}
0
public void setMessage(String message)
{    this.message = message;}
0
public int getCode()
{    return code;}
0
public void setCode(int code)
{    this.code = code;}
0
public String getPath()
{    return path;}
0
public void setPath(String path)
{    this.path = path;}
0
public String getDescription()
{    return description;}
0
public void setDescription(String description)
{    this.description = description;}
0
public RequestMethod getMethod()
{    return method;}
0
public void setMethod(RequestMethod method)
{    this.method = method;}
0
public List<Response> getResponses()
{    return responses;}
0
public void addResponse(String message, int code)
{    Response response = new Response();    response.setMessage(message);    response.setCode(code);    this.responses.add(response);}
0
public Map<String, String> getParameterDescriptions()
{    return parameterDescriptions;}
0
public void addParameterDescription(String name, String description)
{    parameterDescriptions.put(name, description);}
0
public String convertToDatabaseColumn(Object savedSearches)
{    try {        return JSONUtils.INSTANCE.toJSON(savedSearches, false);    } catch (JsonProcessingException e) {            }    return null;}
1
public Object convertToEntityAttribute(String savedSearches)
{    try {        return JSONUtils.INSTANCE.load(savedSearches, Object.class);    } catch (IOException e) {            }    return null;}
1
public String getUser()
{    return user;}
0
public void setUser(String user)
{    this.user = user;}
0
public List<String> getTableColumns()
{    return tableColumns;}
0
public void setTableColumns(List<String> tableColumns)
{    this.tableColumns = tableColumns;}
0
public List<SavedSearch> getSavedSearches()
{    return savedSearches;}
0
public void setSavedSearches(List<SavedSearch> savedSearches)
{    this.savedSearches = savedSearches;}
0
public List<String> getFacetFields()
{    return facetFields;}
0
public void setFacetFields(List<String> facetFields)
{    this.facetFields = facetFields;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    AlertsUIUserSettings that = (AlertsUIUserSettings) o;    return (user != null ? user.equals(that.user) : that.user == null) && (tableColumns != null ? tableColumns.equals(that.tableColumns) : that.tableColumns == null) && (savedSearches != null ? savedSearches.equals(that.savedSearches) : that.savedSearches == null) && (facetFields != null ? facetFields.equals(that.facetFields) : that.facetFields == null);}
0
public int hashCode()
{    int result = user != null ? user.hashCode() : 0;    result = 31 * result + (tableColumns != null ? tableColumns.hashCode() : 0);    result = 31 * result + (savedSearches != null ? savedSearches.hashCode() : 0);    result = 31 * result + (facetFields != null ? facetFields.hashCode() : 0);    return result;}
0
public String getPatternLabel()
{    return patternLabel;}
0
public void setPatternLabel(String patternLabel)
{    this.patternLabel = patternLabel;}
0
public String getStatement()
{    return statement;}
0
public void setStatement(String statement)
{    this.statement = statement;}
0
public String getSampleData()
{    return sampleData;}
0
public void setSampleData(String sampleData)
{    this.sampleData = sampleData;}
0
public Map<String, Object> getResults()
{    if (results == null) {        return new HashMap<>();    }    return results;}
0
public void setResults(Map<String, Object> results)
{    this.results = results;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    GrokValidation that = (GrokValidation) o;    if (patternLabel != null ? !patternLabel.equals(that.patternLabel) : that.patternLabel != null)        return false;    if (statement != null ? !statement.equals(that.statement) : that.statement != null)        return false;    if (sampleData != null ? !sampleData.equals(that.sampleData) : that.sampleData != null)        return false;    return results != null ? results.equals(that.results) : that.results == null;}
0
public int hashCode()
{    int result = patternLabel != null ? patternLabel.hashCode() : 0;    result = 31 * result + (statement != null ? statement.hashCode() : 0);    result = 31 * result + (sampleData != null ? sampleData.hashCode() : 0);    result = 31 * result + (results != null ? results.hashCode() : 0);    return result;}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public int getNumPartitions()
{    return numPartitions;}
0
public void setNumPartitions(int numPartitions)
{    this.numPartitions = numPartitions;}
0
public int getReplicationFactor()
{    return replicationFactor;}
0
public void setReplicationFactor(int replicationFactor)
{    this.replicationFactor = replicationFactor;}
0
public Properties getProperties()
{    return properties;}
0
public void setProperties(Properties properties)
{    this.properties = properties;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    KafkaTopic that = (KafkaTopic) o;    if (numPartitions != that.numPartitions)        return false;    if (replicationFactor != that.replicationFactor)        return false;    if (name != null ? !name.equals(that.name) : that.name != null)        return false;    return properties != null ? properties.equals(that.properties) : that.properties == null;}
0
public int hashCode()
{    int result = name != null ? name.hashCode() : 0;    result = 31 * result + numPartitions;    result = 31 * result + replicationFactor;    result = 31 * result + (properties != null ? properties.hashCode() : 0);    return result;}
0
public SensorParserConfig getSensorParserConfig()
{    return sensorParserConfig;}
0
public void setSensorParserConfig(SensorParserConfig sensorParserConfig)
{    this.sensorParserConfig = sensorParserConfig;}
0
public String getGrokStatement()
{    return grokStatement;}
0
public void setGrokStatement(String grokStatement)
{    this.grokStatement = grokStatement;}
0
public String getSampleData()
{    return sampleData;}
0
public void setSampleData(String sampleData)
{    this.sampleData = sampleData;}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String getPos()
{    return pos;}
0
public void setPos(String pos)
{    this.pos = pos;}
0
public String getShowname()
{    return showname;}
0
public void setShowname(String showname)
{    this.showname = showname;}
0
public String getSize()
{    return size;}
0
public void setSize(String size)
{    this.size = size;}
0
public String getValue()
{    return value;}
0
public void setValue(String value)
{    this.value = value;}
0
public String getShow()
{    return show;}
0
public void setShow(String show)
{    this.show = show;}
0
public String getUnmaskedvalue()
{    return unmaskedvalue;}
0
public void setUnmaskedvalue(String unmaskedvalue)
{    this.unmaskedvalue = unmaskedvalue;}
0
public String getHide()
{    return hide;}
0
public void setHide(String hide)
{    this.hide = hide;}
0
public List<Field> getFields()
{    return fields;}
0
public void setFields(List<Field> fields)
{    this.fields = fields;}
0
public List<Proto> getProtos()
{    return protos;}
0
public void setProtos(List<Proto> protos)
{    this.protos = protos;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Field field = (Field) o;    return Objects.equals(name, field.name) && Objects.equals(pos, field.pos) && Objects.equals(showname, field.showname) && Objects.equals(size, field.size) && Objects.equals(value, field.value) && Objects.equals(show, field.show) && Objects.equals(unmaskedvalue, field.unmaskedvalue) && Objects.equals(hide, field.hide) && Objects.equals(fields, field.fields) && Objects.equals(protos, field.protos);}
0
public int hashCode()
{    return Objects.hash(name, pos, showname, size, value, show, unmaskedvalue, hide, fields, protos);}
0
public String getKey()
{    return key;}
0
public String getIpSrcAddr()
{    return FixedPcapOptions.IP_SRC_ADDR.get(this, String.class);}
0
public void setIpSrcAddr(String ipSrcAddr)
{    FixedPcapOptions.IP_SRC_ADDR.put(this, ipSrcAddr);}
0
public String getIpDstAddr()
{    return FixedPcapOptions.IP_DST_ADDR.get(this, String.class);}
0
public void setIpDstAddr(String ipDstAddr)
{    FixedPcapOptions.IP_DST_ADDR.put(this, ipDstAddr);}
0
public Integer getIpSrcPort()
{    return FixedPcapOptions.IP_SRC_PORT.get(this, Integer.class);}
0
public void setIpSrcPort(Integer ipSrcPort)
{    FixedPcapOptions.IP_SRC_PORT.put(this, ipSrcPort);}
0
public Integer getIpDstPort()
{    return FixedPcapOptions.IP_DST_PORT.get(this, Integer.class);}
0
public void setIpDstPort(Integer ipDstPort)
{    FixedPcapOptions.IP_DST_PORT.put(this, ipDstPort);}
0
public String getProtocol()
{    return FixedPcapOptions.PROTOCOL.get(this, String.class);}
0
public void setProtocol(String protocol)
{    FixedPcapOptions.PROTOCOL.put(this, protocol);}
0
public String getPacketFilter()
{    return FixedPcapOptions.PACKET_FILTER.get(this, String.class);}
0
public void setPacketFilter(String packetFilter)
{    FixedPcapOptions.PACKET_FILTER.put(this, packetFilter);}
0
public Boolean getIncludeReverse()
{    return FixedPcapOptions.INCLUDE_REVERSE.get(this, Boolean.class);}
0
public void setIncludeReverse(Boolean includeReverse)
{    FixedPcapOptions.INCLUDE_REVERSE.put(this, includeReverse);}
0
public void setFields()
{    Map<String, String> fields = new HashMap<>();    if (getIpSrcAddr() != null) {        fields.put(Constants.Fields.SRC_ADDR.getName(), getIpSrcAddr());    }    if (getIpDstAddr() != null) {        fields.put(Constants.Fields.DST_ADDR.getName(), getIpDstAddr());    }    if (getIpSrcPort() != null) {        fields.put(Constants.Fields.SRC_PORT.getName(), getIpSrcPort().toString());    }    if (getIpDstPort() != null) {        fields.put(Constants.Fields.DST_PORT.getName(), getIpDstPort().toString());    }    if (getProtocol() != null) {        fields.put(Constants.Fields.PROTOCOL.getName(), getProtocol());    }    if (getIncludeReverse() != null) {        fields.put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), getIncludeReverse().toString());    }    if (getPacketFilter() != null) {        fields.put(PcapHelper.PacketFields.PACKET_FILTER.getName(), getPacketFilter());    }    PcapOptions.FIELDS.put(this, fields);}
0
public List<Proto> getProtos()
{    return protos;}
0
public void setProtos(List<Proto> protos)
{    this.protos = protos;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Packet packet = (Packet) o;    return Objects.equals(protos, packet.protos);}
0
public int hashCode()
{    return Objects.hash(protos);}
0
public String getBasePath()
{    return PcapOptions.BASE_PATH.get(this, String.class);}
0
public void setBasePath(String basePath)
{    PcapOptions.BASE_PATH.put(this, basePath);}
0
public String getBaseInterimResultPath()
{    return PcapOptions.BASE_INTERIM_RESULT_PATH.get(this, String.class);}
0
public void setBaseInterimResultPath(String baseInterimResultPath)
{    PcapOptions.BASE_INTERIM_RESULT_PATH.put(this, baseInterimResultPath);}
0
public String getFinalOutputPath()
{    return PcapOptions.FINAL_OUTPUT_PATH.get(this, String.class);}
0
public void setFinalOutputPath(String finalOutputPath)
{    PcapOptions.FINAL_OUTPUT_PATH.put(this, finalOutputPath);}
0
public Long getStartTimeMs()
{    return PcapOptions.START_TIME_MS.get(this, Long.class);}
0
public void setStartTimeMs(Long startTime)
{    PcapOptions.START_TIME_MS.put(this, startTime);}
0
public Long getEndTimeMs()
{    return PcapOptions.END_TIME_MS.get(this, Long.class);}
0
public void setEndTimeMs(Long endTime)
{    PcapOptions.END_TIME_MS.put(this, endTime);}
0
public Integer getNumReducers()
{    return PcapOptions.NUM_REDUCERS.get(this, Integer.class);}
0
public void setNumReducers(Integer numReducers)
{    PcapOptions.NUM_REDUCERS.put(this, numReducers);}
0
public String getJobId()
{    return jobId;}
0
public void setJobId(String jobId)
{    this.jobId = jobId;}
0
public String getJobStatus()
{    return jobStatus;}
0
public void setJobStatus(String jobStatus)
{    this.jobStatus = jobStatus;}
0
public String getDescription()
{    return description;}
0
public void setDescription(String description)
{    this.description = description;}
0
public Double getPercentComplete()
{    return percentComplete;}
0
public void setPercentComplete(Double percentComplete)
{    this.percentComplete = percentComplete;}
0
public Integer getPageTotal()
{    return pageTotal;}
0
public void setPageTotal(Integer size)
{    this.pageTotal = size;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    PcapStatus that = (PcapStatus) o;    return Objects.equals(jobId, that.jobId) && Objects.equals(jobStatus, that.jobStatus) && Objects.equals(description, that.description) && Objects.equals(percentComplete, that.percentComplete) && Objects.equals(pageTotal, that.pageTotal);}
0
public int hashCode()
{    return Objects.hash(jobId, jobStatus, description, percentComplete, pageTotal);}
0
public String getVersion()
{    return version;}
0
public void setVersion(String version)
{    this.version = version;}
0
public String getCreator()
{    return creator;}
0
public void setCreator(String creator)
{    this.creator = creator;}
0
public String getTime()
{    return time;}
0
public void setTime(String time)
{    this.time = time;}
0
public String getCaptureFile()
{    return captureFile;}
0
public void setCaptureFile(String captureFile)
{    this.captureFile = captureFile;}
0
public List<Packet> getPackets()
{    return packets;}
0
public void setPackets(List<Packet> packets)
{    this.packets = packets;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Pdml pdml = (Pdml) o;    return Objects.equals(version, pdml.version) && Objects.equals(creator, pdml.creator) && Objects.equals(time, pdml.time) && Objects.equals(captureFile, pdml.captureFile) && Objects.equals(packets, pdml.packets);}
0
public int hashCode()
{    return Objects.hash(version, creator, time, captureFile, packets);}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String getPos()
{    return pos;}
0
public void setPos(String pos)
{    this.pos = pos;}
0
public String getShowname()
{    return showname;}
0
public void setShowname(String showname)
{    this.showname = showname;}
0
public String getSize()
{    return size;}
0
public void setSize(String size)
{    this.size = size;}
0
public String getHide()
{    return hide;}
0
public void setHide(String hide)
{    this.hide = hide;}
0
public List<Field> getFields()
{    return fields;}
0
public void setFields(List<Field> fields)
{    this.fields = fields;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Proto proto = (Proto) o;    return Objects.equals(name, proto.name) && Objects.equals(pos, proto.pos) && Objects.equals(showname, proto.showname) && Objects.equals(size, proto.size) && Objects.equals(hide, proto.hide) && Objects.equals(fields, proto.fields);}
0
public int hashCode()
{    return Objects.hash(name, pos, showname, size, hide, fields);}
0
public String getKey()
{    return key;}
0
public String getQuery()
{    return QueryPcapOptions.QUERY.get(this, String.class);}
0
public void setQuery(String query)
{    QueryPcapOptions.QUERY.put(this, query);}
0
public void setFields()
{    PcapOptions.FIELDS.put(this, getQuery());}
0
public List<byte[]> getPcaps()
{    if (pcaps == null) {        return new ArrayList<>();    } else {        return pcaps;    }}
0
public void setPcaps(List<byte[]> pcaps)
{    this.pcaps = pcaps;}
0
public int getResponseCode()
{    return responseCode;}
0
public String getMessage()
{    return message;}
0
public String getFullMessage()
{    return fullMessage;}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public SearchRequest getSearchRequest()
{    return searchRequest;}
0
public void setSearchRequest(SearchRequest searchRequest)
{    this.searchRequest = searchRequest;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SavedSearch that = (SavedSearch) o;    return name != null ? name.equals(that.name) : that.name == null && (searchRequest != null ? searchRequest.equals(that.searchRequest) : that.searchRequest == null);}
0
public int hashCode()
{    int result = name != null ? name.hashCode() : 0;    result = 31 * result + (searchRequest != null ? searchRequest.hashCode() : 0);    return result;}
0
public Map<String, Object> getSampleData()
{    if (sampleData == null) {        return new HashMap<>();    }    return sampleData;}
0
public void setSampleData(Map<String, Object> sampleData)
{    this.sampleData = sampleData;}
0
public SensorParserConfig getSensorParserConfig()
{    if (sensorParserConfig == null) {        return new SensorParserConfig();    }    return sensorParserConfig;}
0
public void setSensorParserConfig(SensorParserConfig sensorParserConfig)
{    this.sensorParserConfig = sensorParserConfig;}
0
public String getName()
{    return name;}
0
public String getDescription()
{    return description;}
0
public String[] getParams()
{    if (params == null) {        return new String[0];    }    return params;}
0
public String getReturns()
{    return returns;}
0
public String getId()
{    return id;}
0
public void setId(String id)
{    this.id = id;}
0
public String getHost()
{    return host;}
0
public void setHost(String host)
{    this.host = host;}
0
public String getUptime()
{    return uptime;}
0
public void setUptime(String upTime)
{    this.uptime = upTime;}
0
public int getSlotsTotal()
{    return slotsTotal;}
0
public void setSlotsTotal(int slotsTotal)
{    this.slotsTotal = slotsTotal;}
0
public int getSlotsUsed()
{    return slotsUsed;}
0
public void setSlotsUsed(int slotsUsed)
{    this.slotsUsed = slotsUsed;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SupervisorStatus that = (SupervisorStatus) o;    if (getSlotsTotal() != that.getSlotsTotal()) {        return false;    }    if (getSlotsUsed() != that.getSlotsUsed()) {        return false;    }    if (!getId().equals(that.getId())) {        return false;    }    if (!getHost().equals(that.getHost())) {        return false;    }    return getUptime().equals(that.getUptime());}
0
public int hashCode()
{    int result = id != null ? id.hashCode() : 0;    result = 31 * result + (host != null ? host.hashCode() : 0);    result = 31 * result + (uptime != null ? uptime.hashCode() : 0);    result = 31 * result + getSlotsTotal();    result = 31 * result + getSlotsUsed();    return result;}
0
public SupervisorStatus[] getSupervisors()
{    return supervisors;}
0
public void setSupervisors(SupervisorStatus[] supervisors)
{    this.supervisors = supervisors;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    SupervisorSummary that = (SupervisorSummary) o;    return supervisors != null ? Arrays.equals(supervisors, that.supervisors) : that.supervisors != null;}
0
public int hashCode()
{    return supervisors != null ? Arrays.hashCode(supervisors) : 0;}
0
public TopologyResponseCode getStatus()
{    return status;}
0
public String getMessage()
{    return message;}
0
public void setSuccessMessage(String message)
{    this.status = TopologyResponseCode.SUCCESS;    this.message = message;}
0
public void setErrorMessage(String message)
{    this.status = TopologyResponseCode.ERROR;    this.message = message;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    TopologyResponse that = (TopologyResponse) o;    if (status != null ? !status.equals(that.status) : that.status != null)        return false;    return message != null ? message.equals(that.message) : that.message == null;}
0
public int hashCode()
{    int result = status != null ? status.hashCode() : 0;    result = 31 * result + (message != null ? message.hashCode() : 0);    return result;}
0
public String getId()
{    return id;}
0
public void setId(String id)
{    this.id = id;}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public TopologyStatusCode getStatus()
{    return status;}
0
public void setStatus(TopologyStatusCode status)
{    this.status = status;}
0
public double getLatency()
{    return latency;}
0
public double getThroughput()
{    return throughput;}
0
public Integer getEmitted()
{    return emitted;}
0
public long getAcked()
{    return acked;}
0
public void setTopologyStats(List<Map<String, Object>> topologyStats)
{    for (Map<String, Object> topologyStatsItem : topologyStats) {        if ("600".equals(topologyStatsItem.get("window"))) {            latency = Double.parseDouble((String) topologyStatsItem.get("completeLatency"));            if (topologyStatsItem.get("acked") != null) {                acked = (int) topologyStatsItem.get("acked");            }            if (topologyStatsItem.get("emitted") != null) {                emitted = (int) topologyStatsItem.get("emitted");            }            throughput = acked / 600.00;        }    }}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    TopologyStatus that = (TopologyStatus) o;    if (id != null ? !id.equals(that.id) : that.id != null)        return false;    if (name != null ? !name.equals(that.name) : that.name != null)        return false;    if (status != null ? !status.equals(that.status) : that.status != null)        return false;    if (!latency.equals(that.latency))        return false;    return throughput.equals(that.throughput);}
0
public int hashCode()
{    int result = id != null ? id.hashCode() : 0;    result = 31 * result + (name != null ? name.hashCode() : 0);    result = 31 * result + (status != null ? status.hashCode() : 0);    result = 31 * result + (latency != null ? latency.hashCode() : 0);    result = 31 * result + (throughput != null ? throughput.hashCode() : 0);    return result;}
0
public TopologyStatus[] getTopologies()
{    if (topologies == null) {        return new TopologyStatus[0];    }    return topologies;}
0
public void setTopologies(TopologyStatus[] topologies)
{    this.topologies = topologies;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    TopologySummary that = (TopologySummary) o;    return topologies != null ? Arrays.equals(topologies, that.topologies) : that.topologies != null;}
0
public int hashCode()
{    return topologies != null ? Arrays.hashCode(topologies) : 0;}
0
public static int availableProcessors()
{    return NettyRuntime.availableProcessors();}
0
public Aggregator getAggregator()
{    return aggregator;}
0
private static double positiveMean(List<Number> list, Map<String, Object> config)
{    Double ret = 0d;    int num = 0;    boolean negValuesTrump = doNegativeValuesTrump(config);    for (Number n : list) {        if (n.doubleValue() < 0) {            if (negValuesTrump) {                return Double.NEGATIVE_INFINITY;            }        } else if (n.doubleValue() > 0) {            ret += n.doubleValue();            num++;        }    }    return num > 0 ? ret / num : 0d;}
0
private static boolean doNegativeValuesTrump(Map<String, Object> config)
{    boolean negativeValuesTrump = true;    Object negValuesObj = config.get(NEGATIVE_VALUES_TRUMP_CONF);    if (negValuesObj != null) {        Boolean b = ConversionUtils.convert(negValuesObj, Boolean.class);        if (b != null) {            negativeValuesTrump = b;        }    }    return negativeValuesTrump;}
0
private static double accumulate(double initial, BinaryOperator<Number> op, List<Number> list, Map<String, Object> config)
{    if (list.isEmpty()) {        return 0d;    }    boolean negativeValuesTrump = doNegativeValuesTrump(config);    BinaryOperator<Number> binOp = op;    if (negativeValuesTrump) {        binOp = (x, y) -> {            if (y.doubleValue() < 0 || x.doubleValue() < 0) {                return Double.NEGATIVE_INFINITY;            } else {                return op.apply(x, y);            }        };    }    return list.stream().reduce(initial, binOp).doubleValue();}
0
private static double scale(double numberToScale, List<Number> list, Predicate<Number> filterFunc)
{    double scale = list.stream().filter(filterFunc).count();    if (scale < 1e-5) {        scale = 1;    }    return numberToScale / scale;}
0
public Double aggregate(List<Number> scores, Map<String, Object> config)
{    return aggregator.aggregate(scores, config);}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (ConfigurationOptions.HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("configuration_manager", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (ConfigurationOptions o : ConfigurationOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public void dump(CuratorFramework client) throws Exception
{    ConfigurationsUtils.dumpConfigs(System.out, client);}
0
public void dump(CuratorFramework client, ConfigurationType type, Optional<String> configName) throws Exception
{    ConfigurationsUtils.dumpConfigs(System.out, client, type, configName);}
0
public void pull(CuratorFramework client, String outFileStr, final boolean force) throws Exception
{    final File outputDir = new File(outFileStr);    if (!outputDir.exists()) {        if (!outputDir.mkdirs()) {            throw new IllegalStateException("Unable to make directories: " + outputDir.getAbsolutePath());        }    }    ConfigurationsUtils.visitConfigs(client, new ConfigurationsUtils.ConfigurationVisitor() {        @Override        public void visit(ConfigurationType configurationType, String name, String data) {            File out = getFile(outputDir, configurationType, name);            if (!out.exists() || force) {                if (!out.exists()) {                    out.getParentFile().mkdirs();                }                try {                    Files.write(data, out, Charset.defaultCharset());                } catch (IOException e) {                    throw new RuntimeException("Sorry, something bad happened writing the config to " + out.getAbsolutePath() + ": " + e.getMessage(), e);                }            } else if (out.exists() && !force) {                throw new IllegalStateException("Unable to overwrite existing file (" + out.getAbsolutePath() + ") without the force flag (-f or --force) being set.");            }        }    });}
0
public void visit(ConfigurationType configurationType, String name, String data)
{    File out = getFile(outputDir, configurationType, name);    if (!out.exists() || force) {        if (!out.exists()) {            out.getParentFile().mkdirs();        }        try {            Files.write(data, out, Charset.defaultCharset());        } catch (IOException e) {            throw new RuntimeException("Sorry, something bad happened writing the config to " + out.getAbsolutePath() + ": " + e.getMessage(), e);        }    } else if (out.exists() && !force) {        throw new IllegalStateException("Unable to overwrite existing file (" + out.getAbsolutePath() + ") without the force flag (-f or --force) being set.");    }}
0
public void push(String inputDirStr, CuratorFramework client) throws Exception
{    final File inputDir = new File(inputDirStr);    if (!inputDir.exists() || !inputDir.isDirectory()) {        throw new IllegalStateException("Input directory: " + inputDir + " does not exist or is not a directory.");    }    ConfigurationsUtils.uploadConfigsToZookeeper(inputDirStr, client);}
0
public void push(String inputDirStr, CuratorFramework client, ConfigurationType type, Optional<String> configName) throws Exception
{    final File inputDir = new File(inputDirStr);    if (!inputDir.exists() || !inputDir.isDirectory()) {        throw new IllegalStateException("Input directory: " + inputDir + " does not exist or is not a directory.");    }    ConfigurationsUtils.uploadConfigsToZookeeper(inputDirStr, client, type, configName);}
0
public void run(CommandLine cli) throws Exception
{    try (CuratorFramework client = ConfigurationsUtils.getClient(ConfigurationOptions.ZK_QUORUM.get(cli))) {        client.start();        run(client, cli);    }}
0
public void run(CuratorFramework client, CommandLine cli) throws Exception
{    final boolean force = ConfigurationOptions.FORCE.has(cli);    String mode = ConfigurationOptions.MODE.get(cli);    Optional<String> configType = Optional.ofNullable(ConfigurationOptions.CONFIG_TYPE.get(cli));    Optional<String> configName = Optional.ofNullable(ConfigurationOptions.CONFIG_NAME.get(cli));    switch(mode.toLowerCase()) {        case "push":            String inputDirStr = ConfigurationOptions.INPUT.get(cli);            if (StringUtils.isEmpty(inputDirStr)) {                throw new IllegalArgumentException("Input directory is required when performing a PUSH operation.");            }            if (configType.isPresent()) {                push(inputDirStr, client, ConfigurationType.valueOf(configType.get()), configName);            } else {                push(inputDirStr, client);            }            break;        case "dump":            if (configType.isPresent()) {                dump(client, ConfigurationType.valueOf(configType.get()), configName);            } else {                dump(client);            }            break;        case "pull":            pull(client, ConfigurationOptions.OUTPUT.get(cli), force);            break;        case "patch":            if (configType.isPresent()) {                Optional<String> patchPath = Optional.ofNullable(ConfigurationOptions.PATCH_FILE.get(cli));                Optional<String> patchMode = Optional.ofNullable(ConfigurationOptions.PATCH_MODE.get(cli));                Optional<String> patchKey = Optional.ofNullable(ConfigurationOptions.PATCH_KEY.get(cli));                Optional<String> patchValue = Optional.ofNullable(ConfigurationOptions.PATCH_VALUE.get(cli));                patch(client, ConfigurationType.valueOf(configType.get()), configName, patchMode, patchPath, patchKey, patchValue);            } else {                throw new IllegalArgumentException("Patch requires config type");            }            break;        default:            throw new IllegalStateException("Invalid mode: " + mode + " expected DUMP, PULL, PUSH, or PATCH");    }}
0
private void patch(CuratorFramework client, ConfigurationType configType, Optional<String> configName, Optional<String> patchMode, Optional<String> patchPath, Optional<String> patchKey, Optional<String> patchValue) throws Exception
{    try {        byte[] patchData;        if (patchKey.isPresent()) {            patchData = buildPatch(patchMode, patchKey, patchValue).getBytes(StandardCharsets.UTF_8);        } else {            patchData = java.nio.file.Files.readAllBytes(Paths.get(patchPath.get()));        }        ConfigurationsUtils.applyConfigPatchToZookeeper(configType, configName, patchData, client);    } catch (IOException e) {                throw e;    } catch (Exception e) {                throw e;    }}
1
private String buildPatch(Optional<String> patchMode, Optional<String> patchKey, Optional<String> patchValue)
{    PatchMode mode = PatchMode.ADD;    if (patchMode.isPresent()) {        mode = PatchMode.valueOf(patchMode.get());    }    String patch = "";    switch(mode) {        case ADD:            if (!patchKey.isPresent() || !patchValue.isPresent()) {                throw new IllegalArgumentException("Key and value are required to apply patches without a file");            }            patch = String.format("[ { \"op\": \"%s\", \"path\": \"%s\", \"value\": %s } ]", patchMode.get().toString().toLowerCase(), patchKey.get(), patchValue.get());            break;        case REMOVE:            if (!patchKey.isPresent()) {                throw new IllegalArgumentException("Key is required to apply a remove patch without a file");            }            patch = String.format("[ { \"op\": \"%s\", \"path\": \"%s\" } ]", patchMode.get().toString().toLowerCase(), patchKey.get());            break;        default:            throw new UnsupportedOperationException("Patch mode not supported: " + mode.toString());    }    return patch;}
0
private static File getFile(File baseDir, ConfigurationType configurationType, String name)
{    return new File(new File(baseDir, configurationType.getDirectory()), name + ".json");}
0
public static void main(String... argv) throws Exception
{    CommandLineParser parser = new PosixParser();    CommandLine cli = ConfigurationOptions.parse(parser, argv);    ConfigurationManager manager = new ConfigurationManager();    manager.run(cli);}
0
 BiFunction<String, Object, Object> transform()
{    return (s, o) -> o;}
0
 boolean containsOption(Map<String, Object> map)
{    return map.containsKey(getKey());}
0
 void put(Map<String, Object> map, Object value)
{    map.put(getKey(), value);}
0
 T getOrDefault(Map<String, Object> map, Class<T> clazz, T defaultValue)
{    T val;    return ((val = get(map, clazz)) == null ? defaultValue : val);}
0
 T get(Map<String, Object> map, Class<T> clazz)
{    Object obj = map.get(getKey());    if (clazz.isInstance(obj)) {        return clazz.cast(obj);    } else {        return ConversionUtils.convert(obj, clazz);    }}
0
 T getOrDefault(Map<String, Object> map, BiFunction<String, Object, T> transform, Class<T> clazz, T defaultValue)
{    T val;    return ((val = get(map, transform, clazz)) == null ? defaultValue : val);}
0
 T get(Map<String, Object> map, BiFunction<String, Object, T> transform, Class<T> clazz)
{    return clazz.cast(transform.apply(getKey(), map.get(getKey())));}
0
 T getTransformedOrDefault(Map<String, Object> map, Class<T> clazz, T defaultValue)
{    T val;    return ((val = getTransformed(map, clazz)) == null ? defaultValue : val);}
0
 T getTransformed(Map<String, Object> map, Class<T> clazz)
{    return clazz.cast(transform().apply(getKey(), map.get(getKey())));}
0
public void update() throws Exception
{    if (null != curatorFramework) {        ConfigurationsUtils.updateConfigsFromZookeeper(this, this.curatorFramework);    } else {        updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile(configFileRoot.toAbsolutePath().toString()));    }}
0
 String getDirectory()
{    return getTypeName();}
0
 String getZookeeperRoot()
{    return Constants.ZOOKEEPER_TOPOLOGY_ROOT + "/" + getTypeName();}
0
public Map<String, Object> getConfigurations()
{    return configurations;}
0
public Map<String, Object> getGlobalConfig()
{    return getGlobalConfig(true);}
0
public Map<String, Object> getGlobalConfig(boolean emptyMapOnNonExistent)
{    return (Map<String, Object>) getConfigurations().getOrDefault(ConfigurationType.GLOBAL.getTypeName(), emptyMapOnNonExistent ? new HashMap() : null);}
0
public List<FieldValidator> getFieldValidations()
{    return validations;}
0
public void updateGlobalConfig(byte[] data) throws IOException
{    if (data == null)        throw new IllegalStateException("global config data cannot be null");    updateGlobalConfig(new ByteArrayInputStream(data));}
0
public void updateGlobalConfig(InputStream io) throws IOException
{    Map<String, Object> globalConfig = JSONUtils.INSTANCE.load(io, JSONUtils.MAP_SUPPLIER);    updateGlobalConfig(globalConfig);}
0
public void updateGlobalConfig(Map<String, Object> globalConfig)
{    if (globalConfig != null) {        getConfigurations().put(ConfigurationType.GLOBAL.getTypeName(), globalConfig);        validations = FieldValidator.readValidations(getGlobalConfig());    }}
0
public void deleteGlobalConfig()
{    getConfigurations().remove(ConfigurationType.GLOBAL.getTypeName());}
0
public static T getAs(String key, Map<String, Object> map, T defaultValue, Class<T> clazz)
{    return map == null ? defaultValue : ConversionUtils.convert(map.getOrDefault(key, defaultValue), clazz);}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Configurations that = (Configurations) o;    if (validations != null ? !validations.equals(that.validations) : that.validations != null)        return false;    return getConfigurations() != null ? getConfigurations().equals(that.getConfigurations()) : that.getConfigurations() == null;}
0
public int hashCode()
{    int result = validations != null ? validations.hashCode() : 0;    result = 31 * result + (getConfigurations() != null ? getConfigurations().hashCode() : 0);    return result;}
0
public String toString()
{    return "Configurations{" + "validations=" + validations + ", configurations=" + getConfigurations() + '}';}
0
public static CuratorFramework getClient(String zookeeperUrl)
{    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    return CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);}
0
public static void writeGlobalConfigToZookeeper(Map<String, Object> globalConfig, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeGlobalConfigToZookeeper(globalConfig, client);    }}
0
public static void writeGlobalConfigToZookeeper(Map<String, Object> globalConfig, CuratorFramework client) throws Exception
{    writeGlobalConfigToZookeeper(JSONUtils.INSTANCE.toJSONPretty(globalConfig), client);}
0
public static void writeGlobalConfigToZookeeper(byte[] globalConfig, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeGlobalConfigToZookeeper(globalConfig, client);    }}
0
public static void writeGlobalConfigToZookeeper(byte[] globalConfig, CuratorFramework client) throws Exception
{    GLOBAL.deserialize(new String(globalConfig, StandardCharsets.UTF_8));    writeToZookeeper(GLOBAL.getZookeeperRoot(), globalConfig, client);}
0
public static void writeProfilerConfigToZookeeper(byte[] config, CuratorFramework client) throws Exception
{    PROFILER.deserialize(new String(config, StandardCharsets.UTF_8));    writeToZookeeper(PROFILER.getZookeeperRoot(), config, client);}
0
public static void writeSensorParserConfigToZookeeper(String sensorType, SensorParserConfig sensorParserConfig, String zookeeperUrl) throws Exception
{    writeSensorParserConfigToZookeeper(sensorType, JSONUtils.INSTANCE.toJSONPretty(sensorParserConfig), zookeeperUrl);}
0
public static void writeSensorParserConfigToZookeeper(String sensorType, byte[] configData, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeSensorParserConfigToZookeeper(sensorType, configData, client);    }}
0
public static void writeSensorParserConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    SensorParserConfig c = (SensorParserConfig) PARSER.deserialize(new String(configData, StandardCharsets.UTF_8));    c.init();    writeToZookeeper(PARSER.getZookeeperRoot() + "/" + sensorType, configData, client);}
0
public static void writeSensorIndexingConfigToZookeeper(String sensorType, Map<String, Object> sensorIndexingConfig, String zookeeperUrl) throws Exception
{    writeSensorIndexingConfigToZookeeper(sensorType, JSONUtils.INSTANCE.toJSONPretty(sensorIndexingConfig), zookeeperUrl);}
0
public static void writeSensorIndexingConfigToZookeeper(String sensorType, byte[] configData, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeSensorIndexingConfigToZookeeper(sensorType, configData, client);    }}
0
public static void writeSensorIndexingConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    INDEXING.deserialize(new String(configData, StandardCharsets.UTF_8));    writeToZookeeper(INDEXING.getZookeeperRoot() + "/" + sensorType, configData, client);}
0
public static void writeSensorEnrichmentConfigToZookeeper(String sensorType, SensorEnrichmentConfig sensorEnrichmentConfig, String zookeeperUrl) throws Exception
{    writeSensorEnrichmentConfigToZookeeper(sensorType, JSONUtils.INSTANCE.toJSONPretty(sensorEnrichmentConfig), zookeeperUrl);}
0
public static void writeSensorEnrichmentConfigToZookeeper(String sensorType, byte[] configData, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeSensorEnrichmentConfigToZookeeper(sensorType, configData, client);    }}
0
public static void writeSensorEnrichmentConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    ENRICHMENT.deserialize(new String(configData, StandardCharsets.UTF_8));    writeToZookeeper(ENRICHMENT.getZookeeperRoot() + "/" + sensorType, configData, client);}
0
public static void writeConfigToZookeeper(String name, Map<String, Object> config, String zookeeperUrl) throws Exception
{    writeConfigToZookeeper(Constants.ZOOKEEPER_TOPOLOGY_ROOT + "/" + name, JSONUtils.INSTANCE.toJSONPretty(config), zookeeperUrl);}
0
public static void writeConfigToZookeeper(ConfigurationType configType, byte[] configData, String zookeeperUrl) throws Exception
{    writeConfigToZookeeper(configType, Optional.empty(), configData, zookeeperUrl);}
0
public static void writeConfigToZookeeper(ConfigurationType configType, Optional<String> configName, byte[] configData, String zookeeperUrl) throws Exception
{    writeConfigToZookeeper(getConfigZKPath(configType, configName), configData, zookeeperUrl);}
0
public static void writeConfigToZookeeper(ConfigurationType configType, Optional<String> configName, byte[] configData, CuratorFramework client) throws Exception
{    writeToZookeeper(getConfigZKPath(configType, configName), configData, client);}
0
private static String getConfigZKPath(ConfigurationType configType, Optional<String> configName)
{    String pathSuffix = configName.isPresent() && configType != GLOBAL ? "/" + configName.get() : "";    return configType.getZookeeperRoot() + pathSuffix;}
0
public static void writeConfigToZookeeper(String configPath, byte[] config, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeToZookeeper(configPath, config, client);    }}
0
public static void writeToZookeeper(String path, byte[] configData, CuratorFramework client) throws Exception
{    try {        client.setData().forPath(path, configData);    } catch (KeeperException.NoNodeException e) {        client.create().creatingParentsIfNeeded().forPath(path, configData);    }}
0
public static void updateConfigsFromZookeeper(Configurations configurations, CuratorFramework client) throws Exception
{    configurations.updateGlobalConfig(readGlobalConfigBytesFromZookeeper(client));}
0
private static void updateConfigsFromZookeeper(Configurations configurations, ConfigurationType type, Callback callback, CuratorFramework client) throws Exception
{    Exception globalUpdateException = null;    try {        updateConfigsFromZookeeper(configurations, client);    } catch (Exception e) {                globalUpdateException = e;    }    List<String> sensorTypes = client.getChildren().forPath(type.getZookeeperRoot());    for (String sensorType : sensorTypes) {        callback.apply(sensorType);    }    if (globalUpdateException != null) {        throw globalUpdateException;    }}
1
public static void updateParserConfigsFromZookeeper(ParserConfigurations configurations, CuratorFramework client) throws Exception
{    updateConfigsFromZookeeper(configurations, PARSER, sensorType -> configurations.updateSensorParserConfig(sensorType, readSensorParserConfigBytesFromZookeeper(sensorType, client)), client);}
0
public static void updateSensorIndexingConfigsFromZookeeper(IndexingConfigurations configurations, CuratorFramework client) throws Exception
{    updateConfigsFromZookeeper(configurations, INDEXING, sensorType -> configurations.updateSensorIndexingConfig(sensorType, readSensorIndexingConfigBytesFromZookeeper(sensorType, client)), client);}
0
public static void updateEnrichmentConfigsFromZookeeper(EnrichmentConfigurations configurations, CuratorFramework client) throws Exception
{    updateConfigsFromZookeeper(configurations, ENRICHMENT, sensorType -> configurations.updateSensorEnrichmentConfig(sensorType, readSensorEnrichmentConfigBytesFromZookeeper(sensorType, client)), client);}
0
public static Map<String, Object> readGlobalConfigFromZookeeper(CuratorFramework client) throws Exception
{    Map<String, Object> config = null;    Optional<byte[]> bytes = readFromZookeeperSafely(GLOBAL.getZookeeperRoot(), client);    if (bytes.isPresent()) {        InputStream in = new ByteArrayInputStream(bytes.get());        config = JSONUtils.INSTANCE.load(in, JSONUtils.MAP_SUPPLIER);    }    return config;}
0
public static Map<String, Object> readSensorIndexingConfigFromZookeeper(String sensorType, CuratorFramework client) throws Exception
{    Map<String, Object> config = null;    Optional<byte[]> bytes = readFromZookeeperSafely(INDEXING.getZookeeperRoot() + "/" + sensorType, client);    if (bytes.isPresent()) {        InputStream in = new ByteArrayInputStream(bytes.get());        config = JSONUtils.INSTANCE.load(in, JSONUtils.MAP_SUPPLIER);    }    return config;}
0
public static SensorEnrichmentConfig readSensorEnrichmentConfigFromZookeeper(String sensorType, CuratorFramework client) throws Exception
{    SensorEnrichmentConfig config = null;    Optional<byte[]> bytes = readFromZookeeperSafely(ENRICHMENT.getZookeeperRoot() + "/" + sensorType, client);    if (bytes.isPresent()) {        config = SensorEnrichmentConfig.fromBytes(bytes.get());    }    return config;}
0
public static SensorParserConfig readSensorParserConfigFromZookeeper(String sensorType, CuratorFramework client) throws Exception
{    SensorParserConfig config = null;    Optional<byte[]> bytes = readFromZookeeperSafely(PARSER.getZookeeperRoot() + "/" + sensorType, client);    if (bytes.isPresent()) {        config = SensorParserConfig.fromBytes(bytes.get());    }    return config;}
0
public static ProfilerConfig readProfilerConfigFromZookeeper(CuratorFramework client) throws Exception
{    ProfilerConfig config = null;    Optional<byte[]> bytes = readFromZookeeperSafely(PROFILER.getZookeeperRoot(), client);    if (bytes.isPresent()) {        config = ProfilerConfig.fromBytes(bytes.get());    }    return config;}
0
public static byte[] readGlobalConfigBytesFromZookeeper(CuratorFramework client) throws Exception
{    return readFromZookeeper(GLOBAL.getZookeeperRoot(), client);}
0
public static byte[] readProfilerConfigBytesFromZookeeper(CuratorFramework client) throws Exception
{    return readFromZookeeper(PROFILER.getZookeeperRoot(), client);}
0
public static byte[] readSensorIndexingConfigBytesFromZookeeper(String sensorType, CuratorFramework client) throws Exception
{    return readFromZookeeper(INDEXING.getZookeeperRoot() + "/" + sensorType, client);}
0
public static byte[] readSensorParserConfigBytesFromZookeeper(String sensorType, CuratorFramework client) throws Exception
{    return readFromZookeeper(PARSER.getZookeeperRoot() + "/" + sensorType, client);}
0
public static byte[] readSensorEnrichmentConfigBytesFromZookeeper(String sensorType, CuratorFramework client) throws Exception
{    return readFromZookeeper(ENRICHMENT.getZookeeperRoot() + "/" + sensorType, client);}
0
public static byte[] readConfigBytesFromZookeeper(String name, CuratorFramework client) throws Exception
{    return readFromZookeeper(Constants.ZOOKEEPER_TOPOLOGY_ROOT + "/" + name, client);}
0
public static byte[] readConfigBytesFromZookeeper(ConfigurationType configType, String zookeeperUrl) throws Exception
{    return readConfigBytesFromZookeeper(configType, Optional.empty(), zookeeperUrl);}
0
public static byte[] readConfigBytesFromZookeeper(ConfigurationType configType, Optional<String> configName, CuratorFramework client) throws Exception
{    return readFromZookeeper(getConfigZKPath(configType, configName), client);}
0
public static byte[] readConfigBytesFromZookeeper(ConfigurationType configType, Optional<String> configName, String zookeeperUrl) throws Exception
{    return readFromZookeeper(getConfigZKPath(configType, configName), zookeeperUrl);}
0
public static byte[] readFromZookeeper(String path, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        return readFromZookeeper(path, client);    }}
0
public static byte[] readFromZookeeper(String path, CuratorFramework client) throws Exception
{    if (client != null && client.getData() != null && path != null) {        return client.getData().forPath(path);    }    return new byte[] {};}
0
public static void uploadConfigsToZookeeper(String globalConfigPath, String parsersConfigPath, String enrichmentsConfigPath, String indexingConfigPath, String profilerConfigPath, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        uploadConfigsToZookeeper(globalConfigPath, parsersConfigPath, enrichmentsConfigPath, indexingConfigPath, profilerConfigPath, client);    }}
0
public static void uploadConfigsToZookeeper(String rootFilePath, CuratorFramework client) throws Exception
{    uploadConfigsToZookeeper(rootFilePath, rootFilePath, rootFilePath, rootFilePath, rootFilePath, client);}
0
public static void uploadConfigsToZookeeper(String rootFilePath, CuratorFramework client, ConfigurationType type) throws Exception
{    uploadConfigsToZookeeper(rootFilePath, client, type, Optional.empty());}
0
public static void uploadConfigsToZookeeper(String rootFilePath, CuratorFramework client, ConfigurationType type, Optional<String> configName) throws Exception
{    switch(type) {        case GLOBAL:            final byte[] globalConfig = readGlobalConfigFromFile(rootFilePath);            if (globalConfig.length > 0) {                setupStellarStatically(client, Optional.of(new String(globalConfig, StandardCharsets.UTF_8)));                writeGlobalConfigToZookeeper(globalConfig, client);            }            break;                case PARSER:                case ENRICHMENT:        case         INDEXING:            {                Map<String, byte[]> configs = readSensorConfigsFromFile(rootFilePath, type, configName);                for (String sensorType : configs.keySet()) {                    byte[] configData = configs.get(sensorType);                    type.writeSensorConfigToZookeeper(sensorType, configData, client);                }                break;            }        case PROFILER:            {                byte[] configData = readProfilerConfigFromFile(rootFilePath);                if (configData.length > 0) {                    ConfigurationsUtils.writeProfilerConfigToZookeeper(configData, client);                }                break;            }        default:            throw new IllegalArgumentException("Configuration type not found: " + type);    }}
0
public static void uploadConfigsToZookeeper(String globalConfigPath, String parsersConfigPath, String enrichmentsConfigPath, String indexingConfigPath, String profilerConfigPath, CuratorFramework client) throws Exception
{        if (globalConfigPath != null) {        final byte[] globalConfig = readGlobalConfigFromFile(globalConfigPath);        if (globalConfig.length > 0) {            setupStellarStatically(client, Optional.of(new String(globalConfig, StandardCharsets.UTF_8)));            ConfigurationsUtils.writeGlobalConfigToZookeeper(readGlobalConfigFromFile(globalConfigPath), client);        }    }        if (parsersConfigPath != null) {        Map<String, byte[]> sensorParserConfigs = readSensorParserConfigsFromFile(parsersConfigPath);        for (String sensorType : sensorParserConfigs.keySet()) {            ConfigurationsUtils.writeSensorParserConfigToZookeeper(sensorType, sensorParserConfigs.get(sensorType), client);        }    }        if (indexingConfigPath != null) {        Map<String, byte[]> sensorIndexingConfigs = readSensorIndexingConfigsFromFile(indexingConfigPath);        for (String sensorType : sensorIndexingConfigs.keySet()) {            ConfigurationsUtils.writeSensorIndexingConfigToZookeeper(sensorType, sensorIndexingConfigs.get(sensorType), client);        }    }        if (enrichmentsConfigPath != null) {        Map<String, byte[]> sensorEnrichmentConfigs = readSensorEnrichmentConfigsFromFile(enrichmentsConfigPath);        for (String sensorType : sensorEnrichmentConfigs.keySet()) {            ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(sensorType, sensorEnrichmentConfigs.get(sensorType), client);        }    }        if (profilerConfigPath != null) {        byte[] profilerConfig = readProfilerConfigFromFile(profilerConfigPath);        if (profilerConfig.length > 0) {            ConfigurationsUtils.writeProfilerConfigToZookeeper(profilerConfig, client);        }    }}
0
public static void setupStellarStatically(CuratorFramework client) throws Exception
{    byte[] ret = null;    try {        ret = readGlobalConfigBytesFromZookeeper(client);    } catch (KeeperException.NoNodeException nne) {        }    if (ret == null || ret.length == 0) {        setupStellarStatically(client, Optional.empty());    } else {        setupStellarStatically(client, Optional.of(new String(ret, StandardCharsets.UTF_8)));    }}
0
public static void setupStellarStatically(CuratorFramework client, Optional<String> globalConfig)
{    /*      In order to validate stellar functions, the function resolver must be initialized.  Otherwise,      those utilities that require validation cannot validate the stellar expressions necessarily.    */    Context.Builder builder = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client);    if (globalConfig.isPresent()) {        builder = builder.with(Context.Capabilities.GLOBAL_CONFIG, () -> GLOBAL.deserialize(globalConfig.get())).with(Context.Capabilities.STELLAR_CONFIG, () -> GLOBAL.deserialize(globalConfig.get()));    } else {        builder = builder.with(Context.Capabilities.STELLAR_CONFIG, () -> new HashMap<>());    }    Context stellarContext = builder.build();    StellarFunctions.FUNCTION_RESOLVER().initialize(stellarContext);}
0
public static byte[] readGlobalConfigFromFile(String rootPath) throws IOException
{    byte[] globalConfig = new byte[0];    File configPath = new File(rootPath, GLOBAL.getTypeName() + ".json");    if (configPath.exists()) {        globalConfig = Files.readAllBytes(configPath.toPath());    }    return globalConfig;}
0
public static Map<String, byte[]> readSensorParserConfigsFromFile(String rootPath) throws IOException
{    return readSensorConfigsFromFile(rootPath, PARSER, Optional.empty());}
0
public static Map<String, byte[]> readSensorEnrichmentConfigsFromFile(String rootPath) throws IOException
{    return readSensorConfigsFromFile(rootPath, ENRICHMENT, Optional.empty());}
0
public static Map<String, byte[]> readSensorIndexingConfigsFromFile(String rootPath) throws IOException
{    return readSensorConfigsFromFile(rootPath, INDEXING, Optional.empty());}
0
public static byte[] readProfilerConfigFromFile(String rootPath) throws IOException
{    byte[] config = new byte[0];    File configPath = new File(rootPath, PROFILER.getTypeName() + ".json");    if (configPath.exists()) {        config = Files.readAllBytes(configPath.toPath());    }    return config;}
0
public static Map<String, byte[]> readSensorConfigsFromFile(String rootPath, ConfigurationType configType) throws IOException
{    return readSensorConfigsFromFile(rootPath, configType, Optional.empty());}
0
public static Map<String, byte[]> readSensorConfigsFromFile(String rootPath, ConfigurationType configType, Optional<String> configName) throws IOException
{    Map<String, byte[]> sensorConfigs = new HashMap<>();    File configPath = new File(rootPath, configType.getDirectory());    if (configPath.exists() && configPath.isDirectory()) {        File[] children = configPath.listFiles();        if (!configName.isPresent()) {            for (File file : children) {                sensorConfigs.put(FilenameUtils.removeExtension(file.getName()), Files.readAllBytes(file.toPath()));            }        } else {            for (File file : children) {                if (FilenameUtils.removeExtension(file.getName()).equals(configName.get())) {                    sensorConfigs.put(FilenameUtils.removeExtension(file.getName()), Files.readAllBytes(file.toPath()));                }            }            if (sensorConfigs.isEmpty()) {                throw new RuntimeException("Unable to find configuration for " + configName.get());            }        }    }    return sensorConfigs;}
0
public static void applyConfigPatchToZookeeper(ConfigurationType configurationType, byte[] patchData, String zookeeperUrl) throws Exception
{    applyConfigPatchToZookeeper(configurationType, Optional.empty(), patchData, zookeeperUrl);}
0
public static void applyConfigPatchToZookeeper(ConfigurationType configurationType, Optional<String> configName, byte[] patchData, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        applyConfigPatchToZookeeper(configurationType, configName, patchData, client);    }}
0
public static void applyConfigPatchToZookeeper(ConfigurationType configurationType, Optional<String> configName, byte[] patchData, CuratorFramework client) throws Exception
{    byte[] configData = readConfigBytesFromZookeeper(configurationType, configName, client);    byte[] prettyPatchedConfig = JSONUtils.INSTANCE.applyPatch(patchData, configData);        String prettyPatchedConfigStr = new String(prettyPatchedConfig, StandardCharsets.UTF_8);    configurationType.deserialize(prettyPatchedConfigStr);    writeConfigToZookeeper(configurationType, configName, prettyPatchedConfig, client);}
0
public static void visitConfigs(CuratorFramework client, final ConfigurationVisitor callback) throws Exception
{    visitConfigs(client, (type, name, data) -> {        setupStellarStatically(client, Optional.ofNullable(data));        callback.visit(type, name, data);    }, GLOBAL, Optional.empty());    visitConfigs(client, callback, PARSER, Optional.empty());    visitConfigs(client, callback, INDEXING, Optional.empty());    visitConfigs(client, callback, ENRICHMENT, Optional.empty());    visitConfigs(client, callback, PROFILER, Optional.empty());}
0
public static void visitConfigs(CuratorFramework client, ConfigurationVisitor callback, ConfigurationType configType, Optional<String> configName) throws Exception
{    if (client.checkExists().forPath(configType.getZookeeperRoot()) != null) {        if (configType.equals(GLOBAL)) {            byte[] globalConfigData = client.getData().forPath(configType.getZookeeperRoot());            callback.visit(configType, "global", new String(globalConfigData, StandardCharsets.UTF_8));        } else if (configType.equals(PROFILER)) {            byte[] profilerConfigData = client.getData().forPath(configType.getZookeeperRoot());            callback.visit(configType, "profiler", new String(profilerConfigData, StandardCharsets.UTF_8));        } else if (configType.equals(PARSER) || configType.equals(ENRICHMENT) || configType.equals(INDEXING)) {            if (configName.isPresent()) {                byte[] data = readConfigBytesFromZookeeper(configType, configName, client);                callback.visit(configType, configName.get(), new String(data, StandardCharsets.UTF_8));            } else {                List<String> children = client.getChildren().forPath(configType.getZookeeperRoot());                for (String child : children) {                    byte[] data = client.getData().forPath(configType.getZookeeperRoot() + "/" + child);                    callback.visit(configType, child, new String(data, StandardCharsets.UTF_8));                }            }        }    }}
0
public static void dumpConfigs(PrintStream out, CuratorFramework client) throws Exception
{    ConfigurationsUtils.visitConfigs(client, (type, name, data) -> {        type.deserialize(data);        out.println(type + " Config: " + name + System.lineSeparator() + data);    });}
0
public static void dumpConfigs(PrintStream out, CuratorFramework client, ConfigurationType configType, Optional<String> configName) throws Exception
{    ConfigurationsUtils.visitConfigs(client, (type, name, data) -> {        setupStellarStatically(client, Optional.ofNullable(data));        type.deserialize(data);        out.println(type + " Config: " + name + System.lineSeparator() + data);    }, configType, configName);}
0
public static String getFieldName(Map<String, Object> globalConfig, String globalConfigKey, String defaultFieldName)
{    if (globalConfig == null) {        return defaultFieldName;    }    return (String) globalConfig.getOrDefault(globalConfigKey, defaultFieldName);}
0
public String getTypeName()
{    return ops.getTypeName();}
0
public String getDirectory()
{    return ops.getDirectory();}
0
public Object deserialize(String s)
{    try {        return ops.deserialize(s);    } catch (IOException e) {        throw new RuntimeException("Unable to load " + s, e);    }}
0
public Object apply(String s)
{    return deserialize(s);}
0
public void writeSensorConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    ops.writeSensorConfigToZookeeper(sensorType, configData, client);}
0
public String getZookeeperRoot()
{    return ops.getZookeeperRoot();}
0
public Map<String, Object> getConfig()
{    return config;}
0
public void setConfig(Map<String, Object> config)
{    this.config = config;}
0
public Map<String, Object> getFieldMap()
{    return fieldMap;}
0
public Map<String, ConfigHandler> getEnrichmentConfigs()
{    return enrichmentConfigs;}
0
public void setFieldMap(Map<String, Object> fieldMap)
{    this.fieldMap = fieldMap;    for (Map.Entry<String, Object> kv : fieldMap.entrySet()) {        if (kv.getValue() instanceof List) {            enrichmentConfigs.put(kv.getKey(), new ConfigHandler((List<String>) kv.getValue()));        } else {            enrichmentConfigs.put(kv.getKey(), new ConfigHandler(kv.getKey(), (Map<String, Object>) kv.getValue()));        }    }}
0
public Map<String, List<String>> getFieldToTypeMap()
{    return fieldToTypeMap;}
0
public void setFieldToTypeMap(Map<String, List<String>> fieldToTypeMap)
{    this.fieldToTypeMap = fieldToTypeMap;}
0
public String toString()
{    return "EnrichmentConfig{" + "fieldMap=" + fieldMap + ", fieldToTypeMap=" + fieldToTypeMap + ", config=" + config + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    EnrichmentConfig that = (EnrichmentConfig) o;    if (getFieldMap() != null ? !getFieldMap().equals(that.getFieldMap()) : that.getFieldMap() != null)        return false;    if (getFieldToTypeMap() != null ? !getFieldToTypeMap().equals(that.getFieldToTypeMap()) : that.getFieldToTypeMap() != null)        return false;    return getConfig() != null ? getConfig().equals(that.getConfig()) : that.getConfig() == null;}
0
public int hashCode()
{    int result = getFieldMap() != null ? getFieldMap().hashCode() : 0;    result = 31 * result + (getFieldToTypeMap() != null ? getFieldToTypeMap().hashCode() : 0);    result = 31 * result + (getConfig() != null ? getConfig().hashCode() : 0);    return result;}
0
 List<JSONObject> splitByFields(JSONObject message, Object fields, Function<String, String> fieldToEnrichmentKey, ConfigHandler handler)
{    return splitByFields(message, fields, fieldToEnrichmentKey, handler.getType().toConfig(handler.getConfig()));}
0
 List<String> getSubgroups(ConfigHandler handler)
{    return getSubgroups(handler.getType().toConfig(handler.getConfig()));}
0
public Object getConfig()
{    return config;}
0
public void setConfig(Object config)
{    this.config = config;}
0
public Configs getType()
{    return type;}
0
public void setType(Configs retriever)
{    this.type = retriever;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ConfigHandler that = (ConfigHandler) o;    if (getConfig() != null ? !getConfig().equals(that.getConfig()) : that.getConfig() != null)        return false;    return getType() != null ? getType().equals(that.getType()) : that.getType() == null;}
0
public int hashCode()
{    int result = getConfig() != null ? getConfig().hashCode() : 0;    result = 31 * result + (getType() != null ? getType().hashCode() : 0);    return result;}
0
public List<JSONObject> splitByFields(JSONObject message, Object fields, Function<String, String> fieldToEnrichmentKey, Iterable<Map.Entry<String, Object>> config)
{    return configCreator.splitByFields(message, fields, fieldToEnrichmentKey, config);}
0
public List<String> getSubgroups(Iterable<Map.Entry<String, Object>> config)
{    return configCreator.getSubgroups(config);}
0
public Iterable<Map.Entry<String, Object>> toConfig(Object c)
{    return configCreator.toConfig(c);}
0
public List<JSONObject> splitByFields(JSONObject message, Object fieldsObj, Function<String, String> fieldToEnrichmentKey, Iterable<Map.Entry<String, Object>> config)
{    List<String> fields = (List<String>) fieldsObj;    JSONObject enrichmentObject = new JSONObject();    if (fields != null && fields.size() > 0) {        for (String field : fields) {            enrichmentObject.put(fieldToEnrichmentKey.apply(field), message.get(field));        }    }    return ImmutableList.of(enrichmentObject);}
0
public List<String> getSubgroups(Iterable<Map.Entry<String, Object>> config)
{    return ImmutableList.of("");}
0
public Iterable<Map.Entry<String, Object>> toConfig(Object c)
{    if (c instanceof Map) {        return ((Map<String, Object>) c).entrySet();    } else {        return new ArrayList<>();    }}
0
public List<String> getSubgroups(Iterable<Map.Entry<String, Object>> config)
{    boolean includeEmpty = false;    List<String> ret = new ArrayList<>();    for (Map.Entry<String, Object> kv : config) {        if (kv.getValue() instanceof String) {            includeEmpty = true;        } else if (kv.getValue() instanceof Map || kv.getValue() instanceof List) {            ret.add(kv.getKey());        }    }    if (includeEmpty) {        ret.add("");    }    return ret;}
0
public Iterable<Map.Entry<String, Object>> toConfig(Object c)
{    if (c instanceof Map) {        return ((Map<String, Object>) c).entrySet();    } else if (c instanceof Collection) {        List<Map.Entry<String, Object>> ret = new ArrayList<>();        for (Object o : (Collection) c) {            if (o instanceof String) {                StellarAssignment assignment = StellarAssignment.from((String) o);                ret.add(assignment);            } else if (o instanceof Map.Entry) {                ret.add((Map.Entry<String, Object>) o);            } else {                throw new IllegalStateException("Expected " + c + " to be a list of strings, but got non-string.");            }        }        return ret;    }    throw new IllegalStateException("Unable to convert config " + c + " to stellar config.  Expected List<String> or Map<String, Object>");}
0
private Set<String> getFields(StellarProcessor processor, List<String> stellarStatementGroup)
{    Set<String> stellarFields = new HashSet<>();    for (String stellarStatementExpr : stellarStatementGroup) {        StellarAssignment assignment = StellarAssignment.from(stellarStatementExpr);        if (assignment.getStatement() != null) {            Set<String> variables = processor.variablesUsed(assignment.getStatement());            if (variables != null) {                stellarFields.addAll(variables);            }        }    }    return stellarFields;}
0
private Set<String> getFields(StellarProcessor processor, Map<String, String> stellarStatementGroup)
{    Set<String> stellarFields = new HashSet<>();    for (String stellarStatement : stellarStatementGroup.values()) {        Set<String> variables = processor.variablesUsed(stellarStatement);        if (variables != null) {            stellarFields.addAll(variables);        }    }    return stellarFields;}
0
private Map<String, Object> getMessage(Set<String> stellarFields, JSONObject message)
{    Map<String, Object> messageSegment = new HashMap<>();    if (stellarFields.contains(VariableResolver.ALL_FIELDS)) {                messageSegment.putAll(message);    } else {        for (String variable : stellarFields) {            messageSegment.put(variable, message.get(variable));        }    }    return messageSegment;}
0
public Map<String, Object> getConfiguration()
{    return configuration;}
0
public void setConfiguration(Map<String, Object> configuration)
{    this.configuration = configuration;}
0
public EnrichmentConfig getEnrichment()
{    return enrichment;}
0
public void setEnrichment(EnrichmentConfig enrichment)
{    this.enrichment = enrichment;}
0
public ThreatIntelConfig getThreatIntel()
{    return threatIntel;}
0
public void setThreatIntel(ThreatIntelConfig threatIntel)
{    this.threatIntel = threatIntel;}
0
public String toString()
{    return "SensorEnrichmentConfig{" + ", enrichment=" + enrichment + ", threatIntel=" + threatIntel + ", configuration=" + configuration + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    SensorEnrichmentConfig that = (SensorEnrichmentConfig) o;    if (getEnrichment() != null ? !getEnrichment().equals(that.getEnrichment()) : that.getEnrichment() != null)        return false;    if (getThreatIntel() != null ? !getThreatIntel().equals(that.getThreatIntel()) : that.getThreatIntel() != null)        return false;    return getConfiguration() != null ? getConfiguration().equals(that.getConfiguration()) : that.getConfiguration() == null;}
0
public int hashCode()
{    int result = getEnrichment() != null ? getEnrichment().hashCode() : 0;    result = 31 * result + (getEnrichment() != null ? getEnrichment().hashCode() : 0);    result = 31 * result + (getThreatIntel() != null ? getThreatIntel().hashCode() : 0);    result = 31 * result + (getConfiguration() != null ? getConfiguration().hashCode() : 0);    return result;}
0
public static SensorEnrichmentConfig fromBytes(byte[] config) throws IOException
{    return JSONUtils.INSTANCE.load(new String(config, StandardCharsets.UTF_8), SensorEnrichmentConfig.class);}
0
public String toJSON() throws JsonProcessingException
{    return JSONUtils.INSTANCE.toJSON(this, true);}
0
public Type getType()
{    return type;}
0
public void setType(Type type)
{    this.type = type;}
0
public Map<String, List<String>> getFieldToEnrichmentTypes()
{    return fieldToEnrichmentTypes;}
0
public void setFieldToEnrichmentTypes(Map<String, List<String>> fieldToEnrichmentTypes)
{    this.fieldToEnrichmentTypes = fieldToEnrichmentTypes;}
0
public String getZkQuorum()
{    return zkQuorum;}
0
public void setZkQuorum(String zkQuorum)
{    this.zkQuorum = zkQuorum;}
0
public Map<String, FieldList> getSensorToFieldList()
{    return sensorToFieldList;}
0
public void setSensorToFieldList(Map<String, FieldList> sensorToFieldList)
{    this.sensorToFieldList = sensorToFieldList;}
0
public void updateSensorConfigs() throws Exception
{    CuratorFramework client = ConfigurationsUtils.getClient(getZkQuorum());    try {        client.start();        updateSensorConfigs(new ZKSourceConfigHandler(client), sensorToFieldList);    } finally {        client.close();    }}
0
public SensorEnrichmentConfig readConfig(String sensor) throws Exception
{    SensorEnrichmentConfig sensorEnrichmentConfig = new SensorEnrichmentConfig();    try {        sensorEnrichmentConfig = SensorEnrichmentConfig.fromBytes(ConfigurationsUtils.readSensorEnrichmentConfigBytesFromZookeeper(sensor, client));    } catch (KeeperException.NoNodeException e) {    }    return sensorEnrichmentConfig;}
0
public void persistConfig(String sensor, SensorEnrichmentConfig config) throws Exception
{    ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(sensor, config.toJSON().getBytes(StandardCharsets.UTF_8), client);}
0
public static void updateSensorConfigs(SourceConfigHandler scHandler, Map<String, FieldList> sensorToFieldList) throws Exception
{    Map<String, SensorEnrichmentConfig> sourceConfigsChanged = new HashMap<>();    for (Map.Entry<String, FieldList> kv : sensorToFieldList.entrySet()) {        SensorEnrichmentConfig config = findConfigBySensorType(scHandler, sourceConfigsChanged, kv.getKey());        Map<String, Object> fieldMap = null;        Map<String, List<String>> fieldToTypeMap = null;        List<String> fieldList = null;        if (kv.getValue().type == Type.THREAT_INTEL) {            fieldMap = config.getThreatIntel().getFieldMap();            if (fieldMap != null) {                fieldList = (List<String>) fieldMap.get(Constants.SIMPLE_HBASE_THREAT_INTEL);            } else {                fieldMap = new HashMap<>();            }            if (fieldList == null) {                fieldList = new ArrayList<>();                fieldMap.put(Constants.SIMPLE_HBASE_THREAT_INTEL, fieldList);            }            fieldToTypeMap = config.getThreatIntel().getFieldToTypeMap();            if (fieldToTypeMap == null) {                fieldToTypeMap = new HashMap<>();                config.getThreatIntel().setFieldToTypeMap(fieldToTypeMap);            }        } else if (kv.getValue().type == Type.ENRICHMENT) {            fieldMap = config.getEnrichment().getFieldMap();            if (fieldMap != null) {                fieldList = (List<String>) fieldMap.get(Constants.SIMPLE_HBASE_ENRICHMENT);            } else {                fieldMap = new HashMap<>();            }            if (fieldList == null) {                fieldList = new ArrayList<>();                fieldMap.put(Constants.SIMPLE_HBASE_ENRICHMENT, fieldList);            }            fieldToTypeMap = config.getEnrichment().getFieldToTypeMap();            if (fieldToTypeMap == null) {                fieldToTypeMap = new HashMap<>();                config.getEnrichment().setFieldToTypeMap(fieldToTypeMap);            }        }        if (fieldToTypeMap == null || fieldMap == null) {                        continue;        }                {            HashSet<String> fieldSet = new HashSet<>(fieldList);            List<String> additionalFields = new ArrayList<>();            for (String field : kv.getValue().getFieldToEnrichmentTypes().keySet()) {                if (!fieldSet.contains(field)) {                    additionalFields.add(field);                }            }                        if (additionalFields.size() > 0) {                                fieldList.addAll(additionalFields);                sourceConfigsChanged.put(kv.getKey(), config);            }        }                {            for (Map.Entry<String, List<String>> fieldToType : kv.getValue().getFieldToEnrichmentTypes().entrySet()) {                String field = fieldToType.getKey();                final HashSet<String> types = new HashSet<>(fieldToType.getValue());                int sizeBefore = 0;                if (fieldToTypeMap.containsKey(field)) {                    List<String> typeList = (List<String>) fieldToTypeMap.get(field);                    sizeBefore = new HashSet<>(typeList).size();                    types.addAll(typeList);                }                int sizeAfter = types.size();                boolean changed = sizeBefore != sizeAfter;                if (changed) {                    fieldToTypeMap.put(field, new ArrayList<String>() {                        {                            addAll(types);                        }                    });                    sourceConfigsChanged.put(kv.getKey(), config);                }            }        }    }    for (Map.Entry<String, SensorEnrichmentConfig> kv : sourceConfigsChanged.entrySet()) {        scHandler.persistConfig(kv.getKey(), kv.getValue());    }}
1
private static SensorEnrichmentConfig findConfigBySensorType(SourceConfigHandler scHandler, Map<String, SensorEnrichmentConfig> sourceConfigsChanged, String key) throws Exception
{    SensorEnrichmentConfig config = sourceConfigsChanged.get(key);    if (config == null) {        config = scHandler.readConfig(key);        if (LOG.isDebugEnabled()) {                    }    }    return config;}
1
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String getComment()
{    return comment;}
0
public void setComment(String comment)
{    this.comment = comment;}
0
public String getRule()
{    return rule;}
0
public void setRule(String rule)
{    this.rule = rule;}
0
public String getScoreExpression()
{    return scoreExpression;}
0
public void setScoreExpression(Object scoreExpression)
{    if (scoreExpression instanceof Number) {                scoreExpression = Number.class.cast(scoreExpression).toString();    } else if (scoreExpression instanceof String) {                scoreExpression = String.class.cast(scoreExpression);    } else {        throw new IllegalArgumentException(String.format("Expected 'score' to be number or string, but got '%s'", scoreExpression));    }    this.scoreExpression = scoreExpression.toString();}
0
public String getReason()
{    return reason;}
0
public void setReason(String reason)
{    this.reason = reason;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (!(o instanceof RiskLevelRule))        return false;    RiskLevelRule that = (RiskLevelRule) o;    return Objects.equals(name, that.name) && Objects.equals(comment, that.comment) && Objects.equals(rule, that.rule) && Objects.equals(scoreExpression, that.scoreExpression) && Objects.equals(reason, that.reason);}
0
public int hashCode()
{    return Objects.hash(name, comment, rule, scoreExpression, reason);}
0
public String toString()
{    return "RiskLevelRule{" + "name='" + name + '\'' + ", comment='" + comment + '\'' + ", rule='" + rule + '\'' + ", scoreExpression='" + scoreExpression + '\'' + ", reason='" + reason + '\'' + '}';}
0
public String getReason()
{    return reason;}
0
public RiskLevelRule getRule()
{    return rule;}
0
public Number getScore()
{    return score;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (!(o instanceof RuleScore)) {        return false;    }    RuleScore ruleScore = (RuleScore) o;    return Objects.equals(rule, ruleScore.rule) && Objects.equals(reason, ruleScore.reason) && Objects.equals(score, ruleScore.score);}
0
public int hashCode()
{    return Objects.hash(rule, reason, score);}
0
public String toString()
{    return "RuleScore{" + "rule=" + rule + ", reason='" + reason + '\'' + ", score=" + score + '}';}
0
public ThreatTriageConfig getTriageConfig()
{    return triageConfig;}
0
public void setTriageConfig(ThreatTriageConfig triageConfig)
{    this.triageConfig = triageConfig;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    if (!super.equals(o))        return false;    ThreatIntelConfig that = (ThreatIntelConfig) o;    return getTriageConfig() != null ? getTriageConfig().equals(that.getTriageConfig()) : that.getTriageConfig() == null;}
0
public int hashCode()
{    int result = super.hashCode();    result = 31 * result + (getTriageConfig() != null ? getTriageConfig().hashCode() : 0);    return result;}
0
public String toString()
{    return "ThreatIntelConfig{" + "triageConfig=" + triageConfig + '}';}
0
public Double getScore()
{    return score;}
0
public void setScore(Double score)
{    this.score = score;}
0
public List<RuleScore> getRuleScores()
{    return ruleScores;}
0
public void addRuleScore(RuleScore score)
{    this.ruleScores.add(score);}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ThreatScore that = (ThreatScore) o;    if (score != null ? !score.equals(that.score) : that.score != null)        return false;    return ruleScores != null ? ruleScores.equals(that.ruleScores) : that.ruleScores == null;}
0
public int hashCode()
{    int result = score != null ? score.hashCode() : 0;    result = 31 * result + (ruleScores != null ? ruleScores.hashCode() : 0);    return result;}
0
public String toString()
{    return "ThreatScore{" + "score=" + score + ", ruleScores=" + ruleScores + '}';}
0
public List<RiskLevelRule> getRiskLevelRules()
{    return riskLevelRules;}
0
public void setRiskLevelRules(List<RiskLevelRule> riskLevelRules)
{    List<RiskLevelRule> rules = new ArrayList<>();    Set<String> ruleIndex = new HashSet<>();    StellarPredicateProcessor predicateProcessor = new StellarPredicateProcessor();    StellarProcessor processor = new StellarProcessor();    for (RiskLevelRule rule : riskLevelRules) {        if (rule.getRule() == null || rule.getScoreExpression() == null) {            throw new IllegalStateException("Risk level rules must contain both a rule and a score.");        }        if (ruleIndex.contains(rule.getRule())) {            continue;        } else {            ruleIndex.add(rule.getRule());        }                predicateProcessor.validate(rule.getRule());        if (rule.getReason() != null) {            processor.validate(rule.getReason());        }        rules.add(rule);    }    this.riskLevelRules = rules;}
0
public Aggregators getAggregator()
{    return aggregator;}
0
public void setAggregator(String aggregator)
{    try {        this.aggregator = Aggregators.valueOf(aggregator);    } catch (IllegalArgumentException iae) {        throw new IllegalArgumentException("Unable to load aggregator of " + aggregator + ".  Valid aggregators are " + Joiner.on(',').join(Aggregators.values()));    }}
0
public Map<String, Object> getAggregationConfig()
{    return aggregationConfig;}
0
public void setAggregationConfig(Map<String, Object> aggregationConfig)
{    this.aggregationConfig = aggregationConfig;}
0
public String toString()
{    return "ThreatTriageConfig{" + "riskLevelRules=" + riskLevelRules + ", aggregator=" + aggregator + ", aggregationConfig=" + aggregationConfig + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ThreatTriageConfig that = (ThreatTriageConfig) o;    if (riskLevelRules != null ? !riskLevelRules.equals(that.riskLevelRules) : that.riskLevelRules != null)        return false;    if (aggregator != that.aggregator)        return false;    return aggregationConfig != null ? aggregationConfig.equals(that.aggregationConfig) : that.aggregationConfig == null;}
0
public int hashCode()
{    int result = riskLevelRules != null ? riskLevelRules.hashCode() : 0;    result = 31 * result + (aggregator != null ? aggregator.hashCode() : 0);    result = 31 * result + (aggregationConfig != null ? aggregationConfig.hashCode() : 0);    return result;}
0
public String getTypeName()
{    return "enrichments";}
0
public Object deserialize(String s) throws IOException
{    return JSONUtils.INSTANCE.load(s, SensorEnrichmentConfig.class);}
0
public void writeSensorConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(sensorType, configData, client);}
0
public SensorEnrichmentConfig getSensorEnrichmentConfig(String sensorType)
{    return (SensorEnrichmentConfig) getConfigurations().get(getKey(sensorType));}
0
public void updateSensorEnrichmentConfig(String sensorType, byte[] data) throws IOException
{    updateSensorEnrichmentConfig(sensorType, new ByteArrayInputStream(data));}
0
public void updateSensorEnrichmentConfig(String sensorType, InputStream io) throws IOException
{    SensorEnrichmentConfig sensorEnrichmentConfig = JSONUtils.INSTANCE.load(io, SensorEnrichmentConfig.class);    updateSensorEnrichmentConfig(sensorType, sensorEnrichmentConfig);}
0
public void updateSensorEnrichmentConfig(String sensorType, SensorEnrichmentConfig sensorEnrichmentConfig)
{    getConfigurations().put(getKey(sensorType), sensorEnrichmentConfig);}
0
public void delete(String sensorType)
{    getConfigurations().remove(getKey(sensorType));}
0
public int getBatchSize()
{    return getAs(BATCH_SIZE_CONF, getGlobalConfig(true), DEFAULT_KAFKA_BATCH_SIZE, Integer.class);}
0
public int getBatchTimeout()
{    return getAs(BATCH_TIMEOUT_CONF, getGlobalConfig(true), 0, Integer.class);}
0
public List<String> getTypes()
{    List<String> ret = new ArrayList<>();    for (String keyedSensor : getConfigurations().keySet()) {        if (!keyedSensor.isEmpty() && keyedSensor.startsWith(ConfigurationType.ENRICHMENT.getTypeName())) {            ret.add(keyedSensor.substring(ConfigurationType.ENRICHMENT.getTypeName().length() + 1));        }    }    return ret;}
0
public static String getKey(String sensorType)
{    return ConfigurationType.ENRICHMENT.getTypeName() + "." + sensorType;}
0
public List<String> getInput()
{    return input;}
0
public void setInput(Object inputFields)
{    if (inputFields instanceof String) {        this.input = ImmutableList.of(inputFields.toString());    } else if (inputFields instanceof List) {        this.input = (List<String>) inputFields;    }}
0
public List<String> getOutput()
{    return output;}
0
public void setOutput(Object outputField)
{    if (outputField instanceof String) {        this.output = ImmutableList.of(outputField.toString());    } else if (outputField instanceof List) {        this.output = (List<String>) outputField;    }}
0
public Map<String, Object> getConfig()
{    return config;}
0
public void setConfig(LinkedHashMap<String, Object> config)
{    this.config = config;}
0
public String getTransformation()
{    return transformationName;}
0
public FieldTransformation getFieldTransformation()
{    return transformation;}
0
public void setTransformation(String transformation)
{    this.transformationName = transformation;    this.transformation = FieldTransformations.get(transformation);}
0
public void initAndValidate()
{    if (!initialized) {        if (getTransformation() == null) {            throw new IllegalStateException("Mapping cannot be null.");        }        if (output == null || output.isEmpty()) {            if (input == null || input.isEmpty()) {                                output = null;                input = null;            } else {                output = input;            }        }        initialized = true;    }}
0
public Map<String, Object> transform(JSONObject input, Context context, Map<String, Object>... sensorConfig)
{    if (getInput() == null || getInput().isEmpty()) {        return transformation.map(input, getOutput(), config, context, sensorConfig);    } else {        Map<String, Object> in = new HashMap<>();        for (String inputField : getInput()) {            in.put(inputField, input.get(inputField));        }        return transformation.map(in, getOutput(), config, context, sensorConfig);    }}
0
public void transformAndUpdate(JSONObject message, Context context, Map<String, Object>... sensorConfig)
{    Map<String, Object> currentValue = transform(message, context, sensorConfig);    if (currentValue != null) {        for (Map.Entry<String, Object> kv : currentValue.entrySet()) {            if (kv.getValue() == null) {                message.remove(kv.getKey());            } else {                message.put(kv.getKey(), kv.getValue());            }        }    }}
0
public String toString()
{    return "MappingHandler{" + "input=" + input + ", output='" + output + '\'' + ", transformation=" + transformation + ", config=" + config + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    FieldTransformer that = (FieldTransformer) o;    if (getInput() != null ? !getInput().equals(that.getInput()) : that.getInput() != null)        return false;    if (getOutput() != null ? !getOutput().equals(that.getOutput()) : that.getOutput() != null)        return false;    if (getTransformation() != null ? !getTransformation().equals(that.getTransformation()) : that.getTransformation() != null)        return false;    return getConfig() != null ? getConfig().equals(that.getConfig()) : that.getConfig() == null;}
0
public int hashCode()
{    int result = getInput() != null ? getInput().hashCode() : 0;    result = 31 * result + (getOutput() != null ? getOutput().hashCode() : 0);    result = 31 * result + (getTransformation() != null ? getTransformation().hashCode() : 0);    result = 31 * result + (getConfig() != null ? getConfig().hashCode() : 0);    return result;}
0
public T get(Map<String, Object> config, Class<T> clazz)
{    Object o = config.get(key);    if (o == null) {        return null;    }    return clazz.cast(o);}
0
public FieldValidation getValidation()
{    return validation;}
0
public List<String> getInput()
{    return input;}
0
public Map<String, Object> getConfig()
{    return config;}
0
public boolean isValid(JSONObject inputData, Map<String, Object> globalConfig, Context context)
{    Map<String, Object> in = inputData;    if (input != null && !input.isEmpty()) {        in = new HashMap<>();        for (String i : input) {            Object o = inputData.get(i);            in.put(i, o);        }    }    return validation.isValid(in, config, globalConfig, context);}
0
public static List<FieldValidator> readValidations(Map<String, Object> globalConfig)
{    List<FieldValidator> validators = new ArrayList<>();    List<Object> validations = (List<Object>) Config.FIELD_VALIDATIONS.get(globalConfig, List.class);    if (validations != null) {        for (Object o : validations) {            FieldValidator f = new FieldValidator(o);            f.getValidation().initialize(f.getConfig(), globalConfig);            validators.add(new FieldValidator(o));        }    }    return validators;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    FieldValidator that = (FieldValidator) o;    if (getValidation() != null ? !getValidation().equals(that.getValidation()) : that.getValidation() != null)        return false;    if (getInput() != null ? !getInput().equals(that.getInput()) : that.getInput() != null)        return false;    return getConfig() != null ? getConfig().equals(that.getConfig()) : that.getConfig() == null;}
0
public int hashCode()
{    int result = getValidation() != null ? getValidation().hashCode() : 0;    result = 31 * result + (getInput() != null ? getInput().hashCode() : 0);    result = 31 * result + (getConfig() != null ? getConfig().hashCode() : 0);    return result;}
0
public String toString()
{    return "FieldValidator{" + "validation=" + validation + ", input=" + input + ", config=" + config + '}';}
0
public String getTypeName()
{    return "global";}
0
public String getDirectory()
{    return ".";}
0
public Object deserialize(String s) throws IOException
{    return JSONUtils.INSTANCE.load(s, JSONUtils.MAP_SUPPLIER);}
0
public void writeSensorConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client)
{    throw new UnsupportedOperationException("Global configs are not per-sensor");}
0
public String getTypeName()
{    return "indexing";}
0
public Object deserialize(String s) throws IOException
{    return JSONUtils.INSTANCE.load(s, JSONUtils.MAP_SUPPLIER);}
0
public void writeSensorConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    ConfigurationsUtils.writeSensorIndexingConfigToZookeeper(sensorType, configData, client);}
0
public Map<String, Object> getSensorIndexingConfig(String sensorType, boolean emptyMapOnNonExistent)
{    Map<String, Object> ret = (Map<String, Object>) getConfigurations().get(getKey(sensorType));    if (ret == null) {        return emptyMapOnNonExistent ? new HashMap<>() : null;    } else {        return ret;    }}
0
public Map<String, Object> getSensorIndexingConfig(String sensorType)
{    return getSensorIndexingConfig(sensorType, true);}
0
public List<String> getTypes()
{    List<String> ret = new ArrayList<>();    for (String keyedSensor : getConfigurations().keySet()) {        if (!keyedSensor.isEmpty() && keyedSensor.startsWith(ConfigurationType.INDEXING.getTypeName())) {            ret.add(keyedSensor.substring(ConfigurationType.INDEXING.getTypeName().length() + 1));        }    }    return ret;}
0
public void delete(String sensorType)
{    getConfigurations().remove(getKey(sensorType));}
0
public Map<String, Object> getSensorIndexingConfig(String sensorType, String writerName)
{    String key = getKey(sensorType);    Map<String, Object> ret = (Map<String, Object>) getConfigurations().get(key);    if (ret == null) {        return new HashMap();    } else {        Map<String, Object> writerConfig = (Map<String, Object>) ret.get(writerName);        return writerConfig != null ? writerConfig : new HashMap<>();    }}
0
public void updateSensorIndexingConfig(String sensorType, byte[] data) throws IOException
{    updateSensorIndexingConfig(sensorType, new ByteArrayInputStream(data));}
0
public void updateSensorIndexingConfig(String sensorType, InputStream io) throws IOException
{    Map<String, Object> sensorIndexingConfig = JSONUtils.INSTANCE.load(io, JSONUtils.MAP_SUPPLIER);    updateSensorIndexingConfig(sensorType, sensorIndexingConfig);}
0
public void updateSensorIndexingConfig(String sensorType, Map<String, Object> sensorIndexingConfig)
{    getConfigurations().put(getKey(sensorType), sensorIndexingConfig);}
0
public static String getKey(String sensorType)
{    return ConfigurationType.INDEXING.getTypeName() + "." + sensorType;}
0
public boolean isDefault(String sensorName, String writerName)
{    Map<String, Object> ret = (Map<String, Object>) getConfigurations().get(getKey(sensorName));    if (ret == null) {        return true;    } else {        Map<String, Object> writerConfig = (Map<String, Object>) ret.get(writerName);        return writerConfig != null ? false : true;    }}
0
public int getBatchSize(String sensorName, String writerName)
{    return getBatchSize(getSensorIndexingConfig(sensorName, writerName));}
0
public int getBatchTimeout(String sensorName, String writerName)
{    return getBatchTimeout(getSensorIndexingConfig(sensorName, writerName));}
0
public List<Integer> getAllConfiguredTimeouts(String writerName)
{                        String keyPrefixString = getKey("");    int prefixStringLength = keyPrefixString.length();    List<Integer> configuredBatchTimeouts = new ArrayList<>();    for (String sensorKeyString : getConfigurations().keySet()) {        if (sensorKeyString.startsWith(keyPrefixString)) {            String configuredSensorName = sensorKeyString.substring(prefixStringLength);            configuredBatchTimeouts.add(getBatchTimeout(configuredSensorName, writerName));        }    }    return configuredBatchTimeouts;}
0
public String getIndex(String sensorName, String writerName)
{    return getIndex(getSensorIndexingConfig(sensorName, writerName), sensorName);}
0
public boolean isEnabled(String sensorName, String writerName)
{    return isEnabled(getSensorIndexingConfig(sensorName, writerName));}
0
public String getOutputPathFunction(String sensorName, String writerName)
{    return getOutputPathFunction(getSensorIndexingConfig(sensorName, writerName), sensorName);}
0
public String getFieldNameConverter(String sensorName, String writerName)
{    return getFieldNameConverter(getSensorIndexingConfig(sensorName, writerName), sensorName);}
0
public boolean isSetDocumentId(String sensorName, String writerName)
{    return isSetDocumentId(getGlobalConfig(true), getSensorIndexingConfig(sensorName, writerName));}
0
public static boolean isEnabled(Map<String, Object> conf)
{    return getAs(ENABLED_CONF, conf, true, Boolean.class);}
0
public static int getBatchSize(Map<String, Object> conf)
{    return getAs(BATCH_SIZE_CONF, conf, 1, Integer.class);}
0
public static int getBatchTimeout(Map<String, Object> conf)
{    return getAs(BATCH_TIMEOUT_CONF, conf, 0, Integer.class);}
0
public static String getIndex(Map<String, Object> conf, String sensorName)
{    return getAs(INDEX_CONF, conf, sensorName, String.class);}
0
public static String getOutputPathFunction(Map<String, Object> conf, String sensorName)
{    return getAs(OUTPUT_PATH_FUNCTION_CONF, conf, "", String.class);}
0
public static String getFieldNameConverter(Map<String, Object> conf, String sensorName)
{    return getAs(FIELD_NAME_CONVERTER_CONF, conf, "", String.class);}
0
public static boolean isSetDocumentId(Map<String, Object> globalConf, Map<String, Object> sensorConf)
{    return getAs(SET_DOCUMENT_ID_CONF, sensorConf, getAs(GLOBAL_ELASTICSEARCH_SET_DOCUMENT_ID_CONF, globalConf, false, Boolean.class), Boolean.class);}
0
public static Map<String, Object> setEnabled(Map<String, Object> conf, boolean enabled)
{    Map<String, Object> ret = conf == null ? new HashMap<>() : conf;    ret.put(ENABLED_CONF, enabled);    return ret;}
0
public static Map<String, Object> setBatchSize(Map<String, Object> conf, int batchSize)
{    Map<String, Object> ret = conf == null ? new HashMap<>() : conf;    ret.put(BATCH_SIZE_CONF, batchSize);    return ret;}
0
public static Map<String, Object> setBatchTimeout(Map<String, Object> conf, int batchTimeout)
{    Map<String, Object> ret = conf == null ? new HashMap<>() : conf;    ret.put(BATCH_TIMEOUT_CONF, batchTimeout);    return ret;}
0
public static Map<String, Object> setIndex(Map<String, Object> conf, String index)
{    Map<String, Object> ret = conf == null ? new HashMap<>() : conf;    ret.put(INDEX_CONF, index);    return ret;}
0
public static Map<String, Object> setFieldNameConverter(Map<String, Object> conf, String index)
{    Map<String, Object> ret = conf == null ? new HashMap<>() : conf;    ret.put(FIELD_NAME_CONVERTER_CONF, index);    return ret;}
0
public String getTypeName()
{    return "parsers";}
0
public Object deserialize(String s) throws IOException
{    return JSONUtils.INSTANCE.load(s, SensorParserConfig.class);}
0
public void writeSensorConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    ConfigurationsUtils.writeSensorParserConfigToZookeeper(sensorType, configData, client);}
0
public SensorParserConfig getSensorParserConfig(String sensorType)
{    return (SensorParserConfig) getConfigurations().get(getKey(sensorType));}
0
public void updateSensorParserConfig(String sensorType, byte[] data) throws IOException
{    updateSensorParserConfig(sensorType, new ByteArrayInputStream(data));}
0
public void updateSensorParserConfig(String sensorType, InputStream io) throws IOException
{    SensorParserConfig sensorParserConfig = JSONUtils.INSTANCE.load(io, SensorParserConfig.class);    updateSensorParserConfig(sensorType, sensorParserConfig);}
0
public void updateSensorParserConfig(String sensorType, SensorParserConfig sensorParserConfig)
{    sensorParserConfig.init();    getConfigurations().put(getKey(sensorType), sensorParserConfig);}
0
public Map<String, SensorParserGroup> getSensorParserGroups()
{    Object groups = getGlobalConfig(true).getOrDefault(PARSER_GROUPS_CONF, new ArrayList<>());    Collection<SensorParserGroup> sensorParserGroups = JSONUtils.INSTANCE.getMapper().convertValue(groups, new TypeReference<Collection<SensorParserGroup>>() {        {        }    });    return sensorParserGroups.stream().collect(Collectors.toMap(SensorParserGroup::getName, sensorParserGroup -> sensorParserGroup));}
0
public List<String> getTypes()
{    List<String> ret = new ArrayList<>();    for (String keyedSensor : getConfigurations().keySet()) {        if (!keyedSensor.isEmpty() && keyedSensor.startsWith(ConfigurationType.PARSER.getTypeName())) {            ret.add(keyedSensor.substring(ConfigurationType.PARSER.getTypeName().length() + 1));        }    }    return ret;}
0
public void delete(String sensorType)
{    getConfigurations().remove(getKey(sensorType));}
0
public static String getKey(String sensorType)
{    return ConfigurationType.PARSER.getTypeName() + "." + sensorType;}
0
public String getProfile()
{    return profile;}
0
public void setProfile(String profile)
{    this.profile = profile;}
0
public ProfileConfig withProfile(String profile)
{    this.profile = profile;    return this;}
0
public String getForeach()
{    return foreach;}
0
public void setForeach(String foreach)
{    this.foreach = foreach;}
0
public ProfileConfig withForeach(String foreach)
{    this.foreach = foreach;    return this;}
0
public String getOnlyif()
{    return onlyif;}
0
public void setOnlyif(String onlyif)
{    this.onlyif = onlyif;}
0
public ProfileConfig withOnlyif(String onlyif)
{    this.onlyif = onlyif;    return this;}
0
public Map<String, String> getInit()
{    return init;}
0
public void setInit(Map<String, String> init)
{    this.init = init;}
0
public ProfileConfig withInit(Map<String, String> init)
{    this.init.putAll(init);    return this;}
0
public ProfileConfig withInit(String var, String expression)
{    this.init.put(var, expression);    return this;}
0
public Map<String, String> getUpdate()
{    return update;}
0
public void setUpdate(Map<String, String> update)
{    this.update = update;}
0
public ProfileConfig withUpdate(Map<String, String> update)
{    this.update.putAll(update);    return this;}
0
public ProfileConfig withUpdate(String var, String expression)
{    this.update.put(var, expression);    return this;}
0
public List<String> getGroupBy()
{    return groupBy;}
0
public void setGroupBy(List<String> groupBy)
{    this.groupBy = groupBy;}
0
public ProfileConfig withGroupBy(List<String> groupBy)
{    this.groupBy = groupBy;    return this;}
0
public ProfileResult getResult()
{    return result;}
0
public void setResult(ProfileResult result)
{    this.result = result;}
0
public ProfileConfig withResult(String profileExpression)
{    this.result = new ProfileResult(profileExpression);    return this;}
0
public Long getExpires()
{    return expires;}
0
public void setExpires(Long expiresDays)
{    this.expires = expiresDays;}
0
public ProfileConfig withExpires(Long expiresDays)
{    this.expires = TimeUnit.DAYS.toMillis(expiresDays);    return this;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    ProfileConfig that = (ProfileConfig) o;    return new EqualsBuilder().append(profile, that.profile).append(foreach, that.foreach).append(onlyif, that.onlyif).append(init, that.init).append(update, that.update).append(groupBy, that.groupBy).append(result, that.result).append(expires, that.expires).isEquals();}
0
public int hashCode()
{    return new HashCodeBuilder(17, 37).append(profile).append(foreach).append(onlyif).append(init).append(update).append(groupBy).append(result).append(expires).toHashCode();}
0
public String toString()
{    return new ToStringBuilder(this).append("profile", profile).append("foreach", foreach).append("onlyif", onlyif).append("init", init).append("update", update).append("groupBy", groupBy).append("result", result).append("expires", expires).toString();}
0
public static ProfileConfig fromBytes(byte[] bytes) throws IOException
{    return JSONUtils.INSTANCE.load(new String(bytes, StandardCharsets.UTF_8), ProfileConfig.class);}
0
public static ProfileConfig fromJSON(String json) throws IOException
{    return JSONUtils.INSTANCE.load(json, ProfileConfig.class);}
0
public String toJSON() throws JsonProcessingException
{    return JSONUtils.INSTANCE.toJSON(this, true);}
0
public List<ProfileConfig> getProfiles()
{    return profiles;}
0
public void setProfiles(List<ProfileConfig> profiles)
{    this.profiles = profiles;}
0
public ProfilerConfig withProfile(ProfileConfig profileConfig)
{    this.profiles.add(profileConfig);    return this;}
0
public String getTimestampFieldForJson()
{    return timestampField;}
0
public Optional<String> getTimestampField()
{    return Optional.ofNullable(timestampField);}
0
public void setTimestampField(String timestampField)
{    this.timestampField = timestampField;}
0
public void setTimestampField(Optional<String> timestampField)
{    this.timestampField = timestampField.orElse(null);}
0
public ProfilerConfig withTimestampField(Optional<String> timestampField)
{    this.timestampField = timestampField.orElse(null);    return this;}
0
public String toString()
{    return new ToStringBuilder(this).append("profiles", profiles).append("timestampField", timestampField).toString();}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    ProfilerConfig that = (ProfilerConfig) o;    return new EqualsBuilder().append(profiles, that.profiles).append(timestampField, that.timestampField).isEquals();}
0
public int hashCode()
{    return new HashCodeBuilder(17, 37).append(profiles).append(timestampField).toHashCode();}
0
public static ProfilerConfig fromBytes(byte[] bytes) throws IOException
{    return JSONUtils.INSTANCE.load(new String(bytes, StandardCharsets.UTF_8), ProfilerConfig.class);}
0
public static ProfilerConfig fromJSON(String json) throws IOException
{    return JSONUtils.INSTANCE.load(json, ProfilerConfig.class);}
0
public String toJSON() throws JsonProcessingException
{    return JSONUtils.INSTANCE.toJSON(this, true);}
0
public ProfilerConfig getProfilerConfig()
{    return (ProfilerConfig) getConfigurations().get(getKey());}
0
public void updateProfilerConfig(byte[] data) throws IOException
{    updateProfilerConfig(new ByteArrayInputStream(data));}
0
public void updateProfilerConfig(InputStream io) throws IOException
{    ProfilerConfig config = JSONUtils.INSTANCE.load(io, ProfilerConfig.class);    updateProfilerConfig(config);}
0
public void updateProfilerConfig(ProfilerConfig config)
{    getConfigurations().put(getKey(), config);}
0
public static String getKey()
{    return ConfigurationType.PROFILER.getTypeName();}
0
public void delete()
{    configurations.remove(getKey());}
0
public int getBatchSize()
{    return getAs(BATCH_SIZE_CONF, getGlobalConfig(true), DEFAULT_KAFKA_BATCH_SIZE, Integer.class);}
0
public int getBatchTimeout()
{    return getAs(BATCH_TIMEOUT_CONF, getGlobalConfig(true), 0, Integer.class);}
0
public ProfileResultExpressions getProfileExpressions()
{    return profileExpressions;}
0
public void setProfileExpressions(ProfileResultExpressions profileExpressions)
{    this.profileExpressions = profileExpressions;}
0
public ProfileTriageExpressions getTriageExpressions()
{    return triageExpressions;}
0
public void setTriageExpressions(ProfileTriageExpressions triageExpressions)
{    this.triageExpressions = triageExpressions;}
0
public String toString()
{    return "ProfileResult{" + "profileExpressions=" + profileExpressions + ", triageExpressions=" + triageExpressions + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ProfileResult that = (ProfileResult) o;    if (profileExpressions != null ? !profileExpressions.equals(that.profileExpressions) : that.profileExpressions != null)        return false;    return triageExpressions != null ? triageExpressions.equals(that.triageExpressions) : that.triageExpressions == null;}
0
public int hashCode()
{    int result = profileExpressions != null ? profileExpressions.hashCode() : 0;    result = 31 * result + (triageExpressions != null ? triageExpressions.hashCode() : 0);    return result;}
0
public String getExpression()
{    return expression;}
0
public void setExpression(String expression)
{    this.expression = expression;}
0
public String toString()
{    return "ProfileResultExpressions{" + "expression='" + expression + '\'' + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ProfileResultExpressions that = (ProfileResultExpressions) o;    return expression != null ? expression.equals(that.expression) : that.expression == null;}
0
public int hashCode()
{    return expression != null ? expression.hashCode() : 0;}
0
public String getExpression(String name)
{    return expressions.get(name);}
0
public Map<String, String> getExpressions()
{    return expressions;}
0
public void setExpressions(Map<String, String> expressions)
{    this.expressions = expressions;}
0
public String toString()
{    return "ProfileTriageExpressions{" + "expressions=" + expressions + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ProfileTriageExpressions that = (ProfileTriageExpressions) o;    return getExpressions() != null ? getExpressions().equals(that.getExpressions()) : that.getExpressions() == null;}
0
public int hashCode()
{    return getExpressions() != null ? getExpressions().hashCode() : 0;}
0
public String getTypeName()
{    return "profiler";}
0
public String getDirectory()
{    return ".";}
0
public Object deserialize(String s) throws IOException
{    return JSONUtils.INSTANCE.load(s, ProfilerConfig.class);}
0
public void writeSensorConfigToZookeeper(String sensorType, byte[] configData, CuratorFramework client) throws Exception
{    throw new UnsupportedOperationException("Profiler configs are not per-sensor");}
0
public RawMessageStrategy getRawMessageStrategy()
{    return rawMessageStrategy;}
0
public void setRawMessageStrategy(String rawMessageSupplierName)
{    this.rawMessageStrategy = RawMessageStrategies.valueOf(rawMessageSupplierName);}
0
public Map<String, Object> getRawMessageStrategyConfig()
{    return rawMessageStrategyConfig;}
0
public void setRawMessageStrategyConfig(Map<String, Object> rawMessageStrategyConfig)
{    this.rawMessageStrategyConfig = rawMessageStrategyConfig;}
0
public Map<String, Object> getCacheConfig()
{    return cacheConfig;}
0
public void setCacheConfig(Map<String, Object> cacheConfig)
{    this.cacheConfig = cacheConfig;}
0
public Integer getNumWorkers()
{    return numWorkers;}
0
public void setNumWorkers(Integer numWorkers)
{    this.numWorkers = numWorkers;}
0
public Integer getNumAckers()
{    return numAckers;}
0
public void setNumAckers(Integer numAckers)
{    this.numAckers = numAckers;}
0
public Integer getSpoutParallelism()
{    return spoutParallelism;}
0
public void setSpoutParallelism(Integer spoutParallelism)
{    this.spoutParallelism = spoutParallelism;}
0
public Integer getSpoutNumTasks()
{    return spoutNumTasks;}
0
public void setSpoutNumTasks(Integer spoutNumTasks)
{    this.spoutNumTasks = spoutNumTasks;}
0
public Integer getParserParallelism()
{    return parserParallelism;}
0
public void setParserParallelism(Integer parserParallelism)
{    this.parserParallelism = parserParallelism;}
0
public Integer getParserNumTasks()
{    return parserNumTasks;}
0
public void setParserNumTasks(Integer parserNumTasks)
{    this.parserNumTasks = parserNumTasks;}
0
public Integer getErrorWriterParallelism()
{    return errorWriterParallelism;}
0
public void setErrorWriterParallelism(Integer errorWriterParallelism)
{    this.errorWriterParallelism = errorWriterParallelism;}
0
public Integer getErrorWriterNumTasks()
{    return errorWriterNumTasks;}
0
public void setErrorWriterNumTasks(Integer errorWriterNumTasks)
{    this.errorWriterNumTasks = errorWriterNumTasks;}
0
public Map<String, Object> getSpoutConfig()
{    return spoutConfig;}
0
public void setSpoutConfig(Map<String, Object> spoutConfig)
{    this.spoutConfig = spoutConfig;}
0
public String getSecurityProtocol()
{    return securityProtocol;}
0
public void setSecurityProtocol(String securityProtocol)
{    this.securityProtocol = securityProtocol;}
0
public Map<String, Object> getStormConfig()
{    return stormConfig;}
0
public void setStormConfig(Map<String, Object> stormConfig)
{    this.stormConfig = stormConfig;}
0
public Boolean getMergeMetadata()
{    return Optional.ofNullable(mergeMetadata).orElse(getRawMessageStrategy().mergeMetadataDefault());}
0
public void setMergeMetadata(Boolean mergeMetadata)
{    this.mergeMetadata = mergeMetadata;}
0
public Boolean getReadMetadata()
{    return Optional.ofNullable(readMetadata).orElse(getRawMessageStrategy().readMetadataDefault());}
0
public void setReadMetadata(Boolean readMetadata)
{    this.readMetadata = readMetadata;}
0
public String getErrorWriterClassName()
{    return errorWriterClassName;}
0
public void setErrorWriterClassName(String errorWriterClassName)
{    this.errorWriterClassName = errorWriterClassName;}
0
public String getWriterClassName()
{    return writerClassName;}
0
public void setWriterClassName(String classNames)
{    this.writerClassName = classNames;}
0
public List<FieldTransformer> getFieldTransformations()
{    return fieldTransformations;}
0
public void setFieldTransformations(List<FieldTransformer> fieldTransformations)
{    this.fieldTransformations = fieldTransformations;}
0
public String getFilterClassName()
{    return filterClassName;}
0
public void setFilterClassName(String filterClassName)
{    this.filterClassName = filterClassName;}
0
public String getParserClassName()
{    return parserClassName;}
0
public void setParserClassName(String parserClassName)
{    this.parserClassName = parserClassName;}
0
public String getSensorTopic()
{    return sensorTopic;}
0
public void setSensorTopic(String sensorTopic)
{    this.sensorTopic = sensorTopic;}
0
public String getOutputTopic()
{    return outputTopic;}
0
public void setOutputTopic(String outputTopic)
{    this.outputTopic = outputTopic;}
0
public String getErrorTopic()
{    return errorTopic;}
0
public void setErrorTopic(String errorTopic)
{    this.errorTopic = errorTopic;}
0
public Map<String, Object> getParserConfig()
{    return parserConfig;}
0
public void setParserConfig(Map<String, Object> parserConfig)
{    this.parserConfig = parserConfig;}
0
public static SensorParserConfig fromBytes(byte[] config) throws IOException
{    SensorParserConfig ret = JSONUtils.INSTANCE.load(new String(config, StandardCharsets.UTF_8), SensorParserConfig.class);    ret.init();    return ret;}
0
public void init()
{    for (FieldTransformer h : getFieldTransformations()) {        h.initAndValidate();    }}
0
public String toJSON() throws JsonProcessingException
{    return JSONUtils.INSTANCE.toJSON(this, true);}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SensorParserConfig that = (SensorParserConfig) o;    return new EqualsBuilder().append(parserClassName, that.parserClassName).append(filterClassName, that.filterClassName).append(sensorTopic, that.sensorTopic).append(outputTopic, that.outputTopic).append(errorTopic, that.errorTopic).append(writerClassName, that.writerClassName).append(errorWriterClassName, that.errorWriterClassName).append(getReadMetadata(), that.getReadMetadata()).append(getMergeMetadata(), that.getMergeMetadata()).append(numWorkers, that.numWorkers).append(numAckers, that.numAckers).append(spoutParallelism, that.spoutParallelism).append(spoutNumTasks, that.spoutNumTasks).append(parserParallelism, that.parserParallelism).append(parserNumTasks, that.parserNumTasks).append(errorWriterParallelism, that.errorWriterParallelism).append(errorWriterNumTasks, that.errorWriterNumTasks).append(spoutConfig, that.spoutConfig).append(securityProtocol, that.securityProtocol).append(stormConfig, that.stormConfig).append(cacheConfig, that.cacheConfig).append(parserConfig, that.parserConfig).append(fieldTransformations, that.fieldTransformations).append(rawMessageStrategy, that.rawMessageStrategy).append(rawMessageStrategyConfig, that.rawMessageStrategyConfig).isEquals();}
0
public int hashCode()
{    return new HashCodeBuilder(17, 37).append(parserClassName).append(filterClassName).append(sensorTopic).append(outputTopic).append(errorTopic).append(writerClassName).append(errorWriterClassName).append(getReadMetadata()).append(getMergeMetadata()).append(numWorkers).append(numAckers).append(spoutParallelism).append(spoutNumTasks).append(parserParallelism).append(parserNumTasks).append(errorWriterParallelism).append(errorWriterNumTasks).append(spoutConfig).append(securityProtocol).append(stormConfig).append(cacheConfig).append(parserConfig).append(fieldTransformations).append(rawMessageStrategy).append(rawMessageStrategyConfig).toHashCode();}
0
public String toString()
{    return new ToStringBuilder(this).append("parserClassName", parserClassName).append("filterClassName", filterClassName).append("sensorTopic", sensorTopic).append("outputTopic", outputTopic).append("errorTopic", errorTopic).append("writerClassName", writerClassName).append("errorWriterClassName", errorWriterClassName).append("readMetadata", getReadMetadata()).append("mergeMetadata", getMergeMetadata()).append("numWorkers", numWorkers).append("numAckers", numAckers).append("spoutParallelism", spoutParallelism).append("spoutNumTasks", spoutNumTasks).append("parserParallelism", parserParallelism).append("parserNumTasks", parserNumTasks).append("errorWriterParallelism", errorWriterParallelism).append("errorWriterNumTasks", errorWriterNumTasks).append("spoutConfig", spoutConfig).append("securityProtocol", securityProtocol).append("stormConfig", stormConfig).append("cacheConfig", cacheConfig).append("parserConfig", parserConfig).append("fieldTransformations", fieldTransformations).append("rawMessageStrategy", rawMessageStrategy).append("rawMessageStrategyConfig", rawMessageStrategyConfig).toString();}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public String getDescription()
{    return description;}
0
public void setDescription(String description)
{    this.description = description;}
0
public Set<String> getSensors()
{    return sensors;}
0
public void setSensors(Set<String> sensors)
{    this.sensors = sensors;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    SensorParserGroup that = (SensorParserGroup) o;    return Objects.equals(name, that.name) && Objects.equals(description, that.description) && Objects.equals(sensors, that.sensors);}
0
public int hashCode()
{    return Objects.hash(name, description, sensors);}
0
public String toString()
{    return "SensorParserGroup{" + "name='" + name + '\'' + ", description='" + description + '\'' + ", sensors=" + sensors + '}';}
0
public WriterConfiguration createWriterConfig(BulkMessageWriter writer, Configurations configs)
{    return strategy.createWriterConfig(writer, configs);}
0
public ConfigurationsUpdater createUpdater(Reloadable reloadable, Supplier configSupplier)
{    return strategy.createUpdater(reloadable, configSupplier);}
0
public WriterConfiguration createWriterConfig(BulkMessageWriter writer, Configurations configs)
{    if (configs instanceof ParserConfigurations) {        return new ParserWriterConfiguration((ParserConfigurations) configs);    } else {        throw new IllegalArgumentException("Expected config of type ParserConfigurations but found " + configs.getClass());    }}
0
public ConfigurationsUpdater<ParserConfigurations> createUpdater(Reloadable reloadable, Supplier configSupplier)
{    return new ParserUpdater(reloadable, configSupplier);}
0
public WriterConfiguration createWriterConfig(BulkMessageWriter writer, Configurations configs)
{    if (configs instanceof EnrichmentConfigurations) {        return new EnrichmentWriterConfiguration((EnrichmentConfigurations) configs);    } else {        throw new IllegalArgumentException("Expected config of type EnrichmentConfigurations but found " + configs.getClass());    }}
0
public ConfigurationsUpdater<EnrichmentConfigurations> createUpdater(Reloadable reloadable, Supplier configSupplier)
{    return new EnrichmentUpdater(reloadable, configSupplier);}
0
public WriterConfiguration createWriterConfig(BulkMessageWriter writer, Configurations configs)
{    if (configs instanceof IndexingConfigurations) {        return new IndexingWriterConfiguration(writer.getName(), (IndexingConfigurations) configs);    } else {        throw new IllegalArgumentException("Expected config of type IndexingConfigurations but found " + configs.getClass());    }}
0
public ConfigurationsUpdater<IndexingConfigurations> createUpdater(Reloadable reloadable, Supplier configSupplier)
{    return new IndexingUpdater(reloadable, configSupplier);}
0
public WriterConfiguration createWriterConfig(BulkMessageWriter writer, Configurations configs)
{    if (configs instanceof ProfilerConfigurations) {        return new ProfilerWriterConfiguration((ProfilerConfigurations) configs);    } else {        throw new IllegalArgumentException("Expected config of type IndexingConfigurations but found " + configs.getClass());    }}
0
public ConfigurationsUpdater createUpdater(Reloadable reloadable, Supplier configSupplier)
{    return new ProfilerUpdater(reloadable, configSupplier);}
0
public int getBatchSize(String sensorName)
{    return config.orElse(new EnrichmentConfigurations()).getBatchSize();}
0
public int getBatchTimeout(String sensorName)
{    return config.orElse(new EnrichmentConfigurations()).getBatchTimeout();}
0
public List<Integer> getAllConfiguredTimeouts()
{    return asList(getBatchTimeout(null));}
0
public String getIndex(String sensorName)
{    return null;}
0
public boolean isEnabled(String sensorName)
{    return true;}
0
public Map<String, Object> getSensorConfig(String sensorName)
{    return config.orElse(new EnrichmentConfigurations()).getSensorEnrichmentConfig(sensorName).getConfiguration();}
0
public Map<String, Object> getGlobalConfig()
{    return config.orElse(new EnrichmentConfigurations()).getGlobalConfig();}
0
public boolean isDefault(String sensorName)
{    return false;}
0
public String getFieldNameConverter(String sensorName)
{        return null;}
0
public int getBatchSize(String sensorName)
{    return config.orElse(new IndexingConfigurations()).getBatchSize(sensorName, writerName);}
0
public int getBatchTimeout(String sensorName)
{    return config.orElse(new IndexingConfigurations()).getBatchTimeout(sensorName, writerName);}
0
public List<Integer> getAllConfiguredTimeouts()
{    return config.orElse(new IndexingConfigurations()).getAllConfiguredTimeouts(writerName);}
0
public String getIndex(String sensorName)
{    return config.orElse(new IndexingConfigurations()).getIndex(sensorName, writerName);}
0
public boolean isEnabled(String sensorName)
{    return config.orElse(new IndexingConfigurations()).isEnabled(sensorName, writerName);}
0
public Map<String, Object> getSensorConfig(String sensorName)
{    return config.orElse(new IndexingConfigurations()).getSensorIndexingConfig(sensorName, writerName);}
0
public Map<String, Object> getGlobalConfig()
{    return config.orElse(new IndexingConfigurations()).getGlobalConfig();}
0
public boolean isDefault(String sensorName)
{    return config.orElse(new IndexingConfigurations()).isDefault(sensorName, writerName);}
0
public String getFieldNameConverter(String sensorName)
{    return config.orElse(new IndexingConfigurations()).getFieldNameConverter(sensorName, writerName);}
0
public boolean isSetDocumentId(String sensorName)
{    return config.orElse(new IndexingConfigurations()).isSetDocumentId(sensorName, writerName);}
0
public int getBatchSize(String sensorName)
{    if (config != null && config.getSensorParserConfig(sensorName) != null && config.getSensorParserConfig(sensorName).getParserConfig() != null) {        Object batchObj = config.getSensorParserConfig(sensorName).getParserConfig().get(IndexingConfigurations.BATCH_SIZE_CONF);        return batchObj == null ? ParserConfigurations.DEFAULT_KAFKA_BATCH_SIZE : ConversionUtils.convert(batchObj, Integer.class);    }    return 1;}
0
public int getBatchTimeout(String sensorName)
{    if (config != null && config.getSensorParserConfig(sensorName) != null && config.getSensorParserConfig(sensorName).getParserConfig() != null) {        Object batchObj = config.getSensorParserConfig(sensorName).getParserConfig().get(IndexingConfigurations.BATCH_TIMEOUT_CONF);        return batchObj == null ? 0 : ConversionUtils.convert(batchObj, Integer.class);    }    return 0;}
0
public List<Integer> getAllConfiguredTimeouts()
{        return new ArrayList<Integer>();}
0
public String getIndex(String sensorName)
{    if (config != null && config.getSensorParserConfig(sensorName) != null && config.getSensorParserConfig(sensorName).getParserConfig() != null) {        Object indexObj = config.getSensorParserConfig(sensorName).getParserConfig().get(IndexingConfigurations.INDEX_CONF);        if (indexObj != null) {            return indexObj.toString();        }        return null;    }    return sensorName;}
0
public boolean isEnabled(String sensorName)
{    if (config != null && config.getSensorParserConfig(sensorName) != null && config.getSensorParserConfig(sensorName).getParserConfig() != null) {        Object enabledObj = config.getSensorParserConfig(sensorName).getParserConfig().get(IndexingConfigurations.ENABLED_CONF);        return enabledObj == null ? true : ConversionUtils.convert(enabledObj, Boolean.class);    }    return true;}
0
public Map<String, Object> getSensorConfig(String sensorName)
{    return config.getSensorParserConfig(sensorName).getParserConfig();}
0
public Map<String, Object> getGlobalConfig()
{    return config.getGlobalConfig();}
0
public boolean isDefault(String sensorName)
{    return false;}
0
public String getFieldNameConverter(String sensorName)
{        return null;}
0
public int getBatchSize(String sensorName)
{    return config.orElse(new ProfilerConfigurations()).getBatchSize();}
0
public int getBatchTimeout(String sensorName)
{    return config.orElse(new ProfilerConfigurations()).getBatchTimeout();}
0
public List<Integer> getAllConfiguredTimeouts()
{    return asList(getBatchTimeout(null));}
0
public String getIndex(String sensorName)
{    return null;}
0
public boolean isEnabled(String sensorName)
{    return true;}
0
public Map<String, Object> getSensorConfig(String sensorName)
{    throw new UnsupportedOperationException("Profiler does not have sensor configs");}
0
public Map<String, Object> getGlobalConfig()
{    return config.orElse(new ProfilerConfigurations()).getGlobalConfig();}
0
public boolean isDefault(String sensorName)
{    return false;}
0
public String getFieldNameConverter(String sensorName)
{        return null;}
0
public int getBatchSize(String sensorName)
{    return 1;}
0
public int getBatchTimeout(String sensorName)
{    return 0;}
0
public List<Integer> getAllConfiguredTimeouts()
{        return new ArrayList<Integer>();}
0
public String getIndex(String sensorName)
{    return config.getIndex(sensorName);}
0
public boolean isEnabled(String sensorName)
{    return true;}
0
public Map<String, Object> getSensorConfig(String sensorName)
{    return config.getSensorConfig(sensorName);}
0
public Map<String, Object> getGlobalConfig()
{    return config.getGlobalConfig();}
0
public boolean isDefault(String sensorName)
{    return false;}
0
public String getFieldNameConverter(String sensorName)
{        return null;}
0
 boolean isSetDocumentId(String sensorName)
{    return false;}
0
public String getName()
{    return name;}
0
public static Fields fromString(String fieldName)
{    return nameToField.get(fieldName);}
0
public String getName()
{    return name;}
0
public String getType()
{    return type;}
0
public Map<String, Integer> getColumnMap()
{    return columnMap;}
0
public CSVParser getParser()
{    return parser;}
0
public Map<String, String> toMap(String line) throws IOException
{    if (ignore(line)) {        return null;    }    String[] tokens = parser.parseLine(line);    Map<String, String> values = new HashMap<>();    for (Map.Entry<String, Integer> kv : columnMap.entrySet()) {        values.put(kv.getKey().trim(), tokens[kv.getValue()].trim());    }    return values;}
0
public void initialize(Map<String, Object> config)
{    if (config.containsKey(COLUMNS_KEY)) {        columnMap = getColumnMap(config);    } else {        throw new IllegalStateException("CSVExtractor requires " + COLUMNS_KEY + " configuration");    }    char separator = ',';    if (config.containsKey(SEPARATOR_KEY)) {        separator = config.get(SEPARATOR_KEY).toString().charAt(0);    }    parser = new CSVParserBuilder().withSeparator(separator).build();}
0
protected boolean ignore(String line)
{    if (null == line) {        return true;    }    String trimmedLine = line.trim();    return trimmedLine.startsWith("#") || isEmpty(trimmedLine);}
0
public static Map.Entry<String, Integer> getColumnMapEntry(String column, int i)
{    if (column.contains(":")) {        Iterable<String> tokens = Splitter.on(':').split(column);        String col = Iterables.getFirst(tokens, null);        Integer pos = Integer.parseInt(Iterables.getLast(tokens));        return new AbstractMap.SimpleEntry<>(col, pos);    } else {        return new AbstractMap.SimpleEntry<>(column, i);    }}
0
public static Map<String, Integer> getColumnMap(Map<String, Object> config)
{    Map<String, Integer> columnMap = new HashMap<>();    if (config.containsKey(COLUMNS_KEY)) {        Object columnsObj = config.get(COLUMNS_KEY);        if (columnsObj instanceof String) {            String columns = (String) columnsObj;            int i = 0;            for (String column : Splitter.on(',').split(columns)) {                Map.Entry<String, Integer> e = getColumnMapEntry(column, i++);                columnMap.put(e.getKey(), e.getValue());            }        } else if (columnsObj instanceof List) {            List columns = (List) columnsObj;            int i = 0;            for (Object column : columns) {                Map.Entry<String, Integer> e = getColumnMapEntry(column.toString(), i++);                columnMap.put(e.getKey(), e.getValue());            }        } else if (columnsObj instanceof Map) {            Map<Object, Object> map = (Map<Object, Object>) columnsObj;            for (Map.Entry<Object, Object> e : map.entrySet()) {                columnMap.put(e.getKey().toString(), Integer.parseInt(e.getValue().toString()));            }        }    }    return columnMap;}
0
public MetronError withMessage(String message)
{    this.message = message;    return this;}
0
public MetronError withThrowable(Throwable throwable)
{    this.throwable = throwable;    return this;}
0
public MetronError withSensorType(Set<String> sensorTypes)
{    this.sensorTypes = sensorTypes;    return this;}
0
public MetronError withErrorType(ErrorType errorType)
{    this.errorType = errorType;    return this;}
0
public MetronError withErrorFields(Set<String> errorFields)
{    this.errorFields = errorFields;    return this;}
0
public MetronError withMetadata(Map<String, Object> metadata)
{    this.metadata.putAll(metadata);    return this;}
0
public MetronError addRawMessage(Object rawMessage)
{    if (rawMessage != null) {        if (this.rawMessages == null) {            this.rawMessages = new ArrayList<>();        }        this.rawMessages.add(rawMessage);    }    return this;}
0
public MetronError withRawMessages(List<Object> rawMessages)
{    this.rawMessages = rawMessages;    return this;}
0
public Optional<Throwable> getThrowable()
{    return throwable != null ? Optional.of(throwable) : Optional.empty();}
0
public List<Object> getRawMessages()
{    return rawMessages;}
0
public JSONObject getJSONObject()
{    JSONObject errorMessage = new JSONObject();    errorMessage.put(Constants.GUID, UUID.randomUUID().toString());    errorMessage.put(Constants.SENSOR_TYPE, Constants.ERROR_TYPE);    errorMessage.put(ErrorFields.ERROR_TYPE.getName(), errorType.getType());    addFailedSensorType(errorMessage);    addMessageString(errorMessage);    addStacktrace(errorMessage);    addTimestamp(errorMessage);    addHostname(errorMessage);    addRawMessages(errorMessage);    addErrorHash(errorMessage);    addMetadata(errorMessage);    return errorMessage;}
0
private void addFailedSensorType(JSONObject errorMessage)
{    if (sensorTypes.size() == 1) {        errorMessage.put(ErrorFields.FAILED_SENSOR_TYPE.getName(), sensorTypes.iterator().next());    } else {        errorMessage.put(ErrorFields.FAILED_SENSOR_TYPE.getName(), new JSONArray().addAll(sensorTypes));    }}
0
private void addMessageString(JSONObject errorMessage)
{    if (message != null) {        errorMessage.put(ErrorFields.MESSAGE.getName(), message);    } else if (throwable != null) {        errorMessage.put(ErrorFields.MESSAGE.getName(), throwable.getMessage());    }}
0
private void addStacktrace(JSONObject errorMessage)
{    if (throwable != null) {        String stackTrace = ExceptionUtils.getStackTrace(throwable);        String exception = throwable.toString();        errorMessage.put(ErrorFields.EXCEPTION.getName(), exception);        errorMessage.put(ErrorFields.STACK.getName(), stackTrace);    }}
0
private void addTimestamp(JSONObject errorMessage)
{    errorMessage.put(ErrorFields.TIMESTAMP.getName(), System.currentTimeMillis());}
0
private void addHostname(JSONObject errorMessage)
{    try {        errorMessage.put(ErrorFields.HOSTNAME.getName(), InetAddress.getLocalHost().getHostName());    } catch (UnknownHostException ex) {        }}
0
private void addRawMessages(JSONObject errorMessage)
{    if (rawMessages != null) {        for (int i = 0; i < rawMessages.size(); i++) {            Object rawMessage = rawMessages.get(i);                        String rawMessageField = rawMessages.size() == 1 ? ErrorFields.RAW_MESSAGE.getName() : ErrorFields.RAW_MESSAGE.getName() + "_" + i;                        if (rawMessage instanceof byte[]) {                errorMessage.put(rawMessageField, new String((byte[]) rawMessage, UTF_8));                        } else if (rawMessage instanceof JSONObject) {                JSONObject rawMessageJSON = (JSONObject) rawMessage;                String rawMessageJSONString = rawMessageJSON.toJSONString();                errorMessage.put(rawMessageField, rawMessageJSONString);                        } else {                errorMessage.put(rawMessageField, rawMessage.toString());                        }        }    }}
0
private void addErrorHash(JSONObject errorMessage)
{    if (rawMessages != null && rawMessages.size() == 1) {        Object rawMessage = rawMessages.get(0);        if (rawMessage instanceof JSONObject) {            JSONObject rawJSON = (JSONObject) rawMessage;            if (errorFields != null) {                errorMessage.put(ErrorFields.ERROR_FIELDS.getName(), String.join(",", errorFields));                errorMessage.put(ErrorFields.ERROR_HASH.getName(), HashUtils.getMessageHash(rawJSON, errorFields));            } else {                errorMessage.put(ErrorFields.ERROR_HASH.getName(), HashUtils.getMessageHash(rawJSON));            }        } else if (rawMessage instanceof byte[]) {            errorMessage.put(ErrorFields.ERROR_HASH.getName(), HashUtils.getMessageHash((byte[]) rawMessage));        } else {            errorMessage.put(ErrorFields.ERROR_HASH.getName(), HashUtils.getMessageHash(rawMessage.toString().getBytes(UTF_8)));        }    }}
0
private void addMetadata(JSONObject errorMessage)
{    if (metadata != null && metadata.keySet().size() > 0) {                                errorMessage.putAll(metadata);    }}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (!(o instanceof MetronError))        return false;    MetronError that = (MetronError) o;    return Objects.equals(message, that.message) && Objects.equals(throwable, that.throwable) && Objects.equals(sensorTypes, that.sensorTypes) && errorType == that.errorType && Objects.equals(errorFields, that.errorFields) && Objects.equals(rawMessages, that.rawMessages) && Objects.equals(metadata, that.metadata);}
0
public int hashCode()
{    return Objects.hash(message, throwable, sensorTypes, errorType, errorFields, rawMessages, metadata);}
0
public FieldNameConverter get()
{    return converter;}
0
public String convert(String originalField)
{    return converter.convert(originalField);}
0
public String convert(String originalField)
{        return originalField;}
0
public static FieldTransformation get(String mapping)
{    try {        return FieldTransformations.valueOf(mapping).mapping;    } catch (Exception ex) {        return ReflectionUtils.createInstance(mapping);    }}
0
public Class<? extends FieldTransformation> getMappingClass()
{    return mapping.getClass();}
0
public Map<String, Object> map(Object value, String outputField)
{    Map<String, Object> ret = new HashMap<>();    if (value != null && value instanceof Number) {        int protocolNum = ((Number) value).intValue();        ret.put(outputField, PROTOCOLS.get(protocolNum));    }    return ret;}
0
public Object apply(List<Object> objects, Context context) throws ParseException
{    Object keyObj = objects.get(0);    if (keyObj == null) {        return keyObj;    }    Integer key = ConversionUtils.convert(keyObj, Integer.class);    if (key == null) {        return keyObj;    }    Object ret = PROTOCOLS.get(key);    if (ret == null) {        return keyObj;    }    return ret;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Map<String, Object> map(Map<String, Object> input, List<String> outputField, LinkedHashMap<String, Object> fieldMappingConfig, Context context, Map<String, Object>... sensorConfig)
{    String outField = null;    if (!(outputField == null || outputField.isEmpty())) {        outField = outputField.get(0);    }    String inVal = null;    if (!(input == null || input.isEmpty() || input.size() > 1)) {        Object inValObj = Iterables.getFirst(input.entrySet(), null).getValue();        if (inValObj != null) {            inVal = inValObj.toString();        }    }    Map<String, Object> ret = new HashMap<>(1);    if (outField == null || inVal == null) {                return ret;    }    for (Map.Entry<String, Object> valToRegex : fieldMappingConfig.entrySet()) {        if (isMatch(valToRegex.getValue(), inVal)) {            ret.put(outField, valToRegex.getKey());            break;        }    }    return ret;}
0
private static boolean isMatch(Object regexes, String field)
{    if (regexes instanceof String) {        return isMatch((String) regexes, field);    } else if (regexes instanceof List) {        for (Object regex : (List) regexes) {            if (isMatch(regex.toString(), field)) {                return true;            }        }    }    return false;}
0
private static boolean isMatch(String regex, String field)
{    try {        Pattern p = PatternCache.INSTANCE.getPattern(regex);        if (p == null) {            return false;        }        return p.asPredicate().test(field);    } catch (PatternSyntaxException pse) {        return false;    }}
0
public Boolean parse(String rule, VariableResolver resolver, FunctionResolver functionResolver, Context context)
{    return true;}
0
public boolean validate(String rule) throws ParseException
{    return true;}
0
public boolean validate(String rule, boolean throwException, Context context) throws ParseException
{    return true;}
0
private String getCondition(Map<String, Object> fieldMappingConfig)
{    Object conditionObj = fieldMappingConfig.get(CONDITION_CONF);    if (conditionObj == null || !(conditionObj instanceof String)) {        return null;    }    return conditionObj.toString();}
0
private StellarPredicateProcessor getPredicateProcessor(String condition)
{    if (condition == null) {        return PASSTHROUGH_PROCESSOR;    } else {        return new StellarPredicateProcessor();    }}
0
public Map<String, Object> map(Map<String, Object> input, final List<String> outputFields, LinkedHashMap<String, Object> fieldMappingConfig, Context context, Map<String, Object>... sensorConfig)
{    String condition = getCondition(fieldMappingConfig);    StellarPredicateProcessor processor = getPredicateProcessor(condition);    if (processor.parse(condition, new MapVariableResolver(input), StellarFunctions.FUNCTION_RESOLVER(), context)) {        return new HashMap<String, Object>() {            {                for (String outputField : outputFields) {                    put(outputField, null);                }            }        };    }    return null;}
0
public Map<String, Object> map(Map<String, Object> input, List<String> outputField, LinkedHashMap<String, Object> fieldMappingConfig, Context context, Map<String, Object>... sensorConfig)
{    if (fieldMappingConfig == null || fieldMappingConfig.isEmpty()) {        return input;    }    Map<String, Object> ret = new HashMap<>();    for (Map.Entry<String, Object> kv : input.entrySet()) {        Object renamed = fieldMappingConfig.get(kv.getKey());        if (renamed != null) {                        ret.put(renamed.toString(), kv.getValue());                        ret.put(kv.getKey(), null);        } else {            ret.put(kv.getKey(), kv.getValue());        }    }    return ret;}
0
public Map<String, Object> map(Map<String, Object> input, List<String> outputField, LinkedHashMap<String, Object> fieldMappingConfig, Context context, Map<String, Object>... sensorConfig)
{                        HashMap<String, Object> output = new HashMap<String, Object>();    for (Entry<String, Object> e : input.entrySet()) {        if (outputField.contains(e.getKey())) {            output.put(e.getKey(), e.getValue());        } else {            if (!systemFields.contains(e.getKey())) {                output.put(e.getKey(), null);            }        }    }    return output;}
0
public Map<String, Object> map(Map<String, Object> input, List<String> outputField, LinkedHashMap<String, Object> fieldMappingConfig, Context context, Map<String, Object>... sensorConfig)
{    Object value = (input == null) ? null : Iterables.getFirst(input.values(), null);    return map(value, outputField.get(0));}
0
public Map<String, Object> map(Map<String, Object> input, List<String> outputField, LinkedHashMap<String, Object> fieldMappingConfig, Context context, Map<String, Object>... sensorConfig)
{    Map<String, Object> ret = new HashMap<>();    Map<String, Object> intermediateVariables = new HashMap<>();    Set<String> outputs = new HashSet<>(outputField);    MapVariableResolver resolver = new MapVariableResolver(ret, intermediateVariables, input);    resolver.add(sensorConfig);    StellarProcessor processor = new CachingStellarProcessor();    for (Map.Entry<String, Object> kv : fieldMappingConfig.entrySet()) {        String oField = kv.getKey();        Object transformObj = kv.getValue();        if (transformObj != null) {            try {                Object o = processor.parse(transformObj.toString(), resolver, StellarFunctions.FUNCTION_RESOLVER(), context);                if (o != null) {                    if (outputs.contains(oField)) {                        ret.put(oField, o);                    } else {                        intermediateVariables.put(oField, o);                    }                } else {                    if (outputs.contains(oField)) {                        ret.put(oField, o);                    }                    if (o != null) {                        intermediateVariables.put(oField, o);                    } else {                                                intermediateVariables.remove(oField);                    }                }            } catch (Exception ex) {                throw new IllegalStateException("Unable to process transformation: " + transformObj.toString() + " for " + oField + " because " + ex.getMessage(), ex);            }        }    }    return ret;}
0
public static FieldValidation get(String validation)
{    try {        return FieldValidations.valueOf(validation).validation;    } catch (Exception ex) {        return ReflectionUtils.createInstance(validation);    }}
0
public Predicate<Object> getPredicate()
{    return domain -> DomainValidator.getInstance().isValid(domain == null ? null : domain.toString());}
0
public Predicate<Object> getPredicate()
{    return email -> EmailValidator.getInstance().isValid(email == null ? null : email.toString());}
0
public boolean isValid(String ip)
{    return validationPredicate.test(ip);}
0
public static IPType get(String type)
{    if (type == null) {        return DEFAULT;    } else {        try {            return IPType.valueOf(type);        } catch (Exception e) {            return DEFAULT;        }    }}
0
public List get(Map<String, Object> config)
{    Object o = config.get(key);    if (o == null) {        return Collections.singletonList("DEFAULT");    }    if (o instanceof ArrayList) {        return (ArrayList) o;    }    return Collections.singletonList(o);}
0
public boolean test(List<Object> strings)
{    IPType type = IPType.DEFAULT;    if (strings.isEmpty()) {        return false;    }    Object ip = strings.get(0);    if (ip == null) {        return false;    }    if (strings.size() >= 2) {        Object ipType = strings.get(1);        if (ipType != null) {            try {                type = IPType.get(ipType.toString());            } catch (Exception e) {                type = IPType.DEFAULT;            }        }    }    return type.isValid(ip.toString());}
0
public boolean isValid(Map<String, Object> input, Map<String, Object> validationConfig, Map<String, Object> globalConfig, Context context)
{    List types = Config.TYPE.get(validationConfig);    for (Object typeObject : types) {        IPType type = IPType.get(typeObject.toString());        for (Object o : input.values()) {            if (o == null || type.isValid(o.toString())) {                return true;            }        }    }    return false;}
0
public void initialize(Map<String, Object> validationConfig, Map<String, Object> globalConfig)
{}
0
public Predicate<Object> getPredicate()
{    return url -> UrlValidator.getInstance().isValid(url == null ? null : url.toString());}
0
public boolean test(List<Object> strings)
{    if (strings.isEmpty()) {        return false;    }    if (strings.size() >= 2) {        Object date = strings.get(0);        Object format = strings.get(1);        if (date == null || format == null) {            return false;        }        try {            SimpleDateFormat sdf = new SimpleDateFormat(format.toString());            sdf.setLenient(false);            sdf.parse(date.toString());            return true;        } catch (ParseException pe) {            return false;        }    } else {        return false;    }}
0
public T get(Map<String, Object> config, Class<T> clazz)
{    Object o = config.get(key);    if (o == null) {        return null;    }    return clazz.cast(o);}
0
public boolean isValid(Map<String, Object> input, Map<String, Object> validationConfig, Map<String, Object> globalConfig, Context context)
{    String format = Config.FORMAT.get(validationConfig, String.class);    if (format == null) {        return false;    }    SimpleDateFormat sdf = new SimpleDateFormat(format);    sdf.setLenient(false);    for (Object o : input.values()) {        if (o == null) {            return true;        }        try {            Date d = sdf.parse(o.toString());        } catch (ParseException e) {            return false;        }    }    return true;}
0
public void initialize(Map<String, Object> validationConfig, Map<String, Object> globalConfig)
{    String format = Config.FORMAT.get(validationConfig, String.class);    if (format == null) {        throw new IllegalStateException("You must specify '" + Config.FORMAT.key + "' in the config");    }    SimpleDateFormat sdf = new SimpleDateFormat(format);    sdf.setLenient(false);    try {        sdf.format(new Date());    } catch (Exception e) {        throw new IllegalStateException("Invalid date format: " + format, e);    }}
0
public Predicate<Object> getPredicate()
{    return x -> LongValidator.getInstance().isValid(x == null ? null : x.toString());}
0
public Predicate<Object> getPredicate()
{    return s -> !(s == null || s.toString().trim().isEmpty());}
0
protected boolean isNonExistentOk()
{    return false;}
0
public T get(Map<String, Object> config, Class<T> clazz)
{    Object o = config.get(key);    if (o == null) {        return null;    }    return clazz.cast(o);}
0
public boolean isValid(Map<String, Object> input, Map<String, Object> validationConfig, Map<String, Object> globalConfig, Context context)
{    String regex = Config.REGEX.get(validationConfig, String.class);    if (regex == null) {        return false;    }    for (Object o : input.values()) {        if (o != null && !o.toString().matches(regex)) {            return false;        }    }    return true;}
0
public void initialize(Map<String, Object> validationConfig, Map<String, Object> globalConfig)
{    String regex = Config.REGEX.get(validationConfig, String.class);    if (regex == null) {        throw new IllegalStateException("You must specify '" + Config.REGEX.key + "' in the config");    }}
0
public T get(Map<String, Object> config, Class<T> clazz)
{    Object o = config.get(key);    if (o == null) {        return null;    }    return clazz.cast(o);}
0
public boolean isValid(Map<String, Object> input, Map<String, Object> validationConfig, Map<String, Object> globalConfig, Context context)
{    String condition = Config.CONDITION.get(validationConfig, String.class);    if (condition == null) {        return true;    } else {        StellarPredicateProcessor processor = new StellarPredicateProcessor();        return processor.parse(condition, new MapVariableResolver(input, validationConfig, globalConfig), StellarFunctions.FUNCTION_RESOLVER(), context);    }}
0
public void initialize(Map<String, Object> validationConfig, Map<String, Object> globalConfig)
{    String condition = Config.CONDITION.get(validationConfig, String.class);    if (condition == null) {        throw new IllegalStateException("You must specify a condition.");    }    try {        new StellarPredicateProcessor().validate(condition);    } catch (Exception e) {        throw new IllegalStateException("Invalid condition: " + condition, e);    }}
0
public boolean isValid(Map<String, Object> input, Map<String, Object> validationConfig, Map<String, Object> globalConfig, Context context)
{    Predicate<Object> predicate = getPredicate();    if (isNonExistentOk()) {        for (Object o : input.values()) {            if (o != null && !predicate.test(o.toString())) {                return false;            }        }    } else {        for (Object o : input.values()) {            if (o == null || !predicate.test(o.toString())) {                return false;            }        }    }    return true;}
0
public boolean test(List<Object> input)
{    if (input.isEmpty()) {        return false;    }    Predicate<Object> predicate = getPredicate();    for (Object o : input) {        if (o == null || !predicate.test(o)) {            return false;        }    }    return true;}
0
public void initialize(Map<String, Object> validationConfig, Map<String, Object> globalConfig)
{}
0
protected boolean isNonExistentOk()
{    return true;}
0
public Iterator<byte[]> iterator()
{    return Iterators.concat(getIterators(files, config));}
0
private Iterator<byte[]>[] getIterators(List<Path> files, Configuration config)
{    return files.stream().map(f -> new SequenceFileIterator(f, config)).toArray(Iterator[]::new);}
0
public boolean cleanup() throws IOException
{    FileSystem fileSystem = FileSystem.get(config);    boolean success = true;    for (Path file : files) {        success &= fileSystem.delete(file, false);    }    return success;}
0
public boolean hasNext()
{    if (!finished && null == reader) {        try {            reader = new SequenceFile.Reader(config, SequenceFile.Reader.file(path));                    } catch (IOException e) {            throw new RuntimeException("Failed to get reader", e);        }    } else {            }    try {                if (!finished) {            if (null == next && reader.next(key, value)) {                next = value.copyBytes();            } else if (null == next) {                close();            }        }    } catch (IOException e) {        close();        throw new RuntimeException("Failed to get next record", e);    }    return (null != next);}
1
private void close()
{        finished = true;    try {        if (reader != null) {            reader.close();            reader = null;        }    } catch (IOException e) {                    }}
1
public byte[] next()
{    byte[] ret = null;    if (hasNext()) {        ret = next;                next = null;    } else {        throw new NoSuchElementException("No more records");    }    return ret;}
0
public RawMessage get(Map<String, Object> rawMetadata, byte[] rawMessage, boolean readMetadata, Map<String, Object> config)
{    return new RawMessage(rawMessage, rawMetadata);}
0
public void mergeMetadata(JSONObject message, Map<String, Object> metadata, boolean mergeMetadata, Map<String, Object> config)
{    if (mergeMetadata) {        message.putAll(metadata);    }}
0
public boolean mergeMetadataDefault()
{    return false;}
0
public boolean readMetadataDefault()
{    return false;}
0
public void mergeMetadata(JSONObject message, Map<String, Object> metadata, boolean mergeMetadata, Map<String, Object> config)
{        String prefix = MetadataUtil.INSTANCE.getMetadataPrefix(config);    String originalStringFromMetadata = (String) metadata.get(MetadataUtil.INSTANCE.prefixKey(prefix, Constants.Fields.ORIGINAL.getName()));    if (mergeMetadata) {        for (Map.Entry<String, Object> kv : metadata.entrySet()) {                        message.putIfAbsent(kv.getKey(), kv.getValue());        }    }    if (originalStringFromMetadata != null) {        message.put(Constants.Fields.ORIGINAL.getName(), originalStringFromMetadata);    }}
0
public boolean mergeMetadataDefault()
{    return true;}
0
public boolean readMetadataDefault()
{    return true;}
0
public String getMetadataPrefix(Map<String, Object> config)
{    String prefix = (String) config.getOrDefault(METADATA_PREFIX_CONFIG, METADATA_PREFIX);    if (StringUtils.isEmpty(prefix)) {        return null;    }    return prefix;}
0
public String prefixKey(String prefix, String key)
{    if (StringUtils.isEmpty(prefix)) {        return key;    } else {        return prefix + "." + key;    }}
0
public byte[] getMessage()
{    return message;}
0
public void setMessage(byte[] message)
{    this.message = message;}
0
public Map<String, Object> getMetadata()
{    return metadata;}
0
public void setMetadata(Map<String, Object> metadata)
{    this.metadata = metadata;}
0
public String toString()
{    return "RawMessage{" + "message=" + Arrays.toString(message) + ", metadata=" + metadata + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    RawMessage that = (RawMessage) o;    if (!Arrays.equals(getMessage(), that.getMessage()))        return false;    return getMetadata() != null ? getMetadata().equals(that.getMetadata()) : that.getMetadata() == null;}
0
public int hashCode()
{    int result = Arrays.hashCode(getMessage());    result = 31 * result + (getMetadata() != null ? getMetadata().hashCode() : 0);    return result;}
0
public RawMessage get(Map<String, Object> rawMetadata, byte[] originalMessage, boolean readMetadata, Map<String, Object> config)
{    return this.supplier.get(rawMetadata, originalMessage, readMetadata, config);}
0
public void mergeMetadata(JSONObject message, Map<String, Object> metadata, boolean mergeMetadata, Map<String, Object> config)
{    this.supplier.mergeMetadata(message, metadata, mergeMetadata, config);}
0
public boolean mergeMetadataDefault()
{    return this.supplier.mergeMetadataDefault();}
0
public boolean readMetadataDefault()
{    return this.supplier.readMetadataDefault();}
0
public void mark(String markName)
{    timing.mark(markName);}
0
public void log(String markName)
{    if (okToLog()) {        log(markName, "");    }}
0
public void log(String markName, String message)
{    if (okToLog()) {        if (timing.exists(markName)) {                    } else {                    }    }}
1
private boolean okToLog()
{    return logger.isDebugEnabled() && thresholdCalc.isPast(getPercentThreshold());}
0
private Integer getPercentThreshold()
{    return ConversionUtils.convert(getProperty(LOG_PERCENT, LOG_PERCENT_DEFAULT), Integer.class);}
0
private Object getProperty(String key, Object defaultValue)
{    return configSupplier.get().getOrDefault(key, defaultValue);}
0
public void log(String markName, String format, Object arg)
{    if (okToLog()) {        FormattingTuple formattedMessage = MessageFormatter.format(format, arg);        log(markName, formattedMessage.getMessage());    }}
0
public void log(String markName, String format, Object arg1, Object arg2)
{    if (okToLog()) {        FormattingTuple formattedMessage = MessageFormatter.format(format, arg1, arg2);        log(markName, formattedMessage.getMessage());    }}
0
public void log(String markName, String format, Object... arguments)
{    if (okToLog()) {        FormattingTuple formattedMessage = MessageFormatter.arrayFormat(format, arguments);        log(markName, formattedMessage.getMessage());    }}
0
public boolean isDebugEnabled()
{    return logger.isDebugEnabled();}
0
public boolean isPast(int percent)
{    double rd = Math.random();    if (rd <= toDecimal(percent)) {        return true;    }    return false;}
0
private double toDecimal(int percent)
{    return percent / 100.0;}
0
public void mark(String name)
{    startTimes.put(name, System.nanoTime());}
0
public long getElapsed(String name)
{    if (startTimes.containsKey(name)) {        return System.nanoTime() - startTimes.get(name);    } else {        return 0;    }}
0
public boolean exists(String name)
{    return startTimes.containsKey(name);}
0
public long currentTimeMillis()
{    return System.currentTimeMillis();}
0
public String currentTimeFormatted(String stdDateFormat)
{    SimpleDateFormat format = new SimpleDateFormat(stdDateFormat);    format.setTimeZone(TimeZone.getTimeZone(UTC));    return format.format(new Date(currentTimeMillis()));}
0
public String get(String variable)
{    return System.getenv().get(variable);}
0
public long currentTimeMillis()
{    return now_ms;}
0
public void elapseMillis(long duration_ms)
{    long instant_ms = now_ms + duration_ms;    if (duration_ms < 0) {        throw new IllegalArgumentClockNegative(String.format("Attempted to move backward in time, by %d milliseconds.", duration_ms));    } else if (instant_ms < 0) {        throw new IllegalArgumentClockOverflow(String.format("Attempted to advance beyond the edge of time, to epoch %d + %d.", now_ms, duration_ms));    }    now_ms = instant_ms;}
0
public void elapseSeconds(long duration_secs)
{    elapseMillis(TimeUnit.SECONDS.toMillis(duration_secs));}
0
public void advanceToMillis(long instant_ms)
{    if (instant_ms < now_ms) {        throw new IllegalArgumentClockNegative(String.format("Attempted to move backward in time, from epoch %d to %d.", now_ms, instant_ms));    }    if (instant_ms == now_ms) {        throw new IllegalArgumentClockZero(String.format("Time was set to current time, with null advance, at epoch %d.", now_ms));    }    now_ms = instant_ms;}
0
public void advanceToSeconds(long instant_secs)
{    advanceToMillis(TimeUnit.SECONDS.toMillis(instant_secs));}
0
public Set<String> generateCandidates(String domain)
{    Set<String> ret = new HashSet<>();    for (int i = 97; i < 123; ++i) {        char c = Character.toChars(i)[0];        ret.add(domain + c);    }    return ret;}
0
public String name()
{    return "Addition";}
0
public Set<String> generateCandidates(String originalString)
{    Set<String> ret = new HashSet<>();    char[] str = originalString.toCharArray();    for (int i = 0; i < str.length; ++i) {        char c = str[i];        for (int j : MASK) {            int maskedNum = (int) c ^ j;            char maskedChar = (char) maskedNum;            if ((maskedNum >= 48 && maskedNum <= 57) || (maskedNum >= 97 && maskedNum <= 122) || maskedNum == 45) {                ret.add(pasteTogether(str, i, maskedChar));            }        }    }    return ret;}
0
public String name()
{    return "Bitsquatting";}
0
private static String pasteTogether(char[] str, int replacementPoint, char maskedChar)
{    String ret = "";    for (int i = 0; i < replacementPoint; ++i) {        ret += str[i];    }    ret += maskedChar;    for (int i = replacementPoint + 1; i < str.length; ++i) {        ret += str[i];    }    return ret;}
0
public Set<String> generateCandidates(String originalString)
{    Set<String> result = new HashSet<>();    String domain = originalString;    if (StringUtils.isEmpty(domain)) {        return result;    }    if (isAce(domain)) {                domain = IDN.toUnicode(domain);    }    for (int ws = 0; ws < domain.length(); ws++) {        for (int i = 0; i < domain.length() - ws + 1; ++i) {            String win = domain.substring(i, i + ws);            for (int j = 0; j < ws; j++) {                char c = win.charAt(j);                if (glyphs.containsKey(c)) {                    for (String g : glyphs.get(c)) {                        String winNew = win.replaceAll("" + c, g);                        String d = domain.substring(0, i) + winNew + domain.substring(i + ws);                        result.add(d);                        if (!isAce(d)) {                            try {                                String dAscii = IDN.toASCII(d, IDN.ALLOW_UNASSIGNED);                                if (!d.equals(dAscii)) {                                    result.add(dAscii);                                }                            } catch (IllegalArgumentException iae) {                                                            }                        }                    }                }            }        }    }    return result;}
1
public static boolean isAce(String domainRaw)
{    String domain = domainRaw.toLowerCase();    return domain.startsWith("xn--") || domain.contains(".xn--");}
0
public String name()
{    return "Homoglyph";}
0
public Set<String> generateCandidates(String originalString)
{    Set<String> ret = new HashSet<>();    for (int i = 1; i < originalString.length(); ++i) {        ret.add(originalString.substring(0, i) + "-" + originalString.substring(i));    }    return ret;}
0
public String name()
{    return "Hyphenation";}
0
public Set<String> generateCandidates(String domain)
{    Set<String> ret = new HashSet<>();    for (int i = 1; i < domain.length() - 1; ++i) {        for (Keyboards keyboard : Keyboards.values()) {            String mapping = keyboard.getMapping().get(domain.charAt(i));            if (mapping != null) {                for (Character c : mapping.toCharArray()) {                    ret.add(domain.substring(0, i) + c + domain.charAt(i) + domain.substring(i + 1, domain.length()));                    ret.add(domain.substring(0, i) + domain.charAt(i) + c + domain.substring(i + 1, domain.length()));                }            }        }    }    return ret;}
0
public String name()
{    return "Insertion";}
0
public Map<Character, String> getMapping()
{    return mapping;}
0
public Set<String> generateCandidates(String domain)
{    HashSet<String> ret = new HashSet<>();    for (int i = 0; i < domain.length(); ++i) {        ret.add(domain.substring(0, i) + domain.substring(i + 1, domain.length()));    }    return ret;}
0
public String name()
{    return "Omission";}
0
public Set<String> generateCandidates(String domain)
{    Set<String> ret = new HashSet<>();    for (int i = 0; i < domain.length(); ++i) {        Character c = domain.charAt(i);        if (Character.isLetter(c)) {            ret.add(domain.substring(0, i) + c + c + domain.substring(i + 1, domain.length()));        }    }    return ret;}
0
public String name()
{    return "Repetition";}
0
public Set<String> generateCandidates(String domain)
{    Set<String> ret = new HashSet<>();    for (int i = 0; i < domain.length(); ++i) {        for (Keyboards keyboard : Keyboards.values()) {            String mapping = keyboard.getMapping().get(domain.charAt(i));            if (mapping != null) {                for (Character c : mapping.toCharArray()) {                    ret.add(domain.substring(0, i) + c + domain.substring(i + 1, domain.length()));                }            }        }    }    return ret;}
0
public String name()
{    return "Replacement";}
0
public Set<String> generateCandidates(String domain)
{    Set<String> ret = new HashSet<>();    for (int i = 1; i < domain.length(); ++i) {        Character c = domain.charAt(i);        Character prevC = domain.charAt(i - 1);        if (c != '-' && c != '.' && prevC != '-' && prevC != '.') {            ret.add(domain.substring(0, i) + "." + domain.substring(i, domain.length()));        }    }    return ret;}
0
public String name()
{    return "Subdomain";}
0
public Set<String> generateCandidates(String domain)
{    Set<String> ret = new HashSet<>();    for (int i = 0; i < domain.length() - 1; ++i) {        char nextC = domain.charAt(i + 1);        char c = domain.charAt(i);        if (nextC != c) {            ret.add(domain.substring(0, i) + nextC + c + domain.substring(i + 2));        }    }    return ret;}
0
public String name()
{    return "Transposition";}
0
public Set<String> generateCandidates(String originalString)
{    Set<String> candidates = strategy.generateCandidates(originalString);    candidates.remove(originalString);    return candidates;}
0
public static Set<String> generateAllCandidates(String originalString)
{    Set<String> ret = new HashSet<>();    for (TyposquattingStrategy s : values()) {        ret.addAll(s.generateCandidates(originalString));    }    return ret;}
0
public static TyposquattingStrategies byName(String name)
{    for (TyposquattingStrategies s : values()) {        if (s.strategy.name().equals(name)) {            return s;        }    }    return null;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() == 0) {        return null;    }    Object dnObj = args.get(0);    if (dnObj == null) {        return null;    }    if (!(dnObj instanceof String)) {        throw new IllegalStateException("Expected a domain without subdomains or a TLD, but got " + dnObj);    }    return TyposquattingStrategies.generateAllCandidates((String) dnObj);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Set<String> generateCandidates(String domain)
{    HashSet<String> ret = new HashSet<>();    for (int i = 0; i < domain.length(); ++i) {        char c = domain.charAt(i);        for (char vowel : VOWELS) {            if (VOWELS.contains(c)) {                ret.add(domain.substring(0, i) + vowel + domain.substring(i + 1));            }        }    }    return ret;}
0
public String name()
{    return "Vowel-swap";}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    return Optional.empty();}
0
public static Options getOptions(CLIOptions[] values)
{    Options ret = new Options();    for (CLIOptions o : values) {        ret.addOption(o.getOption());    }    return ret;}
0
public static void printHelp(String name, CLIOptions[] values)
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp(name, getOptions(values));}
0
public static EnumMap<OPT_T, Optional<Object>> createConfig(CommandLine cli, OPT_T[] values, Class<OPT_T> clazz)
{    EnumMap<OPT_T, Optional<Object>> ret = new EnumMap<>(clazz);    for (OPT_T option : values) {        ret.put(option, option.getHandler().getValue(option, cli));    }    return ret;}
0
public static CommandLine parse(String name, CommandLineParser parser, String[] args, CLIOptions[] values, CLIOptions helpOption)
{    try {        CommandLine cli = parser.parse(getOptions(values), args);        if (helpOption.has(cli)) {            printHelp(name, values);            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp(name, values);        System.exit(-1);        return null;    }}
0
public void compress(File inFile, File outFile) throws IOException
{    strategy.compress(inFile, outFile);}
0
public void decompress(File inFile, File outFile) throws IOException
{    strategy.decompress(inFile, outFile);}
0
public boolean test(File gzipFile)
{    return strategy.test(gzipFile);}
0
public void compress(File inFile, File outFile) throws IOException
{    try (FileInputStream fis = new FileInputStream(inFile);        FileOutputStream fos = new FileOutputStream(outFile);        GZIPOutputStream gzipOS = new GZIPOutputStream(fos)) {        byte[] buffer = new byte[1024];        int len;        while ((len = fis.read(buffer)) != -1) {            gzipOS.write(buffer, 0, len);        }    }}
0
public void decompress(File inFile, File outFile) throws IOException
{    try (FileInputStream fis = new FileInputStream(inFile);        GZIPInputStream gis = new GZIPInputStream(fis);        FileOutputStream fos = new FileOutputStream(outFile)) {        byte[] buffer = new byte[1024];        int len;        while ((len = gis.read(buffer)) != -1) {            fos.write(buffer, 0, len);        }    }}
0
public boolean test(File gzipFile)
{    try (FileInputStream fis = new FileInputStream(gzipFile);        GZIPInputStream gis = new GZIPInputStream(fis)) {        byte[] buffer = new byte[1024];                gis.read(buffer);    } catch (ZipException | EOFException e) {        return false;    } catch (IOException e) {        throw new IllegalStateException("Error occurred while attempting to validate gzip file", e);    }    return true;}
0
public void forEachRemaining(Consumer<? super String> action)
{    if (action == null) {        throw new NullPointerException();    }    try {        for (String line = null; (line = reader.readLine()) != null; ) {            action.accept(line);        }    } catch (RuntimeException e) {        throw e;    } catch (Exception e) {        throw new IllegalStateException(e);    }}
0
public boolean tryAdvance(Consumer<? super String> action)
{    if (action == null) {        throw new NullPointerException();    }    try {        final String line = reader.readLine();        if (line == null) {            return false;        }        action.accept(line);        return true;    } catch (RuntimeException e) {        throw e;    } catch (Exception e) {        throw new IllegalStateException(e);    }}
0
public Spliterator<String> trySplit()
{    final ConsumerWithLookback holder = new ConsumerWithLookback();    if (!tryAdvance(holder)) {        return null;    }    final String[] batch = new String[batchSize];    int j = 0;    do {        batch[j] = holder.value;    } while (++j < batchSize && tryAdvance(holder));    return spliterator(batch, 0, j, characteristics() | SIZED);}
0
public long estimateSize()
{    return Long.MAX_VALUE;}
0
public int characteristics()
{    return characteristics;}
0
public void accept(String string)
{    this.value = string;}
0
public static Stream<String> lineStream(BufferedReader in, int batchSize)
{    return lineStream(in, batchSize, false);}
0
public static Stream<String> lineStream(BufferedReader in, int batchSize, boolean isParallel)
{    return StreamSupport.stream(new ReaderSpliterator(in, batchSize), isParallel).onClose(() -> {        try {            in.close();        } catch (IOException e) {            throw new UncheckedIOException(e);        }    });}
0
public static String getMessageHash(JSONObject message, Collection<String> hashFields)
{    List<String> hashElements = hashFields.stream().map(errorField -> String.format("%s-%s", errorField, message.get(errorField))).collect(Collectors.toList());    return DigestUtils.sha256Hex(String.join("|", hashElements).getBytes(UTF_8));}
0
public static String getMessageHash(JSONObject message)
{    return DigestUtils.sha256Hex(message.toJSONString().getBytes(UTF_8));}
0
public static String getMessageHash(byte[] bytes)
{    return DigestUtils.sha256Hex(bytes);}
0
public static byte[] readBytes(String path) throws IOException
{    return readBytes(new Path(path));}
0
public static byte[] readBytes(Path inPath) throws IOException
{    FileSystem fs = FileSystem.get(inPath.toUri(), new Configuration());    try (FSDataInputStream inputStream = fs.open(inPath)) {        return IOUtils.toByteArray(inputStream);    }}
0
public static List<String> readFile(String path) throws IOException
{    return readFile(new Configuration(), path);}
0
public static List<String> readFile(Configuration config, String path) throws IOException
{    Path inPath = new Path(path);    FileSystem fs = FileSystem.get(inPath.toUri(), config);    try (FSDataInputStream inputStream = fs.open(inPath)) {        return IOUtils.readLines(inputStream, "UTF-8");    }}
0
public static void write(Configuration config, byte[] bytes, String path) throws IOException
{    Path outPath = new Path(path);    FileSystem fs = FileSystem.get(outPath.toUri(), config);    fs.mkdirs(outPath.getParent());    try (FSDataOutputStream outputStream = fs.create(outPath)) {        outputStream.write(bytes);        outputStream.flush();    }}
0
public TypeReference<T> get()
{    return new TypeReference<T>() {        @Override        public Type getType() {            return type;        }    };}
0
public Type getType()
{    return type;}
0
public T convert(Object original, Class<T> targetClass)
{    return _mapper.get().convertValue(original, targetClass);}
0
public ObjectMapper getMapper()
{    return _mapper.get();}
0
public T load(InputStream is, ReferenceSupplier<T> ref) throws IOException
{    return _mapper.get().readValue(is, (TypeReference<T>) ref.get());}
0
public T load(String is, ReferenceSupplier<T> ref) throws IOException
{    return _mapper.get().readValue(is, (TypeReference<T>) ref.get());}
0
public T load(File f, ReferenceSupplier<T> ref) throws IOException
{    try (InputStream is = new BufferedInputStream(new FileInputStream(f))) {        return _mapper.get().readValue(is, (TypeReference<T>) ref.get());    }}
0
public T load(InputStream is, Class<T> clazz) throws IOException
{    return _mapper.get().readValue(is, clazz);}
0
public T load(File f, Class<T> clazz) throws IOException
{    try (InputStream is = new BufferedInputStream(new FileInputStream(f))) {        return _mapper.get().readValue(is, clazz);    }}
0
public T load(String is, Class<T> clazz) throws IOException
{    return _mapper.get().readValue(is, clazz);}
0
public String toJSON(Object o, boolean pretty) throws JsonProcessingException
{    if (pretty) {        return _mapper.get().writerWithDefaultPrettyPrinter().writeValueAsString(o);    } else {        return _mapper.get().writeValueAsString(o);    }}
0
public byte[] toJSONPretty(String config) throws IOException
{    return toJSONPretty(readTree(config));}
0
public byte[] toJSONPretty(Object config) throws JsonProcessingException
{    return _mapper.get().writerWithDefaultPrettyPrinter().writeValueAsBytes(config);}
0
public JSONObject toJSONObject(Object o) throws JsonProcessingException, ParseException
{    return (JSONObject) _parser.get().parse(toJSON(o, false));}
0
 JsonNode readTree(String json) throws IOException
{    return _mapper.get().readTree(json);}
0
 JsonNode readTree(byte[] json) throws IOException
{    return _mapper.get().readTree(json);}
0
public byte[] applyPatch(String patch, String source) throws IOException
{    JsonNode patchNode = readTree(patch);    JsonNode sourceNode = readTree(source);    return toJSONPretty(JsonPatch.apply(patchNode, sourceNode));}
0
public byte[] applyPatch(byte[] patch, byte[] source) throws IOException
{    JsonNode patchNode = readTree(patch);    JsonNode sourceNode = readTree(source);    return toJSONPretty(JsonPatch.apply(patchNode, sourceNode));}
0
public Map<String, Object> applyPatch(List<Map<String, Object>> patch, Map<String, Object> source)
{    JsonNode originalNode = convert(source, JsonNode.class);    JsonNode patchNode = convert(patch, JsonNode.class);    JsonNode patched = JsonPatch.apply(patchNode, originalNode);    return _mapper.get().convertValue(patched, new TypeReference<Map<String, Object>>() {    });}
0
public List<String> getBrokersFromZookeeper(String zkQuorum) throws Exception
{    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    CuratorFramework framework = CuratorFrameworkFactory.newClient(zkQuorum, retryPolicy);    framework.start();    try {        return getBrokersFromZookeeper(framework);    } finally {        framework.close();    }}
0
public List<String> getBrokersFromZookeeper(CuratorFramework client) throws Exception
{    List<String> ret = new ArrayList<>();    for (String id : client.getChildren().forPath("/brokers/ids")) {        byte[] data = client.getData().forPath("/brokers/ids/" + id);        String brokerInfoStr = new String(data, StandardCharsets.UTF_8);        Map<String, Object> brokerInfo = JSONUtils.INSTANCE.load(brokerInfoStr, JSONUtils.MAP_SUPPLIER);        String host = (String) brokerInfo.get("host");        if (host != null) {            ret.add(host + ":" + brokerInfo.get("port"));        } else {            Object endpoints = brokerInfo.get("endpoints");            if (endpoints != null && endpoints instanceof List) {                List<String> eps = (List<String>) endpoints;                for (String url : eps) {                    ret.addAll(fromEndpoint(url));                }            }        }    }    return ret;}
0
public Map<String, Object> normalizeProtocol(Map<String, Object> configs)
{    if (configs.containsKey(SECURITY_PROTOCOL)) {        String protocol = normalizeProtocol((String) configs.get(SECURITY_PROTOCOL));        configs.put(SECURITY_PROTOCOL, protocol);    }    return configs;}
0
public String normalizeProtocol(String protocol)
{    if (protocol.equalsIgnoreCase("PLAINTEXTSASL") || protocol.equalsIgnoreCase("SASL_PLAINTEXT")) {        if (SecurityProtocol.getNames().contains("PLAINTEXTSASL")) {            return "PLAINTEXTSASL";        } else if (SecurityProtocol.getNames().contains("SASL_PLAINTEXT")) {            return "SASL_PLAINTEXT";        } else {            throw new IllegalStateException("Unable to find the appropriate SASL protocol, " + "viable options are: " + Joiner.on(",").join(SecurityProtocol.getNames()));        }    } else {        return protocol.trim();    }}
0
 List<String> fromEndpoint(String url)
{    List<String> ret = new ArrayList<>();    if (url != null) {        Iterable<String> splits = Splitter.on("//").split(url);        if (Iterables.size(splits) == 2) {            String hostPort = Iterables.getLast(splits);            ret.add(hostPort);        }    }    return ret;}
0
protected HashFunction initialValue()
{    return Hashing.murmur3_128(SEED);}
0
public byte[] getPrefix(byte[] key)
{    Hasher hasher = hFunction.get().newHasher();    hasher.putBytes(key);    return hasher.hash().asBytes();}
0
public byte[] merge(byte[] prefix, byte[] key)
{    byte[] val = new byte[key.length + prefix.length];    int offset = 0;    System.arraycopy(prefix, 0, val, offset, prefix.length);    offset += prefix.length;    System.arraycopy(key, 0, val, offset, key.length);    return val;}
0
public static LazyLogger getLogger(String name)
{    final Logger logger = org.slf4j.LoggerFactory.getLogger(name);    if (logger != null) {                return new LazyLoggerImpl(logger);    } else {        throw new NullPointerException(String.format("Logger not returned for class %s", name == null ? "Null String" : name));    }}
0
public static LazyLogger getLogger(Class clazz)
{    return getLogger(clazz.getName());}
0
public static LazyLogger getLogger(Logger logger)
{    if (logger != null) {        return new LazyLoggerImpl(logger);    } else {        throw new NullPointerException("Null logger passed");    }}
0
public Logger getLogger()
{    return logger;}
0
public String getName()
{    return logger.getName();}
0
public boolean isTraceEnabled()
{    return logger.isTraceEnabled();}
0
public void trace(String msg)
{    logger.trace(msg);}
0
public void trace(String format, Object arg)
{    logger.trace(format, arg);}
0
public void trace(String format, Supplier<Object> arg)
{    if (logger.isTraceEnabled()) {        logger.trace(format, arg.get());    }}
0
public void trace(String format, Object arg1, Object arg2)
{    logger.trace(format, arg1, arg2);}
0
public void trace(String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isTraceEnabled()) {        logger.trace(format, arg1.get(), arg2.get());    }}
0
public void trace(String format, Object... arguments)
{    logger.trace(format, arguments);}
0
public final void trace(String format, Supplier<Object>... arguments)
{    if (logger.isTraceEnabled()) {        logger.trace(format, Arrays.stream(arguments).map(Supplier::get).toArray());    }}
0
public void trace(String msg, Throwable t)
{    logger.trace(msg, t);}
0
public boolean isTraceEnabled(Marker marker)
{    return logger.isTraceEnabled(marker);}
0
public void trace(Marker marker, String msg)
{    logger.trace(marker, msg);}
0
public void trace(Marker marker, String format, Object arg)
{    logger.trace(marker, format, arg);}
0
public void trace(Marker marker, String format, Supplier<Object> arg)
{    if (logger.isTraceEnabled(marker)) {        logger.trace(marker, format, arg.get());    }}
0
public void trace(Marker marker, String format, Object arg1, Object arg2)
{    logger.trace(marker, format, arg1, arg2);}
0
public void trace(Marker marker, String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isTraceEnabled(marker)) {        logger.trace(marker, format, arg1.get(), arg2.get());    }}
0
public void trace(Marker marker, String format, Object... arguments)
{    logger.trace(marker, format, arguments);}
0
public final void trace(Marker marker, String format, Supplier<Object>... arguments)
{    if (logger.isTraceEnabled(marker)) {        logger.trace(marker, format, Arrays.stream(arguments).map(Supplier::get).toArray());    }}
0
public void trace(Marker marker, String msg, Throwable t)
{    logger.trace(marker, msg, t);}
0
public boolean isDebugEnabled()
{    return logger.isDebugEnabled();}
0
public void debug(String msg)
{    }
1
public void debug(String format, Object arg)
{    }
1
public void debug(String format, Supplier<Object> arg)
{    if (logger.isDebugEnabled()) {            }}
1
public void debug(String format, Object arg1, Object arg2)
{    }
1
public void debug(String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isDebugEnabled()) {            }}
1
public void debug(String format, Object... arguments)
{    }
1
public final void debug(String format, Supplier<Object>... arguments)
{    if (logger.isDebugEnabled()) {            }}
1
public void debug(String msg, Throwable t)
{    }
1
public boolean isDebugEnabled(Marker marker)
{    return logger.isDebugEnabled(marker);}
0
public void debug(Marker marker, String msg)
{    }
1
public void debug(Marker marker, String format, Object arg)
{    }
1
public void debug(Marker marker, String format, Supplier<Object> arg)
{    if (logger.isDebugEnabled(marker)) {            }}
1
public void debug(Marker marker, String format, Object arg1, Object arg2)
{    }
1
public void debug(Marker marker, String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isDebugEnabled(marker)) {            }}
1
public void debug(Marker marker, String format, Object... arguments)
{    }
1
public final void debug(Marker marker, String format, Supplier<Object>... arguments)
{    if (logger.isDebugEnabled(marker)) {            }}
1
public void debug(Marker marker, String msg, Throwable t)
{    }
1
public boolean isInfoEnabled()
{    return logger.isInfoEnabled();}
0
public void info(String msg)
{    }
1
public void info(String format, Object arg)
{    }
1
public void info(String format, Supplier<Object> arg)
{    if (logger.isInfoEnabled()) {            }}
1
public void info(String format, Object arg1, Object arg2)
{    }
1
public void info(String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isInfoEnabled()) {            }}
1
public void info(String format, Object... arguments)
{    }
1
public final void info(String format, Supplier<Object>... arguments)
{    if (logger.isInfoEnabled()) {            }}
1
public void info(String msg, Throwable t)
{    }
1
public boolean isInfoEnabled(Marker marker)
{    return logger.isInfoEnabled(marker);}
0
public void info(Marker marker, String msg)
{    }
1
public void info(Marker marker, String format, Object arg)
{    }
1
public void info(Marker marker, String format, Supplier<Object> arg)
{    if (logger.isInfoEnabled(marker)) {            }}
1
public void info(Marker marker, String format, Object arg1, Object arg2)
{    }
1
public void info(Marker marker, String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isInfoEnabled(marker)) {            }}
1
public void info(Marker marker, String format, Object... arguments)
{    }
1
public final void info(Marker marker, String format, Supplier<Object>... arguments)
{    if (logger.isInfoEnabled(marker)) {            }}
1
public void info(Marker marker, String msg, Throwable t)
{    }
1
public boolean isWarnEnabled()
{    return logger.isWarnEnabled();}
0
public void warn(String msg)
{    }
1
public void warn(String format, Object arg)
{    }
1
public void warn(String format, Supplier<Object> arg)
{    if (logger.isWarnEnabled()) {            }}
1
public void warn(String format, Object... arguments)
{    }
1
public final void warn(String format, Supplier<Object>... arguments)
{    if (logger.isWarnEnabled()) {            }}
1
public void warn(String format, Object arg1, Object arg2)
{    }
1
public void warn(String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isWarnEnabled()) {            }}
1
public void warn(String msg, Throwable t)
{    }
1
public boolean isWarnEnabled(Marker marker)
{    return logger.isWarnEnabled(marker);}
0
public void warn(Marker marker, String msg)
{    }
1
public void warn(Marker marker, String format, Object arg)
{    }
1
public void warn(Marker marker, String format, Supplier<Object> arg)
{    if (logger.isWarnEnabled(marker)) {            }}
1
public void warn(Marker marker, String format, Object arg1, Object arg2)
{    }
1
public void warn(Marker marker, String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isWarnEnabled(marker)) {            }}
1
public void warn(Marker marker, String format, Object... arguments)
{    }
1
public final void warn(Marker marker, String format, Supplier<Object>... arguments)
{    if (logger.isWarnEnabled(marker)) {            }}
1
public void warn(Marker marker, String msg, Throwable t)
{    }
1
public boolean isErrorEnabled()
{    return logger.isErrorEnabled();}
0
public void error(String msg)
{    }
1
public void error(String format, Object arg)
{    }
1
public void error(String format, Supplier<Object> arg)
{    if (logger.isErrorEnabled()) {            }}
1
public void error(String format, Object arg1, Object arg2)
{    }
1
public void error(String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isErrorEnabled()) {            }}
1
public void error(String format, Object... arguments)
{    }
1
public final void error(String format, Supplier<Object>... arguments)
{    if (logger.isErrorEnabled()) {            }}
1
public void error(String msg, Throwable t)
{    }
1
public boolean isErrorEnabled(Marker marker)
{    return logger.isErrorEnabled(marker);}
0
public void error(Marker marker, String msg)
{    }
1
public void error(Marker marker, String format, Object arg)
{    }
1
public void error(Marker marker, String format, Supplier<Object> arg)
{    if (logger.isErrorEnabled(marker)) {            }}
1
public void error(Marker marker, String format, Object arg1, Object arg2)
{    }
1
public final void error(Marker marker, String format, Supplier<Object> arg1, Supplier<Object> arg2)
{    if (logger.isErrorEnabled(marker)) {            }}
1
public void error(Marker marker, String format, Object... arguments)
{    }
1
public final void error(Marker marker, String format, Supplier<Object>... arguments)
{    if (logger.isErrorEnabled(marker)) {            }}
1
public void error(Marker marker, String msg, Throwable t)
{    }
1
public static String getGuid(JSONObject message)
{    return (String) message.get(Constants.GUID);}
0
public static String getSensorType(JSONObject message)
{    return (String) message.get(Constants.SENSOR_TYPE);}
0
public static T createInstance(String className, T defaultClass)
{    T instance;    if (className == null || className.length() == 0 || className.charAt(0) == '$') {        return defaultClass;    } else {        instance = createInstance(className);    }    return instance;}
0
public static T createInstance(String className)
{    T instance;    try {        Class<? extends T> clazz = (Class<? extends T>) Class.forName(className);        instance = createInstance(clazz);    } catch (ClassNotFoundException e) {        throw new IllegalStateException("Unable to instantiate connector: class not found", e);    }    return instance;}
0
public static T createInstance(Class<? extends T> clazz)
{    return createInstance(clazz, null, null);}
0
public static T createInstance(Class<? extends T> clazz, Class<?>[] parameterTypes, Object[] parameters)
{    T instance;    try {        if (parameterTypes != null) {            instance = clazz.getConstructor(parameterTypes).newInstance(parameters);        } else {            instance = clazz.getConstructor().newInstance();        }    } catch (InstantiationException e) {        throw new IllegalStateException("Unable to instantiate connector.", e);    } catch (IllegalAccessException e) {        throw new IllegalStateException("Unable to instantiate connector: illegal access", e);    } catch (InvocationTargetException e) {        throw new IllegalStateException("Unable to instantiate connector", e);    } catch (NoSuchMethodException e) {        throw new IllegalStateException("Unable to instantiate connector: no such method", e);    }    return instance;}
0
public static T createInstance(String className, Class<?>[] parameterTypes, Object[] parameters)
{    T instance;    try {        Class<? extends T> clazz = (Class<? extends T>) Class.forName(className);        instance = createInstance(clazz, parameterTypes, parameters);    } catch (ClassNotFoundException e) {        throw new IllegalStateException("Unable to instantiate connector: class not found", e);    }    return instance;}
0
public void throwRuntime(String reason)
{    throwRuntime(reason, Optional.empty());}
0
public void throwRuntime(String reason, Throwable t)
{    throwRuntime(reason, Optional.of(t));}
0
public void throwRuntime(String reason, Optional<Throwable> t)
{    throw func.apply(Pair.of(reason, t));}
0
private static String formatReason(Pair<String, Optional<Throwable>> p)
{    return formatReason(p.getLeft(), p.getRight());}
0
private static String formatReason(String reason, Optional<Throwable> t)
{    if (t.isPresent()) {        return format("%s - reason:%s", reason, t.get());    } else {        return format("%s", reason);    }}
0
protected Kryo initialValue()
{    Kryo ret = new Kryo();    ret.setReferences(true);    ret.setInstantiatorStrategy(new DefaultInstantiatorStrategy(new StdInstantiatorStrategy()));    ret.register(Arrays.asList("").getClass(), new ArraysAsListSerializer());    ret.register(Collections.EMPTY_LIST.getClass(), new CollectionsEmptyListSerializer());    ret.register(Collections.EMPTY_MAP.getClass(), new CollectionsEmptyMapSerializer());    ret.register(Collections.EMPTY_SET.getClass(), new CollectionsEmptySetSerializer());    ret.register(Collections.singletonList("").getClass(), new CollectionsSingletonListSerializer());    ret.register(Collections.singleton("").getClass(), new CollectionsSingletonSetSerializer());    ret.register(Collections.singletonMap("", "").getClass(), new CollectionsSingletonMapSerializer());    ret.register(GregorianCalendar.class, new GregorianCalendarSerializer());    ret.register(InvocationHandler.class, new JdkProxySerializer());    UnmodifiableCollectionsSerializer.registerSerializers(ret);    SynchronizedCollectionsSerializer.registerSerializers(ret);            ret.register(CGLibProxySerializer.CGLibProxyMarker.class, new CGLibProxySerializer());        ret.register(LocalDate.class, new JodaLocalDateSerializer());    ret.register(LocalDateTime.class, new JodaLocalDateTimeSerializer());        ImmutableListSerializer.registerSerializers(ret);    ImmutableSetSerializer.registerSerializers(ret);    ImmutableMapSerializer.registerSerializers(ret);    ImmutableMultimapSerializer.registerSerializers(ret);    return ret;}
0
public void setFallbackInstantiatorStrategy(final InstantiatorStrategy fallbackStrategy)
{    this.fallbackStrategy = fallbackStrategy;}
0
public InstantiatorStrategy getFallbackInstantiatorStrategy()
{    return fallbackStrategy;}
0
public ObjectInstantiator newInstantiatorOf(final Class type)
{    if (!Util.isAndroid) {                Class enclosingType = type.getEnclosingClass();        boolean isNonStaticMemberClass = enclosingType != null && type.isMemberClass() && !Modifier.isStatic(type.getModifiers());        if (!isNonStaticMemberClass) {            try {                final ConstructorAccess access = ConstructorAccess.get(type);                return new ObjectInstantiator() {                    @Override                    public Object newInstance() {                        try {                            return access.newInstance();                        } catch (Exception ex) {                            throw new KryoException("Error constructing instance of class: " + className(type), ex);                        }                    }                };            } catch (Exception ignored) {            }        }    }        try {        Constructor ctor;        try {            ctor = type.getConstructor((Class[]) null);        } catch (Exception ex) {            ctor = type.getDeclaredConstructor((Class[]) null);            ctor.setAccessible(true);        }        final Constructor constructor = ctor;        return new ObjectInstantiator() {            @Override            public Object newInstance() {                try {                    return constructor.newInstance();                } catch (Exception ex) {                    throw new KryoException("Error constructing instance of class: " + className(type), ex);                }            }        };    } catch (Exception ignored) {    }    if (fallbackStrategy == null) {        if (type.isMemberClass() && !Modifier.isStatic(type.getModifiers()))            throw new KryoException("Class cannot be created (non-static member class): " + className(type));        else            throw new KryoException("Class cannot be created (missing no-arg constructor): " + className(type));    }        return fallbackStrategy.newInstantiatorOf(type);}
0
public Object newInstance()
{    try {        return access.newInstance();    } catch (Exception ex) {        throw new KryoException("Error constructing instance of class: " + className(type), ex);    }}
0
public Object newInstance()
{    try {        return constructor.newInstance();    } catch (Exception ex) {        throw new KryoException("Error constructing instance of class: " + className(type), ex);    }}
0
public byte[] apply(Object o)
{    return toBytes(o);}
0
public T apply(byte[] bytes)
{    return fromBytes(bytes, clazz);}
0
public static byte[] toBytes(Object value)
{    try {        ByteArrayOutputStream bos = new ByteArrayOutputStream();        Output output = new Output(bos);        kryo.get().writeClassAndObject(output, value);        output.flush();        bos.flush();        return bos.toByteArray();    } catch (Throwable t) {                throw new IllegalStateException("Unable to serialize " + value + " because " + t.getMessage(), t);    }}
1
public static T fromBytes(byte[] value, Class<T> clazz)
{    try {        Input input = new Input(new ByteArrayInputStream(value));        return clazz.cast(kryo.get().readClassAndObject(input));    } catch (Throwable t) {                throw t;    }}
1
public static String join(String delim, Optional<String>... parts)
{    return Joiner.on(delim).join(Arrays.asList(parts).stream().filter(part -> part.isPresent()).map(part -> part.get()).toArray());}
0
public static String stripLines(String val, int numLines)
{    int start = org.apache.commons.lang3.StringUtils.ordinalIndexOf(val, System.lineSeparator(), numLines);    start = start >= 0 ? start : 0;    return val.substring(start);}
0
public static TimestampConverter getConverter(String converter)
{    if (converter != null) {        return TimestampConverters.valueOf(converter.toUpperCase()).converter;    } else {        throw new IllegalStateException(converter + " is not a valid timestamp converter: " + Joiner.on(",").join(TimestampConverters.values()));    }}
0
public long toNanoseconds(long in)
{    return converter.toNanoseconds(in);}
0
public MessageId getId()
{    return id;}
0
public MESSAGE_T getMessage()
{    return message;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    BulkMessage<?> that = (BulkMessage<?>) o;    return Objects.equals(id, that.id) && Objects.equals(message, that.message);}
0
public int hashCode()
{    return Objects.hash(id, message);}
0
public void addError(Throwable error, MessageId id)
{    errors.put(error, id);}
0
public void addAllErrors(Throwable error, Iterable<MessageId> ids)
{    if (ids != null) {        errors.putAll(error, ids);    }}
0
public boolean hasErrors()
{    return !errors.isEmpty();}
0
public void addSuccess(MessageId success)
{    successes.add(success);}
0
public void addAllSuccesses(Iterable<MessageId> allSuccesses)
{    if (allSuccesses != null) {        Iterables.addAll(successes, allSuccesses);    }}
0
public Map<Throwable, Collection<MessageId>> getErrors()
{    return errors.asMap();}
0
public List<MessageId> getSuccesses()
{    return successes;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    BulkWriterResponse that = (BulkWriterResponse) o;    if (!errors.equals(that.errors))        return false;    return successes.equals(that.successes);}
0
public int hashCode()
{    int result = errors.hashCode();    result = 31 * result + successes.hashCode();    return result;}
0
public String toString()
{    return "BulkWriterResponse{" + "errors=" + errors + ", successes=" + successes + '}';}
0
public String getId()
{    return id;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    MessageId messageId = (MessageId) o;    return Objects.equals(id, messageId.id);}
0
public int hashCode()
{    return Objects.hash(id);}
0
public String toString()
{    return "MessageId{" + "id='" + id + '\'' + '}';}
0
public void update(CuratorFramework client, String path, byte[] data) throws IOException
{    if (data.length != 0) {        String name = path.substring(path.lastIndexOf("/") + 1);        if (path.startsWith(getType().getZookeeperRoot())) {                        update(name, data);            reloadCallback(name, getType());        } else if (ConfigurationType.GLOBAL.getZookeeperRoot().equals(path)) {                        getConfigurations().updateGlobalConfig(data);            reloadCallback(name, ConfigurationType.GLOBAL);        }    }}
1
public void delete(CuratorFramework client, String path, byte[] data) throws IOException
{    String name = path.substring(path.lastIndexOf("/") + 1);    if (path.startsWith(getType().getZookeeperRoot())) {                delete(name);        reloadCallback(name, getType());    } else if (ConfigurationType.GLOBAL.getZookeeperRoot().equals(path)) {                getConfigurations().deleteGlobalConfig();        reloadCallback(name, ConfigurationType.GLOBAL);    }}
1
protected void reloadCallback(String name, ConfigurationType type)
{    reloadable.reloadCallback(name, type);}
0
protected T getConfigurations()
{    return configSupplier.get();}
0
public Class<EnrichmentConfigurations> getConfigurationClass()
{    return EnrichmentConfigurations.class;}
0
public void forceUpdate(CuratorFramework client)
{    try {        ConfigurationsUtils.updateEnrichmentConfigsFromZookeeper(getConfigurations(), client);    } catch (KeeperException.NoNodeException nne) {            } catch (Exception e) {            }}
1
public EnrichmentConfigurations defaultConfigurations()
{    return new EnrichmentConfigurations();}
0
public ConfigurationType getType()
{    return ConfigurationType.ENRICHMENT;}
0
public void delete(String name)
{    getConfigurations().delete(name);}
0
public void update(String name, byte[] data) throws IOException
{    getConfigurations().updateSensorEnrichmentConfig(name, data);}
0
public Class<IndexingConfigurations> getConfigurationClass()
{    return IndexingConfigurations.class;}
0
public void forceUpdate(CuratorFramework client)
{    try {        ConfigurationsUtils.updateSensorIndexingConfigsFromZookeeper(getConfigurations(), client);    } catch (KeeperException.NoNodeException nne) {            } catch (Exception e) {            }}
1
public IndexingConfigurations defaultConfigurations()
{    return new IndexingConfigurations();}
0
public ConfigurationType getType()
{    return ConfigurationType.INDEXING;}
0
public void delete(String name)
{    getConfigurations().delete(name);}
0
public void update(String name, byte[] data) throws IOException
{    getConfigurations().updateSensorIndexingConfig(name, data);}
0
public Class<ParserConfigurations> getConfigurationClass()
{    return ParserConfigurations.class;}
0
public void forceUpdate(CuratorFramework client)
{    try {        ConfigurationsUtils.updateParserConfigsFromZookeeper(getConfigurations(), client);    } catch (KeeperException.NoNodeException nne) {            } catch (Exception e) {            }}
1
public ParserConfigurations defaultConfigurations()
{    return new ParserConfigurations();}
0
public ConfigurationType getType()
{    return ConfigurationType.PARSER;}
0
public void delete(String name)
{    getConfigurations().delete(name);}
0
public void update(String name, byte[] data) throws IOException
{    getConfigurations().updateSensorParserConfig(name, data);}
0
public Class<ProfilerConfigurations> getConfigurationClass()
{    return ProfilerConfigurations.class;}
0
private ProfilerConfig readFromZookeeper(CuratorFramework client) throws Exception
{    byte[] raw = client.getData().forPath(PROFILER.getZookeeperRoot());    return JSONUtils.INSTANCE.load(new ByteArrayInputStream(raw), ProfilerConfig.class);}
0
public void forceUpdate(CuratorFramework client)
{    try {        ConfigurationsUtils.updateConfigsFromZookeeper(getConfigurations(), client);    } catch (KeeperException.NoNodeException nne) {            } catch (Exception e) {            }    try {        ProfilerConfig config = readFromZookeeper(client);        if (config != null) {            getConfigurations().updateProfilerConfig(config);        }    } catch (KeeperException.NoNodeException nne) {            } catch (Exception e) {            }}
1
public ProfilerConfigurations defaultConfigurations()
{    return new ProfilerConfigurations();}
0
public ConfigurationType getType()
{    return ConfigurationType.PROFILER;}
0
public void delete(String name)
{    getConfigurations().delete();}
0
public void update(String name, byte[] data) throws IOException
{    getConfigurations().updateProfilerConfig(data);}
0
public ConfigurationsUpdater<? extends Configurations> create(Map<Class<? extends Configurations>, Configurations> configs, Reloadable reloadCallback)
{    return updaterSupplier.create(configs, reloadCallback);}
0
private static Supplier<T> createSupplier(Class<T> clazz, Map<Class<? extends Configurations>, Configurations> configs)
{    return () -> clazz.cast(configs.get(clazz));}
0
public void start()
{    initializeCache(client);}
0
public void close()
{    Lock writeLock = lock.writeLock();    try {        writeLock.lock();        if (cache != null) {            cache.close();        }    } finally {        writeLock.unlock();    }}
0
public void reset()
{    Lock writeLock = lock.writeLock();    try {        writeLock.lock();        close();        initializeCache(client);    } finally {        writeLock.unlock();    }}
0
private void initializeCache(CuratorFramework client)
{    Lock writeLock = lock.writeLock();    try {        writeLock.lock();        SimpleEventListener listener = new SimpleEventListener.Builder().with(Iterables.transform(updaters, u -> u::update), TreeCacheEvent.Type.NODE_ADDED, TreeCacheEvent.Type.NODE_UPDATED).with(Iterables.transform(updaters, u -> u::delete), TreeCacheEvent.Type.NODE_REMOVED).build();        cache = new ZKCache.Builder().withClient(client).withListener(listener).withRoot(Constants.ZOOKEEPER_TOPOLOGY_ROOT).build();        for (ConfigurationsUpdater<? extends Configurations> updater : updaters) {            updater.forceUpdate(client);        }        cache.start();    } catch (Exception e) {                throw new IllegalStateException("Unable to initialize zookeeper cache: " + e.getMessage(), e);    } finally {        writeLock.unlock();    }}
1
public T get(Class<T> configClass)
{    Lock readLock = lock.readLock();    try {        readLock.lock();        return configClass.cast(configs.get(configClass));    } finally {        readLock.unlock();    }}
0
public void testMax()
{    Assert.assertEquals(Double.NEGATIVE_INFINITY, Aggregators.MAX.aggregate(ImmutableList.of(1, 5, -1, 7), new HashMap<>()), 1e-7);    Assert.assertEquals(Double.NEGATIVE_INFINITY, Aggregators.MAX.aggregate(ImmutableList.of(1, 5, -1, -2), new HashMap<>()), 1e-7);    Assert.assertEquals(7d, Aggregators.MAX.aggregate(ImmutableList.of(1, 5, -1, 7, 0), ImmutableMap.of(Aggregators.NEGATIVE_VALUES_TRUMP_CONF, "false")), 1e-7);}
0
public void testMin()
{    Assert.assertEquals(Double.NEGATIVE_INFINITY, Aggregators.MIN.aggregate(ImmutableList.of(1, 5, -1, 7, 0), new HashMap<>()), 1e-7);    Assert.assertEquals(Double.NEGATIVE_INFINITY, Aggregators.MIN.aggregate(ImmutableList.of(1, 5, -1, -2, 0), new HashMap<>()), 1e-7);    Assert.assertEquals(-1d, Aggregators.MIN.aggregate(ImmutableList.of(1, 5, -1, 7, 0), ImmutableMap.of(Aggregators.NEGATIVE_VALUES_TRUMP_CONF, "false")), 1e-7);}
0
public void testMinAllPositive()
{    Assert.assertEquals(1, Aggregators.MIN.aggregate(ImmutableList.of(1, 5, 7), ImmutableMap.of(Aggregators.NEGATIVE_VALUES_TRUMP_CONF, "false")), 1e-7);}
0
public void testMean()
{    Assert.assertEquals(Double.NEGATIVE_INFINITY, Aggregators.MEAN.aggregate(ImmutableList.of(1, 5, -1, 7, 0), new HashMap<>()), 1e-7);    Assert.assertEquals(12.0 / 5.0, Aggregators.MEAN.aggregate(ImmutableList.of(1, 5, -1, 7, 0), ImmutableMap.of(Aggregators.NEGATIVE_VALUES_TRUMP_CONF, "false")), 1e-7);}
0
public void testPositiveMean()
{    Assert.assertEquals(Double.NEGATIVE_INFINITY, Aggregators.POSITIVE_MEAN.aggregate(ImmutableList.of(1, 5, -1, 7, 0), new HashMap<>()), 1e-7);    Assert.assertEquals(13.0 / 3.0, Aggregators.POSITIVE_MEAN.aggregate(ImmutableList.of(1, 5, -1, 7, 0), ImmutableMap.of(Aggregators.NEGATIVE_VALUES_TRUMP_CONF, "false")), 1e-7);}
0
public void testSum()
{    Assert.assertEquals(Double.NEGATIVE_INFINITY, Aggregators.SUM.aggregate(ImmutableList.of(1, 5, -1, 7), new HashMap<>()), 1e-7);    Assert.assertEquals(1 + 5 + -1 + 7, Aggregators.SUM.aggregate(ImmutableList.of(1, 5, -1, 7), ImmutableMap.of(Aggregators.NEGATIVE_VALUES_TRUMP_CONF, "false")), 1e-7);}
0
private void cleanDir(File rootDir) throws IOException
{    if (rootDir.isDirectory()) {        try {            Files.delete(Paths.get(rootDir.toURI()));        } catch (DirectoryNotEmptyException dne) {            for (File f : rootDir.listFiles()) {                cleanDir(f);            }            rootDir.delete();        }    } else {        rootDir.delete();    }}
0
public void setup() throws Exception
{    testZkServer = new TestingServer(true);    zookeeperUrl = testZkServer.getConnectString();    client = ConfigurationsUtils.getClient(zookeeperUrl);    client.start();    File sensorDir = new File(new File(TestConstants.SAMPLE_CONFIG_PATH), ENRICHMENT.getDirectory());    sensors.addAll(Collections2.transform(Arrays.asList(sensorDir.list()), s -> Iterables.getFirst(Splitter.on('.').split(s), "null")));    tmpDir = TestUtils.createTempDir(this.getClass().getName());    configDir = TestUtils.createDir(tmpDir, "config");    parsersDir = TestUtils.createDir(configDir, "parsers");    enrichmentsDir = TestUtils.createDir(configDir, "enrichments");    indexingDir = TestUtils.createDir(configDir, "indexing");    pushAllConfigs();}
0
private void pushAllConfigs() throws Exception
{    pushAllConfigs(TestConstants.SAMPLE_CONFIG_PATH);}
0
private void pushAllConfigs(String inputDir) throws Exception
{    String[] args = new String[] { "-z", zookeeperUrl, "--mode", "PUSH", "--input_dir", inputDir };    ConfigurationManager manager = new ConfigurationManager();    manager.run(ConfigurationManager.ConfigurationOptions.parse(new PosixParser(), args));}
0
private void pullConfigs(boolean force) throws Exception
{    String[] args = null;    if (force) {        args = new String[] { "-z", zookeeperUrl, "--mode", "PULL", "--output_dir", outDir, "--force" };    } else {        args = new String[] { "-z", zookeeperUrl, "--mode", "PULL", "--output_dir", outDir };    }    ConfigurationManager manager = new ConfigurationManager();    manager.run(ConfigurationManager.ConfigurationOptions.parse(new PosixParser(), args));}
0
private void validateConfigsOnDisk(File configDir) throws IOException
{    File globalConfigFile = new File(configDir, "global.json");    Assert.assertTrue("Global config does not exist", globalConfigFile.exists());    validateConfig("global", GLOBAL, new String(Files.readAllBytes(Paths.get(globalConfigFile.toURI())), StandardCharsets.UTF_8));    for (String sensor : sensors) {        File sensorFile = new File(configDir, ENRICHMENT.getDirectory() + "/" + sensor + ".json");        Assert.assertTrue(sensor + " config does not exist", sensorFile.exists());        validateConfig(sensor, ENRICHMENT, new String(Files.readAllBytes(Paths.get(sensorFile.toURI())), StandardCharsets.UTF_8));    }}
0
public void testPull() throws Exception
{    cleanDir(new File(outDir));    pullConfigs(false);    validateConfigsOnDisk(new File(outDir));    try {                pullConfigs(false);        fail("Should have failed to pull configs in a directory structure that already exists.");    } catch (IllegalStateException t) {                validateConfigsOnDisk(new File(outDir));    }    pullConfigs(true);    validateConfigsOnDisk(new File(outDir));}
0
private void validateConfig(String name, ConfigurationType type, String data)
{    try {        type.deserialize(data);    } catch (Exception e) {        fail("Unable to load config " + name + ": " + data);    }}
0
public void testPushAll() throws Exception
{        pushAllConfigs();        final Set<String> sensorsInZookeeper = new HashSet<>();    final BooleanWritable foundGlobal = new BooleanWritable(false);    ConfigurationsUtils.visitConfigs(client, new ConfigurationsUtils.ConfigurationVisitor() {        @Override        public void visit(ConfigurationType configurationType, String name, String data) {            Assert.assertTrue(data.length() > 0);            validateConfig(name, configurationType, data);            if (configurationType == GLOBAL) {                validateConfig(name, configurationType, data);                foundGlobal.set(true);            } else {                sensorsInZookeeper.add(name);            }        }    });    Assert.assertEquals(true, foundGlobal.get());    Assert.assertEquals(sensorsInZookeeper, sensors);}
0
public void visit(ConfigurationType configurationType, String name, String data)
{    Assert.assertTrue(data.length() > 0);    validateConfig(name, configurationType, data);    if (configurationType == GLOBAL) {        validateConfig(name, configurationType, data);        foundGlobal.set(true);    } else {        sensorsInZookeeper.add(name);    }}
0
public void testPushAllWithBadConfig() throws Exception
{        File globalConfigFile = new File(configDir, "global.json");    TestUtils.write(globalConfigFile, badGlobalConfig);        File squidConfigFile = new File(parsersDir, "squid.json");    TestUtils.write(squidConfigFile, badParserConfig);    pushAllConfigs(configDir.getAbsolutePath());}
0
public void testPushGlobal() throws Exception
{        File configFile = new File(configDir, "global.json");    TestUtils.write(configFile, globalConfig);        pushConfigs(GLOBAL, configDir);        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(globalConfig);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(GLOBAL), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPushGlobalWithBadConfig() throws Exception
{        File configFile = new File(configDir, "global.json");    TestUtils.write(configFile, badGlobalConfig);        pushConfigs(GLOBAL, configDir);}
0
private void pushConfigs(ConfigurationType type, File configPath) throws Exception
{    pushConfigs(type, configPath, Optional.empty());}
0
private void pushConfigs(ConfigurationType type, File configPath, Optional<String> configName) throws Exception
{    String[] args = new String[] { "-z", zookeeperUrl, "--mode", "PUSH", "--config_type", type.toString(), "--input_dir", configPath.getAbsolutePath() };    if (configName.isPresent()) {        args = ArrayUtils.addAll(args, "--config_name", configName.get());    }    ConfigurationManager manager = new ConfigurationManager();    manager.run(ConfigurationManager.ConfigurationOptions.parse(new PosixParser(), args));}
0
private String dumpConfigs(ConfigurationType type) throws Exception
{    return dumpConfigs(type, Optional.empty());}
0
private String dumpConfigs(ConfigurationType type, Optional<String> configName) throws Exception
{    String[] args = new String[] { "-z", zookeeperUrl, "--mode", "DUMP", "--config_type", type.toString() };    if (configName.isPresent()) {        args = ArrayUtils.addAll(args, "--config_name", configName.get());    }    ConfigurationManager manager = new ConfigurationManager();    return redirectSystemOut(args, (a) -> {        manager.run(ConfigurationManager.ConfigurationOptions.parse(new PosixParser(), a));    });}
0
private String redirectSystemOut(final String[] args, RedirectCallback callback) throws Exception
{    PrintStream os = System.out;    try (OutputStream baos = new ByteArrayOutputStream();        PrintStream ps = new PrintStream(baos, false, StandardCharsets.UTF_8.name())) {        System.setOut(ps);        callback.call(args);        System.out.flush();        System.setOut(os);        return baos.toString();    } finally {        System.setOut(os);    }}
0
public void testPushParser() throws Exception
{        File configFile = new File(parsersDir, "myparser.json");    TestUtils.write(configFile, squidParserConfig);        pushConfigs(PARSER, configDir, Optional.of("myparser"));        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(squidParserConfig);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(PARSER, Optional.of("myparser")), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPushParserWithBadConfig() throws Exception
{        File configFile = new File(parsersDir, "badparser.json");    TestUtils.write(configFile, badParserConfig);        pushConfigs(PARSER, configDir, Optional.of("badparser"));}
0
public void testPushEnrichment() throws Exception
{        File configFile = new File(enrichmentsDir, "myenrichment.json");    TestUtils.write(configFile, someEnrichmentConfig);        pushConfigs(ENRICHMENT, configDir, Optional.of("myenrichment"));        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(someEnrichmentConfig);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(ENRICHMENT, Optional.of("myenrichment")), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPushEnrichmentWithBadConfig() throws Exception
{        File configFile = new File(enrichmentsDir, "badenrichment.json");    TestUtils.write(configFile, badEnrichmentConfig);        pushConfigs(ENRICHMENT, configDir, Optional.of("badenrichment"));}
0
public void testPushIndexing() throws Exception
{        File configFile = new File(indexingDir, "myindex.json");    TestUtils.write(configFile, someIndexingConfig);        pushConfigs(INDEXING, configDir, Optional.of("myindex"));        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(someIndexingConfig);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(INDEXING, Optional.of("myindex")), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPushIndexingWithBadConfig() throws Exception
{        File configFile = new File(indexingDir, "myindex.json");    TestUtils.write(configFile, badIndexingConfig);        pushConfigs(INDEXING, configDir, Optional.of("myindex"));}
0
public void testPushProfiler() throws Exception
{        File configFile = new File(configDir, "profiler.json");    TestUtils.write(configFile, someProfilerConfig);        Optional<String> configName = Optional.empty();    pushConfigs(PROFILER, configDir, configName);        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(someProfilerConfig);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(PROFILER, configName), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPushProfilerWithBadConfig() throws Exception
{        File configFile = new File(configDir, "profiler.json");    TestUtils.write(configFile, badProfilerConfig);        Optional<String> configName = Optional.empty();    pushConfigs(PROFILER, configDir, configName);}
0
public void testPatchGlobalFromFile() throws Exception
{        File patchFile = new File(tmpDir, "global-config-patch.json");    TestUtils.write(patchFile, somePatchConfig);        File configFile = new File(configDir, "global.json");    TestUtils.write(configFile, globalConfig);    pushConfigs(GLOBAL, configDir, Optional.of("global"));        patchConfigs(GLOBAL, Optional.of(patchFile), Optional.of("global"), Optional.empty(), Optional.empty(), Optional.empty());        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(expectedSomeConfig);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(GLOBAL, Optional.of("global")), 1));    Assert.assertThat(actual, equalTo(expected));}
0
private void patchConfigs(ConfigurationType type, Optional<File> patchPath, Optional<String> configName, Optional<PatchMode> patchMode, Optional<String> key, Optional<String> value) throws Exception
{    String[] args = new String[] { "-z", zookeeperUrl, "--mode", "PATCH", "--config_type", type.toString() };    if (configName.isPresent()) {        args = ArrayUtils.addAll(args, "--config_name", configName.get());    }    if (patchPath.isPresent()) {        args = ArrayUtils.addAll(args, "--patch_file", patchPath.get().getAbsolutePath());    } else if (patchMode.isPresent()) {        args = ArrayUtils.addAll(args, "--patch_mode", patchMode.get().toString(), "--patch_key", key.get(), "--patch_value", value.get());    }    ConfigurationManager manager = new ConfigurationManager();    manager.run(ConfigurationManager.ConfigurationOptions.parse(new PosixParser(), args));}
0
public void testPatchParserFromFile() throws Exception
{        File patchFile = new File(tmpDir, "parser-patch.json");    TestUtils.write(patchFile, someParserPatch);        File configFile = new File(parsersDir, "myparser.json");    TestUtils.write(configFile, squidParserConfig);    pushConfigs(PARSER, configDir, Optional.of("myparser"));        patchConfigs(PARSER, Optional.of(patchFile), Optional.of("myparser"), Optional.empty(), Optional.empty(), Optional.empty());        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(expectedPatchedParser);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(PARSER, Optional.of("myparser")), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPatchParserFromKeyValue() throws Exception
{        File configFile = new File(parsersDir, "myparser.json");    TestUtils.write(configFile, squidParserConfig);    pushConfigs(PARSER, configDir, Optional.of("myparser"));        patchConfigs(PARSER, Optional.empty(), Optional.of("myparser"), Optional.of(ADD), Optional.of("/parserConfig/timestampField"), Optional.of("\"\"heyjoe\"\""));        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(expectedPatchedParser);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(PARSER, Optional.of("myparser")), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPatchParserWithBadConfig() throws Exception
{        File patchFile = new File(tmpDir, "parser-patch.json");    TestUtils.write(patchFile, badParserPatch);        File configFile = new File(parsersDir, "myparser.json");    TestUtils.write(configFile, squidParserConfig);    pushConfigs(PARSER, configDir, Optional.of("myparser"));        patchConfigs(PARSER, Optional.of(patchFile), Optional.of("myparser"), Optional.empty(), Optional.empty(), Optional.empty());}
0
public void testPatchGlobalFromComplexKeyValue() throws Exception
{        File configFile = new File(configDir, "global.json");    TestUtils.write(configFile, globalConfig);    pushConfigs(GLOBAL, configDir, Optional.of("global"));        patchConfigs(GLOBAL, Optional.empty(), Optional.of("global"), Optional.of(ADD), Optional.of("/foo"), Optional.of("{ \"bar\" : { \"baz\" : [ \"bazval1\", \"bazval2\" ] } }"));        byte[] expected = JSONUtils.INSTANCE.toJSONPretty(expectedComplexConfig);    byte[] actual = JSONUtils.INSTANCE.toJSONPretty(stripLines(dumpConfigs(GLOBAL, Optional.of("global")), 1));    Assert.assertThat(actual, equalTo(expected));}
0
public void testPatchProfilerWithBadConfig() throws Exception
{        File patchFile = new File(tmpDir, "patch.json");    TestUtils.write(patchFile, badProfilerPatch);        File configFile = new File(configDir, "profiler.json");    TestUtils.write(configFile, someProfilerConfig);        pushConfigs(PROFILER, configDir, Optional.empty());        patchConfigs(PROFILER, Optional.of(patchFile), Optional.empty(), Optional.empty(), Optional.empty(), Optional.empty());}
0
public void tearDown() throws IOException
{    client.close();    testZkServer.close();    testZkServer.stop();}
0
public void setup()
{}
0
public void gets_value_of_specified_type()
{    ConfigOption option = newOption("foo");    Map<String, Object> config = new HashMap<>();    option.put(config, 25L);    assertThat(option.get(config, Long.class), equalTo(25L));    assertThat(option.get(mapWith("foo", 25L), Long.class), equalTo(25L));}
0
public void gets_value_of_specified_type_with_transform()
{    ConfigOption option = newOption("foo");    Map<String, Object> config = new HashMap<>();    option.put(config, "25");    BiFunction<String, Object, Long> transform = (s, o) -> o == null ? null : new Long(o.toString());    assertThat(option.get(config, transform, Long.class), equalTo(25L));    assertThat(option.get(mapWith("foo", "25"), transform, Long.class), equalTo(25L));}
0
public void gets_default_value_of_specified_type_with_transform()
{    ConfigOption option = newOption("foo");    Map<String, Object> config = new HashMap<>();    option.put(config, null);    BiFunction<String, Object, Long> transform = (s, o) -> o == null ? null : new Long(o.toString());    assertThat(option.getOrDefault(config, transform, Long.class, 25L), equalTo(25L));    assertThat(option.getOrDefault(mapWith("foo", null), transform, Long.class, 25L), equalTo(25L));}
0
public void gets_default_when_null_value()
{    ConfigOption option = newOption("foo");    Map<String, Object> config = new HashMap<>();    option.put(config, null);    assertThat(option.getOrDefault(config, Long.class, 0L), equalTo(0L));    assertThat(option.getOrDefault(mapWith("foo", null), Long.class, 0L), equalTo(0L));}
0
public void gets_object_transformed_by_class_cast()
{    ConfigOption option = newOption("foo");    Map<String, Object> config = new HashMap<>();    option.put(config, (Object) 25L);    assertThat(option.getTransformed(config, Long.class), equalTo(25L));    assertThat(option.getTransformed(mapWith("foo", (Object) 25L), Long.class), equalTo(25L));}
0
public void gets_default_null_with_cast_when_null()
{    ConfigOption option = newOption("foo");    Map<String, Object> config = new HashMap<>();    option.put(config, null);    assertThat(option.getTransformedOrDefault(config, Long.class, 25L), equalTo(25L));    assertThat(option.getTransformedOrDefault(mapWith("foo", null), Long.class, 25L), equalTo(25L));}
0
private Map<K, V> mapWith(K key, V val)
{    Map<K, V> map = new HashMap<>();    map.put(key, val);    return map;}
0
private ConfigOption newOption(final String key)
{    return new ConfigOption() {        @Override        public String getKey() {            return key;        }    };}
0
public String getKey()
{    return key;}
0
public void test() throws IOException
{    EqualsVerifier.forClass(Configurations.class).suppress(Warning.NONFINAL_FIELDS, Warning.NULL_FIELDS).usingGetClass().verify();    Configurations configurations = new Configurations();    try {        configurations.updateGlobalConfig((byte[]) null);        Assert.fail("Updating a config with null should throw an IllegalStateException");    } catch (IllegalStateException e) {    }    Assert.assertTrue(configurations.toString() != null && configurations.toString().length() > 0);}
0
public void setup() throws Exception
{    testZkServer = new TestingServer(true);    zookeeperUrl = testZkServer.getConnectString();    client = ConfigurationsUtils.getClient(zookeeperUrl);    client.start();    expectedGlobalConfig = ConfigurationsUtils.readGlobalConfigFromFile(TestConstants.SAMPLE_CONFIG_PATH);    expectedSensorParserConfigMap = ConfigurationsUtils.readSensorParserConfigsFromFile(TestConstants.PARSER_CONFIGS_PATH);    expectedSensorEnrichmentConfigMap = ConfigurationsUtils.readSensorEnrichmentConfigsFromFile(TestConstants.ENRICHMENTS_CONFIGS_PATH);}
0
public void test() throws Exception
{    Assert.assertTrue(expectedGlobalConfig.length > 0);    ConfigurationsUtils.writeGlobalConfigToZookeeper(expectedGlobalConfig, zookeeperUrl);    byte[] actualGlobalConfigBytes = ConfigurationsUtils.readGlobalConfigBytesFromZookeeper(client);    Assert.assertTrue(Arrays.equals(expectedGlobalConfig, actualGlobalConfigBytes));    Assert.assertTrue(expectedSensorParserConfigMap.size() > 0);    String testSensorType = "yaf";    byte[] expectedSensorParserConfigBytes = expectedSensorParserConfigMap.get(testSensorType);    ConfigurationsUtils.writeSensorParserConfigToZookeeper(testSensorType, expectedSensorParserConfigBytes, zookeeperUrl);    byte[] actualSensorParserConfigBytes = ConfigurationsUtils.readSensorParserConfigBytesFromZookeeper(testSensorType, client);    Assert.assertTrue(Arrays.equals(expectedSensorParserConfigBytes, actualSensorParserConfigBytes));    Assert.assertTrue(expectedSensorEnrichmentConfigMap.size() > 0);    byte[] expectedSensorEnrichmentConfigBytes = expectedSensorEnrichmentConfigMap.get(testSensorType);    ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(testSensorType, expectedSensorEnrichmentConfigBytes, zookeeperUrl);    byte[] actualSensorEnrichmentConfigBytes = ConfigurationsUtils.readSensorEnrichmentConfigBytesFromZookeeper(testSensorType, client);    Assert.assertTrue(Arrays.equals(expectedSensorEnrichmentConfigBytes, actualSensorEnrichmentConfigBytes));    String name = "testConfig";    Map<String, Object> testConfig = new HashMap<>();    testConfig.put("stringField", "value");    testConfig.put("intField", 1);    testConfig.put("doubleField", 1.1);    ConfigurationsUtils.writeConfigToZookeeper(name, testConfig, zookeeperUrl);    byte[] readConfigBytes = ConfigurationsUtils.readConfigBytesFromZookeeper(name, client);    Assert.assertTrue(Arrays.equals(JSONUtils.INSTANCE.toJSONPretty(testConfig), readConfigBytes));}
0
public void modifiedGlobalConfiguration() throws Exception
{        ConfigurationType type = ConfigurationType.GLOBAL;    ConfigurationsUtils.writeConfigToZookeeper(type, JSONUtils.INSTANCE.toJSONPretty(someParserConfig), zookeeperUrl);        byte[] actual = ConfigurationsUtils.readConfigBytesFromZookeeper(type, zookeeperUrl);    assertThat(actual, equalTo(JSONUtils.INSTANCE.toJSONPretty(someParserConfig)));}
0
public void modifiesSingleParserConfiguration() throws Exception
{        ConfigurationType type = ConfigurationType.PARSER;    String parserName = "a-happy-metron-parser";    byte[] config = JSONUtils.INSTANCE.toJSONPretty(someParserConfig);    ConfigurationsUtils.writeConfigToZookeeper(type, Optional.of(parserName), config, zookeeperUrl);        byte[] actual = ConfigurationsUtils.readConfigBytesFromZookeeper(type, Optional.of(parserName), zookeeperUrl);    assertThat(actual, equalTo(JSONUtils.INSTANCE.toJSONPretty(someParserConfig)));}
0
public void patchesGlobalConfigurationViaPatchJSON() throws Exception
{        final ConfigurationType type = ConfigurationType.GLOBAL;    byte[] config = JSONUtils.INSTANCE.toJSONPretty(someGlobalConfig);    ConfigurationsUtils.writeConfigToZookeeper(type, config, zookeeperUrl);        byte[] patch = JSONUtils.INSTANCE.toJSONPretty(patchGlobalConfig);    ConfigurationsUtils.applyConfigPatchToZookeeper(type, patch, zookeeperUrl);        byte[] actual = ConfigurationsUtils.readConfigBytesFromZookeeper(type, zookeeperUrl);    byte[] expected = JSONUtils.INSTANCE.toJSONPretty(modifiedGlobalConfig);    assertThat(actual, equalTo(expected));}
0
public void patchesParserConfigurationViaPatchJSON() throws Exception
{        final ConfigurationType type = ConfigurationType.PARSER;    final String parserName = "patched-metron-parser";    byte[] config = JSONUtils.INSTANCE.toJSONPretty(someParserConfig);    ConfigurationsUtils.writeConfigToZookeeper(type, Optional.of(parserName), config, zookeeperUrl);        byte[] patch = JSONUtils.INSTANCE.toJSONPretty(patchParserConfig);    ConfigurationsUtils.applyConfigPatchToZookeeper(type, Optional.of(parserName), patch, zookeeperUrl);        byte[] actual = ConfigurationsUtils.readConfigBytesFromZookeeper(type, Optional.of(parserName), zookeeperUrl);    byte[] expected = JSONUtils.INSTANCE.toJSONPretty(modifiedParserConfig);    assertThat(actual, equalTo(expected));}
0
public void tearDown() throws IOException
{    client.close();    testZkServer.close();    testZkServer.stop();}
0
public void testCanReadFromFile() throws Exception
{    Configuration configuration = new Configuration(Paths.get("./src/test/resources/config/"));    configuration.update();    checkResult(configuration);}
0
public void testCanReadFromZookeeper() throws Exception
{    CuratorFramework curatorFramework = mock(CuratorFramework.class);    ExistsBuilder existsBuilder = mock(ExistsBuilder.class);    GetDataBuilder getDataBuilder = mock(GetDataBuilder.class);    GetChildrenBuilder getChildrenBuilder = mock(GetChildrenBuilder.class);    when(getDataBuilder.forPath(ConfigurationType.GLOBAL.getZookeeperRoot())).thenReturn(mockGlobalData());    when(curatorFramework.checkExists()).thenReturn(existsBuilder);    when(curatorFramework.getData()).thenReturn(getDataBuilder);    when(curatorFramework.getChildren()).thenReturn(getChildrenBuilder);    when(getChildrenBuilder.forPath(anyString())).thenReturn(Collections.<String>emptyList());    Configuration configuration = new Configuration(Paths.get("foo"));    configuration.curatorFramework = curatorFramework;    configuration.update();    checkResult(configuration);}
0
private byte[] mockGlobalData()
{    JSONObject global = new JSONObject();    global.put(TEST_PROPERTY, TEST_VALUE);    return global.toString().getBytes(StandardCharsets.UTF_8);}
0
private void checkResult(Configuration configuration)
{    assertEquals("File contains 1 entry: ", 1, configuration.getGlobalConfig().size());    String testValue = configuration.getGlobalConfig().get(TEST_PROPERTY).toString();    assertEquals(TEST_PROPERTY + " should be \"" + TEST_VALUE + "\"", TEST_VALUE, testValue);}
0
public void shouldAllowNumericRuleScore() throws Exception
{        SensorEnrichmentConfig enrichment = (SensorEnrichmentConfig) ENRICHMENT.deserialize(triageRuleWithNumericScore);    ThreatTriageConfig threatTriage = enrichment.getThreatIntel().getTriageConfig();    assertNotNull(threatTriage);    List<RiskLevelRule> rules = threatTriage.getRiskLevelRules();    assertEquals(1, rules.size());    RiskLevelRule rule = rules.get(0);    assertEquals("Rule Name", rule.getName());    assertEquals("Rule Comment", rule.getComment());    assertEquals("ip_src_addr == '10.0.2.3'", rule.getRule());    assertEquals("'Rule Reason'", rule.getReason());    assertEquals("10", rule.getScoreExpression());}
0
public void shouldAllowScoreAsStellarExpression() throws Exception
{        SensorEnrichmentConfig enrichment = (SensorEnrichmentConfig) ENRICHMENT.deserialize(triageRuleWithScoreExpression);    ThreatTriageConfig threatTriage = enrichment.getThreatIntel().getTriageConfig();    assertNotNull(threatTriage);    List<RiskLevelRule> rules = threatTriage.getRiskLevelRules();    assertEquals(1, rules.size());    RiskLevelRule rule = rules.get(0);    assertEquals("Rule Name", rule.getName());    assertEquals("Rule Comment", rule.getComment());    assertEquals("'Rule Reason'", rule.getReason());    assertEquals("ip_src_addr == '10.0.2.3'", rule.getRule());    assertEquals("10 + 10", rule.getScoreExpression());}
0
public void testSerialization() throws Exception
{    EnrichmentConfig config = JSONUtils.INSTANCE.load(sourceConfigStr, EnrichmentConfig.class);    Assert.assertTrue(config.getFieldMap().get("stellar") instanceof Map);    Assert.assertTrue(config.getEnrichmentConfigs().get("stellar") instanceof ConfigHandler);    Assert.assertEquals(Configs.STELLAR, ((ConfigHandler) config.getEnrichmentConfigs().get("stellar")).getType());}
0
public void setup()
{    configurations = new IndexingConfigurations();}
0
public void shouldReturnDefaultSetDocumentId() throws Exception
{        assertFalse(configurations.isSetDocumentId("sensor", "writer"));}
0
public void shouldReturnGlobalSetDocumentId() throws Exception
{        configurations.updateGlobalConfig(globalConfig.getBytes(StandardCharsets.UTF_8));    assertTrue(configurations.isSetDocumentId("sensor", "writer"));    assertTrue(configurations.isSetDocumentId("anySensor", "writer"));}
0
public void shouldReturnSensorSetDocumentId() throws Exception
{        configurations.updateGlobalConfig(new HashMap<>());    configurations.updateSensorIndexingConfig("sensor", sensorConfig.getBytes(StandardCharsets.UTF_8));    assertTrue(configurations.isSetDocumentId("sensor", "writer"));    assertFalse(configurations.isSetDocumentId("anySensor", "writer"));}
0
public void sensorParserConfig_properties_populated_by_JSON_configuration() throws IOException
{    ParserConfigurations parserConfigs = new ParserConfigurations();    parserConfigs.updateSensorParserConfig("test-sensor", parserConfig.getBytes(StandardCharsets.UTF_8));    SensorParserConfig actualSensorConfig = parserConfigs.getSensorParserConfig("test-sensor");    assertThat(actualSensorConfig.getParserClassName(), equalTo("parser-class"));    assertThat(actualSensorConfig.getFilterClassName(), equalTo("filter-class"));    assertThat(actualSensorConfig.getSensorTopic(), equalTo("sensor-topic"));    assertThat(actualSensorConfig.getOutputTopic(), equalTo("output-topic"));    assertThat(actualSensorConfig.getErrorTopic(), equalTo("error-topic"));    assertThat(actualSensorConfig.getWriterClassName(), equalTo("writer-class"));    assertThat(actualSensorConfig.getErrorWriterClassName(), equalTo("error-writer-class"));    assertThat(actualSensorConfig.getReadMetadata(), equalTo(true));    assertThat(actualSensorConfig.getMergeMetadata(), equalTo(true));    assertThat(actualSensorConfig.getNumWorkers(), equalTo(40));    assertThat(actualSensorConfig.getNumAckers(), equalTo(40));    assertThat(actualSensorConfig.getSpoutParallelism(), equalTo(40));    assertThat(actualSensorConfig.getSpoutNumTasks(), equalTo(40));    assertThat(actualSensorConfig.getParserParallelism(), equalTo(40));    assertThat(actualSensorConfig.getParserNumTasks(), equalTo(40));    assertThat(actualSensorConfig.getErrorWriterParallelism(), equalTo(40));    assertThat(actualSensorConfig.getErrorWriterNumTasks(), equalTo(40));    assertThat(actualSensorConfig.getSecurityProtocol(), equalTo("security-protocol"));    assertThat(actualSensorConfig.getSpoutConfig(), not(new HashMap<>()));    assertThat(actualSensorConfig.getSpoutConfig().get("foo"), equalTo("bar"));    assertThat(actualSensorConfig.getStormConfig(), not(new HashMap<>()));    assertThat(actualSensorConfig.getStormConfig().get("storm"), equalTo("config"));    assertThat(actualSensorConfig.getCacheConfig(), not(new HashMap<>()));    assertThat(actualSensorConfig.getCacheConfig().get("stellar.cache.maxSize"), equalTo(20000));    assertThat(actualSensorConfig.getParserConfig(), not(new HashMap<>()));    assertThat(actualSensorConfig.getParserConfig().get("parser"), equalTo("config"));    assertThat(actualSensorConfig.getFieldTransformations(), not(new ArrayList<>()));    assertThat(actualSensorConfig.getFieldTransformations().get(0), not(nullValue()));    assertThat(((FieldTransformer) actualSensorConfig.getFieldTransformations().get(0)).getInput().size(), equalTo(1));    assertThat(((FieldTransformer) actualSensorConfig.getFieldTransformations().get(0)).getInput().get(0), equalTo("input-field"));    assertThat(((FieldTransformer) actualSensorConfig.getFieldTransformations().get(0)).getTransformation(), equalTo("REMOVE"));}
0
public void testFromJSONWithOnlyIfDefault() throws IOException
{    ProfileConfig profile = ProfileConfig.fromJSON(onlyIfDefault);    assertEquals("true", profile.getOnlyif());}
0
public void testToJSONWithOnlyIfDefault() throws Exception
{        ProfileConfig expected = ProfileConfig.fromJSON(onlyIfDefault);        String asJson = expected.toJSON();        ProfileConfig actual = ProfileConfig.fromJSON(asJson);    assertEquals(expected, actual);}
0
public void testFromJSONWithNameMissing() throws IOException
{    ProfileConfig.fromJSON(nameMissing);}
0
public void testFromJSONWithForeachMissing() throws IOException
{    ProfileConfig.fromJSON(foreachMissing);}
0
public void testFromJSONWithResultMissing() throws IOException
{    ProfileConfig.fromJSON(resultMissing);}
0
public void testFromJSONWithResultMissingProfileExpression() throws IOException
{    ProfileConfig.fromJSON(resultMissingProfileExpression);}
0
public void testFromJSONWithResultWithExpression() throws IOException
{    ProfileConfig profile = ProfileConfig.fromJSON(resultWithExpression);    assertEquals("2 + 2", profile.getResult().getProfileExpressions().getExpression());        assertEquals(0, profile.getResult().getTriageExpressions().getExpressions().size());}
0
public void testToJSONWithResultWithExpression() throws Exception
{        ProfileConfig expected = ProfileConfig.fromJSON(resultWithExpression);        String asJson = expected.toJSON();        ProfileConfig actual = ProfileConfig.fromJSON(asJson);    assertEquals(expected, actual);}
0
public void testFromJSONWithResultWithProfileOnly() throws IOException
{    ProfileConfig profile = ProfileConfig.fromJSON(resultWithProfileOnly);    assertEquals("2 + 2", profile.getResult().getProfileExpressions().getExpression());        assertEquals(0, profile.getResult().getTriageExpressions().getExpressions().size());}
0
public void testToJSONWithProfileOnly() throws Exception
{        ProfileConfig expected = ProfileConfig.fromJSON(resultWithProfileOnly);        String asJson = expected.toJSON();        ProfileConfig actual = ProfileConfig.fromJSON(asJson);    assertEquals(expected, actual);}
0
public void testFromJSONWithResultWithTriage() throws IOException
{    ProfileConfig profile = ProfileConfig.fromJSON(resultWithTriage);    assertEquals("4 + 4", profile.getResult().getTriageExpressions().getExpression("eight"));    assertEquals("8 + 8", profile.getResult().getTriageExpressions().getExpression("sixteen"));}
0
public void testToJSONWithResultWithTriage() throws Exception
{        ProfileConfig expected = ProfileConfig.fromJSON(resultWithTriage);        String asJson = expected.toJSON();        ProfileConfig actual = ProfileConfig.fromJSON(asJson);    assertEquals(expected, actual);}
0
public void testFromJSON() throws IOException
{    ProfilerConfig conf = ProfilerConfig.fromJSON(profile);    assertFalse(conf.getTimestampField().isPresent());    assertEquals(1, conf.getProfiles().size());}
0
public void testFromJSONWithNoTimestampField() throws IOException
{    ProfilerConfig conf = ProfilerConfig.fromJSON(noTimestampField);    assertFalse(conf.getTimestampField().isPresent());}
0
public void testFromJSONWithTimestampField() throws IOException
{    ProfilerConfig conf = ProfilerConfig.fromJSON(timestampField);    assertTrue(conf.getTimestampField().isPresent());}
0
public void testFromJSONTwoProfiles() throws IOException
{    ProfilerConfig conf = ProfilerConfig.fromJSON(twoProfiles);    assertEquals(2, conf.getProfiles().size());    assertFalse(conf.getTimestampField().isPresent());}
0
public void testToJSON() throws Exception
{        ProfilerConfig expected = ProfilerConfig.fromJSON(profile);        String asJson = expected.toJSON();        ProfilerConfig actual = ProfilerConfig.fromJSON(asJson);    assertEquals(expected, actual);}
0
public void testToJSONWithTriageExpression() throws Exception
{        ProfilerConfig expected = ProfilerConfig.fromJSON(profileWithTriageExpression);        String asJson = expected.toJSON();        ProfilerConfig actual = ProfilerConfig.fromJSON(asJson);    assertEquals(expected, actual);}
0
public void testToJSONWithTwoProfiles() throws Exception
{        ProfilerConfig expected = ProfilerConfig.fromJSON(twoProfiles);        String asJson = expected.toJSON();        ProfilerConfig actual = ProfilerConfig.fromJSON(asJson);    assertEquals(expected, actual);}
0
public void testKryoSerialization() throws Exception
{        ProfilerConfig expected = ProfilerConfig.fromJSON(profilesToSerialize);    assertNotNull(expected);    Kryo kryo = new Kryo();        ByteArrayOutputStream byteStream = new ByteArrayOutputStream();    Output output = new Output(byteStream);    kryo.writeObject(output, expected);        byte[] bits = output.toBytes();    assertNotNull(bits);        Input input = new Input(new ByteArrayInputStream(bits));    ProfilerConfig actual = kryo.readObject(input, ProfilerConfig.class);        assertNotNull(actual);    assertEquals(expected, actual);}
0
public void testJavaSerialization() throws Exception
{        ProfilerConfig expected = ProfilerConfig.fromJSON(profilesToSerialize);        ByteArrayOutputStream bytes = new ByteArrayOutputStream();    ObjectOutputStream out = new ObjectOutputStream(bytes);    out.writeObject(expected);        byte[] raw = bytes.toByteArray();    assertTrue(raw.length > 0);        ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(raw));    Object actual = in.readObject();        assertEquals(expected, actual);}
0
public void test() throws IOException
{    EqualsVerifier.forClass(SensorEnrichmentConfig.class).suppress(Warning.NONFINAL_FIELDS).usingGetClass().verify();    Map<String, byte[]> testSensorConfigMap = ConfigurationsUtils.readSensorEnrichmentConfigsFromFile(TestConstants.ENRICHMENTS_CONFIGS_PATH);    byte[] sensorConfigBytes = testSensorConfigMap.get("yaf");    SensorEnrichmentConfig sensorEnrichmentConfig = SensorEnrichmentConfig.fromBytes(sensorConfigBytes);    Assert.assertNotNull(sensorEnrichmentConfig);    Assert.assertTrue(sensorEnrichmentConfig.toString() != null && sensorEnrichmentConfig.toString().length() > 0);}
0
public void testSerDe() throws IOException
{    for (File enrichmentConfig : new File(new File(TestConstants.ENRICHMENTS_CONFIGS_PATH), "enrichments").listFiles()) {        SensorEnrichmentConfig config = null;        try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(enrichmentConfig), StandardCharsets.UTF_8))) {            String parserStr = IOUtils.toString(br);            config = SensorEnrichmentConfig.fromBytes(parserStr.getBytes(StandardCharsets.UTF_8));        }        SensorEnrichmentConfig config2 = SensorEnrichmentConfig.fromBytes(config.toJSON().getBytes(StandardCharsets.UTF_8));        Assert.assertEquals(config2, config);    }}
0
public void testThreatIntel() throws Exception
{    SensorEnrichmentConfig broSc = (SensorEnrichmentConfig) ConfigurationType.ENRICHMENT.deserialize(sourceConfigStr);    SensorEnrichmentUpdateConfig threatIntelConfig = JSONUtils.INSTANCE.load(threatIntelConfigStr, SensorEnrichmentUpdateConfig.class);    final Map<String, SensorEnrichmentConfig> finalEnrichmentConfig = new HashMap<>();    SensorEnrichmentUpdateConfig.SourceConfigHandler scHandler = new SensorEnrichmentUpdateConfig.SourceConfigHandler() {        @Override        public SensorEnrichmentConfig readConfig(String sensor) throws Exception {            if (sensor.equals("bro")) {                return JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);            } else {                throw new IllegalStateException("Tried to retrieve an unexpected sensor: " + sensor);            }        }        @Override        public void persistConfig(String sensor, SensorEnrichmentConfig config) throws Exception {            finalEnrichmentConfig.put(sensor, config);        }    };    SensorEnrichmentUpdateConfig.updateSensorConfigs(scHandler, threatIntelConfig.getSensorToFieldList());    Assert.assertNotNull(finalEnrichmentConfig.get("bro"));    Assert.assertNotSame(finalEnrichmentConfig.get("bro"), broSc);    Assert.assertEquals(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) finalEnrichmentConfig.get("bro").getThreatIntel().getFieldMap().get(Constants.SIMPLE_HBASE_THREAT_INTEL)).size(), 2);    Assert.assertEquals(1, finalEnrichmentConfig.get("bro").getThreatIntel().getTriageConfig().getRiskLevelRules().size());    Assert.assertTrue(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) finalEnrichmentConfig.get("bro").getThreatIntel().getFieldMap().get(Constants.SIMPLE_HBASE_THREAT_INTEL)).contains("ip_src_addr"));    Assert.assertTrue(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) finalEnrichmentConfig.get("bro").getThreatIntel().getFieldMap().get(Constants.SIMPLE_HBASE_THREAT_INTEL)).contains("ip_dst_addr"));    Assert.assertEquals(finalEnrichmentConfig.get("bro").toJSON(), finalEnrichmentConfig.get("bro").getThreatIntel().getFieldToTypeMap().keySet().size(), 2);    Assert.assertEquals(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) (finalEnrichmentConfig.get("bro").getThreatIntel().getFieldToTypeMap().get("ip_src_addr"))).size(), 2);    Assert.assertTrue(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) (finalEnrichmentConfig.get("bro").getThreatIntel().getFieldToTypeMap().get("ip_src_addr"))).contains("playful"));    Assert.assertTrue(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) (finalEnrichmentConfig.get("bro").getThreatIntel().getFieldToTypeMap().get("ip_src_addr"))).contains("malicious_ip"));    Assert.assertEquals(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) (finalEnrichmentConfig.get("bro").getThreatIntel().getFieldToTypeMap().get("ip_dst_addr"))).size(), 2);    Assert.assertTrue(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) (finalEnrichmentConfig.get("bro").getThreatIntel().getFieldToTypeMap().get("ip_dst_addr"))).contains("playful"));    Assert.assertTrue(finalEnrichmentConfig.get("bro").toJSON(), ((List<String>) (finalEnrichmentConfig.get("bro").getThreatIntel().getFieldToTypeMap().get("ip_dst_addr"))).contains("malicious_ip"));}
0
public SensorEnrichmentConfig readConfig(String sensor) throws Exception
{    if (sensor.equals("bro")) {        return JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    } else {        throw new IllegalStateException("Tried to retrieve an unexpected sensor: " + sensor);    }}
0
public void persistConfig(String sensor, SensorEnrichmentConfig config) throws Exception
{    finalEnrichmentConfig.put(sensor, config);}
0
public void testEnrichment() throws Exception
{    SensorEnrichmentConfig broSc = JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    SensorEnrichmentUpdateConfig config = JSONUtils.INSTANCE.load(enrichmentConfigStr, SensorEnrichmentUpdateConfig.class);    final Map<String, SensorEnrichmentConfig> outputScs = new HashMap<>();    SensorEnrichmentUpdateConfig.SourceConfigHandler scHandler = new SensorEnrichmentUpdateConfig.SourceConfigHandler() {        @Override        public SensorEnrichmentConfig readConfig(String sensor) throws Exception {            if (sensor.equals("bro")) {                return JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);            } else {                throw new IllegalStateException("Tried to retrieve an unexpected sensor: " + sensor);            }        }        @Override        public void persistConfig(String sensor, SensorEnrichmentConfig config) throws Exception {            outputScs.put(sensor, config);        }    };    SensorEnrichmentUpdateConfig.updateSensorConfigs(scHandler, config.getSensorToFieldList());    Assert.assertNotNull(outputScs.get("bro"));    Assert.assertNotSame(outputScs.get("bro"), broSc);    Assert.assertEquals(outputScs.get("bro").toJSON(), ((List<String>) outputScs.get("bro").getEnrichment().getFieldMap().get(Constants.SIMPLE_HBASE_ENRICHMENT)).size(), 2);    Assert.assertTrue(outputScs.get("bro").toJSON(), ((List<String>) outputScs.get("bro").getEnrichment().getFieldMap().get(Constants.SIMPLE_HBASE_ENRICHMENT)).contains("ip_src_addr"));    Assert.assertTrue(outputScs.get("bro").toJSON(), ((List<String>) outputScs.get("bro").getEnrichment().getFieldMap().get(Constants.SIMPLE_HBASE_ENRICHMENT)).contains("ip_dst_addr"));    Assert.assertEquals(outputScs.get("bro").toJSON(), outputScs.get("bro").getEnrichment().getFieldToTypeMap().keySet().size(), 2);    Assert.assertEquals(outputScs.get("bro").toJSON(), ((List<String>) (outputScs.get("bro").getEnrichment().getFieldToTypeMap().get("ip_src_addr"))).size(), 1);    Assert.assertEquals(outputScs.get("bro").toJSON(), ((List<String>) (outputScs.get("bro").getEnrichment().getFieldToTypeMap().get("ip_src_addr"))).get(0), "playful");    Assert.assertEquals(outputScs.get("bro").toJSON(), ((List<String>) (outputScs.get("bro").getEnrichment().getFieldToTypeMap().get("ip_dst_addr"))).size(), 1);    Assert.assertEquals(outputScs.get("bro").toJSON(), ((List<String>) (outputScs.get("bro").getEnrichment().getFieldToTypeMap().get("ip_dst_addr"))).get(0), "playful");}
0
public SensorEnrichmentConfig readConfig(String sensor) throws Exception
{    if (sensor.equals("bro")) {        return JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    } else {        throw new IllegalStateException("Tried to retrieve an unexpected sensor: " + sensor);    }}
0
public void persistConfig(String sensor, SensorEnrichmentConfig config) throws Exception
{    outputScs.put(sensor, config);}
0
public void testSerDe() throws IOException
{    for (File parserConfig : new File(new File(TestConstants.PARSER_CONFIGS_PATH), "parsers").listFiles()) {        SensorParserConfig config = null;        try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(parserConfig), StandardCharsets.UTF_8))) {            String parserStr = IOUtils.toString(br);            config = SensorParserConfig.fromBytes(parserStr.getBytes(StandardCharsets.UTF_8));        }        SensorParserConfig config2 = SensorParserConfig.fromBytes(config.toJSON().getBytes(StandardCharsets.UTF_8));        Assert.assertEquals(config2, config);    }}
0
public void testSplitter_listWithTemporaryVariables() throws IOException
{    JSONObject message = new JSONObject(ImmutableMap.of("domain_without_subdomains", "yahoo.com"));    EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(conf, EnrichmentConfig.class);    Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));    ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");    List<JSONObject> splits = Configs.STELLAR.splitByFields(message, null, x -> null, handler);    Assert.assertEquals(1, splits.size());    Map<String, Object> split = (Map<String, Object>) (splits.get(0)).get("");    Assert.assertEquals("yahoo.com", split.get("domain_without_subdomains"));    Assert.assertTrue(split.containsKey("dga_result"));    Assert.assertTrue(split.containsKey("dga_model_endpoint"));    Assert.assertTrue(split.containsKey("dga_result_map"));}
0
public void testSplitter_default() throws IOException
{    JSONObject message = getMessage();    for (String c : DEFAULT_CONFIGS) {        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        List<JSONObject> splits = Configs.STELLAR.splitByFields(message, null, x -> null, handler);        Assert.assertEquals(1, splits.size());        Map<String, Object> split = (Map<String, Object>) splits.get(0).get("");        Assert.assertEquals(3, split.size());        Assert.assertEquals("stellar_test", split.get("source.type"));        Assert.assertEquals("foo", split.get("string"));        Assert.assertNull(split.get("stmt1"));    }}
0
public void testGetSubgroups_default() throws IOException
{    for (String c : DEFAULT_CONFIGS) {        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        List<String> subgroups = Configs.STELLAR.getSubgroups(handler);        Assert.assertEquals("", subgroups.get(0));        Assert.assertEquals(1, subgroups.size());    }}
0
public void testSplitter_grouped() throws IOException
{    JSONObject message = getMessage();    for (String c : GROUPED_CONFIGS) {        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        List<JSONObject> splits = Configs.STELLAR.splitByFields(message, null, x -> null, handler);        Assert.assertEquals(2, splits.size());        {            Map<String, Object> split = (Map<String, Object>) splits.get(0).get("group1");            Assert.assertEquals(2, split.size());            Assert.assertEquals("stellar_test", split.get("source.type"));            Assert.assertNull(split.get("stmt1"));        }        {            Map<String, Object> split = (Map<String, Object>) splits.get(1).get("group2");            Assert.assertEquals(1, split.size());            Assert.assertEquals("foo", split.get("string"));        }    }}
0
public void testGetSubgroups_grouped() throws IOException
{    for (String c : GROUPED_CONFIGS) {        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        List<String> subgroups = Configs.STELLAR.getSubgroups(handler);        Assert.assertEquals("group1", subgroups.get(0));        Assert.assertEquals("group2", subgroups.get(1));        Assert.assertEquals(2, subgroups.size());    }}
0
public void testSplitter_mixed() throws IOException
{    JSONObject message = getMessage();    for (String c : Iterables.concat(MIXED_CONFIGS, ImmutableList.of(tempVarStellarConfig_list))) {        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        List<JSONObject> splits = Configs.STELLAR.splitByFields(message, null, x -> null, handler);        Assert.assertEquals(3, splits.size());        {            Map<String, Object> split = (Map<String, Object>) splits.get(0).get("group1");            Assert.assertEquals(2, split.size());            Assert.assertEquals("stellar_test", split.get("source.type"));            Assert.assertNull(split.get("stmt1"));        }        {            Map<String, Object> split = (Map<String, Object>) splits.get(1).get("group2");            Assert.assertEquals(1, split.size());            Assert.assertEquals("foo", split.get("string"));        }        {            Map<String, Object> split = (Map<String, Object>) splits.get(2).get("");            Assert.assertEquals(1, split.size());            Assert.assertEquals("stellar_test", split.get("source.type"));        }    }}
0
public void testGetSubgroups_mixed() throws IOException
{    for (String c : MIXED_CONFIGS) {        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        List<String> subgroups = Configs.STELLAR.getSubgroups(handler);        Assert.assertEquals("group1", subgroups.get(0));        Assert.assertEquals("group2", subgroups.get(1));        Assert.assertEquals("", subgroups.get(2));        Assert.assertEquals(3, subgroups.size());    }}
0
public static JSONObject getMessage() throws IOException
{    Map<String, Object> ret = JSONUtils.INSTANCE.load(message, JSONUtils.MAP_SUPPLIER);    return new JSONObject(ret);}
0
public void setup()
{    MockitoAnnotations.initMocks(this);}
0
public void strategies_build_writer_configs()
{    assertThat(PARSERS.createWriterConfig(writer, new ParserConfigurations()), instanceOf(ParserWriterConfiguration.class));    assertThat(ENRICHMENT.createWriterConfig(writer, new EnrichmentConfigurations()), instanceOf(EnrichmentWriterConfiguration.class));    assertThat(INDEXING.createWriterConfig(writer, new IndexingConfigurations()), instanceOf(IndexingWriterConfiguration.class));    assertThat(PROFILER.createWriterConfig(writer, new ProfilerConfigurations()), instanceOf(ProfilerWriterConfiguration.class));}
0
public void strategies_build_updaters()
{    assertThat(PARSERS.createUpdater(reloadable, ParserConfigurations::new), instanceOf(ParserUpdater.class));    assertThat(ENRICHMENT.createUpdater(reloadable, EnrichmentConfigurations::new), instanceOf(EnrichmentUpdater.class));    assertThat(INDEXING.createUpdater(reloadable, IndexingConfigurations::new), instanceOf(IndexingUpdater.class));    assertThat(PROFILER.createUpdater(reloadable, ProfilerConfigurations::new), instanceOf(ProfilerUpdater.class));}
0
public void gets_batch_size_and_timeout_from_global_config() throws IOException
{    EnrichmentConfigurations configs = new EnrichmentConfigurations();    configs.updateGlobalConfig(globalJson.getBytes(StandardCharsets.UTF_8));    EnrichmentWriterConfiguration writerConfig = new EnrichmentWriterConfiguration(configs);    assertThat("batch timeout should match global config setting", writerConfig.getBatchTimeout(null), equalTo(555));    assertThat("list should have single batch timeout matching global config setting", writerConfig.getAllConfiguredTimeouts(), equalTo(asList(555)));    assertThat("batch size should match global config setting", writerConfig.getBatchSize(null), equalTo(12345));}
0
public void testDefaultBatchSize()
{    IndexingWriterConfiguration config = new IndexingWriterConfiguration("hdfs", new IndexingConfigurations());    Assert.assertEquals(1, config.getBatchSize("foo"));}
0
public void testDefaultBatchTimeout()
{    IndexingWriterConfiguration config = new IndexingWriterConfiguration("hdfs", new IndexingConfigurations());    Assert.assertEquals(0, config.getBatchTimeout("foo"));}
0
public void testGetAllConfiguredTimeouts() throws FileNotFoundException, IOException
{        IndexingWriterConfiguration config = new IndexingWriterConfiguration("hdfs", new IndexingConfigurations());    Assert.assertEquals(0, config.getAllConfiguredTimeouts().size());        IndexingConfigurations iconfigs = new IndexingConfigurations();    iconfigs.updateSensorIndexingConfig(sensorType, new FileInputStream(sampleSensorIndexingConfigPath));    config = new IndexingWriterConfiguration("elasticsearch", iconfigs);    Assert.assertEquals(1, config.getAllConfiguredTimeouts().size());    Assert.assertEquals(7, (long) config.getAllConfiguredTimeouts().get(0));}
0
public void testDefaultIndex()
{    IndexingWriterConfiguration config = new IndexingWriterConfiguration("hdfs", new IndexingConfigurations());    Assert.assertEquals("foo", config.getIndex("foo"));}
0
public void testDefaultBatchSize()
{    ParserWriterConfiguration config = new ParserWriterConfiguration(new ParserConfigurations());    Assert.assertEquals(1, config.getBatchSize("foo"));}
0
public void testDefaultIndex()
{    ParserWriterConfiguration config = new ParserWriterConfiguration(new ParserConfigurations());    Assert.assertEquals("foo", config.getIndex("foo"));}
0
public void pulls_writer_configuration_from_parserConfig() throws IOException
{    ParserConfigurations parserConfigurations = new ParserConfigurations();    final String sensorName = "some-sensor";    parserConfigurations.updateSensorParserConfig("some-sensor", configJson.getBytes(StandardCharsets.UTF_8));    ParserWriterConfiguration writerConfiguration = new ParserWriterConfiguration(parserConfigurations);    assertThat("batch size should match", writerConfiguration.getBatchSize(sensorName), equalTo(5));    assertThat("batch timeout should match", writerConfiguration.getBatchTimeout(sensorName), equalTo(10000));    assertThat("index should match", writerConfiguration.getIndex(sensorName), equalTo("modified-index"));    assertThat("enabled should match", writerConfiguration.isEnabled(sensorName), equalTo(false));}
0
public void gets_batch_size_and_timeout_from_global_config() throws IOException
{    ProfilerConfigurations configs = new ProfilerConfigurations();    configs.updateGlobalConfig(globalJson.getBytes(StandardCharsets.UTF_8));    ProfilerWriterConfiguration writerConfig = new ProfilerWriterConfiguration(configs);    assertThat("batch timeout should match global config setting", writerConfig.getBatchTimeout(null), equalTo(555));    assertThat("list should have single batch timeout matching global config setting", writerConfig.getAllConfiguredTimeouts(), equalTo(asList(555)));    assertThat("batch size should match global config setting", writerConfig.getBatchSize(null), equalTo(12345));}
0
public void setup()
{    message1.put("value", "message1");    message2.put("value", "message2");}
0
public void getJSONObjectShouldReturnBasicInformation()
{    MetronError error = new MetronError().withMessage("test message").withErrorType(Constants.ErrorType.PARSER_ERROR).withSensorType(Collections.singleton("sensorType"));    JSONObject errorJSON = error.getJSONObject();    assertEquals("test message", errorJSON.get(Constants.ErrorFields.MESSAGE.getName()));    assertEquals(Constants.ErrorType.PARSER_ERROR.getType(), errorJSON.get(Constants.ErrorFields.ERROR_TYPE.getName()));    assertEquals("error", errorJSON.get(Constants.SENSOR_TYPE));    assertEquals("sensorType", errorJSON.get(Constants.ErrorFields.FAILED_SENSOR_TYPE.getName()));    String hostName = null;    try {        hostName = InetAddress.getLocalHost().getHostName();    } catch (UnknownHostException uhe) {        }    if (!StringUtils.isEmpty(hostName)) {        assertTrue(((String) errorJSON.get(Constants.ErrorFields.HOSTNAME.getName())).length() > 0);        assertEquals(hostName, (String) errorJSON.get(Constants.ErrorFields.HOSTNAME.getName()));    }    assertTrue(((long) errorJSON.get(Constants.ErrorFields.TIMESTAMP.getName())) > 0);}
0
public void getJSONObjectShouldHandleThrowable()
{    Throwable e = new Exception("test exception");    MetronError error = new MetronError().withThrowable(e);    JSONObject errorJSON = error.getJSONObject();    assertEquals("java.lang.Exception: test exception", errorJSON.get(Constants.ErrorFields.EXCEPTION.getName()));    assertTrue(((String) errorJSON.get(Constants.ErrorFields.STACK.getName())).startsWith("java.lang.Exception: test exception"));    assertEquals(e.getMessage(), errorJSON.get(Constants.ErrorFields.MESSAGE.getName()));}
0
public void getJSONObjectShouldIncludeRawMessages()
{    JSONObject message1 = new JSONObject();    JSONObject message2 = new JSONObject();    message1.put("value", "message1");    message2.put("value", "message2");    MetronError error = new MetronError().withRawMessages(Arrays.asList(message1, message2));    JSONObject errorJSON = error.getJSONObject();    assertEquals("{\"value\":\"message1\"}", errorJSON.get(Constants.ErrorFields.RAW_MESSAGE.getName() + "_0"));    assertEquals("{\"value\":\"message2\"}", errorJSON.get(Constants.ErrorFields.RAW_MESSAGE.getName() + "_1"));    error = new MetronError().addRawMessage("raw message".getBytes(StandardCharsets.UTF_8));    errorJSON = error.getJSONObject();    assertEquals("raw message", errorJSON.get(Constants.ErrorFields.RAW_MESSAGE.getName()));            assertEquals("3b02cb29676bc448c69da1ec5eef7c89f4d6dc6a5a7ce0296ea25b207eea36be", errorJSON.get(Constants.ErrorFields.ERROR_HASH.getName()));    error = new MetronError().addRawMessage(message1);    errorJSON = error.getJSONObject();    assertEquals("{\"value\":\"message1\"}", errorJSON.get(Constants.ErrorFields.RAW_MESSAGE.getName()));    assertEquals("e8aaf87c8494d345aac2d612ffd94fcf0b98c975fe6c4b991e2f8280a3a0bd10", errorJSON.get(Constants.ErrorFields.ERROR_HASH.getName()));}
0
public void getJSONObjectShouldIncludeErrorFields()
{    JSONObject message = new JSONObject();    message.put("field1", "value1");    message.put("field2", "value2");    MetronError error = new MetronError().addRawMessage(message).withErrorFields(Sets.newHashSet("field1", "field2"));    JSONObject errorJSON = error.getJSONObject();    assertEquals(Sets.newHashSet("field1", "field2"), Sets.newHashSet(((String) errorJSON.get(Constants.ErrorFields.ERROR_FIELDS.getName())).split(",")));    assertEquals("04a2629c39e098c3944be85f35c75876598f2b44b8e5e3f52c59fa1ac182817c", errorJSON.get(Constants.ErrorFields.ERROR_HASH.getName()));}
0
public void shouldIncludeMessageMetadata()
{        Map<String, Object> metadata = new HashMap<>();    metadata.put("metron.metadata.topic", "bro");    metadata.put("metron.metadata.partition", 0);    metadata.put("metron.metadata.offset", 123);    JSONObject message = new JSONObject();    message.put("field1", "value1");    message.put("field2", "value2");    MetronError error = new MetronError().addRawMessage(message).withMetadata(metadata);        JSONObject errorMessage = error.getJSONObject();    assertEquals("bro", errorMessage.get("metron.metadata.topic"));    assertEquals(0, errorMessage.get("metron.metadata.partition"));    assertEquals(123, errorMessage.get("metron.metadata.offset"));}
0
public void shouldNotIncludeEmptyMetadata()
{        Map<String, Object> metadata = new HashMap<>();    JSONObject message = new JSONObject();    message.put("field1", "value1");    message.put("field2", "value2");    MetronError error = new MetronError().addRawMessage(message).withMetadata(metadata);        JSONObject errorMessage = error.getJSONObject();    assertFalse(errorMessage.containsKey("metron.metadata.topic"));    assertFalse(errorMessage.containsKey("metron.metadata.partition"));    assertFalse(errorMessage.containsKey("metron.metadata.offset"));}
0
public void testWithColons() throws Exception
{    String actual = new DeDotFieldNameConverter().convert("testfield.with.colons");    assertEquals("testfield:with:colons", actual);}
0
public void testNoColons() throws Exception
{    String actual = new DeDotFieldNameConverter().convert("test-field-no-colons");    assertEquals("test-field-no-colons", actual);}
0
private WriterConfiguration createConfig(String writer, String sensor, String json) throws Exception
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    indexingConfig.updateSensorIndexingConfig(sensor, json.getBytes(StandardCharsets.UTF_8));    return new IndexingWriterConfiguration(writer, indexingConfig);}
0
public void testCreateDedot() throws Exception
{    final String writer = "elasticsearch";    final String sensor = "bro";    WriterConfiguration config = createConfig(writer, sensor, jsonWithDedot);        FieldNameConverter converter = FieldNameConverters.create(sensor, config);    assertEquals(FieldNameConverters.DEDOT, converter);}
0
public void testCreateNoop() throws Exception
{    final String writer = "elasticsearch";    final String sensor = "bro";    WriterConfiguration config = createConfig(writer, sensor, jsonWithNoop);        FieldNameConverter converter = FieldNameConverters.create(sensor, config);    assertEquals(FieldNameConverters.NOOP, converter);}
0
public void testCreateDefault() throws Exception
{    final String writer = "elasticsearch";    final String sensor = "bro";    WriterConfiguration config = createConfig(writer, sensor, jsonWithNoConverter);        FieldNameConverter converter = FieldNameConverters.create(sensor, config);    assertEquals(FieldNameConverters.DEDOT, converter);}
0
public void testConfigChange() throws Exception
{    final String writer = "elasticsearch";    final String sensor = "bro";        WriterConfiguration config = createConfig(writer, sensor, jsonWithNoConverter);    assertEquals(FieldNameConverters.DEDOT, FieldNameConverters.create(sensor, config));        WriterConfiguration newConfig = createConfig(writer, sensor, jsonWithNoop);    assertEquals(FieldNameConverters.NOOP, FieldNameConverters.create(sensor, newConfig));}
0
public void testCreateInvalid() throws Exception
{    final String writer = "elasticsearch";    final String sensor = "bro";    WriterConfiguration config = createConfig(writer, sensor, jsonWithInvalidConverter);        FieldNameConverter converter = FieldNameConverters.create(sensor, config);    assertEquals(FieldNameConverters.DEDOT, converter);}
0
public void testCreateBlank() throws Exception
{    final String writer = "elasticsearch";    final String sensor = "bro";    WriterConfiguration config = createConfig(writer, sensor, jsonWithInvalidConverter);        FieldNameConverter converter = FieldNameConverters.create(sensor, config);    assertEquals(FieldNameConverters.DEDOT, converter);}
0
public Map<String, Object> map(Map<String, Object> input, List<String> outputField, LinkedHashMap<String, Object> fieldMappingConfig, Context context, Map<String, Object>... sensorConfig)
{    return ImmutableMap.of(outputField.get(0), Joiner.on(fieldMappingConfig.get("delim").toString()).join(input.entrySet()));}
0
public void testValidSerde_simple() throws IOException
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(config));    Assert.assertEquals(1, c.getFieldTransformations().size());    Assert.assertEquals(IPProtocolTransformation.class, c.getFieldTransformations().get(0).getFieldTransformation().getClass());    Assert.assertEquals(ImmutableList.of("protocol"), c.getFieldTransformations().get(0).getInput());}
0
public void testInValidSerde_missingMapping() throws IOException
{    SensorParserConfig.fromBytes(Bytes.toBytes(badConfigMissingMapping));}
0
public void testComplexMapping() throws IOException
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(complexConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    Assert.assertNotNull(handler);    Assert.assertEquals(ImmutableMap.of("output", "field1=value1,field2=value2"), handler.transform(new JSONObject(ImmutableMap.of("field1", "value1", "field2", "value2")), Context.EMPTY_CONTEXT(), c.getParserConfig()));}
0
public void testSimpleMapping() throws IOException
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(config));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    Assert.assertNotNull(handler);    Assert.assertEquals(ImmutableMap.of("protocol", "TCP"), handler.transform(new JSONObject(ImmutableMap.of("protocol", 6)), Context.EMPTY_CONTEXT(), c.getParserConfig()));}
0
private String transform(String in, String config) throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(config));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            put("in_field", in);                        put("dummy_field", "dummy");        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    return (String) input.get("out_field");}
0
public void smoketest() throws Exception
{    Assert.assertEquals("option_1", transform("foo", routeSingleInSingleOut));    Assert.assertNull(transform("bar", routeSingleInSingleOut));}
0
public void testListOfRegexes() throws Exception
{    Assert.assertEquals("option_2", transform("I am mortron", routeSingleInSingleOut));    Assert.assertEquals("option_2", transform("metron is for smelling", routeSingleInSingleOut));}
0
public void testPrecedence() throws Exception
{    Assert.assertEquals("option_1", transform("metron is for foorensic cybersecurity", routeSingleInSingleOut));}
0
public void testMissingInput() throws Exception
{    Assert.assertNull(transform("metron", routeMissingInput));}
0
public void testMissingOutput() throws Exception
{    Assert.assertNull(transform("metron", routeMissingOutput));}
0
public void testMultiOutput() throws Exception
{    Assert.assertEquals("option_1", transform("foo", routeMultiOutput));    Assert.assertNull(transform("bar", routeMultiOutput));}
0
public void testBadRegex() throws Exception
{    Assert.assertEquals("option_2", transform("metron", routeBadRegex));}
0
public void testUnconditionalRemove() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(removeUnconditionalConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            put("field1", "foo");        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertFalse(input.containsKey("field1"));}
0
public void testConditionalRemove() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(removeConditionalConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    {        JSONObject input = new JSONObject(new HashMap<String, Object>() {            {                put("field1", "foo");            }        });        handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());                Assert.assertTrue(input.containsKey("field1"));        Assert.assertFalse(input.containsKey("field2"));    }    {        JSONObject input = new JSONObject(new HashMap<String, Object>() {            {                put("field1", "foo");                put("field2", "bar");            }        });        handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());                Assert.assertTrue(input.containsKey("field1"));        Assert.assertTrue(input.containsKey("field2"));    }    {        JSONObject input = new JSONObject(new HashMap<String, Object>() {            {                put("field1", "bar");                put("field2", "foo");            }        });                handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());        Assert.assertFalse(input.containsKey("field1"));        Assert.assertTrue(input.containsKey("field2"));    }}
0
public void smokeTest() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(smoketestConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            for (int i = 1; i <= 10; ++i) {                put("old_field" + i, "f" + i);            }        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertEquals("f1", input.get("new_field1"));    Assert.assertEquals("f2", input.get("new_field2"));    for (int i = 3; i <= 10; ++i) {        Assert.assertEquals("f" + i, input.get("old_field" + i));    }    Assert.assertFalse(input.containsKey("old_field1"));    Assert.assertFalse(input.containsKey("old_field2"));    Assert.assertEquals(10, input.size());}
0
public void renameMissingField() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(renameMissingField));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            for (int i = 2; i <= 10; ++i) {                put("old_field" + i, "f" + i);            }        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertFalse(input.containsKey("new_field1"));    for (int i = 2; i <= 10; ++i) {        Assert.assertEquals("f" + i, input.get("old_field" + i));    }    Assert.assertEquals(9, input.size());}
0
public void testSingleFieldReturned() throws Exception
{    SensorParserConfig sensorConfig = SensorParserConfig.fromBytes(Bytes.toBytes(selectSingleFieldConfig));    FieldTransformer handler = Iterables.getFirst(sensorConfig.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            put("field1", "foo");            put("field2", "bar");        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertTrue(input.containsKey("field1"));    Assert.assertFalse(input.containsKey("field2"));    Assert.assertEquals(1, input.size());}
0
public void testMulitpleFieldReturned() throws Exception
{    SensorParserConfig sensorConfig = SensorParserConfig.fromBytes(Bytes.toBytes(selectMultiFieldConfig));    FieldTransformer handler = Iterables.getFirst(sensorConfig.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            put("field1", "foo");            put("field2", "bar");            put("field3", "bar2");        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertTrue(input.containsKey("field1"));    Assert.assertTrue(input.containsKey("field2"));    Assert.assertFalse(input.containsKey("field3"));    Assert.assertEquals(2, input.size());}
0
public void testPreserveSystemFields() throws Exception
{    SensorParserConfig sensorConfig = SensorParserConfig.fromBytes(Bytes.toBytes(selectSingleFieldConfig));    FieldTransformer handler = Iterables.getFirst(sensorConfig.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            put("timestamp", 12345);            put("original_string", "foo,bar");            put("source.type", "test");            put("field1", "foo");            put("field2", "bar");        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertTrue(input.containsKey("timestamp"));    Assert.assertTrue(input.containsKey("original_string"));    Assert.assertTrue(input.containsKey("source.type"));    Assert.assertTrue(input.containsKey("field1"));    Assert.assertFalse(input.containsKey("field2"));    Assert.assertEquals(4, input.size());}
0
public static Collection<Object[]> data()
{    return Arrays.asList(new Object[][] { { CachingStellarProcessor.createCache(ImmutableMap.of(CachingStellarProcessor.MAX_CACHE_SIZE_PARAM, 10)) }, { CachingStellarProcessor.createCache(ImmutableMap.of(CachingStellarProcessor.MAX_CACHE_SIZE_PARAM, 1)) }, { CachingStellarProcessor.createCache(ImmutableMap.of(CachingStellarProcessor.MAX_CACHE_SIZE_PARAM, 0)) }, { null } });}
0
public void testConfigAll() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(configAll));    JSONObject input = new JSONObject();    input.put("source.type", "test");    for (FieldTransformer handler : c.getFieldTransformations()) {        handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    }    Assert.assertEquals(2, input.size());    Assert.assertTrue(input.containsKey("new_field"));    Assert.assertEquals("test", input.get("new_field"));}
0
public void testStellarRename() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(configRename));    {        JSONObject input = new JSONObject();        input.put("old_field", "val");        input.put("old_field2", "val2");        for (FieldTransformer handler : c.getFieldTransformations()) {            handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());        }        Assert.assertEquals(2, input.size());        Assert.assertTrue(input.containsKey("new_field"));        Assert.assertEquals("val", input.get("new_field"));        Assert.assertEquals("val2", input.get("new_field2"));        Assert.assertTrue(!input.containsKey("old_field"));        Assert.assertTrue(!input.containsKey("old_field2"));    }    {        JSONObject input = new JSONObject();        input.put("old_field", "val");        for (FieldTransformer handler : c.getFieldTransformations()) {            handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());        }        Assert.assertEquals(1, input.size());        Assert.assertTrue(input.containsKey("new_field"));        Assert.assertEquals("val", input.get("new_field"));    }}
0
public void testStellarNumericDomain() throws Exception
{    /*    Despite the domain being weird, URL_TO_HOST should allow it to pass through.    However, because it does NOT form a proper domain (no TLD), DOMAIN_REMOVE_SUBDOMAINS returns    null indicating that the input is semantically incorrect.     */    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(configNumericDomain));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject();    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertTrue(input.containsKey("full_hostname"));    Assert.assertEquals("1234567890123456789012345678901234567890123456789012345678901234567890", input.get("full_hostname"));    Assert.assertFalse(input.containsKey("domain_without_subdomains"));}
0
public void testStellarBadConfig() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(badConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject();    try {        handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    } catch (IllegalStateException ex) {        Assert.assertTrue(ex.getMessage().contains("URL_TO_HOST"));        Assert.assertTrue(ex.getMessage().contains("123"));        throw ex;    }}
0
public void testIntermediateValues() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(intermediateValuesConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    int expected = 3;    Assert.assertEquals(expected, input.get("final_value"));    Assert.assertFalse(input.containsKey("value1"));    Assert.assertFalse(input.containsKey("value2"));}
0
public void testStellarSpecialCharacters() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(stellarConfigEspecial));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            put("timestamp", "2016-01-05 17:02:30");        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    long expected = 1452013350000L;    Assert.assertEquals(expected, input.get("utc_timestamp"));    Assert.assertTrue(input.containsKey("timestamp"));    Assert.assertTrue(input.containsKey("newStellarField"));}
0
public void testStellar() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(stellarConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    JSONObject input = new JSONObject(new HashMap<String, Object>() {        {            put("timestamp", "2016-01-05 17:02:30");        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    long expected = 1452013350000L;    Assert.assertEquals(expected, input.get("utc_timestamp"));    Assert.assertTrue(input.containsKey("timestamp"));}
0
public void testStellar_negative() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(stellarConfig));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);        JSONObject input = new JSONObject(new HashMap<String, Object>() {        {        }    });    handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());    Assert.assertFalse(input.containsKey("utc_timestamp"));    Assert.assertTrue(input.isEmpty());}
0
public void testStellar_multi() throws Exception
{    SensorParserConfig c = SensorParserConfig.fromBytes(Bytes.toBytes(stellarConfig_multi));    FieldTransformer handler = Iterables.getFirst(c.getFieldTransformations(), null);    {                JSONObject input = new JSONObject(new HashMap<String, Object>() {            {                put("timestamp", "2016-01-05 17:02:30");                put("url", "https://caseystella.com/blog");                                put("dc", "portland");            }        });        handler.transformAndUpdate(input, Context.EMPTY_CONTEXT());        long expected = 1452013350000L;        Assert.assertEquals(expected, input.get("utc_timestamp"));        Assert.assertEquals("caseystella.com", input.get("url_host"));        Assert.assertEquals("https", input.get("url_protocol"));        Assert.assertTrue(input.containsKey("timestamp"));        Assert.assertTrue(input.containsKey("url"));    }    {                JSONObject input = new JSONObject(new HashMap<String, Object>() {            {                put("timestamp", "2016-01-05 17:02:30");                put("url", "https://caseystella.com/blog");                put("dc", "london");            }        });        handler.transformAndUpdate(input, Context.EMPTY_CONTEXT(), c.getParserConfig());        long expected = 1452013350000L;        Assert.assertEquals(expected, input.get("utc_timestamp"));        Assert.assertEquals("caseystella.com", input.get("url_host"));        Assert.assertEquals("https", input.get("url_protocol"));        Assert.assertTrue(input.containsKey("timestamp"));        Assert.assertTrue(input.containsKey("url"));    }        {        JSONObject input = new JSONObject(new HashMap<String, Object>() {            {                put("timestamp", "2016-01-05 17:02:30");                put("url", "https://caseystella.com/blog");            }        });        handler.transformAndUpdate(input, Context.EMPTY_CONTEXT(), c.getParserConfig());        long expected = 1452013350000L;        Assert.assertEquals(expected, input.get("utc_timestamp"));        Assert.assertEquals("caseystella.com", input.get("url_host"));        Assert.assertEquals("https", input.get("url_protocol"));        Assert.assertTrue(input.containsKey("timestamp"));        Assert.assertTrue(input.containsKey("url"));    }}
0
public Configurations getConfiguration(String config) throws IOException
{    Configurations configurations = new Configurations();    configurations.updateGlobalConfig(Bytes.toBytes(config));    return configurations;}
0
public FieldValidator getValidator(Configurations configurations) throws IOException
{    return configurations.getFieldValidations().get(0);}
0
public boolean execute(String config, Map<String, Object> input) throws IOException
{    Configurations configurations = getConfiguration(config);    FieldValidator validator = getValidator(configurations);    return validator.isValid(new JSONObject(input), configurations.getGlobalConfig(), Context.EMPTY_CONTEXT());}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "caseystella.com")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "caseystella.com")));    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "www.hotmail.co.uk")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "www.hotmail.co.uk")));}
0
public void negativeTest_empty() throws IOException
{    Assert.assertFalse(runPredicate("IS_DOMAIN()", Collections.emptyMap()));    Assert.assertFalse(runPredicate("IS_DOMAIN('')", Collections.emptyMap()));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "foo")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "foo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "caseystella.turtle")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "caseystella.turtle")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 2.7f)));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", 2.7f)));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", "www.gmail.com", "field2", "www.hotmail.com")));    Assert.assertTrue(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "www.gmail.com", "field2", "www.hotmail.com")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field2", "hotmail.edu")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field2", "hotmail.edu")));    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field1", "", "field2", "gmail.com")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "", "field2", "gmail.com")));}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "me@caseystella.com")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "me@caseystella.com")));    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "me@www.hotmail.co.uk")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "me@www.hotmail.co.uk")));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "me@foo")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "me@foo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "caseystella.turtle")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "caseystella.turtle")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "caseystella.com")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "caseystella.com")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 2.7f)));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", 2.7f)));}
0
public void negativeTest_empty() throws IOException
{    Assert.assertFalse(runPredicate("IS_EMAIL()", Collections.emptyMap()));    Assert.assertFalse(runPredicate("IS_EMAIL('')", Collections.emptyMap()));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", "me@www.gmail.com", "field2", "me@www.hotmail.com")));    Assert.assertTrue(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "me@www.gmail.com", "field2", "me@www.hotmail.com")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field2", "me@hotmail.edu")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field2", "me@hotmail.edu")));    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field1", "", "field2", "me@gmail.com")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "", "field2", "me@gmail.com")));}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "127.0.0.1")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "127.0.0.1")));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "2014/05/01")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "2014/05/01")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 2.3f)));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", 2.3f)));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", "192.168.0.1", "field2", "127.0.0.2")));    Assert.assertTrue(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "192.168.0.1", "field2", "127.0.0.2")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field1", 1, "field2", "192.168.1")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", 1, "field2", "192.168.1")));}
0
public void positiveTest_multiplex2() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFieldsMultipleTypes, ImmutableMap.of("field1", "192.168.0.1", "field2", "127.0.0.2")));    Assert.assertTrue(runPredicate(validWithMultipleFieldsMultipleTypes_MQL, ImmutableMap.of("field1", "192.168.0.1", "field2", "127.0.0.2")));}
0
public void negativeTest_multiplex2() throws IOException
{    Assert.assertFalse(execute(validWithMultipleFieldsMultipleTypes, ImmutableMap.of("field1", 1, "field2", "192.168.1")));    Assert.assertFalse(runPredicate(validWithMultipleFieldsMultipleTypes_MQL, ImmutableMap.of("field1", 1, "field2", "192.168.1")));}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "http://caseystella.com/foo")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "http://caseystella.com/foo")));    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "https://www.hotmail.co.uk")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "https://www.hotmail.co.uk")));}
0
public void negativeTest_empty() throws IOException
{    Assert.assertFalse(runPredicate("IS_URL()", Collections.emptyMap()));    Assert.assertFalse(runPredicate("IS_URL('')", Collections.emptyMap()));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "foo")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "foo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "http://caseystella.turtle")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "http://caseystella.turtle")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 2.7f)));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", 2.7f)));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", "ftp://www.gmail.com", "field2", "http://www.hotmail.com")));    Assert.assertTrue(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "ftp://www.gmail.com", "field2", "http://www.hotmail.com")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field2", "http://hotmail.edu")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field2", "http://hotmail.edu")));    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field1", "", "field2", "http://gmail.com")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "", "field2", "http://gmail.com")));}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "2014-05-01")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "2014-05-01")));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", 2.3f)));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "2014/05/01")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "2014/05/01")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 2.3f)));        Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "2014-25-01")));        Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "2014-05-32")));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", "2014-06-01", "field2", "2014-06-02")));    Assert.assertTrue(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "2014-06-01", "field2", "2014-06-02")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field2", "2014-06-02")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field2", "2014-06-02")));    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field1", 1, "field2", "2014-06-02")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", 1, "field2", "2014-06-02")));    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field3", "2014-06-02")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field3", "2014-06-02")));}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", 1)));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", 1)));    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "1")));    Assert.assertTrue(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "1")));}
0
public void negativeTest_empty() throws IOException
{    Assert.assertFalse(runPredicate("IS_INTEGER()", Collections.emptyMap()));    Assert.assertFalse(runPredicate("IS_INTEGER('')", Collections.emptyMap()));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "foo")));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", "foo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 2.3f)));    Assert.assertFalse(runPredicate(validWithSingleField_MQL, ImmutableMap.of("field1", 2.3f)));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", 1, "field2", "2")));    Assert.assertTrue(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", 1, "field2", "2")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field2", "foo")));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field2", "foo")));    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field1", "", "field2", 1)));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", "", "field2", 1)));    Assert.assertFalse(execute(validWithMultipleFields, ImmutableMap.of("field1", " ", "field2", 2)));    Assert.assertFalse(runPredicate(validWithMultipleFields_MQL, ImmutableMap.of("field1", " ", "field2", 2)));}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "foo")));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field2", "foo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", " ")));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", "foo", "field2", "bar")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field2", "foo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "", "field2", "bar")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", " ", "field2", "bar")));}
0
public void positiveTest_single() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "foo")));    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "fop")));    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field1", "fo")));}
0
public void negativeTest_single() throws IOException
{    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", "flo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 2.3f)));}
0
public void positiveTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithMultipleFields, ImmutableMap.of("field1", "fooo", "field2", "foll")));}
0
public void negativeTest_multiple() throws IOException
{    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field2", "foo")));    Assert.assertFalse(execute(validWithSingleField, ImmutableMap.of("field1", 1, "field2", "foo")));    Assert.assertTrue(execute(validWithSingleField, ImmutableMap.of("field3", "foo")));}
0
public void testPositive() throws IOException
{    Assert.assertTrue(execute(validQueryConfig, ImmutableMap.of("field1", "foo")));}
0
public void testPositive_map() throws IOException
{    Assert.assertTrue(execute(validQueryConfig_map, ImmutableMap.of("dc", "la")));}
0
public void testNegative_map() throws IOException
{    Assert.assertFalse(execute(validQueryConfig_map, ImmutableMap.of("dc", "nyc")));    Assert.assertFalse(execute(validQueryConfig_map, ImmutableMap.of("foo", "nyc")));}
0
public void testNegative() throws IOException
{    Assert.assertFalse(execute(validQueryConfig, ImmutableMap.of("field2", "foo")));}
0
public void testInvalidConfig_missingConfig() throws IOException
{    getConfiguration(invalidQueryConfig1);}
0
public void testInvalidConfig_invalidQuery() throws IOException
{    getConfiguration(invalidQueryConfig2);}
0
public void testValidConfiguration() throws IOException
{    {        Configurations configurations = getConfiguration(validValidationConfigWithStringInput);        Assert.assertNotNull(configurations.getFieldValidations());        Assert.assertEquals(1, configurations.getFieldValidations().size());        Assert.assertEquals(ImmutableList.of("field1"), configurations.getFieldValidations().get(0).getInput());    }    {        Configurations configurations = getConfiguration(validValidationConfigWithListInput);        Assert.assertNotNull(configurations.getFieldValidations());        Assert.assertEquals(1, configurations.getFieldValidations().size());        Assert.assertEquals(ImmutableList.of("field1", "field2"), configurations.getFieldValidations().get(0).getInput());    }}
0
public void testInvalidConfiguration() throws IOException
{    getConfiguration(invalidValidationConfig);}
0
public void setup()
{    MockitoAnnotations.initMocks(this);    configSupplier = () -> ImmutableMap.of("performance.logging.percent.records", thresholdPercent);    when(thresholdCalc.isPast(thresholdPercent)).thenReturn(false).thenReturn(false).thenReturn(true);    when(logger.isDebugEnabled()).thenReturn(true);    when(timing.exists("t1")).thenReturn(true);    perfLogger = new PerformanceLogger(configSupplier, logger, thresholdCalc, timing);}
0
public void logs_on_threshold() throws Exception
{    when(timing.getElapsed("t1")).thenReturn(111L).thenReturn(222L).thenReturn(333L);    perfLogger.mark("t1");    perfLogger.log("t1");    perfLogger.log("t1");    perfLogger.log("t1");    verify(timing).mark("t1");    verify(logger, times(1)).debug(anyString(), anyObject(), eq(111L), eq(""));}
0
public void logs_on_threshold_with_message() throws Exception
{    when(timing.getElapsed("t1")).thenReturn(111L).thenReturn(222L).thenReturn(333L);    perfLogger.mark("t1");    perfLogger.log("t1", "my message");    perfLogger.log("t1", "my message");    perfLogger.log("t1", "my message");    verify(timing).mark("t1");    verify(logger, times(1)).debug(anyString(), anyObject(), eq(111L), eq("my message"));}
0
public void warns_when_logging_nonexisting_marks() throws Exception
{    when(thresholdCalc.isPast(thresholdPercent)).thenReturn(true);    when(timing.getElapsed("t1")).thenReturn(111L);    when(timing.getElapsed("t2")).thenReturn(222L);    when(timing.getElapsed("t3")).thenReturn(333L);    when(timing.exists("t1")).thenReturn(true);    when(timing.exists("t2")).thenReturn(false);    when(timing.exists("t3")).thenReturn(false);    perfLogger.mark("t1");    perfLogger.log("t1", "my message");    perfLogger.log("t2", "my message");    perfLogger.log("t3", "my message");    verify(timing).mark("t1");    verify(timing, never()).mark("t2");    verify(timing, never()).mark("t3");    verify(logger).debug(anyString(), anyObject(), eq(111L), eq("my message"));    verify(logger).debug(anyString(), eq("WARNING - MARK NOT SET"), eq(222L), eq("my message"));    verify(logger).debug(anyString(), eq("WARNING - MARK NOT SET"), eq(333L), eq("my message"));}
0
public void logs_with_multiple_markers() throws Exception
{    when(thresholdCalc.isPast(thresholdPercent)).thenReturn(true);    when(timing.getElapsed("t1")).thenReturn(111L);    when(timing.getElapsed("t2")).thenReturn(222L);    perfLogger.mark("t1");    perfLogger.mark("t2");    perfLogger.log("t2", "my message 2");    perfLogger.log("t1", "my message 1");    verify(timing).mark("t1");    verify(timing).mark("t2");    verify(logger).debug(anyString(), anyObject(), eq(111L), eq("my message 1"));    verify(logger).debug(anyString(), anyObject(), eq(222L), eq("my message 2"));}
0
public void defaults_to_1_percent_threshold() throws Exception
{    configSupplier = () -> new HashMap<>();    when(thresholdCalc.isPast(1)).thenReturn(false).thenReturn(false).thenReturn(true);    when(timing.getElapsed("t1")).thenReturn(111L).thenReturn(222L).thenReturn(333L);    perfLogger.mark("t1");    perfLogger.log("t1", "my message");    perfLogger.log("t1", "my message");    perfLogger.log("t1", "my message");    verify(timing).mark("t1");    verify(logger, times(1)).debug(anyString(), anyObject(), eq(111L), eq("my message"));}
0
public void does_not_log_when_debugging_disabled() throws Exception
{    when(logger.isDebugEnabled()).thenReturn(false);    when(timing.getElapsed("t1")).thenReturn(111L).thenReturn(222L).thenReturn(333L);    perfLogger.mark("t1");    perfLogger.log("t1", "my message");    perfLogger.log("t1", "my message");    perfLogger.log("t1", "my message");    verify(timing).mark("t1");    verify(logger, times(0)).debug(anyString(), anyObject(), eq(111L), eq("my message"));}
0
public void logs_formatted_message_provided_format_args() throws Exception
{    when(thresholdCalc.isPast(thresholdPercent)).thenReturn(true);    when(timing.getElapsed("t1")).thenReturn(111L).thenReturn(222L).thenReturn(333L).thenReturn(444L);    perfLogger.mark("t1");    perfLogger.log("t1", "my {} message", "1");    perfLogger.log("t1", "my {} message {}", "1", "2");    perfLogger.log("t1", "my {} message {} {}", "1", "2", "3");    perfLogger.log("t1", "my {} message {} {} {}", "1", "2", "3", "4");    verify(timing).mark("t1");    verify(logger, times(1)).debug(anyString(), anyObject(), eq(111L), eq("my 1 message"));    verify(logger, times(1)).debug(anyString(), anyObject(), eq(222L), eq("my 1 message 2"));    verify(logger, times(1)).debug(anyString(), anyObject(), eq(333L), eq("my 1 message 2 3"));    verify(logger, times(1)).debug(anyString(), anyObject(), eq(444L), eq("my 1 message 2 3 4"));}
0
public void isDebugEnabled_returns_true_when_debugging_is_set()
{    when(logger.isDebugEnabled()).thenReturn(true);    assertThat(perfLogger.isDebugEnabled(), equalTo(true));}
0
public void setup()
{    timing = new Timing();}
0
public void provides_monotonically_increasing_times_for_single_marker() throws InterruptedException
{    timing.mark("mark1");    long tlast = 0;    for (int i = 0; i < 10; i++) {        tlast = timing.getElapsed("mark1");        Thread.sleep(10);        assertThat(timing.getElapsed("mark1") > tlast, equalTo(true));    }}
0
public void provides_monotonically_increasing_times_for_multiple_markers() throws InterruptedException
{    timing.mark("mark1");    timing.mark("mark2");    long tlast1 = 0;    long tlast2 = 0;    for (int i = 0; i < 10; i++) {        tlast1 = timing.getElapsed("mark1");        tlast2 = timing.getElapsed("mark2");        Thread.sleep(10);        assertThat(timing.getElapsed("mark1") > tlast1, equalTo(true));        assertThat(timing.getElapsed("mark2") > tlast2, equalTo(true));    }}
0
public void elapsed_time_on_nonexistent_marker_is_zero() throws InterruptedException
{    timing.mark("mark1");    long tlast1 = 0;    for (int i = 0; i < 10; i++) {        tlast1 = timing.getElapsed("mark1");        Thread.sleep(10);        assertThat(timing.getElapsed("mark1") > tlast1, equalTo(true));        assertThat(timing.getElapsed("mark2"), equalTo(0L));    }}
0
public void marking_again_resets_timing() throws InterruptedException
{    timing.mark("mark1");    long tlast1 = 0;    for (int i = 0; i < 5; i++) {        Thread.sleep(10);        tlast1 = timing.getElapsed("mark1");        timing.mark("mark1");        assertThat(timing.getElapsed("mark1") < tlast1, equalTo(true));    }}
0
public void exists_checks_mark_existence()
{    timing.mark("mark1");    assertThat(timing.exists("mark1"), equalTo(true));    assertThat(timing.exists("mark2"), equalTo(false));    assertThat(timing.exists("mark3"), equalTo(false));}
0
public void returns_system_time() throws Exception
{    Clock clock = new Clock();    long t1 = clock.currentTimeMillis();    Thread.sleep(50);    long t2 = clock.currentTimeMillis();    Thread.sleep(50);    long t3 = clock.currentTimeMillis();    assertThat("t3 should be greater", t3 > t2, equalTo(true));    assertThat("t2 should be greater", t2 > t1, equalTo(true));}
0
public void formats_system_time_given_passed_format() throws Exception
{    Clock clock = Mockito.spy(Clock.class);    SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMddHHmmssSSSZ");    sdf.setTimeZone(TimeZone.getTimeZone("UTC"));    Date date = sdf.parse("20160615183527162+0000");    Mockito.when(clock.currentTimeMillis()).thenReturn(date.getTime());    assertThat("time not right", clock.currentTimeFormatted("yyyyMMddHHmmssSSSZ"), equalTo("20160615183527162+0000"));}
0
public static void setup() throws Exception
{    for (Map.Entry<String, EnumMap<TyposquattingStrategies, Set<String>>> kv : expected.entrySet()) {        try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream("src/test/resources/typosquat/" + kv.getKey() + ".csv"), StandardCharsets.UTF_8))) {            for (String line = null; (line = br.readLine()) != null; ) {                if (line.startsWith("#")) {                    continue;                }                Iterable<String> tokens = Splitter.on(",").split(line);                String name = Iterables.get(tokens, 0);                String domain = Iterables.get(tokens, 1);                domain = domain.replaceAll(".com", "");                EnumMap<TyposquattingStrategies, Set<String>> expectedValues = kv.getValue();                if (typesToSkip.contains(name)) {                    continue;                }                TyposquattingStrategies strategy = TyposquattingStrategies.byName(name);                Assert.assertNotNull("Couldn't find " + name, strategy);                Set<String> s = expectedValues.get(strategy);                if (s == null) {                    s = new HashSet<>();                    expectedValues.put(strategy, s);                }                s.add(domain);            }        }    }}
0
public static Collection<Object[]> strategies()
{    List<Object[]> ret = new ArrayList<>();    for (TyposquattingStrategies strategy : TyposquattingStrategies.values()) {        ret.add(new Object[] { strategy });    }    return ret;}
0
public void assertExpected(String domain, TyposquattingStrategies strategy)
{    Set<String> expectedValues = expected.get(domain).get(strategy);    Set<String> actualValues = strategy.generateCandidates(domain);    Assert.assertFalse(actualValues.contains(domain));    {        Sets.SetView<String> vals = Sets.difference(expectedValues, actualValues);        String diff = Joiner.on(",").join(vals);        Assert.assertTrue(strategy.name() + ": Found values expected but not generated: " + diff, vals.isEmpty());    }}
0
public void test()
{    for (String domain : expected.keySet()) {        assertExpected(domain, strategy);    }}
0
public void testStellar()
{    for (String domain : expected.keySet()) {        Set<String> expectedAll = TyposquattingStrategies.generateAllCandidates(domain);        Set<String> generatedAll = (Set<String>) StellarProcessorUtils.run("DOMAIN_TYPOSQUAT(domain)", ImmutableMap.of("domain", domain));        Assert.assertTrue(Sets.symmetricDifference(expectedAll, generatedAll).isEmpty());    }}
0
public void setup() throws IOException
{    tempDir = TestUtils.createTempDir(this.getClass().getName());    textFile = new File(tempDir, "test-text-file.txt");    TestUtils.write(textFile, SAMPLE_TEXT);}
0
public void compresses_Gzip() throws IOException
{    File gzipFile = new File(tempDir, "test-gz-compression-file.gz");    CompressionStrategies.GZIP.compress(textFile, gzipFile);    assertThat(CompressionStrategies.GZIP.test(gzipFile), equalTo(true));}
0
public void decompresses_Gzip() throws IOException
{    File gzipFile = new File(tempDir, "test-gz-decompress.gz");    CompressionStrategies.GZIP.compress(textFile, gzipFile);    assertThat("gzipped file should exist", gzipFile.exists(), equalTo(true));    File unzippedText = new File(tempDir, "test-gz-decompressed.txt");    CompressionStrategies.GZIP.decompress(gzipFile, unzippedText);    assertThat("decompressed file should exist", unzippedText.exists(), equalTo(true));    String actual = TestUtils.read(unzippedText);    assertThat("decompressed text should match", actual, equalTo(SAMPLE_TEXT));}
0
public static void setup() throws IOException
{    if (dataFile.exists()) {        dataFile.delete();    }    Files.write(dataFile.toPath(), data.getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE_NEW, StandardOpenOption.TRUNCATE_EXISTING);    dataFile.deleteOnExit();}
0
public static BufferedReader getReader()
{    try {        return new BufferedReader(new InputStreamReader(new FileInputStream(dataFile), StandardCharsets.UTF_8));    } catch (FileNotFoundException e) {        throw new IllegalStateException(e.getMessage(), e);    }}
0
private static void validateMapCount(Map<String, Integer> count)
{    Assert.assertEquals(5, count.size());    Assert.assertEquals(3, (int) count.get("foo"));    Assert.assertEquals(2, (int) count.get("bar"));    Assert.assertEquals(1, (int) count.get("and"));    Assert.assertEquals(1, (int) count.get("the"));}
0
public void testParallelStreamSmallBatch() throws FileNotFoundException
{    try (Stream<String> stream = ReaderSpliterator.lineStream(getReader(), 2)) {        Map<String, Integer> count = stream.parallel().map(s -> s.trim()).collect(Collectors.toMap(s -> s, s -> 1, Integer::sum));        validateMapCount(count);    }}
0
public void testParallelStreamLargeBatch() throws FileNotFoundException
{    try (Stream<String> stream = ReaderSpliterator.lineStream(getReader(), 100)) {        Map<String, Integer> count = stream.parallel().map(s -> s.trim()).collect(Collectors.toMap(s -> s, s -> 1, Integer::sum));        validateMapCount(count);    }}
0
public void testSequentialStreamLargeBatch() throws FileNotFoundException
{    try (Stream<String> stream = ReaderSpliterator.lineStream(getReader(), 100)) {        Map<String, Integer> count = stream.map(s -> s.trim()).collect(Collectors.toMap(s -> s, s -> 1, Integer::sum));        validateMapCount(count);    }}
0
private int getNumberOfBatches(final ReaderSpliterator spliterator) throws ExecutionException, InterruptedException
{    final AtomicInteger numSplits = new AtomicInteger(0);        Spliterator<String> delegatingSpliterator = spy(spliterator);    doAnswer(invocationOnMock -> {        Spliterator<String> ret = spliterator.trySplit();        if (ret != null) {            numSplits.incrementAndGet();        }        return ret;    }).when(delegatingSpliterator).trySplit();    Stream<String> stream = StreamSupport.stream(delegatingSpliterator, true);        ForkJoinPool forkJoinPool = ForkJoinPool.commonPool();    forkJoinPool.submit(() -> {        Map<String, Integer> threads = stream.parallel().map(s -> Thread.currentThread().getName()).collect(Collectors.toMap(s -> s, s -> 1, Integer::sum));        Assert.assertTrue(threads.size() > 0);    }).get();    return numSplits.get();}
0
public void testSmallBatch() throws ExecutionException, InterruptedException, IOException
{        try (BufferedReader reader = getReader()) {        Assert.assertEquals(9, getNumberOfBatches(new ReaderSpliterator(reader, 1)));    }}
0
public void testMediumBatch() throws ExecutionException, InterruptedException, IOException
{        try (BufferedReader reader = getReader()) {        Assert.assertEquals(5, getNumberOfBatches(new ReaderSpliterator(reader, 2)));    }}
0
public void testOneBigBatch() throws ExecutionException, InterruptedException, IOException
{        try (BufferedReader reader = getReader()) {        Assert.assertEquals(1, getNumberOfBatches(new ReaderSpliterator(reader, 10)));    }}
0
public void getMessageHashShouldReturnHashForHashFields()
{    JSONObject message = new JSONObject();    message.put("field1", "value1");    message.put("field2", "value2");    message.put("field3", "value3");    Collection<String> fields = Arrays.asList("field2", "field3");    assertEquals("6eab1c2c827387803ce457c76552f0511858fc1f9505c7dc620e198c0d1f4d02", HashUtils.getMessageHash(message, fields));}
0
public void getMessageHashShouldReturnHashForMessage()
{    JSONObject message = new JSONObject();    message.put("field1", "value1");    message.put("field2", "value2");    message.put("field3", "value3");    assertEquals("a76cdafc5aa49180c0b22c78d4415c505f9997c54847cec6c623f4cacf6a2811", HashUtils.getMessageHash(message));}
0
public void getMessageHashShouldReturnHashForBytes()
{    assertEquals("ab530a13e45914982b79f9b7e3fba994cfd1f3fb22f71cea1afbf02b460c6d1d", HashUtils.getMessageHash("message".getBytes(UTF_8)));}
0
public void writes_file_to_local_fs() throws Exception
{    String outText = "small brown bike and casket lottery";    String outFile = tempDir.getRoot().getAbsolutePath() + "/outfile.txt";    Configuration config = new Configuration();    config.set("fs.default.name", "file:///");    HDFSUtils.write(config, outText.getBytes(StandardCharsets.UTF_8), outFile);    String actual = TestUtils.read(new File(outFile));    assertThat("Text should match", actual, equalTo(outText));}
0
public void writes_file_to_local_fs_with_scheme_defined_only_in_uri() throws Exception
{    String outText = "small brown bike and casket lottery";    String outFile = tempDir.getRoot().getAbsolutePath() + "/outfile.txt";    Configuration config = new Configuration();    HDFSUtils.write(config, outText.getBytes(StandardCharsets.UTF_8), "file:///" + outFile);    String actual = TestUtils.read(new File(outFile));    assertThat("Text should match", actual, equalTo(outText));}
0
public static void setUp() throws Exception
{    tmpDir = UnitTestHelper.createTempDir(new File("target/jsonutilstest"));    configFile = UnitTestHelper.write(new File(tmpDir, "config.json"), config);}
0
public void loads_file_with_typeref() throws Exception
{    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("a", "hello");            put("b", "world");        }    };    Map<String, Object> actual = JSONUtils.INSTANCE.load(configFile, JSONUtils.MAP_SUPPLIER);    assertThat("config not equal", actual, equalTo(expected));}
0
public void loads_file_with_map_class() throws Exception
{    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("a", "hello");            put("b", "world");        }    };    Map<String, Object> actual = JSONUtils.INSTANCE.load(configFile, Map.class);    assertThat("config not equal", actual, equalTo(expected));}
0
public void loads_file_with_custom_class() throws Exception
{    TestConfig expected = new TestConfig().setA("hello").setB("world");    TestConfig actual = JSONUtils.INSTANCE.load(configFile, TestConfig.class);    assertThat("a not equal", actual.getA(), equalTo(expected.getA()));    assertThat("b not equal", actual.getB(), equalTo(expected.getB()));}
0
public String getA()
{    return a;}
0
public TestConfig setA(String a)
{    this.a = a;    return this;}
0
public String getB()
{    return b;}
0
public TestConfig setB(String b)
{    this.b = b;    return this;}
0
public void applyPatch_modifies_source_json_doc() throws IOException
{    String actual = new String(JSONUtils.INSTANCE.applyPatch(patchJson, sourceJson), StandardCharsets.UTF_8);    assertThat(JSONUtils.INSTANCE.load(actual, JSONUtils.MAP_SUPPLIER), equalTo(JSONUtils.INSTANCE.load(expectedJson, JSONUtils.MAP_SUPPLIER)));}
0
public void applyPatch_modifies_complex_source_json_doc() throws IOException
{    String actual = new String(JSONUtils.INSTANCE.applyPatch(patchComplexJson, complexJson), StandardCharsets.UTF_8);    assertThat(JSONUtils.INSTANCE.load(actual, JSONUtils.MAP_SUPPLIER), equalTo(JSONUtils.INSTANCE.load(expectedComplexJson, JSONUtils.MAP_SUPPLIER)));}
0
public void testGetEndpointsFromZookeeperHostPort() throws Exception
{    ArrayList<String> brokerIds = new ArrayList<>();    brokerIds.add("1");    when(client.getChildren()).thenReturn(childrenBuilder);    when(childrenBuilder.forPath("/brokers/ids")).thenReturn(brokerIds);    when(client.getData()).thenReturn(dataBuilder);    when(dataBuilder.forPath("/brokers/ids/1")).thenReturn(brokerWithHostPort.getBytes(StandardCharsets.UTF_8));    ArrayList<String> expected = new ArrayList<>();    expected.add("192.168.1.148:9092");    assertEquals(expected, (KafkaUtils.INSTANCE.getBrokersFromZookeeper(client)));}
0
public void testGetEndpointsFromZookeeperEndpoints() throws Exception
{    ArrayList<String> brokerIds = new ArrayList<>();    brokerIds.add("1");    when(client.getChildren()).thenReturn(childrenBuilder);    when(childrenBuilder.forPath("/brokers/ids")).thenReturn(brokerIds);    when(client.getData()).thenReturn(dataBuilder);    when(dataBuilder.forPath("/brokers/ids/1")).thenReturn(brokerWithEndpoints.getBytes(StandardCharsets.UTF_8));    ArrayList<String> expected = new ArrayList<>();    expected.add("host1:9092");    expected.add("host1:9093");    expected.add("host1:9094");    expected.add("host1:9095");    assertEquals(expected, (KafkaUtils.INSTANCE.getBrokersFromZookeeper(client)));}
0
public void testGetEndpointsFromZookeeperHostPortAndEndpoints() throws Exception
{    ArrayList<String> brokerIds = new ArrayList<>();    brokerIds.add("1");    when(client.getChildren()).thenReturn(childrenBuilder);    when(childrenBuilder.forPath("/brokers/ids")).thenReturn(brokerIds);    when(client.getData()).thenReturn(dataBuilder);    when(dataBuilder.forPath("/brokers/ids/1")).thenReturn(brokerWithHostPortAndEndpoints.getBytes(StandardCharsets.UTF_8));    ArrayList<String> expected = new ArrayList<>();    expected.add("192.168.1.148:9092");    assertEquals(expected, (KafkaUtils.INSTANCE.getBrokersFromZookeeper(client)));}
0
public static Collection<Object[]> data()
{    List<Object[]> ret = new ArrayList<>();    for (String scheme : schemes) {        for (String hostname : hostnames) {            for (String port : ports) {                port = port != null ? (":" + port) : "";                String expected = hostname + port;                ret.add(new Object[] { scheme + "://" + expected, expected });            }        }    }    return ret;}
0
public void testEndpointParsing() throws URISyntaxException
{    assertEquals(expected, KafkaUtils.INSTANCE.fromEndpoint(endpoint).get(0));}
0
public String getName()
{    return null;}
0
public void add(Marker reference)
{}
0
public boolean remove(Marker reference)
{    return false;}
0
public boolean hasChildren()
{    return false;}
0
public boolean hasReferences()
{    return false;}
0
public Iterator<Marker> iterator()
{    return null;}
0
public boolean contains(Marker other)
{    return false;}
0
public boolean contains(String name)
{    return false;}
0
private List<UUID> getGuids(int numGuids)
{    return IntStream.range(0, numGuids).mapToObj(x -> UUID.randomUUID()).collect(Collectors.toList());}
0
private LazyLogger getDisabledLogger()
{    final Logger loggerMock = mock(Logger.class);    return LazyLoggerFactory.getLogger(loggerMock);}
0
private LazyLogger getTraceEnabledLogger()
{    final LazyLogger lazyLogger = getDisabledLogger();    Mockito.when(lazyLogger.getLogger().isTraceEnabled()).thenReturn(true);    Mockito.when(lazyLogger.getLogger().isTraceEnabled(any(Marker.class))).thenReturn(true);    return lazyLogger;}
0
private LazyLogger getDebugEnabledLogger()
{    final LazyLogger lazyLogger = getDisabledLogger();    Mockito.when(lazyLogger.getLogger().isDebugEnabled()).thenReturn(true);    Mockito.when(lazyLogger.getLogger().isDebugEnabled(any(Marker.class))).thenReturn(true);    return lazyLogger;}
0
private LazyLogger getInfoEnabledLogger()
{    final LazyLogger lazyLogger = getDisabledLogger();    Mockito.when(lazyLogger.getLogger().isInfoEnabled()).thenReturn(true);    Mockito.when(lazyLogger.getLogger().isInfoEnabled(any(Marker.class))).thenReturn(true);    return lazyLogger;}
0
private LazyLogger getWarnEnabledLogger()
{    final LazyLogger lazyLogger = getDisabledLogger();    Mockito.when(lazyLogger.getLogger().isWarnEnabled()).thenReturn(true);    Mockito.when(lazyLogger.getLogger().isWarnEnabled(any(Marker.class))).thenReturn(true);    return lazyLogger;}
0
private LazyLogger getErrorEnabledLogger()
{    final LazyLogger lazyLogger = getDisabledLogger();    Mockito.when(lazyLogger.getLogger().isErrorEnabled()).thenReturn(true);    Mockito.when(lazyLogger.getLogger().isErrorEnabled(any(Marker.class))).thenReturn(true);    return lazyLogger;}
0
private Supplier<Object> getMockedSupplier()
{    return mock(Supplier.class);}
0
public void traceEnabled1()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getTraceEnabledLogger();    logger.isTraceEnabled();    Mockito.verify(logger.getLogger()).isTraceEnabled();    logger.isTraceEnabled(marker);    Mockito.verify(logger.getLogger()).isTraceEnabled(marker);    logger.trace(logString0);    Mockito.verify(logger.getLogger()).trace(logString0);    logger.trace(logString0, exception);    Mockito.verify(logger.getLogger()).trace(logString0, exception);    logger.trace(logString1, guids.get(0));    Mockito.verify(logger.getLogger()).trace(logString1, guids.get(0));    logger.trace(marker, logString0);    Mockito.verify(logger.getLogger()).trace(marker, logString0);    logger.trace(marker, logString0, exception);    Mockito.verify(logger.getLogger()).trace(marker, logString0, exception);    logger.trace(marker, logString1, guids.get(0));    Mockito.verify(logger.getLogger()).trace(marker, logString1, guids.get(0));}
0
public void traceEnabled1Lambda()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getTraceEnabledLogger();    logger.trace(logString1, () -> guids.get(0));    Mockito.verify(logger.getLogger()).trace(logString1, guids.get(0));    logger.trace(marker, logString1, () -> guids.get(0));    Mockito.verify(logger.getLogger()).trace(marker, logString1, guids.get(0));}
0
public void traceDisabled1Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();    logger.trace(logString1, supplier);    Mockito.verify(supplier, never()).get();    logger.trace(marker, logString1, supplier);    Mockito.verify(supplier, never()).get();}
0
public void traceEnabled2()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getTraceEnabledLogger();    logger.trace(logString2, guids.get(0), guids.get(1));    Mockito.verify(logger.getLogger()).trace(logString2, guids.get(0), guids.get(1));    logger.trace(marker, logString2, guids.get(0), guids.get(1));    Mockito.verify(logger.getLogger()).trace(marker, logString2, guids.get(0), guids.get(1));}
0
public void traceEnabled2Lambda()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getTraceEnabledLogger();    logger.trace(logString2, () -> guids.get(0), () -> guids.get(1));    Mockito.verify(logger.getLogger()).trace(logString2, guids.get(0), guids.get(1));    logger.trace(marker, logString2, () -> guids.get(0), () -> guids.get(1));    Mockito.verify(logger.getLogger()).trace(marker, logString2, guids.get(0), guids.get(1));}
0
public void traceDisabled2Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();    logger.trace(logString2, supplier, supplier);    Mockito.verify(supplier, never()).get();    logger.trace(marker, logString2, supplier, supplier);    Mockito.verify(supplier, never()).get();}
0
public void traceEnabled3()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getTraceEnabledLogger();    logger.trace(logString3, guids.get(0), guids.get(1), guids.get(2));    Mockito.verify(logger.getLogger()).trace(logString3, guids.get(0), guids.get(1), guids.get(2));    logger.trace(marker, logString3, guids.get(0), guids.get(1), guids.get(2));    Mockito.verify(logger.getLogger()).trace(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
0
public void traceEnabled3Lambda()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getTraceEnabledLogger();    logger.trace(logString3, () -> guids.get(0), () -> guids.get(1), () -> guids.get(2));    Mockito.verify(logger.getLogger()).trace(logString3, guids.get(0), guids.get(1), guids.get(2));    logger.trace(marker, logString3, () -> guids.get(0), () -> guids.get(1), () -> guids.get(2));    Mockito.verify(logger.getLogger()).trace(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
0
public void traceDisabled3Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();    logger.trace(logString3, supplier, supplier, supplier);    Mockito.verify(supplier, never()).get();    logger.trace(marker, logString3, supplier, supplier, supplier);    Mockito.verify(supplier, never()).get();}
0
public void debugEnabled1()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getDebugEnabledLogger();    logger.isDebugEnabled();    Mockito.verify(logger.getLogger()).isDebugEnabled();    logger.isDebugEnabled(marker);    Mockito.verify(logger.getLogger()).isDebugEnabled(marker);        Mockito.verify(logger.getLogger()).debug(logString0);        Mockito.verify(logger.getLogger()).debug(logString0, exception);        Mockito.verify(logger.getLogger()).debug(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).debug(marker, logString0);        Mockito.verify(logger.getLogger()).debug(marker, logString0, exception);        Mockito.verify(logger.getLogger()).debug(marker, logString1, guids.get(0));}
1
public void debugEnabled1Lambda()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getDebugEnabledLogger();        Mockito.verify(logger.getLogger()).debug(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).debug(marker, logString1, guids.get(0));}
1
public void debugDisabled1Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void debugEnabled2()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getDebugEnabledLogger();        Mockito.verify(logger.getLogger()).debug(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).debug(marker, logString2, guids.get(0), guids.get(1));}
1
public void debugEnabled2Lambda()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getDebugEnabledLogger();        Mockito.verify(logger.getLogger()).debug(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).debug(marker, logString2, guids.get(0), guids.get(1));}
1
public void debugDisabled2Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void debugEnabled3()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getDebugEnabledLogger();        Mockito.verify(logger.getLogger()).debug(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).debug(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void debugEnabled3Lambda()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getDebugEnabledLogger();        Mockito.verify(logger.getLogger()).debug(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).debug(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void debugDisabled3Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void infoEnabled1Lambda()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getInfoEnabledLogger();        Mockito.verify(logger.getLogger()).info(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).info(marker, logString1, guids.get(0));}
1
public void infoEnabled1()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getInfoEnabledLogger();    logger.isInfoEnabled();    Mockito.verify(logger.getLogger()).isInfoEnabled();    logger.isInfoEnabled(marker);    Mockito.verify(logger.getLogger()).isInfoEnabled(marker);        Mockito.verify(logger.getLogger()).info(logString0);        Mockito.verify(logger.getLogger()).info(logString0, exception);        Mockito.verify(logger.getLogger()).info(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).info(marker, logString0);        Mockito.verify(logger.getLogger()).info(marker, logString0, exception);        Mockito.verify(logger.getLogger()).info(marker, logString1, guids.get(0));}
1
public void infoDisabled1Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void infoEnabled2Lambda()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getInfoEnabledLogger();        Mockito.verify(logger.getLogger()).info(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).info(marker, logString2, guids.get(0), guids.get(1));}
1
public void infoEnabled2()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getInfoEnabledLogger();        Mockito.verify(logger.getLogger()).info(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).info(marker, logString2, guids.get(0), guids.get(1));}
1
public void infoDisabled2Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void infoEnabled3Lambda()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getInfoEnabledLogger();        Mockito.verify(logger.getLogger()).info(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).info(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void infoEnabled3()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getInfoEnabledLogger();        Mockito.verify(logger.getLogger()).info(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).info(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void infoDisabled3Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void warnEnabled1Lambda()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getWarnEnabledLogger();        Mockito.verify(logger.getLogger()).warn(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).warn(marker, logString1, guids.get(0));}
1
public void warnEnabled1()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getWarnEnabledLogger();    logger.isWarnEnabled();    Mockito.verify(logger.getLogger()).isWarnEnabled();    logger.isWarnEnabled(marker);    Mockito.verify(logger.getLogger()).isWarnEnabled(marker);        Mockito.verify(logger.getLogger()).warn(logString0);        Mockito.verify(logger.getLogger()).warn(logString0, exception);        Mockito.verify(logger.getLogger()).warn(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).warn(marker, logString0);        Mockito.verify(logger.getLogger()).warn(marker, logString0, exception);        Mockito.verify(logger.getLogger()).warn(marker, logString1, guids.get(0));}
1
public void warnDisabled1Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void warnEnabled2Lambda()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getWarnEnabledLogger();        Mockito.verify(logger.getLogger()).warn(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).warn(marker, logString2, guids.get(0), guids.get(1));}
1
public void warnEnabled2()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getWarnEnabledLogger();        Mockito.verify(logger.getLogger()).warn(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).warn(marker, logString2, guids.get(0), guids.get(1));}
1
public void warnDisabled2Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void warnEnabled3Lambda()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getWarnEnabledLogger();        Mockito.verify(logger.getLogger()).warn(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).warn(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void warnEnabled3()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getWarnEnabledLogger();        Mockito.verify(logger.getLogger()).warn(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).warn(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void warnDisabled3Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void errorEnabled1Lambda()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getErrorEnabledLogger();        Mockito.verify(logger.getLogger()).error(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).error(marker, logString1, guids.get(0));}
1
public void errorEnabled1()
{    final List<UUID> guids = getGuids(1);    final LazyLogger logger = getErrorEnabledLogger();    logger.isErrorEnabled();    Mockito.verify(logger.getLogger()).isErrorEnabled();    logger.isErrorEnabled(marker);    Mockito.verify(logger.getLogger()).isErrorEnabled(marker);        Mockito.verify(logger.getLogger()).error(logString0);        Mockito.verify(logger.getLogger()).error(logString0, exception);        Mockito.verify(logger.getLogger()).error(logString1, guids.get(0));        Mockito.verify(logger.getLogger()).error(marker, logString0);        Mockito.verify(logger.getLogger()).error(marker, logString0, exception);        Mockito.verify(logger.getLogger()).error(marker, logString1, guids.get(0));}
1
public void errorDisabled1Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void errorEnabled2Lambda()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getErrorEnabledLogger();        Mockito.verify(logger.getLogger()).error(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).error(marker, logString2, guids.get(0), guids.get(1));}
1
public void errorEnabled2()
{    final List<UUID> guids = getGuids(2);    final LazyLogger logger = getErrorEnabledLogger();        Mockito.verify(logger.getLogger()).error(logString2, guids.get(0), guids.get(1));        Mockito.verify(logger.getLogger()).error(marker, logString2, guids.get(0), guids.get(1));}
1
public void errorDisabled2Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void errorEnabled3Lambda()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getErrorEnabledLogger();        Mockito.verify(logger.getLogger()).error(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).error(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void errorEnabled3()
{    final List<UUID> guids = getGuids(3);    final LazyLogger logger = getErrorEnabledLogger();        Mockito.verify(logger.getLogger()).error(logString3, guids.get(0), guids.get(1), guids.get(2));        Mockito.verify(logger.getLogger()).error(marker, logString3, guids.get(0), guids.get(1), guids.get(2));}
1
public void errorDisabled3Lambda()
{    final Supplier<Object> supplier = getMockedSupplier();    final LazyLogger logger = getDisabledLogger();        Mockito.verify(supplier, never()).get();        Mockito.verify(supplier, never()).get();}
1
public void calcTimes()
{    Map<String, Object> smallMap = new HashMap<>();    for (int i = 0; i < 10; i++) {        smallMap.put("key" + i, RandomStringUtils.randomAlphabetic(10));    }    Map<String, Object> largeMap = new HashMap<>();    for (int i = 0; i < 500; i++) {        largeMap.put("key" + i, RandomStringUtils.randomAlphabetic(1000));    }    JSONObject largeObject = new JSONObject(largeMap);    JSONObject smallObject = new JSONObject(smallMap);    int reps = 1000;    StatisticalSummary summary = runTrial(reps, () -> {        LOG.trace("Writing message {} to path: {}", smallObject.toJSONString(), PATH);    });    printSummary(String.format("Small object %s times", reps), summary);    summary = runTrial(reps, () -> {        LOG.trace("Writing message {} to path: {}", () -> smallObject.toJSONString(), () -> PATH);    });    printSummary(String.format("Small object %s times using lazy logging", reps), summary);    summary = runTrial(reps, () -> {        LOG.trace("Writing message {} to path: {}", largeObject.toJSONString(), PATH);    });    printSummary(String.format("Large object %s times", reps), summary);    summary = runTrial(reps, () -> {        LOG.trace("Writing message {} to path: {}", () -> largeObject.toJSONString(), () -> PATH);    });    printSummary(String.format("Large object %s times using lazy logging", reps), summary);    summary = runTrial(reps, () -> {        LOG.trace("Writing message {} to path: {}", "hello", PATH);    });    printSummary(String.format("Simple string %s times", reps), summary);    summary = runTrial(reps, () -> {        LOG.trace("Writing message {} to path: {}", () -> "hello", () -> PATH);    });    printSummary(String.format("Simple string %s times using lazy logging", reps), summary);}
0
private StatisticalSummary runTrial(int reps, Operation operation)
{    DescriptiveStatistics stats = new DescriptiveStatistics();    long trialTime = timeOperation(() -> {        for (int i = 0; i < reps; i++) {            long time = timeOperation(operation);            stats.addValue(time / NANO_TO_MILLIS);        }    });    System.out.println("Total trial time (ms): " + (trialTime / NANO_TO_MILLIS));    return stats;}
0
private long timeOperation(Operation o)
{    final long start = System.nanoTime();    o.run();    final long finish = System.nanoTime();    return finish - start;}
0
private void printSummary(String desc, StatisticalSummary summary)
{    final String border = "===============================";    System.out.println(border);    System.out.println(desc);    System.out.println(summary.toString());    System.out.println(border);}
0
public void illegal_arg_throws_exception_with_reason() throws Exception
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("illegal arg happened");    exception.expectCause(nullValue(Throwable.class));    RuntimeErrors.ILLEGAL_ARG.throwRuntime("illegal arg happened");}
0
public void illegal_arg_throws_exception_with_reason_and_cause() throws Exception
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("illegal arg happened");    exception.expectCause(instanceOf(IOException.class));    RuntimeErrors.ILLEGAL_ARG.throwRuntime("illegal arg happened", new IOException("bad io"));}
0
public void illegal_state_throws_exception_with_reason() throws Exception
{    exception.expect(IllegalStateException.class);    exception.expectMessage("illegal state happened");    exception.expectCause(nullValue(Throwable.class));    RuntimeErrors.ILLEGAL_STATE.throwRuntime("illegal state happened");}
0
public void illegal_state_throws_exception_with_reason_and_cause() throws Exception
{    exception.expect(IllegalStateException.class);    exception.expectMessage("illegal state happened");    exception.expectCause(instanceOf(IOException.class));    RuntimeErrors.ILLEGAL_STATE.throwRuntime("illegal state happened", new IOException("bad io"));}
0
public void testInteger()
{    final int expected = 2;    byte[] raw = SerDeUtils.toBytes(expected);    int actual = SerDeUtils.fromBytes(raw, Integer.class);    assertEquals(expected, actual);}
0
public void testDouble()
{    final double expected = 2.0;    byte[] raw = SerDeUtils.toBytes(expected);    {        double actual = SerDeUtils.fromBytes(raw, Double.class);        assertEquals(expected, actual, 0.01);    }    {        double actual = (double) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual, 0.01);    }}
0
public void testShort()
{    final short expected = 2;    byte[] raw = SerDeUtils.toBytes(expected);    {        short actual = SerDeUtils.fromBytes(raw, Short.class);        assertEquals(expected, actual);    }    {        short actual = (short) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual);    }}
0
public void testLong()
{    final long expected = 2L;    byte[] raw = SerDeUtils.toBytes(expected);    {        long actual = SerDeUtils.fromBytes(raw, Long.class);        assertEquals(expected, actual);    }    {        long actual = (Long) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual);    }}
0
public void testFloat()
{    final Float expected = 2.2F;    byte[] raw = SerDeUtils.toBytes(expected);    {        float actual = SerDeUtils.fromBytes(raw, Float.class);        assertEquals(expected, actual, 0.01);    }    {        float actual = (float) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual, 0.01);    }}
0
public void testMap()
{    final Map<String, Object> expected = new HashMap<>();    expected.put("foo", "bar");    expected.put("bar", 1.0);    ;    byte[] raw = SerDeUtils.toBytes(expected);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    assertEquals(expected, actual);}
0
public void testList()
{    final List<String> expected = new ArrayList<String>();    expected.add("foo");    expected.add("bar");    byte[] raw = SerDeUtils.toBytes(expected);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    assertEquals(expected, actual);}
0
public void testBloomFilter()
{    final BloomFilter<Object> expected = new BloomFilter<>(new BloomFilter.DefaultSerializer<>(), 10000, 0.01);    expected.add("foo");    expected.add("bar");    byte[] raw = SerDeUtils.toBytes(expected);    BloomFilter<Object> actual = (BloomFilter) SerDeUtils.fromBytes(raw, Object.class);    Assert.assertTrue(actual.mightContain("foo"));    Assert.assertFalse(actual.mightContain("timothy"));    assertEquals(expected, actual);}
0
public List<String> getList()
{    return list;}
0
public void setList(List<String> list)
{    this.list = list;}
0
public String getString()
{    return string;}
0
public void setString(String string)
{    this.string = string;}
0
public Double getD()
{    return d;}
0
public void setD(Double d)
{    this.d = d;}
0
public Map<String, String> getMap()
{    return map;}
0
public void setMap(Map<String, String> map)
{    this.map = map;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ArbitraryPojo that = (ArbitraryPojo) o;    if (getList() != null ? !getList().equals(that.getList()) : that.getList() != null)        return false;    if (getString() != null ? !getString().equals(that.getString()) : that.getString() != null)        return false;    if (getD() != null ? !getD().equals(that.getD()) : that.getD() != null)        return false;    if (getMap() != null ? !getMap().equals(that.getMap()) : that.getMap() != null)        return false;    return immutableList != null ? immutableList.equals(that.immutableList) : that.immutableList == null;}
0
public int hashCode()
{    int result = getList() != null ? getList().hashCode() : 0;    result = 31 * result + (getString() != null ? getString().hashCode() : 0);    result = 31 * result + (getD() != null ? getD().hashCode() : 0);    result = 31 * result + (getMap() != null ? getMap().hashCode() : 0);    result = 31 * result + (immutableList != null ? immutableList.hashCode() : 0);    return result;}
0
public void testArbitraryPojo()
{    final ArbitraryPojo expected = new ArbitraryPojo();    byte[] raw = SerDeUtils.toBytes(expected);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    assertEquals(expected, actual);}
0
public void setup() throws Exception
{    zkComponent = new ZKServerComponent();    zkComponent.start();    client = ConfigurationsUtils.getClient(zkComponent.getConnectionString());    client.start();    cache = new ZKConfigurationsCache(client);    cache.start();    {                byte[] config = IOUtils.toByteArray(new FileInputStream(new File(TestConstants.PARSER_CONFIGS_PATH + "/parsers/bro.json")));        ConfigurationsUtils.writeSensorParserConfigToZookeeper("bro", config, client);    }    {                byte[] config = IOUtils.toByteArray(new FileInputStream(new File(TestConstants.SAMPLE_CONFIG_PATH + "/indexing/test.json")));        ConfigurationsUtils.writeSensorIndexingConfigToZookeeper("test", config, client);    }    {                byte[] config = IOUtils.toByteArray(new FileInputStream(new File(TestConstants.SAMPLE_CONFIG_PATH + "/enrichments/test.json")));        ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper("test", config, client);    }    {                byte[] config = IOUtils.toByteArray(new FileInputStream(new File(TestConstants.SAMPLE_CONFIG_PATH + "/enrichments/test.json")));        ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper("test", config, client);    }    {                byte[] config = IOUtils.toByteArray(new FileInputStream(new File("src/test/resources/profiler/profiler.json")));        ConfigurationsUtils.writeProfilerConfigToZookeeper(config, client);    }    {                byte[] config = IOUtils.toByteArray(new FileInputStream(new File(TestConstants.SAMPLE_CONFIG_PATH + "/global.json")));        ConfigurationsUtils.writeGlobalConfigToZookeeper(config, client);    }}
0
public void teardown() throws Exception
{    if (cache != null) {        cache.close();    }    if (client != null) {        client.close();    }    if (zkComponent != null) {        zkComponent.stop();    }}
0
public void validateDelete() throws Exception
{    client.delete().forPath(ConfigurationType.GLOBAL.getZookeeperRoot());    client.delete().forPath(ConfigurationType.INDEXING.getZookeeperRoot() + "/test");    client.delete().forPath(ConfigurationType.ENRICHMENT.getZookeeperRoot() + "/test");    client.delete().forPath(ConfigurationType.PARSER.getZookeeperRoot() + "/bro");    client.delete().forPath(ConfigurationType.PROFILER.getZookeeperRoot());        {        IndexingConfigurations config = cache.get(IndexingConfigurations.class);        assertEventually(() -> Assert.assertNull(config.getGlobalConfig(false)));    }        {        IndexingConfigurations config = cache.get(IndexingConfigurations.class);        assertEventually(() -> Assert.assertNull(config.getSensorIndexingConfig("test", false)));        assertEventually(() -> Assert.assertNull(config.getGlobalConfig(false)));    }        {        EnrichmentConfigurations config = cache.get(EnrichmentConfigurations.class);        assertEventually(() -> Assert.assertNull(config.getSensorEnrichmentConfig("test")));        assertEventually(() -> Assert.assertNull(config.getGlobalConfig(false)));    }        {        ParserConfigurations config = cache.get(ParserConfigurations.class);        assertEventually(() -> Assert.assertNull(config.getSensorParserConfig("bro")));        assertEventually(() -> Assert.assertNull(config.getGlobalConfig(false)));    }        {        ProfilerConfigurations config = cache.get(ProfilerConfigurations.class);        assertEventually(() -> Assert.assertNull(config.getProfilerConfig()));        assertEventually(() -> Assert.assertNull(config.getGlobalConfig(false)));    }}
0
public void validateUpdate() throws Exception
{    ConfigurationsUtils.writeSensorIndexingConfigToZookeeper("test", testIndexingConfig.getBytes(StandardCharsets.UTF_8), client);    ConfigurationsUtils.writeGlobalConfigToZookeeper(globalConfig.getBytes(StandardCharsets.UTF_8), client);    ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper("test", testEnrichmentConfig.getBytes(StandardCharsets.UTF_8), client);    ConfigurationsUtils.writeSensorParserConfigToZookeeper("bro", testParserConfig.getBytes(StandardCharsets.UTF_8), client);    ConfigurationsUtils.writeProfilerConfigToZookeeper(profilerConfig.getBytes(StandardCharsets.UTF_8), client);        {        Map<String, Object> expectedConfig = JSONUtils.INSTANCE.load(testIndexingConfig, JSONUtils.MAP_SUPPLIER);        IndexingConfigurations config = cache.get(IndexingConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getSensorIndexingConfig("test")));    }        {        SensorEnrichmentConfig expectedConfig = JSONUtils.INSTANCE.load(testEnrichmentConfig, SensorEnrichmentConfig.class);        Map<String, Object> expectedGlobalConfig = JSONUtils.INSTANCE.load(globalConfig, JSONUtils.MAP_SUPPLIER);        EnrichmentConfigurations config = cache.get(EnrichmentConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getSensorEnrichmentConfig("test")));        assertEventually(() -> Assert.assertEquals(expectedGlobalConfig, config.getGlobalConfig()));    }        {        SensorParserConfig expectedConfig = JSONUtils.INSTANCE.load(testParserConfig, SensorParserConfig.class);        ParserConfigurations config = cache.get(ParserConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getSensorParserConfig("bro")));    }        {        ProfilerConfig expectedConfig = JSONUtils.INSTANCE.load(profilerConfig, ProfilerConfig.class);        ProfilerConfigurations config = cache.get(ProfilerConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getProfilerConfig()));    }}
0
public void validateBaseWrite() throws Exception
{    File globalConfigFile = new File(TestConstants.SAMPLE_CONFIG_PATH + "/global.json");    Map<String, Object> expectedGlobalConfig = JSONUtils.INSTANCE.load(globalConfigFile, JSONUtils.MAP_SUPPLIER);        {        File inFile = new File(TestConstants.SAMPLE_CONFIG_PATH + "/indexing/test.json");        Map<String, Object> expectedConfig = JSONUtils.INSTANCE.load(inFile, JSONUtils.MAP_SUPPLIER);        IndexingConfigurations config = cache.get(IndexingConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getSensorIndexingConfig("test")));        assertEventually(() -> Assert.assertEquals(expectedGlobalConfig, config.getGlobalConfig()));        assertEventually(() -> Assert.assertNull(config.getSensorIndexingConfig("notthere", false)));    }        {        File inFile = new File(TestConstants.SAMPLE_CONFIG_PATH + "/enrichments/test.json");        SensorEnrichmentConfig expectedConfig = JSONUtils.INSTANCE.load(inFile, SensorEnrichmentConfig.class);        EnrichmentConfigurations config = cache.get(EnrichmentConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getSensorEnrichmentConfig("test")));        assertEventually(() -> Assert.assertEquals(expectedGlobalConfig, config.getGlobalConfig()));        assertEventually(() -> Assert.assertNull(config.getSensorEnrichmentConfig("notthere")));    }        {        File inFile = new File(TestConstants.PARSER_CONFIGS_PATH + "/parsers/bro.json");        SensorParserConfig expectedConfig = JSONUtils.INSTANCE.load(inFile, SensorParserConfig.class);        ParserConfigurations config = cache.get(ParserConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getSensorParserConfig("bro")));        assertEventually(() -> Assert.assertEquals(expectedGlobalConfig, config.getGlobalConfig()));        assertEventually(() -> Assert.assertNull(config.getSensorParserConfig("notthere")));    }        {        File inFile = new File("src/test/resources/profiler/profiler.json");        ProfilerConfig expectedConfig = JSONUtils.INSTANCE.load(inFile, ProfilerConfig.class);        ProfilerConfigurations config = cache.get(ProfilerConfigurations.class);        assertEventually(() -> Assert.assertEquals(expectedConfig, config.getProfilerConfig()));        assertEventually(() -> Assert.assertEquals(expectedGlobalConfig, config.getGlobalConfig()));    }}
0
public ConfigUploadComponent withConnectionString(String connectionString)
{    this.connectionString = connectionString;    return this;}
0
public ConfigUploadComponent withTopologyProperties(Properties topologyProperties)
{    this.topologyProperties = topologyProperties;    return this;}
0
public ConfigUploadComponent withGlobalConfigsPath(String globalConfigPath)
{    this.globalConfigPath = globalConfigPath;    return this;}
0
public ConfigUploadComponent withParserConfigsPath(String parserConfigsPath)
{    this.parserConfigsPath = parserConfigsPath;    return this;}
0
public ConfigUploadComponent withEnrichmentConfigsPath(String enrichmentConfigsPath)
{    this.enrichmentConfigsPath = enrichmentConfigsPath;    return this;}
0
public ConfigUploadComponent withIndexingConfigsPath(String indexingConfigsPath)
{    this.indexingConfigsPath = indexingConfigsPath;    return this;}
0
public ConfigUploadComponent withProfilerConfigsPath(String profilerConfigsPath)
{    this.profilerConfigPath = profilerConfigsPath;    return this;}
0
public ConfigUploadComponent withParserSensorConfig(String name, SensorParserConfig config)
{    parserSensorConfigs.put(name, config);    return this;}
0
public ConfigUploadComponent withGlobalConfig(String globalConfig)
{    this.globalConfig = Optional.ofNullable(globalConfig);    return this;}
0
public ConfigUploadComponent withPostStartCallback(Consumer<ConfigUploadComponent> f)
{    this.postStartCallback = Optional.ofNullable(f);    return this;}
0
public Properties getTopologyProperties()
{    return topologyProperties;}
0
public String getGlobalConfigPath()
{    return globalConfigPath;}
0
public String getParserConfigsPath()
{    return parserConfigsPath;}
0
public String getEnrichmentConfigsPath()
{    return enrichmentConfigsPath;}
0
public String getIndexingConfigsPath()
{    return indexingConfigsPath;}
0
public String getProfilerConfigPath()
{    return profilerConfigPath;}
0
public Optional<Consumer<ConfigUploadComponent>> getPostStartCallback()
{    return postStartCallback;}
0
public Optional<String> getGlobalConfig()
{    return globalConfig;}
0
public Map<String, SensorParserConfig> getParserSensorConfigs()
{    return parserSensorConfigs;}
0
public void start() throws UnableToStartException
{    update();}
0
public void update() throws UnableToStartException
{    try {        final String zookeeperUrl = connectionString == null ? topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY) : connectionString;        if (globalConfigPath != null || parserConfigsPath != null || enrichmentConfigsPath != null || indexingConfigsPath != null || profilerConfigPath != null) {            uploadConfigsToZookeeper(globalConfigPath, parserConfigsPath, enrichmentConfigsPath, indexingConfigsPath, profilerConfigPath, zookeeperUrl);        }        for (Map.Entry<String, SensorParserConfig> kv : parserSensorConfigs.entrySet()) {            writeSensorParserConfigToZookeeper(kv.getKey(), kv.getValue(), zookeeperUrl);        }        if (globalConfig.isPresent()) {            writeGlobalConfigToZookeeper(globalConfig.get().getBytes(StandardCharsets.UTF_8), zookeeperUrl);        }        if (postStartCallback.isPresent()) {            postStartCallback.get().accept(this);        }    } catch (Exception e) {        throw new UnableToStartException(e.getMessage(), e);    }}
0
public SensorParserConfig getSensorParserConfig(String sensorType)
{    SensorParserConfig sensorParserConfig = new SensorParserConfig();    CuratorFramework client = getClient(topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY));    client.start();    try {        sensorParserConfig = readSensorParserConfigFromZookeeper(sensorType, client);    } catch (Exception e) {        e.printStackTrace();    } finally {        client.close();    }    return sensorParserConfig;}
0
public void stop()
{}
0
public void setCuratorFramework(CuratorFramework client)
{    this.client = client;}
0
public void setZKCache(ZKCache cache)
{    this.cache = cache;}
0
public void reloadCallback(String name, ConfigurationType type)
{}
0
public CONFIG_T getConfigurations()
{    return configurations;}
0
protected ConfigurationStrategy<CONFIG_T> getConfigurationStrategy()
{    return ConfigurationsStrategies.valueOf(configurationStrategy);}
0
protected ConfigurationsUpdater<CONFIG_T> createUpdater()
{    return getConfigurationStrategy().createUpdater(this, this::getConfigurations);}
0
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)
{    prepCache();}
0
protected void prepCache()
{    try {        if (client == null) {            RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);            client = CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);        }        client.start();                                ConfigurationsUtils.setupStellarStatically(client);        if (cache == null) {            ConfigurationsUpdater<CONFIG_T> updater = createUpdater();            SimpleEventListener listener = new SimpleEventListener.Builder().with(updater::update, TreeCacheEvent.Type.NODE_ADDED, TreeCacheEvent.Type.NODE_UPDATED).with(updater::delete, TreeCacheEvent.Type.NODE_REMOVED).build();            cache = new ZKCache.Builder().withClient(client).withListener(listener).withRoot(Constants.ZOOKEEPER_TOPOLOGY_ROOT).build();            updater.forceUpdate(client);            cache.start();        }    } catch (Exception e) {                throw new RuntimeException(e);    }}
1
public void cleanup()
{    cache.close();    client.close();}
0
public void cleanup()
{            super.cleanup();    try {        StellarFunctions.close();    } catch (IOException e) {            }}
1
protected SensorParserConfig getSensorParserConfig(String sensorType)
{    return getConfigurations().getSensorParserConfig(sensorType);}
0
public void cleanup()
{            super.cleanup();    try {        StellarFunctions.close();    } catch (IOException e) {            }}
1
protected ProfilerConfig getProfilerConfig()
{    return getConfigurations().getProfilerConfig();}
0
public byte[] get(Tuple tuple)
{    return tuple.getBinary(position);}
0
public JSONObject get(Tuple tuple)
{    return (JSONObject) ((JSONObject) tuple.getValueByField(fieldValue)).clone();}
0
public JSONObject get(Tuple tuple)
{    return (JSONObject) tuple.getValueByField(messageFieldName);}
0
protected JSONParser initialValue()
{    return new JSONParser();}
0
public JSONObject get(Tuple tuple)
{    String s = null;    try {        s = new String(tuple.getBinary(position), Charsets.UTF_8);        return (JSONObject) parser.get().parse(s);    } catch (Exception e) {        throw new IllegalStateException("Unable to parse " + s + " due to " + e.getMessage(), e);    }}
0
public MessageGetStrategy get(String arg)
{    return messageGetStrategyFunction.apply(arg);}
0
public MessageGetStrategy get()
{    return messageGetStrategy;}
0
public RawMessage getRawMessage(RawMessageStrategy strategy, Tuple t, byte[] rawMessage, boolean readMetadata, Map<String, Object> config)
{    Map<String, Object> metadata = new HashMap<>();    if (readMetadata) {        String prefix = MetadataUtil.INSTANCE.getMetadataPrefix(config);        metadata = extractMetadata(prefix, t);    }    return strategy.get(metadata, rawMessage, readMetadata, config);}
0
public Map<String, Object> extractMetadata(String prefix, Tuple t)
{    Map<String, Object> metadata = new HashMap<>();    if (t == null) {        return metadata;    }    Fields tupleFields = t.getFields();    if (tupleFields == null) {        return metadata;    }    for (int i = 2; i < tupleFields.size(); ++i) {        String envMetadataFieldName = tupleFields.get(i);        Object envMetadataFieldValue = t.getValue(i);        if (!StringUtils.isEmpty(envMetadataFieldName) && envMetadataFieldValue != null) {            metadata.put(MetadataUtil.INSTANCE.prefixKey(prefix, envMetadataFieldName), envMetadataFieldValue);        }    }    byte[] keyObj = t.getBinary(KEY_INDEX);    String keyStr = null;    try {        keyStr = keyObj == null ? null : new String(keyObj, StandardCharsets.UTF_8);        if (!StringUtils.isEmpty(keyStr)) {            Map<String, Object> rawMetadata = JSONUtils.INSTANCE.load(keyStr, JSONUtils.MAP_SUPPLIER);            for (Map.Entry<String, Object> kv : rawMetadata.entrySet()) {                metadata.put(MetadataUtil.INSTANCE.prefixKey(prefix, kv.getKey()), kv.getValue());            }        }    } catch (IOException e) {        String reason = "Unable to parse metadata; expected JSON Map: " + (keyStr == null ? "NON-STRING!" : keyStr);                throw new IllegalStateException(reason, e);    }    return metadata;}
1
public Object get(Tuple tuple)
{    return tuple.getValueByField(fieldValue);}
0
public static void handleError(OutputCollector collector, MetronError error)
{    collector.emit(Constants.ERROR_STREAM, new Values(error.getJSONObject()));    Optional<Throwable> throwable = error.getThrowable();    if (throwable.isPresent()) {        collector.reportError(throwable.get());    }}
0
protected void waitForConfigUpdate(final String expectedConfigUpdate)
{    waitForConfigUpdate(new HashSet<String>() {        {            add(expectedConfigUpdate);        }    });}
0
protected void waitForConfigUpdate(Set<String> expectedConfigUpdates)
{    int count = 0;    while (!configsUpdated.equals(expectedConfigUpdates)) {        if (count++ > 5) {            Assert.fail("ConfiguredBolt was not updated in time");            return;        }        try {            Thread.sleep(500);        } catch (InterruptedException e) {            e.printStackTrace();        }    }}
0
public void execute(Tuple input)
{}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{}
0
public void reloadCallback(String name, ConfigurationType type)
{    configsUpdated.add(name);}
0
public void setupConfiguration() throws Exception
{    TestingServer testZkServer = new TestingServer(true);    this.zookeeperUrl = testZkServer.getConnectString();    byte[] globalConfig = ConfigurationsUtils.readGlobalConfigFromFile(sampleConfigPath);    ConfigurationsUtils.writeGlobalConfigToZookeeper(globalConfig, zookeeperUrl);    enrichmentConfigurationTypes.add(ConfigurationType.GLOBAL.getTypeName());    Map<String, byte[]> sensorEnrichmentConfigs = ConfigurationsUtils.readSensorEnrichmentConfigsFromFile(enrichmentsConfigPath);    for (String sensorType : sensorEnrichmentConfigs.keySet()) {        ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(sensorType, sensorEnrichmentConfigs.get(sensorType), zookeeperUrl);        enrichmentConfigurationTypes.add(sensorType);    }    Map<String, byte[]> sensorParserConfigs = ConfigurationsUtils.readSensorParserConfigsFromFile(parserConfigsPath);    for (String sensorType : sensorParserConfigs.keySet()) {        ConfigurationsUtils.writeSensorParserConfigToZookeeper(sensorType, sensorParserConfigs.get(sensorType), zookeeperUrl);    }}
0
public void test() throws Exception
{    EnrichmentConfigurations sampleConfigurations = new EnrichmentConfigurations();    UnitTestHelper.setLog4jLevel(ConfiguredBolt.class, Level.FATAL);    try {        StandAloneConfiguredEnrichmentBolt configuredBolt = new StandAloneConfiguredEnrichmentBolt(null);        configuredBolt.prepare(new HashMap(), topologyContext, outputCollector);        Assert.fail("A valid zookeeper url must be supplied");    } catch (RuntimeException e) {    }    UnitTestHelper.setLog4jLevel(ConfiguredBolt.class, Level.ERROR);    configsUpdated = new HashSet<>();    sampleConfigurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile(sampleConfigPath));    Map<String, byte[]> sensorEnrichmentConfigs = ConfigurationsUtils.readSensorEnrichmentConfigsFromFile(enrichmentsConfigPath);    for (String sensorType : sensorEnrichmentConfigs.keySet()) {        sampleConfigurations.updateSensorEnrichmentConfig(sensorType, sensorEnrichmentConfigs.get(sensorType));    }    StandAloneConfiguredEnrichmentBolt configuredBolt = new StandAloneConfiguredEnrichmentBolt(zookeeperUrl);    configuredBolt.prepare(new HashMap(), topologyContext, outputCollector);    waitForConfigUpdate(enrichmentConfigurationTypes);    Assert.assertEquals(sampleConfigurations, configuredBolt.getConfigurations());    configsUpdated = new HashSet<>();    Map<String, Object> sampleGlobalConfig = sampleConfigurations.getGlobalConfig();    sampleGlobalConfig.put("newGlobalField", "newGlobalValue");    ConfigurationsUtils.writeGlobalConfigToZookeeper(sampleGlobalConfig, zookeeperUrl);    waitForConfigUpdate(ConfigurationType.GLOBAL.getTypeName());    Assert.assertEquals("Add global config field", sampleConfigurations.getGlobalConfig(), configuredBolt.getConfigurations().getGlobalConfig());    configsUpdated = new HashSet<>();    sampleGlobalConfig.remove("newGlobalField");    ConfigurationsUtils.writeGlobalConfigToZookeeper(sampleGlobalConfig, zookeeperUrl);    waitForConfigUpdate(ConfigurationType.GLOBAL.getTypeName());    Assert.assertEquals("Remove global config field", sampleConfigurations, configuredBolt.getConfigurations());    configsUpdated = new HashSet<>();    String sensorType = "testSensorConfig";    SensorEnrichmentConfig testSensorConfig = new SensorEnrichmentConfig();    Map<String, Object> enrichmentFieldMap = new HashMap<>();    enrichmentFieldMap.put("enrichmentTest", new ArrayList<String>() {        {            add("enrichmentField");        }    });    testSensorConfig.getEnrichment().setFieldMap(enrichmentFieldMap);    Map<String, Object> threatIntelFieldMap = new HashMap<>();    threatIntelFieldMap.put("threatIntelTest", new ArrayList<String>() {        {            add("threatIntelField");        }    });    testSensorConfig.getThreatIntel().setFieldMap(threatIntelFieldMap);    sampleConfigurations.updateSensorEnrichmentConfig(sensorType, testSensorConfig);    ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(sensorType, testSensorConfig, zookeeperUrl);    waitForConfigUpdate(sensorType);    Assert.assertEquals("Add new sensor config", sampleConfigurations, configuredBolt.getConfigurations());    configuredBolt.cleanup();}
0
public void execute(Tuple input)
{}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{}
0
public void reloadCallback(String name, ConfigurationType type)
{    configsUpdated.add(name);}
0
public void setupConfiguration() throws Exception
{    TestingServer testZkServer = new TestingServer(true);    this.zookeeperUrl = testZkServer.getConnectString();    byte[] globalConfig = ConfigurationsUtils.readGlobalConfigFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH);    ConfigurationsUtils.writeGlobalConfigToZookeeper(globalConfig, zookeeperUrl);    parserConfigurationTypes.add(ConfigurationType.GLOBAL.getTypeName());    Map<String, byte[]> sensorEnrichmentConfigs = ConfigurationsUtils.readSensorEnrichmentConfigsFromFile("../" + TestConstants.ENRICHMENTS_CONFIGS_PATH);    for (String sensorType : sensorEnrichmentConfigs.keySet()) {        ConfigurationsUtils.writeSensorEnrichmentConfigToZookeeper(sensorType, sensorEnrichmentConfigs.get(sensorType), zookeeperUrl);    }    Map<String, byte[]> sensorParserConfigs = ConfigurationsUtils.readSensorParserConfigsFromFile("../" + TestConstants.PARSER_CONFIGS_PATH);    for (String sensorType : sensorParserConfigs.keySet()) {        ConfigurationsUtils.writeSensorParserConfigToZookeeper(sensorType, sensorParserConfigs.get(sensorType), zookeeperUrl);        parserConfigurationTypes.add(sensorType);    }}
0
public void test() throws Exception
{    ParserConfigurations sampleConfigurations = new ParserConfigurations();    UnitTestHelper.setLog4jLevel(ConfiguredBolt.class, Level.FATAL);    try {        StandAloneConfiguredParserBolt configuredBolt = new StandAloneConfiguredParserBolt(null);        configuredBolt.prepare(new HashMap(), topologyContext, outputCollector);        Assert.fail("A valid zookeeper url must be supplied");    } catch (RuntimeException e) {    }    UnitTestHelper.setLog4jLevel(ConfiguredBolt.class, Level.ERROR);    configsUpdated = new HashSet<>();    sampleConfigurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH));    Map<String, byte[]> sensorParserConfigs = ConfigurationsUtils.readSensorParserConfigsFromFile("../" + TestConstants.PARSER_CONFIGS_PATH);    for (String sensorType : sensorParserConfigs.keySet()) {        sampleConfigurations.updateSensorParserConfig(sensorType, sensorParserConfigs.get(sensorType));    }    StandAloneConfiguredParserBolt configuredBolt = new StandAloneConfiguredParserBolt(zookeeperUrl);    configuredBolt.prepare(new HashMap(), topologyContext, outputCollector);    waitForConfigUpdate(parserConfigurationTypes);    Assert.assertEquals(sampleConfigurations, configuredBolt.getConfigurations());    configsUpdated = new HashSet<>();    Map<String, Object> sampleGlobalConfig = sampleConfigurations.getGlobalConfig();    sampleGlobalConfig.put("newGlobalField", "newGlobalValue");    ConfigurationsUtils.writeGlobalConfigToZookeeper(sampleGlobalConfig, zookeeperUrl);    waitForConfigUpdate(ConfigurationType.GLOBAL.getTypeName());    Assert.assertEquals("Add global config field", sampleConfigurations.getGlobalConfig(), configuredBolt.getConfigurations().getGlobalConfig());    configsUpdated = new HashSet<>();    sampleGlobalConfig.remove("newGlobalField");    ConfigurationsUtils.writeGlobalConfigToZookeeper(sampleGlobalConfig, zookeeperUrl);    waitForConfigUpdate(ConfigurationType.GLOBAL.getTypeName());    Assert.assertEquals("Remove global config field", sampleConfigurations, configuredBolt.getConfigurations());    configsUpdated = new HashSet<>();    String sensorType = "testSensorConfig";    SensorParserConfig testSensorConfig = new SensorParserConfig();    testSensorConfig.setParserClassName("className");    testSensorConfig.setSensorTopic("sensorTopic");    testSensorConfig.setParserConfig(new HashMap<String, Object>() {        {            put("configName", "configObject");        }    });    sampleConfigurations.updateSensorParserConfig(sensorType, testSensorConfig);    ConfigurationsUtils.writeSensorParserConfigToZookeeper(sensorType, testSensorConfig, zookeeperUrl);    waitForConfigUpdate(sensorType);    ParserConfigurations configuredBoltConfigs = configuredBolt.getConfigurations();    if (!sampleConfigurations.equals(configuredBoltConfigs)) {                if (sampleConfigurations.getFieldValidations().size() != configuredBoltConfigs.getFieldValidations().size()) {            System.out.println("Field validations don't line up");        }        for (int i = 0; i < sampleConfigurations.getFieldValidations().size(); ++i) {            FieldValidator l = sampleConfigurations.getFieldValidations().get(i);            FieldValidator r = configuredBoltConfigs.getFieldValidations().get(i);            if (!l.equals(r)) {                System.out.println(l + " != " + r);            }        }        if (sampleConfigurations.getConfigurations().size() != configuredBoltConfigs.getConfigurations().size()) {            System.out.println("Configs don't line up");        }        for (Map.Entry<String, Object> kv : sampleConfigurations.getConfigurations().entrySet()) {            Object l = kv.getValue();            Object r = configuredBoltConfigs.getConfigurations().get(kv.getKey());            if (!l.equals(r)) {                System.out.println(kv.getKey() + " config does not line up: ");                System.out.println(l);                System.out.println(r);            }        }        Assert.assertEquals("Add new sensor config", sampleConfigurations, configuredBoltConfigs);    }    Assert.assertEquals("Add new sensor config", sampleConfigurations, configuredBoltConfigs);    configuredBolt.cleanup();}
0
public void bytesFromPositionShouldReturnBytes()
{    Tuple tuple = mock(Tuple.class);    when(tuple.getBinary(1)).thenReturn("bytes".getBytes(UTF_8));    MessageGetStrategy messageGetStrategy = MessageGetters.BYTES_FROM_POSITION.get("1");    assertEquals("bytes", new String((byte[]) messageGetStrategy.get(tuple), UTF_8));}
0
public void jsonFromPositionShouldReturnJSON()
{    Tuple tuple = mock(Tuple.class);    when(tuple.getBinary(1)).thenReturn("{\"field\":\"value\"}".getBytes(UTF_8));    JSONObject expected = new JSONObject();    expected.put("field", "value");    MessageGetStrategy messageGetStrategy = MessageGetters.JSON_FROM_POSITION.get("1");    assertEquals(expected, messageGetStrategy.get(tuple));}
0
public void jsonFromPositionShouldThrowException()
{    exception.expect(IllegalStateException.class);    Tuple tuple = mock(Tuple.class);    when(tuple.getBinary(1)).thenReturn("{\"field\":".getBytes(UTF_8));    MessageGetStrategy messageGetStrategy = MessageGetters.JSON_FROM_POSITION.get("1");    messageGetStrategy.get(tuple);}
0
public void jsonFromFieldShouldReturnJSON()
{    JSONObject actual = new JSONObject();    actual.put("field", "value");    Tuple tuple = mock(Tuple.class);    when(tuple.getValueByField("tuple_field")).thenReturn(actual);    JSONObject expected = new JSONObject();    expected.put("field", "value");    MessageGetStrategy messageGetStrategy = MessageGetters.JSON_FROM_FIELD.get("tuple_field");    assertEquals(expected, messageGetStrategy.get(tuple));}
0
public void objectFromFieldShouldReturnObject()
{    Object actual = "object";    Tuple tuple = mock(Tuple.class);    when(tuple.getValueByField("tuple_field")).thenReturn(actual);    Object expected = "object";    MessageGetStrategy messageGetStrategy = MessageGetters.OBJECT_FROM_FIELD.get("tuple_field");    assertEquals(expected, messageGetStrategy.get(tuple));}
0
public void defaultBytesFromPositionShouldReturnBytes()
{    Tuple tuple = mock(Tuple.class);    when(tuple.getBinary(0)).thenReturn("bytes".getBytes(UTF_8));    MessageGetStrategy messageGetStrategy = MessageGetters.DEFAULT_BYTES_FROM_POSITION.get();    assertEquals("bytes", new String((byte[]) messageGetStrategy.get(tuple), UTF_8));}
0
public void defaultJSONFromPositionShouldReturnJSON()
{    Tuple tuple = mock(Tuple.class);    when(tuple.getBinary(0)).thenReturn("{\"field\":\"value\"}".getBytes(UTF_8));    JSONObject expected = new JSONObject();    expected.put("field", "value");    MessageGetStrategy messageGetStrategy = MessageGetters.DEFAULT_JSON_FROM_POSITION.get();    assertEquals(expected, messageGetStrategy.get(tuple));}
0
public void defaultJSONFromFieldShouldReturnJSON()
{    JSONObject actual = new JSONObject();    actual.put("field", "value");    Tuple tuple = mock(Tuple.class);    when(tuple.getValueByField("message")).thenReturn(actual);    JSONObject expected = new JSONObject();    expected.put("field", "value");    MessageGetStrategy messageGetStrategy = MessageGetters.DEFAULT_JSON_FROM_FIELD.get();    assertEquals(expected, messageGetStrategy.get(tuple));}
0
public void defaultObjectFromFieldShouldReturnObject()
{    Object actual = "object";    Tuple tuple = mock(Tuple.class);    when(tuple.getValueByField("message")).thenReturn(actual);    Object expected = "object";    MessageGetStrategy messageGetStrategy = MessageGetters.DEFAULT_OBJECT_FROM_FIELD.get();    assertEquals(expected, messageGetStrategy.get(tuple));}
0
private static Tuple createTuple(Map<String, Object> kafkaFields, String metadata) throws Exception
{    List<Map.Entry<String, Object>> fields = new ArrayList<>();    for (Map.Entry<String, Object> kv : kafkaFields.entrySet()) {        fields.add(kv);    }    Tuple t = mock(Tuple.class);    Fields f = mock(Fields.class);    when(f.size()).thenReturn(fields.size() + 2);    for (int i = 0; i < fields.size(); ++i) {        when(f.get(eq(i + 2))).thenReturn(fields.get(i).getKey());        when(t.getValue(eq(i + 2))).thenReturn(fields.get(i).getValue());    }    when(t.getFields()).thenReturn(f);    when(t.getBinary(eq(RawMessageUtil.KEY_INDEX))).thenReturn(metadata.getBytes(StandardCharsets.UTF_8));    return t;}
0
private void checkKafkaMetadata(RawMessage m, boolean isEmpty)
{    if (!isEmpty) {        Assert.assertEquals("kafka_meta_1_val", m.getMetadata().get(MetadataUtil.METADATA_PREFIX + ".kafka_meta_1"));        Assert.assertEquals("kafka_meta_2_val", m.getMetadata().get(MetadataUtil.METADATA_PREFIX + ".kafka_meta_2"));    } else {        Assert.assertFalse(m.getMetadata().containsKey(MetadataUtil.METADATA_PREFIX + ".kafka_meta_1"));        Assert.assertFalse(m.getMetadata().containsKey(MetadataUtil.METADATA_PREFIX + ".kafka_meta_2"));    }}
0
private void checkAppMetadata(RawMessage m, boolean isEmpty)
{    if (!isEmpty) {        Assert.assertEquals("app_meta_1_val", m.getMetadata().get(MetadataUtil.METADATA_PREFIX + ".app_meta_1"));        Assert.assertEquals("app_meta_2_val", m.getMetadata().get(MetadataUtil.METADATA_PREFIX + ".app_meta_2"));    } else {        Assert.assertFalse(m.getMetadata().containsKey(MetadataUtil.METADATA_PREFIX + ".app_meta_1"));        Assert.assertFalse(m.getMetadata().containsKey(MetadataUtil.METADATA_PREFIX + ".app_meta_2"));    }}
0
public void testDefaultStrategy_withKafkaMetadata_withAppMetadata() throws Exception
{    Tuple t = createTuple(kafkaMetadata, appMetadata);    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), true, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        checkKafkaMetadata(m, false);        checkAppMetadata(m, false);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), false, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
public void testDefaultStrategy_withKafkaMetadata_withoutAppMetadata() throws Exception
{    Tuple t = createTuple(kafkaMetadata, "{}");    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), true, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        checkKafkaMetadata(m, false);        checkAppMetadata(m, true);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), false, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
public void testDefaultStrategy_withoutKafkaMetadata_withAppMetadata() throws Exception
{    Tuple t = createTuple(new HashMap<>(), appMetadata);    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), true, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        checkKafkaMetadata(m, true);        checkAppMetadata(m, false);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), false, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
public void testDefaultStrategy_withoutKafkaMetadata_withoutAppMetadata() throws Exception
{    Tuple t = createTuple(new HashMap<>(), "{}");    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), true, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        checkKafkaMetadata(m, true);        checkAppMetadata(m, true);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.DEFAULT, t, "raw_message".getBytes(StandardCharsets.UTF_8), false, new HashMap<>());        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
private void checkEnvelopeMetadata(RawMessage m)
{    Assert.assertEquals("real_original_string", m.getMetadata().get(MetadataUtil.METADATA_PREFIX + "." + Constants.Fields.ORIGINAL.getName()));    Assert.assertEquals("enveloped_metadata_val_1", m.getMetadata().get(MetadataUtil.METADATA_PREFIX + ".enveloped_metadata_field_1"));    Assert.assertEquals("enveloped_metadata_val_2", m.getMetadata().get(MetadataUtil.METADATA_PREFIX + ".enveloped_metadata_field_2"));}
0
private void checkMergedData(RawMessage m)
{    JSONObject message = new JSONObject(envelopedMessage);    RawMessageStrategies.ENVELOPE.mergeMetadata(message, m.getMetadata(), true, new HashMap<String, Object>() {    });    if (m.getMetadata().containsKey(MetadataUtil.METADATA_PREFIX + "." + Constants.Fields.ORIGINAL.getName())) {        Assert.assertEquals(m.getMetadata().get(MetadataUtil.METADATA_PREFIX + "." + Constants.Fields.ORIGINAL.getName()), message.get(Constants.Fields.ORIGINAL.getName()));    }    Assert.assertEquals("message_val1", message.get("message_field1"));}
0
public void testEnvelopeStrategy_withKafkaMetadata_withAppMetadata() throws Exception
{    Tuple t = createTuple(kafkaMetadata, appMetadata);    Map<String, Object> config = ImmutableMap.of(EnvelopedRawMessageStrategy.MESSAGE_FIELD_CONFIG, "data");    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), true, config);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertFalse(m.getMetadata().containsKey("data"));        checkEnvelopeMetadata(m);        checkMergedData(m);        checkKafkaMetadata(m, false);        checkAppMetadata(m, false);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), false, config);        checkMergedData(m);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertFalse(m.getMetadata().containsKey("data"));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
public void testEnvelopeStrategy_withKafkaMetadata_withoutAppMetadata() throws Exception
{    Tuple t = createTuple(kafkaMetadata, "{}");    Map<String, Object> config = ImmutableMap.of(EnvelopedRawMessageStrategy.MESSAGE_FIELD_CONFIG, "data");    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), true, config);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertFalse(m.getMetadata().containsKey("data"));        checkMergedData(m);        checkEnvelopeMetadata(m);        checkKafkaMetadata(m, false);        checkAppMetadata(m, true);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), false, config);        Assert.assertFalse(m.getMetadata().containsKey("data"));        checkMergedData(m);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
public void testEnvelopeStrategy_withoutKafkaMetadata_withAppMetadata() throws Exception
{    Tuple t = createTuple(new HashMap<>(), appMetadata);    Map<String, Object> config = ImmutableMap.of(EnvelopedRawMessageStrategy.MESSAGE_FIELD_CONFIG, "data");    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), true, config);        Assert.assertFalse(m.getMetadata().containsKey("data"));        checkMergedData(m);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        checkEnvelopeMetadata(m);        checkKafkaMetadata(m, true);        checkAppMetadata(m, false);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), false, config);        Assert.assertFalse(m.getMetadata().containsKey("data"));        checkMergedData(m);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
public void testEnvelopeStrategy_withoutKafkaMetadata_withoutAppMetadata() throws Exception
{    Tuple t = createTuple(new HashMap<>(), "{}");    Map<String, Object> config = ImmutableMap.of(EnvelopedRawMessageStrategy.MESSAGE_FIELD_CONFIG, "data");    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), true, config);        Assert.assertFalse(m.getMetadata().containsKey("data"));        checkMergedData(m);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        checkEnvelopeMetadata(m);        checkKafkaMetadata(m, true);        checkAppMetadata(m, true);    }    {        RawMessage m = RawMessageUtil.INSTANCE.getRawMessage(RawMessageStrategies.ENVELOPE, t, envelopedData.getBytes(StandardCharsets.UTF_8), false, config);        Assert.assertFalse(m.getMetadata().containsKey("data"));        checkMergedData(m);        Assert.assertEquals("raw_message", new String(m.getMessage(), StandardCharsets.UTF_8));        Assert.assertTrue(m.getMetadata().isEmpty());    }}
0
public void handleErrorShouldEmitAndReportError() throws Exception
{    Throwable e = new Exception("error");    MetronError error = new MetronError().withMessage("error message").withThrowable(e);    OutputCollector collector = mock(OutputCollector.class);    StormErrorUtils.handleError(collector, error);    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), argThat(new MetronErrorJSONMatcher(error.getJSONObject())));    verify(collector, times(1)).reportError(any());}
0
protected Date dateAtMidnight(Date date)
{    Calendar calendar = Calendar.getInstance();    calendar.setTime(date);    calendar.set(Calendar.HOUR_OF_DAY, 0);    calendar.set(Calendar.MINUTE, 0);    calendar.set(Calendar.SECOND, 0);    calendar.set(Calendar.MILLISECOND, 0);    return calendar.getTime();}
0
public static void main(String... argv) throws IOException, java.text.ParseException, ClassNotFoundException, InterruptedException
{    /**     * Example     * start=$(date -d '30 days ago' +%m/%d/%Y)     * yarn jar Metron-DataLoads-0.1BETA.jar org.apache.metron.dataloads.bulk.HDFSDataPruner -f hdfs://ec2-52-36-25-217.us-west-2.compute.amazonaws.com:8020 -g '/apps/metron/enrichment/indexed/bro_doc/*enrichment-*' -s $(date -d '30 days ago' +%m/%d/%Y) -n 1;     * echo ${start}     */    Options options = new Options();    Options help = new Options();    {        Option o = new Option("h", "help", false, "This screen");        o.setRequired(false);        help.addOption(o);    }    {        Option o = new Option("s", "start-date", true, "Starting Date (MM/DD/YYYY)");        o.setArgName("START_DATE");        o.setRequired(true);        options.addOption(o);    }    {        Option o = new Option("f", "filesystem", true, "Filesystem uri - e.g. hdfs://host:8020 or file:///");        o.setArgName("FILESYSTEM");        o.setRequired(true);        options.addOption(o);    }    {        Option o = new Option("n", "numdays", true, "Number of days back to purge");        o.setArgName("NUMDAYS");        o.setRequired(true);        options.addOption(o);    }    {        Option o = new Option("g", "glob-string", true, "Glob filemask for files to delete - e.g. /apps/metron/enrichment/bro_doc/file-*");        o.setArgName("GLOBSTRING");        o.setRequired(true);        options.addOption(o);    }    try {        CommandLineParser parser = new PosixParser();        CommandLine cmd = null;        try {            cmd = parser.parse(help, argv, true);            if (cmd.getOptions().length > 0) {                final HelpFormatter usageFormatter = new HelpFormatter();                usageFormatter.printHelp("HDFSDataPruner", null, options, null, true);                System.exit(0);            }            cmd = parser.parse(options, argv);        } catch (ParseException pe) {            final HelpFormatter usageFormatter = new HelpFormatter();            usageFormatter.printHelp("HDFSDataPruner", null, options, null, true);            System.exit(-1);        }        String start = cmd.getOptionValue("s");        Date startDate = new SimpleDateFormat("MM/dd/yyyy").parse(start);        String fileSystemUri = cmd.getOptionValue("f");        Integer numDays = Integer.parseInt(cmd.getOptionValue("n"));        String globString = cmd.getOptionValue("g");                DataPruner pruner = new HDFSDataPruner(startDate, numDays, fileSystemUri, globString);            } catch (Exception e) {        e.printStackTrace();        System.exit(-1);    }}
1
public Long prune() throws IOException
{    long filesPruned = 0L;    FileStatus[] filesToDelete = fileSystem.globStatus(globPath, new HDFSDataPruner.DateFileFilter(this));    for (FileStatus fileStatus : filesToDelete) {                fileSystem.delete(fileStatus.getPath(), false);        filesPruned++;    }    return filesPruned;}
1
public boolean accept(Path path)
{    try {                if (pruner.fileSystem.isDirectory(path)) {            return false;        }    } catch (IOException e) {                if (failOnError) {            throw new RuntimeException(e);        }        return false;    }    try {        FileStatus file = pruner.fileSystem.getFileStatus(path);        long fileModificationTime = file.getModificationTime();        boolean accept = false;        if (fileModificationTime >= pruner.firstTimeMillis && fileModificationTime < pruner.lastTimeMillis) {            accept = true;        }        return accept;    } catch (IOException e) {                if (failOnError) {            throw new RuntimeException(e);        }        return false;    }}
1
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
private static long getTimestamp(CommandLine cli) throws java.text.ParseException
{    Date d = getFormat(cli).parse(BulkLoadOptions.AS_OF_TIME.get(cli));    return d.getTime();}
0
private static DateFormat getFormat(CommandLine cli)
{    DateFormat format = new SimpleDateFormat();    if (BulkLoadOptions.AS_OF_TIME_FORMAT.has(cli)) {        format = new SimpleDateFormat(BulkLoadOptions.AS_OF_TIME_FORMAT.get(cli));    }    return format;}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (BulkLoadOptions.HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("LeastRecentlyUsedPruner", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (BulkLoadOptions o : BulkLoadOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public Option apply(@Nullable String s)
{    return new Option(s, "help", false, "Generate Help screen");}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "table", true, "HBase table to prune");    o.setRequired(true);    o.setArgName("HBASE_TABLE");    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "column_family", true, "Column family of the HBase table to prune");    o.setRequired(false);    o.setArgName("CF_NAME");    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "as_of", true, "The earliest access tracker you want to use.");    o.setArgName("datetime");    o.setRequired(true);    return o;}
0
public Option apply(@Nullable String s)
{    String defaultFormat = new SimpleDateFormat().toLocalizedPattern();    Option o = new Option(s, "as_of_format", true, "The format of the as_of time (only used in conjunction with the as_of option) (Default is: " + defaultFormat + ")");    o.setArgName("format");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "access_table", true, "HBase table containing the access trackers.");    o.setRequired(true);    o.setArgName("HBASE_TABLE");    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "access_column_family", true, "Column family of the HBase table containing the access trackers");    o.setRequired(true);    o.setArgName("CF_NAME");    return o;}
0
public static void setupHBaseJob(Job job, String sourceTable, String cf) throws IOException
{    Scan scan = new Scan();    if (cf != null) {        scan.addFamily(Bytes.toBytes(cf));    }        scan.setCaching(500);        scan.setCacheBlocks(false);        TableMapReduceUtil.initTableMapperJob(    sourceTable,     scan,     PrunerMapper.class,     null,     null, job);    TableMapReduceUtil.initTableReducerJob(    sourceTable,     null, job);}
0
public static Job createJob(Configuration conf, String table, String cf, String accessTrackerTable, String accessTrackerColumnFamily, Long ts) throws IOException
{    Job job = new Job(conf);    job.setJobName("LeastRecentlyUsedPruner: Pruning " + table + ":" + cf + " since " + new SimpleDateFormat().format(new Date(ts)));    System.out.println("Configuring " + job.getJobName());    job.setJarByClass(LeastRecentlyUsedPruner.class);    job.getConfiguration().setLong(PrunerMapper.TIMESTAMP_CONF, ts);    job.getConfiguration().set(PrunerMapper.ACCESS_TRACKER_NAME_CONF, table);    job.getConfiguration().set(PrunerMapper.ACCESS_TRACKER_CF_CONF, accessTrackerColumnFamily);    job.getConfiguration().set(PrunerMapper.ACCESS_TRACKER_TABLE_CONF, accessTrackerTable);    setupHBaseJob(job, table, cf);    job.setNumReduceTasks(0);    return job;}
0
public static void main(String... argv) throws IOException, java.text.ParseException, ClassNotFoundException, InterruptedException
{    Configuration conf = HBaseConfiguration.create();    String[] otherArgs = new GenericOptionsParser(conf, argv).getRemainingArgs();    CommandLine cli = BulkLoadOptions.parse(new PosixParser(), otherArgs);    Long ts = BulkLoadOptions.getTimestamp(cli);    String table = BulkLoadOptions.TABLE.get(cli);    String cf = BulkLoadOptions.COLUMN_FAMILY.get(cli);    String accessTrackerTable = BulkLoadOptions.ACCESS_TABLE.get(cli);    String accessTrackerCF = BulkLoadOptions.ACCESS_COLUMN_FAMILY.get(cli);    Job job = createJob(conf, table, cf, accessTrackerTable, accessTrackerCF, ts);    System.exit(job.waitForCompletion(true) ? 0 : 1);}
0
public int getTypeColumnIndex()
{    return typeColumnIndex;}
0
public String getType()
{    return type;}
0
public int getIndicatorColumn()
{    return indicatorColumn;}
0
public LookupConverter getConverter()
{    return converter;}
0
public Iterable<LookupKV> extract(String line) throws IOException
{    if (ignore(line)) {        return Collections.emptyList();    }    String[] tokens = parser.parseLine(line);    LookupKey key = converter.toKey(getType(tokens), tokens[indicatorColumn]);    Map<String, Object> values = new HashMap<>();    for (Map.Entry<String, Integer> kv : columnMap.entrySet()) {        values.put(kv.getKey(), tokens[kv.getValue()]);    }    return Arrays.asList(new LookupKV(key, converter.toValue(values)));}
0
private String getType(String[] tokens)
{    if (type == null) {        return tokens[typeColumnIndex];    } else {        return type;    }}
0
public void initialize(Map<String, Object> config)
{    super.initialize(config);    if (config.containsKey(INDICATOR_COLUMN_KEY)) {        indicatorColumn = columnMap.get(config.get(INDICATOR_COLUMN_KEY).toString());    }    if (config.containsKey(TYPE_KEY)) {        type = config.get(TYPE_KEY).toString();    } else if (config.containsKey(TYPE_COLUMN_KEY)) {        typeColumnIndex = columnMap.get(config.get(TYPE_COLUMN_KEY).toString());    }    if (config.containsKey(LOOKUP_CONVERTER)) {        converter = LookupConverters.getConverter((String) config.get(LOOKUP_CONVERTER));    }}
0
public LookupConverter getConverter()
{    return converter;}
0
public static LookupConverter getConverter(String name)
{    try {        return LookupConverters.valueOf(name).getConverter();    } catch (Throwable t) {        try {            return (LookupConverter) Class.forName(name).getConstructor().newInstance();        } catch (InstantiationException | IllegalAccessException | ClassNotFoundException | NoSuchMethodException | InvocationTargetException e) {            throw new IllegalStateException("Unable to parse " + name, e);        }    }}
0
public LookupKey toKey(String type, String indicator)
{    return new EnrichmentKey(type, indicator);}
0
public LookupValue toValue(Map<String, Object> metadata)
{    return new EnrichmentValue(metadata);}
0
 Set<ExtractorCapabilities> getCapabilities()
{    return EnumSet.noneOf(ExtractorCapabilities.class);}
0
public Iterable<LookupKV> extract(String line) throws IOException
{    return decoratedExtractor.extract(line);}
0
public void initialize(Map<String, Object> config)
{    decoratedExtractor.initialize(config);}
0
public Extractor getUnderlyingExtractor()
{    return decoratedExtractor;}
0
public Map<String, Object> getConfig()
{    return config;}
0
public void setConfig(Map<String, Object> config)
{    this.config = config;}
0
public InputFormatHandler getInputFormat()
{    return inputFormat;}
0
public void setInputFormat(String handler)
{    try {        this.inputFormat = Formats.create(handler);    } catch (ClassNotFoundException | InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {        throw new IllegalStateException("Unable to create an inputformathandler", e);    }}
0
public Extractor getExtractor()
{    return extractor;}
0
public void setExtractor(String extractor)
{    try {        this.extractor = Extractors.create(extractor);    } catch (ClassNotFoundException | IllegalAccessException | InstantiationException | NoSuchMethodException | InvocationTargetException e) {        throw new IllegalStateException("Unable to create an extractor", e);    }}
0
public static synchronized ExtractorHandler load(InputStream is) throws IOException
{    ExtractorHandler ret = _mapper.readValue(is, ExtractorHandler.class);    ret.getExtractor().initialize(ret.getConfig());    return ret;}
0
public static synchronized ExtractorHandler load(String s, Charset c) throws IOException
{    return load(new ByteArrayInputStream(s.getBytes(c)));}
0
public static synchronized ExtractorHandler load(String s) throws IOException
{    return load(s, Charset.defaultCharset());}
0
public Extractor create()
{    return _creator.create();}
0
public static Extractor create(String extractorName) throws ClassNotFoundException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException
{    try {        ExtractorCreator ec = Extractors.valueOf(extractorName);        return new TransformFilterExtractorDecorator(ec.create());    } catch (IllegalArgumentException iae) {        Extractor ex = (Extractor) Class.forName(extractorName).getConstructor().newInstance();        return new TransformFilterExtractorDecorator(ex);    }}
0
public Extractor create()
{    return new CSVExtractor();}
0
public Extractor create()
{    return new StixExtractor();}
0
public void set(Job job, List<Path> path, Map<String, Object> config) throws IOException
{    _handler.set(job, path, config);}
0
public static InputFormatHandler create(String handlerName) throws ClassNotFoundException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException
{    try {        InputFormatHandler ec = Formats.valueOf(handlerName)._handler;        return ec;    } catch (IllegalArgumentException iae) {        InputFormatHandler ex = (InputFormatHandler) Class.forName(handlerName).getConstructor().newInstance();        return ex;    }}
0
 void set(Job job, Path input, Map<String, Object> config) throws IOException
{    set(job, ImmutableList.of(input), config);}
0
public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    this.fileSplit = (FileSplit) split;    this.conf = context.getConfiguration();}
0
public boolean nextKeyValue() throws IOException, InterruptedException
{    if (!processed) {        byte[] contents = new byte[(int) fileSplit.getLength()];        Path file = fileSplit.getPath();        FileSystem fs = file.getFileSystem(conf);        FSDataInputStream in = null;        try {            in = fs.open(file);            IOUtils.readFully(in, contents, 0, contents.length);            value.set(contents, 0, contents.length);        } finally {            IOUtils.closeStream(in);        }        processed = true;        return true;    }    return false;}
0
public NullWritable getCurrentKey() throws IOException, InterruptedException
{    return NullWritable.get();}
0
public Text getCurrentValue() throws IOException, InterruptedException
{    return value;}
0
public float getProgress() throws IOException
{    return processed ? 1.0f : 0.0f;}
0
public void close() throws IOException
{}
0
protected boolean isSplitable(JobContext context, Path file)
{    return false;}
0
public RecordReader<NullWritable, Text> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException
{    WholeFileRecordReader reader = new WholeFileRecordReader();    reader.initialize(split, context);    return reader;}
0
public void set(Job job, List<Path> inputs, Map<String, Object> config) throws IOException
{    for (Path input : inputs) {        WholeFileInputFormat.addInputPath(job, input);    }    job.setInputFormatClass(WholeFileInputFormat.class);}
0
public Iterable<LookupKV> extract(String line) throws IOException
{    STIXPackage stixPackage = STIXPackage.fromXMLString(line.replaceAll("\"Equal\"", "\"Equals\""));    List<LookupKV> ret = new ArrayList<>();    for (Observable o : getObservables(stixPackage)) {        ObjectType obj = o.getObject();        if (obj != null) {            ObjectPropertiesType props = obj.getProperties();            if (props != null) {                ObjectTypeHandler handler = ObjectTypeHandlers.getHandlerByInstance(props);                if (handler != null) {                    if (LOG.isDebugEnabled()) {                                            }                    Iterable<LookupKV> extractions = handler.extract(props, config);                    for (LookupKV extraction : extractions) {                        ret.add(extraction);                    }                } else if (LOG.isDebugEnabled()) {                                    }            }        }    }    return ret;}
1
public List<Observable> getObservables(STIXPackage stixPackage)
{    List<Observable> ret = new ArrayList<>();    Observables observables = stixPackage.getObservables();    if (observables != null) {        for (Observable o : observables.getObservables()) {            ret.add(o);        }    }    if (stixPackage.getIndicators() != null) {        if (stixPackage.getIndicators().getIndicators() != null) {            List<IndicatorBaseType> indicators = stixPackage.getIndicators().getIndicators();            int indicatorCount = indicators.size();            for (int i = 0; i < indicatorCount; i++) {                Indicator indicator = (Indicator) indicators.get(i);                if (indicator.getObservable() != null) {                    ret.add(indicator.getObservable());                }            }        }    }    return ret;}
0
public void initialize(Map<String, Object> config)
{    this.config = config;}
0
public static Iterable<String> split(StringObjectPropertyType value)
{    final ConditionTypeEnum condition = value.getCondition() == null ? ConditionTypeEnum.EQUALS : value.getCondition();    final ConditionApplicationEnum applyCondition = value.getApplyCondition();    List<String> tokens = new ArrayList<>();    if (condition == ConditionTypeEnum.EQUALS && applyCondition == ConditionApplicationEnum.ANY) {        String delim = value.getDelimiter();        String line = value.getValue().toString();        if (delim != null) {            for (String token : Splitter.on(delim).split(line)) {                tokens.add(token);            }        } else {            tokens.add(line);        }    }    return tokens;}
0
public static void main(String[] args) throws IOException
{    File file = new File("/tmp/sample.xml");    /*if (args.length > 0) {            file = new File(args[0]);        } else {            try {                URL url = XML2Object.class.getClass().getResource(                        "/org/mitre/stix/examples/sample.xml");                file = new File(url.toURI());            } catch (URISyntaxException e) {                throw new RuntimeException(e);            }        }*/    String line = FileUtils.readFileToString(file);    StixExtractor extractor = new StixExtractor();    for (LookupKV results : extractor.extract(line)) {        System.out.println(results);    }}
0
public Class<T> getTypeClass()
{    return objectPropertiesType;}
0
public String getType()
{    return getTypeClass().getSimpleName().toLowerCase();}
0
public Iterable<LookupKV> extract(final Address type, Map<String, Object> config) throws IOException
{    List<LookupKV> ret = new ArrayList<>();    final CategoryTypeEnum category = type.getCategory();    if (!SUPPORTED_CATEGORIES.contains(category)) {        return ret;    }    String typeStr = getType();    if (config != null) {        if (config.containsKey(SPECIFIC_CATEGORY_CONFIG)) {            List<CategoryTypeEnum> categories = new ArrayList<>();            for (String c : Splitter.on(",").split(config.get(SPECIFIC_CATEGORY_CONFIG).toString())) {                categories.add(CategoryTypeEnum.valueOf(c));            }            EnumSet<CategoryTypeEnum> specificCategories = EnumSet.copyOf(categories);            if (!specificCategories.contains(category)) {                return ret;            }        }        if (config.containsKey(TYPE_CONFIG)) {            typeStr = config.get(TYPE_CONFIG).toString();        }    }    StringObjectPropertyType value = type.getAddressValue();    for (String token : StixExtractor.split(value)) {        final String indicatorType = typeStr + ":" + category;        LookupKV results = new LookupKV(new EnrichmentKey(indicatorType, token), new EnrichmentValue(new HashMap<String, Object>() {            {                put("source-type", "STIX");                put("indicator-type", indicatorType);                put("source", type.toXMLString());            }        }));        ret.add(results);    }    return ret;}
0
public List<String> getPossibleTypes()
{    String typeStr = getType();    List<String> ret = new ArrayList<>();    for (CategoryTypeEnum e : SUPPORTED_CATEGORIES) {        ret.add(typeStr + ":" + e);    }    return ret;}
0
public Iterable<LookupKV> extract(final DomainName type, Map<String, Object> config) throws IOException
{    List<LookupKV> ret = new ArrayList<>();    String typeStr = getType();    if (config != null) {        Object o = config.get(TYPE_CONFIG);        if (o != null) {            typeStr = o.toString();        }    }    final DomainNameTypeEnum domainType = type.getType();    if (domainType == null || SUPPORTED_TYPES.contains(domainType)) {        StringObjectPropertyType value = type.getValue();        for (String token : StixExtractor.split(value)) {            final String indicatorType = typeStr + ":" + DomainNameTypeEnum.FQDN;            LookupKV results = new LookupKV(new EnrichmentKey(indicatorType, token), new EnrichmentValue(new HashMap<String, Object>() {                {                    put("source-type", "STIX");                    put("indicator-type", indicatorType);                    put("source", type.toXMLString());                }            }));            ret.add(results);        }    }    return ret;}
0
public List<String> getPossibleTypes()
{    String typeStr = getType();    List<String> ret = new ArrayList<>();    for (DomainNameTypeEnum e : SUPPORTED_TYPES) {        ret.add(typeStr + ":" + e);    }    return ret;}
0
public Iterable<LookupKV> extract(final Hostname type, Map<String, Object> config) throws IOException
{    StringObjectPropertyType value = type.getHostnameValue();    String typeStr = getType();    if (config != null) {        Object o = config.get(TYPE_CONFIG);        if (o != null) {            typeStr = o.toString();        }    }    List<LookupKV> ret = new ArrayList<>();    for (String token : StixExtractor.split(value)) {        final String indicatorType = typeStr;        LookupKV results = new LookupKV(new EnrichmentKey(indicatorType, token), new EnrichmentValue(new HashMap<String, Object>() {            {                put("source-type", "STIX");                put("indicator-type", indicatorType);                put("source", type.toXMLString());            }        }));        ret.add(results);    }    return ret;}
0
public List<String> getPossibleTypes()
{    return ImmutableList.of(getType());}
0
 ObjectTypeHandler getHandler()
{    return _handler;}
0
public static ObjectTypeHandler getHandlerByInstance(ObjectPropertiesType inst)
{    for (ObjectTypeHandlers h : values()) {        if (inst.getClass().equals(h.getHandler().getTypeClass())) {            return h.getHandler();        }    }    return null;}
0
public Iterable<LookupKV> extract(URIObjectType type, Map<String, Object> config) throws IOException
{    List<LookupKV> ret = new ArrayList<>();    if (type != null) {        AnyURIObjectPropertyType val = type.getValue();        if (val != null) {            Object v = val.getValue();            if (v != null) {                final String indicatorType = getType();                LookupKV results = new LookupKV(new EnrichmentKey(indicatorType, v.toString()), new EnrichmentValue(new HashMap<String, Object>() {                    {                        put("source-type", "STIX");                        put("uri", v.toString());                        put("indicator-type", indicatorType);                        put("source", type.toXMLString());                    }                }));                ret.add(results);            }        }    }    return ret;}
0
public List<String> getPossibleTypes()
{    return ImmutableList.of(getType());}
0
public String toString()
{    return key;}
0
public boolean existsIn(Map<String, Object> config)
{    return config == null ? false : config.containsKey(key);}
0
public void initialize(Map<String, Object> config)
{    super.initialize(config);    if (VALUE_TRANSFORM.existsIn(config)) {        this.valueTransforms = getTransforms(config, VALUE_TRANSFORM.toString());    }    if (INDICATOR_TRANSFORM.existsIn(config)) {        this.indicatorTransforms = getTransforms(config, INDICATOR_TRANSFORM.toString());    }    if (VALUE_FILTER.existsIn(config)) {        this.valueFilter = getFilter(config, VALUE_FILTER.toString());    }    if (INDICATOR_FILTER.existsIn(config)) {        this.indicatorFilter = getFilter(config, INDICATOR_FILTER.toString());    }    if (STATE_UPDATE.existsIn(config)) {        capabilities.add(ExtractorCapabilities.STATEFUL);        this.stateUpdate = getTransforms(config, STATE_UPDATE.toString());    }    if (STATE_INIT.existsIn(config)) {        capabilities.add(ExtractorCapabilities.STATEFUL);    }    if (STATE_MERGE.existsIn(config)) {        capabilities.add(ExtractorCapabilities.MERGEABLE);        this.stateMerge = getFilter(config, STATE_MERGE.toString());    }    String zkClientUrl = "";    if (ZK_QUORUM.existsIn(config)) {        zkClientUrl = ConversionUtils.convert(config.get(ZK_QUORUM.toString()), String.class);    }    zkClient = setupClient(zkClient, zkClientUrl);    this.globalConfig = getGlobalConfig(zkClient);    this.stellarContext = createContext(zkClient);    StellarFunctions.initialize(stellarContext);    this.transformProcessor = new StellarProcessor();    this.filterProcessor = new StellarPredicateProcessor();}
0
public Object initializeState(Map<String, Object> config)
{    if (STATE_INIT.existsIn(config)) {        MapVariableResolver resolver = new MapVariableResolver(globalConfig);        return transformProcessor.parse(config.get(STATE_INIT.toString()).toString(), resolver, StellarFunctions.FUNCTION_RESOLVER(), stellarContext);    }    return null;}
0
public Object mergeStates(List<? extends Object> states)
{    return transformProcessor.parse(stateMerge, new MapVariableResolver(new HashMap<String, Object>() {        {            put(STATES_KEY, states);        }    }, globalConfig), StellarFunctions.FUNCTION_RESOLVER(), stellarContext);}
0
private String getFilter(Map<String, Object> config, String valueFilter)
{    return (String) config.get(valueFilter);}
0
private Map<String, String> getTransforms(Map<String, Object> config, String type)
{        @SuppressWarnings("unchecked")    Map<Object, Object> transformsConfig = (Map) config.get(type);    Map<String, String> transforms = new LinkedHashMap<>();    for (Map.Entry<Object, Object> e : transformsConfig.entrySet()) {        transforms.put((String) e.getKey(), (String) e.getValue());    }    return transforms;}
0
private Optional<CuratorFramework> setupClient(Optional<CuratorFramework> zkClient, String zookeeperUrl)
{        if (!zkClient.isPresent()) {        if (StringUtils.isNotBlank(zookeeperUrl)) {            CuratorFramework client = ConfigurationsUtils.getClient(zookeeperUrl);            client.start();            return Optional.of(client);        } else {                        return Optional.empty();        }    } else {        return zkClient;    }}
1
private Map<String, Object> getGlobalConfig(Optional<CuratorFramework> zkClient)
{    if (zkClient.isPresent()) {        try {            return JSONUtils.INSTANCE.load(new ByteArrayInputStream(ConfigurationsUtils.readGlobalConfigBytesFromZookeeper(zkClient.get())), JSONUtils.MAP_SUPPLIER);        } catch (Exception e) {                    }    }    return new LinkedHashMap<>();}
1
private Context createContext(Optional<CuratorFramework> zkClient)
{    Context.Builder builder = new Context.Builder();    if (zkClient.isPresent()) {        builder.with(Context.Capabilities.ZOOKEEPER_CLIENT, zkClient::get);    }    builder.with(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    builder.with(Context.Capabilities.STELLAR_CONFIG, () -> globalConfig);    return builder.build();}
0
public Set<ExtractorCapabilities> getCapabilities()
{    return capabilities;}
0
public Iterable<LookupKV> extract(String line) throws IOException
{    return extract(line, new AtomicReference<>(null));}
0
public Iterable<LookupKV> extract(String line, AtomicReference<Object> state) throws IOException
{    List<LookupKV> lkvs = new ArrayList<>();    for (LookupKV lkv : super.extract(line)) {        if (updateLookupKV(lkv, state)) {            lkvs.add(lkv);        }    }    return lkvs;}
0
private boolean updateLookupKV(LookupKV lkv, AtomicReference<Object> state)
{    Map<String, Object> ret = lkv.getValue().getMetadata();    Map<String, Object> ind = new LinkedHashMap<>();    String indicator = lkv.getKey().getIndicator();        ind.put(INDICATOR.toString(), indicator);    Map<String, Object> stateMap = new LinkedHashMap<>();    stateMap.put(STATE_KEY, state.get());    MapVariableResolver resolver = new MapVariableResolver(ret, ind, globalConfig, stateMap);    transform(valueTransforms, ret, resolver);    transform(indicatorTransforms, ind, resolver);        Object updatedIndicator = ind.get(INDICATOR.toString());    if (updatedIndicator != null || getCapabilities().contains(ExtractorCapabilities.STATEFUL)) {        if (!(updatedIndicator instanceof String)) {            throw new UnsupportedOperationException("Indicator transform must return String type");        }        lkv.getKey().setIndicator((String) updatedIndicator);        boolean update = filter(indicatorFilter, resolver) && filter(valueFilter, resolver);        if (update && !stateUpdate.isEmpty()) {            transform(stateUpdate, stateMap, resolver);            state.set(stateMap.get(STATE_KEY));        }        return update;    } else {        return false;    }}
0
private void transform(Map<String, String> transforms, Map<String, Object> variableMap, MapVariableResolver variableResolver)
{    for (Map.Entry<String, String> entry : transforms.entrySet()) {        Object o = transformProcessor.parse(entry.getValue(), variableResolver, StellarFunctions.FUNCTION_RESOLVER(), stellarContext);        if (o == null) {            variableMap.remove(entry.getKey());        } else {            variableMap.put(entry.getKey(), o);        }    }}
0
private Boolean filter(String filterPredicate, MapVariableResolver variableResolver)
{    if (StringUtils.isEmpty(filterPredicate)) {        return true;    }    return filterProcessor.parse(filterPredicate, variableResolver, StellarFunctions.FUNCTION_RESOLVER(), stellarContext);}
0
protected void setZkClient(Optional<CuratorFramework> zkClient)
{    this.zkClient = zkClient;}
0
public void setup(Context context) throws IOException, InterruptedException
{    initialize(context.getConfiguration());}
0
public void map(Object key, Text value, Context context) throws IOException, InterruptedException
{    for (LookupKV results : extractor.extract(value.toString())) {        if (results != null) {            Put put = converter.toPut(columnFamily, results.getKey(), results.getValue());            write(new ImmutableBytesWritable(results.getKey().toBytes()), put, context);        }    }}
0
protected void initialize(Configuration configuration) throws IOException
{    String configStr = configuration.get(CONFIG_KEY);    extractor = ExtractorHandler.load(configStr).getExtractor();    columnFamily = configuration.get(COLUMN_FAMILY_KEY);    try {        converter = (HbaseConverter) Class.forName(configuration.get(CONVERTER_KEY)).getConstructor().newInstance();    } catch (InstantiationException | IllegalAccessException | ClassNotFoundException | NoSuchMethodException | InvocationTargetException e) {        throw new IllegalStateException("Unable to create converter object: " + configuration.get(CONVERTER_KEY), e);    }}
0
protected void write(ImmutableBytesWritable key, Put value, Context context) throws IOException, InterruptedException
{    context.write(key, value);}
0
public void setup(Context context) throws IOException
{    String atTable = context.getConfiguration().get(ACCESS_TRACKER_TABLE_CONF);    String atCF = context.getConfiguration().get(ACCESS_TRACKER_CF_CONF);    String atName = context.getConfiguration().get(ACCESS_TRACKER_NAME_CONF);    Table table = new HTableProvider().getTable(context.getConfiguration(), atTable);    long timestamp = context.getConfiguration().getLong(TIMESTAMP_CONF, -1);    if (timestamp < 0) {        throw new IllegalStateException("Must specify a timestamp that is positive.");    }    try {        tracker = AccessTrackerUtil.INSTANCE.loadAll(AccessTrackerUtil.INSTANCE.loadAll(table, atCF, atName, timestamp));    } catch (Throwable e) {        throw new IllegalStateException("Unable to load the accesstrackers from the directory", e);    }}
0
public void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException
{    if (tracker == null || key == null) {        throw new RuntimeException("Tracker = " + tracker + " key = " + key);    }    if (!tracker.hasSeen(toLookupKey(key.get()))) {        Delete d = new Delete(key.get());        context.write(key, d);    }}
0
protected LookupKey toLookupKey(final byte[] bytes)
{    return new LookupKey() {        @Override        public byte[] toBytes() {            return bytes;        }        @Override        public void fromBytes(byte[] in) {        }        @Override        public String getIndicator() {            return null;        }        @Override        public void setIndicator(String indicator) {        }    };}
0
public byte[] toBytes()
{    return bytes;}
0
public void fromBytes(byte[] in)
{}
0
public String getIndicator()
{    return null;}
0
public void setIndicator(String indicator)
{}
0
public String getShortCode()
{    return "h";}
0
public Option apply(@Nullable String input)
{    return new Option(getShortCode(), "help", false, "Generate Help screen");}
0
public String getShortCode()
{    return "q";}
0
public Option apply(@Nullable String input)
{    return new Option(getShortCode(), "quiet", false, "Do not update progress");}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    return Optional.of(option.has(cli));}
0
public String getShortCode()
{    return "m";}
0
public Option apply(@Nullable String input)
{    Option o = new Option(getShortCode(), "import_mode", true, "The Import mode to use: " + Joiner.on(",").join(importModes) + ".  Default: " + defaultMode);    o.setArgName("MODE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    String mode = option.get(cli);    return resolver.apply(mode);}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "extractor_config", true, "JSON Document describing the extractor for this input data source");    o.setArgName("JSON_FILE");    o.setRequired(true);    return o;}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    try {        return Optional.ofNullable(FileUtils.readFileToString(new File(option.get(cli).trim())));    } catch (IOException e) {        throw new IllegalStateException("Unable to retrieve extractor config from " + option.get(cli) + ": " + e.getMessage(), e);    }}
0
public String getShortCode()
{    return "e";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "log4j", true, "The log4j properties file to load");    o.setArgName("FILE");    o.setRequired(false);    return o;}
0
public String getShortCode()
{    return "l";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "threads", true, "The number of threads to use when extracting data.  The default is the number of cores of your machine.");    o.setArgName("NUM_THREADS");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    int numThreads = Runtime.getRuntime().availableProcessors();    if (option.has(cli)) {        numThreads = ConversionUtils.convert(option.get(cli), Integer.class);    }    return Optional.of(numThreads);}
0
public String getShortCode()
{    return "p";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "batchSize", true, "The batch size to use for HBase puts");    o.setArgName("SIZE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    int batchSize = 128;    if (option.has(cli)) {        batchSize = ConversionUtils.convert(option.get(cli), Integer.class);    }    return Optional.of(batchSize);}
0
public String getShortCode()
{    return "b";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "input", true, "The CSV File to load");    o.setArgName("FILE");    o.setRequired(true);    return o;}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    List<String> inputs = new ArrayList<>();    for (String input : Splitter.on(",").split(Optional.ofNullable(option.get(cli)).orElse(""))) {        inputs.add(input.trim());    }    return Optional.of(inputs);}
0
public String getShortCode()
{    return "i";}
0
public String getCf()
{    return cf;}
0
public Table getTable()
{    return table;}
0
public Extractor getExtractor()
{    return extractor;}
0
public HbaseConverter getConverter()
{    return converter;}
0
public FileSystem getFileSystem()
{    return fs;}
0
public void importData(final EnumMap<OPTIONS_T, Optional<Object>> config, final ExtractorHandler handler, final Configuration hadoopConfig) throws IOException, InvalidWriterOutput
{    validateState(config, handler);    ThreadLocal<STATE_T> state = createState(config, hadoopConfig, handler);    boolean quiet = isQuiet(config);    boolean lineByLine = !handler.getInputFormat().getClass().equals(WholeFileFormat.class);    List<String> inputs = getInputs(config);    FileSystem fs = FileSystem.get(hadoopConfig);    if (!lineByLine) {        extractWholeFiles(inputs, fs, state, quiet);    } else {        int batchSize = batchSize(config);        int numThreads = numThreads(config, handler);        extractLineByLine(inputs, fs, state, batchSize, numThreads, quiet);    }    if (!quiet) {        System.out.println();    }}
0
protected Location resolveLocation(String input, FileSystem fs)
{    return LocationStrategy.getLocation(input, fs);}
0
public void extractLineByLine(List<String> inputs, FileSystem fs, ThreadLocal<STATE_T> state, int batchSize, int numThreads, boolean quiet) throws IOException
{    inputs.stream().map(input -> resolveLocation(input, fs)).forEach(loc -> {        final Progress progress = new Progress();        if (!quiet) {            System.out.println("\nProcessing " + loc.toString());        }        try (Stream<String> stream = ReaderSpliterator.lineStream(loc.openReader(), batchSize)) {            ForkJoinPool forkJoinPool = new ForkJoinPool(numThreads);            forkJoinPool.submit(() -> stream.parallel().forEach(input -> {                try {                    extract(state.get(), input);                    if (!quiet) {                        progress.update();                    }                } catch (IOException e) {                    throw new IllegalStateException("Unable to continue: " + e.getMessage(), e);                }            })).get();        } catch (Exception e) {            throw new IllegalStateException(e.getMessage(), e);        }    });}
0
public void extractWholeFiles(List<String> inputs, FileSystem fs, ThreadLocal<STATE_T> state, boolean quiet) throws IOException
{    final Progress progress = new Progress();    final List<Location> locations = getLocationsRecursive(inputs, fs);    locations.parallelStream().forEach(loc -> {        try (BufferedReader br = loc.openReader()) {            String s = br.lines().collect(Collectors.joining());            extract(state.get(), s);            if (!quiet) {                progress.update();            }        } catch (IOException e) {            throw new IllegalStateException("Unable to read " + loc + ": " + e.getMessage(), e);        }    });}
0
protected List<Location> getLocationsRecursive(List<String> inputs, FileSystem fs) throws IOException
{    final List<Location> locations = new ArrayList<>();    Location.fileVisitor(inputs, loc -> locations.add(loc), fs);    return locations;}
0
public synchronized void update()
{    int currentCount = count++;    System.out.print("\rProcessed " + currentCount + " - " + anim.charAt(currentCount % anim.length()));}
0
protected void assertOption(EnumMap<OPTIONS_T, Optional<Object>> config, OPTIONS_T option)
{    if (!config.containsKey(option)) {        throw new IllegalStateException("Expected " + option.getOption().getOpt() + " to be set");    }}
0
public Importer getImporter()
{    return importer;}
0
public static Optional<ImportStrategy> getStrategy(String strategyName)
{    if (strategyName == null) {        return Optional.empty();    }    for (ImportStrategy strategy : values()) {        if (strategy.name().equalsIgnoreCase(strategyName.trim())) {            return Optional.of(strategy);        }    }    return Optional.empty();}
0
protected List<String> getInputs(EnumMap<LoadOptions, Optional<Object>> config)
{    return (List<String>) config.get(LoadOptions.INPUT).get();}
0
protected boolean isQuiet(EnumMap<LoadOptions, Optional<Object>> config)
{    return (boolean) config.get(LoadOptions.QUIET).get();}
0
protected int batchSize(EnumMap<LoadOptions, Optional<Object>> config)
{    return (int) config.get(LoadOptions.BATCH_SIZE).get();}
0
protected int numThreads(EnumMap<LoadOptions, Optional<Object>> config, ExtractorHandler handler)
{    return (int) config.get(LoadOptions.NUM_THREADS).get();}
0
protected void validateState(EnumMap<LoadOptions, Optional<Object>> config, ExtractorHandler handler)
{    assertOption(config, LoadOptions.HBASE_CF);    assertOption(config, LoadOptions.HBASE_TABLE);}
0
protected ThreadLocal<HBaseExtractorState> createState(EnumMap<LoadOptions, Optional<Object>> config, Configuration hadoopConfig, final ExtractorHandler handler)
{    ThreadLocal<HBaseExtractorState> state = new ThreadLocal<HBaseExtractorState>() {        @Override        protected HBaseExtractorState initialValue() {            try {                String cf = (String) config.get(LoadOptions.HBASE_CF).get();                Table table = provider.retrieve().getTable(hadoopConfig, (String) config.get(LoadOptions.HBASE_TABLE).get());                return new HBaseExtractorState(table, cf, handler.getExtractor(), new EnrichmentConverter(), hadoopConfig);            } catch (IOException e1) {                throw new IllegalStateException("Unable to get table: " + e1);            }        }    };    return state;}
0
protected HBaseExtractorState initialValue()
{    try {        String cf = (String) config.get(LoadOptions.HBASE_CF).get();        Table table = provider.retrieve().getTable(hadoopConfig, (String) config.get(LoadOptions.HBASE_TABLE).get());        return new HBaseExtractorState(table, cf, handler.getExtractor(), new EnrichmentConverter(), hadoopConfig);    } catch (IOException e1) {        throw new IllegalStateException("Unable to get table: " + e1);    }}
0
protected void extract(HBaseExtractorState state, String line) throws IOException
{    HBaseExtractorState es = state;    es.getTable().put(toPut(line, es.getExtractor(), state.getCf(), es.getConverter()));}
0
public List<Put> toPut(String line, Extractor extractor, String cf, HbaseConverter converter) throws IOException
{    List<Put> ret = new ArrayList<>();    Iterable<LookupKV> kvs = extractor.extract(line);    for (LookupKV kv : kvs) {        Put put = converter.toPut(cf, kv.getKey(), kv.getValue());        ret.add(put);    }    return ret;}
0
public AtomicReference<Object> getState()
{    return state;}
0
public StatefulExtractor getExtractor()
{    return extractor;}
0
protected boolean isQuiet(EnumMap<SummarizeOptions, Optional<Object>> config)
{    return (boolean) config.getOrDefault(SummarizeOptions.QUIET, Optional.of(false)).get();}
0
protected int batchSize(EnumMap<SummarizeOptions, Optional<Object>> config)
{    return (int) config.getOrDefault(SummarizeOptions.BATCH_SIZE, Optional.of(1)).get();}
0
protected int numThreads(EnumMap<SummarizeOptions, Optional<Object>> config, ExtractorHandler handler)
{    if (handler.getExtractor().getCapabilities().contains(ExtractorCapabilities.MERGEABLE)) {        return (int) config.get(SummarizeOptions.NUM_THREADS).get();    } else {                return 1;    }}
0
protected void validateState(EnumMap<SummarizeOptions, Optional<Object>> config, ExtractorHandler handler)
{    if (!(handler.getExtractor() instanceof StatefulExtractor)) {        throw new IllegalStateException("Extractor must be a stateful extractor and " + handler.getExtractor().getClass().getName() + " is not.");    }    assertOption(config, SummarizeOptions.OUTPUT);    if (!handler.getExtractor().getCapabilities().contains(ExtractorCapabilities.STATEFUL)) {        throw new IllegalStateException("Unable to operate on a non-stateful extractor.  " + "If you have not specified \"stateUpdate\" in your Extractor config, there is nothing to do here and nothing will be written.");    }}
0
protected ThreadLocal<SummarizationState> createState(EnumMap<SummarizeOptions, Optional<Object>> config, Configuration hadoopConfig, ExtractorHandler handler)
{    final StatefulExtractor extractor = (StatefulExtractor) handler.getExtractor();    return ThreadLocal.withInitial(() -> {        Object initState = extractor.initializeState(handler.getConfig());        SummarizationState ret = new SummarizationState(extractor, initState);        stateList.add(ret);        return ret;    });}
0
protected void extract(SummarizationState state, String line) throws IOException
{    state.getExtractor().extract(line, state.getState());}
0
public void importData(EnumMap<SummarizeOptions, Optional<Object>> config, ExtractorHandler handler, Configuration hadoopConfig) throws IOException, InvalidWriterOutput
{    Writer writer = (Writer) config.get(SummarizeOptions.OUTPUT_MODE).get();    Optional<String> fileName = Optional.ofNullable((String) config.get(SummarizeOptions.OUTPUT).orElse(null));    writer.validate(fileName, hadoopConfig);    super.importData(config, handler, hadoopConfig);    StatefulExtractor extractor = (StatefulExtractor) handler.getExtractor();    Object finalState = null;    if (stateList.size() == 1) {        finalState = stateList.get(0).getState().get();    } else if (stateList.size() > 1) {        List<Object> states = new ArrayList<>();        for (SummarizationState s : stateList) {            states.add(s.getState().get());        }        finalState = extractor.mergeStates(states);    }    writer.write(finalState, fileName, hadoopConfig);}
0
protected List<String> getInputs(EnumMap<SummarizeOptions, Optional<Object>> config)
{    Object o = config.get(SummarizeOptions.INPUT).get();    if (o == null) {        return new ArrayList<>();    }    if (o instanceof String) {        return ImmutableList.of((String) o);    }    return (List<String>) config.get(SummarizeOptions.INPUT).get();}
0
public void importData(EnumMap<LoadOptions, Optional<Object>> config, ExtractorHandler handler, Configuration hadoopConfig) throws IOException
{    String table = (String) config.get(LoadOptions.HBASE_TABLE).get();    String cf = (String) config.get(LoadOptions.HBASE_CF).get();    String extractorConfigContents = (String) config.get(LoadOptions.EXTRACTOR_CONFIG).get();    Job job = Job.getInstance(hadoopConfig);    List<String> inputs = (List<String>) config.get(LoadOptions.INPUT).get();    job.setJobName("MapReduceImporter: " + inputs.stream().collect(Collectors.joining(",")) + " => " + table + ":" + cf);        job.setJarByClass(MapReduceImporter.class);    job.setMapperClass(org.apache.metron.dataloads.hbase.mr.BulkLoadMapper.class);    job.setOutputFormatClass(TableOutputFormat.class);    job.getConfiguration().set(TableOutputFormat.OUTPUT_TABLE, table);    job.getConfiguration().set(BulkLoadMapper.COLUMN_FAMILY_KEY, cf);    job.getConfiguration().set(BulkLoadMapper.CONFIG_KEY, extractorConfigContents);    job.getConfiguration().set(BulkLoadMapper.CONVERTER_KEY, EnrichmentConverter.class.getName());    job.setOutputKeyClass(ImmutableBytesWritable.class);    job.setOutputValueClass(Put.class);    job.setNumReduceTasks(0);    List<Path> paths = inputs.stream().map(p -> new Path(p)).collect(Collectors.toList());    handler.getInputFormat().set(job, paths, handler.getConfig());    TableMapReduceUtil.initCredentials(job);    try {        job.waitForCompletion(true);    } catch (Exception e) {        throw new IllegalStateException("Unable to complete job: " + e.getMessage(), e);    }}
1
public Importer getSummarizer()
{    return importer;}
0
public static Optional<Summarizers> getStrategy(String strategyName)
{    if (strategyName == null) {        return Optional.empty();    }    for (Summarizers strategy : values()) {        if (strategy.name().equalsIgnoreCase(strategyName.trim())) {            return Optional.of(strategy);        }    }    return Optional.empty();}
0
public OptionHandler<LoadOptions> getHandler()
{    return handler;}
0
public Option getOption()
{    return option;}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    return OptionHandler.parse("SimpleEnrichmentFlatFileLoader", parser, args, values(), HELP);}
0
public static EnumMap<LoadOptions, Optional<Object>> createConfig(CommandLine cli)
{    return OptionHandler.createConfig(cli, values(), LoadOptions.class);}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "hbase_table", true, "HBase table to ingest the data into.");    o.setArgName("TABLE");    o.setRequired(true);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public String getShortCode()
{    return "t";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "hbase_cf", true, "HBase column family to ingest the data into.");    o.setArgName("CF");    o.setRequired(true);    return o;}
0
public Optional<Object> getValue(LoadOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public String getShortCode()
{    return "c";}
0
public String getShortCode()
{    return "n";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "enrichment_config", true, "JSON Document describing the enrichment configuration details." + "  This is used to associate an enrichment type with a field type in zookeeper.");    o.setArgName("JSON_FILE");    o.setRequired(false);    return o;}
0
public Optional<List<String>> list(String loc)
{    List<String> children = new ArrayList<>();    for (File f : new File(loc).listFiles()) {        children.add(f.getPath());    }    return Optional.of(children);}
0
public boolean exists(String loc) throws IOException
{    return new File(loc).exists();}
0
public boolean isDirectory(String loc) throws IOException
{    return new File(loc).isDirectory();}
0
public InputStream openInputStream(String loc) throws IOException
{    return new FileInputStream(loc);}
0
public boolean match(String loc)
{    return new File(loc).exists();}
0
public Optional<List<String>> list(String loc) throws IOException
{    List<String> children = new ArrayList<>();    for (FileStatus f : fs.listStatus(new Path(loc))) {        children.add(f.getPath().toString());    }    return Optional.of(children);}
0
public boolean exists(String loc) throws IOException
{    return fs.exists(new Path(loc));}
0
public boolean isDirectory(String loc) throws IOException
{    return fs.isDirectory(new Path(loc));}
0
public InputStream openInputStream(String loc) throws IOException
{    return fs.open(new Path(loc));}
0
public boolean match(String loc)
{    try {        return loc.startsWith("hdfs://") && exists(loc);    } catch (IOException e) {        return false;    }}
0
public void init(FileSystem state)
{    this.fs = state;}
0
public RawLocation<?> getRawLocation()
{    return rawLocation;}
0
public Optional<List<Location>> getChildren() throws IOException
{    if (exists() && isDirectory()) {        List<Location> children = new ArrayList<>();        for (String child : rawLocation.list(loc).orElse(new ArrayList<>())) {            children.add(new Location(child, rawLocation));        }        return Optional.of(children);    } else {        return Optional.empty();    }}
0
public boolean exists() throws IOException
{    return rawLocation.exists(loc);}
0
public boolean isDirectory() throws IOException
{    return rawLocation.isDirectory(loc);}
0
public BufferedReader openReader() throws IOException
{    return rawLocation.openReader(loc);}
0
public String toString()
{    return loc;}
0
public static void fileVisitor(List<String> inputs, final Consumer<Location> importConsumer, final FileSystem fs) throws IOException
{    Stack<Location> stack = new Stack<>();    for (String input : inputs) {        Location loc = LocationStrategy.getLocation(input, fs);        if (loc.exists()) {            stack.add(loc);        }    }    while (!stack.empty()) {        Location loc = stack.pop();        if (loc.isDirectory()) {            for (Location child : loc.getChildren().orElse(Collections.emptyList())) {                stack.push(child);            }        } else {            importConsumer.accept(loc);        }    }}
0
public static Optional<RawLocation<?>> getRawLocation(String loc, FileSystem fs)
{    for (LocationStrategy strategy : values()) {        RawLocation<?> location = strategy.locationCreator.apply(fs);        if (location.match(loc)) {            return Optional.of(location);        }    }    return Optional.empty();}
0
public static Location getLocation(String loc, FileSystem fs)
{    Optional<RawLocation<?>> rawLoc = getRawLocation(loc, fs);    if (rawLoc.isPresent()) {        return new Location(loc, rawLoc.get());    } else {        throw new IllegalStateException("Unsupported type: " + loc);    }}
0
 void init(T state)
{}
0
 BufferedReader openReader(String loc) throws IOException
{    InputStream is = openInputStream(loc);    if (loc.endsWith(".gz")) {        return new BufferedReader(new InputStreamReader(new GZIPInputStream(is), StandardCharsets.UTF_8));    } else if (loc.endsWith(".zip")) {        ZipInputStream zis = new ZipInputStream(is);        ZipEntry entry = zis.getNextEntry();        if (entry != null) {            return new BufferedReader(new InputStreamReader(zis, StandardCharsets.UTF_8));        } else {            return new BufferedReader(new InputStreamReader(new ByteArrayInputStream(new byte[] {}), StandardCharsets.UTF_8));        }    } else {        return new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8));    }}
0
public Optional<List<String>> list(String loc) throws IOException
{    return Optional.of(Collections.emptyList());}
0
public boolean exists(String loc) throws IOException
{    return true;}
0
public boolean isDirectory(String loc) throws IOException
{    return false;}
0
public InputStream openInputStream(String loc) throws IOException
{    return new URL(loc).openConnection().getInputStream();}
0
public boolean match(String loc)
{    try {        new URL(loc);        return true;    } catch (MalformedURLException e) {        return false;    }}
0
public static void main(String... argv) throws Exception
{    Configuration hadoopConfig = HBaseConfiguration.create();    String[] otherArgs = new GenericOptionsParser(hadoopConfig, argv).getRemainingArgs();    main(hadoopConfig, otherArgs);}
0
public static void main(Configuration hadoopConfig, String[] argv) throws Exception
{    CommandLine cli = LoadOptions.parse(new PosixParser(), argv);    EnumMap<LoadOptions, Optional<Object>> config = LoadOptions.createConfig(cli);    if (LoadOptions.LOG4J_PROPERTIES.has(cli)) {        PropertyConfigurator.configure(LoadOptions.LOG4J_PROPERTIES.get(cli));    }    ExtractorHandler handler = ExtractorHandler.load(FileUtils.readFileToString(new File(LoadOptions.EXTRACTOR_CONFIG.get(cli).trim())));    ImportStrategy strategy = (ImportStrategy) config.get(LoadOptions.IMPORT_MODE).get();    strategy.getImporter().importData(config, handler, hadoopConfig);    SensorEnrichmentUpdateConfig sensorEnrichmentUpdateConfig = null;    if (LoadOptions.ENRICHMENT_CONFIG.has(cli)) {        sensorEnrichmentUpdateConfig = JSONUtils.INSTANCE.load(new File(LoadOptions.ENRICHMENT_CONFIG.get(cli)), SensorEnrichmentUpdateConfig.class);    }    if (sensorEnrichmentUpdateConfig != null) {        sensorEnrichmentUpdateConfig.updateSensorConfigs();    }}
0
public static void main(String... argv) throws Exception
{    Configuration hadoopConfig = HBaseConfiguration.create();    String[] otherArgs = new GenericOptionsParser(hadoopConfig, argv).getRemainingArgs();    main(hadoopConfig, otherArgs);}
0
public static void main(Configuration hadoopConfig, String[] argv) throws Exception
{    CommandLine cli = SummarizeOptions.parse(new PosixParser(), argv);    EnumMap<SummarizeOptions, Optional<Object>> config = SummarizeOptions.createConfig(cli);    if (SummarizeOptions.LOG4J_PROPERTIES.has(cli)) {        PropertyConfigurator.configure(SummarizeOptions.LOG4J_PROPERTIES.get(cli));    }    ExtractorHandler handler = ExtractorHandler.load(FileUtils.readFileToString(new File(SummarizeOptions.EXTRACTOR_CONFIG.get(cli).trim())));    Summarizers strategy = (Summarizers) config.get(SummarizeOptions.IMPORT_MODE).get();    strategy.getSummarizer().importData(config, handler, hadoopConfig);}
0
public OptionHandler<SummarizeOptions> getHandler()
{    return handler;}
0
public Option getOption()
{    return option;}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    return OptionHandler.parse("SimpleFlatFileSummarizer", parser, args, values(), HELP);}
0
public static EnumMap<SummarizeOptions, Optional<Object>> createConfig(CommandLine cli)
{    return OptionHandler.createConfig(cli, values(), SummarizeOptions.class);}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "output_mode", true, "The output mode to use: " + Joiner.on(",").join(Writers.values()) + ".  Default: " + Writers.LOCAL);    o.setArgName("MODE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(SummarizeOptions option, CommandLine cli)
{    String mode = option.get(cli);    return Optional.of(Writers.getStrategy(mode).orElse(Writers.LOCAL));}
0
public String getShortCode()
{    return "om";}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "output", true, "The output file to write");    o.setArgName("FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(SummarizeOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli));}
0
public String getShortCode()
{    return "o";}
0
public void validate(Optional<String> output, Configuration hadoopConfig)
{}
0
public void write(Object obj, Optional<String> output, Configuration hadoopConfig) throws IOException
{    System.out.println(obj);}
0
public void write(byte[] obj, Optional<String> output, Configuration hadoopConfig) throws IOException
{    System.out.println(SerDeUtils.fromBytes(obj, Object.class));}
0
public void validate(Optional<String> fileNameOptional, Configuration hadoopConfig) throws InvalidWriterOutput
{    if (!fileNameOptional.isPresent()) {        throw new InvalidWriterOutput("Filename is not present.");    }    String fileName = fileNameOptional.get();    if (StringUtils.isEmpty(fileName) || fileName.trim().equals(".") || fileName.trim().equals("..") || fileName.trim().endsWith("/")) {        throw new InvalidWriterOutput("Filename is empty or otherwise invalid.");    }}
0
public void write(byte[] obj, Optional<String> output, Configuration hadoopConfig) throws IOException
{    FileSystem fs = FileSystem.get(hadoopConfig);    try (FSDataOutputStream stream = fs.create(new Path(output.get()))) {        IOUtils.write(obj, stream);        stream.flush();    }}
0
public void validate(Optional<String> fileNameOptional, Configuration hadoopConfig) throws InvalidWriterOutput
{    if (!fileNameOptional.isPresent()) {        throw new InvalidWriterOutput("Filename is not present.");    }    String fileName = fileNameOptional.get();    if (StringUtils.isEmpty(fileName) || fileName.trim().equals(".") || fileName.trim().equals("..") || fileName.trim().endsWith("/")) {        throw new InvalidWriterOutput("Filename is empty or otherwise invalid.");    }}
0
public void write(byte[] obj, Optional<String> output, Configuration hadoopConfig) throws IOException
{    File outFile = new File(output.get());    if (!outFile.getParentFile().exists()) {        outFile.getParentFile().mkdirs();    }    try (FileOutputStream fs = new FileOutputStream(outFile)) {        IOUtils.write(obj, fs);        fs.flush();    }}
0
 void write(Object obj, Optional<String> output, Configuration hadoopConfig) throws IOException
{    if (obj != null) {        write(SerDeUtils.toBytes(obj), output, hadoopConfig);    }}
0
public static Optional<Writers> getStrategy(String strategyName)
{    if (strategyName == null) {        return Optional.empty();    }    for (Writers strategy : values()) {        if (strategy.name().equalsIgnoreCase(strategyName.trim())) {            return Optional.of(strategy);        }    }    return Optional.empty();}
0
public void validate(Optional<String> output, Configuration hadoopConf) throws InvalidWriterOutput
{    writer.validate(output, hadoopConf);}
0
public void write(byte[] obj, Optional<String> output, Configuration hadoopConf) throws IOException
{    writer.write(obj, output, hadoopConf);}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public String get(CommandLine cli, String defaultValue)
{    return cli.getOptionValue(shortCode, defaultValue);}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("MaxmindDbEnrichmentLoader", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (MaxmindDbEnrichmentLoader.GeoEnrichmentOptions o : MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public Option apply(@Nullable String s)
{    return new Option(s, "help", false, "Generate Help screen");}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "asn_url", true, "GeoIP URL - " + ASN_URL_DEFAULT);    o.setArgName("ASN_URL");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "geo_url", true, "GeoIP URL - defaults to " + GEO_CITY_URL_DEFAULT);    o.setArgName("GEO_URL");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "remote_dir", true, "HDFS directory to land formatted GeoLite2 City file - defaults to /apps/metron/geo/<epoch millis>/");    o.setArgName("REMOTE_DIR");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "remote_asn_dir", true, "HDFS directory to land formatted GeoLite2 ASN file - defaults to /apps/metron/asn/<epoch millis>/");    o.setArgName("REMOTE_DIR");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "retries", true, "Number of GeoLite2 database download retries, after an initial failure.");    o.setArgName("RETRIES");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "tmp_dir", true, "Directory for landing the temporary GeoLite2 data - defaults to /tmp");    o.setArgName("TMP_DIR");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "zk_quorum", true, "Zookeeper Quorum URL (zk1:port,zk2:port,...)");    o.setArgName("ZK_QUORUM");    o.setRequired(true);    return o;}
0
protected void loadGeoLiteDatabase(CommandLine cli) throws IOException
{        System.out.println("Retrieving GeoLite2 archive");    String geo_url = GeoEnrichmentOptions.GEO_URL.get(cli, GEO_CITY_URL_DEFAULT);    String asn_url = GeoEnrichmentOptions.ASN_URL.get(cli, ASN_URL_DEFAULT);        String tmpDir = GeoEnrichmentOptions.TMP_DIR.get(cli, "/tmp") + "/";    int numRetries = Integer.parseInt(GeoEnrichmentOptions.RETRIES.get(cli, DEFAULT_RETRIES));    File localGeoFile = null;    File localAsnFile = null;    try {        localGeoFile = downloadGeoFile(geo_url, tmpDir, numRetries);        localAsnFile = downloadGeoFile(asn_url, tmpDir, numRetries);    } catch (IllegalStateException ies) {        System.err.println("Failed to download geo db file. Aborting");        System.exit(5);    }        localGeoFile.deleteOnExit();    localAsnFile.deleteOnExit();    System.out.println("GeoIP files downloaded successfully");        String zookeeper = GeoEnrichmentOptions.ZK_QUORUM.get(cli);    long millis = LocalDateTime.now().toInstant(ZoneOffset.UTC).toEpochMilli();    String hdfsGeoLoc = GeoEnrichmentOptions.REMOTE_GEO_DIR.get(cli, "/apps/metron/geo/" + millis);    System.out.println("Putting GeoLite City file into HDFS at: " + hdfsGeoLoc);        Path srcPath = new Path(localGeoFile.getAbsolutePath());    Path dstPath = new Path(hdfsGeoLoc);    putDbFile(srcPath, dstPath);    pushConfig(srcPath, dstPath, GeoLiteCityDatabase.GEO_HDFS_FILE, zookeeper);        String hdfsAsnLoc = GeoEnrichmentOptions.REMOTE_ASN_DIR.get(cli, "/apps/metron/asn/" + millis);    System.out.println("Putting ASN file into HDFS at: " + hdfsAsnLoc);        srcPath = new Path(localAsnFile.getAbsolutePath());    dstPath = new Path(hdfsAsnLoc);    putDbFile(srcPath, dstPath);    pushConfig(srcPath, dstPath, GeoLiteAsnDatabase.ASN_HDFS_FILE, zookeeper);    System.out.println("GeoLite2 file placement complete");    System.out.println("Successfully created and updated new GeoLite information");}
0
protected File downloadGeoFile(String urlStr, String tmpDir, int numRetries)
{    File localFile = null;    int attempts = 0;    boolean valid = false;    while (!valid && attempts <= numRetries) {        try {            URL url = new URL(urlStr);            localFile = new File(tmpDir + new File(url.getPath()).getName());            System.out.println("Downloading " + url.toString() + " to " + localFile.getAbsolutePath());            if (localFile.exists() && !localFile.delete()) {                System.err.println("File already exists locally and can't be deleted.  Please delete before continuing");                System.exit(3);            }            FileUtils.copyURLToFile(url, localFile, 5000, 10000);            if (!CompressionStrategies.GZIP.test(localFile)) {                throw new IOException("Invalid Gzip file");            } else {                valid = true;            }        } catch (MalformedURLException e) {            System.err.println("Malformed URL - aborting: " + e);            e.printStackTrace();            System.exit(4);        } catch (IOException e) {            System.err.println("Warning: Unable to copy remote GeoIP database to local file, attempt " + attempts + ": " + e);            e.printStackTrace();        }        attempts++;    }    if (!valid) {        System.err.println("Unable to copy remote GeoIP database to local file after " + attempts + " attempts");        throw new IllegalStateException("Unable to download geo enrichment database.");    }    return localFile;}
0
protected void pushConfig(Path srcPath, Path dstPath, String configName, String zookeeper)
{    System.out.println("Beginning update of global configs");    try (CuratorFramework client = ConfigurationsUtils.getClient(zookeeper)) {        client.start();                        Map<String, Object> global = JSONUtils.INSTANCE.load(new ByteArrayInputStream(ConfigurationsUtils.readGlobalConfigBytesFromZookeeper(client)), JSONUtils.MAP_SUPPLIER);                global.put(configName, dstPath.toString() + "/" + srcPath.getName());        ConfigurationsUtils.writeGlobalConfigToZookeeper(global, client);    } catch (Exception e) {        System.err.println("Unable to load new GeoLite2 config for " + configName + " into HDFS: " + e);        e.printStackTrace();        System.exit(2);    }    System.out.println("Finished update of global configs");}
0
protected void putDbFile(Path src, Path dst) throws IOException
{    Configuration conf = new Configuration();    FileSystem fileSystem = FileSystem.get(conf);    System.out.println("Putting: " + src + " onto HDFS at: " + dst);    fileSystem.mkdirs(dst);    fileSystem.copyFromLocalFile(true, true, src, dst);    System.out.println("Done putting GeoLite file into HDFS");}
0
public static void main(String... argv) throws IOException
{    String[] otherArgs = new GenericOptionsParser(argv).getRemainingArgs();    CommandLine cli = GeoEnrichmentOptions.parse(new PosixParser(), otherArgs);    MaxmindDbEnrichmentLoader loader = new MaxmindDbEnrichmentLoader();    loader.loadGeoLiteDatabase(cli);}
0
public String getTableName()
{    return tableName;}
0
public String getColumnFamily()
{    return columnFamily;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    TableInfo tableInfo = (TableInfo) o;    if (getTableName() != null ? !getTableName().equals(tableInfo.getTableName()) : tableInfo.getTableName() != null)        return false;    return getColumnFamily() != null ? getColumnFamily().equals(tableInfo.getColumnFamily()) : tableInfo.getColumnFamily() == null;}
0
public int hashCode()
{    int result = getTableName() != null ? getTableName().hashCode() : 0;    result = 31 * result + (getColumnFamily() != null ? getColumnFamily().hashCode() : 0);    return result;}
0
public String toString()
{    return "TableInfo{" + "tableName='" + tableName + '\'' + ", columnFamily='" + columnFamily + '\'' + '}';}
0
public TaxiiConnectionConfig withAllowedIndicatorTypes(List<String> indicatorTypes)
{    allowedIndicatorTypes = new HashSet(indicatorTypes);    return this;}
0
public TaxiiConnectionConfig withTable(String table)
{    this.table = table;    return this;}
0
public TaxiiConnectionConfig withColumnFamily(String cf)
{    this.columnFamily = cf;    return this;}
0
public TaxiiConnectionConfig withBeginTime(Date time)
{    this.beginTime = time;    return this;}
0
public TaxiiConnectionConfig withSubscriptionId(String subId)
{    this.subscriptionId = subId;    return this;}
0
public TaxiiConnectionConfig withCollection(String collection)
{    this.collection = collection;    return this;}
0
public TaxiiConnectionConfig withPort(int port)
{    this.port = port;    return this;}
0
public TaxiiConnectionConfig withEndpoint(URL endpoint)
{    this.endpoint = endpoint;    return this;}
0
public TaxiiConnectionConfig withProxy(URL proxy)
{    this.proxy = proxy;    return this;}
0
public TaxiiConnectionConfig withUsername(String username)
{    this.username = username;    return this;}
0
public TaxiiConnectionConfig withPassword(String password)
{    this.password = password;    return this;}
0
public TaxiiConnectionConfig withConnectionType(ConnectionType type)
{    this.type = type;    return this;}
0
public void setEndpoint(String endpoint) throws MalformedURLException
{    this.endpoint = new URL(endpoint);}
0
public void setPort(int port)
{    this.port = port;}
0
public void setProxy(String proxy) throws MalformedURLException
{    this.proxy = new URL(proxy);}
0
public void setUsername(String username)
{    this.username = username;}
0
public void setPassword(String password)
{    this.password = password;}
0
public void setType(ConnectionType type)
{    this.type = type;}
0
public void setCollection(String collection)
{    this.collection = collection;}
0
public void setSubscriptionId(String subscriptionId)
{    this.subscriptionId = subscriptionId;}
0
public void setBeginTime(String beginTime) throws ParseException
{    SimpleDateFormat sdf = (SimpleDateFormat) DateFormat.getDateInstance(DateFormat.MEDIUM);    this.beginTime = sdf.parse(beginTime);}
0
public String getTable()
{    return table;}
0
public void setTable(String table)
{    this.table = table;}
0
public String getColumnFamily()
{    return columnFamily;}
0
public void setColumnFamily(String columnFamily)
{    this.columnFamily = columnFamily;}
0
public Date getBeginTime()
{    return beginTime;}
0
public int getPort()
{    return port;}
0
public URL getEndpoint()
{    return endpoint;}
0
public URL getProxy()
{    return proxy;}
0
public String getUsername()
{    return username;}
0
public String getPassword()
{    return password;}
0
public ConnectionType getType()
{    return type;}
0
public String getCollection()
{    return collection;}
0
public String getSubscriptionId()
{    return subscriptionId;}
0
public void setAllowedIndicatorTypes(List<String> allowedIndicatorTypes)
{    withAllowedIndicatorTypes(allowedIndicatorTypes);}
0
public Set<String> getAllowedIndicatorTypes()
{    return allowedIndicatorTypes;}
0
public static synchronized TaxiiConnectionConfig load(InputStream is) throws IOException
{    TaxiiConnectionConfig ret = _mapper.readValue(is, TaxiiConnectionConfig.class);    return ret;}
0
public static synchronized TaxiiConnectionConfig load(String s, Charset c) throws IOException
{    return load(new ByteArrayInputStream(s.getBytes(c)));}
0
public static synchronized TaxiiConnectionConfig load(String s) throws IOException
{    return load(s, Charset.defaultCharset());}
0
public String toString()
{    return "TaxiiConnectionConfig{" + "endpoint=" + endpoint + ", port=" + port + ", proxy=" + proxy + ", username='" + username + '\'' + ", password=" + (password == null ? "null" : "'******'") + ", type=" + type + ", allowedIndicatorTypes=" + Joiner.on(',').join(allowedIndicatorTypes) + ", collection='" + collection + '\'' + ", subscriptionId='" + subscriptionId + '\'' + ", beginTime=" + beginTime + ", table=" + table + ":" + columnFamily + '}';}
0
protected TaxiiXmlFactory initialValue()
{    return new TaxiiXmlFactory();}
0
protected ObjectFactory initialValue()
{    return new ObjectFactory();}
0
protected synchronized Table getTable(String table) throws IOException
{    Table ret = connectionCache.get(table);    if (ret == null) {        ret = createHTable(table);        connectionCache.put(table, ret);    }    return ret;}
0
protected synchronized Table createHTable(String tableInfo) throws IOException
{    return new HTableProvider().getTable(config, tableInfo);}
0
public void run()
{    if (inProgress) {        return;    }    Date ts = new Date();        try {        inProgress = true;                String sessionID = MessageHelper.generateMessageId();        PollRequest request = messageFactory.get().createPollRequest().withMessageId(sessionID).withCollectionName(collection);        if (subscriptionId != null) {            request = request.withSubscriptionID(subscriptionId);        } else {            request = request.withPollParameters(messageFactory.get().createPollParametersType());        }        if (beginTime != null) {            Calendar gc = GregorianCalendar.getInstance();            gc.setTime(beginTime);            XMLGregorianCalendar gTime = null;            try {                gTime = DatatypeFactory.newInstance().newXMLGregorianCalendar((GregorianCalendar) gc).normalize();            } catch (DatatypeConfigurationException e) {                RuntimeErrors.ILLEGAL_STATE.throwRuntime("Unable to set the begin time due to", e);            }            gTime.setFractionalSecond(null);                        request.setExclusiveBeginTimestamp(gTime);        }        try {            PollResponse response = call(request, PollResponse.class);                        int numProcessed = 0;            long avgTimeMS = 0;            long timeStartedBlock = System.currentTimeMillis();            for (ContentBlock block : response.getContentBlocks()) {                AnyMixedContentType content = block.getContent();                for (Object o : content.getContent()) {                    numProcessed++;                    long timeS = System.currentTimeMillis();                    String xml = null;                    if (o instanceof Element) {                        Element element = (Element) o;                        xml = getStringFromDocument(element.getOwnerDocument());                        if (LOG.isDebugEnabled() && Math.random() < 0.01) {                                                    }                        for (LookupKV<EnrichmentKey, EnrichmentValue> kv : extractor.extract(xml)) {                            if (allowedIndicatorTypes.isEmpty() || allowedIndicatorTypes.contains(kv.getKey().type)) {                                kv.getValue().getMetadata().put("source_type", "taxii");                                kv.getValue().getMetadata().put("taxii_url", endpoint.toString());                                kv.getValue().getMetadata().put("taxii_collection", collection);                                Put p = converter.toPut(columnFamily, kv.getKey(), kv.getValue());                                Table table = getTable(hbaseTable);                                table.put(p);                                                            }                        }                    }                    avgTimeMS += System.currentTimeMillis() - timeS;                }                if ((numProcessed + 1) % 100 == 0) {                                        timeStartedBlock = System.currentTimeMillis();                    avgTimeMS = 0;                    numProcessed = 0;                }            }        } catch (Exception e) {                        throw new RuntimeException("Unable to make request", e);        }    } finally {        inProgress = false;        beginTime = ts;    }}
1
public String getStringFromDocument(Document doc)
{    try {        DOMSource domSource = new DOMSource(doc);        StringWriter writer = new StringWriter();        StreamResult result = new StreamResult(writer);        TransformerFactory tf = TransformerFactory.newInstance();        tf.setFeature(XMLConstants.FEATURE_SECURE_PROCESSING, true);        Transformer transformer = tf.newTransformer();        transformer.transform(domSource, result);        return writer.toString();    } catch (TransformerException ex) {        ex.printStackTrace();        return null;    }}
0
private RESPONSE_T call(Object request, Class<RESPONSE_T> responseClazz) throws Exception
{    HttpClient taxiiClient = buildClient(proxy, username, password);    return call(taxiiClient, endpoint.toURI(), request, context, responseClazz);}
0
private void initializeClient(TaxiiConnectionConfig config) throws Exception
{        if (context == null) {        context = createContext(config.getEndpoint(), config.getUsername(), config.getPassword(), config.getPort());    }    URL endpoint = config.getEndpoint();    if (config.getType() == ConnectionType.DISCOVER) {                endpoint = discoverPollingClient(config.getProxy(), endpoint, config.getUsername(), config.getPassword(), context, collection).pollEndpoint;        this.endpoint = endpoint;            }}
1
private static HttpClientContext createContext(URL endpoint, String username, String password, int port)
{    HttpClientContext context = null;    HttpHost target = new HttpHost(endpoint.getHost(), port, endpoint.getProtocol());    if (username != null && password != null) {        CredentialsProvider credsProvider = new BasicCredentialsProvider();        credsProvider.setCredentials(new AuthScope(target.getHostName(), target.getPort()), new UsernamePasswordCredentials(username, password));                AuthCache authCache = new BasicAuthCache();        authCache.put(target, new BasicScheme());                context = HttpClientContext.create();        context.setCredentialsProvider(credsProvider);        context.setAuthCache(authCache);    } else {        context = null;    }    return context;}
0
public static RESPONSE_T call(HttpClient taxiiClient, URI endpoint, REQUEST_T request, HttpClientContext context, Class<RESPONSE_T> responseClazz) throws JAXBException, IOException
{    Object responseObj = taxiiClient.callTaxiiService(endpoint, request, context);        try {        return responseClazz.cast(responseObj);    } catch (ClassCastException cce) {        TaxiiXml taxiiXml = xmlFactory.get().createTaxiiXml();        String resp = taxiiXml.marshalToString(responseObj, true);        String msg = "Didn't return the response we expected: " + responseObj.getClass() + " \n" + resp;                throw new RuntimeException(msg, cce);    }}
1
private static HttpClient buildClient(URL proxy, String username, String password) throws Exception
{        HttpClient client = new HttpClient();        HttpClientBuilder builder = HttpClientBuilder.create().useSystemProperties();        if (proxy != null) {        HttpHost proxyHost = new HttpHost(proxy.getHost(), proxy.getPort(), proxy.getProtocol());        builder.setProxy(proxyHost);    }        if (username != null ^ password != null) {        throw new Exception("'username' and 'password' arguments are required to appear together.");    }        SSLContextBuilder ssbldr = new SSLContextBuilder();    ssbldr.loadTrustMaterial(null, new TrustSelfSignedStrategy());    SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(ssbldr.build(), SSLConnectionSocketFactory.BROWSER_COMPATIBLE_HOSTNAME_VERIFIER);    Registry<ConnectionSocketFactory> registry = RegistryBuilder.<ConnectionSocketFactory>create().register("http", new PlainConnectionSocketFactory()).register("https", sslsf).build();    PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(registry);        cm.setMaxTotal(20);        System.setProperty("jsse.enableSNIExtension", "false");    CloseableHttpClient httpClient = builder.setSSLSocketFactory(sslsf).setConnectionManager(cm).build();    client.setHttpclient(httpClient);    return client;}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (TaxiiOptions.HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("TaxiiLoader", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (TaxiiOptions o : TaxiiOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public Option apply(@Nullable String s)
{    return new Option(s, "help", false, "Generate Help screen");}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "extractor_config", true, "JSON Document describing the extractor for this input data source");    o.setArgName("JSON_FILE");    o.setRequired(true);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "taxii_connection_config", true, "The JSON config file to configure the connection");    o.setArgName("config_file");    o.setRequired(true);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "time_between_polls", true, "The time between polls (in ms)");    o.setArgName("MS");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "begin_time", true, "Start time to poll the Taxii server (all data from that point will be gathered in the first pull).");    o.setArgName(DATE_FORMAT.toPattern());    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "log4j", true, "The log4j properties file to load");    o.setArgName("FILE");    o.setRequired(false);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "enrichment_config", true, "JSON Document describing the enrichment configuration details." + "  This is used to associate an enrichment type with a field type in zookeeper.");    o.setArgName("JSON_FILE");    o.setRequired(false);    return o;}
0
public static boolean isStixExtractor(Extractor e)
{    if (e instanceof StixExtractor || (e instanceof ExtractorDecorator && ((ExtractorDecorator) e).getUnderlyingExtractor() instanceof StixExtractor)) {        return true;    } else {        return false;    }}
0
public static void main(String... argv) throws Exception
{    Configuration conf = HBaseConfiguration.create();    String zkQuorum = conf.get(HConstants.ZOOKEEPER_QUORUM);    String[] otherArgs = new GenericOptionsParser(conf, argv).getRemainingArgs();    CommandLine cli = TaxiiOptions.parse(new PosixParser(), otherArgs);    if (TaxiiOptions.LOG4J_PROPERTIES.has(cli)) {        PropertyConfigurator.configure(TaxiiOptions.LOG4J_PROPERTIES.get(cli));    }    ExtractorHandler handler = ExtractorHandler.load(FileUtils.readFileToString(new File(TaxiiOptions.EXTRACTOR_CONFIG.get(cli))));    Extractor e = handler.getExtractor();    SensorEnrichmentUpdateConfig sensorEnrichmentUpdateConfig = null;    if (TaxiiOptions.ENRICHMENT_CONFIG.has(cli)) {        sensorEnrichmentUpdateConfig = JSONUtils.INSTANCE.load(new File(TaxiiOptions.ENRICHMENT_CONFIG.get(cli)), SensorEnrichmentUpdateConfig.class);        sensorEnrichmentUpdateConfig.updateSensorConfigs();    }    Timer timer = new Timer();    if (isStixExtractor(e)) {        Extractor extractor = e;        TaxiiConnectionConfig connectionConfig = TaxiiConnectionConfig.load(FileUtils.readFileToString(new File(TaxiiOptions.CONNECTION_CONFIG.get(cli))));        if (TaxiiOptions.BEGIN_TIME.has(cli)) {            Date d = DATE_FORMAT.parse(TaxiiOptions.BEGIN_TIME.get(cli));            connectionConfig.withBeginTime(d);        }        long timeBetween = DEFAULT_TIME_BETWEEN_POLLS;        if (TaxiiOptions.TIME_BETWEEN_POLLS.has(cli)) {            timeBetween = Long.parseLong(TaxiiOptions.TIME_BETWEEN_POLLS.get(cli));        }        timer.scheduleAtFixedRate(new TaxiiHandler(connectionConfig, extractor, conf), 0, timeBetween);    } else {        throw new IllegalStateException("Extractor must be a STIX Extractor");    }}
0
public static void beforeClass() throws Exception
{    if (dataPath.isDirectory()) {        dataPath.delete();    }    if (!dataPath.mkdirs()) {        throw new RuntimeException("Couldn't create dataPath at: " + dataPath.getAbsolutePath());    }    dataPath.deleteOnExit();}
0
public void setUp() throws Exception
{    Calendar today = Calendar.getInstance();    today.clear(Calendar.HOUR);    today.clear(Calendar.MINUTE);    today.clear(Calendar.SECOND);    todaysDate = today.getTime();    yesterday.setTime(todaysDate.getTime() - TimeUnit.DAYS.toMillis(1));}
0
public void testFailsOnTodaysDate() throws Exception
{    HDFSDataPruner pruner = new HDFSDataPruner(todaysDate, 30, "file:///", dataPath.getAbsolutePath() + "/file-*");}
0
public void testDeletesCorrectFiles() throws Exception
{    createTestFiles();    HDFSDataPruner pruner = new HDFSDataPruner(yesterday, 30, "file:///", dataPath.getAbsolutePath() + "/file-*");    Long prunedCount = pruner.prune();    assertTrue("Should have pruned 45 files- pruned: " + prunedCount, 45 == prunedCount);    File[] filesLeft = dataPath.listFiles();    File[] filesList = new File[filesLeft.length];    for (int i = 0; i < 5; i++) {        filesList[i] = new File(dataPath.getPath() + "//file-" + String.format("%02d", i));    }    Arrays.sort(filesLeft);    assertArrayEquals("First four files should have been left behind", filesLeft, filesList);}
0
public void testThrowsIsDirectory() throws Exception
{    FileSystem testFS = mock(FileSystem.class);    when(testFS.isDirectory(any())).thenThrow(new IOException("Test Exception"));    HDFSDataPruner pruner = new HDFSDataPruner(yesterday, 30, "file:///", dataPath.getAbsolutePath() + "/file-*");    pruner.fileSystem = testFS;    HDFSDataPruner.DateFileFilter filter = new HDFSDataPruner.DateFileFilter(pruner, true);    UnitTestHelper.setLog4jLevel(HDFSDataPruner.class, Level.FATAL);    try {        filter.accept(new Path("foo"));        Assert.fail("Expected Runtime exception, but did not receive one.");    } catch (RuntimeException e) {    }    UnitTestHelper.setLog4jLevel(HDFSDataPruner.class, Level.ERROR);}
0
public void testIgnoresDirectories() throws Exception
{    FileSystem testFS = mock(FileSystem.class);    when(testFS.isDirectory(any())).thenReturn(true);    HDFSDataPruner pruner = new HDFSDataPruner(yesterday, 30, "file:///", dataPath.getAbsolutePath() + "/file-*");    pruner.fileSystem = testFS;    HDFSDataPruner.DateFileFilter filter = new HDFSDataPruner.DateFileFilter(pruner, false);    assertFalse("Should ignore directories", filter.accept(new Path("/tmp")));}
0
public void testThrowBadFile() throws Exception
{    FileSystem testFS = mock(FileSystem.class);    when(testFS.isDirectory(any())).thenReturn(false);    when(testFS.getFileStatus(any())).thenThrow(new IOException("Test Exception"));    HDFSDataPruner pruner = new HDFSDataPruner(yesterday, 30, "file:///", dataPath.getAbsolutePath() + "/file-*");    pruner.fileSystem = testFS;    HDFSDataPruner.DateFileFilter filter = new HDFSDataPruner.DateFileFilter(pruner, true);    UnitTestHelper.setLog4jLevel(HDFSDataPruner.class, Level.FATAL);    try {        filter.accept(new Path("foo"));        Assert.fail("Expected Runtime exception, but did not receive one.");    } catch (RuntimeException e) {    }    UnitTestHelper.setLog4jLevel(HDFSDataPruner.class, Level.ERROR);}
0
private void createTestFiles() throws IOException
{        for (int i = 0; i < 50; i++) {        File file = new File(dataPath.getAbsolutePath() + "//file-" + String.format("%02d", i));        file.createNewFile();        file.deleteOnExit();    }        for (int i = 5; i < 25; i++) {        File file = new File(dataPath.getAbsolutePath() + "//file-" + String.format("%02d", i));        file.setLastModified(todaysDate.getTime() - TimeUnit.DAYS.toMillis(1));        file.deleteOnExit();    }        for (int i = 25; i < 40; i++) {        File file = new File(dataPath.getAbsolutePath() + "//file-" + String.format("%02d", i));        file.setLastModified(todaysDate.getTime() - TimeUnit.DAYS.toMillis(10));        file.deleteOnExit();    }        for (int i = 40; i < 50; i++) {        File file = new File(dataPath.getAbsolutePath() + "//file-" + String.format("%02d", i));        file.setLastModified(todaysDate.getTime() - TimeUnit.DAYS.toMillis(20));        file.deleteOnExit();    }}
0
public void testInitialize() throws Exception
{    CSVExtractor ex = new CSVExtractor();    ExtractorHandler handler = ExtractorHandler.load(testCSVConfig);    ex.initialize(handler.getConfig());    Assert.assertEquals(0, (int) ex.getColumnMap().get("host"));    Assert.assertEquals(2, (int) ex.getColumnMap().get("meta"));    Assert.assertEquals(0, ex.getTypeColumnIndex());    Assert.assertEquals(0, ex.getIndicatorColumn());    Assert.assertEquals("threat", ex.getType());    Assert.assertEquals(',', ex.getParser().getSeparator());}
0
public void testCSVExtractor() throws Exception
{    ExtractorHandler handler = ExtractorHandler.load(testCSVConfig);    validate(handler);}
0
public void validate(ExtractorHandler handler) throws IOException
{    {        LookupKV results = Iterables.getFirst(handler.getExtractor().extract("google.com,1.0,foo"), null);        EnrichmentKey key = (EnrichmentKey) results.getKey();        EnrichmentValue value = (EnrichmentValue) results.getValue();        Assert.assertEquals("google.com", key.indicator);        Assert.assertEquals("threat", key.type);        Assert.assertEquals("google.com", value.getMetadata().get("host"));        Assert.assertEquals("foo", value.getMetadata().get("meta"));        Assert.assertEquals(2, value.getMetadata().size());    }    {        Iterable<LookupKV> results = handler.getExtractor().extract("#google.com,1.0,foo");        Assert.assertEquals(0, Iterables.size(results));    }    {        Iterable<LookupKV> results = handler.getExtractor().extract("");        Assert.assertEquals(0, Iterables.size(results));    }    {        Iterable<LookupKV> results = handler.getExtractor().extract(" ");        Assert.assertEquals(0, Iterables.size(results));    }    {        Iterable<LookupKV> results = handler.getExtractor().extract(null);        Assert.assertEquals(0, Iterables.size(results));    }}
0
public void before()
{    MockitoAnnotations.initMocks(this);}
0
public void sets_member_variables()
{    ExtractorDecorator decorator = new ExtractorDecorator(extractor);    Assert.assertThat(decorator.decoratedExtractor, notNullValue());}
0
public void calls_extractor_methods() throws IOException
{    ExtractorDecorator decorator = new ExtractorDecorator(extractor);    decorator.initialize(new HashMap());    decorator.extract("line");    verify(extractor).initialize(isA(Map.class));    verify(extractor).extract("line");}
0
public Iterable<LookupKV> extract(String line) throws IOException
{    EnrichmentKey key = new EnrichmentKey();    key.indicator = "dummy";    key.type = "type";    Map<String, Object> value = new HashMap<>();    value.put("indicator", "dummy");    return Arrays.asList(new LookupKV(key, new EnrichmentValue(value)));}
0
public void initialize(Map<String, Object> config)
{}
0
public void testDummyExtractor() throws IllegalAccessException, InstantiationException, ClassNotFoundException, IOException, NoSuchMethodException, InvocationTargetException
{    Extractor extractor = Extractors.create(DummyExtractor.class.getName());    LookupKV results = Iterables.getFirst(extractor.extract(null), null);    EnrichmentKey key = (EnrichmentKey) results.getKey();    EnrichmentValue value = (EnrichmentValue) results.getValue();    Assert.assertEquals("dummy", key.indicator);    Assert.assertEquals("type", key.type);    Assert.assertEquals("dummy", value.getMetadata().get("indicator"));}
0
public void testExtractionLoading() throws Exception
{    /**     *         config:     *         {     *            "config" : {}     *            ,"extractor" : "org.apache.metron.dataloads.extractor.ExtractorTest$DummyExtractor"     *         }     */    String config = "{\n" + "            \"config\" : {}\n" + "            ,\"extractor\" : \"org.apache.metron.dataloads.extractor.ExtractorTest$DummyExtractor\"\n" + "         }";    ExtractorHandler handler = ExtractorHandler.load(config);    LookupKV results = Iterables.getFirst(handler.getExtractor().extract(null), null);    EnrichmentKey key = (EnrichmentKey) results.getKey();    EnrichmentValue value = (EnrichmentValue) results.getValue();    Assert.assertEquals("dummy", key.indicator);    Assert.assertEquals("type", key.type);    Assert.assertEquals("dummy", value.getMetadata().get("indicator"));}
0
public void setup() throws IOException
{    stixDoc = Joiner.on("\n").join(IOUtils.readLines(new InputStreamReader(new FileInputStream(new File("src/test/resources/stix_example.xml")), StandardCharsets.UTF_8)));    stixDocWithoutCondition = Joiner.on("\n").join(IOUtils.readLines(new InputStreamReader(new FileInputStream(new File("src/test/resources/stix_example_wo_conditions.xml")), StandardCharsets.UTF_8)));}
0
public void testStixAddressesWithCondition() throws Exception
{    testStixAddresses(stixDoc);}
0
public void testStixAddressesWithoutCondition() throws Exception
{    testStixAddresses(stixDocWithoutCondition);}
0
public void testStixAddresses(final String stixDoc) throws Exception
{    Thread t1 = new Thread(() -> {        try {            ExtractorHandler handler = ExtractorHandler.load(stixConfigOnlyIPV4);            Extractor extractor = handler.getExtractor();            Iterable<LookupKV> results = extractor.extract(stixDoc);            Assert.assertEquals(3, Iterables.size(results));            Assert.assertEquals("10.0.0.0", ((EnrichmentKey) (Iterables.get(results, 0).getKey())).indicator);            Assert.assertEquals("10.0.0.1", ((EnrichmentKey) (Iterables.get(results, 1).getKey())).indicator);            Assert.assertEquals("10.0.0.2", ((EnrichmentKey) (Iterables.get(results, 2).getKey())).indicator);        } catch (Exception ex) {            throw new RuntimeException(ex.getMessage(), ex);        }    });    Thread t2 = new Thread(() -> {        try {            ExtractorHandler handler = ExtractorHandler.load(stixConfig);            Extractor extractor = handler.getExtractor();            Iterable<LookupKV> results = extractor.extract(stixDoc);            Assert.assertEquals(3, Iterables.size(results));            Assert.assertEquals("10.0.0.0", ((EnrichmentKey) (Iterables.get(results, 0).getKey())).indicator);            Assert.assertEquals("10.0.0.1", ((EnrichmentKey) (Iterables.get(results, 1).getKey())).indicator);            Assert.assertEquals("10.0.0.2", ((EnrichmentKey) (Iterables.get(results, 2).getKey())).indicator);        } catch (Exception ex) {            throw new RuntimeException(ex.getMessage(), ex);        }    });    Thread t3 = new Thread(() -> {        try {            ExtractorHandler handler = ExtractorHandler.load(stixConfigOnlyIPV6);            Extractor extractor = handler.getExtractor();            Iterable<LookupKV> results = extractor.extract(stixDoc);            Assert.assertEquals(0, Iterables.size(results));        } catch (Exception ex) {            throw new RuntimeException(ex.getMessage(), ex);        }    });    t1.run();    t2.run();    t3.run();    t1.join();    t2.join();    t3.join();}
0
public void testURIHandler() throws Exception
{    StixExtractor extractor = new StixExtractor();    extractor.initialize(new HashMap<>());    Iterable<LookupKV> kvs = extractor.extract(uriHandlerObject);    Assert.assertEquals(1, Iterables.size(kvs));    LookupKV kv = Iterables.getFirst(kvs, null);    EnrichmentKey key = (EnrichmentKey) kv.getKey();    Assert.assertEquals("http://www.kotimi.com/alpha/gtex/", key.getIndicator());    Assert.assertEquals("uriobjecttype", key.type);}
0
public void setup() throws Exception
{    MockitoAnnotations.initMocks(this);    config1 = new ObjectMapper().readValue(config1Contents, LinkedHashMap.class);    decorator = new TransformFilterExtractorDecorator(extractor);    decorator.setZkClient(Optional.of(zkClient));    decorator.initialize(config1);}
0
public void transforms_values_and_indicators() throws IOException
{    final String indicatorVal = "val2";    EnrichmentKey lookupKey = new EnrichmentKey("testenrichment", indicatorVal);    EnrichmentValue lookupValue = new EnrichmentValue(new HashMap<String, Object>() {        {            put("foo", "val1");            put("bar", indicatorVal);            put("baz", "val3");        }    });    LookupKV lkv = new LookupKV<>(lookupKey, lookupValue);    List<LookupKV> extractedLkvs = new ArrayList<>();    extractedLkvs.add(lkv);    Mockito.when(extractor.extract("val1,val2,val3")).thenReturn(extractedLkvs);    Iterable<LookupKV> extracted = decorator.extract("val1,val2,val3");    EnrichmentKey expectedLookupKey = new EnrichmentKey("testenrichment", "VAL2");    EnrichmentValue expectedLookupValue = new EnrichmentValue(new HashMap<String, Object>() {        {            put("foo", "VAL1");            put("bar", "val2");            put("baz", "val3");            put("newvar", "VAL1");            put("lowernewvar", "val1");        }    });    LookupKV expectedLkv = new LookupKV<>(expectedLookupKey, expectedLookupValue);    List<LookupKV> expectedLkvs = new ArrayList<>();    expectedLkvs.add(expectedLkv);    Assert.assertThat(extracted, CoreMatchers.equalTo(expectedLkvs));}
0
public void filters_values() throws Exception
{    final String indicatorVal = "val2";    EnrichmentKey lookupKey = new EnrichmentKey("testenrichment", indicatorVal);    EnrichmentValue lookupValue = new EnrichmentValue(new HashMap<String, Object>() {        {            put("foo", "val1");            put("bar", indicatorVal);            put("baz", "");        }    });    LookupKV lkv = new LookupKV<>(lookupKey, lookupValue);    List<LookupKV> extractedLkvs = new ArrayList<>();    extractedLkvs.add(lkv);    Mockito.when(extractor.extract("val1,val2,")).thenReturn(extractedLkvs);    Iterable<LookupKV> extracted = decorator.extract("val1,val2,");    Assert.assertThat(extracted, CoreMatchers.equalTo(new ArrayList<>()));}
0
public void filters_indicators() throws Exception
{    EnrichmentKey lookupKey = new EnrichmentKey("testenrichment", "");    EnrichmentValue lookupValue = new EnrichmentValue(new HashMap<String, Object>() {        {            put("foo", "val1");            put("bar", "");            put("baz", "val3");        }    });    LookupKV lkv = new LookupKV<>(lookupKey, lookupValue);    List<LookupKV> extractedLkvs = new ArrayList<>();    extractedLkvs.add(lkv);    Mockito.when(extractor.extract("val1,,val3")).thenReturn(extractedLkvs);    Iterable<LookupKV> extracted = decorator.extract("val1,,val3");    Assert.assertThat(extracted, CoreMatchers.equalTo(new ArrayList<>()));}
0
public void bad_value_transform_causes_exception() throws Exception
{    final int badValue = 5;    exception.expect(ClassCastException.class);    config1.put(TransformFilterExtractorDecorator.ExtractorOptions.VALUE_TRANSFORM.toString(), badValue);    decorator = new TransformFilterExtractorDecorator(extractor);    decorator.setZkClient(Optional.of(zkClient));    decorator.initialize(config1);}
0
public void bad_value_filter_causes_exception() throws Exception
{    final int badValue = 5;    exception.expect(ClassCastException.class);    config1.put(TransformFilterExtractorDecorator.ExtractorOptions.VALUE_FILTER.toString(), badValue);    decorator = new TransformFilterExtractorDecorator(extractor);    decorator.setZkClient(Optional.of(zkClient));    decorator.initialize(config1);}
0
public void bad_indicator_transform_causes_exception() throws Exception
{    final int badValue = 5;    exception.expect(ClassCastException.class);    config1.put(TransformFilterExtractorDecorator.ExtractorOptions.INDICATOR_TRANSFORM.toString(), badValue);    decorator = new TransformFilterExtractorDecorator(extractor);    decorator.setZkClient(Optional.of(zkClient));    decorator.initialize(config1);}
0
public void bad_indicator_filter_causes_exception() throws Exception
{    final int badValue = 5;    exception.expect(ClassCastException.class);    config1.put(TransformFilterExtractorDecorator.ExtractorOptions.INDICATOR_FILTER.toString(), badValue);    decorator = new TransformFilterExtractorDecorator(extractor);    decorator.setZkClient(Optional.of(zkClient));    decorator.initialize(config1);}
0
public void testKeySerializationRemainsConstant()
{    byte[] raw = key.toBytes();    Assert.assertArrayEquals(raw, keyBytes);}
0
public void testKeySerialization()
{    byte[] serialized = key.toBytes();    EnrichmentKey deserialized = new EnrichmentKey();    deserialized.fromBytes(serialized);    Assert.assertEquals(key, deserialized);}
0
public void testPut() throws IOException
{    HbaseConverter<EnrichmentKey, EnrichmentValue> converter = new EnrichmentConverter();    Put put = converter.toPut("cf", key, value);    LookupKV<EnrichmentKey, EnrichmentValue> converted = converter.fromPut(put, "cf");    Assert.assertEquals(results, converted);}
0
public void testResult() throws IOException
{    HbaseConverter<EnrichmentKey, EnrichmentValue> converter = new EnrichmentConverter();    Result r = converter.toResult("cf", key, value);    LookupKV<EnrichmentKey, EnrichmentValue> converted = converter.fromResult(r, "cf");    Assert.assertEquals(results, converted);}
0
public void testGet() throws Exception
{    HbaseConverter<EnrichmentKey, EnrichmentValue> converter = new EnrichmentConverter();    Get get = converter.toGet("cf", key);    Assert.assertArrayEquals(key.toBytes(), get.getRow());}
0
public void testMapper() throws IOException, InterruptedException
{    final Map<ImmutableBytesWritable, Put> puts = new HashMap<>();    BulkLoadMapper mapper = new BulkLoadMapper() {        @Override        protected void write(ImmutableBytesWritable key, Put value, Context context) throws IOException, InterruptedException {            puts.put(key, value);        }    };    mapper.initialize(new Configuration() {        {            set(BulkLoadMapper.COLUMN_FAMILY_KEY, "cf");            set(BulkLoadMapper.CONFIG_KEY, extractorConfig);            set(BulkLoadMapper.LAST_SEEN_KEY, "0");            set(BulkLoadMapper.CONVERTER_KEY, EnrichmentConverter.class.getName());        }    });    {        mapper.map(null, new Text("#google.com,1,foo"), null);        Assert.assertTrue(puts.size() == 0);    }    {        mapper.map(null, new Text("google.com,1,foo"), null);        Assert.assertTrue(puts.size() == 1);        EnrichmentKey expectedKey = new EnrichmentKey() {            {                indicator = "google.com";                type = "threat";            }        };        EnrichmentConverter converter = new EnrichmentConverter();        Put put = puts.get(new ImmutableBytesWritable(expectedKey.toBytes()));        Assert.assertNotNull(puts);        LookupKV<EnrichmentKey, EnrichmentValue> results = converter.fromPut(put, "cf");        Assert.assertEquals(results.getKey().indicator, "google.com");        Assert.assertEquals(results.getValue().getMetadata().size(), 2);        Assert.assertEquals(results.getValue().getMetadata().get("meta"), "foo");        Assert.assertEquals(results.getValue().getMetadata().get("host"), "google.com");    }}
0
protected void write(ImmutableBytesWritable key, Put value, Context context) throws IOException, InterruptedException
{    puts.put(key, value);}
0
public Map.Entry<HBaseTestingUtility, Configuration> create(boolean startMRCluster) throws Exception
{    return create(startMRCluster, null);}
0
public Map.Entry<HBaseTestingUtility, Configuration> create(boolean startMRCluster, Configuration extraConfig) throws Exception
{    Configuration config = HBaseConfiguration.create();    config.set("hbase.master.hostname", "localhost");    config.set("hbase.regionserver.hostname", "localhost");    if (null != extraConfig) {        for (Entry<String, String> entry : extraConfig) {            config.set(entry.getKey(), entry.getValue());        }    }    HBaseTestingUtility testUtil = new HBaseTestingUtility(config);    testUtil.startMiniCluster(1);    if (startMRCluster) {        testUtil.startMiniMapReduceCluster();    }    return new AbstractMap.SimpleEntry<>(testUtil, config);}
0
public void writeFile(String contents, Path filename, FileSystem fs) throws IOException
{    FSDataOutputStream os = fs.create(filename, true);    PrintWriter pw = new PrintWriter(new OutputStreamWriter(os, StandardCharsets.UTF_8));    pw.print(contents);    pw.flush();    os.close();}
0
public String readFile(FileSystem fs, Path filename) throws IOException
{    FSDataInputStream in = fs.open(filename);    BufferedReader br = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8));    List<String> contents = new ArrayList<>();    for (String line = null; (line = br.readLine()) != null; ) {        contents.add(line);    }    return Joiner.on('\n').join(contents);}
0
public void teardown(HBaseTestingUtility testUtil) throws Exception
{    testUtil.shutdownMiniMapReduceCluster();    testUtil.shutdownMiniCluster();    testUtil.cleanupTestDir();}
0
public static void setup() throws Exception
{    UnitTestHelper.setJavaLoggingLevel(Level.SEVERE);    Map.Entry<HBaseTestingUtility, Configuration> kv = HBaseUtil.INSTANCE.create(true);    config = kv.getValue();    testUtil = kv.getKey();    testTable = testUtil.createTable(Bytes.toBytes(tableName), Bytes.toBytes(cf));    atTable = testUtil.createTable(Bytes.toBytes(atTableName), Bytes.toBytes(atCF));}
0
public static void teardown() throws Exception
{    HBaseUtil.INSTANCE.teardown(testUtil);}
0
public List<LookupKey> getKeys(int start, int end)
{    List<LookupKey> keys = new ArrayList<>();    for (int i = start; i < end; ++i) {        keys.add(new EnrichmentKey("type", "key-" + i));    }    return keys;}
0
public void testCommandLine() throws Exception
{    Configuration conf = HBaseConfiguration.create();    String[] argv = { "-a 04/14/2016 12:00:00", "-f cf", "-t malicious_domains", "-u access_trackers", "-v georgia", "-z cf" };    String[] otherArgs = new GenericOptionsParser(conf, argv).getRemainingArgs();    CommandLine cli = LeastRecentlyUsedPruner.BulkLoadOptions.parse(new PosixParser(), otherArgs);    Assert.assertEquals(cf, LeastRecentlyUsedPruner.BulkLoadOptions.COLUMN_FAMILY.get(cli).trim());    Assert.assertEquals(tableName, LeastRecentlyUsedPruner.BulkLoadOptions.TABLE.get(cli).trim());    Assert.assertEquals(atTableName, LeastRecentlyUsedPruner.BulkLoadOptions.ACCESS_TABLE.get(cli).trim());    Assert.assertEquals(atCF, LeastRecentlyUsedPruner.BulkLoadOptions.ACCESS_COLUMN_FAMILY.get(cli).trim());    Assert.assertEquals(beginTime, LeastRecentlyUsedPruner.BulkLoadOptions.AS_OF_TIME.get(cli).trim());    Assert.assertEquals(timeFormat, LeastRecentlyUsedPruner.BulkLoadOptions.AS_OF_TIME_FORMAT.get(cli).trim());}
0
public void test() throws Exception
{    long ts = System.currentTimeMillis();    BloomAccessTracker bat = new BloomAccessTracker("tracker1", 100, 0.03);    PersistentAccessTracker pat = new PersistentAccessTracker(tableName, "0", atTable, atCF, bat, 0L);    EnrichmentLookup lookup = new EnrichmentLookup(testTable, cf, pat);    List<LookupKey> goodKeysHalf = getKeys(0, 5);    List<LookupKey> goodKeysOtherHalf = getKeys(5, 10);    Iterable<LookupKey> goodKeys = Iterables.concat(goodKeysHalf, goodKeysOtherHalf);    List<LookupKey> badKey = getKeys(10, 11);    EnrichmentConverter converter = new EnrichmentConverter();    for (LookupKey k : goodKeysHalf) {        testTable.put(converter.toPut(cf, (EnrichmentKey) k, new EnrichmentValue(new HashMap<String, Object>() {            {                put("k", "dummy");            }        })));        Assert.assertTrue(lookup.exists((EnrichmentKey) k, new EnrichmentLookup.HBaseContext(testTable, cf), true));    }    pat.persist(true);    for (LookupKey k : goodKeysOtherHalf) {        testTable.put(converter.toPut(cf, (EnrichmentKey) k, new EnrichmentValue(new HashMap<String, Object>() {            {                put("k", "dummy");            }        })));        Assert.assertTrue(lookup.exists((EnrichmentKey) k, new EnrichmentLookup.HBaseContext(testTable, cf), true));    }    testUtil.flush();    Assert.assertFalse(lookup.getAccessTracker().hasSeen(goodKeysHalf.get(0)));    for (LookupKey k : goodKeysOtherHalf) {        Assert.assertTrue(lookup.getAccessTracker().hasSeen(k));    }    pat.persist(true);    {        testTable.put(converter.toPut(cf, (EnrichmentKey) badKey.get(0), new EnrichmentValue(new HashMap<String, Object>() {            {                put("k", "dummy");            }        })));    }    testUtil.flush();    Assert.assertFalse(lookup.getAccessTracker().hasSeen(badKey.get(0)));    Job job = LeastRecentlyUsedPruner.createJob(config, tableName, cf, atTableName, atCF, ts);    Assert.assertTrue(job.waitForCompletion(true));    for (LookupKey k : goodKeys) {        Assert.assertTrue(lookup.exists((EnrichmentKey) k, new EnrichmentLookup.HBaseContext(testTable, cf), true));    }    for (LookupKey k : badKey) {        Assert.assertFalse(lookup.exists((EnrichmentKey) k, new EnrichmentLookup.HBaseContext(testTable, cf), true));    }}
0
public static void setup() throws Exception
{    UnitTestHelper.setJavaLoggingLevel(Level.SEVERE);    Map.Entry<HBaseTestingUtility, Configuration> kv = HBaseUtil.INSTANCE.create(true);    config = kv.getValue();    testUtil = kv.getKey();    testTable = testUtil.createTable(Bytes.toBytes(tableName), Bytes.toBytes(cf));    zookeeperUrl = getZookeeperUrl(config.get("hbase.zookeeper.quorum"), testUtil.getZkCluster().getClientPort());    setupGlobalConfig(zookeeperUrl);    for (Result r : testTable.getScanner(Bytes.toBytes(cf))) {        Delete d = new Delete(r.getRow());        testTable.delete(d);    }    if (lineByLineExtractorConfigFile.exists()) {        lineByLineExtractorConfigFile.delete();    }    Files.write(lineByLineExtractorConfigFile.toPath(), lineByLineExtractorConfig.getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE_NEW, StandardOpenOption.TRUNCATE_EXISTING);    if (wholeFileExtractorConfigFile.exists()) {        wholeFileExtractorConfigFile.delete();    }    Files.write(wholeFileExtractorConfigFile.toPath(), wholeFileExtractorConfig.getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE_NEW, StandardOpenOption.TRUNCATE_EXISTING);    if (stellarExtractorConfigFile.exists()) {        stellarExtractorConfigFile.delete();    }    Files.write(stellarExtractorConfigFile.toPath(), stellarExtractorConfig.replace("%ZK_QUORUM%", zookeeperUrl).getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE_NEW, StandardOpenOption.TRUNCATE_EXISTING);    if (customLineByLineExtractorConfigFile.exists()) {        customLineByLineExtractorConfigFile.delete();    }    Files.write(customLineByLineExtractorConfigFile.toPath(), customLineByLineExtractorConfig.replace("%EXTRACTOR_CLASS%", CSVExtractor.class.getName()).getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE_NEW, StandardOpenOption.TRUNCATE_EXISTING);    if (file1.exists()) {        file1.delete();    }    Files.write(file1.toPath(), "google1.com,1,foo2\n".getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE_NEW, StandardOpenOption.TRUNCATE_EXISTING);    if (file2.exists()) {        file2.delete();    }    Files.write(file2.toPath(), "google2.com,2,foo2\n".getBytes(StandardCharsets.UTF_8), StandardOpenOption.CREATE_NEW, StandardOpenOption.TRUNCATE_EXISTING);    if (multilineFile.exists()) {        multilineFile.delete();    }    if (multilineGzFile.exists()) {        multilineGzFile.delete();    }    if (multilineGzFile.exists()) {        multilineZipFile.delete();    }    PrintWriter[] pws = new PrintWriter[] {};    try {        ZipOutputStream zos = new ZipOutputStream(new FileOutputStream(multilineZipFile));        ZipEntry entry = new ZipEntry("file");        zos.putNextEntry(entry);                pws = new PrintWriter[] { new PrintWriter(multilineFile, StandardCharsets.UTF_8.name()), new PrintWriter(new OutputStreamWriter(zos, StandardCharsets.UTF_8)), new PrintWriter(new OutputStreamWriter(new GZIPOutputStream(new FileOutputStream(multilineGzFile)), StandardCharsets.UTF_8)) };        for (int i = 0; i < NUM_LINES; ++i) {            for (PrintWriter pw : pws) {                pw.println("google" + i + ".com," + i + ",foo" + i);            }        }    } finally {        for (PrintWriter pw : pws) {            pw.close();        }    }}
0
private static String getZookeeperUrl(String host, int port)
{    return host + ":" + port;}
0
private static void setupGlobalConfig(String zookeeperUrl) throws Exception
{    client = ConfigurationsUtils.getClient(zookeeperUrl);    client.start();    ConfigurationsUtils.writeGlobalConfigToZookeeper(globalConfig.getBytes(StandardCharsets.UTF_8), zookeeperUrl);}
0
public static void teardown() throws Exception
{    HBaseUtil.INSTANCE.teardown(testUtil);    file1.delete();    file2.delete();    multilineFile.delete();    multilineGzFile.delete();    multilineZipFile.delete();    lineByLineExtractorConfigFile.delete();    wholeFileExtractorConfigFile.delete();    stellarExtractorConfigFile.delete();    customLineByLineExtractorConfigFile.delete();}
0
public void testArgs() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e extractor.json", "-n enrichment_config.json", "-l log4j", "-i input.csv", "-p 2", "-b 128", "-q" };    String[] otherArgs = new GenericOptionsParser(config, argv).getRemainingArgs();    CommandLine cli = LoadOptions.parse(new PosixParser(), otherArgs);    Assert.assertEquals(extractorJson, LoadOptions.EXTRACTOR_CONFIG.get(cli).trim());    Assert.assertEquals(cf, LoadOptions.HBASE_CF.get(cli).trim());    Assert.assertEquals(tableName, LoadOptions.HBASE_TABLE.get(cli).trim());    Assert.assertEquals(enrichmentJson, LoadOptions.ENRICHMENT_CONFIG.get(cli).trim());    Assert.assertEquals(csvFile, LoadOptions.INPUT.get(cli).trim());    Assert.assertEquals(log4jProperty, LoadOptions.LOG4J_PROPERTIES.get(cli).trim());    Assert.assertEquals("2", LoadOptions.NUM_THREADS.get(cli).trim());    Assert.assertEquals("128", LoadOptions.BATCH_SIZE.get(cli).trim());}
0
public void testLocalLineByLine() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e " + lineByLineExtractorConfigFile.getPath(), "-i " + multilineFile.getPath(), "-p 2", "-b 128", "-q" };    SimpleEnrichmentFlatFileLoader.main(config, argv);    EnrichmentConverter converter = new EnrichmentConverter();    ResultScanner scanner = testTable.getScanner(Bytes.toBytes(cf));    List<LookupKV<EnrichmentKey, EnrichmentValue>> results = new ArrayList<>();    for (Result r : scanner) {        results.add(converter.fromResult(r, cf));        testTable.delete(new Delete(r.getRow()));    }    Assert.assertEquals(NUM_LINES, results.size());    Assert.assertTrue(results.get(0).getKey().indicator.startsWith("google"));    Assert.assertEquals(results.get(0).getKey().type, "enrichment");    Assert.assertEquals(results.get(0).getValue().getMetadata().size(), 2);    Assert.assertTrue(results.get(0).getValue().getMetadata().get("meta").toString().startsWith("foo"));    Assert.assertTrue(results.get(0).getValue().getMetadata().get("host").toString().startsWith("google"));}
0
public void testLocalLineByLine_gz() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e " + lineByLineExtractorConfigFile.getPath(), "-i " + multilineGzFile.getPath(), "-p 2", "-b 128", "-q" };    SimpleEnrichmentFlatFileLoader.main(config, argv);    EnrichmentConverter converter = new EnrichmentConverter();    ResultScanner scanner = testTable.getScanner(Bytes.toBytes(cf));    List<LookupKV<EnrichmentKey, EnrichmentValue>> results = new ArrayList<>();    for (Result r : scanner) {        results.add(converter.fromResult(r, cf));        testTable.delete(new Delete(r.getRow()));    }    Assert.assertEquals(NUM_LINES, results.size());    Assert.assertTrue(results.get(0).getKey().indicator.startsWith("google"));    Assert.assertEquals(results.get(0).getKey().type, "enrichment");    Assert.assertEquals(results.get(0).getValue().getMetadata().size(), 2);    Assert.assertTrue(results.get(0).getValue().getMetadata().get("meta").toString().startsWith("foo"));    Assert.assertTrue(results.get(0).getValue().getMetadata().get("host").toString().startsWith("google"));}
0
public void testLocalLineByLine_zip() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e " + lineByLineExtractorConfigFile.getPath(), "-i " + multilineZipFile.getPath(), "-p 2", "-b 128", "-q" };    SimpleEnrichmentFlatFileLoader.main(config, argv);    EnrichmentConverter converter = new EnrichmentConverter();    ResultScanner scanner = testTable.getScanner(Bytes.toBytes(cf));    List<LookupKV<EnrichmentKey, EnrichmentValue>> results = new ArrayList<>();    for (Result r : scanner) {        results.add(converter.fromResult(r, cf));        testTable.delete(new Delete(r.getRow()));    }    Assert.assertEquals(NUM_LINES, results.size());    Assert.assertTrue(results.get(0).getKey().indicator.startsWith("google"));    Assert.assertEquals(results.get(0).getKey().type, "enrichment");    Assert.assertEquals(results.get(0).getValue().getMetadata().size(), 2);    Assert.assertTrue(results.get(0).getValue().getMetadata().get("meta").toString().startsWith("foo"));    Assert.assertTrue(results.get(0).getValue().getMetadata().get("host").toString().startsWith("google"));}
0
public void testLocalWholeFile() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e " + wholeFileExtractorConfigFile.getPath(), "-i " + file1.getPath() + "," + file2.getPath(), "-p 2", "-b 128", "-q" };    SimpleEnrichmentFlatFileLoader.main(config, argv);    EnrichmentConverter converter = new EnrichmentConverter();    ResultScanner scanner = testTable.getScanner(Bytes.toBytes(cf));    List<LookupKV<EnrichmentKey, EnrichmentValue>> results = new ArrayList<>();    for (Result r : scanner) {        results.add(converter.fromResult(r, cf));        testTable.delete(new Delete(r.getRow()));    }    Assert.assertEquals(2, results.size());    Assert.assertTrue(results.get(0).getKey().indicator.startsWith("google"));    Assert.assertEquals(results.get(0).getKey().type, "enrichment");    Assert.assertEquals(results.get(0).getValue().getMetadata().size(), 2);    Assert.assertTrue(results.get(0).getValue().getMetadata().get("meta").toString().startsWith("foo"));    Assert.assertTrue(results.get(0).getValue().getMetadata().get("host").toString().startsWith("google"));}
0
public void testMRLineByLine() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e " + lineByLineExtractorConfigFile.getPath(), "-i " + multilineFile.getName(), "-m MR", "-p 2", "-b 128", "-q" };    FileSystem fs = FileSystem.get(config);    HBaseUtil.INSTANCE.writeFile(new String(Files.readAllBytes(multilineFile.toPath()), StandardCharsets.UTF_8), new Path(multilineFile.getName()), fs);    SimpleEnrichmentFlatFileLoader.main(config, argv);    EnrichmentConverter converter = new EnrichmentConverter();    ResultScanner scanner = testTable.getScanner(Bytes.toBytes(cf));    List<LookupKV<EnrichmentKey, EnrichmentValue>> results = new ArrayList<>();    for (Result r : scanner) {        results.add(converter.fromResult(r, cf));        testTable.delete(new Delete(r.getRow()));    }    Assert.assertEquals(NUM_LINES, results.size());    Assert.assertTrue(results.get(0).getKey().indicator.startsWith("google"));    Assert.assertEquals(results.get(0).getKey().type, "enrichment");    Assert.assertEquals(results.get(0).getValue().getMetadata().size(), 2);    Assert.assertTrue(results.get(0).getValue().getMetadata().get("meta").toString().startsWith("foo"));    Assert.assertTrue(results.get(0).getValue().getMetadata().get("host").toString().startsWith("google"));}
0
public void stellar_transforms_and_filters_indicators_and_value_metadata() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e " + stellarExtractorConfigFile.getPath(), "-i " + multilineFile.getPath(), "-p 2", "-b 128", "-q" };    SimpleEnrichmentFlatFileLoader.main(config, argv);    EnrichmentConverter converter = new EnrichmentConverter();    ResultScanner scanner = testTable.getScanner(Bytes.toBytes(cf));    List<LookupKV<EnrichmentKey, EnrichmentValue>> results = new ArrayList<>();    for (Result r : scanner) {        results.add(converter.fromResult(r, cf));        testTable.delete(new Delete(r.getRow()));    }    Assert.assertEquals(NUM_LINES, results.size());    Assert.assertThat(results.get(0).getKey().getIndicator(), startsWith("GOOGLE"));    Assert.assertThat(results.get(0).getKey().type, equalTo("enrichment"));    Assert.assertThat(results.get(0).getValue().getMetadata().size(), equalTo(3));    Assert.assertThat(results.get(0).getValue().getMetadata().get("meta").toString(), startsWith("foo"));    Assert.assertThat(results.get(0).getValue().getMetadata().get("empty").toString(), startsWith("valfromglobalconfig"));    Assert.assertThat(results.get(0).getValue().getMetadata().get("host").toString(), startsWith("GOOGLE"));}
0
public void custom_extractor_transforms_and_filters_indicators_and_value_metadata() throws Exception
{    String[] argv = { "-c cf", "-t enrichment", "-e " + customLineByLineExtractorConfigFile.getPath(), "-i " + multilineFile.getPath(), "-p 2", "-b 128", "-q" };    SimpleEnrichmentFlatFileLoader.main(config, argv);    EnrichmentConverter converter = new EnrichmentConverter();    ResultScanner scanner = testTable.getScanner(Bytes.toBytes(cf));    List<LookupKV<EnrichmentKey, EnrichmentValue>> results = new ArrayList<>();    for (Result r : scanner) {        results.add(converter.fromResult(r, cf));        testTable.delete(new Delete(r.getRow()));    }    Assert.assertEquals(NUM_LINES, results.size());    Assert.assertThat(results.get(0).getKey().getIndicator(), startsWith("GOOGLE"));    Assert.assertThat(results.get(0).getKey().type, equalTo("enrichment"));    Assert.assertThat(results.get(0).getValue().getMetadata().size(), equalTo(2));    Assert.assertThat(results.get(0).getValue().getMetadata().get("meta").toString(), startsWith("foo"));    Assert.assertThat(results.get(0).getValue().getMetadata().get("host").toString(), startsWith("GOOGLE"));}
0
public static String generateData()
{    List<String> tmp = new ArrayList<>();    int i = 1;    for (String d : domains) {        tmp.add(i + "," + d);    }    return Joiner.on("\n").join(tmp);}
0
public void testArgs() throws Exception
{    String[] argv = { "-e extractor.json", "-o out.ser", "-l log4j", "-i input.csv", "-p 2", "-b 128", "-q" };    Configuration config = new Configuration();    String[] otherArgs = new GenericOptionsParser(config, argv).getRemainingArgs();    CommandLine cli = SummarizeOptions.parse(new PosixParser(), otherArgs);    Assert.assertEquals("extractor.json", SummarizeOptions.EXTRACTOR_CONFIG.get(cli).trim());    Assert.assertEquals("input.csv", SummarizeOptions.INPUT.get(cli).trim());    Assert.assertEquals("log4j", SummarizeOptions.LOG4J_PROPERTIES.get(cli).trim());    Assert.assertEquals("2", SummarizeOptions.NUM_THREADS.get(cli).trim());    Assert.assertEquals("128", SummarizeOptions.BATCH_SIZE.get(cli).trim());}
0
public Optional<List<String>> list(String loc) throws IOException
{    if (loc.equals(".")) {        ArrayList<String> ret = new ArrayList<>(inMemoryData.keySet());        return Optional.of(ret);    }    return Optional.empty();}
0
public boolean exists(String loc)
{    return loc.equals(".") ? true : inMemoryData.containsKey(loc);}
0
public boolean isDirectory(String loc) throws IOException
{    return loc.equals(".") ? true : false;}
0
public InputStream openInputStream(String loc) throws IOException
{    return new ByteArrayInputStream(inMemoryData.get(loc).getBytes(StandardCharsets.UTF_8));}
0
public boolean match(String loc)
{    return exists(loc);}
0
protected List<Location> getLocationsRecursive(List<String> inputs, FileSystem fs) throws IOException
{    Set<Location> ret = new HashSet<>();    for (String input : inputs) {        if (input.equals(".")) {            for (String s : mockData.keySet()) {                ret.add(resolveLocation(s, fs));            }        } else {            ret.add(resolveLocation(input, fs));        }    }    return new ArrayList<>(ret);}
0
protected Location resolveLocation(String input, FileSystem fs)
{    return new Location(input, new InMemoryLocation(mockData));}
0
public void validate(Optional<String> output, Configuration hadoopConfig)
{}
0
public void write(Object obj, Optional<String> output, Configuration hadoopConfig) throws IOException
{    ref.set(obj);}
0
public void write(byte[] obj, Optional<String> output, Configuration hadoopConfig) throws IOException
{}
0
public void testLineByLine() throws IOException, InvalidWriterOutput
{    testLineByLine(5);    testLineByLine(1);}
0
public void testLineByLine(final int numThreads) throws IOException, InvalidWriterOutput
{    ExtractorHandler handler = ExtractorHandler.load(stellarExtractorConfigLineByLine);    LocalSummarizer summarizer = new MockSummarizer(ImmutableMap.of("input.csv", generateData()));    final AtomicReference<Object> finalObj = new AtomicReference<>(null);    EnumMap<SummarizeOptions, Optional<Object>> options = new EnumMap<SummarizeOptions, Optional<Object>>(SummarizeOptions.class) {        {            put(SummarizeOptions.INPUT, Optional.of("input.csv"));            put(SummarizeOptions.BATCH_SIZE, Optional.of(5));            put(SummarizeOptions.QUIET, Optional.of(true));            put(SummarizeOptions.OUTPUT_MODE, Optional.of(new PeekingWriter(finalObj)));            put(SummarizeOptions.OUTPUT, Optional.of("out"));            put(SummarizeOptions.NUM_THREADS, Optional.of(numThreads));        }    };    summarizer.importData(options, handler, new Configuration());    String expr = "MAP_GET(DOMAIN_REMOVE_TLD(domain), s) > 0";    for (String domain : domains) {        Boolean b = (Boolean) StellarProcessorUtils.run(expr, ImmutableMap.of("s", finalObj.get(), "domain", domain));        Assert.assertTrue("Can't find " + domain, b);    }}
0
public void testWholeFile() throws Exception
{    testWholeFile(5);    testWholeFile(1);}
0
public void testWholeFile(final int numThreads) throws IOException, InvalidWriterOutput
{    ExtractorHandler handler = ExtractorHandler.load(stellarExtractorConfigWholeFile);    LocalSummarizer summarizer = new MockSummarizer(new HashMap<String, String>() {        {            for (String domain : domains) {                put(domain, "1," + domain);            }        }    });    final AtomicReference<Object> finalObj = new AtomicReference<>(null);    EnumMap<SummarizeOptions, Optional<Object>> options = new EnumMap<SummarizeOptions, Optional<Object>>(SummarizeOptions.class) {        {            put(SummarizeOptions.INPUT, Optional.of("."));            put(SummarizeOptions.BATCH_SIZE, Optional.of(5));            put(SummarizeOptions.QUIET, Optional.of(true));            put(SummarizeOptions.OUTPUT_MODE, Optional.of(new PeekingWriter(finalObj)));            put(SummarizeOptions.OUTPUT, Optional.of("out"));            put(SummarizeOptions.NUM_THREADS, Optional.of(numThreads));        }    };    summarizer.importData(options, handler, new Configuration());    String expr = "MAP_GET(DOMAIN_REMOVE_TLD(domain), s) > 0";    for (String domain : domains) {        Boolean b = (Boolean) StellarProcessorUtils.run(expr, ImmutableMap.of("s", finalObj.get(), "domain", domain));        Assert.assertTrue("Can't find " + domain, b);    }}
0
protected void pushConfig(Path srcPath, Path dstPath, String configName, String zookeeper)
{}
0
public void setup() throws Exception
{    testFolder.create();    remoteDir = testFolder.newFolder("remoteDir");    tmpDir = testFolder.newFolder("tmpDir");}
0
public void testCommandLineShortOpts() throws Exception
{    String[] argv = { "-g testGeoUrl", "-a testAsnUrl", "-r /test/remoteDirGeo", "-ra", "/test/remoteDirAsn", "-t /test/tmpDir", "-z test:2181" };    String[] otherArgs = new GenericOptionsParser(argv).getRemainingArgs();    CommandLine cli = MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.parse(new PosixParser(), otherArgs);    Assert.assertEquals("testGeoUrl", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.GEO_URL.get(cli).trim());    Assert.assertEquals("testAsnUrl", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.ASN_URL.get(cli).trim());    Assert.assertEquals("/test/remoteDirGeo", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.REMOTE_GEO_DIR.get(cli).trim());    Assert.assertEquals("/test/remoteDirAsn", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.REMOTE_ASN_DIR.get(cli).trim());    Assert.assertEquals("/test/tmpDir", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.TMP_DIR.get(cli).trim());    Assert.assertEquals("test:2181", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.ZK_QUORUM.get(cli).trim());}
0
public void testCommandLineLongOpts() throws Exception
{    String[] argv = { "--geo_url", "testGeoUrl", "--remote_dir", "/test/remoteDir", "-ra", "/test/remoteDir", "--tmp_dir", "/test/tmpDir", "--zk_quorum", "test:2181" };    String[] otherArgs = new GenericOptionsParser(argv).getRemainingArgs();    CommandLine cli = MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.parse(new PosixParser(), otherArgs);    Assert.assertEquals("testGeoUrl", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.GEO_URL.get(cli).trim());    Assert.assertEquals("/test/remoteDir", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.REMOTE_GEO_DIR.get(cli).trim());    Assert.assertEquals("/test/tmpDir", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.TMP_DIR.get(cli).trim());    Assert.assertEquals("test:2181", MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.ZK_QUORUM.get(cli).trim());}
0
public void testLoadGeoIpDatabase() throws Exception
{    File dbPlainTextFile = new File(remoteDir.getAbsolutePath() + "/MaxmindDbEnrichmentLoaderTest.mmdb");    TestUtils.write(dbPlainTextFile, "hello world");    File dbFile = new File(remoteDir.getAbsolutePath() + "/MaxmindDbEnrichmentLoaderTest.mmdb.gz");    CompressionStrategies.GZIP.compress(dbPlainTextFile, dbFile);    String[] argv = { "--geo_url", "file://" + dbFile.getAbsolutePath(), "--remote_dir", remoteDir.getAbsolutePath(), "--remote_asn_dir", remoteDir.getAbsolutePath(), "--tmp_dir", tmpDir.getAbsolutePath(), "--zk_quorum", "test:2181" };    String[] otherArgs = new GenericOptionsParser(argv).getRemainingArgs();    CommandLine cli = MaxmindDbEnrichmentLoader.GeoEnrichmentOptions.parse(new PosixParser(), otherArgs);    MaxmindDbEnrichmentLoader loader = new MockMaxmindDbEnrichmentLoader();    loader.loadGeoLiteDatabase(cli);    Configuration config = new Configuration();    FileSystem fs = FileSystem.get(config);    assertTrue(fs.exists(new Path(remoteDir + "/" + dbFile.getName())));}
0
public void loader_throws_exception_on_bad_gzip_file() throws Exception
{    File dbFile = new File(remoteDir.getAbsolutePath() + "/MaxmindDbEnrichmentLoaderTest.mmdb");    dbFile.createNewFile();    String geoUrl = "file://" + dbFile.getAbsolutePath();    int numRetries = 2;    exception.expect(IllegalStateException.class);    exception.expectMessage("Unable to download geo enrichment database.");    MaxmindDbEnrichmentLoader loader = new MockMaxmindDbEnrichmentLoader();    loader.downloadGeoFile(geoUrl, tmpDir.getAbsolutePath(), numRetries);}
0
public Response getDiscovery()
{    return Response.ok(discoveryMsg, MediaType.APPLICATION_XML_TYPE).header("x-taxii-content-type", "urn:taxii.mitre.org:message:xml:1.1").build();}
0
public Response getData()
{    return Response.ok(pollMsg).type(MediaType.APPLICATION_XML_TYPE).header("x-taxii-content-type", "urn:taxii.mitre.org:message:xml:1.1").build();}
0
public Set<Class<?>> getClasses()
{    return classes;}
0
public static void start(int port) throws IOException
{        URI uri = UriBuilder.fromUri("http://localhost/").port(port).build();    server = HttpServer.create(new InetSocketAddress(uri.getPort()), 0);    HttpHandler handler = RuntimeDelegate.getInstance().createEndpoint(new ApplicationConfig(), HttpHandler.class);    server.createContext(uri.getPath(), handler);    discoveryMsg = discoveryMsg.replaceAll("PORT", "" + uri.getPort());    server.start();}
0
public static void shutdown()
{    if (server != null) {        server.stop(0);    }}
0
public static void setup() throws IOException
{    MockTaxiiService.start(8282);}
0
public static void teardown()
{    MockTaxiiService.shutdown();    MockHBaseTableProvider.clear();}
0
public void testCommandLine() throws Exception
{    Configuration conf = HBaseConfiguration.create();    String[] argv = { "-c connection.json", "-e extractor.json", "-n enrichment_config.json", "-l log4j", "-p 10", "-b 04/14/2016 12:00:00" };    String[] otherArgs = new GenericOptionsParser(conf, argv).getRemainingArgs();    CommandLine cli = TaxiiLoader.TaxiiOptions.parse(new PosixParser(), otherArgs);    Assert.assertEquals(extractorJson, TaxiiLoader.TaxiiOptions.EXTRACTOR_CONFIG.get(cli).trim());    Assert.assertEquals(connectionConfig, TaxiiLoader.TaxiiOptions.CONNECTION_CONFIG.get(cli).trim());    Assert.assertEquals(beginTime, TaxiiLoader.TaxiiOptions.BEGIN_TIME.get(cli).trim());    Assert.assertEquals(enrichmentJson, TaxiiLoader.TaxiiOptions.ENRICHMENT_CONFIG.get(cli).trim());    Assert.assertEquals(timeInteval, TaxiiLoader.TaxiiOptions.TIME_BETWEEN_POLLS.get(cli).trim());    Assert.assertEquals(log4jProperty, TaxiiLoader.TaxiiOptions.LOG4J_PROPERTIES.get(cli).trim());}
0
public void testTaxii() throws Exception
{    final MockHBaseTableProvider provider = new MockHBaseTableProvider();    final Configuration config = HBaseConfiguration.create();    Extractor extractor = new TransformFilterExtractorDecorator(new StixExtractor());    TaxiiHandler handler = new TaxiiHandler(TaxiiConnectionConfig.load(taxiiConnectionConfig), extractor, config) {        @Override        protected synchronized Table createHTable(String tableInfo) throws IOException {            return provider.addToCache("threat_intel", "cf");        }    };        handler.run();    Set<String> maliciousDomains;    {        MockHTable table = (MockHTable) provider.getTable(config, "threat_intel");        maliciousDomains = getIndicators("domainname:FQDN", table.getPutLog(), "cf");    }    Assert.assertTrue(maliciousDomains.contains("www.office-112.com"));    Assert.assertEquals(numStringsMatch(MockTaxiiService.pollMsg, "DomainNameObj:Value condition=\"Equals\""), maliciousDomains.size());    Set<String> maliciousAddresses;    {        MockHTable table = (MockHTable) provider.getTable(config, "threat_intel");        maliciousAddresses = getIndicators("address:IPV_4_ADDR", table.getPutLog(), "cf");    }    Assert.assertTrue(maliciousAddresses.contains("94.102.53.142"));    Assert.assertEquals(numStringsMatch(MockTaxiiService.pollMsg, "AddressObj:Address_Value condition=\"Equal\""), maliciousAddresses.size());    MockHBaseTableProvider.clear();        handler.run();}
0
protected synchronized Table createHTable(String tableInfo) throws IOException
{    return provider.addToCache("threat_intel", "cf");}
0
private static int numStringsMatch(String xmlBundle, String text)
{    int cnt = 0;    for (String line : Splitter.on("\n").split(xmlBundle)) {        if (line.contains(text)) {            cnt++;        }    }    return cnt;}
0
private static Set<String> getIndicators(String indicatorType, Iterable<Put> puts, String cf) throws IOException
{    EnrichmentConverter converter = new EnrichmentConverter();    Set<String> ret = new HashSet<>();    for (Put p : puts) {        LookupKV<EnrichmentKey, EnrichmentValue> kv = converter.fromPut(p, cf);        if (kv.getKey().type.equals(indicatorType)) {            ret.add(kv.getKey().indicator);        }    }    return ret;}
0
public void add(WriteSuccess<D> success)
{    this.successes.add(success);}
0
public void addSuccess(D success)
{    add(new WriteSuccess<D>(success));}
0
public void addSuccesses(List<D> successes)
{    for (D success : successes) {        addSuccess(success);    }}
0
public List<WriteSuccess<D>> getSuccesses()
{    return successes;}
0
public void add(WriteFailure<D> failure)
{    this.failures.add(failure);}
0
public void addFailure(D document, Throwable cause, String message)
{    add(new WriteFailure(document, cause, message));}
0
public List<WriteFailure<D>> getFailures()
{    return failures;}
0
public int size()
{    return documents.size();}
0
public ElasticsearchBulkDocumentWriter<D> withRefreshPolicy(WriteRequest.RefreshPolicy refreshPolicy)
{    this.refreshPolicy = refreshPolicy;    return this;}
0
private void handleBulkResponse(BulkResponse bulkResponse, List<Indexable> documents, BulkDocumentWriterResults<D> results)
{    if (bulkResponse.hasFailures()) {                for (BulkItemResponse response : bulkResponse) {            if (response.isFailed()) {                                D failed = getDocument(response.getItemId());                Exception cause = response.getFailure().getCause();                String message = response.getFailureMessage();                results.addFailure(failed, cause, message);            } else {                                D success = getDocument(response.getItemId());                success.setDocumentID(response.getResponse().getId());                results.addSuccess(success);            }        }    } else {                for (Indexable success : documents) {            results.addSuccess(success.document);        }    }}
0
private D getDocument(int index)
{    return documents.get(index).document;}
0
public static void main(String[] args)
{    if (args.length != 2) {        throw new RuntimeException("Expects 'input' and 'output' file arguments.");    }    final String inPath = args[0];    final String outPath = args[1];    try {        new ElasticsearchImportExport().bulkify(Paths.get(inPath), Paths.get(outPath));    } catch (IOException e) {        e.printStackTrace();        System.exit(1);    }    System.exit(0);}
0
public void bulkify(Path input, Path output) throws IOException
{    List<String> outRecs = new ArrayList<String>();    try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(input.toFile()), StandardCharsets.UTF_8))) {        String line;        while ((line = br.readLine()) != null) {            Map<String, Object> inDoc = JSONUtils.INSTANCE.load(line, JSONUtils.MAP_SUPPLIER);            Object id = inDoc.get("_id");            Object type = inDoc.get("_type");            String createRaw = String.format("{ \"create\" : { \"_id\": \"%s\", \"_type\": \"%s\" } }", id, type);            String outData = JSONUtils.INSTANCE.toJSON(inDoc.get("_source"), false);            outRecs.add(createRaw);            outRecs.add(outData);        }    }    try (BufferedWriter br = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(output.toFile()), StandardCharsets.UTF_8))) {        for (String line : outRecs) {            br.write(line);            br.write(System.lineSeparator());        }    }}
0
public D getDocument()
{    return document;}
0
public Throwable getCause()
{    return cause;}
0
public String getMessage()
{    return message;}
0
public D getDocument()
{    return document;}
0
public RestClient getLowLevelClient()
{    return lowLevelClient;}
0
public RestHighLevelClient getHighLevelClient()
{    return highLevelClient;}
0
public void close() throws IOException
{    if (lowLevelClient != null) {        lowLevelClient.close();    }}
0
public void putMapping(String index, String mappingType, String mapping) throws IOException
{    HttpEntity entity = new StringEntity(mapping);    Response response = lowLevelClient.performRequest("PUT", "/" + index + "/_mapping/" + mappingType, Collections.emptyMap(), entity);    if (response.getStatusLine().getStatusCode() != 200) {        String responseStr = IOUtils.toString(response.getEntity().getContent());        throw new IllegalStateException("Got a " + response.getStatusLine().getStatusCode() + " due to " + responseStr);    }}
0
public String[] getIndices() throws IOException
{    Response response = lowLevelClient.performRequest("GET", "/_cat/indices");    if (response.getStatusLine().getStatusCode() == 200) {        String responseStr = IOUtils.toString(response.getEntity().getContent());        List<String> indices = new ArrayList<>();        for (String line : Splitter.on("\n").split(responseStr)) {            Iterable<String> splits = Splitter.on(" ").split(line.replaceAll("\\s+", " ").trim());            if (Iterables.size(splits) > 3) {                String index = Iterables.get(splits, 2, "");                if (!StringUtils.isEmpty(index)) {                    indices.add(index.trim());                }            }        }        String[] ret = new String[indices.size()];        ret = indices.toArray(ret);        return ret;    }    return null;}
0
public Map<String, FieldMapping> getMappingByIndex(String[] indices) throws IOException
{    Map<String, FieldMapping> ret = new HashMap<>();    String indicesCsv = Joiner.on(",").join(indices);    Response response = lowLevelClient.performRequest("GET", "/" + indicesCsv + "/_mapping");    if (response.getStatusLine().getStatusCode() == 200) {        String responseStr = IOUtils.toString(response.getEntity().getContent());        Map<String, Object> indexToMapping = JSONUtils.INSTANCE.load(responseStr, JSONUtils.MAP_SUPPLIER);        for (Map.Entry<String, Object> index2Mapping : indexToMapping.entrySet()) {            String index = index2Mapping.getKey();            Map<String, Object> mappings = getInnerMap((Map<String, Object>) index2Mapping.getValue(), "mappings");            if (mappings.size() > 0) {                Map.Entry<String, Object> docMap = Iterables.getFirst(mappings.entrySet(), null);                if (docMap != null) {                    Map<String, Object> fieldPropertiesMap = getInnerMap((Map<String, Object>) docMap.getValue(), "properties");                    if (fieldPropertiesMap != null) {                        FieldMapping mapping = new FieldMapping();                        for (Map.Entry<String, Object> field2PropsKV : fieldPropertiesMap.entrySet()) {                            if (field2PropsKV.getValue() != null) {                                FieldProperties props = new FieldProperties((Map<String, Object>) field2PropsKV.getValue());                                mapping.put(field2PropsKV.getKey(), props);                            }                        }                        ret.put(index, mapping);                    }                }            }        }    }    return ret;}
0
private Map<String, Object> getInnerMap(Map<String, Object> outerMap, String... keys)
{    Map<String, Object> ret = outerMap;    if (keys.length == 0) {        return outerMap;    }    for (String key : keys) {        ret = (Map<String, Object>) ret.get(key);        if (ret == null) {            return ret;        }    }    return ret;}
0
public static ElasticsearchClient create(Map<String, Object> globalConfig)
{    ElasticsearchClientConfig esClientConfig = new ElasticsearchClientConfig(getEsSettings(globalConfig));    HttpHost[] httpHosts = getHttpHosts(globalConfig, esClientConfig.getConnectionScheme());    RestClientBuilder builder = RestClient.builder(httpHosts);    builder.setRequestConfigCallback(reqConfigBuilder -> {                        reqConfigBuilder.setConnectTimeout(esClientConfig.getConnectTimeoutMillis());        reqConfigBuilder.setSocketTimeout(esClientConfig.getSocketTimeoutMillis());        return reqConfigBuilder;    });    builder.setMaxRetryTimeoutMillis(esClientConfig.getMaxRetryTimeoutMillis());    builder.setHttpClientConfigCallback(clientBuilder -> {        clientBuilder.setDefaultIOReactorConfig(getIOReactorConfig(esClientConfig));        clientBuilder.setDefaultCredentialsProvider(getCredentialsProvider(esClientConfig));        clientBuilder.setSSLContext(getSSLContext(esClientConfig));        return clientBuilder;    });    RestClient lowLevelClient = builder.build();    RestHighLevelClient client = new RestHighLevelClient(lowLevelClient);    return new ElasticsearchClient(lowLevelClient, client);}
0
private static Map<String, Object> getEsSettings(Map<String, Object> globalConfig)
{    return (Map<String, Object>) globalConfig.getOrDefault(ES_SETTINGS_KEY, new HashMap<>());}
0
private static HttpHost[] getHttpHosts(Map<String, Object> globalConfiguration, String scheme)
{    List<HostnamePort> hps = ElasticsearchUtils.getIps(globalConfiguration);    HttpHost[] httpHosts = new HttpHost[hps.size()];    int i = 0;    for (HostnamePort hp : hps) {        httpHosts[i++] = new HttpHost(hp.hostname, hp.port, scheme);    }    return httpHosts;}
0
private static IOReactorConfig getIOReactorConfig(ElasticsearchClientConfig esClientConfig)
{    if (esClientConfig.getNumClientConnectionThreads().isPresent()) {        Integer numThreads = esClientConfig.getNumClientConnectionThreads().get();                return IOReactorConfig.custom().setIoThreadCount(numThreads).build();    } else {        return IOReactorConfig.DEFAULT;    }}
1
private static CredentialsProvider getCredentialsProvider(ElasticsearchClientConfig esClientConfig)
{    Optional<Entry<String, String>> credentials = esClientConfig.getCredentials();    if (credentials.isPresent()) {                final CredentialsProvider credentialsProvider = new BasicCredentialsProvider();        UsernamePasswordCredentials upcredentials = new UsernamePasswordCredentials(credentials.get().getKey(), credentials.get().getValue());        credentialsProvider.setCredentials(AuthScope.ANY, upcredentials);        return credentialsProvider;    } else {                return null;    }}
1
private static SSLContext getSSLContext(ElasticsearchClientConfig esClientConfig)
{    if (esClientConfig.isSSLEnabled()) {                if (!esClientConfig.getKeyStorePath().isPresent()) {            throw new IllegalStateException("KeyStore path must be provided for SSL connection.");        }        Optional<String> optKeyStorePass = esClientConfig.getKeyStorePassword();        char[] keyStorePass = optKeyStorePass.map(String::toCharArray).orElse(null);        KeyStore trustStore = getStore(esClientConfig.getKeyStoreType(), esClientConfig.getKeyStorePath().get(), keyStorePass);        try {            SSLContextBuilder sslBuilder = SSLContexts.custom().loadTrustMaterial(trustStore, null);            return sslBuilder.build();        } catch (NoSuchAlgorithmException | KeyStoreException | KeyManagementException e) {            throw new IllegalStateException("Unable to load truststore.", e);        }    }    return null;}
1
private static KeyStore getStore(String type, Path path, char[] pass)
{    KeyStore store;    try {        store = KeyStore.getInstance(type);    } catch (KeyStoreException e) {        throw new IllegalStateException("Unable to get keystore type '" + type + "'", e);    }    try (InputStream is = Files.newInputStream(path)) {        store.load(is, pass);    } catch (IOException | NoSuchAlgorithmException | CertificateException e) {        throw new IllegalStateException("Unable to load keystore from path '" + path + "'", e);    }    return store;}
0
public Integer getConnectTimeoutMillis()
{    return ElasticsearchClientOptions.CONNECTION_TIMEOUT_MILLIS.getOrDefault(this, Integer.class, ONE_SECONDS_IN_MILLIS);}
0
public Integer getSocketTimeoutMillis()
{    return ElasticsearchClientOptions.SOCKET_TIMEOUT_MILLIS.getOrDefault(this, Integer.class, THIRTY_SECONDS_IN_MILLIS);}
0
public Integer getMaxRetryTimeoutMillis()
{    return ElasticsearchClientOptions.MAX_RETRY_TIMEOUT_MILLIS.getOrDefault(this, Integer.class, THIRTY_SECONDS_IN_MILLIS);}
0
public Optional<Map.Entry<String, String>> getCredentials()
{    if (ElasticsearchClientOptions.XPACK_PASSWORD_FILE.containsOption(this)) {        if (!ElasticsearchClientOptions.XPACK_USERNAME.containsOption(this) || StringUtils.isEmpty(ElasticsearchClientOptions.XPACK_USERNAME.get(this, String.class))) {            throw new IllegalArgumentException("X-pack username is required when password supplied and cannot be empty");        }        String user = ElasticsearchClientOptions.XPACK_USERNAME.get(this, String.class);        String password = getPasswordFromFile(ElasticsearchClientOptions.XPACK_PASSWORD_FILE.get(this, String.class));        if (user != null && password != null) {            return Optional.of(new AbstractMap.SimpleImmutableEntry<String, String>(user, password));        }    }    return Optional.empty();}
0
private static String getPasswordFromFile(String hdfsPath)
{    List<String> lines = readLines(hdfsPath);    if (lines.size() == 0) {        throw new IllegalArgumentException(format("No password found in file '%s'", hdfsPath));    }    return lines.get(0);}
0
private static List<String> readLines(String hdfsPath)
{    try {        return HDFSUtils.readFile(hdfsPath);    } catch (IOException e) {        throw new IllegalStateException(format("Unable to read XPack password file from HDFS location '%s'", hdfsPath), e);    }}
0
public boolean isSSLEnabled()
{    return ElasticsearchClientOptions.SSL_ENABLED.getOrDefault(this, Boolean.class, false);}
0
public String getConnectionScheme()
{    return isSSLEnabled() ? "https" : "http";}
0
public Optional<Integer> getNumClientConnectionThreads()
{    if (ElasticsearchClientOptions.NUM_CLIENT_CONNECTION_THREADS.containsOption(this)) {        return Optional.of(ElasticsearchClientOptions.NUM_CLIENT_CONNECTION_THREADS.get(this, Integer.class));    }    return Optional.empty();}
0
public String getKeyStoreType()
{    if (ElasticsearchClientOptions.KEYSTORE_TYPE.containsOption(this) && StringUtils.isNotEmpty(ElasticsearchClientOptions.KEYSTORE_TYPE.get(this, String.class))) {        return ElasticsearchClientOptions.KEYSTORE_TYPE.get(this, String.class);    }    return DEFAULT_KEYSTORE_TYPE;}
0
public Optional<String> getKeyStorePassword()
{    if (ElasticsearchClientOptions.KEYSTORE_PASSWORD_FILE.containsOption(this)) {        String password = getPasswordFromFile(ElasticsearchClientOptions.KEYSTORE_PASSWORD_FILE.get(this, String.class));        if (StringUtils.isNotEmpty(password)) {            return Optional.of(password);        }    }    return Optional.empty();}
0
public Optional<Path> getKeyStorePath()
{    if (ElasticsearchClientOptions.KEYSTORE_PATH.containsOption(this)) {        return Optional.of(Paths.get(ElasticsearchClientOptions.KEYSTORE_PATH.get(this, String.class)));    }    return Optional.empty();}
0
public String getKey()
{    return key;}
0
public static void printOptions()
{    String newLine = "";    for (ElasticsearchClientOptions opt : ElasticsearchClientOptions.values()) {        System.out.print(newLine);        System.out.print(opt.getKey());        newLine = System.lineSeparator();    }}
0
private FieldType toFieldType(String type)
{    return elasticsearchTypeMap.getOrDefault(type, FieldType.OTHER);}
0
public AccessConfig getAccessConfig()
{    return accessConfig;}
0
public void setAccessConfig(AccessConfig accessConfig)
{    this.accessConfig = accessConfig;}
0
public synchronized void init(AccessConfig config)
{    if (this.client == null) {        this.client = ElasticsearchClientFactory.create(config.getGlobalConfigSupplier().get());        this.accessConfig = config;        this.columnMetadataDao = new ElasticsearchColumnMetadataDao(this.client);        this.requestSubmitter = new ElasticsearchRequestSubmitter(this.client);        this.searchDao = new ElasticsearchSearchDao(client, accessConfig, columnMetadataDao, requestSubmitter);        this.retrieveLatestDao = new ElasticsearchRetrieveLatestDao(client);        this.updateDao = new ElasticsearchUpdateDao(client, accessConfig, retrieveLatestDao).withRefreshPolicy(refreshPolicy);    }    if (columnMetadataDao == null) {        throw new IllegalArgumentException("No ColumnMetadataDao available");    }    if (requestSubmitter == null) {        throw new IllegalArgumentException("No ElasticsearchRequestSubmitter available");    }}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    return this.searchDao.search(searchRequest);}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    return this.searchDao.group(groupRequest);}
0
public Document getLatest(final String guid, final String sensorType) throws IOException
{    return retrieveLatestDao.getLatest(guid, sensorType);}
0
public Iterable<Document> getAllLatest(final List<GetRequest> getRequests) throws IOException
{    return retrieveLatestDao.getAllLatest(getRequests);}
0
public Document update(Document update, Optional<String> index) throws IOException
{    return updateDao.update(update, index);}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) throws IOException
{    return updateDao.batchUpdate(updates);}
0
public Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    return updateDao.patch(retrieveLatestDao, request, timestamp);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    return updateDao.addCommentToAlert(request);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    return updateDao.removeCommentFromAlert(request);}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    return this.columnMetadataDao.getColumnMetadata(indices);}
0
public Optional<Map<String, Object>> getLatestResult(GetRequest request) throws IOException
{    return retrieveLatestDao.getLatestResult(request);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return this.updateDao.addCommentToAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return this.updateDao.removeCommentFromAlert(request, latest);}
0
public ElasticsearchDao withRefreshPolicy(WriteRequest.RefreshPolicy refreshPolicy)
{    this.refreshPolicy = refreshPolicy;    return this;}
0
protected Optional<String> getIndexName(String guid, String sensorType) throws IOException
{    return updateDao.findIndexNameByGUID(guid, sensorType);}
0
protected SearchResponse search(SearchRequest request, QueryBuilder queryBuilder) throws InvalidSearchException
{    return searchDao.search(request, queryBuilder);}
0
protected GroupResponse group(GroupRequest groupRequest, QueryBuilder queryBuilder) throws InvalidSearchException
{    return searchDao.group(groupRequest, queryBuilder);}
0
public ElasticsearchClient getClient()
{    return this.client;}
0
public void init(IndexDao indexDao, Optional<String> threatSort)
{    if (indexDao instanceof MultiIndexDao) {        this.indexDao = indexDao;        MultiIndexDao multiIndexDao = (MultiIndexDao) indexDao;        for (IndexDao childDao : multiIndexDao.getIndices()) {            if (childDao instanceof ElasticsearchDao) {                this.elasticsearchDao = (ElasticsearchDao) childDao;            }        }    } else if (indexDao instanceof ElasticsearchDao) {        this.indexDao = indexDao;        this.elasticsearchDao = (ElasticsearchDao) indexDao;    } else {        throw new IllegalArgumentException("Need an ElasticsearchDao when using ElasticsearchMetaAlertDao");    }    if (threatSort.isPresent()) {        this.threatSort = threatSort.get();    }    Supplier<Map<String, Object>> globalConfigSupplier = () -> new HashMap<>();    if (elasticsearchDao != null && elasticsearchDao.getAccessConfig() != null) {        globalConfigSupplier = elasticsearchDao.getAccessConfig().getGlobalConfigSupplier();    }    MetaAlertConfig config = new MetaAlertConfig(metaAlertsIndex, this.threatSort, globalConfigSupplier) {        @Override        protected String getDefaultThreatTriageField() {            return THREAT_TRIAGE_FIELD;        }        @Override        protected String getDefaultSourceTypeField() {            return SOURCE_TYPE_FIELD;        }    };    this.metaAlertSearchDao = new ElasticsearchMetaAlertSearchDao(elasticsearchDao, config, pageSize);    this.metaAlertRetrieveLatestDao = new ElasticsearchMetaAlertRetrieveLatestDao(indexDao);    this.metaAlertUpdateDao = new ElasticsearchMetaAlertUpdateDao(elasticsearchDao, metaAlertRetrieveLatestDao, config, pageSize);}
0
protected String getDefaultThreatTriageField()
{    return THREAT_TRIAGE_FIELD;}
0
protected String getDefaultSourceTypeField()
{    return SOURCE_TYPE_FIELD;}
0
public void init(AccessConfig config)
{}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    return indexDao.getColumnMetadata(indices);}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    return indexDao.getLatest(guid, sensorType);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    return indexDao.getAllLatest(getRequests);}
0
public SearchResponse getAllMetaAlertsForAlert(String guid) throws InvalidSearchException, IOException
{    return metaAlertSearchDao.getAllMetaAlertsForAlert(guid);}
0
public Document createMetaAlert(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    return metaAlertUpdateDao.createMetaAlert(request);}
0
public Document addAlertsToMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.addAlertsToMetaAlert(metaAlertGuid, alertRequests);}
0
public Document removeAlertsFromMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.removeAlertsFromMetaAlert(metaAlertGuid, alertRequests);}
0
public Document updateMetaAlertStatus(String metaAlertGuid, MetaAlertStatus status) throws IOException
{    return metaAlertUpdateDao.updateMetaAlertStatus(metaAlertGuid, status);}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    return metaAlertSearchDao.search(searchRequest);}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    return metaAlertSearchDao.group(groupRequest);}
0
public Document update(Document update, Optional<String> index) throws IOException
{    return metaAlertUpdateDao.update(update, index);}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates)
{    return metaAlertUpdateDao.batchUpdate(updates);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    return indexDao.addCommentToAlert(request);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    return indexDao.removeCommentFromAlert(request);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return indexDao.addCommentToAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return indexDao.removeCommentFromAlert(request, latest);}
0
public Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    return metaAlertUpdateDao.patch(retrieveLatestDao, request, timestamp);}
0
public void setPageSize(int pageSize)
{    this.pageSize = pageSize;}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    return retrieveLatestDao.getLatest(guid, sensorType);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    return retrieveLatestDao.getAllLatest(getRequests);}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{        QueryBuilder qb = constantScoreQuery(boolQuery().must(boolQuery().should(new QueryStringQueryBuilder(searchRequest.getQuery())).should(nestedQuery(MetaAlertConstants.ALERT_FIELD, new QueryStringQueryBuilder(searchRequest.getQuery()), ScoreMode.None))).must(boolQuery().should(termQuery(MetaAlertConstants.STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString())).should(boolQuery().mustNot(existsQuery(MetaAlertConstants.STATUS_FIELD)))).mustNot(existsQuery(MetaAlertConstants.METAALERT_FIELD)));    return elasticsearchDao.search(searchRequest, qb);}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{        QueryBuilder qb = QueryBuilders.boolQuery().must(new QueryStringQueryBuilder(groupRequest.getQuery())).mustNot(existsQuery(MetaAlertConstants.METAALERT_FIELD));    return elasticsearchDao.group(groupRequest, qb);}
0
public SearchResponse getAllMetaAlertsForAlert(String guid) throws InvalidSearchException, IOException
{    if (guid == null || guid.trim().isEmpty()) {        throw new InvalidSearchException("Guid cannot be empty");    }        QueryBuilder qb = boolQuery().must(nestedQuery(MetaAlertConstants.ALERT_FIELD, boolQuery().must(termQuery(MetaAlertConstants.ALERT_FIELD + "." + GUID, guid)), ScoreMode.None).innerHit(new InnerHitBuilder())).must(termQuery(MetaAlertConstants.STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString()));    return queryAllResults(elasticsearchDao.getClient().getHighLevelClient(), qb, config.getMetaAlertIndex(), pageSize);}
0
public Document createMetaAlert(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    List<GetRequest> alertRequests = request.getAlerts();    if (request.getAlerts().isEmpty()) {        throw new InvalidCreateException("MetaAlertCreateRequest must contain alerts");    }    if (request.getGroups().isEmpty()) {        throw new InvalidCreateException("MetaAlertCreateRequest must contain UI groups");    }        Iterable<Document> alerts = retrieveLatestDao.getAllLatest(alertRequests);    Document metaAlert = buildCreateDocument(alerts, request.getGroups(), MetaAlertConstants.ALERT_FIELD);    MetaScores.calculateMetaScores(metaAlert, getConfig().getThreatTriageField(), getConfig().getThreatSort());        metaAlert.getDocument().put(getConfig().getSourceTypeField(), MetaAlertConstants.METAALERT_TYPE);        Map<Document, Optional<String>> updates = new HashMap<>();    updates.put(metaAlert, Optional.of(getConfig().getMetaAlertIndex()));    try {                        Map<String, Optional<String>> guidToIndices = alertRequests.stream().collect(Collectors.toMap(GetRequest::getGuid, GetRequest::getIndex));        Map<String, String> guidToSensorTypes = alertRequests.stream().collect(Collectors.toMap(GetRequest::getGuid, GetRequest::getSensorType));        for (Document alert : alerts) {            if (addMetaAlertToAlert(metaAlert.getGuid(), alert)) {                                Optional<String> index = guidToIndices.get(alert.getGuid());                if (!index.isPresent()) {                                        index = elasticsearchDao.getIndexName(alert.getGuid(), guidToSensorTypes.get(alert.getGuid()));                    if (!index.isPresent()) {                        throw new IllegalArgumentException("Could not find index for " + alert.getGuid());                    }                }                updates.put(alert, index);            }        }                update(updates);        return metaAlert;    } catch (IOException ioe) {        throw new InvalidCreateException("Unable to create meta alert", ioe);    }}
0
public Document update(Document update, Optional<String> index) throws IOException
{    if (MetaAlertConstants.METAALERT_TYPE.equals(update.getSensorType())) {                throw new UnsupportedOperationException("Meta alerts cannot be directly updated");    } else {        Map<Document, Optional<String>> updates = new HashMap<>();        updates.put(update, index);        try {                                    SearchResponse response = getMetaAlertsForAlert(update.getGuid());            Collection<Document> metaAlerts = response.getResults().stream().map(result -> toDocument(result, update.getTimestamp())).collect(Collectors.toList());                        for (Document metaAlert : metaAlerts) {                replaceAlertInMetaAlert(metaAlert, update);                updates.put(metaAlert, Optional.of(METAALERTS_INDEX));            }        } catch (IndexNotFoundException e) {            List<String> indicesNotFound = e.getMetadata(INDEX_NOT_FOUND_INDICES_KEY);                        if (indicesNotFound.size() != 1 || !METAALERTS_INDEX.equals(indicesNotFound.get(0))) {                throw e;            }        }                elasticsearchDao.batchUpdate(updates);        return update;    }}
0
private Document toDocument(SearchResult result, Long timestamp)
{    Document document = Document.fromJSON(result.getSource());    document.setTimestamp(timestamp);    document.setDocumentID(result.getId());    return document;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    return getUpdateDao().addCommentToAlert(request);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    return getUpdateDao().removeCommentFromAlert(request);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return getUpdateDao().addCommentToAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return getUpdateDao().removeCommentFromAlert(request, latest);}
0
protected SearchResponse getMetaAlertsForAlert(String alertGuid) throws IOException
{    QueryBuilder qb = boolQuery().must(nestedQuery(MetaAlertConstants.ALERT_FIELD, boolQuery().must(termQuery(MetaAlertConstants.ALERT_FIELD + "." + Constants.GUID, alertGuid)), ScoreMode.None).innerHit(new InnerHitBuilder())).must(termQuery(MetaAlertConstants.STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString()));    return ElasticsearchUtils.queryAllResults(elasticsearchDao.getClient().getHighLevelClient(), qb, getConfig().getMetaAlertIndex(), pageSize);}
0
protected void replaceAlertInMetaAlert(Document metaAlert, Document alert)
{    boolean metaAlertUpdated = removeAlertsFromMetaAlert(metaAlert, Collections.singleton(alert.getGuid()));    if (metaAlertUpdated) {        addAlertsToMetaAlert(metaAlert, Collections.singleton(alert));    }}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    Optional<Document> doc = searchByGuid(guid, sensorType, hit -> toDocument(hit));    return doc.orElse(null);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    Collection<String> guids = new HashSet<>();    Collection<String> sensorTypes = new HashSet<>();    for (GetRequest getRequest : getRequests) {        guids.add(getRequest.getGuid());        sensorTypes.add(getRequest.getSensorType());    }    List<Document> documents = searchByGuids(guids, sensorTypes, hit -> toDocument(hit));    return documents;}
0
 Optional<T> searchByGuid(String guid, String sensorType, Function<SearchHit, Optional<T>> callback) throws IOException
{    Collection<String> sensorTypes = sensorType != null ? Collections.singleton(sensorType) : null;    List<T> results = searchByGuids(Collections.singleton(guid), sensorTypes, callback);    if (results.size() > 0) {        return Optional.of(results.get(0));    } else {        return Optional.empty();    }}
0
 List<T> searchByGuids(Collection<String> guids, Collection<String> sensorTypes, Function<SearchHit, Optional<T>> callback) throws IOException
{    if (guids == null || guids.isEmpty()) {        return Collections.emptyList();    }            BoolQueryBuilder guidQuery = boolQuery().must(termsQuery(Constants.GUID, guids));        BoolQueryBuilder sensorQuery = boolQuery();    sensorTypes.forEach(sensorType -> sensorQuery.should(typeQuery(sensorType + "_doc")));        BoolQueryBuilder query = boolQuery().must(guidQuery).must(sensorQuery);        SearchResponse response;    try {        SearchSourceBuilder source = new SearchSourceBuilder().query(query).size(guids.size());        SearchRequest request = new SearchRequest().source(source);        response = submitter.submitSearch(request);    } catch (InvalidSearchException e) {        throw new IOException(e);    }        List<T> results = new ArrayList<>();    for (SearchHit hit : response.getHits()) {        Optional<T> result = callback.apply(hit);        result.ifPresent(r -> results.add(r));    }    return results;}
0
private Optional<Document> toDocument(SearchHit hit)
{    Document document = Document.fromJSON(hit.getSource());    document.setDocumentID(hit.getId());    return Optional.of(document);}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    if (searchRequest.getQuery() == null) {        throw new InvalidSearchException("Search query is invalid: null");    }    return search(searchRequest, new QueryStringQueryBuilder(searchRequest.getQuery()));}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    return group(groupRequest, new QueryStringQueryBuilder(groupRequest.getQuery()));}
0
protected SearchResponse search(SearchRequest request, QueryBuilder queryBuilder) throws InvalidSearchException
{    org.elasticsearch.action.search.SearchRequest esRequest;    org.elasticsearch.action.search.SearchResponse esResponse;    if (client == null) {        throw new InvalidSearchException("Uninitialized Dao!  You must call init() prior to use.");    }    if (request.getSize() > accessConfig.getMaxSearchResults()) {        throw new InvalidSearchException("Search result size must be less than " + accessConfig.getMaxSearchResults());    }    esRequest = buildSearchRequest(request, queryBuilder);    esResponse = requestSubmitter.submitSearch(esRequest);    return buildSearchResponse(request, esResponse);}
0
private org.elasticsearch.search.sort.SortOrder getElasticsearchSortOrder(org.apache.metron.indexing.dao.search.SortOrder sortOrder)
{    return sortOrder == org.apache.metron.indexing.dao.search.SortOrder.DESC ? org.elasticsearch.search.sort.SortOrder.DESC : org.elasticsearch.search.sort.SortOrder.ASC;}
0
private String getFacetAggregationName(String field)
{    return String.format("%s_count", field);}
0
private String[] wildcardIndices(List<String> indices)
{    if (indices == null)        return new String[] {};    return indices.stream().map(index -> String.format("%s%s*", index, INDEX_NAME_DELIMITER)).toArray(value -> new String[indices.size()]);}
0
private SearchResult getSearchResult(SearchHit searchHit, List<String> fields)
{    SearchResult searchResult = new SearchResult();    searchResult.setId(searchHit.getId());    Map<String, Object> source;    if (fields != null) {        Map<String, Object> resultSourceAsMap = searchHit.getSourceAsMap();        source = new HashMap<>();        fields.forEach(field -> {            source.put(field, resultSourceAsMap.get(field));        });    } else {        source = searchHit.getSource();    }    searchResult.setSource(source);    searchResult.setScore(searchHit.getScore());    searchResult.setIndex(searchHit.getIndex());    return searchResult;}
0
private Map<String, Map<String, Long>> getFacetCounts(List<String> fields, Aggregations aggregations, Map<String, FieldType> commonColumnMetadata)
{    Map<String, Map<String, Long>> fieldCounts = new HashMap<>();    for (String field : fields) {        Map<String, Long> valueCounts = new HashMap<>();        if (aggregations != null) {            Aggregation aggregation = aggregations.get(getFacetAggregationName(field));            if (aggregation instanceof Terms) {                Terms terms = (Terms) aggregation;                terms.getBuckets().stream().forEach(bucket -> valueCounts.put(formatKey(bucket.getKey(), commonColumnMetadata.get(field)), bucket.getDocCount()));            }        }        fieldCounts.put(field, valueCounts);    }    return fieldCounts;}
0
private String formatKey(Object key, FieldType type)
{    if (FieldType.IP.equals(type) && key instanceof Long) {        return LegacyIpFieldMapper.longToIp((Long) key);    } else if (FieldType.BOOLEAN.equals(type)) {        return (Long) key == 1 ? "true" : "false";    } else {        return key.toString();    }}
0
protected GroupResponse group(GroupRequest groupRequest, QueryBuilder queryBuilder) throws InvalidSearchException
{    org.elasticsearch.action.search.SearchRequest esRequest;    org.elasticsearch.action.search.SearchResponse esResponse;    if (client == null) {        throw new InvalidSearchException("Uninitialized Dao!  You must call init() prior to use.");    }    if (groupRequest.getGroups() == null || groupRequest.getGroups().size() == 0) {        throw new InvalidSearchException("At least 1 group must be provided.");    }    esRequest = buildGroupRequest(groupRequest, queryBuilder);    esResponse = requestSubmitter.submitSearch(esRequest);    GroupResponse response = buildGroupResponse(groupRequest, esResponse);    return response;}
0
private org.elasticsearch.action.search.SearchRequest buildGroupRequest(GroupRequest groupRequest, QueryBuilder queryBuilder)
{        TermsAggregationBuilder groups = getGroupsTermBuilder(groupRequest, 0);    final SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder().query(queryBuilder).aggregation(groups);        String[] indices = wildcardIndices(groupRequest.getIndices());    return new org.elasticsearch.action.search.SearchRequest().indices(indices).source(searchSourceBuilder);}
0
private TermsAggregationBuilder getGroupsTermBuilder(GroupRequest groupRequest, int index)
{    List<Group> groups = groupRequest.getGroups();    Group group = groups.get(index);    String aggregationName = getGroupByAggregationName(group.getField());    TermsAggregationBuilder termsBuilder = AggregationBuilders.terms(aggregationName);    termsBuilder.field(group.getField()).size(accessConfig.getMaxSearchGroups()).order(getElasticsearchGroupOrder(group.getOrder()));    if (index < groups.size() - 1) {        termsBuilder.subAggregation(getGroupsTermBuilder(groupRequest, index + 1));    }    Optional<String> scoreField = groupRequest.getScoreField();    if (scoreField.isPresent()) {        SumAggregationBuilder scoreSumAggregationBuilder = AggregationBuilders.sum(getSumAggregationName(scoreField.get())).field(scoreField.get()).missing(0);        termsBuilder.subAggregation(scoreSumAggregationBuilder);    }    return termsBuilder;}
0
private String getGroupByAggregationName(String field)
{    return String.format("%s_group", field);}
0
private String getSumAggregationName(String field)
{    return String.format("%s_score", field);}
0
private Order getElasticsearchGroupOrder(GroupOrder groupOrder)
{    if (groupOrder.getGroupOrderType() == GroupOrderType.TERM) {        return groupOrder.getSortOrder() == SortOrder.ASC ? Order.term(true) : Order.term(false);    } else {        return groupOrder.getSortOrder() == SortOrder.ASC ? Order.count(true) : Order.count(false);    }}
0
private GroupResponse buildGroupResponse(GroupRequest groupRequest, org.elasticsearch.action.search.SearchResponse response) throws InvalidSearchException
{        Map<String, FieldType> commonColumnMetadata;    try {        commonColumnMetadata = columnMetadataDao.getColumnMetadata(groupRequest.getIndices());    } catch (IOException e) {        throw new InvalidSearchException(String.format("Could not get common column metadata for indices %s", Arrays.toString(groupRequest.getIndices().toArray())));    }    GroupResponse groupResponse = new GroupResponse();    groupResponse.setGroupedBy(groupRequest.getGroups().get(0).getField());    groupResponse.setGroupResults(getGroupResults(groupRequest, 0, response.getAggregations(), commonColumnMetadata));    return groupResponse;}
0
private List<GroupResult> getGroupResults(GroupRequest groupRequest, int index, Aggregations aggregations, Map<String, FieldType> commonColumnMetadata)
{    List<Group> groups = groupRequest.getGroups();    String field = groups.get(index).getField();    List<GroupResult> searchResultGroups = new ArrayList<>();    if (aggregations != null) {        Terms terms = aggregations.get(getGroupByAggregationName(field));        for (Bucket bucket : terms.getBuckets()) {            GroupResult groupResult = new GroupResult();            groupResult.setKey(formatKey(bucket.getKey(), commonColumnMetadata.get(field)));            groupResult.setTotal(bucket.getDocCount());            Optional<String> scoreField = groupRequest.getScoreField();            if (scoreField.isPresent()) {                Sum score = bucket.getAggregations().get(getSumAggregationName(scoreField.get()));                groupResult.setScore(score.getValue());            }            if (index < groups.size() - 1) {                groupResult.setGroupedBy(groups.get(index + 1).getField());                groupResult.setGroupResults(getGroupResults(groupRequest, index + 1, bucket.getAggregations(), commonColumnMetadata));            }            searchResultGroups.add(groupResult);        }    }    return searchResultGroups;}
0
public Document update(Document update, Optional<String> index) throws IOException
{    Map<Document, Optional<String>> updates = new HashMap<>();    updates.put(update, index);    Map<Document, Optional<String>> results = batchUpdate(updates);    return results.keySet().iterator().next();}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) throws IOException
{    Map<String, Object> globalConfig = accessConfig.getGlobalConfigSupplier().get();    String indexPostfix = ElasticsearchUtils.getIndexFormat(globalConfig).format(new Date());    for (Map.Entry<Document, Optional<String>> entry : updates.entrySet()) {        Document document = entry.getKey();        Optional<String> optionalIndex = entry.getValue();        String indexName = optionalIndex.orElse(getIndexName(document, indexPostfix));        documentWriter.addDocument(document, indexName);    }        BulkDocumentWriterResults<Document> results = documentWriter.write();    int failures = results.getFailures().size();    if (failures > 0) {        int successes = results.getSuccesses().size();        String msg = format("Failed to update all documents; %d successes, %d failures", successes, failures);                        for (WriteFailure<Document> failure : results.getFailures()) {                    }                Throwable cause = results.getFailures().get(0).getCause();        throw new IOException(msg, cause);    }    return updates;}
1
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = retrieveLatestDao.getLatest(request.getGuid(), request.getSensorType());    return addCommentToAlert(request, latest);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to add comment. Document with guid %s cannot be found.", request.getGuid()));    }    List<Map<String, Object>> commentsField = (List<Map<String, Object>>) latest.getDocument().getOrDefault(COMMENTS_FIELD, new ArrayList<>());    List<Map<String, Object>> originalComments = new ArrayList<>(commentsField);    originalComments.add(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()).asMap());    Document newVersion = new Document(latest);    newVersion.getDocument().put(COMMENTS_FIELD, originalComments);    return update(newVersion, Optional.empty());}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = retrieveLatestDao.getLatest(request.getGuid(), request.getSensorType());    return removeCommentFromAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s cannot be found.", request.getGuid()));    }    List<Map<String, Object>> commentMap = (List<Map<String, Object>>) latest.getDocument().get(COMMENTS_FIELD);        if (commentMap == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s has no comments.", request.getGuid()));    }    List<Map<String, Object>> originalComments = new ArrayList<>(commentMap);    List<AlertComment> alertComments = new ArrayList<>();    for (Map<String, Object> commentRaw : originalComments) {        alertComments.add(new AlertComment(commentRaw));    }    alertComments.remove(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()));    List<Map<String, Object>> commentsFinal = alertComments.stream().map(AlertComment::asMap).collect(Collectors.toList());    Document newVersion = new Document(latest);    if (commentsFinal.size() > 0) {        newVersion.getDocument().put(COMMENTS_FIELD, commentsFinal);        update(newVersion, Optional.empty());    } else {        newVersion.getDocument().remove(COMMENTS_FIELD);    }    return update(newVersion, Optional.empty());}
0
public ElasticsearchUpdateDao withRefreshPolicy(WriteRequest.RefreshPolicy refreshPolicy)
{    documentWriter.withRefreshPolicy(refreshPolicy);    return this;}
0
protected String getIndexName(Document update, String indexPostFix) throws IOException
{    return findIndexNameByGUID(update.getGuid(), update.getSensorType()).orElse(ElasticsearchUtils.getIndexName(update.getSensorType(), indexPostFix, null));}
0
protected Optional<String> findIndexNameByGUID(String guid, String sensorType) throws IOException
{    return retrieveLatestDao.searchByGuid(guid, sensorType, hit -> Optional.ofNullable(hit.getIndex()));}
0
public static SimpleDateFormat getIndexFormat(Map<String, Object> globalConfig)
{    String format = (String) globalConfig.get("es.date.format");    return DATE_FORMAT_CACHE.get().computeIfAbsent(format, SimpleDateFormat::new);}
0
public static String getIndexName(String sensorType, String indexPostfix, WriterConfiguration configurations)
{    String indexName = sensorType;    if (configurations != null) {        indexName = configurations.getIndex(sensorType);    }    indexName = indexName + INDEX_NAME_DELIMITER + "_" + indexPostfix;    return indexName;}
0
public static List<HostnamePort> getIps(Map<String, Object> globalConfiguration)
{    Object ipObj = globalConfiguration.get("es.ip");    Object portObj = globalConfiguration.get("es.port");    if (ipObj == null) {        return Collections.emptyList();    }    if (ipObj instanceof String && ipObj.toString().contains(",") && ipObj.toString().contains(":")) {        List<String> ips = Arrays.asList(((String) ipObj).split(","));        List<HostnamePort> ret = new ArrayList<>();        for (String ip : ips) {            Iterable<String> tokens = Splitter.on(":").split(ip);            String host = Iterables.getFirst(tokens, null);            String portStr = Iterables.getLast(tokens, null);            ret.add(new HostnamePort(host, Integer.parseInt(portStr)));        }        return ret;    } else if (ipObj instanceof String && ipObj.toString().contains(",")) {        List<String> ips = Arrays.asList(((String) ipObj).split(","));        List<HostnamePort> ret = new ArrayList<>();        for (String ip : ips) {            ret.add(new HostnamePort(ip, Integer.parseInt(portObj + "")));        }        return ret;    } else if (ipObj instanceof String && !ipObj.toString().contains(":")) {        return ImmutableList.of(new HostnamePort(ipObj.toString(), Integer.parseInt(portObj + "")));    } else if (ipObj instanceof String && ipObj.toString().contains(":")) {        Iterable<String> tokens = Splitter.on(":").split(ipObj.toString());        String host = Iterables.getFirst(tokens, null);        String portStr = Iterables.getLast(tokens, null);        return ImmutableList.of(new HostnamePort(host, Integer.parseInt(portStr)));    } else if (ipObj instanceof List) {        List<String> ips = (List) ipObj;        List<HostnamePort> ret = new ArrayList<>();        for (String ip : ips) {            Iterable<String> tokens = Splitter.on(":").split(ip);            String host = Iterables.getFirst(tokens, null);            String portStr = Iterables.getLast(tokens, null);            ret.add(new HostnamePort(host, Integer.parseInt(portStr)));        }        return ret;    }    throw new IllegalStateException("Unable to read the elasticsearch ips, expected es.ip to be either a list of strings, a string hostname or a host:port string");}
0
public static Optional<String> toJSON(org.elasticsearch.action.search.SearchRequest esRequest)
{    Optional<String> json = Optional.empty();    if (esRequest != null && esRequest.source() != null) {        try {            BytesReference requestBytes = esRequest.source().buildAsBytes();            json = Optional.of(XContentHelper.convertToJson(requestBytes, true));        } catch (Throwable t) {                    }    }    return json;}
1
public static Optional<String> toJSON(Object request)
{    Optional<String> json = Optional.empty();    if (request != null) {        try {            json = Optional.of(new ObjectMapper().writer().withDefaultPrettyPrinter().writeValueAsString(request));        } catch (Throwable t) {                    }    }    return json;}
1
public static SearchResponse queryAllResults(RestHighLevelClient transportClient, QueryBuilder qb, String index, int pageSize) throws IOException
{    org.elasticsearch.action.search.SearchRequest request = new org.elasticsearch.action.search.SearchRequest();    SearchSourceBuilder builder = new SearchSourceBuilder();    builder.query(qb);    builder.size(pageSize);    builder.fetchSource(true);    builder.storedField("*");    request.source(builder);    request.indices(index);    org.elasticsearch.action.search.SearchResponse esResponse = transportClient.search(request);    List<SearchResult> allResults = getSearchResults(esResponse);    long total = esResponse.getHits().getTotalHits();    if (total > pageSize) {        int pages = (int) (total / pageSize) + 1;        for (int i = 1; i < pages; i++) {            int from = i * pageSize;            builder.from(from);            esResponse = transportClient.search(request);            allResults.addAll(getSearchResults(esResponse));        }    }    SearchResponse searchResponse = new SearchResponse();    searchResponse.setTotal(total);    searchResponse.setResults(allResults);    return searchResponse;}
0
protected static List<SearchResult> getSearchResults(org.elasticsearch.action.search.SearchResponse searchResponse)
{    return Arrays.stream(searchResponse.getHits().getHits()).map(searchHit -> {        SearchResult searchResult = new SearchResult();        searchResult.setId(searchHit.getId());        searchResult.setSource(searchHit.getSource());        searchResult.setScore(searchHit.getScore());        searchResult.setIndex(searchHit.getIndex());        return searchResult;    }).collect(Collectors.toList());}
0
public void init(Map stormConf, WriterConfiguration configurations)
{    Map<String, Object> globalConfiguration = configurations.getGlobalConfig();    dateFormat = ElasticsearchUtils.getIndexFormat(globalConfiguration);        if (documentWriter == null) {        client = ElasticsearchClientFactory.create(globalConfiguration);        documentWriter = new ElasticsearchBulkDocumentWriter<>(client);    }}
0
public BulkWriterResponse write(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages)
{        FieldNameConverter fieldNameConverter = FieldNameConverters.create(sensorType, configurations);    String indexPostfix = dateFormat.format(new Date());    String indexName = ElasticsearchUtils.getIndexName(sensorType, indexPostfix, configurations);        for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        MessageIdBasedDocument document = createDocument(bulkWriterMessage, sensorType, fieldNameConverter, configurations.isSetDocumentId(sensorType));        documentWriter.addDocument(document, indexName);    }        BulkDocumentWriterResults<MessageIdBasedDocument> results = documentWriter.write();        BulkWriterResponse response = new BulkWriterResponse();    for (WriteSuccess<MessageIdBasedDocument> success : results.getSuccesses()) {        response.addSuccess(success.getDocument().getMessageId());    }    for (WriteFailure<MessageIdBasedDocument> failure : results.getFailures()) {        response.addError(failure.getCause(), failure.getDocument().getMessageId());    }    return response;}
0
public String getName()
{    return "elasticsearch";}
0
public void close() throws Exception
{    if (client != null) {        client.close();    }}
0
private void copyField(String sourceFieldName, JSONObject source, JSONObject destination, FieldNameConverter fieldNameConverter)
{        String destinationFieldName = fieldNameConverter.convert(sourceFieldName);        destination.put(destinationFieldName, source.get(sourceFieldName));}
0
public void setDocumentWriter(BulkDocumentWriter<MessageIdBasedDocument> documentWriter)
{    this.documentWriter = documentWriter;}
0
public MessageId getMessageId()
{    return messageId;}
0
public void setup()
{        highLevelClient = mock(RestHighLevelClient.class);    client = mock(ElasticsearchClient.class);    when(client.getHighLevelClient()).thenReturn(highLevelClient);    writer = new ElasticsearchBulkDocumentWriter<>(client);}
0
public void testWriteSuccess() throws IOException
{    setupElasticsearchToSucceed();        Document doc = document(message());    String index = "bro_index";    writer.addDocument(doc, index);    BulkDocumentWriterResults<Document> results = writer.write();    assertEquals(1, results.getSuccesses().size());    assertEquals(0, results.getFailures().size());    WriteSuccess<Document> success = results.getSuccesses().get(0);    assertEquals(doc, success.getDocument());}
0
public void testWriteFailure() throws IOException
{    setupElasticsearchToFail();        Document doc = document(message());    String index = "bro_index";    writer.addDocument(doc, index);    BulkDocumentWriterResults<Document> results = writer.write();    assertEquals(0, results.getSuccesses().size());    assertEquals(1, results.getFailures().size());    WriteFailure<Document> failure = results.getFailures().get(0);    assertEquals(doc, failure.getDocument());    assertEquals("error message", failure.getMessage());    assertNotNull(failure.getCause());}
0
public void testSizeWhenWriteSuccessful() throws IOException
{    setupElasticsearchToSucceed();    assertEquals(0, writer.size());        String index = "bro_index";    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    assertEquals(5, writer.size());        writer.write();    assertEquals(0, writer.size());}
0
public void testSizeWhenWriteFails() throws IOException
{    setupElasticsearchToFail();    assertEquals(0, writer.size());        String index = "bro_index";    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    writer.addDocument(document(message()), index);    assertEquals(5, writer.size());        writer.write();    assertEquals(0, writer.size());}
0
private void setupElasticsearchToFail() throws IOException
{    final String errorMessage = "error message";    final Exception cause = new Exception("test exception");    final boolean isFailed = true;    final int itemID = 0;        BulkItemResponse.Failure failure = mock(BulkItemResponse.Failure.class);    when(failure.getCause()).thenReturn(cause);    when(failure.getMessage()).thenReturn(errorMessage);        BulkItemResponse itemResponse = mock(BulkItemResponse.class);    when(itemResponse.isFailed()).thenReturn(isFailed);    when(itemResponse.getItemId()).thenReturn(itemID);    when(itemResponse.getFailure()).thenReturn(failure);    when(itemResponse.getFailureMessage()).thenReturn("error message");    List<BulkItemResponse> itemsResponses = Collections.singletonList(itemResponse);        BulkResponse response = mock(BulkResponse.class);    when(response.iterator()).thenReturn(itemsResponses.iterator());    when(response.hasFailures()).thenReturn(isFailed);        when(highLevelClient.bulk(any(BulkRequest.class))).thenReturn(response);}
0
private void setupElasticsearchToSucceed() throws IOException
{    final String documentId = UUID.randomUUID().toString();    final boolean isFailed = false;    final int itemID = 0;        DocWriteResponse writeResponse = mock(DocWriteResponse.class);    when(writeResponse.getId()).thenReturn(documentId);        BulkItemResponse itemResponse = mock(BulkItemResponse.class);    when(itemResponse.isFailed()).thenReturn(isFailed);    when(itemResponse.getItemId()).thenReturn(itemID);    when(itemResponse.getResponse()).thenReturn(writeResponse);    List<BulkItemResponse> itemsResponses = Collections.singletonList(itemResponse);        BulkResponse response = mock(BulkResponse.class);    when(response.iterator()).thenReturn(itemsResponses.iterator());    when(response.hasFailures()).thenReturn(isFailed);        when(highLevelClient.bulk(any(BulkRequest.class))).thenReturn(response);}
0
private Document document(JSONObject message)
{    String guid = UUID.randomUUID().toString();    String sensorType = "bro";    Long timestamp = System.currentTimeMillis();    return new Document(message, guid, sensorType, timestamp);}
0
private JSONObject message()
{    JSONObject message = new JSONObject();    message.put(Constants.GUID, UUID.randomUUID().toString());    message.put(Constants.Fields.TIMESTAMP.getName(), System.currentTimeMillis());    message.put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");    return message;}
0
public void setup() throws Exception
{    tempDir = TestUtils.createTempDir(this.getClass().getName());}
0
public void bulk_exporter_writes_elasticsearch_records_in_bulk_import_format() throws Exception
{    Path recordsFile = Paths.get(tempDir.getPath(), "inputfile.json");    Path outputFile = Paths.get(tempDir.getPath(), "outputfile.json");    TestUtils.write(recordsFile.toFile(), records);    ElasticsearchImportExport tool = new ElasticsearchImportExport();    tool.bulkify(recordsFile, outputFile);    String actual = TestUtils.read(outputFile.toFile());    assertThat(actual, equalTo(expected));}
0
public ElasticsearchColumnMetadataDao setup(String[] indices)
{    return setup(indices, new HashMap<>());}
0
public ElasticsearchColumnMetadataDao setup(String[] indices, Map<String, FieldMapping> mappings)
{    ElasticsearchClient client = new ElasticsearchClient(mock(RestClient.class), mock(RestHighLevelClient.class)) {        @Override        public String[] getIndices() throws IOException {            return indices;        }        @Override        public Map<String, FieldMapping> getMappingByIndex(String[] indices) throws IOException {            return mappings;        }    };    return new ElasticsearchColumnMetadataDao(client);}
0
public String[] getIndices() throws IOException
{    return indices;}
0
public Map<String, FieldMapping> getMappingByIndex(String[] indices) throws IOException
{    return mappings;}
0
public void testGetOneLatestIndex() throws IOException
{        String[] existingIndices = new String[] { "bro_index_2017.10.03.19", "bro_index_2017.10.03.20", "bro_index_2017.10.03.21", "snort_index_2017.10.03.19", "snort_index_2017.10.03.20", "snort_index_2017.10.03.21" };    ElasticsearchColumnMetadataDao dao = setup(existingIndices);        List<String> args = Collections.singletonList("bro");    String[] actual = dao.getLatestIndices(args);        String[] expected = new String[] { "bro_index_2017.10.03.21" };    assertArrayEquals(expected, actual);}
0
public void testGetLatestIndices() throws IOException
{        String[] existingIndices = new String[] { "bro_index_2017.10.03.19", "bro_index_2017.10.03.20", "bro_index_2017.10.03.21", "snort_index_2017.10.03.19", "snort_index_2017.10.03.19", "snort_index_2017.10.03.21" };    ElasticsearchColumnMetadataDao dao = setup(existingIndices);        List<String> args = Arrays.asList("bro", "snort");    String[] actual = dao.getLatestIndices(args);        String[] expected = new String[] { "bro_index_2017.10.03.21", "snort_index_2017.10.03.21" };    assertArrayEquals(expected, actual);}
0
public void testLatestIndicesWhereNoneExist() throws IOException
{        String[] existingIndices = new String[] {};    ElasticsearchColumnMetadataDao dao = setup(existingIndices);        List<String> args = Arrays.asList("bro", "snort");    String[] actual = dao.getLatestIndices(args);        String[] expected = new String[] {};    assertArrayEquals(expected, actual);}
0
private void setup(RestStatus status, int maxSearchResults, Map<String, FieldType> metadata) throws Exception
{        SearchHit hit1 = mock(SearchHit.class);    when(hit1.getId()).thenReturn("id1");    when(hit1.getSource()).thenReturn(new HashMap<String, Object>() {        {            put("field", "value1");        }    });    when(hit1.getScore()).thenReturn(0.1f);    SearchHit hit2 = mock(SearchHit.class);    when(hit2.getId()).thenReturn("id2");    when(hit2.getSource()).thenReturn(new HashMap<String, Object>() {        {            put("field", "value2");        }    });    when(hit2.getScore()).thenReturn(0.2f);        SearchHit[] hits = { hit1, hit2 };    SearchHits searchHits = mock(SearchHits.class);    when(searchHits.getHits()).thenReturn(hits);    when(searchHits.getTotalHits()).thenReturn(Integer.toUnsignedLong(hits.length));        org.elasticsearch.action.search.SearchResponse response = mock(org.elasticsearch.action.search.SearchResponse.class);    when(response.status()).thenReturn(status);    when(response.getHits()).thenReturn(searchHits);        ElasticsearchColumnMetadataDao columnMetadataDao = mock(ElasticsearchColumnMetadataDao.class);    when(columnMetadataDao.getColumnMetadata(any())).thenReturn(metadata);        requestSubmitter = mock(ElasticsearchRequestSubmitter.class);    when(requestSubmitter.submitSearch(any())).thenReturn(response);    RestHighLevelClient highLevel = mock(RestHighLevelClient.class);    ElasticsearchClient client = new ElasticsearchClient(mock(RestClient.class), highLevel);        AccessConfig config = mock(AccessConfig.class);    when(config.getMaxSearchResults()).thenReturn(maxSearchResults);    ElasticsearchSearchDao elasticsearchSearchDao = new ElasticsearchSearchDao(client, config, columnMetadataDao, requestSubmitter);    ElasticsearchRetrieveLatestDao elasticsearchRetrieveLatestDao = new ElasticsearchRetrieveLatestDao(client);    ElasticsearchUpdateDao elasticsearchUpdateDao = new ElasticsearchUpdateDao(client, config, elasticsearchRetrieveLatestDao);    dao = new ElasticsearchDao(client, config, elasticsearchSearchDao, elasticsearchUpdateDao, elasticsearchRetrieveLatestDao, columnMetadataDao, requestSubmitter);}
0
private void setup(RestStatus status, int maxSearchResults) throws Exception
{    setup(status, maxSearchResults, new HashMap<>());}
0
public void searchShouldSortByGivenFields() throws Exception
{        Map<String, FieldType> columnMetadata = new HashMap<>();    columnMetadata.put("sortByStringDesc", FieldType.TEXT);    columnMetadata.put("sortByIntAsc", FieldType.INTEGER);        setup(RestStatus.OK, 25, columnMetadata);        SortField[] expectedSortFields = { sortBy("sortByStringDesc", SortOrder.DESC), sortBy("sortByIntAsc", SortOrder.ASC), sortBy("sortByUndefinedDesc", SortOrder.DESC) };        final List<String> indices = Arrays.asList("bro", "snort");    SearchRequest searchRequest = new SearchRequest();    searchRequest.setSize(2);    searchRequest.setIndices(indices);    searchRequest.setFrom(5);    searchRequest.setSort(Arrays.asList(expectedSortFields));    searchRequest.setQuery("some query");        SearchResponse searchResponse = dao.search(searchRequest);    assertNotNull(searchResponse);        ArgumentCaptor<org.elasticsearch.action.search.SearchRequest> argument = ArgumentCaptor.forClass(org.elasticsearch.action.search.SearchRequest.class);    verify(requestSubmitter).submitSearch(argument.capture());    org.elasticsearch.action.search.SearchRequest request = argument.getValue();        JSONParser parser = new JSONParser();    JSONObject json = (JSONObject) parser.parse(ElasticsearchUtils.toJSON(request).orElse("???"));        JSONArray sortFields = (JSONArray) json.get("sort");    assertEquals(3, sortFields.size());    {                JSONObject aSortField = (JSONObject) sortFields.get(0);        JSONObject sortBy = (JSONObject) aSortField.get("sortByStringDesc");        assertEquals("desc", sortBy.get("order"));        assertEquals("_last", sortBy.get("missing"));        assertEquals("text", sortBy.get("unmapped_type"));    }    {                JSONObject aSortField = (JSONObject) sortFields.get(1);        JSONObject sortByIntAsc = (JSONObject) aSortField.get("sortByIntAsc");        assertEquals("asc", sortByIntAsc.get("order"));        assertEquals("_first", sortByIntAsc.get("missing"));        assertEquals("integer", sortByIntAsc.get("unmapped_type"));    }    {                JSONObject aSortField = (JSONObject) sortFields.get(2);        JSONObject sortByUndefinedDesc = (JSONObject) aSortField.get("sortByUndefinedDesc");        assertEquals("desc", sortByUndefinedDesc.get("order"));        assertEquals("_last", sortByUndefinedDesc.get("missing"));        assertEquals("other", sortByUndefinedDesc.get("unmapped_type"));    }}
0
public void searchShouldWildcardIndices() throws Exception
{        setup(RestStatus.OK, 25);        SortField[] expectedSortFields = { sortBy("sortByStringDesc", SortOrder.DESC), sortBy("sortByIntAsc", SortOrder.ASC), sortBy("sortByUndefinedDesc", SortOrder.DESC) };        final List<String> indices = Arrays.asList("bro", "snort");    SearchRequest searchRequest = new SearchRequest();    searchRequest.setSize(2);    searchRequest.setIndices(indices);    searchRequest.setFrom(5);    searchRequest.setSort(Arrays.asList(expectedSortFields));    searchRequest.setQuery("some query");        SearchResponse searchResponse = dao.search(searchRequest);    assertNotNull(searchResponse);        ArgumentCaptor<org.elasticsearch.action.search.SearchRequest> argument = ArgumentCaptor.forClass(org.elasticsearch.action.search.SearchRequest.class);    verify(requestSubmitter).submitSearch(argument.capture());    org.elasticsearch.action.search.SearchRequest request = argument.getValue();        JSONParser parser = new JSONParser();    JSONObject json = (JSONObject) parser.parse(ElasticsearchUtils.toJSON(request).orElse("???"));        String[] expected = { "bro_index*", "snort_index*" };    assertArrayEquals(expected, request.indices());}
0
public void searchShouldThrowExceptionWhenMaxResultsAreExceeded() throws Exception
{    int maxSearchResults = 20;    setup(RestStatus.OK, maxSearchResults);    SearchRequest searchRequest = new SearchRequest();    searchRequest.setSize(maxSearchResults + 1);    searchRequest.setQuery("");    dao.search(searchRequest);}
0
private SortField sortBy(String field, SortOrder order)
{    SortField sortField = new SortField();    sortField.setField(field);    sortField.setSortOrder(order.toString());    return sortField;}
0
public void testInvalidInit()
{    IndexDao dao = new IndexDao() {        @Override        public SearchResponse search(SearchRequest searchRequest) {            return null;        }        @Override        public GroupResponse group(GroupRequest groupRequest) {            return null;        }        @Override        public void init(AccessConfig config) {        }        @Override        public Document getLatest(String guid, String sensorType) {            return null;        }        @Override        public Iterable<Document> getAllLatest(List<GetRequest> getRequests) {            return null;        }        @Override        public Document update(Document update, Optional<String> index) {            return update;        }        @Override        public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) {            return updates;        }        @Override        public Map<String, FieldType> getColumnMetadata(List<String> indices) {            return null;        }        @Override        public Document addCommentToAlert(CommentAddRemoveRequest request) {            return null;        }        @Override        public Document removeCommentFromAlert(CommentAddRemoveRequest request) {            return null;        }        @Override        public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) {            return null;        }        @Override        public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) {            return null;        }    };    ElasticsearchMetaAlertDao metaAlertDao = new ElasticsearchMetaAlertDao();    metaAlertDao.init(dao);}
0
public SearchResponse search(SearchRequest searchRequest)
{    return null;}
0
public GroupResponse group(GroupRequest groupRequest)
{    return null;}
0
public void init(AccessConfig config)
{}
0
public Document getLatest(String guid, String sensorType)
{    return null;}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests)
{    return null;}
0
public Document update(Document update, Optional<String> index)
{    return update;}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates)
{    return updates;}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public void testInitInvalidDao()
{    HBaseDao dao = new HBaseDao();    ElasticsearchMetaAlertDao esDao = new ElasticsearchMetaAlertDao();    esDao.init(dao, Optional.empty());}
0
public void testCreateMetaAlertEmptyGuids() throws InvalidCreateException, IOException
{    ElasticsearchDao esDao = new ElasticsearchDao();    ElasticsearchMetaAlertDao emaDao = new ElasticsearchMetaAlertDao();    emaDao.init(esDao);    MetaAlertCreateRequest createRequest = new MetaAlertCreateRequest();    emaDao.createMetaAlert(createRequest);}
0
public void testCreateMetaAlertEmptyGroups() throws InvalidCreateException, IOException
{    ElasticsearchDao esDao = new ElasticsearchDao();    MultiIndexDao miDao = new MultiIndexDao(esDao);    ElasticsearchMetaAlertDao emaDao = new ElasticsearchMetaAlertDao();    emaDao.init(miDao);    MetaAlertCreateRequest createRequest = new MetaAlertCreateRequest();    createRequest.setAlerts(Collections.singletonList(new GetRequest("don't", "care")));    emaDao.createMetaAlert(createRequest);}
0
public void testUpdateShouldUpdateOnMissingMetaAlertIndex() throws Exception
{    ElasticsearchDao elasticsearchDao = mock(ElasticsearchDao.class);    ElasticsearchMetaAlertRetrieveLatestDao elasticsearchMetaAlertRetrieveLatestDao = mock(ElasticsearchMetaAlertRetrieveLatestDao.class);    MetaAlertConfig metaAlertConfig = mock(MetaAlertConfig.class);    ElasticsearchMetaAlertUpdateDao emauDao = spy(new ElasticsearchMetaAlertUpdateDao(elasticsearchDao, elasticsearchMetaAlertRetrieveLatestDao, metaAlertConfig, 1));    doThrow(new IndexNotFoundException(ElasticsearchMetaAlertDao.METAALERTS_INDEX)).when(emauDao).getMetaAlertsForAlert("alert_one");    Document update = new Document(new HashMap<>(), "alert_one", "", 0L);    emauDao.update(update, Optional.empty());    Map<Document, Optional<String>> expectedUpdate = new HashMap<Document, Optional<String>>() {        {            put(update, Optional.empty());        }    };    verify(elasticsearchDao).batchUpdate(expectedUpdate);}
0
public void testUpdateShouldThrowExceptionOnMissingSensorIndex() throws Exception
{    ElasticsearchDao elasticsearchDao = mock(ElasticsearchDao.class);    ElasticsearchMetaAlertRetrieveLatestDao elasticsearchMetaAlertRetrieveLatestDao = mock(ElasticsearchMetaAlertRetrieveLatestDao.class);    MetaAlertConfig metaAlertConfig = mock(MetaAlertConfig.class);    ElasticsearchMetaAlertUpdateDao emauDao = spy(new ElasticsearchMetaAlertUpdateDao(elasticsearchDao, elasticsearchMetaAlertRetrieveLatestDao, metaAlertConfig, 1));    doThrow(new IndexNotFoundException("bro")).when(emauDao).getMetaAlertsForAlert("alert_one");    Document update = new Document(new HashMap<>(), "alert_one", "", 0L);    emauDao.update(update, Optional.empty());}
0
public ElasticsearchRequestSubmitter setup(SearchResponse response) throws IOException
{        RestHighLevelClient highLevelClient = mock(RestHighLevelClient.class);    ElasticsearchClient client = new ElasticsearchClient(mock(RestClient.class), highLevelClient);        when(highLevelClient.search(any())).thenReturn(response);    return new ElasticsearchRequestSubmitter(client);}
0
public void searchShouldSucceedWhenOK() throws InvalidSearchException, IOException
{        SearchResponse response = mock(SearchResponse.class);    SearchRequest request = new SearchRequest();        SearchHits hits = mock(SearchHits.class);    when(hits.getTotalHits()).thenReturn(1L);        when(response.status()).thenReturn(RestStatus.OK);    when(response.getFailedShards()).thenReturn(0);    when(response.getTotalShards()).thenReturn(2);    when(response.getHits()).thenReturn(hits);        ElasticsearchRequestSubmitter submitter = setup(response);    SearchResponse actual = submitter.submitSearch(request);    assertNotNull(actual);}
0
public void searchShouldFailWhenNotOK() throws InvalidSearchException, IOException
{        SearchResponse response = mock(SearchResponse.class);    SearchRequest request = new SearchRequest();        when(response.status()).thenReturn(RestStatus.PARTIAL_CONTENT);    when(response.getFailedShards()).thenReturn(0);    when(response.getTotalShards()).thenReturn(2);        ElasticsearchRequestSubmitter submitter = setup(response);    submitter.submitSearch(request);}
0
public void searchShouldHandleShardFailure() throws InvalidSearchException, IOException
{        SearchResponse response = mock(SearchResponse.class);    SearchRequest request = new SearchRequest();    ShardSearchFailure fail = mock(ShardSearchFailure.class);    SearchShardTarget target = new SearchShardTarget("node1", mock(Index.class), 1, "metron");        when(response.status()).thenReturn(RestStatus.OK);        SearchHits hits = mock(SearchHits.class);    when(hits.getTotalHits()).thenReturn(1L);        when(response.getFailedShards()).thenReturn(1);    when(response.getTotalShards()).thenReturn(2);    when(response.getHits()).thenReturn(hits);        ShardSearchFailure[] failures = { fail };    when(response.getShardFailures()).thenReturn(failures);        when(fail.shard()).thenReturn(target);        when(fail.index()).thenReturn("bro_index_2017-10-11");    when(fail.shardId()).thenReturn(1);        ElasticsearchRequestSubmitter submitter = setup(response);    SearchResponse actual = submitter.submitSearch(request);    assertNotNull(actual);}
0
public void setup()
{    accessConfig = new AccessConfig();    retrieveLatestDao = mock(ElasticsearchRetrieveLatestDao.class);    RestHighLevelClient highLevel = mock(RestHighLevelClient.class);    ElasticsearchClient client = new ElasticsearchClient(mock(RestClient.class), highLevel);    updateDao = new ElasticsearchUpdateDao(client, accessConfig, retrieveLatestDao);}
0
public UpdateDao getUpdateDao()
{    return updateDao;}
0
public Builder withMapping(String index, String docType, String mapping)
{    mappings.add(new Mapping(index, docType, mapping));    return this;}
0
public Builder withHttpPort(int httpPort)
{    this.httpPort = httpPort;    return this;}
0
public Builder withIndexDir(File indexDir)
{    this.indexDir = indexDir;    return this;}
0
public Builder withExtraElasticSearchSettings(Map<String, String> extraElasticSearchSettings)
{    this.extraElasticSearchSettings = extraElasticSearchSettings;    return this;}
0
public Builder withAccessConfig(AccessConfig accessConfig)
{    this.accessConfig = accessConfig;    return this;}
0
public ElasticSearchComponent build()
{    return new ElasticSearchComponent(httpPort, indexDir, extraElasticSearchSettings, mappings, accessConfig);}
0
public void start() throws UnableToStartException
{    File logDir = new File(indexDir, "/logs");    File dataDir = new File(indexDir, "/data");    try {        cleanDir(logDir);        cleanDir(dataDir);    } catch (IOException e) {        throw new UnableToStartException("Unable to clean log or data directories", e);    }    Settings.Builder settingsBuilder = Settings.builder().put("cluster.name", "metron").put("path.logs", logDir.getAbsolutePath()).put("path.data", dataDir.getAbsolutePath()).put("path.home", indexDir.getAbsoluteFile()).put("transport.type", "netty4").put("http.enabled", "true");    if (extraElasticSearchSettings != null) {        settingsBuilder = settingsBuilder.put(extraElasticSearchSettings);    }    node = new TestNode(settingsBuilder.build(), asList(Netty4Plugin.class));    client = node.client();    try {        node.start();    } catch (NodeValidationException e) {        throw new UnableToStartException("Error starting ES node.", e);    }    waitForCluster(client, ClusterHealthStatus.YELLOW, STARTUP_TIMEOUT);    for (Mapping m : Optional.ofNullable(mappings).orElse(new ArrayList<>())) {        client.admin().indices().prepareCreate(m.index).addMapping(m.docType, m.mapping).get();    }    indexDao = new ElasticsearchDao().withRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);    indexDao.init(accessConfig);}
0
private void cleanDir(File dir) throws IOException
{    if (dir.exists()) {        FileUtils.deleteDirectory(dir);    }    dir.mkdirs();}
0
public static void waitForCluster(Client client, ClusterHealthStatus statusThreshold, String timeout) throws UnableToStartException
{    try {        ClusterHealthResponse healthResponse = (ClusterHealthResponse) client.execute(ClusterHealthAction.INSTANCE, new ClusterHealthRequest().waitForStatus(statusThreshold).timeout(timeout)).actionGet();        if (healthResponse != null && healthResponse.isTimedOut()) {            throw new UnableToStartException("cluster state is " + healthResponse.getStatus().name() + " and not " + statusThreshold.name() + ", from here on, everything will fail!");        }    } catch (ElasticsearchTimeoutException e) {        throw new UnableToStartException("timeout, cluster does not respond to health request, cowardly refusing to continue with operations");    }}
0
public Client getClient()
{    return client;}
0
public void add(String indexName, String sensorType, String... docs) throws IOException, ParseException
{    List<String> d = new ArrayList<>();    Collections.addAll(d, docs);    add(indexName, sensorType, d, false);}
0
public void add(String indexName, String sensorType, Iterable<String> docs) throws IOException, ParseException
{    add(indexName, sensorType, docs, false);}
0
public void add(String indexName, String sensorType, Iterable<String> docs, boolean setDocumentId) throws IOException, ParseException
{        JSONParser parser = new JSONParser();    Map<Document, Optional<String>> documents = new HashMap<>();    for (String json : docs) {        JSONObject message = (JSONObject) parser.parse(json);        documents.put(createDocument(message, sensorType, setDocumentId), Optional.of(indexName));    }        indexDao.batchUpdate(documents);}
0
private static Document createDocument(JSONObject message, String docType, boolean setDocumentId) throws IOException
{    Long timestamp = ConversionUtils.convert(message.get("timestamp"), Long.class);    String source = message.toJSONString();    String guid = (String) message.get("guid");    Document document = new Document(source, guid, docType, timestamp);    if (setDocumentId) {        document.setDocumentID(guid);    }    return document;}
0
public void createIndexWithMapping(String indexName, String mappingType, String mappingSource) throws IOException
{    CreateIndexResponse cir = client.admin().indices().prepareCreate(indexName).addMapping(mappingType, mappingSource).get();    if (!cir.isAcknowledged()) {        throw new IOException("Create index was not acknowledged");    }}
0
public List<Map<String, Object>> getAllIndexedDocs(String index, String sourceType) throws IOException
{    return getAllIndexedDocs(index, sourceType, null);}
0
public List<Map<String, Object>> getAllIndexedDocs(String index, String sourceType, String subMessage) throws IOException
{    getClient().admin().indices().refresh(new RefreshRequest());    SearchResponse response = getClient().prepareSearch(index).setTypes(sourceType).setFrom(0).setSize(1000).execute().actionGet();    List<Map<String, Object>> ret = new ArrayList<Map<String, Object>>();    for (SearchHit hit : response.getHits()) {        Object o = null;        if (subMessage == null) {            o = hit.getSource();        } else {            o = hit.getSource().get(subMessage);        }        ret.add((Map<String, Object>) (o));    }    return ret;}
0
public boolean hasIndex(String indexName)
{    Set<String> indices = getClient().admin().indices().stats(new IndicesStatsRequest()).actionGet().getIndices().keySet();    return indices.contains(indexName);}
0
public void stop()
{    try {        if (node != null) {            node.close();        }    } catch (IOException e) {        throw new RuntimeException("Unable to stop node.", e);    }    node = null;    client = null;}
0
public void reset()
{    client.admin().indices().delete(new DeleteIndexRequest("*")).actionGet();}
0
public static void setupElasticsearch() throws Exception
{    AccessConfig accessConfig = new AccessConfig();    accessConfig.setGlobalConfigSupplier(() -> globals());    elasticsearch = new ElasticSearchComponent.Builder().withHttpPort(9211).withIndexDir(indexDir.getRoot()).withAccessConfig(accessConfig).build();    elasticsearch.start();}
0
public static void tearDownElasticsearch()
{    if (elasticsearch != null) {        elasticsearch.stop();    }}
0
public void setup() throws Exception
{    client = ElasticsearchClientFactory.create(globals());    retrieveDao = new ElasticsearchRetrieveLatestDao(client);    writer = new ElasticsearchBulkDocumentWriter<>(client).withRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);        JSONObject broTemplate = JSONUtils.INSTANCE.load(new File(broTemplatePath), JSONObject.class);    String broTemplateJson = JSONUtils.INSTANCE.toJSON(broTemplate, true);    HttpEntity broEntity = new NStringEntity(broTemplateJson, ContentType.APPLICATION_JSON);    Response response = client.getLowLevelClient().performRequest("PUT", "/_template/bro_template", Collections.emptyMap(), broEntity);    assertThat(response.getStatusLine().getStatusCode(), CoreMatchers.equalTo(200));}
0
public void tearDown() throws IOException
{    if (client != null) {        client.close();    }}
0
public void testWrite() throws Exception
{        List<Document> documents = new ArrayList<>();    for (int i = 0; i < 10; i++) {        Document document = Document.fromJSON(createMessage());        documents.add(document);    }        for (Document doc : documents) {        writer.addDocument(doc, "bro_index");    }    writer.write();        for (Document expected : documents) {        Document actual = retrieveDao.getLatest(expected.getGuid(), expected.getSensorType());        assertNotNull("No document found", actual);        assertEquals(expected.getGuid(), actual.getGuid());        assertEquals(expected.getSensorType(), actual.getSensorType());        assertEquals(expected.getDocument(), actual.getDocument());        assertTrue(actual.getDocumentID().isPresent());                assertNotEquals(actual.getDocument(), actual.getGuid());    }}
0
private static Map<String, Object> globals()
{    Map<String, Object> globals = new HashMap<>();    globals.put("es.clustername", "metron");    globals.put("es.ip", "localhost");    globals.put("es.port", "9200");    globals.put("es.date.format", "yyyy.MM.dd.HH");    return globals;}
0
private JSONObject createMessage()
{    JSONObject message = new JSONObject();    message.put(Constants.GUID, UUID.randomUUID().toString());    message.put(Constants.Fields.TIMESTAMP.getName(), System.currentTimeMillis());    message.put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");    message.put("source:type", "bro");    return message;}
0
public static Collection<Object[]> data()
{    Function<List<String>, List<String>> asteriskTransform = x -> ImmutableList.of("*");    Function<List<String>, List<String>> explicitTransform = allIndices -> allIndices.stream().map(x -> x.replace("_index", "")).collect(Collectors.toCollection(ArrayList::new));    return Arrays.asList(new Object[][] { { asteriskTransform }, { explicitTransform } });}
0
public static void setupBefore() throws Exception
{        MAX_RETRIES = 10;    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put("es.clustername", "metron");            put("es.port", "9200");            put("es.ip", "localhost");            put("es.date.format", DATE_FORMAT);        }    };    accessConfig = new AccessConfig();    accessConfig.setMaxSearchResults(1000);    accessConfig.setMaxSearchGroups(100);    accessConfig.setGlobalConfigSupplier(() -> globalConfig);        es = new ElasticSearchComponent.Builder().withHttpPort(9211).withIndexDir(new File(INDEX_DIR)).withAccessConfig(accessConfig).build();    es.start();}
0
public void setup() throws IOException
{    es.createIndexWithMapping(METAALERTS_INDEX, METAALERT_DOC, template.replace("%MAPPING_NAME%", METAALERT_TYPE));    es.createIndexWithMapping(INDEX, "test_doc", template.replace("%MAPPING_NAME%", "test"));    esDao = new ElasticsearchDao();    esDao.init(accessConfig);    ElasticsearchMetaAlertDao elasticsearchMetaDao = new ElasticsearchMetaAlertDao(esDao);    elasticsearchMetaDao.setPageSize(5);    metaDao = elasticsearchMetaDao;}
0
public static void teardown()
{    if (es != null) {        es.stop();    }}
0
public void reset()
{    es.reset();}
0
public void shouldSearchByNestedAlert() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(4);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(0).put("ip_src_addr", "192.168.1.1");    alerts.get(0).put("ip_src_port", 8010);    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(1).put("ip_src_addr", "192.168.1.2");    alerts.get(1).put("ip_src_port", 8009);    alerts.get(2).put("ip_src_addr", "192.168.1.3");    alerts.get(2).put("ip_src_port", 8008);    alerts.get(3).put("ip_src_addr", "192.168.1.4");    alerts.get(3).put("ip_src_port", 8007);    addRecords(alerts, INDEX, SENSOR_NAME);        setupTypings();        Map<String, Object> activeMetaAlert = buildMetaAlert("meta_active", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(1))));    Map<String, Object> inactiveMetaAlert = buildMetaAlert("meta_inactive", MetaAlertStatus.INACTIVE, Optional.of(Arrays.asList(alerts.get(2), alerts.get(3))));        addRecords(Arrays.asList(activeMetaAlert, inactiveMetaAlert), METAALERTS_INDEX, METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME), new GetRequest("message_3", SENSOR_NAME), new GetRequest("meta_active", METAALERT_TYPE), new GetRequest("meta_inactive", METAALERT_TYPE)));    SearchResponse searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("(ip_src_addr:192.168.1.1 AND ip_src_port:8009) OR (metron_alert.ip_src_addr:192.168.1.1 AND metron_alert.ip_src_port:8009)");            setIndices(Collections.singletonList(METAALERT_TYPE));            setFrom(0);            setSize(5);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(0, searchResponse.getTotal());            searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("(ip_src_addr:192.168.1.1 AND ip_src_port:8010)" + " OR (metron_alert.ip_src_addr:192.168.1.1 AND metron_alert.ip_src_port:8010)");            setIndices(queryIndices);            setFrom(0);            setSize(5);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());    Assert.assertEquals("meta_active", searchResponse.getResults().get(0).getSource().get("guid"));            searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("(ip_src_addr:192.168.1.3 AND ip_src_port:8008)" + " OR (metron_alert.ip_src_addr:192.168.1.3 AND metron_alert.ip_src_port:8008)");            setIndices(Collections.singletonList("*"));            setFrom(0);            setSize(1);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());    Assert.assertEquals("message_2", searchResponse.getResults().get(0).getSource().get("guid"));}
0
protected long getMatchingAlertCount(String fieldName, Object fieldValue) throws IOException, InterruptedException
{    long cnt = 0;    for (int t = 0; t < MAX_RETRIES && cnt == 0; ++t, Thread.sleep(SLEEP_MS)) {        List<Map<String, Object>> docs = es.getAllIndexedDocs(INDEX, SENSOR_NAME + "_doc");        cnt = docs.stream().filter(d -> {            Object newfield = d.get(fieldName);            return newfield != null && newfield.equals(fieldValue);        }).count();    }    return cnt;}
0
protected long getMatchingMetaAlertCount(String fieldName, String fieldValue) throws IOException, InterruptedException
{    long cnt = 0;    for (int t = 0; t < MAX_RETRIES && cnt == 0; ++t, Thread.sleep(SLEEP_MS)) {        List<Map<String, Object>> docs = es.getAllIndexedDocs(METAALERTS_INDEX, METAALERT_DOC);        cnt = docs.stream().filter(d -> {            @SuppressWarnings("unchecked")            List<Map<String, Object>> alerts = (List<Map<String, Object>>) d.get(ALERT_FIELD);            for (Map<String, Object> alert : alerts) {                Object newField = alert.get(fieldName);                if (newField != null && newField.equals(fieldValue)) {                    return true;                }            }            return false;        }).count();    }    return cnt;}
0
protected void addRecords(List<Map<String, Object>> inputData, String index, String docType) throws IOException, ParseException
{    es.add(index, docType, inputData.stream().map(m -> {        try {            return JSONUtils.INSTANCE.toJSON(m, true);        } catch (JsonProcessingException e) {            throw new IllegalStateException(e.getMessage(), e);        }    }).collect(Collectors.toList()));}
0
protected void setupTypings() throws IOException
{    ((ElasticsearchDao) esDao).getClient().putMapping(INDEX, "test_doc", nestedAlertMapping);}
0
protected String getTestIndexName()
{    return INDEX_RAW;}
0
protected String getTestIndexFullName()
{    return INDEX;}
0
protected String getMetaAlertIndex()
{    return METAALERTS_INDEX;}
0
protected String getSourceTypeField()
{    return ElasticsearchMetaAlertDao.SOURCE_TYPE_FIELD;}
0
protected void setEmptiedMetaAlertField(Map<String, Object> docMap)
{    docMap.put(METAALERT_FIELD, new ArrayList<>());}
0
protected boolean isFiniteDoubleOnly()
{    return true;}
0
protected boolean isEmptyMetaAlertList()
{    return true;}
0
public static void setup() throws Exception
{    globalConfig = new HashMap<String, Object>() {        {            put("es.clustername", "metron");            put("es.port", "9200");            put("es.ip", "localhost");            put("es.date.format", dateFormat);        }    };    accessConfig = new AccessConfig();    accessConfig.setMaxSearchResults(100);    accessConfig.setMaxSearchGroups(100);    accessConfig.setGlobalConfigSupplier(() -> globalConfig);    indexComponent = startIndex();    ElasticsearchClient esClient = ElasticsearchClientFactory.create(globalConfig);    lowLevelClient = esClient.getLowLevelClient();    highLevelClient = esClient.getHighLevelClient();    dao = new ElasticsearchDao();    dao.init(accessConfig);        loadTestData();}
0
protected static InMemoryComponent startIndex() throws Exception
{    InMemoryComponent es = new ElasticSearchComponent.Builder().withHttpPort(9211).withIndexDir(new File(indexDir)).withAccessConfig(accessConfig).build();    es.start();    return es;}
0
protected static void loadTestData() throws Exception
{    ElasticSearchComponent es = (ElasticSearchComponent) indexComponent;        JSONObject broTemplate = JSONUtils.INSTANCE.load(new File(broTemplatePath), JSONObject.class);    addTestFieldMappings(broTemplate, "bro_doc");    String broTemplateJson = JSONUtils.INSTANCE.toJSON(broTemplate, true);    HttpEntity broEntity = new NStringEntity(broTemplateJson, ContentType.APPLICATION_JSON);    Response response = lowLevelClient.performRequest("PUT", "/_template/bro_template", Collections.emptyMap(), broEntity);    assertThat(response.getStatusLine().getStatusCode(), equalTo(200));        JSONObject snortTemplate = JSONUtils.INSTANCE.load(new File(snortTemplatePath), JSONObject.class);    addTestFieldMappings(snortTemplate, "snort_doc");    String snortTemplateJson = JSONUtils.INSTANCE.toJSON(snortTemplate, true);    HttpEntity snortEntity = new NStringEntity(snortTemplateJson, ContentType.APPLICATION_JSON);    response = lowLevelClient.performRequest("PUT", "/_template/snort_template", Collections.emptyMap(), snortEntity);    assertThat(response.getStatusLine().getStatusCode(), equalTo(200));        response = lowLevelClient.performRequest("PUT", BRO_INDEX);    assertThat(response.getStatusLine().getStatusCode(), equalTo(200));        response = lowLevelClient.performRequest("PUT", SNORT_INDEX);    assertThat(response.getStatusLine().getStatusCode(), equalTo(200));        List<String> broDocuments = new ArrayList<>();    for (Object broObject : (JSONArray) new JSONParser().parse(broData)) {        broDocuments.add(((JSONObject) broObject).toJSONString());    }        es.add(BRO_INDEX, "bro", broDocuments.subList(0, 4), true);        es.add(BRO_INDEX, "bro", broDocuments.subList(4, 5), false);        List<String> snortDocuments = new ArrayList<>();    for (Object snortObject : (JSONArray) new JSONParser().parse(snortData)) {        snortDocuments.add(((JSONObject) snortObject).toJSONString());    }    es.add(SNORT_INDEX, "snort", snortDocuments);}
0
private static void addTestFieldMappings(JSONObject template, String docType)
{    Map mappings = (Map) template.get("mappings");    Map docTypeJSON = (Map) mappings.get(docType);    Map properties = (Map) docTypeJSON.get("properties");    Map<String, String> longType = new HashMap<>();    longType.put("type", "long");    properties.put("long_field", longType);    Map<String, String> floatType = new HashMap<>();    floatType.put("type", "float");    properties.put("latitude", floatType);    Map<String, String> doubleType = new HashMap<>();    doubleType.put("type", "double");    properties.put("score", doubleType);}
0
public void bad_facet_query_throws_exception() throws Exception
{    thrown.expect(InvalidSearchException.class);    thrown.expectMessage("Failed to execute search");    SearchRequest request = JSONUtils.INSTANCE.load(badFacetQuery, SearchRequest.class);    dao.search(request);}
0
public void returns_column_metadata_for_specified_indices() throws Exception
{        {        Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Collections.singletonList("bro"));        Assert.assertEquals(262, fieldTypes.size());        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("method"));        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("ttl"));        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("guid"));        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("source:type"));        Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));        Assert.assertEquals(FieldType.LONG, fieldTypes.get("long_field"));        Assert.assertEquals(FieldType.DATE, fieldTypes.get("timestamp"));        Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("latitude"));        Assert.assertEquals(FieldType.DOUBLE, fieldTypes.get("score"));        Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("location_point"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("metron_alert"));    }        {        Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Collections.singletonList("snort"));        Assert.assertEquals(32, fieldTypes.size());        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("sig_generator"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ttl"));        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("guid"));        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("source:type"));        Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));        Assert.assertEquals(FieldType.LONG, fieldTypes.get("long_field"));        Assert.assertEquals(FieldType.DATE, fieldTypes.get("timestamp"));        Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("latitude"));        Assert.assertEquals(FieldType.DOUBLE, fieldTypes.get("score"));        Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("location_point"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ttl"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("metron_alert"));    }}
0
public void returns_column_data_for_multiple_indices() throws Exception
{    Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Arrays.asList("bro", "snort"));    Assert.assertEquals(277, fieldTypes.size());        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("guid"));    Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("source:type"));    Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("threat:triage:score"));    Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("alert_status"));    Assert.assertEquals(FieldType.OTHER, fieldTypes.get("metron_alert"));    Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));    Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));    Assert.assertEquals(FieldType.LONG, fieldTypes.get("long_field"));    Assert.assertEquals(FieldType.DATE, fieldTypes.get("timestamp"));    Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("latitude"));    Assert.assertEquals(FieldType.DOUBLE, fieldTypes.get("score"));    Assert.assertEquals(FieldType.DOUBLE, fieldTypes.get("suppress_for"));    Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("method"));        Assert.assertEquals(FieldType.KEYWORD, fieldTypes.get("sig_generator"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("ttl"));    Assert.assertEquals(FieldType.OTHER, fieldTypes.get("msg"));}
0
public void throws_exception_on_aggregation_queries_on_non_string_non_numeric_fields() throws Exception
{    thrown.expect(InvalidSearchException.class);    thrown.expectMessage("Failed to execute search");    GroupRequest request = JSONUtils.INSTANCE.load(badGroupQuery, GroupRequest.class);    dao.group(request);}
0
public void different_type_filter_query() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(differentTypeFilterQuery, SearchRequest.class);    SearchResponse response = dao.search(request);    Assert.assertEquals(1, response.getTotal());    List<SearchResult> results = response.getResults();    Assert.assertEquals("bro", results.get(0).getSource().get("source:type"));    Assert.assertEquals("data 1", results.get(0).getSource().get("ttl"));}
0
protected String getSourceTypeField()
{    return Constants.SENSOR_TYPE.replace('.', ':');}
0
protected IndexDao getIndexDao()
{    return dao;}
0
protected String getIndexName(String sensorType)
{    if ("bro".equals(sensorType)) {        return BRO_INDEX;    } else {        return SNORT_INDEX;    }}
0
protected String getIndexName()
{    return SENSOR_NAME + "_index_" + new SimpleDateFormat(dateFormat).format(new Date());}
0
public static void setupBeforeClass() throws UnableToStartException, IOException
{    Configuration config = HBaseConfiguration.create();    MockHBaseTableProvider tableProvider = new MockHBaseTableProvider();    MockHBaseTableProvider.addToCache(TABLE_NAME, CF);    table = (MockHTable) tableProvider.getTable(config, TABLE_NAME);    globalConfig = new HashMap<>();    globalConfig.put("es.clustername", "metron");    globalConfig.put("es.port", "9200");    globalConfig.put("es.ip", "localhost");    globalConfig.put("es.date.format", dateFormat);    globalConfig.put(HBaseDao.HBASE_TABLE, TABLE_NAME);    globalConfig.put(HBaseDao.HBASE_CF, CF);    accessConfig = new AccessConfig();    accessConfig.setTableProvider(tableProvider);    accessConfig.setGlobalConfigSupplier(() -> globalConfig);    es = new ElasticSearchComponent.Builder().withHttpPort(9211).withIndexDir(new File(indexDir)).withAccessConfig(accessConfig).build();    es.start();    installIndexTemplate();}
0
public void setup()
{    elasticsearchDao = new ElasticsearchDao().withRefreshPolicy(WriteRequest.RefreshPolicy.WAIT_UNTIL);    elasticsearchDao.init(accessConfig);    setDao(elasticsearchDao);}
0
public void reset()
{    es.reset();    table.clear();}
0
public static void teardown()
{    es.stop();}
0
protected void addTestData(String indexName, String sensorType, List<Map<String, Object>> docs) throws Exception
{    es.add(index, SENSOR_NAME, Iterables.transform(docs, m -> {        try {            return JSONUtils.INSTANCE.toJSON(m, true);        } catch (JsonProcessingException e) {            throw new IllegalStateException(e.getMessage(), e);        }    }));}
0
protected List<Map<String, Object>> getIndexedTestData(String indexName, String sensorType) throws Exception
{    return es.getAllIndexedDocs(index, SENSOR_NAME + "_doc");}
0
private static void installIndexTemplate() throws IOException
{    HttpEntity broEntity = new NStringEntity(indexTemplate, ContentType.APPLICATION_JSON);    ElasticsearchClient client = ElasticsearchClientFactory.create(globalConfig);    Response response = client.getLowLevelClient().performRequest("PUT", "/_template/test_template", Collections.emptyMap(), broEntity);    Assert.assertThat(response.getStatusLine().getStatusCode(), CoreMatchers.equalTo(200));}
0
public void setup()
{    writerConfiguration = mock(WriterConfiguration.class);    when(writerConfiguration.getGlobalConfig()).thenReturn(globals());    stormConf = new HashMap();}
0
public void shouldWriteSuccessfully()
{        List<BulkMessage<JSONObject>> messages = createMessages(1);        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addSuccess(createDocument(messages.get(0)));    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        assertFalse(response.hasErrors());    assertTrue(response.getSuccesses().contains(new MessageId("message1")));}
0
public void shouldWriteManySuccessfully()
{        List<BulkMessage<JSONObject>> messages = createMessages(3);        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addSuccess(createDocument(messages.get(0)));    results.addSuccess(createDocument(messages.get(1)));    results.addSuccess(createDocument(messages.get(2)));    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        assertFalse(response.hasErrors());    assertTrue(response.getSuccesses().contains(new MessageId("message1")));    assertTrue(response.getSuccesses().contains(new MessageId("message2")));    assertTrue(response.getSuccesses().contains(new MessageId("message3")));}
0
public void shouldHandleWriteFailure()
{        List<BulkMessage<JSONObject>> messages = createMessages(3);    Exception cause = new Exception();        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addFailure(createDocument(messages.get(0)), cause, "error");    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        assertEquals(0, response.getSuccesses().size());    assertEquals(1, response.getErrors().size());    Collection<MessageId> errors = response.getErrors().get(cause);    assertTrue(errors.contains(new MessageId("message1")));}
0
public void shouldHandleManyWriteFailures()
{        int count = 3;    List<BulkMessage<JSONObject>> messages = createMessages(count);    Exception cause = new Exception();        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addFailure(createDocument(messages.get(0)), cause, "error");    results.addFailure(createDocument(messages.get(1)), cause, "error");    results.addFailure(createDocument(messages.get(2)), cause, "error");    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        assertEquals(0, response.getSuccesses().size());    assertEquals(1, response.getErrors().size());    Collection<MessageId> errors = response.getErrors().get(cause);    assertTrue(errors.contains(new MessageId("message1")));    assertTrue(errors.contains(new MessageId("message2")));    assertTrue(errors.contains(new MessageId("message3")));}
0
public void shouldHandlePartialFailures()
{        int count = 2;    List<BulkMessage<JSONObject>> messages = createMessages(count);    Exception cause = new Exception();        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addFailure(createDocument(messages.get(0)), cause, "error");    results.addSuccess(createDocument(messages.get(1)));    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        assertEquals(1, response.getSuccesses().size());    assertEquals(1, response.getErrors().size());    assertTrue(response.getErrors().get(cause).contains(new MessageId("message1")));    assertTrue(response.getSuccesses().contains(new MessageId("message2")));}
0
public void shouldWriteSuccessfullyWhenMessageTimestampIsString()
{    List<BulkMessage<JSONObject>> messages = createMessages(1);    JSONObject message = messages.get(0).getMessage();        message.put(Constants.Fields.TIMESTAMP.getName(), new Long(System.currentTimeMillis()).toString());        String timestamp = (String) message.get(Constants.Fields.TIMESTAMP.getName());    String guid = (String) message.get(Constants.GUID);    String sensorType = (String) message.get(Constants.SENSOR_TYPE);    MessageIdBasedDocument document = new MessageIdBasedDocument(message, guid, sensorType, Long.parseLong(timestamp), new MessageId("message1"));        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addSuccess(document);    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        assertFalse(response.hasErrors());    assertTrue(response.getSuccesses().contains(new MessageId("message1")));}
0
public void shouldWriteSuccessfullyWhenMissingGUID()
{        List<BulkMessage<JSONObject>> messages = createMessages(1);        assertNotNull(messages.get(0).getMessage().remove(Constants.GUID));        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addSuccess(createDocument(messages.get(0)));    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        assertFalse(response.hasErrors());    assertTrue(response.getSuccesses().contains(new MessageId("message1")));}
0
public void shouldWriteManySuccessfullyWithSetDocumentId()
{    when(writerConfiguration.isSetDocumentId("bro")).thenReturn(true);    when(writerConfiguration.getFieldNameConverter("bro")).thenReturn("NOOP");    mockStatic(ElasticsearchUtils.class);    when(ElasticsearchUtils.getIndexFormat(globals())).thenReturn(new SimpleDateFormat());    when(ElasticsearchUtils.getIndexName(eq("bro"), any(), eq(writerConfiguration))).thenReturn("bro_index");        List<BulkMessage<JSONObject>> messages = createMessages(3);        MessageIdBasedDocument document1 = createDocument(messages.get(0));    MessageIdBasedDocument document2 = createDocument(messages.get(1));    MessageIdBasedDocument document3 = createDocument(messages.get(2));        document1.setDocumentID(document1.getGuid());    document2.setDocumentID(document1.getGuid());    document3.setDocumentID(document1.getGuid());        BulkDocumentWriterResults<MessageIdBasedDocument> results = new BulkDocumentWriterResults<>();    results.addSuccess(document1);    results.addSuccess(document2);    results.addSuccess(document3);    BulkDocumentWriter<MessageIdBasedDocument> docWriter = mock(BulkDocumentWriter.class);    when(docWriter.write()).thenReturn(results);        ElasticsearchWriter esWriter = new ElasticsearchWriter();    esWriter.setDocumentWriter(docWriter);    esWriter.init(stormConf, writerConfiguration);    BulkWriterResponse response = esWriter.write("bro", writerConfiguration, messages);        verify(docWriter, times(1)).addDocument(document1, "bro_index");    verify(docWriter, times(1)).addDocument(document1, "bro_index");    verify(docWriter, times(1)).addDocument(document1, "bro_index");        assertFalse(response.hasErrors());    assertTrue(response.getSuccesses().contains(new MessageId("message1")));    assertTrue(response.getSuccesses().contains(new MessageId("message2")));    assertTrue(response.getSuccesses().contains(new MessageId("message3")));}
0
private MessageIdBasedDocument createDocument(BulkMessage<JSONObject> bulkWriterMessage)
{    MessageId messageId = bulkWriterMessage.getId();    JSONObject message = bulkWriterMessage.getMessage();    Long timestamp = (Long) bulkWriterMessage.getMessage().get(Constants.Fields.TIMESTAMP.getName());    String guid = (String) message.get(Constants.GUID);    String sensorType = (String) message.get(Constants.SENSOR_TYPE);    return new MessageIdBasedDocument(message, guid, sensorType, timestamp, messageId);}
0
private JSONObject message()
{    JSONObject message = new JSONObject();    message.put(Constants.GUID, UUID.randomUUID().toString());    message.put(Constants.Fields.TIMESTAMP.getName(), System.currentTimeMillis());    message.put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");    message.put(Constants.SENSOR_TYPE, "bro");    return message;}
0
private Map<String, Object> globals()
{    Map<String, Object> globals = new HashMap<>();    globals.put("es.date.format", "yyyy.MM.dd.HH");    return globals;}
0
private List<BulkMessage<JSONObject>> createMessages(int count)
{    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    for (int i = 0; i < count; i++) {        messages.add(new BulkMessage<>(new MessageId("message" + (i + 1)), message()));    }    return messages;}
0
public FieldNameConverter getFieldNameConverter()
{    return fieldNameConverter;}
0
public InMemoryComponent getSearchComponent(final Properties topologyProperties)
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put("es.clustername", "metron");            put("es.port", "9200");            put("es.ip", "localhost");            put("es.date.format", dateFormat);        }    };    AccessConfig accessConfig = new AccessConfig();    accessConfig.setGlobalConfigSupplier(() -> globalConfig);    return new ElasticSearchComponent.Builder().withHttpPort(9211).withIndexDir(new File(indexDir)).withMapping(index, "yaf_doc", mapping).withAccessConfig(accessConfig).build();}
0
public Processor<List<Map<String, Object>>> getProcessor(final List<byte[]> inputMessages)
{    return new Processor<List<Map<String, Object>>>() {        List<Map<String, Object>> docs = null;        List<byte[]> errors = null;        final AtomicInteger missCount = new AtomicInteger(0);        @Override        public ReadinessState process(ComponentRunner runner) {            ElasticSearchComponent elasticSearchComponent = runner.getComponent("search", ElasticSearchComponent.class);            KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);            if (elasticSearchComponent.hasIndex(index)) {                try {                    docs = elasticSearchComponent.getAllIndexedDocs(index, testSensorType + "_doc");                } catch (IOException e) {                    throw new IllegalStateException("Unable to retrieve indexed documents.", e);                }                if (docs.size() < inputMessages.size()) {                    errors = kafkaComponent.readMessages(ERROR_TOPIC);                    if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {                        return ReadinessState.READY;                    }                    return ReadinessState.NOT_READY;                } else {                    return ReadinessState.READY;                }            } else {                return ReadinessState.NOT_READY;            }        }        @Override        public ProcessorResult<List<Map<String, Object>>> getResult() {            ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();            return builder.withResult(docs).withProcessErrors(errors).build();        }    };}
0
public ReadinessState process(ComponentRunner runner)
{    ElasticSearchComponent elasticSearchComponent = runner.getComponent("search", ElasticSearchComponent.class);    KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);    if (elasticSearchComponent.hasIndex(index)) {        try {            docs = elasticSearchComponent.getAllIndexedDocs(index, testSensorType + "_doc");        } catch (IOException e) {            throw new IllegalStateException("Unable to retrieve indexed documents.", e);        }        if (docs.size() < inputMessages.size()) {            errors = kafkaComponent.readMessages(ERROR_TOPIC);            if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {                return ReadinessState.READY;            }            return ReadinessState.NOT_READY;        } else {            return ReadinessState.READY;        }    } else {        return ReadinessState.NOT_READY;    }}
0
public ProcessorResult<List<Map<String, Object>>> getResult()
{    ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();    return builder.withResult(docs).withProcessErrors(errors).build();}
0
public void setAdditionalProperties(Properties topologyProperties)
{    topologyProperties.setProperty("es.clustername", "metron");    topologyProperties.setProperty("es.port", "9300");    topologyProperties.setProperty("es.ip", "localhost");    topologyProperties.setProperty("ra_indexing_writer_class_name", "org.apache.metron.elasticsearch.writer.ElasticsearchWriter");    topologyProperties.setProperty("ra_indexing_kafka_start", "UNCOMMITTED_EARLIEST");    topologyProperties.setProperty("ra_indexing_workers", "1");    topologyProperties.setProperty("ra_indexing_acker_executors", "0");    topologyProperties.setProperty("ra_indexing_topology_max_spout_pending", "");    topologyProperties.setProperty("ra_indexing_kafka_spout_parallelism", "1");    topologyProperties.setProperty("ra_indexing_writer_parallelism", "1");}
0
public String cleanField(String field)
{    return field;}
0
public String getTemplatePath()
{    return "./src/main/config/elasticsearch.properties.j2";}
0
public String getFluxPath()
{    return "../../metron-indexing/metron-indexing-storm/src/main/flux/indexing/random_access/remote.yaml";}
0
public void cleanup()
{}
0
public void logAccess(CacheKey value)
{}
0
public JSONObject enrich(CacheKey k)
{    String metadata = k.coerceValue(String.class);    JSONObject output = new JSONObject();        output.putAll(getCIFObject(metadata));    return output;}
1
protected Map getCIFObject(String key)
{        Get get = new Get(key.getBytes(StandardCharsets.UTF_8));    Result rs;    Map output = new HashMap();    try {        rs = table.get(get);        for (KeyValue kv : rs.raw()) output.put(new String(kv.getQualifier(), StandardCharsets.UTF_8), "Y");    } catch (IOException e) {                e.printStackTrace();    }    return output;}
1
public boolean initializeAdapter(Map<String, Object> config)
{        Configuration conf = null;    conf = HBaseConfiguration.create();    conf.set("hbase.zookeeper.quorum", _quorum);    conf.set("hbase.zookeeper.property.clientPort", _port);    try {                        Connection connection = ConnectionFactory.createConnection(conf);        table = connection.getTable(TableName.valueOf(_tableName));        return true;    } catch (IOException e) {                e.printStackTrace();    }    return false;}
1
public void updateAdapter(Map<String, Object> config)
{}
0
public String enrichByIP(String metadata)
{    return null;}
0
public String enrichByDomain(String metadata)
{    return null;}
0
public String enrichByEmail(String metadata)
{    return null;}
0
public void cleanup()
{}
0
public String getOutputPrefix(CacheKey value)
{    return value.getField();}
0
public void logAccess(CacheKey value)
{}
0
public String getOutputPrefix(CacheKey value)
{    return value.getField();}
0
public JSONObject enrich(CacheKey value)
{    JSONObject enriched = new JSONObject();    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(value.coerceValue(String.class));    if (!result.isPresent()) {        return new JSONObject();    }    enriched = new JSONObject(result.get());    _LOG.trace("GEO Enrichment success: {}", enriched);    return enriched;}
0
public boolean initializeAdapter(Map<String, Object> config)
{    GeoLiteCityDatabase.INSTANCE.update((String) config.get(GeoLiteCityDatabase.GEO_HDFS_FILE));    return true;}
0
public void updateAdapter(Map<String, Object> config)
{    GeoLiteCityDatabase.INSTANCE.updateIfNecessary(config);}
0
public void cleanup()
{}
0
public void cleanup()
{}
0
public String getOutputPrefix(CacheKey value)
{    return value.getField();}
0
public boolean initializeAdapter(Map<String, Object> config)
{    if (_known_hosts.size() > 0)        return true;    else        return false;}
0
public void updateAdapter(Map<String, Object> config)
{}
0
public void logAccess(CacheKey value)
{}
0
public JSONObject enrich(CacheKey k)
{    String metadata = k.coerceValue(String.class);    if (!_known_hosts.containsKey(metadata))        return new JSONObject();    JSONObject enrichment = new JSONObject();    String prefix = "known_info.";    JSONObject knownInfo = _known_hosts.get(metadata);    for (Object key : knownInfo.keySet()) {        enrichment.put(prefix + key, knownInfo.get(key));    }        return enrichment;}
0
public boolean initializeAdapter(Map<String, Object> config)
{    if (_known_hosts.size() > 0)        return true;    else        return false;}
0
public void updateAdapter(Map<String, Object> config)
{}
0
public String getOutputPrefix(CacheKey value)
{    return value.getField();}
0
public void logAccess(CacheKey value)
{}
0
public JSONObject enrich(CacheKey metadata)
{    if (!_known_hosts.containsKey(metadata.getValue()))        return new JSONObject();    JSONObject enrichment = new JSONObject();    enrichment.put("known_info", (JSONObject) _known_hosts.get(metadata.getValue()));    return enrichment;}
0
public String getHost()
{    return host;}
0
public void setHost(String host)
{    this.host = host;}
0
public int getPort()
{    return port;}
0
public void setPort(int port)
{    this.port = port;}
0
public String getUsername()
{    return username;}
0
public void setUsername(String username)
{    this.username = username;}
0
public String getPassword()
{    return password;}
0
public void setPassword(String password)
{    this.password = password;}
0
public String getTable()
{    return table;}
0
public void setTable(String table)
{    this.table = table;}
0
protected boolean isConnectionClosed()
{    boolean isClosed = statement == null || connection == null;    if (!isClosed) {        try {            isClosed = statement.isClosed() || connection.isClosed();        } catch (SQLException e) {            _            isClosed = true;        }    }    return isClosed;}
1
protected boolean resetConnectionIfNecessary()
{    if (isConnectionClosed()) {        this.cleanup();        return this.initializeAdapter(null);    }    return true;}
0
public void setStatement(Statement statement)
{    this.statement = statement;}
0
public JdbcAdapter withJdbcConfig(JdbcConfig config)
{    this.config = config;    this.host = config.getHost();    return this;}
0
public String getClassName()
{    return "com.mysql.jdbc.Driver";}
0
public String getJdbcUrl()
{    StringBuilder url = new StringBuilder();    url.append("jdbc:mysql://").append(host);    if (port > 0) {        url.append(":").append(port);    }    url.append("/").append(table);    url.append("?user=").append(username);    url.append("&password=").append(password);    return url.toString();}
0
public String getSimpleName()
{    return simpleName;}
0
public Object get(Map<String, Object> map)
{    return getter.apply(map);}
0
public void set(Map<String, Object> map, Object val)
{    map.put(simpleName, val);}
0
public String getHdfsFileConfig()
{    return ASN_HDFS_FILE;}
0
public String getHdfsFileDefault()
{    return ASN_HDFS_FILE_DEFAULT;}
0
public void lockIfNecessary()
{    writeLock.lock();}
0
public void unlockIfNecessary()
{    writeLock.unlock();}
0
public DatabaseReader getReader()
{    return reader;}
0
public void setReader(DatabaseReader reader)
{    GeoLiteAsnDatabase.reader = reader;}
0
public synchronized void updateIfNecessary(Map<String, Object> globalConfig)
{        LOG.trace("Determining if GeoLiteAsnDatabase update required");    String hdfsFile = ASN_HDFS_FILE_DEFAULT;    if (globalConfig != null) {        hdfsFile = (String) globalConfig.getOrDefault(ASN_HDFS_FILE, ASN_HDFS_FILE_DEFAULT);    }        if (reader == null || !hdfsLoc.equals(hdfsFile)) {                hdfsLoc = hdfsFile;        update(hdfsFile);    } else {        LOG.trace("Update to GeoLiteAsnDatabase unnecessary");    }}
0
public Optional<Map<String, Object>> get(String ip)
{    if (MaxMindDbUtilities.invalidIp(ip)) {        return Optional.empty();    }    try {        readLock.lock();        InetAddress addr = InetAddress.getByName(ip);        AsnResponse asnResponse = reader.asn(addr);        HashMap<String, Object> asnInfo = new HashMap<>();        AsnProps.ASN.set(asnInfo, asnResponse.getAutonomousSystemNumber());        AsnProps.ASO.set(asnInfo, MaxMindDbUtilities.convertNullToEmptyString(asnResponse.getAutonomousSystemOrganization()));        AsnProps.NETWORK.set(asnInfo, MaxMindDbUtilities.convertNullToEmptyString(asnResponse.getIpAddress()));        return Optional.of(asnInfo);    } catch (UnknownHostException | AddressNotFoundException e) {            } catch (GeoIp2Exception | IOException e) {            } finally {        readLock.unlock();    }    return Optional.empty();}
1
public String getSimpleName()
{    return simpleName;}
0
public String get(Map<String, String> map)
{    return getter.apply(map);}
0
public void set(Map<String, String> map, String val)
{    map.put(simpleName, val);}
0
public String getHdfsFileConfig()
{    return GEO_HDFS_FILE;}
0
public String getHdfsFileDefault()
{    return GEO_HDFS_FILE_DEFAULT;}
0
public void lockIfNecessary()
{    writeLock.lock();}
0
public void unlockIfNecessary()
{    writeLock.unlock();}
0
public DatabaseReader getReader()
{    return reader;}
0
public void setReader(DatabaseReader reader)
{    GeoLiteCityDatabase.reader = reader;}
0
public synchronized void updateIfNecessary(Map<String, Object> globalConfig)
{        LOG.trace("Determining if GeoIpDatabase update required");    String hdfsFile = GEO_HDFS_FILE_DEFAULT;    if (globalConfig != null) {        hdfsFile = (String) globalConfig.getOrDefault(GEO_HDFS_FILE, GEO_HDFS_FILE_DEFAULT);        hdfsFile = determineHdfsDirWithFallback(globalConfig, hdfsFile, GEO_HDFS_FILE_DEFAULT_FALLBACK);    }        if (reader == null || !hdfsLoc.equals(hdfsFile)) {                hdfsLoc = hdfsFile;        update(hdfsFile);    } else {        LOG.trace("Update to GeoLiteCity2Database unnecessary");    }}
0
protected String determineHdfsDirWithFallback(Map<String, Object> globalConfig, String hdfsFile, String hdfsFallbackFile)
{        if (!globalConfig.containsKey(GEO_HDFS_FILE)) {        FileSystem fs = MaxMindDbUtilities.getFileSystem();        try {                        if (hdfsPathsExist(fs, hdfsFile, hdfsFallbackFile)) {                hdfsFile = hdfsFallbackFile;            }        } catch (IOException e) {                            }    }    return hdfsFile;}
1
protected boolean hdfsPathsExist(FileSystem fs, String hdfsFile, String fallbackFile) throws IOException
{    return !fs.exists(new Path(hdfsFile)) && fs.exists(new Path(fallbackFile));}
0
public Optional<Map<String, String>> get(String ip)
{    if (MaxMindDbUtilities.invalidIp(ip)) {        return Optional.empty();    }    try {        readLock.lock();        InetAddress addr = InetAddress.getByName(ip);        CityResponse cityResponse = reader.city(addr);        HashMap<String, String> geoInfo = new HashMap<>();        Country country = cityResponse.getCountry();        City city = cityResponse.getCity();        Postal postal = cityResponse.getPostal();        Location location = cityResponse.getLocation();        GeoProps.LOC_ID.set(geoInfo, MaxMindDbUtilities.convertNullToEmptyString(city.getGeoNameId()));        GeoProps.COUNTRY.set(geoInfo, MaxMindDbUtilities.convertNullToEmptyString(country.getIsoCode()));        GeoProps.CITY.set(geoInfo, MaxMindDbUtilities.convertNullToEmptyString(city.getName()));        GeoProps.POSTAL_CODE.set(geoInfo, MaxMindDbUtilities.convertNullToEmptyString(postal.getCode()));        GeoProps.DMA_CODE.set(geoInfo, MaxMindDbUtilities.convertNullToEmptyString(location.getMetroCode()));        Double latitudeRaw = location.getLatitude();        String latitude = MaxMindDbUtilities.convertNullToEmptyString(latitudeRaw);        GeoProps.LATITUDE.set(geoInfo, latitude);        Double longitudeRaw = location.getLongitude();        String longitude = MaxMindDbUtilities.convertNullToEmptyString(longitudeRaw);        GeoProps.LONGITUDE.set(geoInfo, longitude);        if (latitudeRaw == null || longitudeRaw == null) {            GeoProps.LOCATION_POINT.set(geoInfo, "");        } else {            GeoProps.LOCATION_POINT.set(geoInfo, latitude + "," + longitude);        }        return Optional.of(geoInfo);    } catch (UnknownHostException | AddressNotFoundException e) {            } catch (GeoIp2Exception | IOException e) {            } finally {        readLock.unlock();    }    return Optional.empty();}
1
public Optional<WGS84Point> toPoint(Map<String, String> geoInfo)
{    String latitude = GeoProps.LATITUDE.get(geoInfo);    String longitude = GeoProps.LONGITUDE.get(geoInfo);    if (latitude == null || longitude == null) {        return Optional.empty();    }    try {        double latD = Double.parseDouble(latitude);        double longD = Double.parseDouble(longitude);        return Optional.of(new WGS84Point(latD, longD));    } catch (NumberFormatException nfe) {                return Optional.empty();    }}
1
public double distance(WGS84Point point1, WGS84Point point2)
{    return strat.distance(point1, point2);}
0
public Optional<String> computeHash(Double latitude, Double longitude, int precision)
{    if (latitude == null || longitude == null) {        return Optional.empty();    }    return computeHash(new WGS84Point(latitude, longitude), precision);}
0
public Optional<String> computeHash(WGS84Point point, int precision)
{    GeoHash hash = GeoHash.withCharacterPrecision(point.getLatitude(), point.getLongitude(), precision);    return Optional.of(hash.toBase32());}
0
public Optional<String> computeHash(Map<String, String> geoLoc, int precision)
{    Optional<WGS84Point> point = GeoLiteCityDatabase.INSTANCE.toPoint(geoLoc);    if (point.isPresent()) {        return computeHash(point.get(), precision);    } else {        return Optional.empty();    }}
0
public Optional<WGS84Point> toPoint(String hash)
{    if (hash == null) {        return Optional.empty();    }    GeoHash h = GeoHash.fromGeohashString(hash);    return Optional.ofNullable(h == null ? null : h.getPoint());}
0
public double distance(WGS84Point point1, WGS84Point point2, DistanceStrategy strategy)
{    return strategy.distance(point1, point2);}
0
public WGS84Point centroidOfHashes(Iterable<String> hashes)
{    Iterable<WGS84Point> points = Iterables.transform(hashes, h -> toPoint(h).orElse(null));    return centroidOfPoints(points);}
0
public WGS84Point centroidOfPoints(Iterable<WGS84Point> points)
{    Iterable<WGS84Point> nonNullPoints = Iterables.filter(points, p -> p != null);    return centroid(Iterables.transform(nonNullPoints, p -> new AbstractMap.SimpleImmutableEntry<>(p, 1)));}
0
public WGS84Point centroidOfWeightedPoints(Map<String, Number> points)
{    Iterable<Map.Entry<WGS84Point, Number>> weightedPoints = Iterables.transform(points.entrySet(), kv -> {        WGS84Point pt = toPoint(kv.getKey()).orElse(null);        return new AbstractMap.SimpleImmutableEntry<>(pt, kv.getValue());    });    return centroid(Iterables.filter(weightedPoints, kv -> kv.getKey() != null));}
0
private WGS84Point centroid(Iterable<Map.Entry<WGS84Point, Number>> points)
{    double x = 0d, y = 0d, z = 0d, totalWeight = 0d;    int n = 0;    /**     * So, it's first important to realize that long/lat are not cartesian, so simple weighted averaging     * is insufficient here as it denies the fact that we're not living on a flat square, but rather the surface of     * an ellipsoid.  A crow, for instance, does not fly a straight line to an observer outside of Earth, but     * rather flies across the arc tracing the surface of earth, or a "great-earth arc".  When computing the centroid     * you want to find the centroid of the points with distance defined as the great-earth arc.     *     * The general strategy is to:     * 1. Change coordinate systems from degrees on a WGS84 projection (e.g. lat/long)     *    to a 3 dimensional cartesian surface atop a sphere approximating the earth.     * 2. Compute a weighted average of the cartesian coordinates     * 3. Change coordinate systems of the resulting centroid in cartesian space back to lat/long     *     * This is generally detailed at http://www.geomidpoint.com/example.html     */    for (Map.Entry<WGS84Point, Number> weightedPoint : points) {        WGS84Point pt = weightedPoint.getKey();        if (pt == null) {            continue;        }        double latRad = Math.toRadians(pt.getLatitude());        double longRad = Math.toRadians(pt.getLongitude());        double cosLat = Math.cos(latRad);        /*       Convert from lat/long coordinates to cartesian coordinates.  The cartesian coordinate system is a right-hand,       rectangular, three-dimensional, earth-fixed coordinate system       with an origin at (0, 0, 0). The Z-axis, is parrallel to the axis of rotation of the earth. The Z-coordinate       is positive toward the North pole. The X-Y plane lies in the equatorial plane. The X-axis lies along the       intersection of the plane containing the prime meridian and the equatorial plane. The X-coordinate is positive       toward the intersection of the prime meridian and equator.       Please see https://en.wikipedia.org/wiki/Geographic_coordinate_conversion#From_geodetic_to_ECEF_coordinates       for more information about this coordinate transformation.       */        double ptX = cosLat * Math.cos(longRad);        double ptY = cosLat * Math.sin(longRad);        double ptZ = Math.sin(latRad);        double weight = weightedPoint.getValue().doubleValue();        x += ptX * weight;        y += ptY * weight;        z += ptZ * weight;        n++;        totalWeight += weight;    }    if (n == 0) {        return null;    }        x /= totalWeight;    y /= totalWeight;    z /= totalWeight;        double longitude = Math.atan2(y, x);    double hypotenuse = Math.sqrt(x * x + y * y);    double latitude = Math.atan2(z, hypotenuse);        return new WGS84Point(Math.toDegrees(latitude), Math.toDegrees(longitude));}
0
public double maxDistanceHashes(Iterable<String> hashes, DistanceStrategy strategy)
{    Iterable<WGS84Point> points = Iterables.transform(hashes, s -> toPoint(s).orElse(null));    return maxDistancePoints(Iterables.filter(points, p -> p != null), strategy);}
0
public double maxDistancePoints(Iterable<WGS84Point> points, DistanceStrategy strategy)
{        int i = 0;    double max = Double.NaN;    for (WGS84Point pt1 : points) {        int j = 0;        for (WGS84Point pt2 : points) {            if (j <= i) {                double d = strategy.distance(pt1, pt2);                if (Double.isNaN(max) || d > max) {                    max = d;                }                j++;            } else {                break;            }        }        i++;    }    return max;}
0
 void update(String hdfsFile)
{        if (hdfsFile == null || hdfsFile.isEmpty()) {                hdfsFile = getHdfsFileDefault();    }    FileSystem fs = MaxMindDbUtilities.getFileSystem();    if (hdfsFile.endsWith(MaxMindDatabase.EXTENSION_MMDB)) {        lockIfNecessary();        try (BufferedInputStream is = new BufferedInputStream(fs.open(new Path(hdfsFile)))) {            setReader(MaxMindDbUtilities.readNewDatabase(getReader(), hdfsFile, is));        } catch (IOException e) {            MaxMindDbUtilities.handleDatabaseIOException(hdfsFile, e);        } finally {            unlockIfNecessary();        }    } else if (hdfsFile.endsWith(MaxMindDatabase.EXTENSION_MMDB_GZ)) {        lockIfNecessary();        try (GZIPInputStream is = new GZIPInputStream(fs.open(new Path(hdfsFile)))) {            setReader(MaxMindDbUtilities.readNewDatabase(getReader(), hdfsFile, is));        } catch (IOException e) {            MaxMindDbUtilities.handleDatabaseIOException(hdfsFile, e);        } finally {            unlockIfNecessary();        }    } else if (hdfsFile.endsWith(MaxMindDatabase.EXTENSION_TAR_GZ)) {        lockIfNecessary();        try (TarArchiveInputStream is = new TarArchiveInputStream(new GZIPInputStream(fs.open(new Path(hdfsFile))))) {                        TarArchiveEntry entry = is.getNextTarEntry();            while (entry != null) {                if (entry.isFile() && entry.getName().endsWith(MaxMindDatabase.EXTENSION_MMDB)) {                    try (InputStream mmdb = new BufferedInputStream(is)) {                                                setReader(MaxMindDbUtilities.readNewDatabase(getReader(), hdfsFile, mmdb));                                                break;                    }                }                entry = is.getNextTarEntry();            }        } catch (IOException e) {            MaxMindDbUtilities.handleDatabaseIOException(hdfsFile, e);        } finally {            unlockIfNecessary();        }    }}
1
public static boolean invalidIp(String ip)
{    LOG.trace("Called validateIp({})", ip);    InetAddress addr;    try {        addr = InetAddress.getByName(ip);    } catch (UnknownHostException e) {                return true;    }    if (isIneligibleAddress(ip, addr)) {                return true;    }    return false;}
1
public static boolean isIneligibleAddress(String ipStr, InetAddress addr)
{    return addr.isAnyLocalAddress() || addr.isLoopbackAddress() || addr.isSiteLocalAddress() || addr.isMulticastAddress() || !ipvalidator.isValidInet4Address(ipStr);}
0
public static void handleDatabaseIOException(String hdfsFile, IOException e)
{        throw new IllegalStateException("Unable to update MaxMind database");}
1
public static DatabaseReader readNewDatabase(DatabaseReader reader, String hdfsFile, InputStream is) throws IOException
{            DatabaseReader newReader = new DatabaseReader.Builder(is).withCache(new CHMCache()).build();        if (reader != null) {        reader.close();    }        return newReader;}
1
public static FileSystem getFileSystem()
{    FileSystem fs;    try {        fs = FileSystem.get(new Configuration());    } catch (IOException e) {                throw new IllegalStateException("Unable to get HDFS FileSystem");    }    return fs;}
1
public static String convertNullToEmptyString(Object raw)
{    return raw == null ? "" : String.valueOf(raw);}
0
public SimpleHBaseAdapter withConfig(SimpleHBaseConfig config)
{    this.config = config;    return this;}
0
public void logAccess(CacheKey value)
{}
0
public boolean isInitialized()
{    return lookup != null && lookup.getTable() != null;}
0
public JSONObject enrich(CacheKey value)
{    JSONObject enriched = new JSONObject();    if (!isInitialized()) {        initializeAdapter(null);    }    List<String> enrichmentTypes = value.getConfig().getEnrichment().getFieldToTypeMap().get(EnrichmentUtils.toTopLevelField(value.getField()));    if (isInitialized() && enrichmentTypes != null && value.getValue() != null) {        try {            for (LookupKV<EnrichmentKey, EnrichmentValue> kv : lookup.get(Iterables.transform(enrichmentTypes, new EnrichmentUtils.TypeToKey(value.coerceValue(String.class), lookup.getTable(), value.getConfig().getEnrichment())), false)) {                if (kv != null && kv.getValue() != null && kv.getValue().getMetadata() != null) {                    for (Map.Entry<String, Object> values : kv.getValue().getMetadata().entrySet()) {                        enriched.put(kv.getKey().type + "." + values.getKey(), values.getValue());                    }                    LOG.trace("Enriched type {} => {}", () -> kv.getKey().type, () -> enriched);                }            }        } catch (IOException e) {                        initializeAdapter(null);            throw new RuntimeException("Unable to retrieve value: " + e.getMessage(), e);        }    }    LOG.trace("SimpleHBaseAdapter succeeded: {}", enriched);    return enriched;}
1
public boolean initializeAdapter(Map<String, Object> configuration)
{    String hbaseTable = config.getHBaseTable();    Configuration hbaseConfig = HBaseConfiguration.create();    try {        lookup = new EnrichmentLookup(config.getProvider().getTable(hbaseConfig, hbaseTable), config.getHBaseCF(), new NoopAccessTracker());    } catch (IOException e) {                return false;    }    return true;}
1
public void updateAdapter(Map<String, Object> config)
{}
0
public void cleanup()
{    try {        lookup.close();    } catch (Exception e) {            }}
1
public String getOutputPrefix(CacheKey value)
{    return value.getField();}
0
public String getHBaseTable()
{    return hBaseTable;}
0
public String getHBaseCF()
{    return hBaseCF;}
0
public TableProvider getProvider()
{    return provider;}
0
public SimpleHBaseConfig withProviderImpl(String connectorImpl)
{    provider = EnrichmentUtils.getTableProvider(connectorImpl, new HTableProvider());    return this;}
0
public SimpleHBaseConfig withHBaseTable(String hBaseTable)
{    this.hBaseTable = hBaseTable;    return this;}
0
public SimpleHBaseConfig withHBaseCF(String cf)
{    this.hBaseCF = cf;    return this;}
0
public ConfigHandler apply(SensorEnrichmentConfig cacheKey)
{    return func.apply(cacheKey);}
0
public StellarAdapter ofType(String enrichmentType)
{    this.enrichmentType = enrichmentType;    return this;}
0
public String getOutputPrefix(CacheKey value)
{    return "";}
0
public void logAccess(CacheKey value)
{}
0
public String getStreamSubGroup(String enrichmentType, String field)
{    return field;}
0
public static Iterable<Map.Entry<String, Object>> getStellarStatements(ConfigHandler handler, String field)
{    if (field.length() == 0) {        return handler.getType().toConfig(handler.getConfig());    } else {        Map<String, Object> groupStatements = (Map<String, Object>) handler.getConfig();        return handler.getType().toConfig(groupStatements.get(field));    }}
0
public JSONObject enrich(CacheKey value)
{    Context stellarContext = (Context) value.getConfig().getConfiguration().get(STELLAR_CONTEXT_CONF);    ConfigHandler handler = getHandler.apply(value.getConfig());    Map<String, Object> globalConfig = value.getConfig().getConfiguration();    Map<String, Object> sensorConfig = value.getConfig().getEnrichment().getConfig();    if (handler == null) {        _LOG.trace("Stellar ConfigHandler is null.");        return new JSONObject();    }    Long slowLogThreshold = null;    if (_PERF_LOG.isDebugEnabled()) {        slowLogThreshold = ConversionUtils.convert(globalConfig.getOrDefault(STELLAR_SLOW_LOG, STELLAR_SLOW_LOG_DEFAULT), Long.class);    }            Map<String, Object> message = new HashMap<>(value.getValue(Map.class));    VariableResolver resolver = new MapVariableResolver(message, sensorConfig, globalConfig);    StellarProcessor processor = new StellarProcessor();    JSONObject enriched = process(message, handler, value.getField(), slowLogThreshold, processor, resolver, stellarContext);    _LOG.trace("Stellar Enrichment Success: {}", enriched);    return enriched;}
0
public boolean initializeAdapter(Map<String, Object> config)
{    getHandler = EnrichmentType.valueOf(enrichmentType);    return true;}
0
public void updateAdapter(Map<String, Object> config)
{}
0
public void cleanup()
{}
0
public ThreatIntelAdapter withConfig(ThreatIntelConfig config)
{    this.config = config;    return this;}
0
public void logAccess(CacheKey value)
{    List<String> enrichmentTypes = value.getConfig().getThreatIntel().getFieldToTypeMap().get(value.getField());    if (enrichmentTypes != null) {        for (String enrichmentType : enrichmentTypes) {            lookup.getAccessTracker().logAccess(new EnrichmentKey(enrichmentType, value.coerceValue(String.class)));        }    }}
0
public JSONObject enrich(CacheKey value)
{    if (!isInitialized()) {        initializeAdapter(null);    }    JSONObject enriched = new JSONObject();    List<String> enrichmentTypes = value.getConfig().getThreatIntel().getFieldToTypeMap().get(EnrichmentUtils.toTopLevelField(value.getField()));    if (isInitialized() && enrichmentTypes != null) {        int i = 0;        try {            for (Boolean isThreat : lookup.exists(Iterables.transform(enrichmentTypes, new EnrichmentUtils.TypeToKey(value.coerceValue(String.class), lookup.getTable(), value.getConfig().getThreatIntel())), false)) {                String enrichmentType = enrichmentTypes.get(i++);                if (isThreat) {                    enriched.put(enrichmentType, "alert");                    LOG.trace("Theat Intel Enriched value => {}", enriched);                }            }        } catch (IOException e) {                        initializeAdapter(null);            throw new RuntimeException("Theat Intel Unable to retrieve value", e);        }    }    LOG.trace("Threat Intel Enrichment Success: {}", enriched);    return enriched;}
1
public boolean isInitialized()
{    return lookup != null && lookup.getTable() != null;}
0
public boolean initializeAdapter(Map<String, Object> configuration)
{    PersistentAccessTracker accessTracker;    String hbaseTable = config.getHBaseTable();    int expectedInsertions = config.getExpectedInsertions();    double falsePositives = config.getFalsePositiveRate();    String trackerHBaseTable = config.getTrackerHBaseTable();    String trackerHBaseCF = config.getTrackerHBaseCF();    long millisecondsBetweenPersist = config.getMillisecondsBetweenPersists();    BloomAccessTracker bat = new BloomAccessTracker(hbaseTable, expectedInsertions, falsePositives);    Configuration hbaseConfig = HBaseConfiguration.create();    try {        accessTracker = new PersistentAccessTracker(hbaseTable, UUID.randomUUID().toString(), config.getProvider().getTable(hbaseConfig, trackerHBaseTable), trackerHBaseCF, bat, millisecondsBetweenPersist);        lookup = new EnrichmentLookup(config.getProvider().getTable(hbaseConfig, hbaseTable), config.getHBaseCF(), accessTracker);    } catch (IOException e) {                return false;    }    return true;}
1
public void updateAdapter(Map<String, Object> config)
{}
0
public void cleanup()
{    try {        lookup.close();    } catch (Exception e) {        throw new RuntimeException("Unable to cleanup access tracker", e);    }}
0
public String getOutputPrefix(CacheKey value)
{    return value.getField();}
0
public String getHBaseTable()
{    return hBaseTable;}
0
public int getExpectedInsertions()
{    return expectedInsertions;}
0
public double getFalsePositiveRate()
{    return falsePositiveRate;}
0
public String getTrackerHBaseTable()
{    return trackerHBaseTable;}
0
public String getTrackerHBaseCF()
{    return trackerHBaseCF;}
0
public long getMillisecondsBetweenPersists()
{    return millisecondsBetweenPersists;}
0
public String getHBaseCF()
{    return hBaseCF;}
0
public TableProvider getProvider()
{    return provider;}
0
public ThreatIntelConfig withProviderImpl(String connectorImpl)
{    provider = EnrichmentUtils.getTableProvider(connectorImpl, new HTableProvider());    return this;}
0
public ThreatIntelConfig withTrackerHBaseTable(String hBaseTable)
{    this.trackerHBaseTable = hBaseTable;    return this;}
0
public ThreatIntelConfig withTrackerHBaseCF(String cf)
{    this.trackerHBaseCF = cf;    return this;}
0
public ThreatIntelConfig withHBaseTable(String hBaseTable)
{    this.hBaseTable = hBaseTable;    return this;}
0
public ThreatIntelConfig withHBaseCF(String cf)
{    this.hBaseCF = cf;    return this;}
0
public ThreatIntelConfig withFalsePositiveRate(double falsePositiveRate)
{    this.falsePositiveRate = falsePositiveRate;    return this;}
0
public ThreatIntelConfig withExpectedInsertions(int expectedInsertions)
{    this.expectedInsertions = expectedInsertions;    return this;}
0
public ThreatIntelConfig withMillisecondsBetweenPersists(long millisecondsBetweenPersists)
{    this.millisecondsBetweenPersists = millisecondsBetweenPersists;    return this;}
0
public String getField()
{    return field;}
0
public Object getValue()
{    return value;}
0
public T getValue(Class<T> clazz)
{    return clazz.cast(getValue());}
0
public T coerceValue(Class<T> clazz)
{    return ConversionUtils.convert(getValue(), clazz);}
0
public SensorEnrichmentConfig getConfig()
{    return config;}
0
public String toString()
{    return "CacheKey{" + "field='" + field + '\'' + ", value='" + value + '\'' + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    CacheKey cacheKey = (CacheKey) o;    if (getField() != null ? !getField().equals(cacheKey.getField()) : cacheKey.getField() != null)        return false;    if (getValue() != null ? !getValue().equals(cacheKey.getValue()) : cacheKey.getValue() != null)        return false;    return config != null ? config.equals(cacheKey.config) : cacheKey.config == null;}
0
public int hashCode()
{    int result = getField() != null ? getField().hashCode() : 0;    result = 31 * result + (getValue() != null ? getValue().hashCode() : 0);    result = 31 * result + (config != null ? config.hashCode() : 0);    return result;}
0
public Object load(String s) throws Exception
{        if (StringUtils.isEmpty(s)) {        throw new IllegalArgumentException("Path cannot be empty");    }    Object object = null;    Path p = new Path(s);    if (fs.exists(p)) {        if (fs.getFileStatus(p).getLen() <= objectCacheConfig.getMaxFileSize()) {            try (InputStream is = new BufferedInputStream(fs.open(p))) {                byte[] serialized = IOUtils.toByteArray(is);                if (serialized.length > 0) {                    object = SerDeUtils.fromBytes(serialized, Object.class);                }            }        } else {            throw new IllegalArgumentException(String.format("File at path '%s' is larger than the configured max file size of %s", p, objectCacheConfig.getMaxFileSize()));        }    } else {        throw new IllegalArgumentException(String.format("Path '%s' could not be found in HDFS", s));    }    return object;}
1
public Object get(String path)
{    return cache.get(path);}
0
public void initialize(ObjectCacheConfig config)
{    try {        lock.writeLock().lock();        cache = setupCache(config);    } catch (IOException e) {        throw new IllegalStateException("Unable to initialize: " + e.getMessage(), e);    } finally {        lock.writeLock().unlock();    }}
0
public boolean isInitialized()
{    try {        lock.readLock().lock();        return cache != null;    } finally {        lock.readLock().unlock();    }}
0
protected LoadingCache<String, Object> setupCache(ObjectCacheConfig config) throws IOException
{        return Caffeine.newBuilder().maximumSize(config.getCacheSize()).expireAfterWrite(config.getCacheExpiration(), config.getTimeUnit()).removalListener((path, value, removalCause) -> {            }).build(new Loader(new Configuration(), config));}
1
public boolean isEmpty()
{    return cache == null || cache.estimatedSize() == 0;}
0
public boolean containsKey(String key)
{    return cache != null && cache.asMap().containsKey(key);}
0
public long getCacheSize()
{    return cacheSize;}
0
public void setCacheSize(long cacheSize)
{    this.cacheSize = cacheSize;}
0
public long getCacheExpiration()
{    return cacheExpiration;}
0
public void setCacheExpiration(long cacheExpiration)
{    this.cacheExpiration = cacheExpiration;}
0
public TimeUnit getTimeUnit()
{    return timeUnit;}
0
public void setTimeUnit(TimeUnit timeUnit)
{    this.timeUnit = timeUnit;}
0
public long getMaxFileSize()
{    return maxFileSize;}
0
public void setMaxFileSize(long maxFileSize)
{    this.maxFileSize = maxFileSize;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ObjectCacheConfig that = (ObjectCacheConfig) o;    return cacheSize == that.cacheSize && cacheExpiration == that.cacheExpiration && timeUnit == that.timeUnit && maxFileSize == that.maxFileSize;}
0
public int hashCode()
{    return Objects.hash(cacheSize, cacheExpiration, timeUnit, maxFileSize);}
0
public String toString()
{    return "ObjectCacheConfig{" + "cacheSize=" + cacheSize + ", cacheExpiration=" + cacheExpiration + ", timeUnit=" + timeUnit + ", maxFileSize=" + maxFileSize + '}';}
0
public void updateMetrics(List<String> metrics)
{    this.metrics = metrics;}
0
public Map<Pair, DescriptiveStatistics> getStatsMap(int depth)
{    Map<Pair, DescriptiveStatistics> statsMap = depthMap.get(depth);    if (statsMap == null) {        statsMap = new HashMap<>();        depthMap.put(depth, statsMap);    }    return statsMap;}
0
public DescriptiveStatistics getStats(int depth, Pair p)
{    Map<Pair, DescriptiveStatistics> statsMap = getStatsMap(depth);    DescriptiveStatistics stats = statsMap.get(p);    if (stats == null) {        stats = new DescriptiveStatistics();        statsMap.put(p, stats);    }    return stats;}
0
public void put(int depth, Pair p, double val)
{    getStats(depth, p).addValue(val);}
0
public static void summary(String title, DescriptiveStatistics statistics, PrintStream pw, boolean meanOnly)
{    if (meanOnly) {        pw.println(title + ": " + "\n\tMean: " + statistics.getMean());    } else {        pw.println(title + ": " + "\n\tMean: " + statistics.getMean() + "\n\tMin: " + statistics.getMin() + "\n\t1th: " + statistics.getPercentile(1) + "\n\t5th: " + statistics.getPercentile(5) + "\n\t10th: " + statistics.getPercentile(10) + "\n\t25th: " + statistics.getPercentile(25) + "\n\t50th: " + statistics.getPercentile(50) + "\n\t90th: " + statistics.getPercentile(90) + "\n\t95th: " + statistics.getPercentile(95) + "\n\t99th: " + statistics.getPercentile(99) + "\n\tMax: " + statistics.getMax() + "\n\tStdDev: " + statistics.getStandardDeviation());    }}
0
public void printDepthSummary(int depth, boolean meanOnly)
{    Map<Pair, DescriptiveStatistics> statsMap = depthMap.get(depth);    System.out.println("\nDistance " + depth);    System.out.println("----------------\n");    List<Map.Entry<Pair, DescriptiveStatistics>> sortedStats = new ArrayList<>();    for (Map.Entry<Pair, DescriptiveStatistics> stats : statsMap.entrySet()) {        sortedStats.add(stats);    }    Collections.sort(sortedStats, new Comparator<Map.Entry<Pair, DescriptiveStatistics>>() {        @Override        public int compare(Map.Entry<Pair, DescriptiveStatistics> o1, Map.Entry<Pair, DescriptiveStatistics> o2) {            return -1 * Double.compare(o1.getValue().getMean(), o2.getValue().getMean());        }    });    for (Map.Entry<Pair, DescriptiveStatistics> stats : sortedStats) {        summary(stats.getKey().getKey() + " -> " + stats.getKey().getValue(), stats.getValue(), System.out, meanOnly);    }}
0
public int compare(Map.Entry<Pair, DescriptiveStatistics> o1, Map.Entry<Pair, DescriptiveStatistics> o2)
{    return -1 * Double.compare(o1.getValue().getMean(), o2.getValue().getMean());}
0
public void printSummary(boolean meanOnly)
{    System.out.println("Flow:");    System.out.println("\t" + Joiner.on(" -> ").join(metrics));    System.out.println("\nSUMMARY BY DISTANCE\n--------------------------");    for (int depth : depthMap.keySet()) {        printDepthSummary(depth, meanOnly);    }}
0
public static String getBaseMetric(String s)
{    Iterable<String> tokenIt = Splitter.on('.').split(s);    int num = Iterables.size(tokenIt);    return Joiner.on('.').join(Iterables.limit(tokenIt, num - 1));}
0
public static void updateStats(LatencyStats stats, Map<String, Object> doc)
{    Map<String, Long> latencyMap = new HashMap<>();    NavigableMap<Long, String> latencyInvMap = new TreeMap<>();    for (Map.Entry<String, Object> kv : doc.entrySet()) {        if (kv.getKey().endsWith(".ts")) {            String base = getBaseMetric(kv.getKey());            long latency = Long.parseLong(kv.getValue().toString());            latencyInvMap.put(latency, base);            latencyMap.put(base, latency);        }    }    List<String> metrics = new ArrayList<>();    for (Map.Entry<Long, String> kv : latencyInvMap.entrySet()) {        metrics.add(kv.getValue());    }    stats.updateMetrics(metrics);    for (int i = 0; i < metrics.size(); ++i) {        for (int j = i + 1; j < metrics.size(); ++j) {            Pair p = new Pair(metrics.get(i), metrics.get(j));            long ms = latencyMap.get(metrics.get(j)) - latencyMap.get(metrics.get(i));            stats.put(j - i, p, ms);        }    }}
0
public static void main(String... argv) throws IOException
{    Options options = new Options();    {        Option o = new Option("h", "help", false, "This screen");        o.setRequired(false);        options.addOption(o);    }    {        Option o = new Option("m", "mean_only", false, "Print the mean only when we summarize");        o.setRequired(false);        options.addOption(o);    }    CommandLineParser parser = new PosixParser();    CommandLine cmd = null;    try {        cmd = parser.parse(options, argv);    } catch (ParseException pe) {        pe.printStackTrace();        final HelpFormatter usageFormatter = new HelpFormatter();        usageFormatter.printHelp(LatencySummarizer.class.getSimpleName().toLowerCase(), null, options, null, true);        System.exit(-1);    }    if (cmd.hasOption("h")) {        final HelpFormatter usageFormatter = new HelpFormatter();        usageFormatter.printHelp(LatencySummarizer.class.getSimpleName().toLowerCase(), null, options, null, true);        System.exit(0);    }    LatencyStats statsMap = new LatencyStats();    BufferedReader reader = new BufferedReader(new InputStreamReader(System.in, StandardCharsets.UTF_8));    for (String line = null; (line = reader.readLine()) != null; ) {        Map<String, Object> doc = JSONUtils.INSTANCE.load(line, JSONUtils.MAP_SUPPLIER);        updateStats(statsMap, doc);    }    statsMap.printSummary(cmd.hasOption('m'));}
0
public List<String> getFields()
{    return fields;}
0
public void setFields(List<String> fields)
{    this.fields = fields;}
0
public String getType()
{    return type;}
0
public void setType(String type)
{    this.type = type;}
0
public T getAdapter()
{    return adapter;}
0
public void setAdapter(T adapter)
{    this.adapter = adapter;}
0
public Map.Entry<byte[], byte[]> apply(@Nullable Cell cell)
{    return new AbstractMap.SimpleEntry<>(cell.getQualifier(), cell.getValue());}
0
public Put toPut(String columnFamily, KEY_T key, VALUE_T values) throws IOException
{    Put put = new Put(key.toBytes());    byte[] cf = Bytes.toBytes(columnFamily);    for (Map.Entry<byte[], byte[]> kv : values.toColumns()) {        put.add(cf, kv.getKey(), kv.getValue());    }    return put;}
0
public LookupKV<KEY_T, VALUE_T> fromPut(Put put, String columnFamily, KEY_T key, VALUE_T value) throws IOException
{    key.fromBytes(put.getRow());    byte[] cf = Bytes.toBytes(columnFamily);    value.fromColumns(Iterables.transform(put.getFamilyCellMap().get(cf), CELL_TO_ENTRY));    return new LookupKV<>(key, value);}
0
public Result toResult(String columnFamily, KEY_T key, VALUE_T values) throws IOException
{    Put put = toPut(columnFamily, key, values);    return Result.create(put.getFamilyCellMap().get(Bytes.toBytes(columnFamily)));}
0
public LookupKV<KEY_T, VALUE_T> fromResult(Result result, String columnFamily, KEY_T key, VALUE_T value) throws IOException
{    if (result == null || result.getRow() == null) {        return null;    }    key.fromBytes(result.getRow());    byte[] cf = Bytes.toBytes(columnFamily);    NavigableMap<byte[], byte[]> cols = result.getFamilyMap(cf);    value.fromColumns(cols.entrySet());    return new LookupKV<>(key, value);}
0
public Get toGet(String columnFamily, KEY_T key)
{    Get ret = new Get(key.toBytes());    ret.addFamily(Bytes.toBytes(columnFamily));    return ret;}
0
public static Iterable<Map.Entry<byte[], byte[]>> toEntries(byte[]... kvs)
{    if (kvs.length % 2 != 0) {        throw new IllegalStateException("Must be an even size");    }    List<Map.Entry<byte[], byte[]>> ret = new ArrayList<>(kvs.length / 2);    for (int i = 0; i < kvs.length; i += 2) {        ret.add(new AbstractMap.SimpleImmutableEntry<>(kvs[i], kvs[i + 1]));    }    return ret;}
0
public LookupKV<EnrichmentKey, EnrichmentValue> fromPut(Put put, String columnFamily) throws IOException
{    return fromPut(put, columnFamily, new EnrichmentKey(), new EnrichmentValue());}
0
public LookupKV<EnrichmentKey, EnrichmentValue> fromResult(Result result, String columnFamily) throws IOException
{    return fromResult(result, columnFamily, new EnrichmentKey(), new EnrichmentValue());}
0
public void load(Table table, String cf, Iterable<LookupKV<EnrichmentKey, EnrichmentValue>> results) throws IOException
{    for (LookupKV<EnrichmentKey, EnrichmentValue> result : results) {        Put put = converter.toPut(cf, result.getKey(), result.getValue());        table.put(put);    }}
0
private byte[] typedIndicatorToBytes() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutputStream w = new DataOutputStream(baos);    w.writeUTF(type);    w.writeUTF(indicator);    w.flush();    return baos.toByteArray();}
0
public byte[] toBytes()
{    byte[] indicatorBytes = new byte[0];    try {        indicatorBytes = typedIndicatorToBytes();    } catch (IOException e) {        throw new RuntimeException("Unable to convert type and indicator to bytes", e);    }    byte[] prefix = KeyUtil.INSTANCE.getPrefix(Bytes.toBytes(indicator));    return KeyUtil.INSTANCE.merge(prefix, indicatorBytes);}
0
public void fromBytes(byte[] row)
{    ByteArrayInputStream baos = new ByteArrayInputStream(row);    baos.skip(KeyUtil.HASH_PREFIX_SIZE);    DataInputStream w = new DataInputStream(baos);    try {        type = w.readUTF();        indicator = w.readUTF();    } catch (IOException e) {        throw new RuntimeException("Unable to convert type and indicator from bytes", e);    }}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    EnrichmentKey that = (EnrichmentKey) o;    if (indicator != null ? !indicator.equals(that.indicator) : that.indicator != null)        return false;    return type != null ? type.equals(that.type) : that.type == null;}
0
public int hashCode()
{    int result = indicator != null ? indicator.hashCode() : 0;    result = 31 * result + (type != null ? type.hashCode() : 0);    return result;}
0
public String toString()
{    return "EnrichmentKey{" + "indicator='" + indicator + '\'' + ", type='" + type + '\'' + '}';}
0
public String getIndicator()
{    return indicator;}
0
public void setIndicator(String indicator)
{    this.indicator = indicator;}
0
protected ObjectMapper initialValue()
{    return new ObjectMapper();}
0
public Map<String, Object> getMetadata()
{    return metadata;}
0
public Iterable<Map.Entry<byte[], byte[]>> toColumns()
{    return AbstractConverter.toEntries(VALUE_COLUMN_NAME_B, Bytes.toBytes(valueToString(metadata)));}
0
public void fromColumns(Iterable<Map.Entry<byte[], byte[]>> values)
{    for (Map.Entry<byte[], byte[]> cell : values) {        if (Bytes.equals(cell.getKey(), VALUE_COLUMN_NAME_B)) {            metadata = stringToValue(Bytes.toString(cell.getValue()));        }    }}
0
public Map<String, Object> stringToValue(String s)
{    try {        return _mapper.get().readValue(s, new TypeReference<Map<String, Object>>() {        });    } catch (IOException e) {        throw new RuntimeException("Unable to convert string to metadata: " + s);    }}
0
public String valueToString(Map<String, Object> value)
{    try {        return _mapper.get().writeValueAsString(value);    } catch (IOException e) {        throw new RuntimeException("Unable to convert metadata to string: " + value);    }}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    EnrichmentValue that = (EnrichmentValue) o;    return getMetadata() != null ? getMetadata().equals(that.getMetadata()) : that.getMetadata() == null;}
0
public int hashCode()
{    return getMetadata() != null ? getMetadata().hashCode() : 0;}
0
public String toString()
{    return "EnrichmentValue{" + "metadata=" + metadata + '}';}
0
 String getStreamSubGroup(String enrichmentType, String field)
{    return "";}
0
public AccessTracker create(Map<String, Object> config, TableProvider provider) throws IOException
{    return creator.create(config, provider);}
0
public AccessTracker deserializeTracker(byte[] bytes) throws IOException, ClassNotFoundException
{    ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(bytes));    return (AccessTracker) ois.readObject();}
0
public byte[] serializeTracker(AccessTracker tracker) throws IOException
{    ByteArrayOutputStream bos = new ByteArrayOutputStream();    ObjectOutputStream oos = new ObjectOutputStream(bos);    oos.writeObject(tracker);    oos.flush();    oos.close();    return bos.toByteArray();}
0
public void persistTracker(Table accessTrackerTable, String columnFamily, PersistentAccessTracker.AccessTrackerKey key, AccessTracker underlyingTracker) throws IOException
{    Put put = new Put(key.toRowKey());    put.add(Bytes.toBytes(columnFamily), COLUMN, serializeTracker(underlyingTracker));    accessTrackerTable.put(put);}
0
public Iterable<AccessTracker> loadAll(Table accessTrackerTable, final String columnFamily, final String name, final long earliest) throws IOException
{    Scan scan = new Scan(PersistentAccessTracker.AccessTrackerKey.getTimestampScanKey(name, earliest));    ResultScanner scanner = accessTrackerTable.getScanner(scan);    return Iterables.transform(scanner, new Function<Result, AccessTracker>() {        @Nullable        @Override        public AccessTracker apply(@Nullable Result result) {            try {                return deserializeTracker(result.getValue(Bytes.toBytes(columnFamily), COLUMN));            } catch (Exception e) {                throw new RuntimeException("Unable to deserialize " + name + " @ " + earliest);            }        }    });}
0
public AccessTracker apply(@Nullable Result result)
{    try {        return deserializeTracker(result.getValue(Bytes.toBytes(columnFamily), COLUMN));    } catch (Exception e) {        throw new RuntimeException("Unable to deserialize " + name + " @ " + earliest);    }}
0
public AccessTracker loadAll(Iterable<AccessTracker> trackers) throws IOException, ClassNotFoundException
{    AccessTracker tracker = null;    for (AccessTracker t : trackers) {        if (tracker == null) {            tracker = t;        } else {            tracker = tracker.union(t);        }    }    return tracker;}
0
public byte[] apply(LookupKey lookupKey)
{    return lookupKey.toBytes();}
0
protected BloomFilter<LookupKey> getFilter()
{    return filter;}
0
public void logAccess(LookupKey key)
{    numInsertions++;    filter.add(key);}
0
public void configure(Map<String, Object> config)
{    expectedInsertions = toInt(config.get(EXPECTED_INSERTIONS_KEY));    falsePositiveRate = toDouble(config.get(FALSE_POSITIVE_RATE_KEY));    name = config.get(NAME_KEY).toString();    filter = new BloomFilter<LookupKey>(new LookupKeySerializer(), expectedInsertions, falsePositiveRate);}
0
public boolean hasSeen(LookupKey key)
{    return filter.mightContain(key);}
0
public void reset()
{    filter = new BloomFilter<LookupKey>(new LookupKeySerializer(), expectedInsertions, falsePositiveRate);}
0
private static double toDouble(Object o)
{    if (o instanceof String) {        return Double.parseDouble((String) o);    } else if (o instanceof Number) {        return ((Number) o).doubleValue();    } else {        throw new IllegalStateException("Unable to convert " + o + " to a double.");    }}
0
private static int toInt(Object o)
{    if (o instanceof String) {        return Integer.parseInt((String) o);    } else if (o instanceof Number) {        return ((Number) o).intValue();    } else {        throw new IllegalStateException("Unable to convert " + o + " to a double.");    }}
0
public String getName()
{    return name;}
0
public AccessTracker union(AccessTracker tracker)
{    if (filter == null) {        throw new IllegalStateException("Unable to union access tracker, because this tracker is not initialized.");    }    if (tracker instanceof BloomAccessTracker) {        filter.merge(((BloomAccessTracker) tracker).getFilter());        return this;    } else {        throw new IllegalStateException("Unable to union access tracker, because it's not of the right type (BloomAccessTracker)");    }}
0
public boolean isFull()
{    return numInsertions >= expectedInsertions;}
0
public void cleanup() throws IOException
{}
0
public void logAccess(LookupKey key)
{}
0
public void configure(Map<String, Object> config)
{}
0
public boolean hasSeen(LookupKey key)
{    return false;}
0
public String getName()
{    return "noop";}
0
public AccessTracker union(AccessTracker tracker)
{    return null;}
0
public void reset()
{}
0
public boolean isFull()
{    return false;}
0
public void cleanup() throws IOException
{}
0
public byte[] toRowKey()
{    ByteArrayOutputStream os = new ByteArrayOutputStream();    DataOutputStream dos = new DataOutputStream(os);    try {        dos.writeUTF(name);        dos.writeLong(timestamp);        dos.writeUTF(containerName);        dos.flush();    } catch (IOException e) {        throw new RuntimeException("Unable to write rowkey: " + this, e);    }    return os.toByteArray();}
0
public static byte[] getTimestampScanKey(String name, long timestamp)
{    ByteArrayOutputStream os = new ByteArrayOutputStream();    DataOutputStream dos = new DataOutputStream(os);    try {        dos.writeUTF(name);        dos.writeLong(timestamp);    } catch (IOException e) {        throw new RuntimeException("Unable to create scan key ", e);    }    return os.toByteArray();}
0
public static AccessTrackerKey fromRowKey(byte[] rowKey)
{    ByteArrayInputStream is = new ByteArrayInputStream(rowKey);    DataInputStream dis = new DataInputStream(is);    try {        String name = dis.readUTF();        long timestamp = dis.readLong();        String containerName = dis.readUTF();        return new AccessTrackerKey(name, containerName, timestamp);    } catch (IOException e) {        throw new RuntimeException("Unable to read rowkey: ", e);    }}
0
public void run()
{    tracker.persist(false);}
0
public void persist(boolean force)
{    synchronized (sync) {        if (force || (System.currentTimeMillis() - timestamp) >= maxMillisecondsBetweenPersists) {                        try {                AccessTrackerUtil.INSTANCE.persistTracker(accessTrackerTable, accessTrackerColumnFamily, new AccessTrackerKey(name, containerName, timestamp), underlyingTracker);                timestamp = System.currentTimeMillis();                reset();            } catch (IOException e) {                            }        }    }}
1
public void logAccess(LookupKey key)
{    synchronized (sync) {        underlyingTracker.logAccess(key);        if (isFull()) {            persist(true);        }    }}
0
public void configure(Map<String, Object> config)
{    underlyingTracker.configure(config);}
0
public boolean hasSeen(LookupKey key)
{    synchronized (sync) {        return underlyingTracker.hasSeen(key);    }}
0
public String getName()
{    return underlyingTracker.getName();}
0
public AccessTracker union(AccessTracker tracker)
{    PersistentAccessTracker t1 = (PersistentAccessTracker) tracker;    underlyingTracker = underlyingTracker.union(t1.underlyingTracker);    return this;}
0
public void reset()
{    synchronized (sync) {        underlyingTracker.reset();    }}
0
public boolean isFull()
{    synchronized (sync) {        return underlyingTracker.isFull();    }}
0
public void cleanup() throws IOException
{    synchronized (sync) {        try {            persist(true);        } catch (Throwable t) {                    }        underlyingTracker.cleanup();        accessTrackerTable.close();    }}
1
public String getHBaseTable()
{    return hBaseTable;}
0
public String getHBaseCF()
{    return hBaseCF;}
0
public double getFalsePositiveRate()
{    return falsePositiveRate;}
0
public int getExpectedInsertions()
{    return expectedInsertions;}
0
public long getMillisecondsBetweenPersists()
{    return millisecondsBetweenPersists;}
0
public AccessTracker create(Map<String, Object> config, TableProvider provider) throws IOException
{    Config patConfig = new Config(config);    String hbaseTable = patConfig.getHBaseTable();    int expectedInsertions = patConfig.getExpectedInsertions();    double falsePositives = patConfig.getFalsePositiveRate();    long millisecondsBetweenPersist = patConfig.getMillisecondsBetweenPersists();    BloomAccessTracker bat = new BloomAccessTracker(hbaseTable, expectedInsertions, falsePositives);    Configuration hbaseConfig = HBaseConfiguration.create();    AccessTracker ret = new PersistentAccessTracker(hbaseTable, UUID.randomUUID().toString(), provider.getTable(hbaseConfig, hbaseTable), patConfig.getHBaseCF(), bat, millisecondsBetweenPersist);    return ret;}
0
public Table getTable()
{    return table;}
0
public String getColumnFamily()
{    return columnFamily;}
0
private String getColumnFamily(HBaseContext context)
{    return context.getColumnFamily() == null ? columnFamily : context.getColumnFamily();}
0
public boolean exists(EnrichmentKey key, HBaseContext context, boolean logAccess) throws IOException
{    return context.getTable().exists(converter.toGet(getColumnFamily(context), key));}
0
public LookupKV<EnrichmentKey, EnrichmentValue> get(EnrichmentKey key, HBaseContext context, boolean logAccess) throws IOException
{    return converter.fromResult(context.getTable().get(converter.toGet(getColumnFamily(context), key)), getColumnFamily(context));}
0
private List<Get> keysToGets(Iterable<KeyWithContext<EnrichmentKey, HBaseContext>> keys)
{    List<Get> ret = new ArrayList<>();    for (KeyWithContext<EnrichmentKey, HBaseContext> key : keys) {        ret.add(converter.toGet(getColumnFamily(key.getContext()), key.getKey()));    }    return ret;}
0
public Iterable<Boolean> exists(Iterable<KeyWithContext<EnrichmentKey, HBaseContext>> key, boolean logAccess) throws IOException
{    List<Boolean> ret = new ArrayList<>();    if (Iterables.isEmpty(key)) {        return Collections.emptyList();    }    Table table = Iterables.getFirst(key, null).getContext().getTable();    for (boolean b : table.existsAll(keysToGets(key))) {        ret.add(b);    }    return ret;}
0
public Iterable<LookupKV<EnrichmentKey, EnrichmentValue>> get(Iterable<KeyWithContext<EnrichmentKey, HBaseContext>> keys, boolean logAccess) throws IOException
{    if (Iterables.isEmpty(keys)) {        return Collections.emptyList();    }    Table table = Iterables.getFirst(keys, null).getContext().getTable();    List<LookupKV<EnrichmentKey, EnrichmentValue>> ret = new ArrayList<>();    Iterator<KeyWithContext<EnrichmentKey, HBaseContext>> keyWithContextIterator = keys.iterator();    for (Result result : table.get(keysToGets(keys))) {        HBaseContext context = keyWithContextIterator.next().getContext();        ret.add(converter.fromResult(result, getColumnFamily(context)));    }    return ret;}
0
public void close() throws Exception
{}
0
public Table getTable()
{    return table;}
0
public void close() throws Exception
{    super.close();    table.close();}
0
public KEY_T getKey()
{    return key;}
0
public CONTEXT_T getContext()
{    return context;}
0
public String getName()
{    return name;}
0
public void setName(String name)
{    this.name = name;}
0
public AccessTracker getAccessTracker()
{    return accessTracker;}
0
public void setAccessTracker(AccessTracker accessTracker)
{    this.accessTracker = accessTracker;}
0
public Handler<CONTEXT_T, KEY_T, RESULT_T> getLookupHandler()
{    return lookupHandler;}
0
public void setLookupHandler(Handler<CONTEXT_T, KEY_T, RESULT_T> lookupHandler)
{    this.lookupHandler = lookupHandler;}
0
public boolean exists(KEY_T key, CONTEXT_T context, boolean logAccess) throws IOException
{    if (logAccess) {        accessTracker.logAccess(key);    }    return lookupHandler.exists(key, context, logAccess);}
0
public RESULT_T get(KEY_T key, CONTEXT_T context, boolean logAccess) throws IOException
{    if (logAccess) {        accessTracker.logAccess(key);    }    return lookupHandler.get(key, context, logAccess);}
0
public Iterable<Boolean> exists(Iterable<KeyWithContext<KEY_T, CONTEXT_T>> key, boolean logAccess) throws IOException
{    if (logAccess) {        for (KeyWithContext<KEY_T, CONTEXT_T> k : key) {            accessTracker.logAccess(k.getKey());        }    }    return lookupHandler.exists(key, logAccess);}
0
public Iterable<RESULT_T> get(Iterable<KeyWithContext<KEY_T, CONTEXT_T>> key, boolean logAccess) throws IOException
{    if (logAccess) {        for (KeyWithContext<KEY_T, CONTEXT_T> k : key) {            accessTracker.logAccess(k.getKey());        }    }    return lookupHandler.get(key, logAccess);}
0
public void close() throws Exception
{    accessTracker.cleanup();    lookupHandler.close();}
0
public KEY_T getKey()
{    return key;}
0
public VALUE_T getValue()
{    return value;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    LookupKV<?, ?> lookupKV = (LookupKV<?, ?>) o;    if (key != null ? !key.equals(lookupKV.key) : lookupKV.key != null)        return false;    return value != null ? value.equals(lookupKV.value) : lookupKV.value == null;}
0
public int hashCode()
{    int result = key != null ? key.hashCode() : 0;    result = 31 * result + (value != null ? value.hashCode() : 0);    return result;}
0
public String toString()
{    return "LookupKV{" + "key=" + key + ", value=" + value + '}';}
0
public static ConcurrencyContext get(EnrichmentStrategies strategy)
{    return strategyToInfrastructure.get(strategy);}
0
public synchronized void initialize(int numThreads, long maxCacheSize, long maxTimeRetain, WorkerPoolStrategies poolStrategy, Logger log, boolean logStats)
{    if (executor == null) {        if (log != null) {                    }        executor = (poolStrategy == null ? WorkerPoolStrategies.FIXED : poolStrategy).create(numThreads);    }    if (cache == null) {        if (log != null) {                    }        Caffeine builder = Caffeine.newBuilder().maximumSize(maxCacheSize).expireAfterWrite(maxTimeRetain, TimeUnit.MINUTES).executor(executor);        if (logStats) {            builder = builder.recordStats();        }        cache = builder.build();    }}
1
public static Executor getExecutor()
{    return executor;}
0
public Cache<CacheKey, JSONObject> getCache()
{    return cache;}
0
public JSONObject call() throws Exception
{        adapter.logAccess(key);    return adapter.enrich(key);}
0
public JSONObject apply(CacheKey cacheKey)
{    adapter.logAccess(key);    return adapter.enrich(cacheKey);}
0
public FunctionResolver getFunctionResolver()
{    return functionResolver;}
0
public Context getStellarContext()
{    return stellarContext;}
0
public EnrichmentConfig getUnderlyingConfig(SensorEnrichmentConfig config)
{    return enrichmentStrategy.getUnderlyingConfig(config);}
0
public String fieldToEnrichmentKey(String type, String field)
{    return enrichmentStrategy.fieldToEnrichmentKey(type, field);}
0
public JSONObject postProcess(JSONObject message, SensorEnrichmentConfig config, EnrichmentContext context)
{    return enrichmentStrategy.postProcess(message, config, context);}
0
public Constants.ErrorType getErrorType()
{    return enrichmentStrategy.getErrorType();}
0
public EnrichmentConfig getUnderlyingConfig(SensorEnrichmentConfig config)
{    return config.getEnrichment();}
0
public Constants.ErrorType getErrorType()
{    return Constants.ErrorType.ENRICHMENT_ERROR;}
0
public String fieldToEnrichmentKey(String type, String field)
{    return EnrichmentUtils.getEnrichmentKey(type, field);}
0
public EnrichmentConfig getUnderlyingConfig(SensorEnrichmentConfig config)
{    return config.getThreatIntel();}
0
public Constants.ErrorType getErrorType()
{    return Constants.ErrorType.THREAT_INTEL_ERROR;}
0
public String fieldToEnrichmentKey(String type, String field)
{    return ThreatIntelUtils.getThreatIntelKey(type, field);}
0
public JSONObject postProcess(JSONObject message, SensorEnrichmentConfig config, EnrichmentContext context)
{    return ThreatIntelUtils.triage(message, config, context.getFunctionResolver(), context.getStellarContext());}
0
 JSONObject postProcess(JSONObject message, SensorEnrichmentConfig config, EnrichmentContext context)
{    return message;}
0
public JSONObject getResult()
{    return result;}
0
public List<Map.Entry<Object, Throwable>> getEnrichmentErrors()
{    return enrichmentErrors;}
0
public EnrichmentResult apply(JSONObject message, EnrichmentStrategies strategy, SensorEnrichmentConfig config, PerformanceLogger perfLog) throws ExecutionException, InterruptedException
{    if (message == null) {        return null;    }    if (perfLog != null) {        perfLog.mark("execute");        if (perfLog.isDebugEnabled() && !cacheStats.isEmpty()) {            CacheStats before = cacheStats.get(strategy);            CacheStats after = concurrencyContext.getCache().stats();            if (before != null && after != null) {                CacheStats delta = after.minus(before);                perfLog.log("cache", delta.toString());            }            cacheStats.put(strategy, after);        }    }    String sensorType = MessageUtils.getSensorType(message);    message.put(getClass().getSimpleName().toLowerCase() + ".splitter.begin.ts", "" + System.currentTimeMillis());                        Map<String, List<JSONObject>> tasks = splitMessage(message, strategy, config);    message.put(getClass().getSimpleName().toLowerCase() + ".splitter.end.ts", "" + System.currentTimeMillis());    message.put(getClass().getSimpleName().toLowerCase() + ".enrich.begin.ts", "" + System.currentTimeMillis());    if (perfLog != null) {        perfLog.mark("enrich");    }    List<CompletableFuture<JSONObject>> taskList = new ArrayList<>();    List<Map.Entry<Object, Throwable>> errors = Collections.synchronizedList(new ArrayList<>());    for (Map.Entry<String, List<JSONObject>> task : tasks.entrySet()) {                EnrichmentAdapter<CacheKey> adapter = enrichmentsByType.get(task.getKey());        if (adapter == null) {            throw new IllegalStateException("Unable to find an adapter for " + task.getKey() + ", possible adapters are: " + Joiner.on(",").join(enrichmentsByType.keySet()));        }        message.put("adapter." + adapter.getClass().getSimpleName().toLowerCase() + ".begin.ts", "" + System.currentTimeMillis());        for (JSONObject m : task.getValue()) {            /* now for each unit of work (each of these only has one element in them)         * the key is the field name and the value is value associated with that field.         *         * In the case of stellar enrichment, the field name is the subgroup name or empty string.         * The value is the subset of the message needed for the enrichment.         *         * In the case of another enrichment (e.g. hbase), the field name is the field name being enriched.         * The value is the corresponding value.         */            for (Object o : m.keySet()) {                String field = (String) o;                Object value = m.get(o);                if (value == null) {                    message.put("adapter." + adapter.getClass().getSimpleName().toLowerCase() + ".end.ts", "" + System.currentTimeMillis());                    continue;                }                CacheKey cacheKey = new CacheKey(field, value, config);                String prefix = adapter.getOutputPrefix(cacheKey);                Supplier<JSONObject> supplier = () -> {                    try {                        JSONObject ret = concurrencyContext.getCache().get(cacheKey, new EnrichmentCallable(cacheKey, adapter));                        if (ret == null) {                            ret = new JSONObject();                        }                                                JSONObject adjustedKeys = EnrichmentUtils.adjustKeys(new JSONObject(), ret, cacheKey.getField(), prefix);                        adjustedKeys.put("adapter." + adapter.getClass().getSimpleName().toLowerCase() + ".end.ts", "" + System.currentTimeMillis());                        return adjustedKeys;                    } catch (Throwable e) {                        JSONObject errorMessage = new JSONObject();                        errorMessage.putAll(m);                        errorMessage.put(Constants.SENSOR_TYPE, sensorType);                        errors.add(new AbstractMap.SimpleEntry<>(errorMessage, new IllegalStateException(strategy + " error with " + task.getKey() + " failed: " + e.getMessage(), e)));                        return new JSONObject();                    }                };                                taskList.add(CompletableFuture.supplyAsync(supplier, ConcurrencyContext.getExecutor()));            }        }    }    if (taskList.isEmpty()) {        message.put(getClass().getSimpleName().toLowerCase() + ".enrich.end.ts", "" + System.currentTimeMillis());        return new EnrichmentResult(message, errors);    }    EnrichmentResult ret = new EnrichmentResult(all(taskList, message, (left, right) -> join(left, right)).get(), errors);    ret.getResult().put(getClass().getSimpleName().toLowerCase() + ".enrich.end.ts", "" + System.currentTimeMillis());    if (perfLog != null) {        String key = message.get(Constants.GUID) + "";        perfLog.log("enrich", "key={}, elapsed time to enrich", key);        perfLog.log("execute", "key={}, elapsed time to run execute", key);    }    return ret;}
0
private static JSONObject join(JSONObject left, JSONObject right)
{    JSONObject message = new JSONObject();    message.putAll(left);    message.putAll(right);    List<Object> emptyKeys = new ArrayList<>();    for (Object key : message.keySet()) {        Object value = message.get(key);        if (value == null || value.toString().length() == 0) {            emptyKeys.add(key);        }    }    for (Object o : emptyKeys) {        message.remove(o);    }    return message;}
0
public static CompletableFuture<JSONObject> all(List<CompletableFuture<JSONObject>> futures, JSONObject identity, BinaryOperator<JSONObject> reduceOp)
{    CompletableFuture[] cfs = futures.toArray(new CompletableFuture[futures.size()]);    CompletableFuture<Void> future = CompletableFuture.allOf(cfs);    return future.thenApply(aVoid -> futures.stream().map(CompletableFuture::join).reduce(identity, reduceOp));}
0
public Map<String, List<JSONObject>> splitMessage(JSONObject message, EnrichmentStrategy enrichmentStrategy, SensorEnrichmentConfig config)
{    Map<String, List<JSONObject>> streamMessageMap = new HashMap<>();    Map<String, Object> enrichmentFieldMap = enrichmentStrategy.getUnderlyingConfig(config).getFieldMap();    Map<String, ConfigHandler> fieldToHandler = enrichmentStrategy.getUnderlyingConfig(config).getEnrichmentConfigs();    Set<String> enrichmentTypes = new HashSet<>(enrichmentFieldMap.keySet());        enrichmentTypes.addAll(fieldToHandler.keySet());        for (String enrichmentType : enrichmentTypes) {        Object fields = enrichmentFieldMap.get(enrichmentType);        ConfigHandler retriever = fieldToHandler.get(enrichmentType);                List<JSONObject> enrichmentObject = retriever.getType().splitByFields(message, fields, field -> enrichmentStrategy.fieldToEnrichmentKey(enrichmentType, field), retriever);        streamMessageMap.put(enrichmentType, enrichmentObject);    }    return streamMessageMap;}
0
public ExecutorService create(int numThreads)
{    return creator.apply(numThreads);}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (!initialized) {        return null;    }    if (args.size() > 2) {        throw new IllegalArgumentException("ASN_GET received more arguments than expected: " + args.size());    }    if (args.size() == 1 && args.get(0) instanceof String) {                String ip = (String) args.get(0);        if (ip == null || ip.trim().isEmpty()) {                        return null;        }        Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get(ip);        return result.orElse(Collections.EMPTY_MAP);    } else if (args.size() == 2 && args.get(1) instanceof List) {                String ip = (String) args.get(0);        @SuppressWarnings("unchecked")        List<String> fields = (List) args.get(1);        Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get(ip);                if (fields.size() == 1 && result.isPresent()) {            if (!result.get().containsKey(fields.get(0))) {                return null;            }            return result.get().get(fields.get(0));        } else if (result.isPresent()) {                        Map<String, Object> filteredInfo = new HashMap<>();            for (String field : fields) {                Map<String, Object> asnInfo = result.get();                filteredInfo.put(field, asnInfo.get(field));            }            return filteredInfo;        }    }    return null;}
1
public void initialize(Context context)
{        Map<String, Object> config = getConfig(context);    String hdfsDir = (String) config.get(GeoLiteAsnDatabase.ASN_HDFS_FILE);    GeoLiteAsnDatabase.INSTANCE.update(hdfsDir);    initialized = true;}
1
private static Map<String, Object> getConfig(Context context)
{    return (Map<String, Object>) context.getCapability(Context.Capabilities.GLOBAL_CONFIG, false).orElse(new HashMap<>());}
0
public boolean isInitialized()
{    return initialized;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() != 2) {        throw new IllegalArgumentException("All parameters are mandatory, submit 'hdfs path', 'indicator'");    }    if (!isInitialized()) {        return null;    }    String path = (String) args.get(0);    String indicator = (String) args.get(1);    if (path == null || indicator == null) {        return null;    }    Object value;    try {        Map cachedMap = (Map) objectCache.get(path);                value = cachedMap.get(indicator);    } catch (ClassCastException e) {        throw new ClassCastException(String.format("The object stored in HDFS at '%s' must be serialized in JSON format.", path));    }    return value;}
1
public void initialize(Context context)
{    Map<String, Object> config = (Map<String, Object>) context.getCapability(Context.Capabilities.GLOBAL_CONFIG, false).orElse(new HashMap<>());    Map<String, Object> enrichmentGetConfig = (Map<String, Object>) config.getOrDefault(ENRICHMENT_OBJECT_GET_SETTINGS, new HashMap<>());    ObjectCacheConfig objectCacheConfig = new ObjectCacheConfig(enrichmentGetConfig);    objectCache = new ObjectCache();    objectCache.initialize(objectCacheConfig);}
0
public boolean isInitialized()
{    return objectCache != null && objectCache.isInitialized();}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (!initialized) {        return null;    }    if (args.size() > 2) {        throw new IllegalArgumentException("GEO_GET received more arguments than expected: " + args.size());    }    if (args.size() == 1 && args.get(0) instanceof String) {                String ip = (String) args.get(0);        if (ip == null || ip.trim().isEmpty()) {            return null;        }        Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(ip);        return result.orElse(Collections.emptyMap());    } else if (args.size() == 2 && args.get(1) instanceof List) {                String ip = (String) args.get(0);        @SuppressWarnings("unchecked")        List<String> fields = (List) args.get(1);        Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(ip);                if (fields.size() == 1 && result.isPresent()) {            return result.get().get(fields.get(0));        } else if (result.isPresent()) {                        Map<String, String> filteredInfo = new HashMap<>();            for (String field : fields) {                Map<String, String> geoInfo = result.get();                filteredInfo.put(field, geoInfo.get(field));            }            return filteredInfo;        }    }    return null;}
0
public void initialize(Context context)
{        Map<String, Object> config = getConfig(context);    String hdfsDir = (String) config.get(GeoLiteCityDatabase.GEO_HDFS_FILE);    GeoLiteCityDatabase.INSTANCE.update(hdfsDir);    initialized = true;}
1
private static Map<String, Object> getConfig(Context context)
{    return (Map<String, Object>) context.getCapability(Context.Capabilities.GLOBAL_CONFIG, false).orElse(new HashMap<>());}
0
public boolean isInitialized()
{    return initialized;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < 1) {        return null;    }    String hash = (String) args.get(0);    if (hash == null) {        return null;    }    Optional<WGS84Point> point = GeoHashUtil.INSTANCE.toPoint(hash);    if (point.isPresent()) {        Map<String, Object> ret = new HashMap<>();        ret.put(GeoLiteCityDatabase.GeoProps.LONGITUDE.getSimpleName(), point.get().getLongitude());        ret.put(GeoLiteCityDatabase.GeoProps.LATITUDE.getSimpleName(), point.get().getLatitude());        return ret;    }    return null;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < 2) {        return null;    }    Object latObj = args.get(0);    Object longObj = args.get(1);    if (latObj == null || longObj == null) {        return null;    }    Double latitude = ConversionUtils.convert(latObj, Double.class);    Double longitude = ConversionUtils.convert(longObj, Double.class);    int charPrecision = 12;    if (args.size() > 2) {        charPrecision = ConversionUtils.convert(args.get(2), Integer.class);    }    Optional<String> ret = GeoHashUtil.INSTANCE.computeHash(latitude, longitude, charPrecision);    return ret.orElse(null);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < 1) {        return null;    }    Map<String, String> map = (Map<String, String>) args.get(0);    if (map == null) {        return null;    }    int charPrecision = 12;    if (args.size() > 1) {        charPrecision = ConversionUtils.convert(args.get(1), Integer.class);    }    Optional<String> ret = GeoHashUtil.INSTANCE.computeHash(map, charPrecision);    return ret.orElse(null);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < 2) {        return null;    }    String hash1 = (String) args.get(0);    if (hash1 == null) {        return null;    }    Optional<WGS84Point> pt1 = GeoHashUtil.INSTANCE.toPoint(hash1);    String hash2 = (String) args.get(1);    if (hash2 == null) {        return null;    }    Optional<WGS84Point> pt2 = GeoHashUtil.INSTANCE.toPoint(hash2);    DistanceStrategy strat = DistanceStrategies.HAVERSINE;    if (args.size() > 2) {        strat = DistanceStrategies.valueOf((String) args.get(2));    }    if (pt1.isPresent() && pt2.isPresent()) {        return GeoHashUtil.INSTANCE.distance(pt1.get(), pt2.get(), strat);    }    return Double.NaN;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < 1) {        return null;    }    Iterable<String> hashes = (Iterable<String>) args.get(0);    if (hashes == null) {        return null;    }    DistanceStrategy strat = DistanceStrategies.HAVERSINE;    if (args.size() > 1) {        strat = DistanceStrategies.valueOf((String) args.get(1));    }    return GeoHashUtil.INSTANCE.maxDistanceHashes(hashes, strat);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < 1) {        return null;    }    Object o1 = args.get(0);    if (o1 == null) {        return null;    }    WGS84Point centroid = null;    if (o1 instanceof Map) {        centroid = GeoHashUtil.INSTANCE.centroidOfWeightedPoints((Map<String, Number>) o1);    } else if (o1 instanceof Iterable) {        centroid = GeoHashUtil.INSTANCE.centroidOfHashes((Iterable<String>) o1);    }    if (centroid == null) {        return null;    }    Integer precision = 12;    if (args.size() > 1) {        precision = (Integer) args.get(1);    }    return GeoHashUtil.INSTANCE.computeHash(centroid, precision).orElse(null);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (!isInitialized()) {        return null;    }    if (args.size() < 1) {        return null;    }    Object o = args.get(0);    if (o == null) {        return null;    }    if (o instanceof String) {        return objectCache.get((String) o);    } else {        throw new IllegalStateException("Unable to retrieve " + o + " as it is not a path");    }}
0
public void initialize(Context context)
{    Map<String, Object> config = getConfig(context);    objectCache = new ObjectCache();    objectCache.initialize(new ObjectCacheConfig(config));}
0
public boolean isInitialized()
{    return objectCache != null && objectCache.isInitialized();}
0
protected Map<String, Object> getConfig(Context context)
{    return (Map<String, Object>) context.getCapability(Context.Capabilities.GLOBAL_CONFIG, false).orElse(new HashMap<>());}
0
public String toString()
{    return "Table{" + "name='" + name + '\'' + ", columnFamily='" + columnFamily + '\'' + '}';}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    WrapperTable table = (WrapperTable) o;    if (name != null ? !name.equals(table.name) : table.name != null)        return false;    return columnFamily != null ? columnFamily.equals(table.columnFamily) : table.columnFamily == null;}
0
public int hashCode()
{    int result = name != null ? name.hashCode() : 0;    result = 31 * result + (columnFamily != null ? columnFamily.hashCode() : 0);    return result;}
0
private static Map<String, Object> getConfig(Context context)
{    return (Map<String, Object>) context.getCapability(Context.Capabilities.GLOBAL_CONFIG).orElse(new HashMap<>());}
0
private static synchronized void initializeTracker(Map<String, Object> config, TableProvider provider) throws IOException
{    if (tracker == null) {        String accessTrackerType = (String) config.getOrDefault(ACCESS_TRACKER_TYPE_CONF, AccessTrackers.NOOP.toString());        AccessTrackers trackers = AccessTrackers.valueOf(accessTrackerType);        tracker = trackers.create(config, provider);    }}
0
private static TableProvider createProvider(String tableProviderClass)
{    try {        Class<? extends TableProvider> providerClazz = (Class<? extends TableProvider>) Class.forName(tableProviderClass);        return providerClazz.getConstructor().newInstance();    } catch (Exception e) {        return new HTableProvider();    }}
0
private static synchronized void initializeProvider(Map<String, Object> config)
{    if (provider != null) {        return;    } else {        String tableProviderClass = (String) config.getOrDefault(TABLE_PROVIDER_TYPE_CONF, HTableProvider.class.getName());        provider = createProvider(tableProviderClass);    }}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (!initialized) {        return false;    }    if (args.size() != 4) {        throw new IllegalStateException("All parameters are mandatory, submit 'enrichment type', 'indicator', 'nosql_table' and 'column_family'");    }    int i = 0;    String enrichmentType = (String) args.get(i++);    String indicator = (String) args.get(i++);    String table = (String) args.get(i++);    String cf = (String) args.get(i++);    if (enrichmentType == null || indicator == null) {        return false;    }    final WrapperTable key = new WrapperTable(table, cf);    EnrichmentLookup lookup = null;    try {        lookup = enrichmentCollateralCache.get(key, () -> {            Table hTable = provider.getTable(HBaseConfiguration.create(), key.name);            return new EnrichmentLookup(hTable, key.columnFamily, tracker);        });    } catch (ExecutionException e) {                return false;    }    EnrichmentLookup.HBaseContext hbaseContext = new EnrichmentLookup.HBaseContext(lookup.getTable(), cf);    try {        return lookup.exists(new EnrichmentKey(enrichmentType, indicator), hbaseContext, true);    } catch (IOException e) {                return false;    }}
1
public void initialize(Context context)
{    try {        Map<String, Object> config = getConfig(context);        initializeProvider(config);        initializeTracker(config, provider);    } catch (IOException e) {            } finally {        initialized = true;    }}
1
public boolean isInitialized()
{    return initialized;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (!initialized) {        return false;    }    if (args.size() != 4) {        throw new IllegalStateException("All parameters are mandatory, submit 'enrichment type', 'indicator', 'nosql_table' and 'column_family'");    }    int i = 0;    String enrichmentType = (String) args.get(i++);    String indicator = (String) args.get(i++);    String table = (String) args.get(i++);    String cf = (String) args.get(i++);    if (enrichmentType == null || indicator == null) {        return new HashMap<String, Object>();    }    final WrapperTable key = new WrapperTable(table, cf);    EnrichmentLookup lookup = null;    try {        lookup = enrichmentCollateralCache.get(key, () -> {            Table hTable = provider.getTable(HBaseConfiguration.create(), key.name);            return new EnrichmentLookup(hTable, key.columnFamily, tracker);        });    } catch (ExecutionException e) {                return new HashMap<String, Object>();    }    EnrichmentLookup.HBaseContext hbaseContext = new EnrichmentLookup.HBaseContext(lookup.getTable(), cf);    try {        LookupKV<EnrichmentKey, EnrichmentValue> kv = lookup.get(new EnrichmentKey(enrichmentType, indicator), hbaseContext, true);        if (kv != null && kv.getValue() != null && kv.getValue().getMetadata() != null) {            return kv.getValue().getMetadata();        }        return new HashMap<String, Object>();    } catch (IOException e) {                return new HashMap<String, Object>();    }}
1
public void initialize(Context context)
{    try {        Map<String, Object> config = getConfig(context);        initializeProvider(config);        initializeTracker(config, provider);    } catch (IOException e) {            } finally {        initialized = true;    }}
1
public boolean isInitialized()
{    return initialized;}
0
public static String getEnrichmentKey(String enrichmentName, String field)
{    return Joiner.on(".").join(new String[] { KEY_PREFIX, enrichmentName, field });}
0
public KeyWithContext<EnrichmentKey, EnrichmentLookup.HBaseContext> apply(@Nullable String enrichmentType)
{    EnrichmentKey key = new EnrichmentKey(enrichmentType, indicator);    EnrichmentLookup.HBaseContext context = new EnrichmentLookup.HBaseContext(table, getColumnFamily(enrichmentType, config));    return new KeyWithContext<>(key, context);}
0
protected Map<Object, Map<String, String>> initialValue()
{    return new HashMap<>();}
0
public static String getColumnFamily(String enrichmentType, EnrichmentConfig config)
{    Object o = config.getConfig().get(TYPE_TO_COLUMN_FAMILY_CONF);    if (o == null) {        return null;    } else {        Map<String, String> cfMap = typeToCFs.get().get(o);        if (cfMap == null) {            cfMap = new HashMap<>();            if (o instanceof Map) {                Map map = (Map) o;                for (Object key : map.keySet()) {                    cfMap.put(key.toString(), map.get(key).toString());                }            }            typeToCFs.get().put(o, cfMap);        }        return cfMap.get(enrichmentType);    }}
0
public static String toTopLevelField(String field)
{    if (field == null) {        return null;    }    return Iterables.getLast(Splitter.on('.').split(field));}
0
public static TableProvider getTableProvider(String connectorImpl, TableProvider defaultImpl)
{    if (connectorImpl == null || connectorImpl.length() == 0 || connectorImpl.charAt(0) == '$') {        return defaultImpl;    } else {        try {            Class<? extends TableProvider> clazz = (Class<? extends TableProvider>) Class.forName(connectorImpl);            return clazz.getConstructor().newInstance();        } catch (InstantiationException e) {            throw new IllegalStateException("Unable to instantiate connector.", e);        } catch (IllegalAccessException e) {            throw new IllegalStateException("Unable to instantiate connector: illegal access", e);        } catch (InvocationTargetException e) {            throw new IllegalStateException("Unable to instantiate connector", e);        } catch (NoSuchMethodException e) {            throw new IllegalStateException("Unable to instantiate connector: no such method", e);        } catch (ClassNotFoundException e) {            throw new IllegalStateException("Unable to instantiate connector: class not found", e);        }    }}
0
public static JSONObject adjustKeys(JSONObject enrichedMessage, JSONObject enrichedField, String field, String prefix)
{    if (!enrichedField.isEmpty()) {        for (Object enrichedKey : enrichedField.keySet()) {            if (!StringUtils.isEmpty(prefix)) {                enrichedMessage.put(field + "." + enrichedKey, enrichedField.get(enrichedKey));            } else {                enrichedMessage.put(enrichedKey, enrichedField.get(enrichedKey));            }        }    }    return enrichedMessage;}
0
public static String getThreatIntelKey(String threatIntelName, String field)
{    return Joiner.on(".").join(new String[] { KEY_PREFIX, threatIntelName, field });}
0
public static JSONObject triage(JSONObject ret, SensorEnrichmentConfig config, FunctionResolver functionResolver, Context stellarContext)
{    LOG.trace("Received joined messages: {}", ret);    boolean isAlert = ret.containsKey("is_alert");    if (!isAlert) {        for (Object key : ret.keySet()) {            if (key.toString().startsWith("threatintels") && !key.toString().endsWith(".ts")) {                isAlert = true;                break;            }        }    } else {        Object isAlertObj = ret.get("is_alert");        isAlert = ConversionUtils.convert(isAlertObj, Boolean.class);        if (!isAlert) {            ret.remove("is_alert");        }    }    if (isAlert) {        ret.put("is_alert", "true");        String sourceType = MessageUtils.getSensorType(ret);        ThreatTriageConfig triageConfig = null;        if (config != null) {            triageConfig = config.getThreatIntel().getTriageConfig();            if (LOG.isDebugEnabled()) {                            }        } else {                    }        if (triageConfig != null) {            if (LOG.isDebugEnabled()) {                            }            if (LOG.isDebugEnabled() && (triageConfig.getRiskLevelRules() == null || triageConfig.getRiskLevelRules().isEmpty())) {                            }                        ThreatTriageProcessor threatTriageProcessor = new ThreatTriageProcessor(config, functionResolver, stellarContext);            ThreatScore score = threatTriageProcessor.apply(ret);            if (LOG.isDebugEnabled()) {                String rules = Joiner.on('\n').join(triageConfig.getRiskLevelRules());                            }                        if (score.getRuleScores().size() > 0) {                appendThreatScore(score, ret);            }        } else {                    }    }    return ret;}
1
private static void appendThreatScore(ThreatScore threatScore, JSONObject message)
{        message.put(THREAT_TRIAGE_SCORE_KEY, threatScore.getScore());        Joiner joiner = Joiner.on(".");    int i = 0;    for (RuleScore score : threatScore.getRuleScores()) {        message.put(joiner.join(THREAT_TRIAGE_RULES_KEY, i, THREAT_TRIAGE_RULE_NAME), score.getRule().getName());        message.put(joiner.join(THREAT_TRIAGE_RULES_KEY, i, THREAT_TRIAGE_RULE_COMMENT), score.getRule().getComment());        message.put(joiner.join(THREAT_TRIAGE_RULES_KEY, i, THREAT_TRIAGE_RULE_SCORE), score.getRule().getScoreExpression());        message.put(joiner.join(THREAT_TRIAGE_RULES_KEY, i++, THREAT_TRIAGE_RULE_REASON), score.getReason());    }}
0
public ThreatScore apply(@Nullable Map message)
{    ThreatScore threatScore = new ThreatScore();    StellarPredicateProcessor predicateProcessor = new StellarPredicateProcessor();    StellarProcessor processor = new StellarProcessor();    VariableResolver variableResolver = new MapVariableResolver(message, sensorConfig.getConfiguration(), threatIntelConfig.getConfig());        for (RiskLevelRule rule : threatTriageConfig.getRiskLevelRules()) {        if (predicateProcessor.parse(rule.getRule(), variableResolver, functionResolver, context)) {                        String reason = execute(rule.getReason(), processor, variableResolver, String.class);            Double score = execute(rule.getScoreExpression(), processor, variableResolver, Double.class);            threatScore.addRuleScore(new RuleScore(rule, reason, score));        }    }        List<Number> ruleScores = new ArrayList<>();    for (RuleScore ruleScore : threatScore.getRuleScores()) {        ruleScores.add(ruleScore.getScore());    }    Aggregators aggregators = threatTriageConfig.getAggregator();    Double aggregateScore = aggregators.aggregate(ruleScores, threatTriageConfig.getAggregationConfig());    threatScore.setScore(aggregateScore);    return threatScore;}
0
private T execute(String expression, StellarProcessor processor, VariableResolver resolver, Class<T> clazz)
{    Object result = processor.parse(expression, resolver, functionResolver, context);    return ConversionUtils.convert(result, clazz);}
0
public List<RiskLevelRule> getRiskLevelRules()
{    return threatTriageConfig.getRiskLevelRules();}
0
public SensorEnrichmentConfig getSensorConfig()
{    return sensorConfig;}
0
public String toString()
{    return String.format("ThreatTriage{%d rule(s)}", threatTriageConfig.getRiskLevelRules().size());}
0
public void parseJSON() throws ParseException
{    JSONParser jsonParser = new JSONParser();    expectedMessage = (JSONObject) jsonParser.parse(expectedMessageString);}
0
public void testEnrich() throws Exception
{    HostFromJSONListAdapter hja = new HostFromJSONListAdapter(expectedKnownHostsString);    JSONObject actualMessage = hja.enrich(new CacheKey("dummy", ip, null));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(expectedMessage, actualMessage);    actualMessage = hja.enrich(new CacheKey("dummy", ip1, null));    JSONObject emptyJson = new JSONObject();    Assert.assertEquals(emptyJson, actualMessage);}
0
public void testEnrichNonString() throws Exception
{    HostFromJSONListAdapter hja = new HostFromJSONListAdapter(expectedKnownHostsString);    JSONObject actualMessage = hja.enrich(new CacheKey("dummy", ip, null));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(expectedMessage, actualMessage);    actualMessage = hja.enrich(new CacheKey("dummy", 10L, null));    JSONObject emptyJson = new JSONObject();    Assert.assertEquals(emptyJson, actualMessage);}
0
public void testInitializeAdapter() throws Exception
{    HostFromJSONListAdapter hja = new HostFromJSONListAdapter(expectedKnownHostsString);    Assert.assertTrue(hja.initializeAdapter(null));}
0
public void parseJSON() throws ParseException
{    JSONParser jsonParser = new JSONParser();    expectedMessage = (JSONObject) jsonParser.parse(expectedMessageString);}
0
public void testEnrich() throws Exception
{    Map<String, JSONObject> mapKnownHosts = new HashMap<>();    JSONArray jsonArray = (JSONArray) JSONValue.parse(expectedKnownHostsString);    Iterator jsonArrayIterator = jsonArray.iterator();    while (jsonArrayIterator.hasNext()) {        JSONObject jsonObject = (JSONObject) jsonArrayIterator.next();        String host = (String) jsonObject.remove("ip");        mapKnownHosts.put(host, jsonObject);    }    HostFromPropertiesFileAdapter hfa = new HostFromPropertiesFileAdapter(mapKnownHosts);    JSONObject actualMessage = hfa.enrich(new CacheKey("dummy", ip, null));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(expectedMessage, actualMessage);    actualMessage = hfa.enrich(new CacheKey("dummy", ip1, null));    JSONObject emptyJson = new JSONObject();    Assert.assertEquals(emptyJson, actualMessage);}
0
public void testInitializeAdapter() throws Exception
{    Map<String, JSONObject> mapKnownHosts = new HashMap<>();    HostFromPropertiesFileAdapter hfa = new HostFromPropertiesFileAdapter(mapKnownHosts);    Assert.assertFalse(hfa.initializeAdapter(null));    JSONArray jsonArray = (JSONArray) JSONValue.parse(expectedKnownHostsString);    Iterator jsonArrayIterator = jsonArray.iterator();    while (jsonArrayIterator.hasNext()) {        JSONObject jsonObject = (JSONObject) jsonArrayIterator.next();        String host = (String) jsonObject.remove("ip");        mapKnownHosts.put(host, jsonObject);    }    hfa = new HostFromPropertiesFileAdapter(mapKnownHosts);    Assert.assertTrue(hfa.initializeAdapter(null));}
0
public void setupJdbc()
{    conn = new MySqlConfig();    conn.setHost("10.22.0.214");    conn.setPort(3306);    conn.setTable("GEO");    conn.setUsername("root");    conn.setPassword("hadoop123");}
0
public void testGetJdbcUrl() throws Exception
{    Assert.assertEquals(sampleURL, conn.getJdbcUrl());}
0
public static void setupOnce() throws IOException
{        expectedAsnMessage.put("autonomous_system_organization", "Google LLC");    expectedAsnMessage.put("autonomous_system_number", 15169);    expectedAsnMessage.put("network", "8.8.4.0");    String baseDir = UnitTestHelper.findDir("GeoLite");    asnHdfsFile = new File(new File(baseDir), GEO_ASN_FILE_NAME);    asnHdfsFile_update = new File(new File(baseDir), GEO_ASN_COPY_FILE_NAME);    FileUtils.copyFile(asnHdfsFile, asnHdfsFile_update);}
0
public static void tearDown()
{    FileUtils.deleteQuietly(asnHdfsFile_update);}
0
public void setup() throws Exception
{    testFolder.create();    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> ImmutableMap.of(GeoLiteAsnDatabase.ASN_HDFS_FILE, asnHdfsFile.getAbsolutePath())).build();}
0
public void testGetLocal()
{    GeoLiteAsnDatabase.INSTANCE.update(asnHdfsFile.getAbsolutePath());    Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get("192.168.0.1");    Assert.assertFalse("Local address result should be empty", result.isPresent());}
0
public void testExternalAddressNotFound()
{    GeoLiteAsnDatabase.INSTANCE.update(asnHdfsFile.getAbsolutePath());        Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get("203.0.113.1");    Assert.assertFalse("External address not found", result.isPresent());}
0
public void testGetRemote()
{    GeoLiteAsnDatabase.INSTANCE.update(asnHdfsFile.getAbsolutePath());    Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get(IP_ADDR);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedAsnMessage, result.get());}
0
public void testMultipleUpdates()
{    GeoLiteAsnDatabase.INSTANCE.update(asnHdfsFile.getAbsolutePath());    GeoLiteAsnDatabase.INSTANCE.update(asnHdfsFile.getAbsolutePath());    Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get(IP_ADDR);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedAsnMessage, result.get());}
0
public void testUpdateIfNecessary()
{    HashMap<String, Object> globalConfig = new HashMap<>();    globalConfig.put(GeoLiteAsnDatabase.ASN_HDFS_FILE, asnHdfsFile.getAbsolutePath());    GeoLiteAsnDatabase.INSTANCE.updateIfNecessary(globalConfig);    Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get(IP_ADDR);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedAsnMessage, result.get());}
0
public void testMultipleUpdateIfNecessary()
{    HashMap<String, Object> globalConfig = new HashMap<>();    globalConfig.put(GeoLiteAsnDatabase.ASN_HDFS_FILE, asnHdfsFile.getAbsolutePath());    GeoLiteAsnDatabase.INSTANCE.updateIfNecessary(globalConfig);    GeoLiteAsnDatabase.INSTANCE.updateIfNecessary(globalConfig);    Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get(IP_ADDR);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedAsnMessage, result.get());}
0
public void testDifferingUpdateIfNecessary()
{    HashMap<String, Object> globalConfig = new HashMap<>();    globalConfig.put(GeoLiteAsnDatabase.ASN_HDFS_FILE, asnHdfsFile.getAbsolutePath());    GeoLiteAsnDatabase.INSTANCE.updateIfNecessary(globalConfig);    Optional<Map<String, Object>> result = GeoLiteAsnDatabase.INSTANCE.get(IP_ADDR);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedAsnMessage, result.get());    globalConfig.put(GeoLiteAsnDatabase.ASN_HDFS_FILE, asnHdfsFile_update.getAbsolutePath());    GeoLiteAsnDatabase.INSTANCE.updateIfNecessary(globalConfig);    result = GeoLiteAsnDatabase.INSTANCE.get(IP_ADDR);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedAsnMessage, result.get());}
0
public static void setupOnce() throws ParseException
{    JSONParser jsonParser = new JSONParser();    expectedMessage = (JSONObject) jsonParser.parse(expectedMessageString);    String baseDir = UnitTestHelper.findDir("GeoLite");    geoHdfsFile = new File(new File(baseDir), "GeoLite2-City.mmdb.gz");    geo = new GeoAdapter();    geo.initializeAdapter(ImmutableMap.of(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath()));}
0
public void testEnrich() throws Exception
{    JSONObject actualMessage = geo.enrich(new CacheKey("dummy", IP, null));    Assert.assertNotNull(actualMessage.get("locID"));    Assert.assertEquals(expectedMessage, actualMessage);}
0
public void testEnrichNonString() throws Exception
{    JSONObject actualMessage = geo.enrich(new CacheKey("dummy", 10L, null));    Assert.assertEquals(new JSONObject(), actualMessage);}
0
public static void setupOnce() throws ParseException, IOException
{    JSONParser jsonParser = new JSONParser();    expectedNoDmaMessage = (JSONObject) jsonParser.parse(expectedNoDmaMessageString);    expectedDmaMessage = (JSONObject) jsonParser.parse(expectedDmaMessageString);    expectedMessageTarGz = (JSONObject) jsonParser.parse(expectedMessageStringTarGz);    String baseDir = UnitTestHelper.findDir("GeoLite");    geoHdfsFile = new File(new File(baseDir), GEO_CITY_FILE_NAME);    geoHdfsFile_update = new File(new File(baseDir), GEO_CITY_COPY_FILE_NAME);    FileUtils.copyFile(geoHdfsFile, geoHdfsFile_update);    geoHdfsFileTarGz = new File(new File(baseDir), GEO_CITY + EXTENSION_TAR_GZ);    Configuration config = new Configuration();    fs = FileSystem.get(config);}
0
public static void tearDown()
{    FileUtils.deleteQuietly(geoHdfsFile_update);}
0
public void setup() throws Exception
{    testFolder.create();    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> ImmutableMap.of(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath())).build();}
0
public void testGetLocal()
{    GeoLiteCityDatabase.INSTANCE.update(geoHdfsFile.getAbsolutePath());    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get("192.168.0.1");    Assert.assertFalse("Local address result should be empty", result.isPresent());}
0
public void testExternalAddressNotFound()
{    GeoLiteCityDatabase.INSTANCE.update(geoHdfsFile.getAbsolutePath());        Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get("203.0.113.1");    Assert.assertFalse("External address not found", result.isPresent());}
0
public void testGetRemoteWithDma()
{    GeoLiteCityDatabase.INSTANCE.update(geoHdfsFile.getAbsolutePath());    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(IP_WITH_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedDmaMessage, result.get());}
0
public void testGetRemoteWithTarGzFile()
{    GeoLiteCityDatabase.INSTANCE.update(geoHdfsFileTarGz.getAbsolutePath());    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(IP_WITH_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedMessageTarGz, result.get());}
0
public void testGetRemoteNoDma()
{    GeoLiteCityDatabase.INSTANCE.update(geoHdfsFile.getAbsolutePath());    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(IP_NO_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedNoDmaMessage, result.get());}
0
public void testMultipleUpdates()
{    GeoLiteCityDatabase.INSTANCE.update(geoHdfsFile.getAbsolutePath());    GeoLiteCityDatabase.INSTANCE.update(geoHdfsFile.getAbsolutePath());    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(IP_NO_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedNoDmaMessage, result.get());}
0
public void testUpdateIfNecessary()
{    HashMap<String, Object> globalConfig = new HashMap<>();    globalConfig.put(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath());    GeoLiteCityDatabase.INSTANCE.updateIfNecessary(globalConfig);    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(IP_NO_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedNoDmaMessage, result.get());}
0
public void testMultipleUpdateIfNecessary()
{    HashMap<String, Object> globalConfig = new HashMap<>();    globalConfig.put(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath());    GeoLiteCityDatabase.INSTANCE.updateIfNecessary(globalConfig);    GeoLiteCityDatabase.INSTANCE.updateIfNecessary(globalConfig);    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(IP_NO_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedNoDmaMessage, result.get());}
0
public void testDifferingUpdateIfNecessary()
{    HashMap<String, Object> globalConfig = new HashMap<>();    globalConfig.put(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath());    GeoLiteCityDatabase.INSTANCE.updateIfNecessary(globalConfig);    Optional<Map<String, String>> result = GeoLiteCityDatabase.INSTANCE.get(IP_NO_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedNoDmaMessage, result.get());    globalConfig.put(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile_update.getAbsolutePath());    GeoLiteCityDatabase.INSTANCE.updateIfNecessary(globalConfig);    result = GeoLiteCityDatabase.INSTANCE.get(IP_NO_DMA);    Assert.assertEquals("Remote Local IP should return result based on DB", expectedNoDmaMessage, result.get());}
0
public void testFallbackUnnecessary()
{    String fakeFile = "fakefile.geolitecitydbtest";    Map<String, Object> globalConfig = Collections.singletonMap(GeoLiteCityDatabase.GEO_HDFS_FILE, fakeFile);    Assert.assertEquals(GeoLiteCityDatabase.INSTANCE.determineHdfsDirWithFallback(globalConfig, fakeFile, ""), fakeFile);}
0
public void testFallbackUnncessaryAlreadyDefault()
{    String defaultFile = GeoLiteCityDatabase.GEO_HDFS_FILE_DEFAULT;    Map<String, Object> globalConfig = Collections.singletonMap(GeoLiteCityDatabase.GEO_HDFS_FILE, defaultFile);    Assert.assertEquals(GeoLiteCityDatabase.INSTANCE.determineHdfsDirWithFallback(globalConfig, defaultFile, ""), defaultFile);}
0
public void testFallbackToDefault()
{    String defaultFile = GeoLiteCityDatabase.GEO_HDFS_FILE_DEFAULT;    Assert.assertEquals(GeoLiteCityDatabase.INSTANCE.determineHdfsDirWithFallback(Collections.emptyMap(), defaultFile, "fallback"), defaultFile);}
0
public void testFallbackToOldDefault() throws IOException
{    String fakeFile = "fakefile.geolitecitydbtest";    File file = File.createTempFile(this.getClass().getSimpleName(), "testfile");    file.deleteOnExit();    String fileName = file.getAbsolutePath();    Assert.assertEquals(GeoLiteCityDatabase.INSTANCE.determineHdfsDirWithFallback(Collections.emptyMap(), fakeFile, fileName), fileName);}
0
public void setup() throws Exception
{    final MockHTable trackerTable = (MockHTable) MockHBaseTableProvider.addToCache(atTableName, cf);    final MockHTable hbaseTable = (MockHTable) MockHBaseTableProvider.addToCache(hbaseTableName, cf);    EnrichmentHelper.INSTANCE.load(hbaseTable, cf, new ArrayList<LookupKV<EnrichmentKey, EnrichmentValue>>() {        {            add(new LookupKV<>(new EnrichmentKey(PLAYFUL_CLASSIFICATION_TYPE, "10.0.2.3"), new EnrichmentValue(PLAYFUL_ENRICHMENT)));        }    });    EnrichmentHelper.INSTANCE.load(hbaseTable, cf1, new ArrayList<LookupKV<EnrichmentKey, EnrichmentValue>>() {        {            add(new LookupKV<>(new EnrichmentKey(CF1_CLASSIFICATION_TYPE, "10.0.2.4"), new EnrichmentValue(CF1_ENRICHMENT)));        }    });    BloomAccessTracker bat = new BloomAccessTracker(hbaseTableName, 100, 0.03);    PersistentAccessTracker pat = new PersistentAccessTracker(hbaseTableName, "0", trackerTable, cf, bat, 0L);    lookup = new EnrichmentLookup(hbaseTable, cf, pat);    JSONParser jsonParser = new JSONParser();    expectedMessage = (JSONObject) jsonParser.parse(expectedMessageString);}
0
public void testEnrich() throws Exception
{    SimpleHBaseAdapter sha = new SimpleHBaseAdapter();    sha.lookup = lookup;    SensorEnrichmentConfig broSc = JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    JSONObject actualMessage = sha.enrich(new CacheKey("test", "test", broSc));    Assert.assertEquals(actualMessage, new JSONObject());    actualMessage = sha.enrich(new CacheKey("ip_dst_addr", "10.0.2.3", broSc));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(expectedMessage, actualMessage);}
0
public void testEnrichNonStringValue() throws Exception
{    SimpleHBaseAdapter sha = new SimpleHBaseAdapter();    sha.lookup = lookup;    SensorEnrichmentConfig broSc = JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    JSONObject actualMessage = sha.enrich(new CacheKey("test", "test", broSc));    Assert.assertEquals(actualMessage, new JSONObject());    actualMessage = sha.enrich(new CacheKey("ip_dst_addr", 10L, broSc));    Assert.assertEquals(actualMessage, new JSONObject());}
0
public void testMultiColumnFamilies() throws Exception
{    SimpleHBaseAdapter sha = new SimpleHBaseAdapter();    sha.lookup = lookup;    SensorEnrichmentConfig broSc = JSONUtils.INSTANCE.load(sourceConfigWithCFStr, SensorEnrichmentConfig.class);    JSONObject actualMessage = sha.enrich(new CacheKey("test", "test", broSc));    Assert.assertEquals(actualMessage, new JSONObject());    actualMessage = sha.enrich(new CacheKey("ip_dst_addr", "10.0.2.4", broSc));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(new JSONObject(ImmutableMap.of("cf1.key", "value")), actualMessage);}
0
public void testMultiColumnFamiliesWrongCF() throws Exception
{    SimpleHBaseAdapter sha = new SimpleHBaseAdapter();    sha.lookup = lookup;    SensorEnrichmentConfig broSc = JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    JSONObject actualMessage = sha.enrich(new CacheKey("test", "test", broSc));    Assert.assertEquals(actualMessage, new JSONObject());    actualMessage = sha.enrich(new CacheKey("ip_dst_addr", "10.0.2.4", broSc));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(new JSONObject(new HashMap<String, Object>()), actualMessage);}
0
public void testInitializeAdapter()
{    SimpleHBaseConfig config = new SimpleHBaseConfig();    SimpleHBaseAdapter sha = new SimpleHBaseAdapter(config);    sha.initializeAdapter(null);}
0
public void test()
{    SimpleHBaseConfig shc = new SimpleHBaseConfig();    shc.withHBaseCF(cf);    shc.withHBaseTable(table);    provider = new HTableProvider();    Assert.assertEquals(cf, shc.getHBaseCF());    Assert.assertEquals(table, shc.getHBaseTable());}
0
private JSONObject enrich(JSONObject message, String field, ConfigHandler handler)
{    VariableResolver resolver = new MapVariableResolver(message);    return StellarAdapter.process(message, handler, field, 1000L, processor, resolver, Context.EMPTY_CONTEXT());}
0
public void test_default() throws Exception
{    for (String c : DEFAULT_CONFIGS) {        JSONObject message = getMessage();        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        JSONObject enriched = enrich(message, "", handler);        Assert.assertEquals("STELLAR_TEST", enriched.get("stmt1"));        Assert.assertEquals("stellar_test", enriched.get("stmt2"));        Assert.assertEquals("foo", enriched.get("stmt3"));        Assert.assertEquals(3, enriched.size());    }}
0
public void test_grouped() throws Exception
{    for (String c : GROUPED_CONFIGS) {        JSONObject message = getMessage();        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        {            JSONObject enriched = enrich(message, "group1", handler);            Assert.assertEquals("STELLAR_TEST", enriched.get("stmt1"));            Assert.assertEquals("stellar_test", enriched.get("stmt2"));            Assert.assertEquals(2, enriched.size());        }        {            JSONObject enriched = enrich(message, "group2", handler);            Assert.assertEquals("foo", enriched.get("stmt3"));            Assert.assertEquals(1, enriched.size());        }    }}
0
public void test_mixed() throws Exception
{    for (String c : MIXED_CONFIGS) {        JSONObject message = getMessage();        EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(c, EnrichmentConfig.class);        Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));        ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");        {            JSONObject enriched = enrich(message, "group1", handler);            Assert.assertEquals("STELLAR_TEST", enriched.get("stmt1"));            Assert.assertEquals("stellar_test", enriched.get("stmt2"));            Assert.assertEquals(2, enriched.size());        }        {            JSONObject enriched = enrich(message, "group2", handler);            Assert.assertEquals("foo", enriched.get("stmt3"));            Assert.assertEquals(1, enriched.size());        }        {            JSONObject enriched = enrich(message, "", handler);            Assert.assertEquals(2, enriched.get("stmt4"));            Assert.assertEquals("stellar_test", enriched.get("stmt5"));            Assert.assertEquals(2, enriched.size());        }    }}
0
public void test_tempVariable() throws Exception
{    JSONObject message = getMessage();    EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(tempVarStellarConfig_list, EnrichmentConfig.class);    Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));    ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");    {        JSONObject enriched = enrich(message, "group1", handler);        Assert.assertEquals("stellar_test", enriched.get("stmt2"));        Assert.assertEquals(1, enriched.size());    }    {        JSONObject enriched = enrich(message, "group2", handler);        Assert.assertEquals("foo", enriched.get("stmt3"));        Assert.assertEquals(1, enriched.size());    }    {        JSONObject enriched = enrich(message, "", handler);        Assert.assertEquals(2, enriched.get("stmt4"));        Assert.assertEquals("stellar_test", enriched.get("stmt5"));        Assert.assertEquals(2, enriched.size());    }}
0
private void testMapEnrichment(String config, String field) throws Exception
{    JSONObject message = getMessage();    EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(config, EnrichmentConfig.class);    Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));    ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");    JSONObject enriched = enrich(message, field, handler);    Assert.assertEquals(2, enriched.size());    Assert.assertEquals("stellar_test", enriched.get("stmt2.foo"));    Assert.assertEquals("stellar_test".toUpperCase(), enriched.get("stmt1"));}
0
public void testMapEnrichment_subgroup() throws Exception
{    testMapEnrichment(mapConfig_subgroup, "group1");}
0
public void testMapEnrichment_default() throws Exception
{    testMapEnrichment(mapConfig_default, "");}
0
public void testAllVariableUsage() throws Exception
{    JSONObject message = getMessage();    EnrichmentConfig enrichmentConfig = JSONUtils.INSTANCE.load(allVariableConfig, EnrichmentConfig.class);    Assert.assertNotNull(enrichmentConfig.getEnrichmentConfigs().get("stellar"));    ConfigHandler handler = enrichmentConfig.getEnrichmentConfigs().get("stellar");    JSONObject enriched = enrich(message, "", handler);    Assert.assertEquals("stellar_test", enriched.get("stmt1"));}
0
public Table getTable(Configuration config, String tableName) throws IOException
{    throw new IOException();}
0
public void setup() throws Exception
{    final MockHTable trackerTable = (MockHTable) MockHBaseTableProvider.addToCache(atTableName, cf);    final MockHTable threatIntelTable = (MockHTable) MockHBaseTableProvider.addToCache(threatIntelTableName, cf);    EnrichmentHelper.INSTANCE.load(threatIntelTable, cf, new ArrayList<LookupKV<EnrichmentKey, EnrichmentValue>>() {        {            add(new LookupKV<>(new EnrichmentKey("10.0.2.3", "10.0.2.3"), new EnrichmentValue(new HashMap<>())));        }    });    BloomAccessTracker bat = new BloomAccessTracker(threatIntelTableName, 100, 0.03);    PersistentAccessTracker pat = new PersistentAccessTracker(threatIntelTableName, "0", trackerTable, cf, bat, 0L);    lookup = new EnrichmentLookup(threatIntelTable, cf, pat);    JSONParser jsonParser = new JSONParser();    expectedMessage = (JSONObject) jsonParser.parse(expectedMessageString);}
0
public void testEnrich() throws Exception
{    ThreatIntelAdapter tia = new ThreatIntelAdapter();    tia.lookup = lookup;    SensorEnrichmentConfig broSc = JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    JSONObject actualMessage = tia.enrich(new CacheKey("ip_dst_addr", "10.0.2.3", broSc));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(expectedMessage, actualMessage);}
0
public void testEnrichNonString() throws Exception
{    ThreatIntelAdapter tia = new ThreatIntelAdapter();    tia.lookup = lookup;    SensorEnrichmentConfig broSc = JSONUtils.INSTANCE.load(sourceConfigStr, SensorEnrichmentConfig.class);    JSONObject actualMessage = tia.enrich(new CacheKey("ip_dst_addr", "10.0.2.3", broSc));    Assert.assertNotNull(actualMessage);    Assert.assertEquals(expectedMessage, actualMessage);    actualMessage = tia.enrich(new CacheKey("ip_dst_addr", 10L, broSc));    Assert.assertEquals(actualMessage, new JSONObject());}
0
public void testInitializeAdapter()
{    String cf = "cf";    String table = "threatintel";    String trackCf = "cf";    String trackTable = "Track";    double falsePositive = 0.03;    int expectedInsertion = 1;    long millionseconds = (long) 0.1;    ThreatIntelConfig config = new ThreatIntelConfig();    config.withHBaseCF(cf);    config.withHBaseTable(table);    config.withExpectedInsertions(expectedInsertion);    config.withFalsePositiveRate(falsePositive);    config.withMillisecondsBetweenPersists(millionseconds);    config.withTrackerHBaseCF(trackCf);    config.withTrackerHBaseTable(trackTable);    config.withProviderImpl(ExceptionProvider.class.getName());    ThreatIntelAdapter tia = new ThreatIntelAdapter(config);    UnitTestHelper.setLog4jLevel(ThreatIntelAdapter.class, Level.FATAL);    tia.initializeAdapter(null);    UnitTestHelper.setLog4jLevel(ThreatIntelAdapter.class, Level.ERROR);    Assert.assertFalse(tia.isInitialized());}
0
public void test()
{    ThreatIntelConfig tic = new ThreatIntelConfig();    tic.withHBaseCF(cf);    tic.withHBaseTable(table);    tic.withExpectedInsertions(expectedInsertion);    tic.withFalsePositiveRate(falsePositive);    tic.withMillisecondsBetweenPersists(millionseconds);    tic.withTrackerHBaseCF(trackCf);    tic.withTrackerHBaseTable(trackTable);    Assert.assertEquals(cf, tic.getHBaseCF());    Assert.assertEquals(table, tic.getHBaseTable());    Assert.assertEquals(trackCf, tic.getTrackerHBaseCF());    Assert.assertEquals(trackTable, tic.getTrackerHBaseTable());    Assert.assertEquals(expectedInsertion, tic.getExpectedInsertions());    Assert.assertEquals(millionseconds, tic.getMillisecondsBetweenPersists());}
0
public void setup() throws IOException
{    fs = FileSystem.get(new Configuration());    data = new ArrayList<>();    {        data.add("apache");        data.add("metron");        data.add("is");        data.add("great");    }    cache = new ObjectCache();    tempDir = TestUtils.createTempDir(this.getClass().getName());}
0
public void test() throws Exception
{    String filename = "test.ser";    Assert.assertTrue(cache.isEmpty() || !cache.containsKey(filename));    assertDataIsReadCorrectly(filename);}
0
public void assertDataIsReadCorrectly(String filename) throws IOException
{    File file = new File(tempDir, filename);    try (BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(file))) {        IOUtils.write(SerDeUtils.toBytes(data), bos);    }    cache.initialize(new ObjectCacheConfig(new HashMap<>()));    List<String> readData = (List<String>) cache.get(file.getAbsolutePath());    Assert.assertEquals(readData, data);    Assert.assertTrue(cache.containsKey(file.getAbsolutePath()));}
0
public void testMultithreaded() throws Exception
{    String filename = "testmulti.ser";    Assert.assertTrue(cache.isEmpty() || !cache.containsKey(filename));    Thread[] ts = new Thread[10];    for (int i = 0; i < ts.length; ++i) {        ts[i] = new Thread(() -> {            try {                assertDataIsReadCorrectly(filename);            } catch (Exception e) {                throw new IllegalStateException(e.getMessage(), e);            }        });        ts[i].start();    }    for (Thread t : ts) {        t.join();    }}
0
public void shouldThrowExceptionOnMaxFileSize() throws Exception
{    String filename = "maxSizeException.ser";    File file = new File(tempDir, filename);    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage(String.format("File at path '%s' is larger than the configured max file size of 1", file.getAbsolutePath()));    try (BufferedOutputStream bos = new BufferedOutputStream(fs.create(new Path(file.getAbsolutePath()), true))) {        IOUtils.write(SerDeUtils.toBytes(data), bos);    }    ObjectCacheConfig objectCacheConfig = new ObjectCacheConfig(new HashMap<>());    objectCacheConfig.setMaxFileSize(1);    cache.initialize(objectCacheConfig);    cache.get(file.getAbsolutePath());}
0
public void testKeyConversion()
{    EnrichmentKey k1 = new EnrichmentKey("type", "indicator1");    byte[] serialized = k1.toBytes();    EnrichmentKey k2 = new EnrichmentKey();    k2.fromBytes(serialized);    Assert.assertEquals(k1, k2);}
0
public void testValueConversion() throws IOException
{    EnrichmentConverter converter = new EnrichmentConverter();    EnrichmentKey k1 = new EnrichmentKey("type", "indicator");    EnrichmentValue v1 = new EnrichmentValue(new HashMap<String, Object>() {        {            put("k1", "v1");            put("k2", "v2");        }    });    Put serialized = converter.toPut("cf", k1, v1);    LookupKV<EnrichmentKey, EnrichmentValue> kv = converter.fromPut(serialized, "cf");    Assert.assertEquals(k1, kv.getKey());    Assert.assertEquals(v1, kv.getValue());}
0
public void logAccess(CacheKey value)
{}
0
public JSONObject enrich(CacheKey value)
{    return null;}
0
public boolean initializeAdapter(Map<String, Object> config)
{    return false;}
0
public void updateAdapter(Map<String, Object> config)
{}
0
public void cleanup()
{}
0
public String getOutputPrefix(CacheKey value)
{    return null;}
0
public void logAccess(CacheKey value)
{    numAccesses.incrementAndGet();}
0
public static void setup()
{    ConcurrencyContext infrastructure = new ConcurrencyContext();    infrastructure.initialize(5, 100, 10, null, null, false);    stellarContext = new Context.Builder().build();    StellarFunctions.initialize(stellarContext);    StellarAdapter adapter = new AccessLoggingStellarAdapter().ofType("ENRICHMENT");    adapter.initializeAdapter(new HashMap<>());    EnrichmentAdapter<CacheKey> dummy = new DummyEnrichmentAdapter();    enrichmentsByType = ImmutableMap.of("stellar", adapter, "dummy", dummy);    enricher = new ParallelEnricher(enrichmentsByType, infrastructure, false);}
0
public void testCacheHit() throws Exception
{    numAccesses.set(0);    JSONObject message = new JSONObject() {        {            put(Constants.SENSOR_TYPE, "test");        }    };    for (int i = 0; i < 10; ++i) {        SensorEnrichmentConfig config = JSONUtils.INSTANCE.load(goodConfig, SensorEnrichmentConfig.class);        config.getConfiguration().putIfAbsent("stellarContext", stellarContext);        ParallelEnricher.EnrichmentResult result = enricher.apply(message, EnrichmentStrategies.ENRICHMENT, config, null);    }        Assert.assertTrue(2 >= numAccesses.get());}
0
public void testGoodConfig() throws Exception
{    SensorEnrichmentConfig config = JSONUtils.INSTANCE.load(goodConfig, SensorEnrichmentConfig.class);    config.getConfiguration().putIfAbsent("stellarContext", stellarContext);    JSONObject message = new JSONObject() {        {            put(Constants.SENSOR_TYPE, "test");        }    };    ParallelEnricher.EnrichmentResult result = enricher.apply(message, EnrichmentStrategies.ENRICHMENT, config, null);    JSONObject ret = result.getResult();    Assert.assertEquals("Got the wrong result count: " + ret, 11, ret.size());    Assert.assertEquals(1, ret.get("map.blah"));    Assert.assertEquals("test", ret.get("source.type"));    Assert.assertEquals(1, ret.get("one"));    Assert.assertEquals(2, ret.get("foo"));    Assert.assertEquals("TEST", ret.get("ALL_CAPS"));    Assert.assertEquals(0, result.getEnrichmentErrors().size());    Assert.assertTrue(result.getResult().containsKey("adapter.accessloggingstellaradapter.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("adapter.accessloggingstellaradapter.end.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.splitter.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.splitter.end.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.enrich.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.enrich.end.ts"));}
0
public void testNullEnrichment() throws Exception
{    SensorEnrichmentConfig config = JSONUtils.INSTANCE.load(nullConfig, SensorEnrichmentConfig.class);    config.getConfiguration().putIfAbsent("stellarContext", stellarContext);    JSONObject message = new JSONObject() {        {            put(Constants.SENSOR_TYPE, "test");        }    };    ParallelEnricher.EnrichmentResult result = enricher.apply(message, EnrichmentStrategies.ENRICHMENT, config, null);    JSONObject ret = result.getResult();    Assert.assertEquals("Got the wrong result count: " + ret, 7, ret.size());    Assert.assertTrue(result.getResult().containsKey("adapter.dummyenrichmentadapter.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("adapter.dummyenrichmentadapter.end.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.splitter.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.splitter.end.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.enrich.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.enrich.end.ts"));}
0
public void testBadConfig() throws Exception
{    SensorEnrichmentConfig config = JSONUtils.INSTANCE.load(badConfig, SensorEnrichmentConfig.class);    config.getConfiguration().putIfAbsent("stellarContext", stellarContext);    JSONObject message = new JSONObject() {        {            put(Constants.SENSOR_TYPE, "test");        }    };    ParallelEnricher.EnrichmentResult result = enricher.apply(message, EnrichmentStrategies.ENRICHMENT, config, null);    JSONObject ret = result.getResult();    Assert.assertEquals(ret + " is not what I expected", 11, ret.size());    Assert.assertEquals(1, ret.get("map.blah"));    Assert.assertEquals("test", ret.get("source.type"));    Assert.assertEquals(1, ret.get("one"));    Assert.assertEquals(2, ret.get("foo"));    Assert.assertEquals("TEST", ret.get("ALL_CAPS"));    Assert.assertEquals(1, result.getEnrichmentErrors().size());    Assert.assertTrue(result.getResult().containsKey("adapter.accessloggingstellaradapter.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("adapter.accessloggingstellaradapter.end.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.splitter.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.splitter.end.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.enrich.begin.ts"));    Assert.assertTrue(result.getResult().containsKey("parallelenricher.enrich.end.ts"));}
0
public void testBadConfigWrongEnrichmentType() throws Exception
{    SensorEnrichmentConfig config = JSONUtils.INSTANCE.load(badConfigWrongEnrichmentType, SensorEnrichmentConfig.class);    config.getConfiguration().putIfAbsent("stellarContext", stellarContext);    JSONObject message = new JSONObject() {        {            put(Constants.SENSOR_TYPE, "test");        }    };    try {        enricher.apply(message, EnrichmentStrategies.ENRICHMENT, config, null);        Assert.fail("This is an invalid config, we should have failed.");    } catch (IllegalStateException ise) {        Assert.assertEquals(ise.getMessage(), "Unable to find an adapter for hbaseThreatIntel, possible adapters are: " + Joiner.on(",").join(enrichmentsByType.keySet()));    }}
0
public static void setupOnce()
{        expectedMessage.put("autonomous_system_organization", "Google LLC");    expectedMessage.put("autonomous_system_number", 15169);    expectedMessage.put("network", "8.8.4.0");    expectedSubsetMessage.put("autonomous_system_organization", "Google LLC");    expectedSubsetMessage.put("autonomous_system_number", 15169);    String baseDir = UnitTestHelper.findDir("GeoLite");    asnHdfsFile = new File(new File(baseDir), "GeoLite2-ASN.tar.gz");}
0
public void setup() throws Exception
{    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> ImmutableMap.of(GeoLiteAsnDatabase.ASN_HDFS_FILE, asnHdfsFile.getAbsolutePath())).build();}
0
public Object run(String rule, Map<String, Object> variables)
{    StellarProcessor processor = new StellarProcessor();    Assert.assertTrue(rule + " not valid.", processor.validate(rule, context));    return processor.parse(rule, new DefaultVariableResolver(variables::get, variables::containsKey), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void testMissingDb()
{    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> ImmutableMap.of(GeoLiteAsnDatabase.ASN_HDFS_FILE, "./fakefile.mmdb")).build();    String stellar = "ASN_GET()";    try {        run(stellar, ImmutableMap.of());    } catch (Exception expected) {        Assert.assertTrue(expected.getMessage().contains("File fakefile.mmdb does not exist"));    }}
0
public void testMissingDbDuringUpdate()
{    String stellar = "ASN_GET()";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Null IP should return null", result);    try {        GeoLiteAsnDatabase.INSTANCE.updateIfNecessary(Collections.singletonMap(GeoLiteAsnDatabase.ASN_HDFS_FILE, "./fakefile.mmdb"));    } catch (IllegalStateException e) {        }        result = run(stellar, ImmutableMap.of());    Assert.assertNull("Null IP should return null", result);}
0
public void testGetEmpty()
{    String stellar = "ASN_GET()";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Empty IP should return null", result);}
0
public void testGetNull()
{    String stellar = "ASN_GET(null)";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Null IP should return null", result);}
0
public void testGetUndefined()
{    String stellar = "ASN_GET(undefined)";    run(stellar, ImmutableMap.of());}
0
public void testGetEmptyString()
{    String stellar = "ASN_GET('  ')";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Empty IP should return null", result);}
0
public void testGetLocal()
{    String stellar = "ASN_GET('192.168.0.1')";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Local IP should return empty map", new HashMap<String, String>(), result);}
0
public void testGetRemote() throws Exception
{    String stellar = "ASN_GET('8.8.4.0')";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Remote IP should return result based on DB", expectedMessage, result);}
0
public void testGetRemoteSingleField() throws Exception
{    String stellar = "ASN_GET('8.8.4.0', ['autonomous_system_organization'])";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Remote IP should return country result based on DB", "Google LLC", result);}
0
public void testGetRemoteSingleFieldInteger() throws Exception
{    String stellar = "ASN_GET('8.8.4.0', ['autonomous_system_number'])";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Remote IP should return country result based on DB", 15169, result);}
0
public void testGetRemoteMultipleFields() throws Exception
{    String stellar = "ASN_GET('8.8.4.0', ['autonomous_system_organization', 'autonomous_system_number'])";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Remote IP should return country result based on DB", expectedSubsetMessage, result);}
0
public void testGetTooManyParams() throws Exception
{    String stellar = "ASN_GET('8.8.4.0', ['autonomous_system_organization', 'autonomous_system_number', 'network'], 'garbage')";    run(stellar, ImmutableMap.of());}
0
public static void main(String... argv)
{    List<StellarFunctionInfo> functions = Lists.newArrayList(SingletonFunctionResolver.getInstance().getFunctionInfo());    Collections.sort(functions, (o1, o2) -> o1.getName().compareTo(o2.getName()));    for (StellarFunctionInfo info : functions) {        System.out.println("### `" + info.getName() + "`");        System.out.println("  * Description: " + info.getDescription());        System.out.println("  * Input:");        for (String param : info.getParams()) {            System.out.println("    * " + param);        }        System.out.println("  * Returns: " + info.getReturns());        System.out.println("");    }}
0
public void setup() throws Exception
{    File tempDir = TestUtils.createTempDir(this.getClass().getName());    file = new File(tempDir, "enrichment.ser");    try (BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(file))) {        IOUtils.write(SerDeUtils.toBytes(new HashMap<String, Object>() {            {                put("key", "value");            }        }), bos);    }}
0
public void shouldReturnEnrichment()
{    String expression = String.format("ENRICHMENT_OBJECT_GET('%s', '%s')", file.getAbsolutePath(), "key");    String value = (String) StellarProcessorUtils.run(expression, new HashMap<>());    assertEquals("value", value);}
0
public void shouldThrowExceptionOnInvalidPath()
{    thrown.expect(ParseException.class);    thrown.expectMessage("Unable to parse ENRICHMENT_OBJECT_GET('/some/path', 'key'): Unable to parse: ENRICHMENT_OBJECT_GET('/some/path', 'key') due to: Path '/some/path' could not be found in HDFS");    String expression = String.format("ENRICHMENT_OBJECT_GET('%s', '%s')", "/some/path", "key");    StellarProcessorUtils.run(expression, new HashMap<>());}
0
public void setup() throws Exception
{    enrichmentObjectGet = new EnrichmentObjectGet();    objectCache = mock(ObjectCache.class);    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, HashMap::new).build();    whenNew(ObjectCache.class).withNoArguments().thenReturn(objectCache);}
0
public void shouldInitializeWithDefaultSettings() throws Exception
{    when(objectCache.isInitialized()).thenReturn(true);    enrichmentObjectGet.initialize(context);    ObjectCacheConfig expectedConfig = new ObjectCacheConfig(new HashMap<>());    verify(objectCache, times(1)).initialize(expectedConfig);    assertTrue(enrichmentObjectGet.isInitialized());}
0
public void shouldInitializeWithCustomSettings() throws Exception
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(ENRICHMENT_OBJECT_GET_SETTINGS, new HashMap<String, Object>() {                {                    put(OBJECT_CACHE_SIZE_KEY, 1);                    put(OBJECT_CACHE_EXPIRATION_KEY, 2);                    put(OBJECT_CACHE_TIME_UNIT_KEY, "SECONDS");                    put(OBJECT_CACHE_MAX_FILE_SIZE_KEY, 3);                }            });        }    };    when(objectCache.isInitialized()).thenReturn(true);    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig).build();    assertFalse(enrichmentObjectGet.isInitialized());    enrichmentObjectGet.initialize(context);    ObjectCacheConfig expectedConfig = new ObjectCacheConfig(new HashMap<>());    expectedConfig.setCacheSize(1);    expectedConfig.setCacheExpiration(2);    expectedConfig.setTimeUnit(TimeUnit.SECONDS);    expectedConfig.setMaxFileSize(3);    verify(objectCache, times(1)).initialize(expectedConfig);    assertTrue(enrichmentObjectGet.isInitialized());}
0
public void shouldApplyEnrichmentObjectGet()
{    Map<String, Object> enrichment = new HashMap<String, Object>() {        {            put("key", "value");        }    };    when(objectCache.get("/path")).thenReturn(enrichment);    assertNull(enrichmentObjectGet.apply(Arrays.asList("/path", "key"), context));    when(objectCache.isInitialized()).thenReturn(true);    enrichmentObjectGet.initialize(context);    assertNull(enrichmentObjectGet.apply(Arrays.asList(null, null), context));    assertEquals("value", enrichmentObjectGet.apply(Arrays.asList("/path", "key"), context));}
0
public void shouldThrowExceptionOnIncorrectObjectFormat()
{    thrown.expect(ClassCastException.class);    thrown.expectMessage("The object stored in HDFS at '/path' must be serialized in JSON format.");    when(objectCache.get("/path")).thenReturn("incorrect format");    when(objectCache.isInitialized()).thenReturn(true);    enrichmentObjectGet.initialize(context);    enrichmentObjectGet.apply(Arrays.asList("/path", "key"), context);}
0
public void restGetShouldThrownExceptionOnMissingParameter()
{    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage("All parameters are mandatory, submit 'hdfs path', 'indicator'");    enrichmentObjectGet.apply(new ArrayList<>(), context);}
0
public static void setupOnce() throws ParseException
{    JSONParser jsonParser = new JSONParser();    expectedMessage = (JSONObject) jsonParser.parse(expectedMessageString);    expectedSubsetMessage = (JSONObject) jsonParser.parse(expectedSubsetString);    String baseDir = UnitTestHelper.findDir("GeoLite");    geoHdfsFile = new File(new File(baseDir), "GeoLite2-City.mmdb.gz");}
0
public void setup() throws Exception
{    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> ImmutableMap.of(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath())).build();}
0
public Object run(String rule, Map<String, Object> variables)
{    StellarProcessor processor = new StellarProcessor();    Assert.assertTrue(rule + " not valid.", processor.validate(rule, context));    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void testMissingDb()
{    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> ImmutableMap.of(GeoLiteCityDatabase.GEO_HDFS_FILE, "./fakefile.mmdb")).build();    String stellar = "GEO_GET()";    try {        run(stellar, ImmutableMap.of());    } catch (Exception expected) {        Assert.assertTrue(expected.getMessage().contains("File fakefile.mmdb does not exist"));    }}
0
public void testMissingDbDuringUpdate()
{    String stellar = "GEO_GET()";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Null IP should return null", result);    try {        GeoLiteCityDatabase.INSTANCE.updateIfNecessary(Collections.singletonMap(GeoLiteCityDatabase.GEO_HDFS_FILE, "./fakefile.mmdb"));    } catch (IllegalStateException e) {        }        result = run(stellar, ImmutableMap.of());    Assert.assertNull("Null IP should return null", result);}
0
public void testGetEmpty()
{    String stellar = "GEO_GET()";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Empty IP should return null", result);}
0
public void testGetNull()
{    String stellar = "GEO_GET(null)";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Null IP should return null", result);}
0
public void testGetUndefined()
{    String stellar = "GEO_GET(undefined)";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Null IP should return null", result);}
0
public void testGetEmptyString()
{    String stellar = "GEO_GET('  ')";    Object result = run(stellar, ImmutableMap.of());    Assert.assertNull("Empty IP should return null", result);}
0
public void testGetLocal()
{    String stellar = "GEO_GET('192.168.0.1')";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Local IP should return empty map", new HashMap<String, String>(), result);}
0
public void testGetRemote()
{    String stellar = "GEO_GET('216.160.83.56')";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Remote IP should return result based on DB", expectedMessage, result);}
0
public void testGetRemoteSingleField()
{    String stellar = "GEO_GET('216.160.83.56', ['country'])";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Remote IP should return country result based on DB", "US", result);}
0
public void testGetRemoteMultipleFields()
{    String stellar = "GEO_GET('216.160.83.56', ['country', 'city', 'dmaCode', 'location_point'])";    Object result = run(stellar, ImmutableMap.of());    Assert.assertEquals("Remote IP should return country result based on DB", expectedSubsetMessage, result);}
0
public void testGetTooManyParams()
{    String stellar = "GEO_GET('216.160.83.56', ['country', 'city', 'dmaCode', 'location_point'], 'garbage')";    run(stellar, ImmutableMap.of());}
0
public void testToLatLong_happypath() throws Exception
{    Map<String, Object> latLong = (Map<String, Object>) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(hash)", ImmutableMap.of("hash", explicitJutlandHash));    Assert.assertEquals(jutlandPoint.getLatitude(), (double) latLong.get("latitude"), 1e-3);    Assert.assertEquals(jutlandPoint.getLongitude(), (double) latLong.get("longitude"), 1e-3);}
0
public void testToLatLong_degenerate() throws Exception
{    {        Map<String, Object> latLong = (Map<String, Object>) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(hash)", ImmutableMap.of("hash", "u"));        Assert.assertFalse(Double.isNaN((double) latLong.get("latitude")));        Assert.assertFalse(Double.isNaN((double) latLong.get("longitude")));    }    {        Map<String, Object> latLong = (Map<String, Object>) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(hash)", ImmutableMap.of("hash", ""));        Assert.assertEquals(0d, (double) latLong.get("latitude"), 1e-3);        Assert.assertEquals(0d, (double) latLong.get("longitude"), 1e-3);    }    {        Map<String, Object> latLong = (Map<String, Object>) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(null)", new HashMap<>());        Assert.assertNull(latLong);    }}
0
public void testHash_fromlatlong() throws Exception
{    Assert.assertEquals("u4pruydqmv", StellarProcessorUtils.run("GEOHASH_FROM_LATLONG(lat, long, 10)", ImmutableMap.of("lat", jutlandPoint.getLatitude(), "long", jutlandPoint.getLongitude())));    Assert.assertEquals("u4pruydqmvpb", StellarProcessorUtils.run("GEOHASH_FROM_LATLONG(lat, long)", ImmutableMap.of("lat", jutlandPoint.getLatitude(), "long", jutlandPoint.getLongitude())));    Assert.assertEquals("u4pruydqmv".substring(0, 6), StellarProcessorUtils.run("GEOHASH_FROM_LATLONG(lat, long, 6)", ImmutableMap.of("lat", jutlandPoint.getLatitude(), "long", jutlandPoint.getLongitude())));    Assert.assertNull(StellarProcessorUtils.run("GEOHASH_FROM_LATLONG(lat)", ImmutableMap.of("lat", jutlandPoint.getLatitude())));    Assert.assertNull(StellarProcessorUtils.run("GEOHASH_FROM_LATLONG(lat, long, 10)", ImmutableMap.of("lat", "blah", "long", jutlandPoint.getLongitude())));}
0
public void testHash_fromLocation() throws Exception
{    Map<String, String> loc = ImmutableMap.of("latitude", "" + jutlandPoint.getLatitude(), "longitude", "" + jutlandPoint.getLongitude());    Assert.assertEquals("u4pruydqmv", StellarProcessorUtils.run("GEOHASH_FROM_LOC(loc, 10)", ImmutableMap.of("loc", loc)));    Assert.assertEquals("u4pruydqmv".substring(0, 6), StellarProcessorUtils.run("GEOHASH_FROM_LOC(loc, 6)", ImmutableMap.of("loc", loc)));    Assert.assertEquals("u4pruydqmvpb", StellarProcessorUtils.run("GEOHASH_FROM_LOC(loc)", ImmutableMap.of("loc", loc)));    Assert.assertNull(StellarProcessorUtils.run("GEOHASH_FROM_LOC(loc)", ImmutableMap.of("loc", ImmutableMap.of("latitude", "57.64911"))));    Assert.assertNull(StellarProcessorUtils.run("GEOHASH_FROM_LOC(loc, 10)", ImmutableMap.of("loc", ImmutableMap.of("latitude", "blah", "longitude", "10.40740"))));}
0
public void testDistanceHaversine() throws Exception
{    testDistance(Optional.empty());    testDistance(Optional.of("HAVERSINE"));}
0
public void testDistanceLawOfCosines() throws Exception
{    testDistance(Optional.of("LAW_OF_COSINES"));}
0
public void testDistanceLawOfVicenty() throws Exception
{    testDistance(Optional.of("VICENTY"));}
0
public void testMaxDistance_happyPath() throws Exception
{    Double maxDistance = (double) StellarProcessorUtils.run("GEOHASH_MAX_DIST([empireState, mosconeCenter, jutland])", ImmutableMap.of("empireState", empireStateHash, "mosconeCenter", mosconeCenterHash, "jutland", jutlandHash));    double expectedDistance = 8528;    Assert.assertEquals(expectedDistance, maxDistance, 1d);}
0
public void testMaxDistance_differentOrder() throws Exception
{    Double maxDistance = (double) StellarProcessorUtils.run("GEOHASH_MAX_DIST([jutland, mosconeCenter, empireState])", ImmutableMap.of("empireState", empireStateHash, "mosconeCenter", mosconeCenterHash, "jutland", jutlandHash));    double expectedDistance = 8528;    Assert.assertEquals(expectedDistance, maxDistance, 1d);}
0
public void testMaxDistance_withNulls() throws Exception
{    Double maxDistance = (double) StellarProcessorUtils.run("GEOHASH_MAX_DIST([jutland, mosconeCenter, empireState, null])", ImmutableMap.of("empireState", empireStateHash, "mosconeCenter", mosconeCenterHash, "jutland", jutlandHash));    double expectedDistance = 8528;    Assert.assertEquals(expectedDistance, maxDistance, 1d);}
0
public void testMaxDistance_allSame() throws Exception
{    Double maxDistance = (double) StellarProcessorUtils.run("GEOHASH_MAX_DIST([jutland, jutland, jutland])", ImmutableMap.of("jutland", jutlandHash));    Assert.assertEquals(0, maxDistance, 1e-6d);}
0
public void testMaxDistance_emptyList() throws Exception
{    Double maxDistance = (double) StellarProcessorUtils.run("GEOHASH_MAX_DIST([])", new HashMap<>());    Assert.assertTrue(Double.isNaN(maxDistance));}
0
public void testMaxDistance_nullList() throws Exception
{    Double maxDistance = (Double) StellarProcessorUtils.run("GEOHASH_MAX_DIST(null)", new HashMap<>());    Assert.assertNull(maxDistance);}
0
public void testMaxDistance_invalidList() throws Exception
{    Double maxDistance = (Double) StellarProcessorUtils.run("GEOHASH_MAX_DIST()", new HashMap<>());    Assert.assertNull(maxDistance);}
0
public void testDistance(Optional<String> method) throws Exception
{        double expectedDistance = 4128;    Map<String, Object> vars = ImmutableMap.of("empireState", empireStateHash, "mosconeCenter", mosconeCenterHash);        {        String stellarStatement = getDistStellarStatement(ImmutableList.of("mosconeCenter", "empireState"), method);        Assert.assertEquals(expectedDistance, (double) StellarProcessorUtils.run(stellarStatement, vars), 1D);    }    {        String stellarStatement = getDistStellarStatement(ImmutableList.of("empireState", "mosconeCenter"), method);        Assert.assertEquals(expectedDistance, (double) StellarProcessorUtils.run(stellarStatement, vars), 1D);    }}
0
private static String getDistStellarStatement(List<String> hashVariables, Optional<String> method)
{    if (method.isPresent()) {        List<String> vars = new ArrayList<>();        vars.addAll(hashVariables);        vars.add("\'" + method.get() + "\'");        return "GEOHASH_DIST(" + Joiner.on(",").skipNulls().join(vars) + ")";    } else {        return "GEOHASH_DIST(" + Joiner.on(",").skipNulls().join(hashVariables) + ")";    }}
0
public void testCentroid_List() throws Exception
{        {        double         expectedLong = -98.740087, expectedLat = 41.86921;        Map<String, Double> centroid = (Map) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(GEOHASH_CENTROID([empireState, mosconeCenter]))", ImmutableMap.of("empireState", empireStateHash, "mosconeCenter", mosconeCenterHash));        Assert.assertEquals(expectedLong, centroid.get("longitude"), 1e-3);        Assert.assertEquals(expectedLat, centroid.get("latitude"), 1e-3);    }        {        double expectedLong = empireStatePoint.getLongitude(), expectedLat = empireStatePoint.getLatitude();        Map<String, Double> centroid = (Map) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(GEOHASH_CENTROID([empireState, empireState]))", ImmutableMap.of("empireState", empireStateHash));        Assert.assertEquals(expectedLong, centroid.get("longitude"), 1e-3);        Assert.assertEquals(expectedLat, centroid.get("latitude"), 1e-3);    }        {        double expectedLong = empireStatePoint.getLongitude(), expectedLat = empireStatePoint.getLatitude();        Map<String, Double> centroid = (Map) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(GEOHASH_CENTROID([empireState]))", ImmutableMap.of("empireState", empireStateHash));        Assert.assertEquals(expectedLong, centroid.get("longitude"), 1e-3);        Assert.assertEquals(expectedLat, centroid.get("latitude"), 1e-3);    }        {        Map<String, Double> centroid = (Map) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(GEOHASH_CENTROID([]))", new HashMap<>());        Assert.assertNull(centroid);    }}
0
public void testCentroid_weighted() throws Exception
{        {        double         expectedLong = -98.740087, expectedLat = 41.86921;        for (int weight = 1; weight < 10; ++weight) {            Map<Object, Integer> weightedPoints = ImmutableMap.of(empireStateHash, weight, mosconeCenterHash, weight);            Map<String, Double> centroid = (Map) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(GEOHASH_CENTROID(weightedPoints))", ImmutableMap.of("weightedPoints", weightedPoints));            Assert.assertEquals(expectedLong, centroid.get("longitude"), 1e-3);            Assert.assertEquals(expectedLat, centroid.get("latitude"), 1e-3);        }    }        {        double expectedLong = empireStatePoint.getLongitude(), expectedLat = empireStatePoint.getLatitude();        for (int weight = 1; weight < 10; ++weight) {            Map<Object, Integer> weightedPoints = ImmutableMap.of(empireStateHash, weight);            Map<String, Double> centroid = (Map) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(GEOHASH_CENTROID(weightedPoints))", ImmutableMap.of("weightedPoints", weightedPoints));            Assert.assertEquals(expectedLong, centroid.get("longitude"), 1e-3);            Assert.assertEquals(expectedLat, centroid.get("latitude"), 1e-3);        }    }        {        Map<Object, Integer> weightedPoints = new HashMap<>();        Map<String, Double> centroid = (Map) StellarProcessorUtils.run("GEOHASH_TO_LATLONG(GEOHASH_CENTROID(weightedPoints))", ImmutableMap.of("weightedPoints", weightedPoints));        Assert.assertNull(centroid);    }}
0
public void setup() throws Exception
{    File tempDir = TestUtils.createTempDir(this.getClass().getName());    file = new File(tempDir, "object.ser");    try (BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(file))) {        IOUtils.write(SerDeUtils.toBytes("object get data"), bos);    }}
0
public void shouldReturnEnrichment()
{    String expression = String.format("OBJECT_GET('%s')", file.getAbsolutePath());    String value = (String) StellarProcessorUtils.run(expression, new HashMap<>());    assertEquals("object get data", value);}
0
public void shouldThrowExceptionOnInvalidPath()
{    thrown.expect(ParseException.class);    thrown.expectMessage("Unable to parse OBJECT_GET('/some/path'): Unable to parse: OBJECT_GET('/some/path') due to: Path '/some/path' could not be found in HDFS");    String expression = String.format("OBJECT_GET('%s')", "/some/path");    StellarProcessorUtils.run(expression, new HashMap<>());}
0
public void setup() throws Exception
{    objectGet = new ObjectGet();    objectCache = mock(ObjectCache.class);    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, HashMap::new).build();    whenNew(ObjectCache.class).withNoArguments().thenReturn(objectCache);}
0
public void shouldInitialize() throws Exception
{    when(objectCache.isInitialized()).thenReturn(true);    assertFalse(objectGet.isInitialized());    objectGet.initialize(context);    ObjectCacheConfig expectedConfig = new ObjectCacheConfig(new HashMap<>());    verify(objectCache, times(1)).initialize(expectedConfig);    assertTrue(objectGet.isInitialized());}
0
public void shouldApplyObjectGet()
{    Object object = mock(Object.class);    when(objectCache.get("/path")).thenReturn(object);    assertNull(objectGet.apply(Collections.singletonList("/path"), context));    when(objectCache.isInitialized()).thenReturn(true);    objectGet.initialize(context);    assertNull(objectGet.apply(new ArrayList<>(), context));    assertNull(objectGet.apply(Collections.singletonList(null), context));    assertEquals(object, objectGet.apply(Collections.singletonList("/path"), context));}
0
public void shouldThrowIllegalStateExceptionOnInvalidPath()
{    thrown.expect(IllegalStateException.class);    thrown.expectMessage("Unable to retrieve 1 as it is not a path");    when(objectCache.isInitialized()).thenReturn(true);    objectGet.initialize(context);    objectGet.apply(Collections.singletonList(1), context);}
0
public void setup() throws Exception
{    final MockHTable hbaseTable = (MockHTable) MockHBaseTableProvider.addToCache(hbaseTableName, cf);    EnrichmentHelper.INSTANCE.load(hbaseTable, cf, new ArrayList<LookupKV<EnrichmentKey, EnrichmentValue>>() {        {            for (int i = 0; i < 5; ++i) {                add(new LookupKV<>(new EnrichmentKey(ENRICHMENT_TYPE, "indicator" + i), new EnrichmentValue(ImmutableMap.of("key" + i, "value" + i))));            }        }    });    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> ImmutableMap.of(SimpleHBaseEnrichmentFunctions.TABLE_PROVIDER_TYPE_CONF, MockHBaseTableProvider.class.getName())).build();}
0
public Object run(String rule, Map<String, Object> variables) throws Exception
{    StellarProcessor processor = new StellarProcessor();    Assert.assertTrue(rule + " not valid.", processor.validate(rule, context));    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void testExists() throws Exception
{    String stellar = "ENRICHMENT_EXISTS('et', indicator, 'enrichments', 'cf')";    Object result = run(stellar, ImmutableMap.of("indicator", "indicator0"));    Assert.assertTrue(result instanceof Boolean);    Assert.assertTrue((Boolean) result);}
0
public void testNotExists() throws Exception
{    String stellar = "ENRICHMENT_EXISTS('et', indicator, 'enrichments', 'cf')";    Object result = run(stellar, ImmutableMap.of("indicator", "indicator7"));    Assert.assertTrue(result instanceof Boolean);    Assert.assertFalse((Boolean) result);}
0
public void testSuccessfulGet() throws Exception
{    String stellar = "ENRICHMENT_GET('et', indicator, 'enrichments', 'cf')";    Object result = run(stellar, ImmutableMap.of("indicator", "indicator0"));    Assert.assertTrue(result instanceof Map);    Map<String, Object> out = (Map<String, Object>) result;    Assert.assertEquals("value0", out.get("key0"));}
0
public void testMultiGet() throws Exception
{    String stellar = "MAP([ 'indicator0', 'indicator1' ], indicator -> ENRICHMENT_GET('et', indicator, 'enrichments', 'cf') )";    Object result = run(stellar, new HashMap<>());    Assert.assertTrue(result instanceof List);    List<Map<String, Object>> out = (List<Map<String, Object>>) result;    Assert.assertEquals(2, out.size());    for (int i = 0; i < 2; ++i) {        Map<String, Object> map = out.get(i);        Assert.assertEquals("value" + i, map.get("key" + i));    }}
0
public void testUnsuccessfulGet() throws Exception
{    String stellar = "ENRICHMENT_GET('et', indicator, 'enrichments', 'cf')";    Object result = run(stellar, ImmutableMap.of("indicator", "indicator7"));    Assert.assertTrue(result instanceof Map);    Map<String, Object> out = (Map<String, Object>) result;    Assert.assertTrue(out.isEmpty());}
0
public void testProvidedParameters() throws Exception
{    String stellar = "ENRICHMENT_GET('et', indicator)";    Object result = run(stellar, ImmutableMap.of("indicator", "indicator7"));}
0
public void smokeTest() throws Exception
{    ThreatTriageProcessor threatTriageProcessor = getProcessor(smokeTestProcessorConfig);    Assert.assertEquals("Expected a score of 0", 0d, new ThreatTriageProcessor(new SensorEnrichmentConfig(), StellarFunctions.FUNCTION_RESOLVER(), Context.EMPTY_CONTEXT()).apply(new HashMap<Object, Object>() {        {            put("user.type", "admin");            put("asset.type", "web");        }    }).getScore(), 1e-10);    Assert.assertEquals("Expected a score of 10", 10d, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("user.type", "admin");            put("asset.type", "web");        }    }).getScore(), 1e-10);    Assert.assertEquals("Expected a score of 5", 5d, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("user.type", "normal");            put("asset.type", "web");        }    }).getScore(), 1e-10);    Assert.assertEquals("Expected a score of 0", 0d, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("user.type", "foo");            put("asset.type", "bar");        }    }).getScore(), 1e-10);    Assert.assertEquals("Expected a score of -Inf", Double.NEGATIVE_INFINITY, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("user.type", "abnormal");            put("asset.type", "bar");        }    }).getScore(), 1e-10);}
0
public void testThreatScoreWithMultipleRules() throws Exception
{    Map<Object, Object> message = new HashMap<Object, Object>() {        {            put("user.type", "admin");            put("asset.type", "web");        }    };    ThreatScore score = getProcessor(smokeTestProcessorConfig).apply(message);        List<String> expectedNames = ImmutableList.of("rule 1", "rule 2");    Assert.assertEquals(2, score.getRuleScores().size());    score.getRuleScores().forEach(ruleScore -> Assert.assertTrue(expectedNames.contains(ruleScore.getRule().getName())));}
0
public void testThreatScoreWithOneRule() throws Exception
{    Map<Object, Object> message = new HashMap<Object, Object>() {        {            put("user.type", "abnormal");            put("asset.type", "invalid");        }    };    ThreatScore score = getProcessor(smokeTestProcessorConfig).apply(message);        List<String> expectedNames = ImmutableList.of("rule 4");    Assert.assertEquals(1, score.getRuleScores().size());    score.getRuleScores().forEach(ruleScore -> Assert.assertTrue(expectedNames.contains(ruleScore.getRule().getName())));}
0
public void testThreatScoreWithNoRules() throws Exception
{    Map<Object, Object> message = new HashMap<Object, Object>() {        {            put("user.type", "foo");            put("asset.type", "bar");        }    };    ThreatScore score = getProcessor(smokeTestProcessorConfig).apply(message);        Assert.assertEquals(0, score.getRuleScores().size());}
0
public void testPositiveMeanAggregationScores() throws Exception
{    ThreatTriageProcessor threatTriageProcessor = getProcessor(positiveMeanProcessorConfig);    Assert.assertEquals("Expected a score of 0", 5d, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("user.type", "normal");            put("asset.type", "web");        }    }).getScore(), 1e-10);    Assert.assertEquals("Expected a score of 7.5", (10 + 5) / 2.0, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("user.type", "admin");            put("asset.type", "web");        }    }).getScore(), 1e-10);    Assert.assertEquals("Expected a score of 0", 0d, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("user.type", "foo");            put("asset.type", "bar");        }    }).getScore(), 1e-10);}
0
public void testWithStellarFunction() throws Exception
{    ThreatTriageProcessor threatTriageProcessor = getProcessor(testWithStellarFunction);    Assert.assertEquals(10d, threatTriageProcessor.apply(new HashMap<Object, Object>() {        {            put("ip_dst_addr", "172.2.2.2");        }    }).getScore(), 1e-10);}
0
public void testReason() throws Exception
{    Map<Object, Object> message = new HashMap<Object, Object>() {        {            put("variable.name", "variable.value");        }    };    ThreatScore score = getProcessor(testReasonConfig).apply(message);    assertEquals(1, score.getRuleScores().size());    for (RuleScore ruleScore : score.getRuleScores()) {                assertEquals("variable.value", ruleScore.getReason());    }}
0
public void testInvalidReason() throws Exception
{    Map<Object, Object> message = new HashMap<Object, Object>() {        {                }    };    ThreatScore score = getProcessor(testReasonConfig).apply(message);    assertEquals(1, score.getRuleScores().size());    for (RuleScore ruleScore : score.getRuleScores()) {                assertEquals(null, ruleScore.getReason());    }}
0
public void shouldAllowNumericRuleScore() throws Exception
{    Map<String, Object> message = new HashMap<>();    ThreatTriageProcessor threatTriageProcessor = getProcessor(shouldAllowNumericRuleScore);    Assert.assertEquals(10d, threatTriageProcessor.apply(message).getScore(), 1e-10);}
0
public void shouldAllowScoreAsStellarExpression() throws Exception
{        Map<Object, Object> message = new HashMap<Object, Object>() {        {            put("priority", 100);        }    };    ThreatTriageProcessor threatTriageProcessor = getProcessor(shouldAllowScoreAsStellarExpression);    Assert.assertEquals(1010.0d, threatTriageProcessor.apply(message).getScore(), 1e-10);}
0
private static ThreatTriageProcessor getProcessor(String config) throws IOException
{    SensorEnrichmentConfig c = JSONUtils.INSTANCE.load(config, SensorEnrichmentConfig.class);    return new ThreatTriageProcessor(c, StellarFunctions.FUNCTION_RESOLVER(), Context.EMPTY_CONTEXT());}
0
public GenericEnrichmentBolt withEnrichment(Enrichment enrichment)
{    this.enrichmentType = enrichment.getType();    this.adapter = enrichment.getAdapter();    return this;}
0
public GenericEnrichmentBolt withMaxCacheSize(long maxCacheSize)
{    this.maxCacheSize = maxCacheSize;    return this;}
0
public GenericEnrichmentBolt withMaxTimeRetain(long maxTimeRetain)
{    this.maxTimeRetain = maxTimeRetain;    return this;}
0
public GenericEnrichmentBolt withCacheInvalidationOnReload(boolean cacheInvalidationOnReload)
{    this.invalidateCacheOnReload = cacheInvalidationOnReload;    return this;}
0
public void reloadCallback(String name, ConfigurationType type)
{    if (invalidateCacheOnReload) {        if (cache != null) {            cache.invalidateAll();        }    }    if (type == ConfigurationType.GLOBAL) {        adapter.updateAdapter(getConfigurations().getGlobalConfig());    }}
0
public void prepare(Map conf, TopologyContext topologyContext, OutputCollector collector)
{    super.prepare(conf, topologyContext, collector);    this.collector = collector;    if (this.maxCacheSize == null)        throw new IllegalStateException("MAX_CACHE_SIZE_OBJECTS_NUM must be specified");    if (this.maxTimeRetain == null)        throw new IllegalStateException("MAX_TIME_RETAIN_MINUTES must be specified");    if (this.adapter == null)        throw new IllegalStateException("Adapter must be specified");    loader = key -> adapter.enrich(key);    cache = Caffeine.newBuilder().maximumSize(maxCacheSize).expireAfterWrite(maxTimeRetain, TimeUnit.MINUTES).build(loader);    boolean success = adapter.initializeAdapter(getConfigurations().getGlobalConfig());    if (!success) {                throw new IllegalStateException("Could not initialize adapter...");    }    perfLog = new PerformanceLogger(() -> getConfigurations().getGlobalConfig(), GenericEnrichmentBolt.Perf.class.getName());    initializeStellar();}
1
protected void initializeStellar()
{    stellarContext = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client).with(Context.Capabilities.GLOBAL_CONFIG, () -> getConfigurations().getGlobalConfig()).with(Context.Capabilities.STELLAR_CONFIG, () -> getConfigurations().getGlobalConfig()).build();    StellarFunctions.initialize(stellarContext);}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    declarer.declareStream(enrichmentType, new Fields("key", "message", "subgroup"));    declarer.declareStream(ERROR_STREAM, new Fields("message"));}
0
public void execute(Tuple tuple)
{    perfLog.mark("execute");    String key = tuple.getStringByField("key");    JSONObject rawMessage = (JSONObject) tuple.getValueByField("message");    String subGroup = "";    JSONObject enrichedMessage = new JSONObject();    enrichedMessage.put("adapter." + adapter.getClass().getSimpleName().toLowerCase() + ".begin.ts", "" + System.currentTimeMillis());    try {        if (rawMessage == null || rawMessage.isEmpty())            throw new Exception("Could not parse binary stream to JSON");        if (key == null)            throw new Exception("Key is not valid");        String sourceType = null;        if (rawMessage.containsKey(Constants.SENSOR_TYPE)) {            sourceType = rawMessage.get(Constants.SENSOR_TYPE).toString();        } else {            throw new RuntimeException("Source type is missing from enrichment fragment: " + rawMessage.toJSONString());        }        String prefix = null;        for (Object o : rawMessage.keySet()) {            String field = (String) o;            Object value = rawMessage.get(field);            if (field.equals(Constants.SENSOR_TYPE)) {                enrichedMessage.put(Constants.SENSOR_TYPE, value);            } else {                JSONObject enrichedField = new JSONObject();                if (value != null) {                    SensorEnrichmentConfig config = getConfigurations().getSensorEnrichmentConfig(sourceType);                    if (config == null) {                                                MetronError metronError = new MetronError().withErrorType(Constants.ErrorType.ENRICHMENT_ERROR).withMessage("Unable to find SensorEnrichmentConfig for sourceType: " + sourceType).addRawMessage(rawMessage);                        StormErrorUtils.handleError(collector, metronError);                        continue;                    }                    config.getConfiguration().putIfAbsent(STELLAR_CONTEXT_CONF, stellarContext);                    CacheKey cacheKey = new CacheKey(field, value, config);                    try {                        adapter.logAccess(cacheKey);                        prefix = adapter.getOutputPrefix(cacheKey);                        subGroup = adapter.getStreamSubGroup(enrichmentType, field);                        perfLog.mark("enrich");                        enrichedField = cache.get(cacheKey);                        perfLog.log("enrich", "key={}, time to run enrichment type={}", key, enrichmentType);                        if (enrichedField == null)                            throw new Exception("[Metron] Could not enrich string: " + value);                    } catch (Exception e) {                                                MetronError metronError = new MetronError().withErrorType(Constants.ErrorType.ENRICHMENT_ERROR).withThrowable(e).withErrorFields(new HashSet() {                            {                                add(field);                            }                        }).addRawMessage(rawMessage);                        StormErrorUtils.handleError(collector, metronError);                        continue;                    }                }                enrichedMessage = EnrichmentUtils.adjustKeys(enrichedMessage, enrichedField, field, prefix);            }        }        enrichedMessage.put("adapter." + adapter.getClass().getSimpleName().toLowerCase() + ".end.ts", "" + System.currentTimeMillis());        if (!enrichedMessage.isEmpty()) {            collector.emit(enrichmentType, new Values(key, enrichedMessage, subGroup));        }    } catch (Exception e) {        handleError(key, rawMessage, subGroup, enrichedMessage, e);    }    perfLog.log("execute", "key={}, elapsed time to run execute", key);}
1
protected void handleError(String key, JSONObject rawMessage, String subGroup, JSONObject enrichedMessage, Exception e)
{        if (key != null) {        collector.emit(enrichmentType, new Values(key, enrichedMessage, subGroup));    }    MetronError error = new MetronError().withErrorType(Constants.ErrorType.ENRICHMENT_ERROR).withThrowable(e).addRawMessage(rawMessage);    StormErrorUtils.handleError(collector, error);}
1
public void cleanup()
{    super.cleanup();    adapter.cleanup();}
0
public Context getStellarContext()
{    return stellarContext;}
0
public UnifiedEnrichmentBolt withEnrichments(List<Enrichment> enrichments)
{    for (Enrichment e : enrichments) {        enrichmentsByType.put(e.getType(), e.getAdapter());    }    return this;}
0
public UnifiedEnrichmentBolt withCaptureCacheStats(boolean captureCacheStats)
{    this.captureCacheStats = captureCacheStats;    return this;}
0
public UnifiedEnrichmentBolt withMessageGetter(String getter)
{    this.getterStrategy = MessageGetters.valueOf(getter);    return this;}
0
private static int getNumThreads(Object numThreads)
{    if (numThreads instanceof Number) {        return ((Number) numThreads).intValue();    } else if (numThreads instanceof String) {        String numThreadsStr = ((String) numThreads).trim().toUpperCase();        if (numThreadsStr.endsWith("C")) {            Integer factor = Integer.parseInt(numThreadsStr.replace("C", ""));            return factor * Runtime.getRuntime().availableProcessors();        } else {            return Integer.parseInt(numThreadsStr);        }    }    return 2 * Runtime.getRuntime().availableProcessors();}
0
public UnifiedEnrichmentBolt withStrategy(String strategy)
{    this.strategy = EnrichmentStrategies.valueOf(strategy);    return this;}
0
public UnifiedEnrichmentBolt withMaxCacheSize(long maxCacheSize)
{    this.maxCacheSize = maxCacheSize;    return this;}
0
public UnifiedEnrichmentBolt withMaxTimeRetain(long maxTimeRetain)
{    this.maxTimeRetain = maxTimeRetain;    return this;}
0
public UnifiedEnrichmentBolt withCacheInvalidationOnReload(boolean cacheInvalidationOnReload)
{    this.invalidateCacheOnReload = cacheInvalidationOnReload;    return this;}
0
public void reloadCallback(String name, ConfigurationType type)
{    if (invalidateCacheOnReload) {        if (strategy != null && ConcurrencyContext.get(strategy).getCache() != null) {            ConcurrencyContext.get(strategy).getCache().invalidateAll();        }    }    if (type == ConfigurationType.GLOBAL && enrichmentsByType != null) {        for (EnrichmentAdapter adapter : enrichmentsByType.values()) {            adapter.updateAdapter(getConfigurations().getGlobalConfig());        }    }}
0
public void execute(Tuple input)
{    JSONObject message = generateMessage(input);    try {        String sourceType = MessageUtils.getSensorType(message);        SensorEnrichmentConfig config = getConfigurations().getSensorEnrichmentConfig(sourceType);        if (config == null) {                        config = new SensorEnrichmentConfig();        }                        config.getConfiguration().putIfAbsent(STELLAR_CONTEXT_CONF, stellarContext);        String guid = getGUID(input, message);                ParallelEnricher.EnrichmentResult result = enricher.apply(message, strategy, config, perfLog);        JSONObject enriched = result.getResult();        enriched = strategy.postProcess(enriched, config, enrichmentContext);                collector.emit("message", input, new Values(guid, enriched));                for (Map.Entry<Object, Throwable> t : result.getEnrichmentErrors()) {                        MetronError error = new MetronError().withErrorType(strategy.getErrorType()).withMessage(t.getValue().getMessage()).withThrowable(t.getValue()).addRawMessage(t.getKey());            StormErrorUtils.handleError(collector, error);        }    } catch (Exception e) {                                MetronError error = new MetronError().withErrorType(strategy.getErrorType()).withMessage(e.getMessage()).withThrowable(e).addRawMessage(message);        StormErrorUtils.handleError(collector, error);    } finally {        collector.ack(input);    }}
1
public UnifiedEnrichmentBolt withMessageFieldName(String messageFieldName)
{    this.messageFieldName = messageFieldName;    return this;}
0
public JSONObject generateMessage(Tuple tuple)
{    return (JSONObject) messageGetter.get(tuple);}
0
public final void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector)
{    super.prepare(map, topologyContext, outputCollector);    collector = outputCollector;    if (this.maxCacheSize == null) {        throw new IllegalStateException("MAX_CACHE_SIZE_OBJECTS_NUM must be specified");    }    if (this.maxTimeRetain == null) {        throw new IllegalStateException("MAX_TIME_RETAIN_MINUTES must be specified");    }    if (this.enrichmentsByType.isEmpty()) {        throw new IllegalStateException("Adapter must be specified");    }    for (Map.Entry<String, EnrichmentAdapter<CacheKey>> adapterKv : enrichmentsByType.entrySet()) {        boolean success = adapterKv.getValue().initializeAdapter(getConfigurations().getGlobalConfig());        if (!success) {                        throw new IllegalStateException("Could not initialize adapter: " + adapterKv.getKey());        }    }    WorkerPoolStrategies workerPoolStrategy = WorkerPoolStrategies.FIXED;    if (map.containsKey(THREADPOOL_TYPE_TOPOLOGY_CONF)) {        workerPoolStrategy = WorkerPoolStrategies.valueOf(map.get(THREADPOOL_TYPE_TOPOLOGY_CONF) + "");    }    if (map.containsKey(THREADPOOL_NUM_THREADS_TOPOLOGY_CONF)) {        int numThreads = getNumThreads(map.get(THREADPOOL_NUM_THREADS_TOPOLOGY_CONF));        ConcurrencyContext.get(strategy).initialize(numThreads, maxCacheSize, maxTimeRetain, workerPoolStrategy, LOG, captureCacheStats);    } else {        throw new IllegalStateException("You must pass " + THREADPOOL_NUM_THREADS_TOPOLOGY_CONF + " via storm config.");    }    messageGetter = this.getterStrategy.get(messageFieldName);    enricher = new ParallelEnricher(enrichmentsByType, ConcurrencyContext.get(strategy), captureCacheStats);    perfLog = new PerformanceLogger(() -> getConfigurations().getGlobalConfig(), Perf.class.getName());    GeoLiteCityDatabase.INSTANCE.update((String) getConfigurations().getGlobalConfig().get(GeoLiteCityDatabase.GEO_HDFS_FILE));    GeoLiteAsnDatabase.INSTANCE.update((String) getConfigurations().getGlobalConfig().get(GeoLiteAsnDatabase.ASN_HDFS_FILE));    initializeStellar();    enrichmentContext = new EnrichmentContext(StellarFunctions.FUNCTION_RESOLVER(), stellarContext);}
1
protected void initializeStellar()
{    stellarContext = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client).with(Context.Capabilities.GLOBAL_CONFIG, () -> getConfigurations().getGlobalConfig()).with(Context.Capabilities.STELLAR_CONFIG, () -> getConfigurations().getGlobalConfig()).build();    StellarFunctions.initialize(stellarContext);}
0
public String getGUID(Tuple tuple, JSONObject message)
{    String key = null, guid = null;    try {        key = tuple.getStringByField("key");        guid = (String) message.get(Constants.GUID);    } catch (Throwable t) {        }    if (key != null) {        return key;    } else if (guid != null) {        return guid;    } else {        return UUID.randomUUID().toString();    }}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    declarer.declareStream("message", new Fields("key", "message"));    declarer.declareStream("error", new Fields("message"));}
0
public boolean matches(Object o)
{    Values values = (Values) o;    String actualKey = (String) values.get(0);    JSONObject actualMessage = (JSONObject) values.get(1);    removeTimingFields(actualMessage);    return expectedKey.equals(actualKey) && expectedMessage.equals(actualMessage);}
0
public void describeTo(Description description)
{    description.appendText(String.format("[%s]", expectedMessage));}
0
public void parseMessages() throws ParseException
{    JSONParser parser = new JSONParser();    originalMessage = (JSONObject) parser.parse(originalMessageString);    enrichedField1 = (JSONObject) parser.parse(enrichedField1String);    enrichedField2 = (JSONObject) parser.parse(enrichedField2String);    enrichedMessage = (JSONObject) parser.parse(enrichedMessageString);}
0
public void initMocks()
{    MockitoAnnotations.initMocks(this);}
0
public void test() throws IOException
{    when(tuple.getSourceComponent()).thenReturn("unit test component");    when(tuple.getSourceStreamId()).thenReturn("unit test stream");    String key = "someKey";    String enrichmentType = "enrichmentType";    Enrichment<EnrichmentAdapter<CacheKey>> testEnrichment = new Enrichment<>();    testEnrichment.setType(enrichmentType);    testEnrichment.setAdapter(enrichmentAdapter);    GenericEnrichmentBolt genericEnrichmentBolt = new GenericEnrichmentBolt("zookeeperUrl") {        @Override        protected void initializeStellar() {                }    };    genericEnrichmentBolt.setCuratorFramework(client);    genericEnrichmentBolt.setZKCache(cache);    genericEnrichmentBolt.getConfigurations().updateSensorEnrichmentConfig(sensorType, new FileInputStream(enrichmentConfigPath));    HashMap<String, Object> globalConfig = new HashMap<>();    String baseDir = UnitTestHelper.findDir(new File("../metron-enrichment-common"), "GeoLite");    File geoHdfsFile = new File(new File(baseDir), "GeoLite2-City.mmdb.gz");    globalConfig.put(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath());    genericEnrichmentBolt.getConfigurations().updateGlobalConfig(globalConfig);    try {        genericEnrichmentBolt.prepare(new HashMap(), topologyContext, outputCollector);        fail("Should fail if a maxCacheSize property is not set");    } catch (IllegalStateException e) {    }    genericEnrichmentBolt.withMaxCacheSize(100);    try {        genericEnrichmentBolt.prepare(new HashMap(), topologyContext, outputCollector);        fail("Should fail if a maxTimeRetain property is not set");    } catch (IllegalStateException e) {    }    genericEnrichmentBolt.withMaxTimeRetain(10000);    try {        genericEnrichmentBolt.prepare(new HashMap(), topologyContext, outputCollector);        fail("Should fail if an adapter is not set");    } catch (IllegalStateException e) {    }    genericEnrichmentBolt.withEnrichment(testEnrichment);    when(enrichmentAdapter.initializeAdapter(globalConfig)).thenReturn(true);    genericEnrichmentBolt.prepare(new HashMap(), topologyContext, outputCollector);    verify(enrichmentAdapter, times(1)).initializeAdapter(globalConfig);    when(enrichmentAdapter.initializeAdapter(globalConfig)).thenReturn(false);    UnitTestHelper.setLog4jLevel(GenericEnrichmentBolt.class, Level.FATAL);    try {        genericEnrichmentBolt.prepare(new HashMap(), topologyContext, outputCollector);        fail("An exception should be thrown if enrichment adapter initialization fails");    } catch (IllegalStateException e) {    }    UnitTestHelper.setLog4jLevel(GenericEnrichmentBolt.class, Level.ERROR);    genericEnrichmentBolt.declareOutputFields(declarer);    verify(declarer, times(1)).declareStream(eq(enrichmentType), argThat(new FieldsMatcher("key", "message", "subgroup")));    verify(declarer, times(1)).declareStream(eq("error"), argThat(new FieldsMatcher("message")));    when(tuple.getStringByField("key")).thenReturn(null);    UnitTestHelper.setLog4jLevel(GenericEnrichmentBolt.class, Level.FATAL);    genericEnrichmentBolt.execute(tuple);    UnitTestHelper.setLog4jLevel(GenericEnrichmentBolt.class, Level.ERROR);    MetronError error = new MetronError().withErrorType(Constants.ErrorType.ENRICHMENT_ERROR).withThrowable(new Exception("Could not parse binary stream to JSON"));    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), argThat(new MetronErrorJSONMatcher(error.getJSONObject())));    when(tuple.getStringByField("key")).thenReturn(key);    when(tuple.getValueByField("message")).thenReturn(originalMessage);    when(enrichmentAdapter.enrich(any())).thenReturn(new JSONObject());    genericEnrichmentBolt.execute(tuple);    verify(outputCollector, times(1)).emit(eq(enrichmentType), argThat(new EnrichedMessageMatcher(key, new JSONObject(ImmutableMap.of("source.type", "test")))));    reset(enrichmentAdapter);    SensorEnrichmentConfig sensorEnrichmentConfig = SensorEnrichmentConfig.fromBytes(ConfigurationsUtils.readSensorEnrichmentConfigsFromFile(sampleConfigPath).get(sensorType));    sensorEnrichmentConfig.getConfiguration().put(STELLAR_CONTEXT_CONF, genericEnrichmentBolt.getStellarContext());    CacheKey cacheKey1 = new CacheKey("field1", "value1", sensorEnrichmentConfig);    CacheKey cacheKey2 = new CacheKey("field2", "value2", sensorEnrichmentConfig);    genericEnrichmentBolt.cache.invalidateAll();    when(enrichmentAdapter.getOutputPrefix(cacheKey1)).thenReturn("field1");    when(enrichmentAdapter.getOutputPrefix(cacheKey2)).thenReturn("field2");    when(enrichmentAdapter.enrich(cacheKey1)).thenReturn(enrichedField1);    when(enrichmentAdapter.enrich(cacheKey2)).thenReturn(enrichedField2);    genericEnrichmentBolt.execute(tuple);    verify(enrichmentAdapter, times(1)).logAccess(cacheKey1);    verify(enrichmentAdapter, times(1)).logAccess(cacheKey2);    verify(outputCollector, times(1)).emit(eq(enrichmentType), argThat(new EnrichedMessageMatcher(key, enrichedMessage)));    reset(outputCollector);    genericEnrichmentBolt.cache.invalidateAll();    when(enrichmentAdapter.enrich(cacheKey1)).thenReturn(null);    genericEnrichmentBolt.execute(tuple);    error = new MetronError().withErrorType(Constants.ErrorType.ENRICHMENT_ERROR).withErrorFields(new HashSet<String>() {        {            add("field1");        }    }).addRawMessage(new JSONObject() {        {            put("field1", "value1");            put("field2", "value2");            put("source.type", "test");        }    }).withThrowable(new Exception("[Metron] Could not enrich string: value1"));    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), argThat(new MetronErrorJSONMatcher(error.getJSONObject())));}
0
protected void initializeStellar()
{}
0
private static List<byte[]> getInputMessages(String path)
{    try {        List<byte[]> ret = TestUtils.readSampleData(path);        {                        Map<String, Object> sansDestinationIp = JSONUtils.INSTANCE.load(new String(ret.get(ret.size() - 1), StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER);            sansDestinationIp.remove(Constants.Fields.DST_ADDR.getName());            ret.add(JSONUtils.INSTANCE.toJSONPretty(sansDestinationIp));        }        return ret;    } catch (IOException ioe) {        return null;    }}
0
public static void setupOnce() throws ParseException
{    String baseDir = UnitTestHelper.findDir(new File("../metron-enrichment-common"), "GeoLite");    geoHdfsFile = new File(new File(baseDir), "GeoLite2-City.mmdb.gz");    asnHdfsFile = new File(new File(baseDir), "GeoLite2-ASN.tar.gz");}
0
public String getTemplatePath()
{    return "src/main/config/enrichment.properties.j2";}
0
public String fluxPath()
{    return "src/main/flux/enrichment/remote.yaml";}
0
public Properties getTopologyProperties()
{    return new Properties() {        {                        setProperty("enrichment_workers", "1");            setProperty("enrichment_acker_executors", "0");            setProperty("enrichment_topology_worker_childopts", "");            setProperty("topology_auto_credentials", "[]");            setProperty("enrichment_topology_max_spout_pending", "500");                        setProperty("kafka_security_protocol", "PLAINTEXT");            setProperty("enrichment_kafka_start", "UNCOMMITTED_EARLIEST");            setProperty("enrichment_input_topic", Constants.ENRICHMENT_TOPIC);            setProperty("enrichment_output_topic", Constants.INDEXING_TOPIC);            setProperty("enrichment_error_topic", ERROR_TOPIC);            setProperty("threatintel_error_topic", ERROR_TOPIC);                        setProperty("enrichment_hbase_provider_impl", "" + MockHBaseTableProvider.class.getName());            setProperty("enrichment_hbase_table", enrichmentsTableName);            setProperty("enrichment_hbase_cf", cf);            setProperty("enrichment_host_known_hosts", "[{\"ip\":\"10.1.128.236\", \"local\":\"YES\", \"type\":\"webserver\", \"asset_value\" : \"important\"}," + "{\"ip\":\"10.1.128.237\", \"local\":\"UNKNOWN\", \"type\":\"unknown\", \"asset_value\" : \"important\"}," + "{\"ip\":\"10.60.10.254\", \"local\":\"YES\", \"type\":\"printer\", \"asset_value\" : \"important\"}," + "{\"ip\":\"10.0.2.15\", \"local\":\"YES\", \"type\":\"printer\", \"asset_value\" : \"important\"}]");                        setProperty("threatintel_hbase_table", threatIntelTableName);            setProperty("threatintel_hbase_cf", cf);                        setProperty("unified_kafka_spout_parallelism", "1");            setProperty("unified_enrichment_parallelism", "1");            setProperty("unified_threat_intel_parallelism", "1");            setProperty("unified_kafka_writer_parallelism", "1");                        setProperty("unified_enrichment_cache_size", "1000");            setProperty("unified_threat_intel_cache_size", "1000");                        setProperty("unified_enrichment_threadpool_size", "1");            setProperty("unified_enrichment_threadpool_type", "FIXED");        }    };}
0
public void test() throws Exception
{    final Properties topologyProperties = getTopologyProperties();    final ZKServerComponent zkServerComponent = getZKServerComponent(topologyProperties);    final KafkaComponent kafkaComponent = getKafkaComponent(topologyProperties, new ArrayList<KafkaComponent.Topic>() {        {            add(new KafkaComponent.Topic(Constants.ENRICHMENT_TOPIC, 1));            add(new KafkaComponent.Topic(Constants.INDEXING_TOPIC, 1));            add(new KafkaComponent.Topic(ERROR_TOPIC, 1));        }    });    String globalConfigStr = null;    {        File globalConfig = new File(enrichmentConfigPath, "global.json");        Map<String, Object> config = JSONUtils.INSTANCE.load(globalConfig, JSONUtils.MAP_SUPPLIER);        config.put(SimpleHBaseEnrichmentFunctions.TABLE_PROVIDER_TYPE_CONF, MockHBaseTableProvider.class.getName());        config.put(SimpleHBaseEnrichmentFunctions.ACCESS_TRACKER_TYPE_CONF, "PERSISTENT_BLOOM");        config.put(PersistentBloomTrackerCreator.Config.PERSISTENT_BLOOM_TABLE, trackerHBaseTableName);        config.put(PersistentBloomTrackerCreator.Config.PERSISTENT_BLOOM_CF, cf);        config.put(GeoLiteCityDatabase.GEO_HDFS_FILE, geoHdfsFile.getAbsolutePath());        config.put(GeoLiteAsnDatabase.ASN_HDFS_FILE, asnHdfsFile.getAbsolutePath());        globalConfigStr = JSONUtils.INSTANCE.toJSON(config, true);    }    ConfigUploadComponent configUploadComponent = new ConfigUploadComponent().withTopologyProperties(topologyProperties).withGlobalConfig(globalConfigStr).withEnrichmentConfigsPath(enrichmentConfigPath);        final MockHTable trackerTable = (MockHTable) MockHBaseTableProvider.addToCache(trackerHBaseTableName, cf);    final MockHTable threatIntelTable = (MockHTable) MockHBaseTableProvider.addToCache(threatIntelTableName, cf);    EnrichmentHelper.INSTANCE.load(threatIntelTable, cf, new ArrayList<LookupKV<EnrichmentKey, EnrichmentValue>>() {        {            add(new LookupKV<>(new EnrichmentKey(MALICIOUS_IP_TYPE, "10.0.2.3"), new EnrichmentValue(new HashMap<>())));        }    });    final MockHTable enrichmentTable = (MockHTable) MockHBaseTableProvider.addToCache(enrichmentsTableName, cf);    EnrichmentHelper.INSTANCE.load(enrichmentTable, cf, new ArrayList<LookupKV<EnrichmentKey, EnrichmentValue>>() {        {            add(new LookupKV<>(new EnrichmentKey(PLAYFUL_CLASSIFICATION_TYPE, "10.0.2.3"), new EnrichmentValue(PLAYFUL_ENRICHMENT)));        }    });    FluxTopologyComponent fluxComponent = new FluxTopologyComponent.Builder().withTopologyLocation(new File(fluxPath())).withTopologyName("test").withTemplateLocation(new File(getTemplatePath())).withTopologyProperties(topologyProperties).build();        ComponentRunner runner = new ComponentRunner.Builder().withComponent("zk", zkServerComponent).withComponent("kafka", kafkaComponent).withComponent("config", configUploadComponent).withComponent("storm", fluxComponent).withMillisecondsBetweenAttempts(15000).withCustomShutdownOrder(new String[] { "storm", "config", "kafka", "zk" }).withNumRetries(10).build();    try {        runner.start();        fluxComponent.submitTopology();        kafkaComponent.writeMessages(Constants.ENRICHMENT_TOPIC, inputMessages);        ProcessorResult<Map<String, List<Map<String, Object>>>> result = runner.process(getProcessor());        Map<String, List<Map<String, Object>>> outputMessages = result.getResult();        List<Map<String, Object>> docs = outputMessages.get(Constants.INDEXING_TOPIC);        Assert.assertEquals(inputMessages.size(), docs.size());        validateAll(docs);        List<Map<String, Object>> errors = outputMessages.get(ERROR_TOPIC);        Assert.assertEquals(inputMessages.size(), errors.size());        validateErrors(errors);    } finally {        runner.stop();    }}
0
public void dumpParsedMessages(List<Map<String, Object>> outputMessages, StringBuffer buffer)
{    for (Map<String, Object> map : outputMessages) {        for (String json : map.keySet()) {            buffer.append(json).append("\n");        }    }}
0
public static void validateAll(List<Map<String, Object>> docs)
{    for (Map<String, Object> doc : docs) {        baseValidation(doc);        hostEnrichmentValidation(doc);        geoEnrichmentValidation(doc);        threatIntelValidation(doc);        simpleEnrichmentValidation(doc);    }}
0
protected void validateErrors(List<Map<String, Object>> errors)
{    for (Map<String, Object> error : errors) {        Assert.assertTrue(error.get(Constants.ErrorFields.MESSAGE.getName()).toString(), error.get(Constants.ErrorFields.MESSAGE.getName()).toString().contains("/ by zero"));        Assert.assertTrue(error.get(Constants.ErrorFields.EXCEPTION.getName()).toString().contains("/ by zero"));        Assert.assertEquals(Constants.ErrorType.ENRICHMENT_ERROR.getType(), error.get(Constants.ErrorFields.ERROR_TYPE.getName()));        Assert.assertEquals("{\"error_test\":{},\"source.type\":\"test\"}", error.get(Constants.ErrorFields.RAW_MESSAGE.getName()));    }}
0
public static void baseValidation(Map<String, Object> jsonDoc)
{    assertEnrichmentsExists("threatintels.", setOf("hbaseThreatIntel"), jsonDoc.keySet());    assertEnrichmentsExists("enrichments.", setOf("geo", "host", "hbaseEnrichment"), jsonDoc.keySet());        for (Map.Entry<String, Object> kv : jsonDoc.entrySet()) {        String actual = Objects.toString(kv.getValue(), "");        Assert.assertTrue(String.format("Value of '%s' is empty: '%s'", kv.getKey(), actual), StringUtils.isNotEmpty(actual));    }        Assert.assertNotNull(jsonDoc.get(SRC_IP));    Assert.assertNotNull(jsonDoc.get("ALL_CAPS"));    Assert.assertNotNull(jsonDoc.get("map.blah"));    Assert.assertNull(jsonDoc.get("map"));    Assert.assertNotNull(jsonDoc.get("one"));    Assert.assertEquals(1, jsonDoc.get("one"));    Assert.assertEquals(1, jsonDoc.get("map.blah"));    Assert.assertNotNull(jsonDoc.get("foo"));    Assert.assertNotNull(jsonDoc.get("alt_src_type"));    Assert.assertEquals("test", jsonDoc.get("alt_src_type"));    Assert.assertEquals("TEST", jsonDoc.get("ALL_CAPS"));    Assert.assertNotNull(jsonDoc.get("bar"));    Assert.assertEquals("TEST", jsonDoc.get("bar"));}
0
public boolean apply(EvaluationPayload payload)
{    return _predicate.apply(payload);}
0
public boolean apply(@Nullable EvaluationPayload evaluationPayload)
{    return evaluationPayload.indexedDoc.getOrDefault("enrichments.host." + evaluationPayload.key + ".known_info.local", "").equals("YES");}
0
public boolean apply(@Nullable EvaluationPayload evaluationPayload)
{    return evaluationPayload.indexedDoc.getOrDefault("enrichments.host." + evaluationPayload.key + ".known_info.local", "").equals("UNKNOWN");}
0
public boolean apply(@Nullable EvaluationPayload evaluationPayload)
{    return evaluationPayload.indexedDoc.getOrDefault("enrichments.host." + evaluationPayload.key + ".known_info.asset_value", "").equals("important");}
0
public boolean apply(@Nullable EvaluationPayload evaluationPayload)
{    return evaluationPayload.indexedDoc.getOrDefault("enrichments.host." + evaluationPayload.key + ".known_info.type", "").equals("printer");}
0
public boolean apply(@Nullable EvaluationPayload evaluationPayload)
{    return evaluationPayload.indexedDoc.getOrDefault("enrichments.host." + evaluationPayload.key + ".known_info.type", "").equals("webserver");}
0
public boolean apply(@Nullable EvaluationPayload evaluationPayload)
{    return evaluationPayload.indexedDoc.getOrDefault("enrichments.host." + evaluationPayload.key + ".known_info.type", "").equals("unknown");}
0
private static void assertEnrichmentsExists(String topLevel, Set<String> expectedEnrichments, Set<String> keys)
{    for (String key : keys) {        if (key.startsWith(topLevel)) {            String secondLevel = Iterables.get(Splitter.on(".").split(key), 1);            String message = "Found an enrichment/threat intel (" + secondLevel + ") that I didn't expect (expected enrichments :" + Joiner.on(",").join(expectedEnrichments) + "), but it was not there.  If you've created a new" + " enrichment, then please add a validation method to this unit test.  Otherwise, it's a solid error" + " and should be investigated.";            Assert.assertTrue(message, expectedEnrichments.contains(secondLevel));        }    }}
0
private static void simpleEnrichmentValidation(Map<String, Object> indexedDoc)
{    if (indexedDoc.getOrDefault(SRC_IP, "").equals("10.0.2.3") || indexedDoc.getOrDefault(DST_IP, "").equals("10.0.2.3")) {        Assert.assertTrue(keyPatternExists("enrichments.hbaseEnrichment", indexedDoc));        if (indexedDoc.getOrDefault(SRC_IP, "").equals("10.0.2.3")) {            Assert.assertEquals(indexedDoc.get("enrichments.hbaseEnrichment." + SRC_IP + "." + PLAYFUL_CLASSIFICATION_TYPE + ".orientation"), PLAYFUL_ENRICHMENT.get("orientation"));            Assert.assertEquals(indexedDoc.get("src_classification.orientation"), PLAYFUL_ENRICHMENT.get("orientation"));            Assert.assertEquals(indexedDoc.get("is_src_malicious"), true);        } else if (indexedDoc.getOrDefault(DST_IP, "").equals("10.0.2.3")) {            Assert.assertEquals(indexedDoc.get("enrichments.hbaseEnrichment." + DST_IP + "." + PLAYFUL_CLASSIFICATION_TYPE + ".orientation"), PLAYFUL_ENRICHMENT.get("orientation"));            Assert.assertEquals(indexedDoc.get("dst_classification.orientation"), PLAYFUL_ENRICHMENT.get("orientation"));        }        if (!indexedDoc.getOrDefault(SRC_IP, "").equals("10.0.2.3")) {            Assert.assertEquals(indexedDoc.get("is_src_malicious"), false);        }    } else {        Assert.assertEquals(indexedDoc.get("is_src_malicious"), false);    }}
0
private static void threatIntelValidation(Map<String, Object> indexedDoc)
{    if (indexedDoc.getOrDefault(SRC_IP, "").equals("10.0.2.3") || indexedDoc.getOrDefault(DST_IP, "").equals("10.0.2.3")) {                Assert.assertTrue(keyPatternExists("threatintels.", indexedDoc));        Assert.assertEquals(indexedDoc.getOrDefault("is_alert", ""), "true");                Assert.assertTrue(indexedDoc.containsKey(ThreatIntelUtils.THREAT_TRIAGE_SCORE_KEY));        Double score = (Double) indexedDoc.get(ThreatIntelUtils.THREAT_TRIAGE_SCORE_KEY);        Assert.assertEquals(score, 10d, 1e-7);                Joiner joiner = Joiner.on(".");        Stream.of(joiner.join(ThreatIntelUtils.THREAT_TRIAGE_RULES_KEY, 0, ThreatIntelUtils.THREAT_TRIAGE_RULE_NAME), joiner.join(ThreatIntelUtils.THREAT_TRIAGE_RULES_KEY, 0, ThreatIntelUtils.THREAT_TRIAGE_RULE_COMMENT), joiner.join(ThreatIntelUtils.THREAT_TRIAGE_RULES_KEY, 0, ThreatIntelUtils.THREAT_TRIAGE_RULE_REASON), joiner.join(ThreatIntelUtils.THREAT_TRIAGE_RULES_KEY, 0, ThreatIntelUtils.THREAT_TRIAGE_RULE_SCORE)).forEach(key -> Assert.assertTrue(String.format("Missing expected key: '%s'", key), indexedDoc.containsKey(key)));    } else {                Assert.assertNull(indexedDoc.get("is_alert"));        Assert.assertFalse(keyPatternExists("threatintels.", indexedDoc));    }        if (keyPatternExists("threatintels.hbaseThreatIntel.", indexedDoc)) {        if (indexedDoc.getOrDefault(SRC_IP, "").equals("10.0.2.3")) {            Assert.assertEquals(indexedDoc.get("threatintels.hbaseThreatIntel." + SRC_IP + "." + MALICIOUS_IP_TYPE), "alert");        } else if (indexedDoc.getOrDefault(DST_IP, "").equals("10.0.2.3")) {            Assert.assertEquals(indexedDoc.get("threatintels.hbaseThreatIntel." + DST_IP + "." + MALICIOUS_IP_TYPE), "alert");        } else {            Assert.fail("There was a threat intels that I did not expect: " + indexedDoc);        }    }}
0
private static void geoEnrichmentValidation(Map<String, Object> indexedDoc)
{        if (indexedDoc.containsKey("enrichments.geo." + DST_IP + ".location_point")) {        Assert.assertEquals(DEFAULT_LOCATION_POINT, indexedDoc.get("enrichments.geo." + DST_IP + ".location_point"));        Assert.assertEquals(DEFAULT_LONGITUDE, indexedDoc.get("enrichments.geo." + DST_IP + ".longitude"));        Assert.assertEquals(DEFAULT_CITY, indexedDoc.get("enrichments.geo." + DST_IP + ".city"));        Assert.assertEquals(DEFAULT_LATITUDE, indexedDoc.get("enrichments.geo." + DST_IP + ".latitude"));        Assert.assertEquals(DEFAULT_COUNTRY, indexedDoc.get("enrichments.geo." + DST_IP + ".country"));        Assert.assertEquals(DEFAULT_DMACODE, indexedDoc.get("enrichments.geo." + DST_IP + ".dmaCode"));        Assert.assertEquals(DEFAULT_POSTAL_CODE, indexedDoc.get("enrichments.geo." + DST_IP + ".postalCode"));    }    if (indexedDoc.containsKey("enrichments.geo." + SRC_IP + ".location_point")) {        Assert.assertEquals(DEFAULT_LOCATION_POINT, indexedDoc.get("enrichments.geo." + SRC_IP + ".location_point"));        Assert.assertEquals(DEFAULT_LONGITUDE, indexedDoc.get("enrichments.geo." + SRC_IP + ".longitude"));        Assert.assertEquals(DEFAULT_CITY, indexedDoc.get("enrichments.geo." + SRC_IP + ".city"));        Assert.assertEquals(DEFAULT_LATITUDE, indexedDoc.get("enrichments.geo." + SRC_IP + ".latitude"));        Assert.assertEquals(DEFAULT_COUNTRY, indexedDoc.get("enrichments.geo." + SRC_IP + ".country"));        Assert.assertEquals(DEFAULT_DMACODE, indexedDoc.get("enrichments.geo." + SRC_IP + ".dmaCode"));        Assert.assertEquals(DEFAULT_POSTAL_CODE, indexedDoc.get("enrichments.geo." + SRC_IP + ".postalCode"));    }}
0
private static void hostEnrichmentValidation(Map<String, Object> indexedDoc)
{    boolean enriched = false;        {        Set<String> ips = setOf("10.0.2.15", "10.60.10.254");        if (ips.contains(indexedDoc.get(SRC_IP))) {                        Assert.assertTrue(Predicates.and(HostEnrichments.LOCAL_LOCATION, HostEnrichments.IMPORTANT, HostEnrichments.PRINTER_TYPE).apply(new EvaluationPayload(indexedDoc, SRC_IP)));            enriched = true;        }        if (ips.contains(indexedDoc.get(DST_IP))) {            boolean isEnriched = Predicates.and(HostEnrichments.LOCAL_LOCATION, HostEnrichments.IMPORTANT, HostEnrichments.PRINTER_TYPE).apply(new EvaluationPayload(indexedDoc, DST_IP));            Assert.assertTrue(isEnriched);            enriched = true;        }    }        {        Set<String> ips = setOf("10.1.128.236");        if (ips.contains(indexedDoc.get(SRC_IP))) {                        Assert.assertTrue(Predicates.and(HostEnrichments.LOCAL_LOCATION, HostEnrichments.IMPORTANT, HostEnrichments.WEBSERVER_TYPE).apply(new EvaluationPayload(indexedDoc, SRC_IP)));            enriched = true;        }        if (ips.contains(indexedDoc.get(DST_IP))) {            boolean isEnriched = Predicates.and(HostEnrichments.LOCAL_LOCATION, HostEnrichments.IMPORTANT, HostEnrichments.WEBSERVER_TYPE).apply(new EvaluationPayload(indexedDoc, DST_IP));            Assert.assertTrue(isEnriched);            enriched = true;        }    }    if (!enriched) {        Assert.assertFalse(keyPatternExists("enrichments.host", indexedDoc));    }}
0
private static boolean keyPatternExists(String pattern, Map<String, Object> indexedObj)
{    for (String k : indexedObj.keySet()) {        if (k.startsWith(pattern)) {            return true;        }    }    return false;}
0
private static Set<String> setOf(String... items)
{    Set<String> ret = new HashSet<>();    for (String item : items) {        ret.add(item);    }    return ret;}
0
private static List<Map<String, Object>> loadMessages(List<byte[]> outputMessages)
{    List<Map<String, Object>> tmp = new ArrayList<>();    Iterables.addAll(tmp, Iterables.transform(outputMessages, message -> {        try {            return new HashMap<>(JSONUtils.INSTANCE.load(new String(message, StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER));        } catch (Exception ex) {            throw new IllegalStateException(ex);        }    }));    return tmp;}
0
private KafkaProcessor<Map<String, List<Map<String, Object>>>> getProcessor()
{    return new KafkaProcessor<>().withKafkaComponentName("kafka").withReadTopic(Constants.INDEXING_TOPIC).withErrorTopic(ERROR_TOPIC).withValidateReadMessages(new Function<KafkaMessageSet, Boolean>() {        @Nullable        @Override        public Boolean apply(@Nullable KafkaMessageSet messageSet) {            return (messageSet.getMessages().size() == inputMessages.size()) && (messageSet.getErrors().size() == inputMessages.size());        }    }).withProvideResult(new Function<KafkaMessageSet, Map<String, List<Map<String, Object>>>>() {        @Nullable        @Override        public Map<String, List<Map<String, Object>>> apply(@Nullable KafkaMessageSet messageSet) {            return new HashMap<String, List<Map<String, Object>>>() {                {                    put(Constants.INDEXING_TOPIC, loadMessages(messageSet.getMessages()));                    put(ERROR_TOPIC, loadMessages(messageSet.getErrors()));                }            };        }    });}
0
public Boolean apply(@Nullable KafkaMessageSet messageSet)
{    return (messageSet.getMessages().size() == inputMessages.size()) && (messageSet.getErrors().size() == inputMessages.size());}
0
public Map<String, List<Map<String, Object>>> apply(@Nullable KafkaMessageSet messageSet)
{    return new HashMap<String, List<Map<String, Object>>>() {        {            put(Constants.INDEXING_TOPIC, loadMessages(messageSet.getMessages()));            put(ERROR_TOPIC, loadMessages(messageSet.getErrors()));        }    };}
0
public void addMutation(byte[] rowKey, ColumnList cols, Durability durability)
{    if (cols.hasColumns()) {        Put put = createPut(rowKey, cols, durability);        mutations.add(put);    }    if (cols.hasCounters()) {        Increment inc = createIncrement(rowKey, cols, durability);        mutations.add(inc);    }    if (mutations.isEmpty()) {        mutations.add(new Put(rowKey));    }}
0
public void addMutation(byte[] rowKey, ColumnList cols, Durability durability, Long timeToLiveMillis)
{    if (cols.hasColumns()) {        Put put = createPut(rowKey, cols, durability, timeToLiveMillis);        mutations.add(put);    }    if (cols.hasCounters()) {        Increment inc = createIncrement(rowKey, cols, durability, timeToLiveMillis);        mutations.add(inc);    }    if (mutations.isEmpty()) {        Put put = new Put(rowKey);        put.setTTL(timeToLiveMillis);        mutations.add(put);    }}
0
public void clearMutations()
{    mutations.clear();}
0
public int mutate()
{    int mutationCount = mutations.size();    Object[] result = new Object[mutationCount];    try {        table.batch(mutations, result);        mutations.clear();    } catch (Exception e) {        String msg = String.format("'%d' HBase write(s) failed on table '%s'", size(mutations), tableName(table));                throw new RuntimeException(msg, e);    }    return mutationCount;}
1
public void addGet(byte[] rowKey, HBaseProjectionCriteria criteria)
{    Get get = new Get(rowKey);    if (criteria != null) {        criteria.getColumnFamilies().forEach(cf -> get.addFamily(cf));        criteria.getColumns().forEach(col -> get.addColumn(col.getColumnFamily(), col.getQualifier()));    }        this.gets.add(get);}
0
public void clearGets()
{    gets.clear();}
0
public Result[] getAll()
{    try {        Result[] results = table.get(gets);        gets.clear();        return results;    } catch (Exception e) {        String msg = String.format("'%d' HBase read(s) failed on table '%s'", size(gets), tableName(table));                throw new RuntimeException(msg, e);    }}
1
public void close() throws IOException
{    if (table != null) {        table.close();    }}
0
private Put createPut(byte[] rowKey, ColumnList cols, Durability durability)
{    Put put = new Put(rowKey);    put.setDurability(durability);    addColumns(cols, put);    return put;}
0
private Put createPut(byte[] rowKey, ColumnList cols, Durability durability, long timeToLiveMillis)
{    Put put = new Put(rowKey);    put.setDurability(durability);    put.setTTL(timeToLiveMillis);    addColumns(cols, put);    return put;}
0
private void addColumns(ColumnList cols, Put put)
{    for (ColumnList.Column col : cols.getColumns()) {        if (col.getTs() > 0) {            put.add(col.getFamily(), col.getQualifier(), col.getTs(), col.getValue());        } else {            put.add(col.getFamily(), col.getQualifier(), col.getValue());        }    }}
0
private Increment createIncrement(byte[] rowKey, ColumnList cols, Durability durability)
{    Increment inc = new Increment(rowKey);    inc.setDurability(durability);    cols.getCounters().forEach(cnt -> inc.addColumn(cnt.getFamily(), cnt.getQualifier(), cnt.getIncrement()));    return inc;}
0
private Increment createIncrement(byte[] rowKey, ColumnList cols, Durability durability, long timeToLiveMillis)
{    Increment inc = new Increment(rowKey);    inc.setDurability(durability);    inc.setTTL(timeToLiveMillis);    cols.getCounters().forEach(cnt -> inc.addColumn(cnt.getFamily(), cnt.getQualifier(), cnt.getIncrement()));    return inc;}
0
private static String tableName(Table table)
{    String tableName = "null";    if (table != null) {        if (table.getName() != null) {            tableName = table.getName().getNameAsString();        }    }    return tableName;}
0
public void put(String rowKey, String columnFamily, String columnQualifier, String value) throws IOException
{    Put put = new Put(Bytes.toBytes(rowKey));    put.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(columnQualifier), Bytes.toBytes(value));    table.put(put);}
0
public List<String> readRecords() throws IOException
{    Scan scan = new Scan();    ResultScanner scanner = table.getScanner(scan);    List<String> rows = new ArrayList<>();    for (Result r = scanner.next(); r != null; r = scanner.next()) {        rows.add(Bytes.toString(r.getRow()));    }    return rows;}
0
public byte[] getFamily()
{    return family;}
0
public byte[] getQualifier()
{    return qualifier;}
0
public byte[] getValue()
{    return value;}
0
public long getTs()
{    return ts;}
0
public long getIncrement()
{    return incr;}
0
private ArrayList<Column> columns()
{    if (this.columns == null) {        this.columns = new ArrayList<>();    }    return this.columns;}
0
private ArrayList<Counter> counters()
{    if (this.counters == null) {        this.counters = new ArrayList<>();    }    return this.counters;}
0
public ColumnList addColumn(byte[] family, byte[] qualifier, long ts, byte[] value)
{    columns().add(new Column(family, qualifier, ts, value));    return this;}
0
public ColumnList addColumn(byte[] family, byte[] qualifier, byte[] value)
{    columns().add(new Column(family, qualifier, -1, value));    return this;}
0
public ColumnList addColumn(IColumn column)
{    return this.addColumn(column.family(), column.qualifier(), column.timestamp(), column.value());}
0
public ColumnList addCounter(byte[] family, byte[] qualifier, long incr)
{    counters().add(new Counter(family, qualifier, incr));    return this;}
0
public ColumnList addCounter(ICounter counter)
{    return this.addCounter(counter.family(), counter.qualifier(), counter.increment());}
0
public boolean hasColumns()
{    return this.columns != null;}
0
public boolean hasCounters()
{    return this.counters != null;}
0
public List<Column> getColumns()
{    return this.columns;}
0
public List<Counter> getCounters()
{    return this.counters;}
0
public byte[] getColumnFamily()
{    return columnFamily;}
0
public byte[] getQualifier()
{    return qualifier;}
0
public HBaseProjectionCriteria addColumnFamily(String columnFamily)
{    this.columnFamilies.add(columnFamily.getBytes(StandardCharsets.UTF_8));    return this;}
0
public HBaseProjectionCriteria addColumn(ColumnMetaData column)
{    this.columns.add(column);    return this;}
0
public List<ColumnMetaData> getColumns()
{    return columns;}
0
public List<byte[]> getColumnFamilies()
{    return columnFamilies;}
0
public Connection getUnderlying() throws IOException
{    if (conn == null || conn.isClosed()) {        conn = ConnectionFactory.createConnection(config);    }    return conn;}
0
public Table getTable(Configuration config, String tableName) throws IOException
{    return getConnection(config).getTable(TableName.valueOf(tableName));}
0
private Connection getConnection(Configuration config) throws IOException
{    ThreadLocal<RetryingConnection> threadLocal = connMap.computeIfAbsent(config, c -> ThreadLocal.withInitial(() -> new RetryingConnection(config)));    return threadLocal.get().getUnderlying();}
0
public String getTableName()
{    return tableName;}
0
public TableConfig withConnectorImpl(String impl)
{    connectorImpl = impl;    return this;}
0
public TableConfig withTable(String table)
{    this.tableName = table;    return this;}
0
public TableConfig withBatch(Boolean isBatch)
{    this.batch = isBatch;    return this;}
0
public String getConnectorImpl()
{    return connectorImpl;}
0
public boolean isBatch()
{    return batch;}
0
public void setBatch(boolean batch)
{    this.batch = batch;}
0
public void setWriteBufferSize(long writeBufferSize)
{    this.writeBufferSize = writeBufferSize;}
0
public long getWriteBufferSize()
{    return writeBufferSize;}
0
public Set<String> getColumnFamilies()
{    return this.columnFamilies.keySet();}
0
 static TableProvider create(String impl, Supplier<TableProvider> defaultSupplier) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException
{    if (impl == null) {        return defaultSupplier.get();    }    Class<? extends TableProvider> clazz = (Class<? extends TableProvider>) Class.forName(impl);    return clazz.getConstructor().newInstance();}
0
public static void startHBase() throws Exception
{    Configuration config = HBaseConfiguration.create();    config.set("hbase.master.hostname", "localhost");    config.set("hbase.regionserver.hostname", "localhost");    util = new HBaseTestingUtility(config);    util.startMiniCluster();    admin = util.getHBaseAdmin();        table = util.createTable(Bytes.toBytes(tableName), cf);    util.waitTableEnabled(table.getName());        client = new HBaseClient((c, t) -> table, table.getConfiguration(), tableName);}
0
public static void stopHBase() throws Exception
{    util.deleteTable(tableName);    util.shutdownMiniCluster();    util.cleanupTestDir();}
0
public void clearTable() throws Exception
{    List<Delete> deletions = new ArrayList<>();    for (Result r : table.getScanner(new Scan())) {        deletions.add(new Delete(r.getRow()));    }    table.delete(deletions);}
0
public void setupTuples() throws Exception
{    rowKey1 = Bytes.toBytes("rowKey1");    cols1 = new ColumnList();    cols1.addColumn(cf, column, value1);    rowKey2 = Bytes.toBytes("rowKey2");    cols2 = new ColumnList();    cols2.addColumn(cf, column, value2);}
0
public void testWrite() throws Exception
{        client.addMutation(rowKey1, cols1, Durability.SYNC_WAL);    client.mutate();    HBaseProjectionCriteria criteria = new HBaseProjectionCriteria();    criteria.addColumnFamily(Bytes.toString(cf));        client.addGet(rowKey1, criteria);    Result[] results = client.getAll();    Assert.assertEquals(1, results.length);        assertEquals(1, results.length);    assertArrayEquals(rowKey1, results[0].getRow());    assertArrayEquals(value1, results[0].getValue(cf, column));}
0
public void testBatchWrite() throws Exception
{        client.addMutation(rowKey1, cols1, Durability.SYNC_WAL);    client.addMutation(rowKey2, cols2, Durability.SYNC_WAL);    int count = client.mutate();        Assert.assertEquals(2, count);    HBaseProjectionCriteria criteria = new HBaseProjectionCriteria();    criteria.addColumnFamily(Bytes.toString(cf));        client.addGet(rowKey1, criteria);    client.addGet(rowKey2, criteria);    Result[] results = client.getAll();        assertEquals(2, results.length);    assertArrayEquals(rowKey1, results[0].getRow());    assertArrayEquals(value1, results[0].getValue(cf, column));    assertArrayEquals(rowKey1, results[0].getRow());    assertArrayEquals(value2, results[1].getValue(cf, column));}
0
public void testEmptyBatch() throws Exception
{        int count = client.mutate();    Assert.assertEquals(0, count);    HBaseProjectionCriteria criteria = new HBaseProjectionCriteria();    criteria.addColumnFamily(Bytes.toString(cf));        client.addGet(rowKey1, criteria);    client.addGet(rowKey2, criteria);    Result[] results = client.getAll();        assertEquals(2, results.length);    for (Result result : results) {        Assert.assertTrue(result.isEmpty());    }}
0
public void testWriteWithTimeToLive() throws Exception
{    long timeToLive = TimeUnit.DAYS.toMillis(30);        client.addMutation(rowKey1, cols1, Durability.SYNC_WAL, timeToLive);    client.addMutation(rowKey2, cols2, Durability.SYNC_WAL, timeToLive);    client.mutate();    HBaseProjectionCriteria criteria = new HBaseProjectionCriteria();    criteria.addColumnFamily(Bytes.toString(cf));        client.addGet(rowKey1, criteria);    client.addGet(rowKey2, criteria);    Result[] results = client.getAll();        assertEquals(2, results.length);    assertArrayEquals(rowKey1, results[0].getRow());    assertArrayEquals(value1, results[0].getValue(cf, column));    assertArrayEquals(rowKey1, results[0].getRow());    assertArrayEquals(value2, results[1].getValue(cf, column));}
0
public void testExpiredRows() throws Exception
{    long timeToLive = TimeUnit.MILLISECONDS.toMillis(1);        client.addMutation(rowKey1, cols1, Durability.SYNC_WAL, timeToLive);    client.addMutation(rowKey2, cols2, Durability.SYNC_WAL, timeToLive);    client.mutate();    HBaseProjectionCriteria criteria = new HBaseProjectionCriteria();    criteria.addColumnFamily(Bytes.toString(cf));        Thread.sleep(TimeUnit.SECONDS.toMillis(2));        client.addGet(rowKey1, criteria);    client.addGet(rowKey2, criteria);    Result[] results = client.getAll();        assertEquals(2, results.length);    assertTrue(results[0].isEmpty());    assertTrue(results[1].isEmpty());}
0
public void testUnableToOpenConnection() throws IOException
{        TableProvider tableProvider = mock(TableProvider.class);    when(tableProvider.getTable(any(), any())).thenThrow(new IllegalArgumentException("test exception"));    client = new HBaseClient(tableProvider, HBaseConfiguration.create(), tableName);}
0
public void testFailureToMutate() throws IOException, InterruptedException
{        Table table = mock(Table.class);    doThrow(new IOException("exception!")).when(table).batch(any(), any());    TableProvider tableProvider = mock(TableProvider.class);    when(tableProvider.getTable(any(), any())).thenReturn(table);    client = new HBaseClient(tableProvider, HBaseConfiguration.create(), tableName);    client.addMutation(rowKey1, cols1, Durability.SYNC_WAL);    client.mutate();}
0
public void testFailureToGetAll() throws IOException
{        Table table = mock(Table.class);    when(table.get(anyListOf(Get.class))).thenThrow(new IOException("exception!"));    TableProvider tableProvider = mock(TableProvider.class);    when(tableProvider.getTable(any(), any())).thenReturn(table);    HBaseProjectionCriteria criteria = new HBaseProjectionCriteria();    criteria.addColumnFamily(Bytes.toString(cf));    client = new HBaseClient(tableProvider, HBaseConfiguration.create(), tableName);    client.addGet(rowKey1, criteria);    client.addGet(rowKey2, criteria);    client.getAll();}
0
public Table getTable(Configuration configuration, String tableName) throws IOException
{    Table ret = _cache.get(tableName);    return ret;}
0
public static Table getFromCache(String tableName)
{    return _cache.get(tableName);}
0
public static Table addToCache(String tableName, String... columnFamilies)
{    MockHTable ret = new MockHTable(tableName, columnFamilies);    _cache.put(tableName, ret);    return ret;}
0
public static void clear()
{    _cache.clear();}
0
private static List<KeyValue> toKeyValue(byte[] row, NavigableMap<byte[], NavigableMap<byte[], NavigableMap<Long, byte[]>>> rowdata, int maxVersions)
{    return toKeyValue(row, rowdata, 0, Long.MAX_VALUE, maxVersions);}
0
private static List<KeyValue> toKeyValue(byte[] row, NavigableMap<byte[], NavigableMap<byte[], NavigableMap<Long, byte[]>>> rowdata, long timestampStart, long timestampEnd, int maxVersions)
{    List<KeyValue> ret = new ArrayList<KeyValue>();    for (byte[] family : rowdata.keySet()) for (byte[] qualifier : rowdata.get(family).keySet()) {        int versionsAdded = 0;        for (Map.Entry<Long, byte[]> tsToVal : rowdata.get(family).get(qualifier).descendingMap().entrySet()) {            if (versionsAdded++ == maxVersions)                break;            Long timestamp = tsToVal.getKey();            if (timestamp < timestampStart)                continue;            if (timestamp > timestampEnd)                continue;            byte[] value = tsToVal.getValue();            ret.add(new KeyValue(row, family, qualifier, timestamp, value));        }    }    return ret;}
0
public int size()
{    return data.size();}
0
public void addColumnFamily(String columnFamily)
{    this.columnFamilies.add(columnFamily);    descriptors = new HColumnDescriptor[columnFamilies.size()];    int i = 0;    for (String cf : columnFamilies) {        descriptors[i++] = new HColumnDescriptor(cf);    }}
0
public byte[] getTableName()
{    return Bytes.toBytes(tableName);}
0
public TableName getName()
{    return TableName.valueOf(tableName);}
0
public Configuration getConfiguration()
{    return HBaseConfiguration.create();}
0
public HTableDescriptor getTableDescriptor() throws IOException
{    HTableDescriptor ret = new HTableDescriptor(tableName);    for (HColumnDescriptor c : descriptors) {        ret.addFamily(c);    }    return ret;}
0
public boolean exists(Get get) throws IOException
{    if (get.getFamilyMap() == null || get.getFamilyMap().size() == 0) {        return data.containsKey(get.getRow());    } else {        byte[] row = get.getRow();        if (!data.containsKey(row)) {            return false;        }        for (byte[] family : get.getFamilyMap().keySet()) {            if (!data.get(row).containsKey(family)) {                return false;            } else {                return true;            }        }        return true;    }}
0
public boolean[] existsAll(List<Get> gets) throws IOException
{    boolean[] ret = new boolean[gets.size()];    int i = 0;    for (boolean b : exists(gets)) {        ret[i++] = b;    }    return ret;}
0
public Boolean[] exists(List<Get> list) throws IOException
{    Boolean[] ret = new Boolean[list.size()];    int i = 0;    for (Get g : list) {        ret[i++] = exists(g);    }    return ret;}
0
public void batch(List<? extends Row> list, Object[] objects) throws IOException, InterruptedException
{    Object[] results = batch(list);    System.arraycopy(results, 0, objects, 0, results.length);}
0
public Object[] batch(List<? extends Row> actions) throws IOException, InterruptedException
{    List<Result> results = new ArrayList<Result>();    for (Row r : actions) {        if (r instanceof Delete) {            delete((Delete) r);            continue;        }        if (r instanceof Put) {            put((Put) r);            continue;        }        if (r instanceof Get) {            results.add(get((Get) r));        }    }    return results.toArray();}
0
public void batchCallback(List<? extends Row> list, Object[] objects, Batch.Callback<R> callback) throws IOException, InterruptedException
{    throw new UnsupportedOperationException();}
0
public Object[] batchCallback(List<? extends Row> list, Batch.Callback<R> callback) throws IOException, InterruptedException
{    throw new UnsupportedOperationException();}
0
public Result get(Get get) throws IOException
{    if (!data.containsKey(get.getRow()))        return new Result();    byte[] row = get.getRow();    List<KeyValue> kvs = new ArrayList<KeyValue>();    if (!get.hasFamilies()) {        kvs = toKeyValue(row, data.get(row), get.getMaxVersions());    } else {        for (byte[] family : get.getFamilyMap().keySet()) {            if (data.get(row).get(family) == null)                continue;            NavigableSet<byte[]> qualifiers = get.getFamilyMap().get(family);            if (qualifiers == null || qualifiers.isEmpty())                qualifiers = data.get(row).get(family).navigableKeySet();            for (byte[] qualifier : qualifiers) {                if (qualifier == null)                    qualifier = "".getBytes(StandardCharsets.UTF_8);                if (!data.get(row).containsKey(family) || !data.get(row).get(family).containsKey(qualifier) || data.get(row).get(family).get(qualifier).isEmpty())                    continue;                Map.Entry<Long, byte[]> timestampAndValue = data.get(row).get(family).get(qualifier).lastEntry();                kvs.add(new KeyValue(row, family, qualifier, timestampAndValue.getKey(), timestampAndValue.getValue()));            }        }    }    Filter filter = get.getFilter();    if (filter != null) {        filter.reset();        List<KeyValue> nkvs = new ArrayList<KeyValue>(kvs.size());        for (KeyValue kv : kvs) {            if (filter.filterAllRemaining()) {                break;            }            if (filter.filterRowKey(kv.getBuffer(), kv.getRowOffset(), kv.getRowLength())) {                continue;            }            if (filter.filterKeyValue(kv) == Filter.ReturnCode.INCLUDE) {                nkvs.add(kv);            }                }        if (filter.hasFilterRow()) {            filter.filterRow();        }        kvs = nkvs;    }    return new Result(kvs);}
0
public Result[] get(List<Get> list) throws IOException
{    Result[] ret = new Result[list.size()];    int i = 0;    for (Get g : list) {        ret[i++] = get(g);    }    return ret;}
0
public Result getRowOrBefore(byte[] bytes, byte[] bytes1) throws IOException
{    throw new UnsupportedOperationException();}
0
public ResultScanner getScanner(Scan scan) throws IOException
{    final List<Result> ret = new ArrayList<Result>();    byte[] st = scan.getStartRow();    byte[] sp = scan.getStopRow();    Filter filter = scan.getFilter();    for (byte[] row : data.keySet()) {                if (st != null && st.length > 0 && Bytes.BYTES_COMPARATOR.compare(st, row) != 0) {                        if (st != null && st.length > 0 && Bytes.BYTES_COMPARATOR.compare(st, row) > 0)                continue;                        if (sp != null && sp.length > 0 && Bytes.BYTES_COMPARATOR.compare(sp, row) <= 0)                break;        }        List<KeyValue> kvs = null;        if (!scan.hasFamilies()) {            kvs = toKeyValue(row, data.get(row), scan.getTimeRange().getMin(), scan.getTimeRange().getMax(), scan.getMaxVersions());        } else {            kvs = new ArrayList<KeyValue>();            for (byte[] family : scan.getFamilyMap().keySet()) {                if (data.get(row).get(family) == null)                    continue;                NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(family);                if (qualifiers == null || qualifiers.isEmpty())                    qualifiers = data.get(row).get(family).navigableKeySet();                for (byte[] qualifier : qualifiers) {                    if (data.get(row).get(family).get(qualifier) == null)                        continue;                    for (Long timestamp : data.get(row).get(family).get(qualifier).descendingKeySet()) {                        if (timestamp < scan.getTimeRange().getMin())                            continue;                        if (timestamp > scan.getTimeRange().getMax())                            continue;                        byte[] value = data.get(row).get(family).get(qualifier).get(timestamp);                        kvs.add(new KeyValue(row, family, qualifier, timestamp, value));                        if (kvs.size() == scan.getMaxVersions()) {                            break;                        }                    }                }            }        }        if (filter != null) {            filter.reset();            List<KeyValue> nkvs = new ArrayList<KeyValue>(kvs.size());            for (KeyValue kv : kvs) {                if (filter.filterAllRemaining()) {                    break;                }                if (filter.filterRowKey(kv.getBuffer(), kv.getRowOffset(), kv.getRowLength())) {                    continue;                }                Filter.ReturnCode filterResult = filter.filterKeyValue(kv);                if (filterResult == Filter.ReturnCode.INCLUDE) {                    nkvs.add(kv);                } else if (filterResult == Filter.ReturnCode.NEXT_ROW) {                    break;                }                        }            if (filter.hasFilterRow()) {                filter.filterRow();            }            kvs = nkvs;        }        if (!kvs.isEmpty()) {            ret.add(new Result(kvs));        }    }    return new ResultScanner() {        private final Iterator<Result> iterator = ret.iterator();        @Override        public Iterator<Result> iterator() {            return iterator;        }        @Override        public Result[] next(int nbRows) throws IOException {            ArrayList<Result> resultSets = new ArrayList<Result>(nbRows);            for (int i = 0; i < nbRows; i++) {                Result next = next();                if (next != null) {                    resultSets.add(next);                } else {                    break;                }            }            return resultSets.toArray(new Result[resultSets.size()]);        }        @Override        public Result next() throws IOException {            try {                return iterator().next();            } catch (NoSuchElementException e) {                return null;            }        }        @Override        public void close() {        }    };}
0
public Iterator<Result> iterator()
{    return iterator;}
0
public Result[] next(int nbRows) throws IOException
{    ArrayList<Result> resultSets = new ArrayList<Result>(nbRows);    for (int i = 0; i < nbRows; i++) {        Result next = next();        if (next != null) {            resultSets.add(next);        } else {            break;        }    }    return resultSets.toArray(new Result[resultSets.size()]);}
0
public Result next() throws IOException
{    try {        return iterator().next();    } catch (NoSuchElementException e) {        return null;    }}
0
public void close()
{}
0
public ResultScanner getScanner(byte[] family) throws IOException
{    Scan scan = new Scan();    scan.addFamily(family);    return getScanner(scan);}
0
public ResultScanner getScanner(byte[] family, byte[] qualifier) throws IOException
{    Scan scan = new Scan();    scan.addColumn(family, qualifier);    return getScanner(scan);}
0
public List<Put> getPutLog()
{    synchronized (putLog) {        return ImmutableList.copyOf(putLog);    }}
0
public void addToPutLog(Put put)
{    synchronized (putLog) {        putLog.add(put);    }}
0
public void clear()
{    synchronized (putLog) {        putLog.clear();    }    data.clear();}
0
public void put(Put put) throws IOException
{    addToPutLog(put);    byte[] row = put.getRow();    NavigableMap<byte[], NavigableMap<byte[], NavigableMap<Long, byte[]>>> rowData = forceFind(data, row, new TreeMap<byte[], NavigableMap<byte[], NavigableMap<Long, byte[]>>>(Bytes.BYTES_COMPARATOR));    for (byte[] family : put.getFamilyMap().keySet()) {        NavigableMap<byte[], NavigableMap<Long, byte[]>> familyData = forceFind(rowData, family, new TreeMap<byte[], NavigableMap<Long, byte[]>>(Bytes.BYTES_COMPARATOR));        for (KeyValue kv : put.getFamilyMap().get(family)) {            kv.updateLatestStamp(Bytes.toBytes(System.currentTimeMillis()));            byte[] qualifier = kv.getQualifier();            NavigableMap<Long, byte[]> qualifierData = forceFind(familyData, qualifier, new TreeMap<Long, byte[]>());            qualifierData.put(kv.getTimestamp(), kv.getValue());        }    }}
0
private V forceFind(NavigableMap<K, V> map, K key, V newObject)
{    V data = map.get(key);    if (data == null) {        data = newObject;        map.put(key, data);    }    return data;}
0
public void put(List<Put> puts) throws IOException
{    for (Put put : puts) put(put);}
0
public boolean checkAndPut(byte[] bytes, byte[] bytes1, byte[] bytes2, byte[] bytes3, Put put) throws IOException
{    throw new UnsupportedOperationException();}
0
public boolean checkAndPut(byte[] row, byte[] family, byte[] qualifier, CompareFilter.CompareOp compareOp, byte[] value, Put put) throws IOException
{    return false;}
0
public void delete(Delete delete) throws IOException
{    byte[] row = delete.getRow();    if (data.containsKey(row)) {        data.remove(row);    } else {        throw new IOException();    }}
0
public void delete(List<Delete> list) throws IOException
{    throw new UnsupportedOperationException();}
0
public boolean checkAndDelete(byte[] bytes, byte[] bytes1, byte[] bytes2, byte[] bytes3, Delete delete) throws IOException
{    throw new UnsupportedOperationException();}
0
public boolean checkAndDelete(byte[] row, byte[] family, byte[] qualifier, CompareFilter.CompareOp compareOp, byte[] value, Delete delete) throws IOException
{    return false;}
0
public void mutateRow(RowMutations rowMutations) throws IOException
{    throw new UnsupportedOperationException();}
0
public Result append(Append append) throws IOException
{    throw new UnsupportedOperationException();}
0
public Result increment(Increment increment) throws IOException
{    throw new UnsupportedOperationException();}
0
public long incrementColumnValue(byte[] bytes, byte[] bytes1, byte[] bytes2, long l) throws IOException
{    throw new UnsupportedOperationException();}
0
public long incrementColumnValue(byte[] bytes, byte[] bytes1, byte[] bytes2, long l, Durability durability) throws IOException
{    throw new UnsupportedOperationException();}
0
public long incrementColumnValue(byte[] bytes, byte[] bytes1, byte[] bytes2, long l, boolean b) throws IOException
{    throw new UnsupportedOperationException();}
0
public boolean isAutoFlush()
{    return autoflush;}
0
public void flushCommits() throws IOException
{}
0
public void close() throws IOException
{}
0
public CoprocessorRpcChannel coprocessorService(byte[] bytes)
{    throw new UnsupportedOperationException();}
0
public Map<byte[], R> coprocessorService(Class<T> aClass, byte[] bytes, byte[] bytes1, Batch.Call<T, R> call) throws ServiceException, Throwable
{    throw new UnsupportedOperationException();}
0
public void coprocessorService(Class<T> aClass, byte[] bytes, byte[] bytes1, Batch.Call<T, R> call, Batch.Callback<R> callback) throws ServiceException, Throwable
{    throw new UnsupportedOperationException();}
0
public void setAutoFlush(boolean b)
{    autoflush = b;}
0
public void setAutoFlush(boolean b, boolean b1)
{    autoflush = b;}
0
public void setAutoFlushTo(boolean b)
{    autoflush = b;}
0
public long getWriteBufferSize()
{    return writeBufferSize;}
0
public void setWriteBufferSize(long l) throws IOException
{    writeBufferSize = l;}
0
public Map<byte[], R> batchCoprocessorService(Descriptors.MethodDescriptor methodDescriptor, Message message, byte[] bytes, byte[] bytes1, R r) throws ServiceException, Throwable
{    throw new UnsupportedOperationException();}
0
public void batchCoprocessorService(Descriptors.MethodDescriptor methodDescriptor, Message message, byte[] bytes, byte[] bytes1, R r, Batch.Callback<R> callback) throws ServiceException, Throwable
{    throw new UnsupportedOperationException();}
0
public boolean checkAndMutate(byte[] row, byte[] family, byte[] qualifier, CompareFilter.CompareOp compareOp, byte[] value, RowMutations mutation) throws IOException
{    return false;}
0
public void start(CoprocessorEnvironment ce) throws IOException
{        if (ce instanceof RegionCoprocessorEnvironment) {        this.coprocessorEnv = (RegionCoprocessorEnvironment) ce;    } else {        throw new CoprocessorException("Enrichment coprocessor must be loaded on a table region.");    }        if (null == this.cache) {                        String zkUrl = getZookeeperUrl(this.coprocessorEnv.getConfiguration());        if (null == globalConfigService) {            globalConfigService = getGlobalConfigService(zkUrl);        }        globalConfig = globalConfigService.get();        Configuration config = this.coprocessorEnv.getConfiguration();        CacheWriter<String, String> cacheWriter = null;        try {            String hbaseTableProviderName = (String) globalConfig.get(EnrichmentConfigurations.TABLE_PROVIDER);            String tableName = (String) globalConfig.get(EnrichmentConfigurations.TABLE_NAME);            String columnFamily = (String) globalConfig.get(EnrichmentConfigurations.COLUMN_FAMILY);            cacheWriter = new HBaseCacheWriter(config, TableProvider.create(hbaseTableProviderName, HTableProvider::new), tableName, columnFamily, COLUMN_QUALIFIER);        } catch (ClassNotFoundException | InstantiationException | InvocationTargetException | IllegalAccessException | NoSuchMethodException e) {            throw new IOException("Unable to instantiate cache writer", e);        }        this.cache = Caffeine.newBuilder().writer(cacheWriter).build();            }    }
1
private String getZookeeperUrl(Configuration config)
{    String zkUrl = config.get(ZOOKEEPER_URL);    if (null == zkUrl) {        throw new IllegalStateException("Enrichment coprocessor requires property '" + ZOOKEEPER_URL + "' to be provided at startup.");    }    return zkUrl;}
0
private GlobalConfigService getGlobalConfigService(String zkUrl)
{    return new GlobalConfigService() {        @Override        public Map<String, Object> get() {            try (CuratorFramework client = ConfigurationsUtils.getClient(zkUrl)) {                client.start();                return ConfigurationsUtils.readGlobalConfigFromZookeeper(client);            } catch (Exception e) {                throw new IllegalStateException("Unable to read global configuration from zookeeper", e);            }        }    };}
0
public Map<String, Object> get()
{    try (CuratorFramework client = ConfigurationsUtils.getClient(zkUrl)) {        client.start();        return ConfigurationsUtils.readGlobalConfigFromZookeeper(client);    } catch (Exception e) {        throw new IllegalStateException("Unable to read global configuration from zookeeper", e);    }}
0
public void postPut(ObserverContext<RegionCoprocessorEnvironment> e, Put put, WALEdit edit, Durability durability) throws IOException
{    LOG.trace("enrichment coprocessor postPut call begin");    try {        LOG.trace("Extracting enrichment type from rowkey");        String type = getEnrichmentType(put);                final String metadata = "{}";        LOG.trace("Enrichment type '{}' extracted from rowkey", type);        addToCache(type, metadata);    } catch (Throwable t) {                        throw new IOException("Error occurred while processing enrichment Put.", t);    }    LOG.trace("enrichment coprocessor postPut call complete");}
1
private String getEnrichmentType(Put put)
{    EnrichmentKey key = new EnrichmentKey();    key.fromBytes(put.getRow());    return key.type;}
0
private void addToCache(String cacheKey, String value)
{    LOG.trace("Checking if cacheKey '{}'present in cache", cacheKey);        if (null == cache.getIfPresent(cacheKey)) {        LOG.trace("cacheKey '{}' not present, adding with value='{}' to cache", cacheKey, value);        cache.put(cacheKey, value);        LOG.trace("Done adding cacheKey '{}' to cache with value='{}'", cacheKey, value);    }}
0
public void write(@Nonnull String key, @Nonnull String value)
{        try (HBaseClient hbClient = new HBaseClient(this.tableProvider, this.config, this.tableName)) {                hbClient.put(key, columnFamily, columnQualifier, value);            } catch (IOException e) {        throw new RuntimeException("Error writing to HBase table", e);    }    }
1
public void delete(@Nonnull String key, @Nullable String value, @Nonnull RemovalCause cause)
{}
0
public static void setupAll() throws Exception
{    silenceLogging();        startZookeeper(new Properties());    globalConfig = globalConfig.replace("%TABLE_NAME%", ENRICHMENT_LIST_TABLE).replace("%COLUMN_FAMILY%", COLUMN_FAMILY).replace("%PROVIDER_NAME%", HTableProvider.class.getName());    uploadGlobalConfigToZK(globalConfig);    configureAndStartHBase();    addCoprocessor(enrichmentTable.getName());}
0
private static void silenceLogging()
{    originalLog4jRootLoggerLevel = UnitTestHelper.getLog4jLevel();    originalJavaLoggerLevel = UnitTestHelper.getJavaLoggingLevel();    UnitTestHelper.setLog4jLevel(Level.ERROR);        /*    UnitTestHelper.setLog4jLevel(EnrichmentCoprocessor.class, Level.DEBUG);    UnitTestHelper.setLog4jLevel(HBaseCacheWriter.class, Level.DEBUG);    */    UnitTestHelper.setJavaLoggingLevel(java.util.logging.Level.SEVERE);}
0
private static void startZookeeper(Properties properties) throws UnableToStartException
{    zookeeperComponent = getZKServerComponent(properties);    componentRunner = new ComponentRunner.Builder().withComponent("zk", zookeeperComponent).withMillisecondsBetweenAttempts(15000).withNumRetries(10).build();    componentRunner.start();}
0
private static void uploadGlobalConfigToZK(String config) throws Exception
{    ConfigurationsUtils.writeGlobalConfigToZookeeper(config.getBytes(StandardCharsets.UTF_8), zookeeperComponent.getConnectionString());}
0
private static void configureAndStartHBase() throws Exception
{    Configuration extraConfig = new Configuration();    extraConfig.set(EnrichmentCoprocessor.ZOOKEEPER_URL, zookeeperComponent.getConnectionString());    Map.Entry<HBaseTestingUtility, Configuration> kv = HBaseUtil.INSTANCE.create(true, extraConfig);    testUtil = kv.getKey();    hBaseConfig = kv.getValue();    enrichmentTable = testUtil.createTable(Bytes.toBytes(ENRICHMENT_TABLE), Bytes.toBytes(COLUMN_FAMILY));    enrichmentListTable = testUtil.createTable(Bytes.toBytes(ENRICHMENT_LIST_TABLE), Bytes.toBytes(COLUMN_FAMILY));    for (Result r : enrichmentTable.getScanner(Bytes.toBytes(COLUMN_FAMILY))) {        Delete d = new Delete(r.getRow());        enrichmentTable.delete(d);    }    for (Result r : enrichmentListTable.getScanner(Bytes.toBytes(COLUMN_FAMILY))) {        Delete d = new Delete(r.getRow());        enrichmentListTable.delete(d);    }}
0
private static void addCoprocessor(TableName tableName) throws IOException
{        Admin hbaseAdmin = testUtil.getConnection().getAdmin();    hbaseAdmin.disableTable(tableName);    HTableDescriptor htd = new HTableDescriptor(tableName);    htd.addFamily(new HColumnDescriptor(COLUMN_FAMILY));    htd.addCoprocessor(EnrichmentCoprocessor.class.getCanonicalName());    hbaseAdmin.modifyTable(tableName, htd);    hbaseAdmin.enableTable(tableName);}
0
public static void teardown() throws Exception
{    HBaseUtil.INSTANCE.teardown(testUtil);    componentRunner.stop();    resetLogging();}
0
private static void resetLogging()
{    UnitTestHelper.setLog4jLevel(originalLog4jRootLoggerLevel);    UnitTestHelper.setJavaLoggingLevel(originalJavaLoggerLevel);}
0
public void enrichments_loaded_in_list_table() throws Exception
{        Map<String, String> enrichments = new HashMap<String, String>() {        {            put("111", "foo");            put("222", "foo");            put("333", "bar");            put("444", "bar");            put("555", "baz");            put("666", "baz");        }    };    Set<String> expectedEnrichmentTypes = new HashSet<>();    for (Map.Entry<String, String> enrichKV : enrichments.entrySet()) {        String indicator = enrichKV.getKey();        String type = enrichKV.getValue();        expectedEnrichmentTypes.add(type);        HelperDao.insertRecord(enrichmentTable, new EnrichmentKey(type, indicator), COLUMN_FAMILY, "{ \"apache\" : \"metron\" }");    }    List<String> enrichmentsList = HelperDao.readRecords(enrichmentListTable);    assertThat(new HashSet<String>(enrichmentsList), equalTo(expectedEnrichmentTypes));}
0
public void setup()
{    MockitoAnnotations.initMocks(this);    cop = new EnrichmentCoprocessor(cacheWriter, globalConfigService);    config = HBaseConfiguration.create();    config.set(EnrichmentCoprocessor.ZOOKEEPER_URL, "foobar");    when(copEnv.getConfiguration()).thenReturn(config);    instantiatedCustomTableProvider = false;}
0
public void cache_writes_only_on_first_cache_miss() throws Exception
{    cop.start(copEnv);    String[] enrichTypes = new String[] { "foo", "bar", "baz", "metron" };    final int putsPerType = 3;    Map<String, List<Put>> putsByType = simulateMultiplePutsPerType(putsPerType, enrichTypes);    int totalPuts = 0;    for (Map.Entry<String, List<Put>> entry : putsByType.entrySet()) {        String type = entry.getKey();        List<Put> puts = entry.getValue();        for (Put put : puts) {            cop.postPut(observerContext, put, null, null);            verify(cacheWriter, times(1)).write(eq(type), eq("{}"));            totalPuts++;        }    }    assertThat(totalPuts, equalTo(enrichTypes.length * putsPerType));}
0
private Map<String, List<Put>> simulateMultiplePutsPerType(int count, String... types)
{    Map<String, List<Put>> putsByType = new HashMap<>();    for (String type : types) {        List<Put> puts = putsByType.getOrDefault(type, new ArrayList<>());        for (int i = 0; i < count; i++) {            EnrichmentKey ek = new EnrichmentKey(type, String.valueOf(i));            puts.add(new Put(ek.toBytes()));            putsByType.put(type, puts);        }    }    return putsByType;}
0
public Table getTable(Configuration config, String tableName) throws IOException
{        return null;}
0
public void creates_tableprovider_from_config_property() throws Exception
{    cop = new EnrichmentCoprocessor(globalConfigService);    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(EnrichmentConfigurations.TABLE_PROVIDER, TestTableProvider.class.getName());        }    };    when(globalConfigService.get()).thenReturn(globalConfig);    cop.start(copEnv);    assertThat(instantiatedCustomTableProvider, equalTo(true));}
0
public void bad_enrichment_key_exceptions_thrown_as_IOException() throws Exception
{    thrown.expect(IOException.class);    thrown.expectMessage("Error occurred while processing enrichment Put.");    thrown.expectCause(instanceOf(RuntimeException.class));    cop.start(copEnv);    cop.postPut(observerContext, new Put("foo".getBytes(StandardCharsets.UTF_8)), null, null);}
0
public void general_exceptions_thrown_as_IOException() throws Exception
{    Throwable cause = new Throwable("Bad things happened.");    thrown.expect(IOException.class);    thrown.expectMessage("Error occurred while processing enrichment Put.");    thrown.expectCause(equalTo(cause));            willAnswer(i -> {        throw cause;    }).given(cacheWriter).write(any(), any());    cop.start(copEnv);    EnrichmentKey ek = new EnrichmentKey("foo", "bar");    cop.postPut(observerContext, new Put(ek.toBytes()), null, null);}
0
public static void insertRecord(Table table, EnrichmentKey key, String cf, String value) throws IOException
{    Put put = createPut(key, cf, value);    table.put(put);}
0
private static Put createPut(EnrichmentKey rowKey, String cf, String value) throws IOException
{    return new EnrichmentConverter().toPut(cf, rowKey, new EnrichmentValue(JSONUtils.INSTANCE.load(value, JSONUtils.MAP_SUPPLIER)));}
0
public static List<String> readRecords(Table table) throws Exception
{    Scan scan = new Scan();    ResultScanner scanner = table.getScanner(scan);    List<String> rows = new ArrayList<>();    for (Result r = scanner.next(); r != null; r = scanner.next()) {        rows.add(Bytes.toString(r.getRow()));    }    return rows;}
0
public Supplier<Map<String, Object>> getGlobalConfigSupplier()
{    return globalConfigSupplier;}
0
public void setGlobalConfigSupplier(Supplier<Map<String, Object>> globalConfigSupplier)
{    this.globalConfigSupplier = globalConfigSupplier;}
0
public Function<String, String> getIndexSupplier()
{    return indexSupplier;}
0
public void setIndexSupplier(Function<String, String> indexSupplier)
{    this.indexSupplier = indexSupplier;}
0
public Integer getMaxSearchResults()
{    return maxSearchResults;}
0
public void setMaxSearchResults(Integer maxSearchResults)
{    this.maxSearchResults = maxSearchResults;}
0
public Integer getMaxSearchGroups()
{    return maxSearchGroups;}
0
public void setMaxSearchGroups(Integer maxSearchGroups)
{    this.maxSearchGroups = maxSearchGroups;}
0
public Map<String, String> getOptionalSettings()
{    return optionalSettings;}
0
public void setOptionalSettings(Map<String, String> optionalSettings)
{    this.optionalSettings = optionalSettings;}
0
public TableProvider getTableProvider()
{    return tableProvider;}
0
public void setTableProvider(TableProvider tableProvider)
{    this.tableProvider = tableProvider;}
0
public Boolean getKerberosEnabled()
{    return isKerberosEnabled;}
0
public void setKerberosEnabled(Boolean kerberosEnabled)
{    isKerberosEnabled = kerberosEnabled;}
0
public String getGuid()
{    return guid;}
0
public String getSensorType()
{    return sensorType;}
0
public static Key fromBytes(byte[] buffer) throws IOException
{    ByteArrayInputStream baos = new ByteArrayInputStream(buffer);    DataInputStream w = new DataInputStream(baos);    baos.skip(KeyUtil.HASH_PREFIX_SIZE);    return new Key(w.readUTF(), w.readUTF());}
0
public byte[] toBytes() throws IOException
{    ByteArrayOutputStream baos = new ByteArrayOutputStream();    if (getGuid() == null || getSensorType() == null) {        throw new IllegalStateException("Guid and sensor type must not be null: guid = " + getGuid() + ", sensorType = " + getSensorType());    }    DataOutputStream w = new DataOutputStream(baos);    w.writeUTF(getGuid());    w.writeUTF(getSensorType());    w.flush();    byte[] key = baos.toByteArray();    byte[] prefix = KeyUtil.INSTANCE.getPrefix(key);    return KeyUtil.INSTANCE.merge(prefix, key);}
0
public static byte[] toBytes(Key k) throws IOException
{    return k.toBytes();}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Key key = (Key) o;    if (getGuid() != null ? !getGuid().equals(key.getGuid()) : key.getGuid() != null)        return false;    return getSensorType() != null ? getSensorType().equals(key.getSensorType()) : key.getSensorType() == null;}
0
public int hashCode()
{    int result = getGuid() != null ? getGuid().hashCode() : 0;    result = 31 * result + (getSensorType() != null ? getSensorType().hashCode() : 0);    return result;}
0
public synchronized SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    return null;}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    return null;}
0
public synchronized void init(AccessConfig config)
{    if (this.tableInterface == null) {        this.config = config;        Map<String, Object> globalConfig = config.getGlobalConfigSupplier().get();        if (globalConfig == null) {            throw new IllegalStateException("Cannot find the global config.");        }        String table = (String) globalConfig.get(HBASE_TABLE);        String cf = (String) config.getGlobalConfigSupplier().get().get(HBASE_CF);        if (table == null || cf == null) {            throw new IllegalStateException("You must configure " + HBASE_TABLE + " and " + HBASE_CF + " in the global config.");        }        try {            tableInterface = config.getTableProvider().getTable(HBaseConfiguration.create(), table);            this.cf = cf.getBytes(StandardCharsets.UTF_8);        } catch (IOException e) {            throw new IllegalStateException("Unable to initialize HBaseDao: " + e.getMessage(), e);        }    }}
0
public Table getTableInterface()
{    if (tableInterface == null) {        init(config);    }    return tableInterface;}
0
public synchronized Document getLatest(String guid, String sensorType) throws IOException
{    Key k = new Key(guid, sensorType);    Get get = new Get(Key.toBytes(k));    get.addFamily(cf);    Result result = getTableInterface().get(get);    return getDocumentFromResult(result);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    List<Get> gets = new ArrayList<>();    for (GetRequest getRequest : getRequests) {        gets.add(buildGet(getRequest));    }    Result[] results = getTableInterface().get(gets);    List<Document> allLatest = new ArrayList<>();    for (Result result : results) {        Document d = getDocumentFromResult(result);        if (d != null) {            allLatest.add(d);        }    }    return allLatest;}
0
private Document getDocumentFromResult(Result result) throws IOException
{    NavigableMap<byte[], byte[]> columns = result.getFamilyMap(cf);    if (columns == null || columns.size() == 0) {        return null;    }    Map.Entry<byte[], byte[]> entry = columns.lastEntry();    Long ts = Bytes.toLong(entry.getKey());    if (entry.getValue() != null) {        Map<String, Object> json = JSONUtils.INSTANCE.load(new String(entry.getValue(), StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER);                @SuppressWarnings("unchecked")        List<Map<String, Object>> commentsMap = (List<Map<String, Object>>) json.get(COMMENTS_FIELD);        try {            if (commentsMap != null) {                List<AlertComment> comments = new ArrayList<>();                for (Map<String, Object> commentMap : commentsMap) {                    comments.add(new AlertComment(commentMap));                }                if (comments.size() > 0) {                    json.put(COMMENTS_FIELD, comments.stream().map(AlertComment::asMap).collect(Collectors.toList()));                }            }            Key k = Key.fromBytes(result.getRow());            return new Document(json, k.getGuid(), k.getSensorType(), ts);        } catch (IOException e) {            throw new RuntimeException("Unable to convert row key to a document", e);        }    } else {        return null;    }}
0
public synchronized Document update(Document update, Optional<String> index) throws IOException
{    Put put = buildPut(update);    getTableInterface().put(put);    return update;}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) throws IOException
{    List<Put> puts = new ArrayList<>();    for (Map.Entry<Document, Optional<String>> updateEntry : updates.entrySet()) {        Document update = updateEntry.getKey();        Put put = buildPut(update);        puts.add(put);    }    getTableInterface().put(puts);    return updates;}
0
protected Get buildGet(GetRequest getRequest) throws IOException
{    Key k = new Key(getRequest.getGuid(), getRequest.getSensorType());    Get get = new Get(Key.toBytes(k));    get.addFamily(cf);    return get;}
0
protected Put buildPut(Document update) throws IOException
{    Key k = new Key(update.getGuid(), update.getSensorType());    Put put = new Put(Key.toBytes(k));    long ts = update.getTimestamp() == null || update.getTimestamp() == 0 ? System.currentTimeMillis() : update.getTimestamp();    byte[] columnQualifier = Bytes.toBytes(ts);    byte[] doc = JSONUtils.INSTANCE.toJSONPretty(update.getDocument());    put.addColumn(cf, columnQualifier, doc);    return put;}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = getLatest(request.getGuid(), request.getSensorType());    return addCommentToAlert(request, latest);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to add comment. Document with guid %s cannot be found.", request.getGuid()));    }    List<Map<String, Object>> comments = (List<Map<String, Object>>) latest.getDocument().getOrDefault(COMMENTS_FIELD, new ArrayList<>());    List<Map<String, Object>> originalComments = new ArrayList<>(comments);        List<Map<String, Object>> commentsMap = new ArrayList<>();    for (Map<String, Object> comment : originalComments) {        commentsMap.add(new AlertComment(comment).asMap());    }    commentsMap.add(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()).asMap());    Document newVersion = new Document(latest);    newVersion.getDocument().put(COMMENTS_FIELD, commentsMap);    return update(newVersion, Optional.empty());}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = getLatest(request.getGuid(), request.getSensorType());    return removeCommentFromAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s cannot be found.", request.getGuid()));    }    List<Map<String, Object>> commentMap = (List<Map<String, Object>>) latest.getDocument().get(COMMENTS_FIELD);        if (commentMap == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s has no comments.", request.getGuid()));    }    List<Map<String, Object>> originalComments = new ArrayList<>(commentMap);    List<AlertComment> comments = new ArrayList<>();    for (Map<String, Object> commentStr : originalComments) {        comments.add(new AlertComment(commentStr));    }    comments.remove(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()));    Document newVersion = new Document(latest);    if (comments.size() > 0) {        List<Map<String, Object>> commentsAsMap = comments.stream().map(AlertComment::asMap).collect(Collectors.toList());        newVersion.getDocument().put(COMMENTS_FIELD, commentsAsMap);        update(newVersion, Optional.empty());    } else {        newVersion.getDocument().remove(COMMENTS_FIELD);    }    return update(newVersion, Optional.empty());}
0
public static List<IndexDao> create(String daoImpls, AccessConfig config) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException
{    List<IndexDao> ret = new ArrayList<>();    for (String daoImpl : Splitter.on(",").split(daoImpls)) {        Class<? extends IndexDao> clazz = (Class<? extends IndexDao>) Class.forName(daoImpl);        IndexDao instance = clazz.getConstructor().newInstance();        instance.init(config);        ret.add(instance);    }    return ret;}
0
public static IndexDao combine(Iterable<IndexDao> daos) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException
{    return combine(daos, x -> x);}
0
public static IndexDao combine(Iterable<IndexDao> daos, Function<IndexDao, IndexDao> daoTransformation) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException
{    int numDaos = Iterables.size(daos);    if (numDaos == 0) {        throw new IllegalArgumentException("Trying to combine 0 dao's into a DAO is not a supported configuration.");    }    if (numDaos == 1) {        return daoTransformation.apply(Iterables.getFirst(daos, null));    }    return new MultiIndexDao(daos, daoTransformation);}
0
 String getThreatTriageField()
{    return MetaAlertConstants.THREAT_FIELD_DEFAULT;}
0
 String getThreatSort()
{    return MetaAlertConstants.THREAT_SORT_DEFAULT;}
0
public UpdateDao getUpdateDao()
{    return updateDao;}
0
public MetaAlertRetrieveLatestDao getRetrieveLatestDao()
{    return retrieveLatestDao;}
0
public MetaAlertConfig getConfig()
{    return config;}
0
public Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    if (isPatchAllowed(request)) {        return updateDao.patch(retrieveLatestDao, request, timestamp);    } else {        throw new IllegalArgumentException("Meta alert patches are not allowed for /alert or /status paths.  " + "Please use the add/remove alert or update status functions instead.");    }}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates)
{    throw new UnsupportedOperationException("Meta alerts do not allow for bulk updates");}
0
protected Document buildCreateDocument(Iterable<Document> alerts, List<String> groups, String alertField)
{        Map<String, Object> metaSource = new HashMap<>();    List<Map<String, Object>> alertList = new ArrayList<>();    for (Document alert : alerts) {        alertList.add(alert.getDocument());    }    metaSource.put(alertField, alertList);        String guid = UUID.randomUUID().toString();    metaSource.put(GUID, guid);    metaSource.put(Constants.Fields.TIMESTAMP.getName(), System.currentTimeMillis());    metaSource.put(MetaAlertConstants.GROUPS_FIELD, groups);    metaSource.put(MetaAlertConstants.STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString());    return new Document(metaSource, guid, MetaAlertConstants.METAALERT_TYPE, System.currentTimeMillis());}
0
protected Map<Document, Optional<String>> buildRemoveAlertsFromMetaAlert(Document metaAlert, Iterable<Document> alerts) throws IOException
{    Map<Document, Optional<String>> updates = new HashMap<>();    List<String> alertGuids = new ArrayList<>();    for (Document alert : alerts) {        alertGuids.add(alert.getGuid());    }    List<Map<String, Object>> alertsBefore = new ArrayList<>();    Map<String, Object> documentBefore = metaAlert.getDocument();    if (documentBefore.containsKey(MetaAlertConstants.ALERT_FIELD)) {        alertsBefore.addAll((List<Map<String, Object>>) documentBefore.get(MetaAlertConstants.ALERT_FIELD));    }    boolean metaAlertUpdated = removeAlertsFromMetaAlert(metaAlert, alertGuids);    if (metaAlertUpdated) {        List<Map<String, Object>> alertsAfter = (List<Map<String, Object>>) metaAlert.getDocument().get(MetaAlertConstants.ALERT_FIELD);        if (alertsAfter.size() < alertsBefore.size() && alertsAfter.size() == 0) {            throw new IllegalStateException("Removing these alerts will result in an empty meta alert.  Empty meta alerts are not allowed.");        }        MetaScores.calculateMetaScores(metaAlert, config.getThreatTriageField(), config.getThreatSort());        updates.put(metaAlert, Optional.of(config.getMetaAlertIndex()));        for (Document alert : alerts) {            if (removeMetaAlertFromAlert(metaAlert.getGuid(), alert)) {                updates.put(alert, Optional.empty());            }        }    }    return updates;}
0
public Document addAlertsToMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    Document metaAlert = retrieveLatestDao.getLatest(metaAlertGuid, MetaAlertConstants.METAALERT_TYPE);    if (metaAlert == null) {        throw new IOException(String.format("Unable to add alerts to meta alert.  Meta alert with guid %s cannot be found.", metaAlertGuid));    }    if (MetaAlertStatus.ACTIVE.getStatusString().equals(metaAlert.getDocument().get(MetaAlertConstants.STATUS_FIELD))) {        Iterable<Document> alerts = retrieveLatestDao.getAllLatest(alertRequests);        Set<String> missingAlerts = getMissingAlerts(alertRequests, alerts);        if (!missingAlerts.isEmpty()) {            throw new IOException(String.format("Unable to add alerts to meta alert.  Alert with guid %s cannot be found.", missingAlerts.iterator().next()));        }        Map<Document, Optional<String>> updates = buildAddAlertToMetaAlertUpdates(metaAlert, alerts);        update(updates);        return metaAlert;    } else {        throw new IllegalStateException("Adding alerts to an INACTIVE meta alert is not allowed");    }}
0
public Document removeAlertsFromMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException, IllegalStateException
{    Document metaAlert = retrieveLatestDao.getLatest(metaAlertGuid, MetaAlertConstants.METAALERT_TYPE);    if (metaAlert == null) {        throw new IOException(String.format("Unable to remove alerts from meta alert.  Meta alert with guid %s cannot be found.", metaAlertGuid));    }    if (MetaAlertStatus.ACTIVE.getStatusString().equals(metaAlert.getDocument().get(MetaAlertConstants.STATUS_FIELD))) {        Iterable<Document> alerts = retrieveLatestDao.getAllLatest(alertRequests);        Set<String> missingAlerts = getMissingAlerts(alertRequests, alerts);        if (!missingAlerts.isEmpty()) {            throw new IOException(String.format("Unable to remove alerts from meta alert.  Alert with guid %s cannot be found.", missingAlerts.iterator().next()));        }        Map<Document, Optional<String>> updates = buildRemoveAlertsFromMetaAlert(metaAlert, alerts);        update(updates);        return metaAlert;    } else {        throw new IllegalStateException("Removing alerts from an INACTIVE meta alert is not allowed");    }}
0
protected boolean removeAlertsFromMetaAlert(Document metaAlert, Collection<String> alertGuids)
{        if (!metaAlert.getDocument().containsKey(MetaAlertConstants.ALERT_FIELD) || alertGuids.size() == 0) {        return false;    }    @SuppressWarnings("unchecked")    List<Map<String, Object>> currentAlerts = (List<Map<String, Object>>) metaAlert.getDocument().get(MetaAlertConstants.ALERT_FIELD);    int previousSize = currentAlerts.size();        currentAlerts.removeIf(currentAlert -> alertGuids.contains(currentAlert.get(GUID)));    return currentAlerts.size() != previousSize;}
0
public Document updateMetaAlertStatus(String metaAlertGuid, MetaAlertStatus status) throws IOException
{    Document metaAlert = retrieveLatestDao.getLatest(metaAlertGuid, MetaAlertConstants.METAALERT_TYPE);    if (metaAlert == null) {        throw new IOException(String.format("Unable to update meta alert status.  Meta alert with guid %s cannot be found.", metaAlertGuid));    }    String currentStatus = (String) metaAlert.getDocument().get(MetaAlertConstants.STATUS_FIELD);    boolean metaAlertUpdated = !status.getStatusString().equals(currentStatus);    if (metaAlertUpdated) {        List<GetRequest> getRequests = new ArrayList<>();        @SuppressWarnings("unchecked")        List<Map<String, Object>> currentAlerts = (List<Map<String, Object>>) metaAlert.getDocument().get(MetaAlertConstants.ALERT_FIELD);        currentAlerts.stream().forEach(currentAlert -> getRequests.add(new GetRequest((String) currentAlert.get(GUID), (String) currentAlert.get(config.getSourceTypeField()))));        Iterable<Document> alerts = retrieveLatestDao.getAllLatest(getRequests);        Map<Document, Optional<String>> updates = buildStatusChangeUpdates(metaAlert, alerts, status);        update(updates);    }    return metaAlert;}
0
protected Map<Document, Optional<String>> buildStatusChangeUpdates(Document metaAlert, Iterable<Document> alerts, MetaAlertStatus status)
{    metaAlert.getDocument().put(MetaAlertConstants.STATUS_FIELD, status.getStatusString());    Map<Document, Optional<String>> updates = new HashMap<>();    updates.put(metaAlert, Optional.of(config.getMetaAlertIndex()));    for (Document alert : alerts) {        boolean metaAlertAdded = false;        boolean metaAlertRemoved = false;                if (MetaAlertStatus.ACTIVE.equals(status)) {            metaAlertAdded = addMetaAlertToAlert(metaAlert.getGuid(), alert);        }                if (MetaAlertStatus.INACTIVE.equals(status)) {            metaAlertRemoved = removeMetaAlertFromAlert(metaAlert.getGuid(), alert);        }        if (metaAlertAdded || metaAlertRemoved) {            updates.put(alert, Optional.empty());        }    }    return updates;}
0
protected Map<Document, Optional<String>> buildAddAlertToMetaAlertUpdates(Document metaAlert, Iterable<Document> alerts)
{    Map<Document, Optional<String>> updates = new HashMap<>();    boolean metaAlertUpdated = addAlertsToMetaAlert(metaAlert, alerts);    if (metaAlertUpdated) {        MetaScores.calculateMetaScores(metaAlert, config.getThreatTriageField(), config.getThreatSort());        updates.put(metaAlert, Optional.of(config.getMetaAlertIndex()));        for (Document alert : alerts) {            if (addMetaAlertToAlert(metaAlert.getGuid(), alert)) {                updates.put(alert, Optional.empty());            }        }    }    return updates;}
0
protected boolean addAlertsToMetaAlert(Document metaAlert, Iterable<Document> alerts)
{    boolean alertAdded = false;    @SuppressWarnings("unchecked")    List<Map<String, Object>> currentAlerts = (List<Map<String, Object>>) metaAlert.getDocument().get(MetaAlertConstants.ALERT_FIELD);    if (currentAlerts == null) {        currentAlerts = new ArrayList<>();        metaAlert.getDocument().put(MetaAlertConstants.ALERT_FIELD, currentAlerts);    }    Set<String> currentAlertGuids = currentAlerts.stream().map(currentAlert -> (String) currentAlert.get(GUID)).collect(Collectors.toSet());    for (Document alert : alerts) {        String alertGuid = alert.getGuid();                if (!currentAlertGuids.contains(alertGuid)) {            currentAlerts.add(alert.getDocument());            alertAdded = true;        }    }    return alertAdded;}
0
protected void update(Map<Document, Optional<String>> updates) throws IOException
{    if (updates.size() == 1) {        Entry<Document, Optional<String>> singleUpdate = updates.entrySet().iterator().next();        updateDao.update(singleUpdate.getKey(), singleUpdate.getValue());    } else if (updates.size() > 1) {        updateDao.batchUpdate(updates);    }}
0
protected Set<String> getMissingAlerts(List<GetRequest> alertRequests, Iterable<Document> results) throws IOException
{    Set<String> requestGuids = alertRequests.stream().map(GetRequest::getGuid).collect(Collectors.toSet());    Set<String> resultGuids = StreamSupport.stream(results.spliterator(), false).map(Document::getGuid).collect(Collectors.toSet());    Set<String> missingGuids = new HashSet<>(requestGuids);    missingGuids.removeAll(resultGuids);    return missingGuids;}
0
public String getMetaAlertGuid()
{    return metaAlertGuid;}
0
public void setMetaAlertGuid(String metaAlertGuid)
{    this.metaAlertGuid = metaAlertGuid;}
0
public List<GetRequest> getAlerts()
{    return alerts;}
0
public void setAlerts(List<GetRequest> alerts)
{    this.alerts = alerts;}
0
public String getMetaAlertIndex()
{    return metaAlertIndex;}
0
public void setMetaAlertIndex(String metaAlertIndex)
{    this.metaAlertIndex = metaAlertIndex;}
0
public String getThreatTriageField()
{    Optional<Map<String, Object>> globalConfig = Optional.ofNullable(globalConfigSupplier.get());    if (!globalConfig.isPresent()) {        return getDefaultThreatTriageField();    }    return ConfigurationsUtils.getFieldName(globalConfig.get(), Constants.THREAT_SCORE_FIELD_PROPERTY, getDefaultThreatTriageField());}
0
public String getThreatSort()
{    return threatSort;}
0
public void setThreatSort(String threatSort)
{    this.threatSort = threatSort;}
0
public String getSourceTypeField()
{    Optional<Map<String, Object>> globalConfig = Optional.ofNullable(globalConfigSupplier.get());    if (!globalConfig.isPresent()) {        return getDefaultSourceTypeField();    }    return ConfigurationsUtils.getFieldName(globalConfig.get(), Constants.SENSOR_TYPE_FIELD_PROPERTY, getDefaultSourceTypeField());}
0
public List<GetRequest> getAlerts()
{    return alerts;}
0
public void setAlerts(List<GetRequest> alerts)
{    this.alerts = alerts;}
0
public List<String> getGroups()
{    return groups;}
0
public void setGroups(List<String> groups)
{    this.groups = groups;}
0
 void init(IndexDao indexDao)
{    init(indexDao, Optional.empty());}
0
public String getStatusString()
{    return statusString;}
0
 boolean isPatchAllowed(PatchRequest request)
{    if (request.getPatch() != null && !request.getPatch().isEmpty()) {        for (Map<String, Object> patch : request.getPatch()) {            Object pathObj = patch.get("path");            if (pathObj != null && pathObj instanceof String) {                String path = (String) pathObj;                if (STATUS_PATH.equals(path) || ALERT_PATH.equals(path)) {                    return false;                }            }        }    }    return true;}
0
 boolean removeMetaAlertFromAlert(String metaAlertGuid, Document alert)
{    List<String> metaAlertField = new ArrayList<>();    @SuppressWarnings("unchecked")    List<String> alertField = (List<String>) alert.getDocument().get(MetaAlertConstants.METAALERT_FIELD);    if (alertField != null) {        metaAlertField.addAll(alertField);    }    boolean metaAlertRemoved = metaAlertField.remove(metaAlertGuid);    if (metaAlertRemoved) {        alert.getDocument().put(MetaAlertConstants.METAALERT_FIELD, metaAlertField);    }    return metaAlertRemoved;}
0
 boolean addMetaAlertToAlert(String metaAlertGuid, Document alert)
{    List<String> metaAlertField = new ArrayList<>();    @SuppressWarnings("unchecked")    List<String> alertField = (List<String>) alert.getDocument().get(MetaAlertConstants.METAALERT_FIELD);    if (alertField != null) {        metaAlertField.addAll(alertField);    }    boolean metaAlertAdded = !metaAlertField.contains(metaAlertGuid);    if (metaAlertAdded) {        metaAlertField.add(metaAlertGuid);        alert.getDocument().put(MetaAlertConstants.METAALERT_FIELD, metaAlertField);    }    return metaAlertAdded;}
0
public Map<String, Object> getMetaScores()
{    return metaScores;}
0
public static void calculateMetaScores(Document metaAlert, String threatTriageField, String threatSort)
{    MetaScores metaScores = new MetaScores(new ArrayList<>());    List<Object> alertsRaw = ((List<Object>) metaAlert.getDocument().get(MetaAlertConstants.ALERT_FIELD));    if (alertsRaw != null && !alertsRaw.isEmpty()) {        ArrayList<Double> scores = new ArrayList<>();        for (Object alertRaw : alertsRaw) {            Map<String, Object> alert = (Map<String, Object>) alertRaw;            Double scoreNum = parseThreatField(alert.get(threatTriageField));            if (scoreNum != null) {                scores.add(scoreNum);            }        }        metaScores = new MetaScores(scores);    }        metaAlert.getDocument().putAll(metaScores.getMetaScores());            Object threatScore = metaScores.getMetaScores().get(threatSort);            metaAlert.getDocument().put(threatTriageField, ConversionUtils.convert(threatScore, Float.class));}
0
protected static Double parseThreatField(Object threatRaw)
{    Double threat = null;    if (threatRaw instanceof Number) {        threat = ((Number) threatRaw).doubleValue();    } else if (threatRaw instanceof String) {        threat = Double.parseDouble((String) threatRaw);    }    return threat;}
0
public Document update(final Document update, Optional<String> index) throws IOException
{    List<String> exceptions = indices.parallelStream().map(dao -> {        try {            dao.update(update, index);            return null;        } catch (Throwable e) {            return dao.getClass() + ": " + e.getMessage() + "\n" + ExceptionUtils.getStackTrace(e);        }    }).filter(e -> e != null).collect(Collectors.toList());    if (exceptions.size() > 0) {        throw new IOException(Joiner.on("\n").join(exceptions));    }    return update;}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) throws IOException
{    List<String> exceptions = indices.parallelStream().map(dao -> {        try {            dao.batchUpdate(updates);            return null;        } catch (Throwable e) {            return dao.getClass() + ": " + e.getMessage() + "\n" + ExceptionUtils.getStackTrace(e);        }    }).filter(e -> e != null).collect(Collectors.toList());    if (exceptions.size() > 0) {        throw new IOException(Joiner.on("\n").join(exceptions));    }    return updates;}
0
public Map<String, FieldType> getColumnMetadata(List<String> in) throws IOException
{    for (IndexDao dao : indices) {        Map<String, FieldType> r = dao.getColumnMetadata(in);        if (r != null) {            return r;        }    }    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = getLatest(request.getGuid(), request.getSensorType());    return addCommentToAlert(request, latest);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    List<DocumentContainer> output = indices.parallelStream().map(dao -> addCommentToAlert(dao, request, latest)).collect(Collectors.toList());    return getLatestDocument(output);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = getLatest(request.getGuid(), request.getSensorType());    return removeCommentFromAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    List<DocumentContainer> output = indices.parallelStream().map(dao -> removeCommentFromAlert(dao, request, latest)).collect(Collectors.toList());    return getLatestDocument(output);}
0
public Optional<Document> getDocument()
{    return d;}
0
public Optional<Throwable> getException()
{    return t;}
0
public Optional<Iterable<Document>> getDocumentIterable()
{    return d;}
0
public Optional<Throwable> getException()
{    return t;}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    for (IndexDao dao : indices) {        SearchResponse s = dao.search(searchRequest);        if (s != null) {            return s;        }    }    return null;}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    for (IndexDao dao : indices) {        GroupResponse s = dao.group(groupRequest);        if (s != null) {            return s;        }    }    return null;}
0
public void init(AccessConfig config)
{    for (IndexDao dao : indices) {        dao.init(config);    }}
0
public Document getLatest(final String guid, String sensorType) throws IOException
{    List<DocumentContainer> output = indices.parallelStream().map(dao -> getLatest(dao, guid, sensorType)).collect(Collectors.toList());    return getLatestDocument(output);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    Iterable<Document> ret = null;    List<DocumentIterableContainer> output = indices.parallelStream().map(dao -> {        try {            return new DocumentIterableContainer(dao.getAllLatest(getRequests));        } catch (Throwable e) {            return new DocumentIterableContainer(e);        }    }).collect(Collectors.toList());    List<String> error = new ArrayList<>();    for (DocumentIterableContainer dc : output) {        if (dc.getException().isPresent()) {            Throwable e = dc.getException().get();            error.add(e.getMessage() + "\n" + ExceptionUtils.getStackTrace(e));        } else {            if (dc.getDocumentIterable().isPresent()) {                Iterable<Document> documents = dc.getDocumentIterable().get();                if (ret == null) {                    ret = documents;                }            }        }    }    if (error.size() > 0) {        throw new IOException(Joiner.on("\n").join(error));    }    return ret;}
0
public List<IndexDao> getIndices()
{    return indices;}
0
private Document getLatestDocument(List<DocumentContainer> documentContainers) throws IOException
{    Document latestDocument = null;    List<String> error = new ArrayList<>();    for (DocumentContainer dc : documentContainers) {        if (dc.getException().isPresent()) {                        Throwable e = dc.getException().get();            error.add(e.getMessage() + "\n" + ExceptionUtils.getStackTrace(e));        } else if (dc.getDocument().isPresent()) {            Document d = dc.getDocument().get();                        if (latestDocument == null || latestDocument.getTimestamp() < d.getTimestamp()) {                latestDocument = d;            }        } else {                }    }    if (error.size() > 0) {                throw new IOException(Joiner.on("\n").join(error));    }    return latestDocument;}
0
 Optional<Map<String, Object>> getLatestResult(GetRequest request) throws IOException
{    Document ret = getLatest(request.getGuid(), request.getSensorType());    if (ret == null) {        return Optional.empty();    } else {        return Optional.ofNullable(ret.getDocument());    }}
0
public String getComment()
{    return comment;}
0
public String getUsername()
{    return username;}
0
public long getTimestamp()
{    return timestamp;}
0
public String asJson()
{    return asJSONObject().toJSONString();}
0
public Map<String, Object> asMap()
{    Map<String, Object> map = new HashMap<>();    map.put(COMMENT_FIELD, comment);    map.put(COMMENT_USERNAME_FIELD, username);    map.put(COMMENT_TIMESTAMP_FIELD, timestamp);    return map;}
0
public JSONObject asJSONObject()
{    JSONObject json = new JSONObject();    json.put(COMMENT_FIELD, comment);    json.put(COMMENT_USERNAME_FIELD, username);    json.put(COMMENT_TIMESTAMP_FIELD, timestamp);    return json;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    AlertComment that = (AlertComment) o;    if (getTimestamp() != that.getTimestamp()) {        return false;    }    if (getComment() != null ? !getComment().equals(that.getComment()) : that.getComment() != null) {        return false;    }    return getUsername() != null ? getUsername().equals(that.getUsername()) : that.getUsername() == null;}
0
public int hashCode()
{    int result = getComment() != null ? getComment().hashCode() : 0;    result = 31 * result + (getUsername() != null ? getUsername().hashCode() : 0);    result = 31 * result + (int) (getTimestamp() ^ (getTimestamp() >>> 32));    return result;}
0
public String toString()
{    return "AlertComment{" + "comment='" + comment + '\'' + ", username='" + username + '\'' + ", timestamp=" + timestamp + '}';}
0
public String getFieldType()
{    return fieldType;}
0
public String getGuid()
{    return guid;}
0
public void setGuid(String guid)
{    this.guid = guid;}
0
public String getSensorType()
{    return sensorType;}
0
public void setSensorType(String sensorType)
{    this.sensorType = sensorType;}
0
public Optional<String> getIndex()
{    return index != null ? Optional.of(this.index) : Optional.empty();}
0
public String getIndexString()
{    return index;}
0
public void setIndex(String index)
{    this.index = index;}
0
public GroupOrder getOrder()
{    return order;}
0
public void setOrder(GroupOrder order)
{    this.order = order;}
0
public String getField()
{    return field;}
0
public void setField(String field)
{    this.field = field;}
0
public SortOrder getSortOrder()
{    return sortOrder;}
0
public void setSortOrder(String sortOrder)
{    this.sortOrder = SortOrder.fromString(sortOrder);}
0
public GroupOrderType getGroupOrderType()
{    return groupOrderType;}
0
public void setGroupOrderType(String groupOrderType)
{    this.groupOrderType = GroupOrderType.fromString(groupOrderType);}
0
public String getGroupOrderType()
{    return groupOrderType;}
0
public static GroupOrderType fromString(String groupOrderType)
{    return GroupOrderType.valueOf(groupOrderType.toUpperCase());}
0
public List<String> getIndices()
{    return indices;}
0
public void setIndices(List<String> indices)
{    this.indices = indices;}
0
public String getQuery()
{    return query;}
0
public void setQuery(String query)
{    this.query = query;}
0
public Optional<String> getScoreField()
{    return scoreField == null ? Optional.empty() : Optional.of(scoreField);}
0
public void setScoreField(String scoreField)
{    this.scoreField = scoreField;}
0
public List<Group> getGroups()
{    return groups;}
0
public void setGroups(List<Group> groups)
{    this.groups = groups;}
0
public String getGroupedBy()
{    return groupedBy;}
0
public void setGroupedBy(String groupedBy)
{    this.groupedBy = groupedBy;}
0
public List<GroupResult> getGroupResults()
{    return groupResults;}
0
public void setGroupResults(List<GroupResult> groupResults)
{    this.groupResults = groupResults;}
0
public String getKey()
{    return key;}
0
public void setKey(String key)
{    this.key = key;}
0
public long getTotal()
{    return total;}
0
public void setTotal(long total)
{    this.total = total;}
0
public Double getScore()
{    return score;}
0
public void setScore(Double score)
{    this.score = score;}
0
public String getGroupedBy()
{    return groupedBy;}
0
public void setGroupedBy(String groupedBy)
{    this.groupedBy = groupedBy;}
0
public List<GroupResult> getGroupResults()
{    return groupResults;}
0
public void setGroupResults(List<GroupResult> groups)
{    this.groupResults = groups;}
0
public List<String> getIndices()
{    return indices;}
0
public void setIndices(List<String> indices)
{    this.indices = indices;}
0
public String getQuery()
{    return query;}
0
public void setQuery(String query)
{    this.query = query;}
0
public int getSize()
{    return size;}
0
public void setSize(int size)
{    this.size = size;}
0
public int getFrom()
{    return from;}
0
public void setFrom(int from)
{    this.from = from;}
0
public List<SortField> getSort()
{    return sort;}
0
public void setSort(List<SortField> sort)
{    this.sort = sort;}
0
public List<String> getFields()
{    return fields;}
0
public void setFields(List<String> fields)
{    this.fields = fields;}
0
public List<String> getFacetFields()
{    return facetFields;}
0
public void setFacetFields(List<String> facetFields)
{    this.facetFields = facetFields;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SearchRequest that = (SearchRequest) o;    return (indices != null ? indices.equals(that.indices) : that.indices == null) && (query != null ? query.equals(that.query) : that.query == null) && size == that.size && from == that.from && (sort != null ? sort.equals(that.sort) : that.sort == null) && (fields != null ? fields.equals(that.fields) : that.fields == null) && (facetFields != null ? facetFields.equals(that.facetFields) : that.facetFields == null);}
0
public int hashCode()
{    int result = indices != null ? indices.hashCode() : 0;    result = 31 * result + (query != null ? query.hashCode() : 0);    result = 31 * result + getSize();    result = 31 * result + getFrom();    result = 31 * result + (sort != null ? sort.hashCode() : 0);    result = 31 * result + (fields != null ? fields.hashCode() : 0);    result = 31 * result + (facetFields != null ? facetFields.hashCode() : 0);    return result;}
0
public long getTotal()
{    return total;}
0
public void setTotal(long total)
{    this.total = total;}
0
public List<SearchResult> getResults()
{    return results;}
0
public void setResults(List<SearchResult> results)
{    this.results = results;}
0
public Map<String, Map<String, Long>> getFacetCounts()
{    return facetCounts;}
0
public void setFacetCounts(Map<String, Map<String, Long>> facetCounts)
{    this.facetCounts = facetCounts;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SearchResponse that = (SearchResponse) o;    return getTotal() == that.getTotal() && (getResults() != null ? getResults().equals(that.getResults()) : that.getResults() != null) && (getFacetCounts() != null ? getFacetCounts().equals(that.getFacetCounts()) : that.getFacetCounts() != null);}
0
public int hashCode()
{    int result = 31 * (int) getTotal() + (getResults() != null ? getResults().hashCode() : 0);    result = 31 * result + (getFacetCounts() != null ? getFacetCounts().hashCode() : 0);    return result;}
0
public String toString()
{    return "SearchResponse{" + "total=" + total + ", results=" + results + ", facetCounts=" + facetCounts + '}';}
0
public String getIndex()
{    return index;}
0
public void setIndex(String index)
{    this.index = index;}
0
public String getId()
{    return id;}
0
public void setId(String id)
{    this.id = id;}
0
public Map<String, Object> getSource()
{    return source;}
0
public void setSource(Map<String, Object> source)
{    this.source = source;}
0
public float getScore()
{    return score;}
0
public void setScore(float score)
{    this.score = score;}
0
public String toString()
{    return "SearchResult{" + "id='" + id + '\'' + ", source=" + source + ", score=" + score + ", index='" + index + '\'' + '}';}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SearchResult that = (SearchResult) o;    if (Float.compare(that.getScore(), getScore()) != 0) {        return false;    }    if (getId() != null ? !getId().equals(that.getId()) : that.getId() != null) {        return false;    }    if (getSource() != null ? !getSource().equals(that.getSource()) : that.getSource() != null) {        return false;    }    return getIndex() != null ? getIndex().equals(that.getIndex()) : that.getIndex() == null;}
0
public int hashCode()
{    int result = getId() != null ? getId().hashCode() : 0;    result = 31 * result + (getSource() != null ? getSource().hashCode() : 0);    result = 31 * result + (getScore() != +0.0f ? Float.floatToIntBits(getScore()) : 0);    result = 31 * result + (getIndex() != null ? getIndex().hashCode() : 0);    return result;}
0
public String getField()
{    return field;}
0
public void setField(String field)
{    this.field = field;}
0
public SortOrder getSortOrder()
{    return sortOrder;}
0
public void setSortOrder(String sortOrder)
{    this.sortOrder = SortOrder.fromString(sortOrder);}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SortField that = (SortField) o;    return (field != null ? field.equals(that.field) : that.field == null) && (sortOrder != null ? sortOrder.equals(that.sortOrder) : that.sortOrder == null);}
0
public String getSortOrder()
{    return sortOrder;}
0
public static SortOrder fromString(String order)
{    return SortOrder.valueOf(order.toUpperCase());}
0
public String getGuid()
{    return guid;}
0
public void setGuid(String guid)
{    this.guid = guid;}
0
public String getSensorType()
{    return sensorType;}
0
public void setSensorType(String sensorType)
{    this.sensorType = sensorType;}
0
public String getComment()
{    return comment;}
0
public void setComment(String comment)
{    this.comment = comment;}
0
public String getUsername()
{    return username;}
0
public void setUsername(String username)
{    this.username = username;}
0
public long getTimestamp()
{    return timestamp;}
0
public void setTimestamp(long timestamp)
{    this.timestamp = timestamp;}
0
public String toString()
{    return "CommentAddRemoveRequest{" + "guid='" + guid + '\'' + ", sensorType='" + sensorType + '\'' + ", comment='" + comment + '\'' + ", username='" + username + '\'' + ", timestamp=" + timestamp + '}';}
0
public static Document fromJSON(Map<String, Object> json)
{    String guid = getGUID(json);    Long timestamp = getTimestamp(json).orElse(0L);    String sensorType = getSensorType(json);    return new Document(json, guid, sensorType, timestamp);}
0
private static Map<String, Object> convertDoc(String document) throws IOException
{    return JSONUtils.INSTANCE.load(document, JSONUtils.MAP_SUPPLIER);}
0
public String getSensorType()
{    return sensorType;}
0
public void setSensorType(String sensorType)
{    this.sensorType = sensorType;}
0
public Long getTimestamp()
{    return timestamp;}
0
public void setTimestamp(Long timestamp)
{    this.timestamp = timestamp != null ? timestamp : System.currentTimeMillis();}
0
public Map<String, Object> getDocument()
{    return document;}
0
public void setDocument(Map<String, Object> document)
{    this.document = document;}
0
public String getGuid()
{    return guid;}
0
public void setGuid(String guid)
{    this.guid = guid;}
0
public Optional<String> getDocumentID()
{    return Optional.ofNullable(documentID);}
0
public void setDocumentID(Optional<String> documentID)
{    this.documentID = documentID.orElse(null);}
0
public void setDocumentID(String documentID)
{    this.documentID = documentID;}
0
private static Optional<Long> getTimestamp(Map<String, Object> document)
{    Object value = document.get(TIMESTAMP.getName());    if (value != null && value instanceof Long) {        return Optional.of(Long.class.cast(value));    }    return Optional.empty();}
0
private static String getGUID(Map<String, Object> document)
{    Object value = document.get(GUID);    if (value != null && value instanceof String) {        return String.class.cast(value);    }    throw new IllegalStateException(String.format("Missing '%s' field", GUID));}
0
private static String getSensorType(Map<String, Object> document)
{    Object value = document.get(SENSOR_TYPE);    if (value != null && value instanceof String) {        return String.class.cast(value);    }    value = document.get(SENSOR_TYPE.replace(".", ":"));    if (value != null && value instanceof String) {        return String.class.cast(value);    }    throw new IllegalStateException(String.format("Missing '%s' field", SENSOR_TYPE));}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (!(o instanceof Document))        return false;    Document document1 = (Document) o;    return Objects.equals(timestamp, document1.timestamp) && Objects.equals(document, document1.document) && Objects.equals(guid, document1.guid) && Objects.equals(sensorType, document1.sensorType) && Objects.equals(documentID, document1.documentID);}
0
public int hashCode()
{    return Objects.hash(timestamp, document, guid, sensorType, documentID);}
0
public String toString()
{    return "Document{" + "timestamp=" + timestamp + ", document=" + document + ", guid='" + guid + '\'' + ", sensorType='" + sensorType + '\'' + ", documentID=" + documentID + '}';}
0
public String getIndex()
{    return index;}
0
public void setIndex(String index)
{    this.index = index;}
0
public List<Map<String, Object>> getPatch()
{    return patch;}
0
public void setPatch(List<Map<String, Object>> patch)
{    this.patch = patch;}
0
public Map<String, Object> getSource()
{    return source;}
0
public void setSource(Map<String, Object> source)
{    this.source = source;}
0
public String getGuid()
{    return guid;}
0
public void setGuid(String guid)
{    this.guid = guid;}
0
public String getSensorType()
{    return sensorType;}
0
public void setSensorType(String sensorType)
{    this.sensorType = sensorType;}
0
public Map<String, Object> applyPatch(List<Map<String, Object>> patches, Map<String, Object> source)
{    Map<String, Object> patchedObject = new HashMap<>(source);    for (Map<String, Object> patch : patches) {                String operation = (String) patch.get(OP);        PatchOperation patchOperation;        try {            patchOperation = PatchOperation.valueOf(operation.toUpperCase());        } catch (IllegalArgumentException e) {            throw new UnsupportedOperationException(String.format("The %s operation is not supported", operation));        }        Object value = patch.get(VALUE);        String path = (String) patch.get(PATH);                List<String> fieldNames = getFieldNames(path);        String nestedFieldName = fieldNames.get(fieldNames.size() - 1);        Map<String, Object> nestedObject = getNestedObject(fieldNames, patchedObject);                if (ADD.equals(patchOperation) || REPLACE.equals(patchOperation)) {            nestedObject.put(nestedFieldName, value);        } else if (REMOVE.equals(patchOperation)) {            nestedObject.remove(nestedFieldName);        } else if (COPY.equals(patchOperation) || MOVE.equals(patchOperation)) {                        String from = (String) patch.get(FROM);            List<String> fromFieldNames = getFieldNames(from);            String fromNestedFieldName = fromFieldNames.get(fromFieldNames.size() - 1);            Map<String, Object> fromNestedObject = getNestedObject(fromFieldNames, patchedObject);                        Object copyValue = fromNestedObject.get(fromNestedFieldName);            nestedObject.put(nestedFieldName, copyValue);            if (MOVE.equals(patchOperation)) {                                nestedObject.remove(fromNestedFieldName);            }        } else if (TEST.equals(patchOperation)) {            Object testValue = nestedObject.get(nestedFieldName);            if (!Objects.equals(value, testValue)) {                throw new PatchException(String.format("TEST operation failed: supplied value [%s] != target value [%s]", value, testValue));            }        }    }    return patchedObject;}
0
private List<String> getFieldNames(String path)
{    String[] parts = path.split(PATH_SEPARATOR);    return new ArrayList<>(Arrays.asList(parts).subList(1, parts.length));}
0
private Map<String, Object> getNestedObject(List<String> fieldNames, Map<String, Object> patchedObject)
{    Map<String, Object> nestedObject = patchedObject;    for (int i = 0; i < fieldNames.size() - 1; i++) {        Object object = nestedObject.get(fieldNames.get(i));        if (object == null || !(object instanceof Map)) {            throw new IllegalArgumentException(String.format("Invalid path: /%s", String.join(PATH_SEPARATOR, fieldNames)));        } else {            nestedObject = (Map<String, Object>) object;        }    }    return nestedObject;}
0
 Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    Document d = getPatchedDocument(retrieveLatestDao, request, timestamp);    return update(d, Optional.ofNullable(request.getIndex()));}
0
 Document getPatchedDocument(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> optionalTimestamp) throws OriginalNotFoundException, IOException
{    String guid = request.getGuid();    String sensorType = request.getSensorType();    String documentID = null;    Long timestamp = optionalTimestamp.orElse(System.currentTimeMillis());    Map<String, Object> originalSource = request.getSource();    if (originalSource == null) {                Document toPatch = retrieveLatestDao.getLatest(guid, sensorType);        if (toPatch != null && toPatch.getDocument() != null) {            originalSource = toPatch.getDocument();            documentID = toPatch.getDocumentID().orElse(null);        } else {            String error = format("Document does not exist, but is required; guid=%s, sensorType=%s", guid, sensorType);            throw new OriginalNotFoundException(error);        }    }    Map<String, Object> patchedSource = PatchUtils.INSTANCE.applyPatch(request.getPatch(), originalSource);    return new Document(patchedSource, guid, sensorType, timestamp, documentID);}
0
public static Function<String, String> getIndexLookupFunction(ConfigurationsCache cache, String writerName)
{    return sensorType -> {        String indexingTopic = sensorType;        IndexingConfigurations indexingConfigs = cache.get(IndexingConfigurations.class);        Map<String, Object> indexingSensorConfigs = indexingConfigs.getSensorIndexingConfig(sensorType);        if (indexingSensorConfigs != null) {            Map<String, Object> writerConfigs = (Map<String, Object>) indexingSensorConfigs.get(writerName);            if (writerConfigs != null) {                indexingTopic = (String) writerConfigs.getOrDefault(IndexingConfigurations.INDEX_CONF, indexingTopic);            }        }        return indexingTopic;    };}
0
public void setup()
{    dao = new HBaseDao();}
0
public UpdateDao getUpdateDao()
{    return dao;}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    if (config.getMaxSearchResults() != null && searchRequest.getSize() > config.getMaxSearchResults()) {        throw new InvalidSearchException("Search result size must be less than " + config.getMaxSearchResults());    }    List<SearchResult> response = new ArrayList<>();    for (String index : searchRequest.getIndices()) {        String i = null;        for (String storedIdx : BACKING_STORE.keySet()) {            if (storedIdx.equals(index) || storedIdx.startsWith(index + "_")) {                i = storedIdx;            }        }        if (i == null) {            continue;        }        for (String doc : BACKING_STORE.get(i)) {            Map<String, Object> docParsed = parse(doc);            if (isMatch(searchRequest.getQuery(), docParsed)) {                SearchResult result = new SearchResult();                result.setSource(docParsed);                result.setScore((float) Math.random());                result.setId(docParsed.getOrDefault(Constants.GUID, UUID.randomUUID()).toString());                response.add(result);            }        }    }    if (searchRequest.getSort().size() != 0) {        Collections.sort(response, sorted(searchRequest.getSort()));    }    SearchResponse ret = new SearchResponse();    List<SearchResult> finalResp = new ArrayList<>();    int maxSize = config.getMaxSearchResults() == null ? searchRequest.getSize() : config.getMaxSearchResults();    for (int i = searchRequest.getFrom(); i < response.size() && finalResp.size() <= maxSize; ++i) {        finalResp.add(response.get(i));    }    ret.setTotal(response.size());    ret.setResults(finalResp);    Map<String, Map<String, Long>> facetCounts = new HashMap<>();    List<String> facetFields = searchRequest.getFacetFields();    if (facetFields != null) {        for (String facet : facetFields) {            facetCounts.put(facet, FACET_COUNTS.get(facet));        }        ret.setFacetCounts(facetCounts);    }    return ret;}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    GroupResponse groupResponse = new GroupResponse();    groupResponse.setGroupedBy(groupRequest.getGroups().get(0).getField());    groupResponse.setGroupResults(getGroupResults(groupRequest.getGroups(), 0));    return groupResponse;}
0
private List<GroupResult> getGroupResults(List<Group> groups, int index)
{    Group group = groups.get(index);    GroupResult groupResult = new GroupResult();    groupResult.setKey(group.getField() + "_value");    if (index < groups.size() - 1) {        groupResult.setGroupedBy(groups.get(index + 1).getField());        groupResult.setGroupResults(getGroupResults(groups, index + 1));    } else {        groupResult.setScore(50.0);    }    groupResult.setTotal(10);    return Collections.singletonList(groupResult);}
0
public int compare(Comparable o1, Comparable o2)
{    int result = ComparisonChain.start().compare(o1, o2, Ordering.natural().nullsLast()).result();    return order == SortOrder.ASC ? result : -1 * result;}
0
private static Comparator<SearchResult> sorted(final List<SortField> fields)
{    return (o1, o2) -> {        ComparisonChain chain = ComparisonChain.start();        for (SortField field : fields) {            Comparable f1 = (Comparable) o1.getSource().get(field.getField());            Comparable f2 = (Comparable) o2.getSource().get(field.getField());            chain = chain.compare(f1, f2, new ComparableComparator(field.getSortOrder()));        }        return chain.result();    };}
0
private static boolean isMatch(String query, Map<String, Object> doc)
{    if (query == null) {        return false;    }    if (query.equals("*")) {        return true;    }    if (query.contains(":")) {        Iterable<String> splits = Splitter.on(":").split(query.trim());        String field = Iterables.getFirst(splits, "");        String val = Iterables.getLast(splits, "");                if (val == null) {            return false;        }                String nestingField = null;        if (field.contains("|")) {            Iterable<String> fieldSplits = Splitter.on('|').split(field);            nestingField = Iterables.getFirst(fieldSplits, null);            field = Iterables.getLast(fieldSplits, null);        }        if (nestingField == null) {                        Object o = doc.get(field);            return val.equals(o);        } else {                        @SuppressWarnings("unchecked")            List<Map<String, Object>> nestedList = (List<Map<String, Object>>) doc.get(nestingField);            if (nestedList == null) {                return false;            } else {                for (Map<String, Object> nestedEntry : nestedList) {                    if (val.equals(nestedEntry.get(field))) {                        return true;                    }                }            }        }    }    return false;}
0
public static Map<String, Object> parse(String doc)
{    try {        return JSONUtils.INSTANCE.load(doc, JSONUtils.MAP_SUPPLIER);    } catch (IOException e) {        throw new IllegalStateException(e.getMessage(), e);    }}
0
public void init(AccessConfig config)
{    this.config = config;}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    for (Map.Entry<String, List<String>> kv : BACKING_STORE.entrySet()) {        if (kv.getKey().startsWith(sensorType)) {            for (String doc : kv.getValue()) {                Map<String, Object> docParsed = parse(doc);                if (docParsed.getOrDefault(Constants.GUID, "").equals(guid)) {                    return new Document(doc, guid, sensorType, 0L);                }            }        }    }    return null;}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    List<Document> documents = new ArrayList<>();    for (Map.Entry<String, List<String>> kv : BACKING_STORE.entrySet()) {        for (String doc : kv.getValue()) {            Map<String, Object> docParsed = parse(doc);            String guid = (String) docParsed.getOrDefault(Constants.GUID, "");            for (GetRequest getRequest : getRequests) {                if (getRequest.getGuid().equals(guid)) {                    documents.add(new Document(doc, guid, getRequest.getSensorType(), 0L));                }            }        }    }    return documents;}
0
public Document update(Document update, Optional<String> index) throws IOException
{    for (Map.Entry<String, List<String>> kv : BACKING_STORE.entrySet()) {        if (kv.getKey().startsWith(update.getSensorType())) {            for (Iterator<String> it = kv.getValue().iterator(); it.hasNext(); ) {                String doc = it.next();                Map<String, Object> docParsed = parse(doc);                if (docParsed.getOrDefault(Constants.GUID, "").equals(update.getGuid())) {                    it.remove();                }            }            kv.getValue().add(JSONUtils.INSTANCE.toJSON(update.getDocument(), true));        }    }    return update;}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) throws IOException
{    for (Map.Entry<Document, Optional<String>> update : updates.entrySet()) {        update(update.getKey(), update.getValue());    }    return updates;}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    Map<String, FieldType> indexColumnMetadata = new HashMap<>();    for (String index : indices) {        if (COLUMN_METADATA.containsKey(index)) {            Map<String, FieldType> columnMetadata = COLUMN_METADATA.get(index);            for (Entry entry : columnMetadata.entrySet()) {                String field = (String) entry.getKey();                FieldType type = (FieldType) entry.getValue();                if (indexColumnMetadata.containsKey(field)) {                    if (!type.equals(indexColumnMetadata.get(field))) {                        indexColumnMetadata.put(field, FieldType.OTHER);                    }                } else {                    indexColumnMetadata.put(field, type);                }            }        }    }    return indexColumnMetadata;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public static void setColumnMetadata(Map<String, Map<String, FieldType>> columnMetadata)
{    Map<String, Map<String, FieldType>> columnMetadataMap = new HashMap<>();    for (Map.Entry<String, Map<String, FieldType>> e : columnMetadata.entrySet()) {        columnMetadataMap.put(e.getKey(), Collections.unmodifiableMap(e.getValue()));    }    COLUMN_METADATA = columnMetadataMap;}
0
public static void setFacetCounts(Map<String, Map<String, Long>> facetCounts)
{    Map<String, Map<String, Long>> facetCountsMap = new HashMap<>();    for (Map.Entry<String, Map<String, Long>> e : facetCounts.entrySet()) {        facetCountsMap.put(e.getKey(), Collections.unmodifiableMap(e.getValue()));    }    FACET_COUNTS = facetCountsMap;}
0
public static void load(Map<String, List<String>> backingStore)
{    BACKING_STORE = backingStore;}
0
public static void clear()
{    BACKING_STORE.clear();    COLUMN_METADATA.clear();    FACET_COUNTS.clear();}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    return indexDao.search(searchRequest);}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    return indexDao.group(groupRequest);}
0
public void init(AccessConfig config)
{}
0
public void init(IndexDao indexDao, Optional<String> threatSort)
{    this.indexDao = indexDao;    this.metaAlertRetrieveLatestDao = new InMemoryMetaAlertRetrieveLatestDao(indexDao);    Supplier<Map<String, Object>> globalConfigSupplier = () -> new HashMap<>();    MetaAlertConfig config = new MetaAlertConfig(METAALERT_INDEX, null, globalConfigSupplier) {        @Override        protected String getDefaultThreatTriageField() {            return MetaAlertConstants.THREAT_FIELD_DEFAULT;        }        @Override        protected String getDefaultSourceTypeField() {            return SENSOR_TYPE;        }    };    this.metaAlertUpdateDao = new InMemoryMetaAlertUpdateDao(indexDao, metaAlertRetrieveLatestDao, config, -1);}
0
protected String getDefaultThreatTriageField()
{    return MetaAlertConstants.THREAT_FIELD_DEFAULT;}
0
protected String getDefaultSourceTypeField()
{    return SENSOR_TYPE;}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    return indexDao.getLatest(guid, sensorType);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    return indexDao.getAllLatest(getRequests);}
0
public Document update(Document update, Optional<String> index) throws IOException
{    return indexDao.update(update, index);}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates)
{    throw new UnsupportedOperationException("InMemoryMetaAlertDao can't do bulk updates");}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    return indexDao.getColumnMetadata(indices);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Optional<Map<String, Object>> getLatestResult(GetRequest request) throws IOException
{    return indexDao.getLatestResult(request);}
0
public Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    return indexDao.patch(retrieveLatestDao, request, timestamp);}
0
public SearchResponse getAllMetaAlertsForAlert(String guid) throws InvalidSearchException
{    SearchRequest request;    try {        String replacedQuery = metaAlertsForAlertQuery.replace("${GUID}", guid);        request = JSONUtils.INSTANCE.load(replacedQuery, SearchRequest.class);    } catch (IOException e) {        throw new InvalidSearchException("Unable to process query:", e);    }    return search(request);}
0
public Document createMetaAlert(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    return metaAlertUpdateDao.createMetaAlert(request);}
0
public Document addAlertsToMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.addAlertsToMetaAlert(metaAlertGuid, alertRequests);}
0
public Document removeAlertsFromMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.removeAlertsFromMetaAlert(metaAlertGuid, alertRequests);}
0
public Document updateMetaAlertStatus(String metaAlertGuid, MetaAlertStatus status) throws IOException
{    return metaAlertUpdateDao.updateMetaAlertStatus(metaAlertGuid, status);}
0
public static void clear()
{    InMemoryDao.clear();}
0
public Document createMetaAlert(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    List<GetRequest> alertRequests = request.getAlerts();    if (alertRequests.isEmpty()) {        return null;    }        Iterable<Document> alerts = indexDao.getAllLatest(alertRequests);    Document metaAlert = buildCreateDocument(alerts, request.getGroups(), MetaAlertConstants.ALERT_FIELD);    metaAlert.getDocument().put(getConfig().getSourceTypeField(), MetaAlertConstants.METAALERT_TYPE);    return metaAlert;}
0
public Document update(Document update, Optional<String> index) throws IOException
{    return indexDao.update(update, index);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return null;}
0
public void setup()
{    dao = new TestLuceneMetaAlertUpdateDao();}
0
protected String getDefaultThreatTriageField()
{    return THREAT_FIELD_DEFAULT.replace(':', '.');}
0
protected String getDefaultSourceTypeField()
{    return Constants.SENSOR_TYPE;}
0
public Document getLatest(String guid, String sensorType)
{    return documents.get(guid);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests)
{    return null;}
0
public Document update(Document update, Optional<String> index)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp)
{    return null;}
0
public Document createMetaAlert(MetaAlertCreateRequest request)
{    return null;}
0
public void testBatchUpdateThrowsException()
{    dao.batchUpdate(null);}
0
public void testPatchNotAllowedAlert() throws ParseException
{    PatchRequest pr = new PatchRequest();    Map<String, Object> patch = (JSONObject) new JSONParser().parse(alertPatchRequest);    pr.setPatch(Collections.singletonList((JSONObject) ((JSONArray) patch.get("patch")).get(0)));    assertFalse(dao.isPatchAllowed(pr));}
0
public void testPatchNotAllowedStatus() throws ParseException
{    PatchRequest pr = new PatchRequest();    Map<String, Object> patch = (JSONObject) new JSONParser().parse(statusPatchRequest);    pr.setPatch(Collections.singletonList((JSONObject) ((JSONArray) patch.get("patch")).get(0)));    assertFalse(dao.isPatchAllowed(pr));}
0
public void testPatchAllowedName() throws ParseException
{    PatchRequest pr = new PatchRequest();    Map<String, Object> patch = (JSONObject) new JSONParser().parse(namePatchRequest);    pr.setPatch(Collections.singletonList((JSONObject) ((JSONArray) patch.get("patch")).get(0)));    assertTrue(dao.isPatchAllowed(pr));}
0
public void testUpdateSingle() throws IOException
{    Map<Document, Optional<String>> updates = new HashMap<>();    Document document = new Document(new HashMap<>(), "guid", "sensor", 0L);    updates.put(document, Optional.empty());    dao.update(updates);    verify(indexDao, times(1)).update(document, Optional.empty());}
0
public void testUpdateMultiple() throws IOException
{    Map<Document, Optional<String>> updates = new HashMap<>();    Document documentOne = new Document(new HashMap<>(), "guid", "sensor", 0L);    updates.put(documentOne, Optional.empty());    Document documentTwo = new Document(new HashMap<>(), "guid2", "sensor", 0L);    updates.put(documentTwo, Optional.empty());    dao.update(updates);    verify(indexDao, times(1)).batchUpdate(updates);}
0
public void testBuildAddAlertToMetaAlertUpdatesEmpty()
{    Document metaDoc = new Document(new HashMap<>(), METAALERT_GUID, METAALERT_TYPE, 0L);    metaDoc.getDocument().put(ALERT_FIELD, getRawMaps(buildChildAlerts(1, METAALERT_GUID, null)));    Map<Document, Optional<String>> actual = dao.buildAddAlertToMetaAlertUpdates(metaDoc, new ArrayList<>());    assertEquals(0, actual.size());}
0
public void testBuildAddAlertToMetaAlertUpdates()
{    List<Document> alerts = buildChildAlerts(1, METAALERT_GUID, null);    Document metaDoc = buildMetaAlert(alerts);    List<Document> newAlerts = buildChildAlerts(2, null, "new_");    Map<Document, Optional<String>> actual = dao.buildAddAlertToMetaAlertUpdates(metaDoc, newAlerts);    assertEquals(3, actual.size());    HashMap<String, Object> expectedExistingAlert = new HashMap<>();    expectedExistingAlert.put(Constants.GUID, "child_0");    expectedExistingAlert.put(METAALERT_FIELD, Collections.singletonList(METAALERT_GUID));    expectedExistingAlert.put(THREAT_FIELD_DEFAULT, 0.0f);    List<Map<String, Object>> expectedAlerts = new ArrayList<>();    expectedAlerts.add(expectedExistingAlert);    expectedAlerts.addAll(getRawMaps(newAlerts));    List<Double> scores = new ArrayList<>();    scores.add(0.0d);    scores.add(0.0d);    scores.add(0.0d);    Map<String, Object> expectedMetaAlertMap = new HashMap<>();    expectedMetaAlertMap.put(Constants.GUID, METAALERT_GUID);    expectedMetaAlertMap.put(ALERT_FIELD, expectedAlerts);    expectedMetaAlertMap.put(THREAT_FIELD_DEFAULT, 0.0f);    expectedMetaAlertMap.putAll(new MetaScores(scores).getMetaScores());    Document expectedMetaAlertDoc = new Document(expectedMetaAlertMap, METAALERT_GUID, METAALERT_TYPE, 0L);    Map<Document, Optional<String>> expected = new HashMap<>();    expected.put(expectedMetaAlertDoc, Optional.of(METAALERT_INDEX));    expected.put(newAlerts.get(0), Optional.empty());    expected.put(newAlerts.get(1), Optional.empty());    assertTrue(updatesMapEquals(expected, actual));}
0
public void testRemoveAlertsFromMetaAlert() throws IOException
{    List<Document> alerts = buildChildAlerts(3, METAALERT_GUID, null);    Document metaDoc = buildMetaAlert(alerts);    List<Document> deletedAlerts = new ArrayList<>();    deletedAlerts.add(alerts.get(0));    deletedAlerts.add(alerts.get(2));    Map<Document, Optional<String>> actual = dao.buildRemoveAlertsFromMetaAlert(metaDoc, deletedAlerts);    assertEquals(3, actual.size());    Map<String, Object> expectedDeletedAlert = new HashMap<>();    expectedDeletedAlert.put(Constants.GUID, "child_0");    expectedDeletedAlert.put(THREAT_FIELD_DEFAULT, 0.0f);    expectedDeletedAlert.put(MetaAlertConstants.METAALERT_FIELD, new ArrayList<>());    Document expectedDeletedDocument = new Document(expectedDeletedAlert, "child_0", "test", 0L);    Map<String, Object> expectedDeletedAlert3 = new HashMap<>();    expectedDeletedAlert3.put(Constants.GUID, "child_2");    expectedDeletedAlert3.put(THREAT_FIELD_DEFAULT, 0.0f);    expectedDeletedAlert3.put(MetaAlertConstants.METAALERT_FIELD, new ArrayList<>());    Document expectedDeletedDocument2 = new Document(expectedDeletedAlert3, "child_2", "test", 0L);    List<Map<String, Object>> expectedAlerts = new ArrayList<>();    expectedAlerts.add(alerts.get(1).getDocument());    Map<String, Object> expectedMetaAlertMap = new HashMap<>();    expectedMetaAlertMap.put(Constants.GUID, METAALERT_GUID);    expectedMetaAlertMap.put(ALERT_FIELD, expectedAlerts);    expectedMetaAlertMap.put(THREAT_FIELD_DEFAULT, 0.0f);    expectedMetaAlertMap.putAll(new MetaScores(Collections.singletonList(0.0d)).getMetaScores());    Document expectedMetaAlertDoc = new Document(expectedMetaAlertMap, METAALERT_GUID, METAALERT_TYPE, 0L);    Map<Document, Optional<String>> expected = new HashMap<>();    expected.put(expectedDeletedDocument, Optional.empty());    expected.put(expectedDeletedDocument2, Optional.empty());    expected.put(expectedMetaAlertDoc, Optional.of(METAALERT_INDEX));    assertTrue(updatesMapEquals(expected, actual));}
0
public void testBuildRemoveAlertsFromMetaAlertThrowsException() throws Exception
{    thrown.expect(IllegalStateException.class);    thrown.expectMessage("Removing these alerts will result in an empty meta alert.  Empty meta alerts are not allowed.");    List<Document> alerts = buildChildAlerts(1, METAALERT_GUID, null);    Document metaDoc = buildMetaAlert(alerts);    dao.buildRemoveAlertsFromMetaAlert(metaDoc, alerts);}
0
public void testRemoveAlertsFromMetaAlertNoChildAlerts()
{    Document empty = new Document(new HashMap<>(), "empty", METAALERT_TYPE, 0L);    boolean actual = dao.removeAlertsFromMetaAlert(empty, Collections.singletonList("child"));    assertFalse(actual);}
0
public void testRemoveAlertsFromMetaAlertEmptyRemoveList()
{    Document metaDoc = new Document(new HashMap<>(), METAALERT_GUID, METAALERT_TYPE, 0L);    metaDoc.getDocument().put(STATUS_FIELD, ACTIVE.getStatusString());    metaDoc.getDocument().put(ALERT_FIELD, new HashMap<String, Object>() {        {            put(Constants.GUID, "child_0");        }    });    boolean actual = dao.removeAlertsFromMetaAlert(metaDoc, new ArrayList<>());    assertFalse(actual);}
0
public void testRemoveAlertsFromMetaAlertEmptyRemoveSingle()
{    Document metaDoc = new Document(new HashMap<>(), METAALERT_GUID, METAALERT_TYPE, 0L);    metaDoc.getDocument().put(STATUS_FIELD, ACTIVE.getStatusString());    List<Map<String, Object>> alerts = new ArrayList<>();    alerts.add(new HashMap<String, Object>() {        {            put(Constants.GUID, "child_0");        }    });    metaDoc.getDocument().put(ALERT_FIELD, alerts);    boolean actual = dao.removeAlertsFromMetaAlert(metaDoc, Collections.singletonList("child_0"));    Document expected = new Document(new HashMap<>(), METAALERT_GUID, METAALERT_TYPE, 0L);    expected.getDocument().put(STATUS_FIELD, ACTIVE.getStatusString());    expected.getDocument().put(ALERT_FIELD, new ArrayList<>());    assertTrue(actual);    assertEquals(expected, metaDoc);}
0
public void testBuildStatusChangeUpdatesToInactive()
{    List<Document> alerts = buildChildAlerts(2, METAALERT_GUID, null);    Map<String, Object> metaAlertMap = new HashMap<>();    metaAlertMap.put(ALERT_FIELD, getRawMaps(alerts));    metaAlertMap.put(Constants.GUID, METAALERT_GUID);    metaAlertMap.put(STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString());    Document metaDoc = new Document(metaAlertMap, METAALERT_GUID, METAALERT_TYPE, 0L);    Map<Document, Optional<String>> actual = dao.buildStatusChangeUpdates(metaDoc, alerts, MetaAlertStatus.INACTIVE);    assertEquals(3, actual.size());    List<Document> expectedDeletedAlerts = buildChildAlerts(2, null, null);    List<Map<String, Object>> expectedAlerts = new ArrayList<>();    expectedAlerts.add(alerts.get(0).getDocument());    expectedAlerts.add(alerts.get(1).getDocument());    Map<String, Object> expectedMetaAlertMap = new HashMap<>();    expectedMetaAlertMap.put(Constants.GUID, METAALERT_GUID);    expectedMetaAlertMap.put(ALERT_FIELD, expectedAlerts);    expectedMetaAlertMap.put(STATUS_FIELD, MetaAlertStatus.INACTIVE.getStatusString());    Document expectedMetaAlertDoc = new Document(expectedMetaAlertMap, METAALERT_GUID, METAALERT_TYPE, 0L);    Map<Document, Optional<String>> expected = new HashMap<>();    expected.put(expectedMetaAlertDoc, Optional.of(METAALERT_INDEX));    expected.put(expectedDeletedAlerts.get(0), Optional.empty());    expected.put(expectedDeletedAlerts.get(1), Optional.empty());    assertTrue(updatesMapEquals(expected, actual));}
0
public void testBuildStatusChangeUpdatesToActive()
{    List<Document> alerts = buildChildAlerts(2, METAALERT_GUID, null);    Map<String, Object> metaAlertMap = new HashMap<>();    metaAlertMap.put(ALERT_FIELD, getRawMaps(alerts));    metaAlertMap.put(Constants.GUID, METAALERT_GUID);    metaAlertMap.put(STATUS_FIELD, MetaAlertStatus.INACTIVE.getStatusString());    Document metaDoc = new Document(metaAlertMap, METAALERT_GUID, METAALERT_TYPE, 0L);    Map<Document, Optional<String>> actual = dao.buildStatusChangeUpdates(metaDoc, alerts, MetaAlertStatus.ACTIVE);    List<Map<String, Object>> expectedAlerts = new ArrayList<>();    expectedAlerts.add(alerts.get(0).getDocument());    expectedAlerts.add(alerts.get(1).getDocument());    Map<String, Object> expectedMetaAlertMap = new HashMap<>();    expectedMetaAlertMap.put(ALERT_FIELD, expectedAlerts);    expectedMetaAlertMap.put(Constants.GUID, METAALERT_GUID);    expectedMetaAlertMap.put(STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString());    Document expectedMetaAlertDoc = new Document(expectedMetaAlertMap, METAALERT_GUID, METAALERT_TYPE, 0L);    Map<Document, Optional<String>> expected = new HashMap<>();    expected.put(expectedMetaAlertDoc, Optional.of(METAALERT_INDEX));    assertTrue(updatesMapEquals(expected, actual));}
0
public void testRemoveAlertsFromMetaAlertEmptyRemoveMultiple()
{    Document metDoc = new Document(new HashMap<>(), METAALERT_GUID, METAALERT_TYPE, 0L);    metDoc.getDocument().put(STATUS_FIELD, ACTIVE.getStatusString());    List<Document> alerts = buildChildAlerts(3, null, null);    metDoc.getDocument().put(ALERT_FIELD, getRawMaps(alerts));    List<String> removeGuids = new ArrayList<>();    removeGuids.add("child_0");    removeGuids.add("child_2");    removeGuids.add("child_doesn't_exist");    boolean actual = dao.removeAlertsFromMetaAlert(metDoc, removeGuids);        Document expected = new Document(new HashMap<>(), METAALERT_GUID, METAALERT_TYPE, 0L);    expected.getDocument().put(STATUS_FIELD, ACTIVE.getStatusString());    List<Map<String, Object>> alertsExpected = new ArrayList<>();    alertsExpected.add(new HashMap<String, Object>() {        {            put(METAALERT_FIELD, new ArrayList<>());            put(Constants.GUID, "child_1");            put(THREAT_FIELD_DEFAULT, 0.0f);        }    });    expected.getDocument().put(ALERT_FIELD, alertsExpected);    assertEquals(expected, metDoc);    assertTrue(actual);}
0
public void testRemoveAlertsFromMetaAlertInactive() throws IOException
{    dao.removeAlertsFromMetaAlert(INACTIVE.getStatusString(), null);}
0
public void testRemoveMetaAlertFromAlertSuccess()
{    List<String> metaAlertGuids = new ArrayList<>();    metaAlertGuids.add("metaalert1");    metaAlertGuids.add("metaalert2");    Map<String, Object> alertFields = new HashMap<>();    alertFields.put(METAALERT_FIELD, metaAlertGuids);    Document alert = new Document(alertFields, "alert", "test", 0L);    Document expected = new Document(new HashMap<>(), "alert", "test", 0L);    List<String> expectedMetaAlertGuids = new ArrayList<>();    expectedMetaAlertGuids.add("metaalert2");    expected.getDocument().put(METAALERT_FIELD, expectedMetaAlertGuids);    boolean actual = dao.removeMetaAlertFromAlert("metaalert1", alert);    assertTrue(actual);    assertEquals(expected, alert);}
0
public void testRemoveMetaAlertFromAlertMissing()
{    List<String> metaAlertGuids = new ArrayList<>();    metaAlertGuids.add("metaalert1");    metaAlertGuids.add("metaalert2");    Map<String, Object> alertFields = new HashMap<>();    alertFields.put(METAALERT_FIELD, metaAlertGuids);    Document alert = new Document(alertFields, "alert", "test", 0L);    boolean actual = dao.removeMetaAlertFromAlert("metaalert3", alert);    assertFalse(actual);}
0
public void testAddMetaAlertToAlertEmpty()
{    Map<String, Object> alertFields = new HashMap<>();    alertFields.put(METAALERT_FIELD, new ArrayList<>());    Document alert = new Document(alertFields, "alert", "test", 0L);    Document expected = new Document(new HashMap<>(), "alert", "test", 0L);    List<String> expectedMetaAlertGuids = new ArrayList<>();    expectedMetaAlertGuids.add("metaalert1");    expected.getDocument().put(METAALERT_FIELD, expectedMetaAlertGuids);    boolean actual = dao.addMetaAlertToAlert("metaalert1", alert);    assertTrue(actual);    assertEquals(expected, alert);}
0
public void testAddMetaAlertToAlertNonEmpty()
{    List<String> metaAlertGuids = new ArrayList<>();    metaAlertGuids.add("metaalert1");    Map<String, Object> alertFields = new HashMap<>();    alertFields.put(METAALERT_FIELD, metaAlertGuids);    Document alert = new Document(alertFields, "alert", "test", 0L);    Document expected = new Document(new HashMap<>(), "alert", "test", 0L);    List<String> expectedMetaAlertGuids = new ArrayList<>();    expectedMetaAlertGuids.add("metaalert1");    expectedMetaAlertGuids.add("metaalert2");    expected.getDocument().put(METAALERT_FIELD, expectedMetaAlertGuids);    boolean actual = dao.addMetaAlertToAlert("metaalert2", alert);    assertTrue(actual);    assertEquals(expected, alert);}
0
public void testAddMetaAlertToAlertDuplicate()
{    List<String> metaAlertGuids = new ArrayList<>();    metaAlertGuids.add("metaalert1");    Map<String, Object> alertFields = new HashMap<>();    alertFields.put(METAALERT_FIELD, metaAlertGuids);    Document alert = new Document(alertFields, "alert", "test", 0L);    boolean actual = dao.addMetaAlertToAlert("metaalert1", alert);    assertFalse(actual);}
0
public void testBuildCreateDocumentSingleAlert()
{    List<String> groups = new ArrayList<>();    groups.add("group_one");    groups.add("group_two");        Map<String, Object> alertOne = new HashMap<>();    alertOne.put(Constants.GUID, "alert_one");    alertOne.put(THREAT_FIELD_DEFAULT, 10.0d);    List<Document> alerts = new ArrayList<Document>() {        {            add(new Document(alertOne, "", "", 0L));        }    };        Document actual = dao.buildCreateDocument(alerts, groups, ALERT_FIELD);    ArrayList<Map<String, Object>> alertList = new ArrayList<>();    alertList.add(alertOne);    Map<String, Object> actualDocument = actual.getDocument();    assertEquals(MetaAlertStatus.ACTIVE.getStatusString(), actualDocument.get(STATUS_FIELD));    assertEquals(alertList, actualDocument.get(ALERT_FIELD));    assertEquals(groups, actualDocument.get(GROUPS_FIELD));        UUID.fromString((String) actualDocument.get(Constants.GUID));}
0
public void testBuildCreateDocumentMultipleAlerts()
{    List<String> groups = new ArrayList<>();    groups.add("group_one");    groups.add("group_two");        Map<String, Object> alertOne = new HashMap<>();    alertOne.put(Constants.GUID, "alert_one");    alertOne.put(THREAT_FIELD_DEFAULT, 10.0d);        Map<String, Object> alertTwo = new HashMap<>();    alertTwo.put(Constants.GUID, "alert_one");    alertTwo.put(THREAT_FIELD_DEFAULT, 5.0d);    List<Document> alerts = new ArrayList<>();    alerts.add(new Document(alertOne, "", "", 0L));    alerts.add(new Document(alertTwo, "", "", 0L));        Document actual = dao.buildCreateDocument(alerts, groups, ALERT_FIELD);    ArrayList<Map<String, Object>> alertList = new ArrayList<>();    alertList.add(alertOne);    alertList.add(alertTwo);    Map<String, Object> actualDocument = actual.getDocument();    assertNotNull(actualDocument.get(Fields.TIMESTAMP.getName()));    assertEquals(alertList, actualDocument.get(ALERT_FIELD));    assertEquals(groups, actualDocument.get(GROUPS_FIELD));        UUID.fromString((String) actualDocument.get(Constants.GUID));}
0
public void addAlertsToMetaAlertShouldThrowExceptionOnMissingMetaAlert() throws Exception
{    thrown.expect(IOException.class);    thrown.expectMessage("Unable to add alerts to meta alert.  Meta alert with guid some_guid cannot be found.");    dao.addAlertsToMetaAlert("some_guid", new ArrayList<>());}
0
public void removeAlertsFromMetaAlertShouldThrowExceptionOnMissingMetaAlert() throws Exception
{    thrown.expect(IOException.class);    thrown.expectMessage("Unable to remove alerts from meta alert.  Meta alert with guid some_guid cannot be found.");    dao.removeAlertsFromMetaAlert("some_guid", new ArrayList<>());}
0
public void updateMetaAlertStatusShouldThrowExceptionOnMissingMetaAlert() throws Exception
{    thrown.expect(IOException.class);    thrown.expectMessage("Unable to update meta alert status.  Meta alert with guid some_guid cannot be found.");    dao.updateMetaAlertStatus("some_guid", MetaAlertStatus.INACTIVE);}
0
protected boolean updatesMapEquals(Map<Document, Optional<String>> expected, Map<Document, Optional<String>> actual)
{    Entry<Document, Optional<String>> expectedMetaEntry;    Entry<Document, Optional<String>> actualMetaEntry;    expectedMetaEntry = findMetaEntry(expected);    actualMetaEntry = findMetaEntry(actual);        if (!metaAlertDocumentEquals(expectedMetaEntry.getKey(), actualMetaEntry.getKey())) {        return false;    } else {                return removeMetaEntry(expected).equals(removeMetaEntry(actual));    }}
0
protected Entry<Document, Optional<String>> findMetaEntry(Map<Document, Optional<String>> expected)
{    for (Entry<Document, Optional<String>> entry : expected.entrySet()) {        if (entry.getKey().getSensorType().equals(METAALERT_TYPE)) {            return entry;        }    }    return null;}
0
protected Map<Document, Optional<String>> removeMetaEntry(Map<Document, Optional<String>> updates)
{    Map<Document, Optional<String>> filteredUpdates = new HashMap<>();    for (Entry<Document, Optional<String>> entry : updates.entrySet()) {        if (!(entry.getKey().getSensorType().equals(METAALERT_TYPE))) {            filteredUpdates.put(entry.getKey(), entry.getValue());        }    }    return filteredUpdates;}
0
private boolean metaAlertDocumentEquals(Document expected, Document actual)
{    if (!expected.getGuid().equals(actual.getGuid())) {        return false;    }    if (!expected.getSensorType().equals(actual.getSensorType())) {        return false;    }    if (!expected.getTimestamp().equals(actual.getTimestamp())) {        return false;    }        Map<String, Object> expectedDocument = expected.getDocument();    Map<String, Object> actualDocument = actual.getDocument();    if (expectedDocument.size() != actualDocument.size()) {        return false;    }    for (Entry<String, Object> entry : expectedDocument.entrySet()) {        Object value = entry.getValue();        Object actualValue = actual.getDocument().get(entry.getKey());        if (value instanceof Float) {            if (!MathUtils.equals((Float) value, (Float) actualValue, EPS)) {                return false;            }        } else if (value instanceof Double) {            if (!MathUtils.equals((Double) value, (Double) actualValue, EPS)) {                return false;            }        } else {            if (!value.equals(actual.getDocument().get(entry.getKey()))) {                return false;            }        }    }    return true;}
0
protected List<Document> buildChildAlerts(int num, String parent, String guidPrefix)
{    String prefix = guidPrefix != null ? guidPrefix : DEFAULT_PREFIX;    List<Document> alerts = new ArrayList<>();    for (int i = 0; i < num; i++) {        HashMap<String, Object> fields = new HashMap<>();        fields.put(Constants.GUID, prefix + i);        fields.put(THREAT_FIELD_DEFAULT, 0.0f);        if (parent != null) {            fields.put(METAALERT_FIELD, Collections.singletonList(parent));        } else {            fields.put(METAALERT_FIELD, new ArrayList<>());        }        alerts.add(new Document(fields, prefix + i, "test", 0L));    }    return alerts;}
0
protected List<Map<String, Object>> getRawMaps(List<Document> documents)
{    List<Map<String, Object>> rawMaps = new ArrayList<>();    for (Document document : documents) {        rawMaps.add(document.getDocument());    }    return rawMaps;}
0
protected Document buildMetaAlert(List<Document> alerts)
{    Map<String, Object> metaAlertMap = new HashMap<>();    metaAlertMap.put(ALERT_FIELD, getRawMaps(alerts));    metaAlertMap.put(Constants.GUID, METAALERT_GUID);    return new Document(metaAlertMap, METAALERT_GUID, METAALERT_TYPE, 0L);}
0
public void shouldGetAllMetaAlertsForAlert() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(3);    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        List<Map<String, Object>> metaAlerts = buildMetaAlerts(12, MetaAlertStatus.ACTIVE, Optional.of(Collections.singletonList(alerts.get(0))));    metaAlerts.add(buildMetaAlert("meta_active_12", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(2)))));    metaAlerts.add(buildMetaAlert("meta_inactive", MetaAlertStatus.INACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(2)))));        addRecords(metaAlerts, getMetaAlertIndex(), METAALERT_TYPE);        List<GetRequest> createdDocs = metaAlerts.stream().map(metaAlert -> new GetRequest((String) metaAlert.get(Constants.GUID), METAALERT_TYPE)).collect(Collectors.toList());    createdDocs.addAll(alerts.stream().map(alert -> new GetRequest((String) alert.get(Constants.GUID), SENSOR_NAME)).collect(Collectors.toList()));    findCreatedDocs(createdDocs);    {                SearchResponse searchResponse0 = metaDao.getAllMetaAlertsForAlert("message_0");        List<SearchResult> searchResults0 = searchResponse0.getResults();        Assert.assertEquals(13, searchResults0.size());        Set<Map<String, Object>> resultSet = new HashSet<>();        Iterables.addAll(resultSet, Iterables.transform(searchResults0, r -> r.getSource()));        StringBuffer reason = new StringBuffer("Unable to find " + metaAlerts.get(0) + "\n");        reason.append(Joiner.on("\n").join(resultSet));        Assert.assertTrue(reason.toString(), resultSet.contains(metaAlerts.get(0)));                SearchResponse searchResponse1 = metaDao.getAllMetaAlertsForAlert("message_1");        List<SearchResult> searchResults1 = searchResponse1.getResults();        Assert.assertEquals(0, searchResults1.size());                SearchResponse searchResponse2 = metaDao.getAllMetaAlertsForAlert("message_2");        List<SearchResult> searchResults2 = searchResponse2.getResults();        Assert.assertEquals(1, searchResults2.size());        Assert.assertEquals(metaAlerts.get(12), searchResults2.get(0).getSource());    }}
0
public void shouldSortByThreatTriageScore() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(2);    alerts.get(0).put(METAALERT_FIELD, "meta_active_0");    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        List<Map<String, Object>> metaAlerts = buildMetaAlerts(1, MetaAlertStatus.ACTIVE, Optional.of(Collections.singletonList(alerts.get(0))));        addRecords(metaAlerts, getMetaAlertIndex(), METAALERT_TYPE);        List<GetRequest> createdDocs = metaAlerts.stream().map(metaAlert -> new GetRequest((String) metaAlert.get(Constants.GUID), METAALERT_TYPE)).collect(Collectors.toList());    createdDocs.addAll(alerts.stream().map(alert -> new GetRequest((String) alert.get(Constants.GUID), SENSOR_NAME)).collect(Collectors.toList()));    findCreatedDocs(createdDocs);        SortField sf = new SortField();    sf.setField(getThreatTriageField());    sf.setSortOrder(SortOrder.DESC.getSortOrder());    SearchRequest sr = new SearchRequest();    sr.setQuery("*:*");    sr.setSize(5);    sr.setIndices(Arrays.asList(getTestIndexName(), METAALERT_TYPE));    sr.setSort(Collections.singletonList(sf));    SearchResponse result = metaDao.search(sr);    List<SearchResult> results = result.getResults();    Assert.assertEquals(2, results.size());    Assert.assertEquals("meta_active_0", results.get((0)).getSource().get(Constants.GUID));    Assert.assertEquals("message_1", results.get((1)).getSource().get(Constants.GUID));        SortField sfAsc = new SortField();    sfAsc.setField(getThreatTriageField());    sfAsc.setSortOrder(SortOrder.ASC.getSortOrder());    SearchRequest srAsc = new SearchRequest();    srAsc.setQuery("*:*");    srAsc.setSize(2);    srAsc.setIndices(Arrays.asList(getTestIndexName(), METAALERT_TYPE));    srAsc.setSort(Collections.singletonList(sfAsc));    result = metaDao.search(srAsc);    results = result.getResults();    Assert.assertEquals("message_1", results.get((0)).getSource().get(Constants.GUID));    Assert.assertEquals("meta_active_0", results.get((1)).getSource().get(Constants.GUID));    Assert.assertEquals(2, results.size());}
0
public void getAllMetaAlertsForAlertShouldThrowExceptionForEmptyGuid() throws Exception
{    try {        metaDao.getAllMetaAlertsForAlert("");        Assert.fail("An exception should be thrown for empty guid");    } catch (InvalidSearchException ise) {        Assert.assertEquals("Guid cannot be empty", ise.getMessage());    }}
0
public void shouldCreateMetaAlert() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(3);    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME)));    {        MetaAlertCreateRequest metaAlertCreateRequest = new MetaAlertCreateRequest() {            {                setAlerts(new ArrayList<GetRequest>() {                    {                        add(new GetRequest("message_1", SENSOR_NAME));                        add(new GetRequest("message_2", SENSOR_NAME, getTestIndexFullName()));                    }                });                setGroups(Collections.singletonList("group"));            }        };        Document actualMetaAlert = metaDao.createMetaAlert(metaAlertCreateRequest);                Map<String, Object> expectedMetaAlert = new HashMap<>();        expectedMetaAlert.put(Constants.GUID, actualMetaAlert.getGuid());        expectedMetaAlert.put(getSourceTypeField(), METAALERT_TYPE);        expectedMetaAlert.put(STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString());                @SuppressWarnings("unchecked")        List<Map<String, Object>> metaAlertAlerts = new ArrayList<>();                Map<String, Object> expectedAlert1 = alerts.get(1);        expectedAlert1.put(METAALERT_FIELD, Collections.singletonList(actualMetaAlert.getGuid()));        metaAlertAlerts.add(expectedAlert1);        Map<String, Object> expectedAlert2 = alerts.get(2);        expectedAlert2.put(METAALERT_FIELD, Collections.singletonList(actualMetaAlert.getGuid()));        metaAlertAlerts.add(expectedAlert2);        expectedMetaAlert.put(ALERT_FIELD, metaAlertAlerts);                expectedMetaAlert.put("average", 1.5d);        expectedMetaAlert.put("min", 1.0d);        expectedMetaAlert.put("median", 1.5d);        expectedMetaAlert.put("max", 2.0d);        expectedMetaAlert.put("count", 2);        expectedMetaAlert.put("sum", 3.0d);        expectedMetaAlert.put(getThreatTriageField(), 3.0d);        {                        assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());            findCreatedDoc(actualMetaAlert.getGuid(), METAALERT_TYPE);        }        {                        Document alert = metaDao.getLatest("message_0", SENSOR_NAME);            Assert.assertEquals(4, alert.getDocument().size());            Assert.assertNull(alert.getDocument().get(METAALERT_FIELD));        }        {                        Map<String, Object> expectedAlert = new HashMap<>(alerts.get(1));            expectedAlert.put(METAALERT_FIELD, Collections.singletonList(actualMetaAlert.getGuid()));            findUpdatedDoc(expectedAlert, "message_1", SENSOR_NAME);        }        {                        Map<String, Object> expectedAlert = new HashMap<>(alerts.get(2));            expectedAlert.put(METAALERT_FIELD, Collections.singletonList(actualMetaAlert.getGuid()));            findUpdatedDoc(expectedAlert, "message_2", SENSOR_NAME);        }    }}
0
public void shouldAddAlertsToMetaAlert() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(4);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        Map<String, Object> metaAlert = buildMetaAlert("meta_alert", MetaAlertStatus.ACTIVE, Optional.of(Collections.singletonList(alerts.get(0))));    addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME), new GetRequest("message_3", SENSOR_NAME), new GetRequest("meta_alert", METAALERT_TYPE)));        Map<String, Object> expectedMetaAlert = new HashMap<>(metaAlert);        @SuppressWarnings("unchecked")    List<Map<String, Object>> metaAlertAlerts = new ArrayList<>((List<Map<String, Object>>) expectedMetaAlert.get(ALERT_FIELD));        Map<String, Object> expectedAlert1 = alerts.get(1);    expectedAlert1.put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    metaAlertAlerts.add(expectedAlert1);    Map<String, Object> expectedAlert2 = alerts.get(2);    expectedAlert2.put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    metaAlertAlerts.add(expectedAlert2);    expectedMetaAlert.put(ALERT_FIELD, metaAlertAlerts);        expectedMetaAlert.put("average", 1.0d);    expectedMetaAlert.put("min", 0.0d);    expectedMetaAlert.put("median", 1.0d);    expectedMetaAlert.put("max", 2.0d);    expectedMetaAlert.put("count", 3);    expectedMetaAlert.put("sum", 3.0d);    expectedMetaAlert.put(getThreatTriageField(), 3.0d);    {                Document actualMetaAlert = metaDao.addAlertsToMetaAlert("meta_alert", Arrays.asList(new GetRequest("message_1", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME)));        assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);    }    {                Document actualMetaAlert = metaDao.addAlertsToMetaAlert("meta_alert", Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME)));        assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);    }    {                metaAlertAlerts = (List<Map<String, Object>>) expectedMetaAlert.get(ALERT_FIELD);        Map<String, Object> expectedAlert3 = alerts.get(3);        expectedAlert3.put(METAALERT_FIELD, Collections.singletonList("meta_alert"));        metaAlertAlerts.add(expectedAlert3);        expectedMetaAlert.put(ALERT_FIELD, metaAlertAlerts);        expectedMetaAlert.put("average", 1.5d);        expectedMetaAlert.put("min", 0.0d);        expectedMetaAlert.put("median", 1.5d);        expectedMetaAlert.put("max", 3.0d);        expectedMetaAlert.put("count", 4);        expectedMetaAlert.put("sum", 6.0d);        expectedMetaAlert.put(getThreatTriageField(), 6.0d);        Document actualMetaAlert = metaDao.addAlertsToMetaAlert("meta_alert", Arrays.asList(new GetRequest("message_2", SENSOR_NAME), new GetRequest("message_3", SENSOR_NAME)));        assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);    }}
0
public void shouldRemoveAlertsFromMetaAlert() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(4);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    alerts.get(2).put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    alerts.get(3).put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        Map<String, Object> metaAlert = buildMetaAlert("meta_alert", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(1), alerts.get(2), alerts.get(3))));    addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME), new GetRequest("message_3", SENSOR_NAME), new GetRequest("meta_alert", METAALERT_TYPE)));        Map<String, Object> expectedMetaAlert = new HashMap<>(metaAlert);        List<Map<String, Object>> metaAlertAlerts = new ArrayList<>((List<Map<String, Object>>) expectedMetaAlert.get(ALERT_FIELD));    metaAlertAlerts.remove(0);    metaAlertAlerts.remove(0);    expectedMetaAlert.put(ALERT_FIELD, metaAlertAlerts);        expectedMetaAlert.put("average", 2.5d);    expectedMetaAlert.put("min", 2.0d);    expectedMetaAlert.put("median", 2.5d);    expectedMetaAlert.put("max", 3.0d);    expectedMetaAlert.put("count", 2);    expectedMetaAlert.put("sum", 5.0d);    expectedMetaAlert.put(getThreatTriageField(), 5.0d);    {                Document actualMetaAlert = metaDao.removeAlertsFromMetaAlert("meta_alert", Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME)));        assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);    }    {                Document actualMetaAlert = metaDao.removeAlertsFromMetaAlert("meta_alert", Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME)));        assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);    }    {                metaAlertAlerts = new ArrayList<>((List<Map<String, Object>>) expectedMetaAlert.get(ALERT_FIELD));        metaAlertAlerts.remove(0);        expectedMetaAlert.put(ALERT_FIELD, metaAlertAlerts);        expectedMetaAlert.put("average", 3.0d);        expectedMetaAlert.put("min", 3.0d);        expectedMetaAlert.put("median", 3.0d);        expectedMetaAlert.put("max", 3.0d);        expectedMetaAlert.put("count", 1);        expectedMetaAlert.put("sum", 3.0d);        expectedMetaAlert.put(getThreatTriageField(), 3.0d);        Document actualMetaAlert = metaDao.removeAlertsFromMetaAlert("meta_alert", Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME)));        assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);    }    {                metaAlertAlerts = new ArrayList<>((List<Map<String, Object>>) expectedMetaAlert.get(ALERT_FIELD));        metaAlertAlerts.remove(0);        if (isEmptyMetaAlertList()) {            expectedMetaAlert.put(ALERT_FIELD, metaAlertAlerts);        } else {            expectedMetaAlert.remove(ALERT_FIELD);        }        expectedMetaAlert.put("average", 0.0d);        expectedMetaAlert.put("count", 0);        expectedMetaAlert.put("sum", 0.0d);        expectedMetaAlert.put(getThreatTriageField(), 0.0d);                if (isFiniteDoubleOnly()) {            expectedMetaAlert.put("min", String.valueOf(Double.POSITIVE_INFINITY));            expectedMetaAlert.put("median", String.valueOf(Double.NaN));            expectedMetaAlert.put("max", String.valueOf(Double.NEGATIVE_INFINITY));        } else {            expectedMetaAlert.put("min", Double.POSITIVE_INFINITY);            expectedMetaAlert.put("median", Double.NaN);            expectedMetaAlert.put("max", Double.NEGATIVE_INFINITY);        }                try {            metaDao.removeAlertsFromMetaAlert("meta_alert", Collections.singletonList(new GetRequest("message_3", SENSOR_NAME)));            Assert.fail("Removing these alerts will result in an empty meta alert.  Empty meta alerts are not allowed.");        } catch (IllegalStateException ise) {            Assert.assertEquals("Removing these alerts will result in an empty meta alert.  Empty meta alerts are not allowed.", ise.getMessage());        }    }}
0
public void addRemoveAlertsShouldThrowExceptionForInactiveMetaAlert() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(2);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        Map<String, Object> metaAlert = buildMetaAlert("meta_alert", MetaAlertStatus.INACTIVE, Optional.of(Collections.singletonList(alerts.get(0))));    addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("meta_alert", METAALERT_TYPE)));    {                try {            metaDao.addAlertsToMetaAlert("meta_alert", Collections.singletonList(new GetRequest("message_1", SENSOR_NAME)));            Assert.fail("Adding alerts to an inactive meta alert should throw an exception");        } catch (IllegalStateException ise) {            Assert.assertEquals("Adding alerts to an INACTIVE meta alert is not allowed", ise.getMessage());        }    }    {                try {            metaDao.removeAlertsFromMetaAlert("meta_alert", Collections.singletonList(new GetRequest("message_0", SENSOR_NAME)));            Assert.fail("Removing alerts from an inactive meta alert should throw an exception");        } catch (IllegalStateException ise) {            Assert.assertEquals("Removing alerts from an INACTIVE meta alert is not allowed", ise.getMessage());        }    }}
0
public void shouldUpdateMetaAlertStatus() throws Exception
{    int numChildAlerts = 25;    int numUnrelatedAlerts = 25;    int totalAlerts = numChildAlerts + numUnrelatedAlerts;        List<Map<String, Object>> alerts = buildAlerts(totalAlerts);    List<Map<String, Object>> childAlerts = alerts.subList(0, numChildAlerts);    List<Map<String, Object>> unrelatedAlerts = alerts.subList(numChildAlerts, totalAlerts);    for (Map<String, Object> alert : childAlerts) {        alert.put(METAALERT_FIELD, Collections.singletonList("meta_alert"));    }    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        Map<String, Object> metaAlert = buildMetaAlert("meta_alert", MetaAlertStatus.ACTIVE, Optional.of(childAlerts));        addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);    List<GetRequest> requests = new ArrayList<>();    for (int i = 0; i < numChildAlerts; ++i) {        requests.add(new GetRequest("message_" + i, SENSOR_NAME));    }    requests.add(new GetRequest("meta_alert", METAALERT_TYPE));        findCreatedDocs(requests);    {                Map<String, Object> expectedMetaAlert = new HashMap<>(metaAlert);        expectedMetaAlert.put(STATUS_FIELD, MetaAlertStatus.INACTIVE.getStatusString());        Document actualMetaAlert = metaDao.updateMetaAlertStatus("meta_alert", MetaAlertStatus.INACTIVE);        Assert.assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);        for (int i = 0; i < numChildAlerts; ++i) {            Map<String, Object> expectedAlert = new HashMap<>(childAlerts.get(i));            setEmptiedMetaAlertField(expectedAlert);            findUpdatedDoc(expectedAlert, "message_" + i, SENSOR_NAME);        }                for (int i = 0; i < numUnrelatedAlerts; ++i) {            Map<String, Object> expectedAlert = new HashMap<>(unrelatedAlerts.get(i));                        findUpdatedDoc(expectedAlert, "message_" + (i + numChildAlerts), SENSOR_NAME);        }    }    {                Map<String, Object> expectedMetaAlert = new HashMap<>(metaAlert);        expectedMetaAlert.put(STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString());        Document actualMetaAlert = metaDao.updateMetaAlertStatus("meta_alert", MetaAlertStatus.ACTIVE);        Assert.assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());        findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);        for (int i = 0; i < numChildAlerts; ++i) {            Map<String, Object> expectedAlert = new HashMap<>(alerts.get(i));            expectedAlert.put("metaalerts", Collections.singletonList("meta_alert"));            findUpdatedDoc(expectedAlert, "message_" + i, SENSOR_NAME);        }                for (int i = 0; i < numUnrelatedAlerts; ++i) {            Map<String, Object> expectedAlert = new HashMap<>(unrelatedAlerts.get(i));                        findUpdatedDoc(expectedAlert, "message_" + (i + numChildAlerts), SENSOR_NAME);        }    }    {        {                        Map<String, Object> expectedMetaAlert = new HashMap<>(metaAlert);            expectedMetaAlert.put(STATUS_FIELD, MetaAlertStatus.ACTIVE.getStatusString());            Document actualMetaAlert = metaDao.updateMetaAlertStatus("meta_alert", MetaAlertStatus.ACTIVE);            Assert.assertEquals(expectedMetaAlert, actualMetaAlert.getDocument());            findUpdatedDoc(expectedMetaAlert, "meta_alert", METAALERT_TYPE);            for (int i = 0; i < numChildAlerts; ++i) {                Map<String, Object> expectedAlert = new HashMap<>(alerts.get(i));                expectedAlert.put("metaalerts", Collections.singletonList("meta_alert"));                findUpdatedDoc(expectedAlert, "message_" + i, SENSOR_NAME);            }                        for (int i = 0; i < numUnrelatedAlerts; ++i) {                Map<String, Object> expectedAlert = new HashMap<>(unrelatedAlerts.get(i));                                findUpdatedDoc(expectedAlert, "message_" + (i + numChildAlerts), SENSOR_NAME);            }        }    }}
0
public void shouldSearchByStatus() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(1);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(0).put("ip_src_addr", "192.168.1.1");    alerts.get(0).put("ip_src_port", 8010);        Map<String, Object> activeMetaAlert = buildMetaAlert("meta_active", MetaAlertStatus.ACTIVE, Optional.of(Collections.singletonList(alerts.get(0))));    Map<String, Object> inactiveMetaAlert = buildMetaAlert("meta_inactive", MetaAlertStatus.INACTIVE, Optional.empty());        addRecords(Arrays.asList(activeMetaAlert, inactiveMetaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("meta_active", METAALERT_TYPE), new GetRequest("meta_inactive", METAALERT_TYPE)));    SearchResponse searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("*:*");            setIndices(Collections.singletonList(METAALERT_TYPE));            setFrom(0);            setSize(5);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());    Assert.assertEquals(MetaAlertStatus.ACTIVE.getStatusString(), searchResponse.getResults().get(0).getSource().get(STATUS_FIELD));}
0
public void shouldSortMetaAlertsByAlertStatus() throws Exception
{    final String guid = "meta_alert";    setupTypings();        SortField sortField = new SortField();    sortField.setField("alert_status");    sortField.setSortOrder("asc");        Assert.assertEquals(0, searchForSortedMetaAlerts(sortField).getTotal());        createMetaAlert(guid);    Assert.assertEquals(1, searchForSortedMetaAlerts(sortField).getTotal());        escalateMetaAlert(guid);    Assert.assertEquals(1, searchForSortedMetaAlerts(sortField).getTotal());}
0
private Map<String, Object> createMetaAlert(String guid) throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(2);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList(guid));    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList(guid));    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        Map<String, Object> metaAlert = buildMetaAlert(guid, MetaAlertStatus.ACTIVE, Optional.of(alerts));    addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("meta_alert", METAALERT_TYPE)));    return metaAlert;}
0
private void escalateMetaAlert(String guid) throws Exception
{        Map<String, Object> patch = new HashMap<>();    patch.put("op", "add");    patch.put("path", "/alert_status");    patch.put("value", "escalate");        PatchRequest patchRequest = new PatchRequest();    patchRequest.setGuid(guid);    patchRequest.setIndex(getMetaAlertIndex());    patchRequest.setSensorType(METAALERT_TYPE);    patchRequest.setPatch(Collections.singletonList(patch));    metaDao.patch(metaDao, patchRequest, Optional.of(System.currentTimeMillis()));        assertEventually(() -> {        Document updated = metaDao.getLatest(guid, METAALERT_TYPE);        Assert.assertEquals("escalate", updated.getDocument().get("alert_status"));    });}
0
private SearchResponse searchForSortedMetaAlerts(SortField sortBy) throws InvalidSearchException
{    SearchRequest searchRequest = new SearchRequest();    searchRequest.setFrom(0);    searchRequest.setSize(10);    searchRequest.setIndices(Arrays.asList(getTestIndexName(), METAALERT_TYPE));    searchRequest.setQuery("*:*");    searchRequest.setSort(Collections.singletonList(sortBy));    return metaDao.search(searchRequest);}
0
public void shouldHidesAlertsOnGroup() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(2);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(0).put("ip_src_addr", "192.168.1.1");    alerts.get(0).put("score", 1);    alerts.get(1).put("ip_src_addr", "192.168.1.1");    alerts.get(1).put("score", 10);    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        setupTypings();            findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME)));        Group searchGroup = new Group();    searchGroup.setField("ip_src_addr");    List<Group> groupList = new ArrayList<>();    groupList.add(searchGroup);    GroupResponse groupResponse = metaDao.group(new GroupRequest() {        {            setQuery("ip_src_addr:192.168.1.1");            setIndices(queryIndices);            setScoreField("score");            setGroups(groupList);        }    });        GroupResult result = groupResponse.getGroupResults().get(0);    Assert.assertEquals(1, result.getTotal());    Assert.assertEquals("192.168.1.1", result.getKey());        Assert.assertEquals(10.0d, result.getScore(), 0.0d);}
0
public void shouldUpdateMetaAlertOnAlertUpdate() throws Exception
{    final String expectedFieldValue = "metron";    {                List<Map<String, Object>> alerts = buildAlerts(2);        alerts.get(0).put(METAALERT_FIELD, Arrays.asList("meta_active", "meta_inactive"));        addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);                Map<String, Object> activeMetaAlert = buildMetaAlert("meta_active", MetaAlertStatus.ACTIVE, Optional.of(Collections.singletonList(alerts.get(0))));                Map<String, Object> inactiveMetaAlert = buildMetaAlert("meta_inactive", MetaAlertStatus.INACTIVE, Optional.of(Collections.singletonList(alerts.get(0))));                addRecords(Arrays.asList(activeMetaAlert, inactiveMetaAlert), getMetaAlertIndex(), METAALERT_TYPE);                findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("meta_active", METAALERT_TYPE), new GetRequest("meta_inactive", METAALERT_TYPE)));    }    {                Document message0 = metaDao.getLatest("message_0", SENSOR_NAME);        message0.getDocument().put(NEW_FIELD, expectedFieldValue);        message0.getDocument().put(THREAT_FIELD_DEFAULT, 10.0d);        metaDao.update(message0, Optional.of(getTestIndexFullName()));    }        assertEventually(() -> {        Document message0 = metaDao.getLatest("message_0", SENSOR_NAME);        Assert.assertNotNull(message0);        Assert.assertEquals(expectedFieldValue, message0.getDocument().get(NEW_FIELD));    });        assertEventually(() -> {        Document active = metaDao.getLatest("meta_active", METAALERT_TYPE);        Object value = active.getDocument().get(ALERT_FIELD);        List<Map<String, Object>> children = List.class.cast(value);        Assert.assertNotNull(children);        Assert.assertEquals(1, children.size());        Assert.assertEquals(expectedFieldValue, children.get(0).get(NEW_FIELD));    });        assertEventually(() -> {        Document inactive = metaDao.getLatest("meta_inactive", METAALERT_TYPE);        Object value = inactive.getDocument().get(ALERT_FIELD);        List<Map<String, Object>> children = List.class.cast(value);        Assert.assertNotNull(children);        Assert.assertEquals(1, children.size());        Assert.assertFalse(children.get(0).containsKey(NEW_FIELD));    });}
0
public void shouldThrowExceptionOnMetaAlertUpdate() throws Exception
{    Document metaAlert = new Document(new HashMap<>(), "meta_alert", METAALERT_TYPE, 0L);    try {                metaDao.update(metaAlert, Optional.empty());        Assert.fail("Direct meta alert update should throw an exception");    } catch (UnsupportedOperationException uoe) {        Assert.assertEquals("Meta alerts cannot be directly updated", uoe.getMessage());    }}
0
public void shouldPatchMetaAlertFields() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(2);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        setupTypings();        Map<String, Object> metaAlert = buildMetaAlert("meta_alert", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(1))));        addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("meta_alert", METAALERT_TYPE)));        String namePatch = namePatchRequest.replace(META_INDEX_FLAG, getMetaAlertIndex());    PatchRequest patchRequest = JSONUtils.INSTANCE.load(namePatch, PatchRequest.class);    metaDao.patch(metaDao, patchRequest, Optional.of(System.currentTimeMillis()));        assertEventually(() -> {        Document updated = metaDao.getLatest("meta_alert", METAALERT_TYPE);        Assert.assertEquals("New Meta Alert", updated.getDocument().get(NAME_FIELD));    });}
0
public void shouldThrowExceptionIfPatchAlertField() throws Exception
{    setupTypings();        List<Map<String, Object>> alerts = buildAlerts(2);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        Map<String, Object> metaAlert = buildMetaAlert("meta_alert", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(1))));    addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("meta_alert", METAALERT_TYPE)));        try {        String alertPatch = alertPatchRequest.replace(META_INDEX_FLAG, getMetaAlertIndex());        PatchRequest patchRequest = JSONUtils.INSTANCE.load(alertPatch, PatchRequest.class);        metaDao.patch(metaDao, patchRequest, Optional.of(System.currentTimeMillis()));        Assert.fail("A patch on the alert field should throw an exception");    } catch (IllegalArgumentException iae) {        Assert.assertEquals("Meta alert patches are not allowed for /alert or /status paths.  " + "Please use the add/remove alert or update status functions instead.", iae.getMessage());    }        assertEventually(() -> {        Document updated = metaDao.getLatest("meta_alert", METAALERT_TYPE);        Assert.assertEquals(metaAlert.get(ALERT_FIELD), updated.getDocument().get(ALERT_FIELD));    });}
0
public void shouldThrowExceptionIfPatchStatusField() throws Exception
{    setupTypings();        List<Map<String, Object>> alerts = buildAlerts(2);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    addRecords(alerts, getTestIndexFullName(), SENSOR_NAME);        Map<String, Object> metaAlert = buildMetaAlert("meta_alert", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(1))));    addRecords(Collections.singletonList(metaAlert), getMetaAlertIndex(), METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("meta_alert", METAALERT_TYPE)));        try {        String statusPatch = statusPatchRequest.replace(META_INDEX_FLAG, getMetaAlertIndex());        PatchRequest patchRequest = JSONUtils.INSTANCE.load(statusPatch, PatchRequest.class);        metaDao.patch(metaDao, patchRequest, Optional.of(System.currentTimeMillis()));        Assert.fail("A patch on the status field should throw an exception");    } catch (IllegalArgumentException iae) {        Assert.assertEquals("Meta alert patches are not allowed for /alert or /status paths.  " + "Please use the add/remove alert or update status functions instead.", iae.getMessage());    }        assertEventually(() -> {        Document updated = metaDao.getLatest("meta_alert", METAALERT_TYPE);        Assert.assertEquals(metaAlert.get(STATUS_FIELD), updated.getDocument().get(STATUS_FIELD));    });}
0
protected void findUpdatedDoc(Map<String, Object> message0, String guid, String sensorType) throws InterruptedException, IOException, OriginalNotFoundException
{    commit();    for (int t = 0; t < MAX_RETRIES; ++t, Thread.sleep(SLEEP_MS)) {        Document doc = metaDao.getLatest(guid, sensorType);                convertAlertsFieldToSet(doc.getDocument());        convertAlertsFieldToSet(message0);        if (doc.getDocument() != null && message0.equals(doc.getDocument())) {            convertAlertsFieldToList(doc.getDocument());            convertAlertsFieldToList(message0);            return;        }    }    throw new OriginalNotFoundException("Count not find " + guid + " after " + MAX_RETRIES + " tries");}
0
protected void convertAlertsFieldToSet(Map<String, Object> document)
{    if (document.get(ALERT_FIELD) instanceof List) {        @SuppressWarnings("unchecked")        List<Map<String, Object>> message0AlertField = (List<Map<String, Object>>) document.get(ALERT_FIELD);        Set<Map<String, Object>> message0AlertSet = new HashSet<>(message0AlertField);        document.put(ALERT_FIELD, message0AlertSet);    }}
0
protected void convertAlertsFieldToList(Map<String, Object> document)
{    if (document.get(ALERT_FIELD) instanceof Set) {        @SuppressWarnings("unchecked")        Set<Map<String, Object>> message0AlertField = (Set<Map<String, Object>>) document.get(ALERT_FIELD);        List<Map<String, Object>> message0AlertList = new ArrayList<>(message0AlertField);        message0AlertList.sort(Comparator.comparing(o -> ((String) o.get(Constants.GUID))));        document.put(ALERT_FIELD, message0AlertList);    }}
0
protected boolean findCreatedDoc(String guid, String sensorType) throws InterruptedException, IOException, OriginalNotFoundException
{    for (int t = 0; t < MAX_RETRIES; ++t, Thread.sleep(SLEEP_MS)) {        Document doc = metaDao.getLatest(guid, sensorType);        if (doc != null) {            return true;        }    }    throw new OriginalNotFoundException("Count not find " + guid + " after " + MAX_RETRIES + "tries");}
0
protected boolean findCreatedDocs(List<GetRequest> getRequests) throws InterruptedException, IOException, OriginalNotFoundException
{    for (int t = 0; t < MAX_RETRIES; ++t, Thread.sleep(SLEEP_MS)) {        Iterable<Document> docs = metaDao.getAllLatest(getRequests);        if (docs != null) {            int docCount = 0;            for (Document doc : docs) {                docCount++;            }            if (getRequests.size() == docCount) {                return true;            }        }    }    throw new OriginalNotFoundException("Count not find guids after " + MAX_RETRIES + "tries");}
0
protected void assertEquals(Map<String, Object> expected, Map<String, Object> actual)
{    Assert.assertEquals(expected.get(Constants.GUID), actual.get(Constants.GUID));    Assert.assertEquals(expected.get(getSourceTypeField()), actual.get(getSourceTypeField()));    Double actualThreatTriageField = actual.get(getThreatTriageField()) instanceof Float ? ((Float) actual.get(getThreatTriageField())).doubleValue() : (Double) actual.get(getThreatTriageField());    Assert.assertEquals(expected.get(getThreatTriageField()), actualThreatTriageField);    List<Map<String, Object>> expectedAlerts = (List<Map<String, Object>>) expected.get(ALERT_FIELD);    List<Map<String, Object>> actualAlerts = (List<Map<String, Object>>) actual.get(ALERT_FIELD);    expectedAlerts.sort(Comparator.comparing(o -> ((String) o.get(Constants.GUID))));    actualAlerts.sort(Comparator.comparing(o -> ((String) o.get(Constants.GUID))));    Assert.assertEquals(expectedAlerts, actualAlerts);    Assert.assertEquals(expected.get(STATUS_FIELD), actual.get(STATUS_FIELD));    Assert.assertEquals(expected.get("average"), actual.get("average"));    Assert.assertEquals(expected.get("min"), actual.get("min"));    Assert.assertEquals(expected.get("median"), actual.get("median"));    Assert.assertEquals(expected.get("max"), actual.get("max"));    Integer actualCountField = actual.get("count") instanceof Long ? ((Long) actual.get("count")).intValue() : (Integer) actual.get("count");    Assert.assertEquals(expected.get("count"), actualCountField);    Assert.assertEquals(expected.get("sum"), actual.get("sum"));}
0
protected List<Map<String, Object>> buildAlerts(int count)
{    List<Map<String, Object>> inputData = new ArrayList<>();    for (int i = 0; i < count; ++i) {        final String guid = "message_" + i;        Map<String, Object> alerts = new HashMap<>();        alerts.put(Constants.GUID, guid);        alerts.put(getSourceTypeField(), SENSOR_NAME);        alerts.put(THREAT_FIELD_DEFAULT, (double) i);        alerts.put("timestamp", System.currentTimeMillis());        inputData.add(alerts);    }    return inputData;}
0
protected List<Map<String, Object>> buildMetaAlerts(int count, MetaAlertStatus status, Optional<List<Map<String, Object>>> alerts)
{    List<Map<String, Object>> inputData = new ArrayList<>();    for (int i = 0; i < count; ++i) {        final String guid = "meta_" + status.getStatusString() + "_" + i;        inputData.add(buildMetaAlert(guid, status, alerts));    }    return inputData;}
0
protected Map<String, Object> buildMetaAlert(String guid, MetaAlertStatus status, Optional<List<Map<String, Object>>> alerts)
{    Map<String, Object> metaAlert = new HashMap<>();    metaAlert.put(Constants.GUID, guid);    metaAlert.put(getSourceTypeField(), METAALERT_TYPE);    metaAlert.put(STATUS_FIELD, status.getStatusString());    metaAlert.put(getThreatTriageField(), 100.0d);    if (alerts.isPresent()) {        List<Map<String, Object>> alertsList = alerts.get();        metaAlert.put(ALERT_FIELD, alertsList);    }    return metaAlert;}
0
protected String getTestIndexFullName()
{    return getTestIndexName();}
0
protected String getThreatTriageField()
{    return THREAT_FIELD_DEFAULT;}
0
protected void commit() throws IOException
{}
0
public void testCalculateMetaScoresList()
{    final double delta = 0.001;    List<Map<String, Object>> alertList = new ArrayList<>();        alertList.add(Collections.singletonMap(THREAT_FIELD_DEFAULT, 10.0f));        alertList.add(Collections.singletonMap(THREAT_FIELD_DEFAULT, 20.0f));        alertList.add(Collections.singletonMap("alert3", "has no threat score"));        Map<String, Object> docMap = new HashMap<>();    docMap.put(ALERT_FIELD, alertList);    Document metaalert = new Document(docMap, "guid", METAALERT_TYPE, 0L);        MetaScores.calculateMetaScores(metaalert, THREAT_FIELD_DEFAULT, THREAT_SORT_DEFAULT);        assertEquals(20D, (Double) metaalert.getDocument().get("max"), delta);    assertEquals(10D, (Double) metaalert.getDocument().get("min"), delta);    assertEquals(15D, (Double) metaalert.getDocument().get("average"), delta);    assertEquals(2L, metaalert.getDocument().get("count"));    assertEquals(30D, (Double) metaalert.getDocument().get("sum"), delta);    assertEquals(15D, (Double) metaalert.getDocument().get("median"), delta);            Object threatScore = metaalert.getDocument().get(THREAT_FIELD_DEFAULT);    assertTrue(threatScore instanceof Float);        assertEquals(30.0F, threatScore);}
0
public void testCalculateMetaScoresWithDifferentFieldName()
{    List<Map<String, Object>> alertList = new ArrayList<>();        alertList.add(Collections.singletonMap(MetaAlertConstants.THREAT_FIELD_DEFAULT, 10.0f));        Map<String, Object> docMap = new HashMap<>();    docMap.put(MetaAlertConstants.ALERT_FIELD, alertList);    Document metaalert = new Document(docMap, "guid", MetaAlertConstants.METAALERT_TYPE, 0L);        AccessConfig accessConfig = new AccessConfig();    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(Constants.THREAT_SCORE_FIELD_PROPERTY, MetaAlertConstants.THREAT_FIELD_DEFAULT);        }    });    MetaScores.calculateMetaScores(metaalert, MetaAlertConstants.THREAT_FIELD_DEFAULT, MetaAlertConstants.THREAT_SORT_DEFAULT);    assertNotNull(metaalert.getDocument().get(MetaAlertConstants.THREAT_FIELD_DEFAULT));}
0
public void setup()
{    dao1 = mock(IndexDao.class);    dao2 = mock(IndexDao.class);    multiIndexDao = new MultiIndexDao(dao1, dao2);    document1 = new Document(new HashMap<>(), "guid", "bro", 1L);    document2 = new Document(new HashMap<>(), "guid", "bro", 2L);}
0
public void shouldUpdateAll() throws IOException
{    Document actual = multiIndexDao.update(document1, Optional.of("bro"));    Assert.assertEquals(document1, actual);        verify(dao1).update(eq(document1), eq(Optional.of("bro")));    verify(dao2).update(eq(document1), eq(Optional.of("bro")));}
0
public void shouldThrowExceptionWithPartialFailureOnUpdate() throws IOException
{        when(dao2.update(any(), any())).thenThrow(new IllegalStateException());    multiIndexDao.update(document1, Optional.of("bro"));}
0
public void shouldBatchUpdateAll() throws IOException
{    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(document1, Optional.of("bro"));            put(document2, Optional.of("bro"));        }    };    Map<Document, Optional<String>> actual = multiIndexDao.batchUpdate(updates);    Assert.assertEquals(updates, actual);        verify(dao1).batchUpdate(eq(updates));    verify(dao2).batchUpdate(eq(updates));}
0
public void shouldThrowExceptionWithPartialFailureOnBatchUpdate() throws IOException
{        when(dao2.batchUpdate(any())).thenThrow(new IllegalStateException());    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(document1, Optional.of("bro"));            put(document2, Optional.of("bro"));        }    };    multiIndexDao.batchUpdate(updates);}
0
public void getLatestShouldReturnLatestAlert() throws Exception
{    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");    when(dao1.getLatest("guid", "bro")).thenReturn(document1);    when(dao2.getLatest("guid", "bro")).thenReturn(document2);    Document expected = new Document(new HashMap<>(), "guid", "bro", 2L);    Assert.assertEquals(expected, multiIndexDao.getLatest("guid", "bro"));}
0
public void addCommentShouldAddCommentToAlert() throws Exception
{    Document latest = mock(Document.class);    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");    when(dao1.addCommentToAlert(request, latest)).thenReturn(document1);    when(dao2.addCommentToAlert(request, latest)).thenReturn(document2);    Document expected = new Document(new HashMap<>(), "guid", "bro", 2L);    Assert.assertEquals(expected, multiIndexDao.addCommentToAlert(request, latest));}
0
public void shouldThrowExceptionWithPartialFailureOnAddComment() throws Exception
{    Document latest = mock(Document.class);    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");        when(dao1.addCommentToAlert(request, latest)).thenReturn(document1);    when(dao2.addCommentToAlert(request, latest)).thenThrow(new IllegalStateException());    multiIndexDao.addCommentToAlert(request, latest);}
0
public void removeCommentShouldRemoveCommentFromAlert() throws Exception
{    Document latest = mock(Document.class);    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");    when(dao1.removeCommentFromAlert(request, latest)).thenReturn(document1);    when(dao2.removeCommentFromAlert(request, latest)).thenReturn(document2);    Document expected = new Document(new HashMap<>(), "guid", "bro", 2L);    Assert.assertEquals(expected, multiIndexDao.removeCommentFromAlert(request, latest));}
0
public void shouldThrowExceptionWithPartialFailureOnRemoveComment() throws Exception
{    Document latest = mock(Document.class);    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");        when(dao1.removeCommentFromAlert(request, latest)).thenReturn(document1);    when(dao2.removeCommentFromAlert(request, latest)).thenThrow(new IllegalStateException());    multiIndexDao.removeCommentFromAlert(request, latest);}
0
public void shouldGetColumnMetadata() throws Exception
{    List<String> indices = Arrays.asList("bro");    Map<String, FieldType> expected = new HashMap<String, FieldType>() {        {            put("bro", FieldType.TEXT);        }    };    when(dao1.getColumnMetadata(eq(indices))).thenReturn(null);    when(dao2.getColumnMetadata(eq(indices))).thenReturn(expected);    Map<String, FieldType> actual = multiIndexDao.getColumnMetadata(indices);    Assert.assertEquals(expected, actual);}
0
public void shouldGetColumnMetadataWithNulls() throws Exception
{    List<String> indices = Arrays.asList("bro");        when(dao1.getColumnMetadata(eq(indices))).thenReturn(null);    when(dao2.getColumnMetadata(eq(indices))).thenReturn(null);    Map<String, FieldType> actual = multiIndexDao.getColumnMetadata(indices);    Assert.assertNull(actual);}
0
public void shouldSearch() throws Exception
{    SearchRequest request = new SearchRequest();    SearchResponse expected = new SearchResponse();    when(dao1.search(eq(request))).thenReturn(null);    when(dao2.search(eq(request))).thenReturn(expected);    SearchResponse actual = multiIndexDao.search(request);    Assert.assertEquals(expected, actual);}
0
public void shouldSearchWithNulls() throws Exception
{    SearchRequest request = new SearchRequest();    when(dao1.search(eq(request))).thenReturn(null);    when(dao2.search(eq(request))).thenReturn(null);    SearchResponse actual = multiIndexDao.search(request);    Assert.assertNull(actual);}
0
public void shouldGroup() throws Exception
{    GroupRequest request = new GroupRequest();    GroupResponse expected = new GroupResponse();    when(dao1.group(eq(request))).thenReturn(null);    when(dao2.group(eq(request))).thenReturn(expected);    GroupResponse actual = multiIndexDao.group(request);    Assert.assertEquals(expected, actual);}
0
public void shouldGroupWithNulls() throws Exception
{    GroupRequest request = new GroupRequest();    when(dao1.group(eq(request))).thenReturn(null);    when(dao2.group(eq(request))).thenReturn(null);    GroupResponse actual = multiIndexDao.group(request);    Assert.assertNull(actual);}
0
public void all_query_returns_all_results() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(allQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    List<SearchResult> results = response.getResults();    Assert.assertEquals(10, results.size());    for (int i = 0; i < 5; ++i) {        Assert.assertEquals("snort", results.get(i).getSource().get(getSourceTypeField()));        Assert.assertEquals(getIndexName("snort"), results.get(i).getIndex());        Assert.assertEquals(10 - i + "", results.get(i).getSource().get("timestamp").toString());    }    for (int i = 5; i < 10; ++i) {        Assert.assertEquals("bro", results.get(i).getSource().get(getSourceTypeField()));        Assert.assertEquals(getIndexName("bro"), results.get(i).getIndex());        Assert.assertEquals(10 - i + "", results.get(i).getSource().get("timestamp").toString());    }}
0
public void find_one_guid() throws Exception
{    GetRequest request = JSONUtils.INSTANCE.load(findOneGuidQuery, GetRequest.class);    Optional<Map<String, Object>> response = getIndexDao().getLatestResult(request);    Assert.assertTrue(response.isPresent());    Map<String, Object> doc = response.get();    Assert.assertEquals("bro", doc.get(getSourceTypeField()));    Assert.assertEquals("3", doc.get("timestamp").toString());}
0
public void get_all_latest_guid() throws Exception
{    List<GetRequest> request = JSONUtils.INSTANCE.load(getAllLatestQuery, new JSONUtils.ReferenceSupplier<List<GetRequest>>() {    });    Map<String, Document> docs = new HashMap<>();    for (Document doc : getIndexDao().getAllLatest(request)) {        docs.put(doc.getGuid(), doc);    }    Assert.assertEquals(2, docs.size());    Assert.assertTrue(docs.keySet().contains("bro_1"));    Assert.assertTrue(docs.keySet().contains("snort_2"));    Assert.assertEquals("bro", docs.get("bro_1").getDocument().get(getSourceTypeField()));    Assert.assertEquals("snort", docs.get("snort_2").getDocument().get(getSourceTypeField()));}
0
public void filter_query_filters_results() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(filterQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(3, response.getTotal());    List<SearchResult> results = response.getResults();    Assert.assertEquals("snort", results.get(0).getSource().get(getSourceTypeField()));    Assert.assertEquals("9", results.get(0).getSource().get("timestamp").toString());    Assert.assertEquals("snort", results.get(1).getSource().get(getSourceTypeField()));    Assert.assertEquals("7", results.get(1).getSource().get("timestamp").toString());    Assert.assertEquals("bro", results.get(2).getSource().get(getSourceTypeField()));    Assert.assertEquals("1", results.get(2).getSource().get("timestamp").toString());}
0
public void sort_query_sorts_results_ascending() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(sortQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    List<SearchResult> results = response.getResults();    for (int i = 8001; i < 8011; ++i) {        Assert.assertEquals(i, results.get(i - 8001).getSource().get("ip_src_port"));    }}
0
public void sort_ascending_with_missing_fields() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(sortAscendingWithMissingFields, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    List<SearchResult> results = response.getResults();    Assert.assertEquals(10, results.size());        for (int i = 0; i < 8; i++) {        Assert.assertFalse(results.get(i).getSource().containsKey("threat:triage:score"));    }        Assert.assertEquals("10.0", results.get(8).getSource().get("threat:triage:score").toString());    Assert.assertEquals("20.0", results.get(9).getSource().get("threat:triage:score").toString());}
0
public void sort_descending_with_missing_fields() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(sortDescendingWithMissingFields, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    List<SearchResult> results = response.getResults();    Assert.assertEquals(10, results.size());        Assert.assertEquals("20.0", results.get(0).getSource().get("threat:triage:score").toString());    Assert.assertEquals("10.0", results.get(1).getSource().get("threat:triage:score").toString());        for (int i = 2; i < 10; i++) {        Assert.assertFalse(results.get(i).getSource().containsKey("threat:triage:score"));    }}
0
public void results_are_paginated() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(paginationQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    List<SearchResult> results = response.getResults();    Assert.assertEquals(3, results.size());    Assert.assertEquals("snort", results.get(0).getSource().get(getSourceTypeField()));    Assert.assertEquals("6", results.get(0).getSource().get("timestamp").toString());    Assert.assertEquals("bro", results.get(1).getSource().get(getSourceTypeField()));    Assert.assertEquals("5", results.get(1).getSource().get("timestamp").toString());    Assert.assertEquals("bro", results.get(2).getSource().get(getSourceTypeField()));    Assert.assertEquals("4", results.get(2).getSource().get("timestamp").toString());}
0
public void returns_results_only_for_specified_indices() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(indexQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(5, response.getTotal());    List<SearchResult> results = response.getResults();    for (int i = 5, j = 0; i > 0; i--, j++) {        Assert.assertEquals("bro", results.get(j).getSource().get(getSourceTypeField()));        Assert.assertEquals(i + "", results.get(j).getSource().get("timestamp").toString());    }}
0
public void facet_query_yields_field_types() throws Exception
{    String facetQuery = facetQueryRaw.replace("source:type", getSourceTypeField());    SearchRequest request = JSONUtils.INSTANCE.load(facetQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    Map<String, Map<String, Long>> facetCounts = response.getFacetCounts();    Assert.assertEquals(8, facetCounts.size());    Map<String, Long> sourceTypeCounts = facetCounts.get(getSourceTypeField());    Assert.assertEquals(2, sourceTypeCounts.size());    Assert.assertEquals(new Long(5), sourceTypeCounts.get("bro"));    Assert.assertEquals(new Long(5), sourceTypeCounts.get("snort"));    Map<String, Long> ipSrcAddrCounts = facetCounts.get("ip_src_addr");    Assert.assertEquals(8, ipSrcAddrCounts.size());    Assert.assertEquals(new Long(3), ipSrcAddrCounts.get("192.168.1.1"));    Assert.assertEquals(new Long(1), ipSrcAddrCounts.get("192.168.1.2"));    Assert.assertEquals(new Long(1), ipSrcAddrCounts.get("192.168.1.3"));    Assert.assertEquals(new Long(1), ipSrcAddrCounts.get("192.168.1.4"));    Assert.assertEquals(new Long(1), ipSrcAddrCounts.get("192.168.1.5"));    Assert.assertEquals(new Long(1), ipSrcAddrCounts.get("192.168.1.6"));    Assert.assertEquals(new Long(1), ipSrcAddrCounts.get("192.168.1.7"));    Assert.assertEquals(new Long(1), ipSrcAddrCounts.get("192.168.1.8"));    Map<String, Long> ipSrcPortCounts = facetCounts.get("ip_src_port");    Assert.assertEquals(10, ipSrcPortCounts.size());    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8001"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8002"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8003"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8004"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8005"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8006"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8007"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8008"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8009"));    Assert.assertEquals(new Long(1), ipSrcPortCounts.get("8010"));    Map<String, Long> longFieldCounts = facetCounts.get("long_field");    Assert.assertEquals(2, longFieldCounts.size());    Assert.assertEquals(new Long(8), longFieldCounts.get("10000"));    Assert.assertEquals(new Long(2), longFieldCounts.get("20000"));    Map<String, Long> timestampCounts = facetCounts.get("timestamp");    Assert.assertEquals(10, timestampCounts.size());    Assert.assertEquals(new Long(1), timestampCounts.get("1"));    Assert.assertEquals(new Long(1), timestampCounts.get("2"));    Assert.assertEquals(new Long(1), timestampCounts.get("3"));    Assert.assertEquals(new Long(1), timestampCounts.get("4"));    Assert.assertEquals(new Long(1), timestampCounts.get("5"));    Assert.assertEquals(new Long(1), timestampCounts.get("6"));    Assert.assertEquals(new Long(1), timestampCounts.get("7"));    Assert.assertEquals(new Long(1), timestampCounts.get("8"));    Assert.assertEquals(new Long(1), timestampCounts.get("9"));    Assert.assertEquals(new Long(1), timestampCounts.get("10"));    Map<String, Long> latitudeCounts = facetCounts.get("latitude");    Assert.assertEquals(2, latitudeCounts.size());    List<String> latitudeKeys = new ArrayList<>(latitudeCounts.keySet());    Collections.sort(latitudeKeys);    Assert.assertEquals(48.0001, Double.parseDouble(latitudeKeys.get(0)), 0.00001);    Assert.assertEquals(48.5839, Double.parseDouble(latitudeKeys.get(1)), 0.00001);    Assert.assertEquals(new Long(2), latitudeCounts.get(latitudeKeys.get(0)));    Assert.assertEquals(new Long(8), latitudeCounts.get(latitudeKeys.get(1)));    Map<String, Long> scoreFieldCounts = facetCounts.get("score");    Assert.assertEquals(4, scoreFieldCounts.size());    List<String> scoreFieldKeys = new ArrayList<>(scoreFieldCounts.keySet());    Collections.sort(scoreFieldKeys);    Assert.assertEquals(10.0, Double.parseDouble(scoreFieldKeys.get(0)), 0.00001);    Assert.assertEquals(20.0, Double.parseDouble(scoreFieldKeys.get(1)), 0.00001);    Assert.assertEquals(50.0, Double.parseDouble(scoreFieldKeys.get(2)), 0.00001);    Assert.assertEquals(98.0, Double.parseDouble(scoreFieldKeys.get(3)), 0.00001);    Assert.assertEquals(new Long(4), scoreFieldCounts.get(scoreFieldKeys.get(0)));    Assert.assertEquals(new Long(2), scoreFieldCounts.get(scoreFieldKeys.get(1)));    Assert.assertEquals(new Long(3), scoreFieldCounts.get(scoreFieldKeys.get(2)));    Assert.assertEquals(new Long(1), scoreFieldCounts.get(scoreFieldKeys.get(3)));    Map<String, Long> isAlertCounts = facetCounts.get("is_alert");    Assert.assertEquals(2, isAlertCounts.size());    Assert.assertEquals(new Long(6), isAlertCounts.get("true"));    Assert.assertEquals(new Long(4), isAlertCounts.get("false"));}
0
public void disabled_facet_query_returns_null_count() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(disabledFacetQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertNull(response.getFacetCounts());}
0
public void missing_type_facet_query() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(missingTypeFacetQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    Map<String, Map<String, Long>> facetCounts = response.getFacetCounts();    Assert.assertEquals(1, facetCounts.size());    Map<String, Long> snortFieldCounts = facetCounts.get("sig_generator");    Assert.assertEquals(5, snortFieldCounts.size());    Assert.assertEquals(1L, snortFieldCounts.get("sig_generator 5").longValue());    Assert.assertEquals(1L, snortFieldCounts.get("sig_generator 4").longValue());    Assert.assertEquals(1L, snortFieldCounts.get("sig_generator 3").longValue());    Assert.assertEquals(1L, snortFieldCounts.get("sig_generator 2").longValue());    Assert.assertEquals(1L, snortFieldCounts.get("sig_generator 1").longValue());    response.getFacetCounts();}
0
public void different_type_facet_query() throws Exception
{    thrown.expect(Exception.class);    SearchRequest request = JSONUtils.INSTANCE.load(differentTypeFacetQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(3, response.getTotal());}
0
public void exceeding_max_results_throws_exception() throws Exception
{    thrown.expect(InvalidSearchException.class);    thrown.expectMessage("Search result size must be less than 100");    SearchRequest request = JSONUtils.INSTANCE.load(exceededMaxResultsQuery, SearchRequest.class);    getIndexDao().search(request);}
0
public void column_metadata_for_missing_index() throws Exception
{        {        Map<String, FieldType> fieldTypes = getIndexDao().getColumnMetadata(Collections.singletonList("someindex"));        Assert.assertEquals(0, fieldTypes.size());    }}
0
public void no_results_returned_when_query_does_not_match() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(noResultsFieldsQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(0, response.getTotal());}
0
public void group_by_ip_query() throws Exception
{    GroupRequest request = JSONUtils.INSTANCE.load(groupByIpQuery, GroupRequest.class);    GroupResponse response = getIndexDao().group(request);        Assert.assertEquals("ip_src_addr", response.getGroupedBy());        List<GroupResult> groups = response.getGroupResults();    Assert.assertEquals(8, groups.size());        Assert.assertEquals("192.168.1.8", groups.get(0).getKey());    Assert.assertEquals("192.168.1.7", groups.get(1).getKey());    Assert.assertEquals("192.168.1.6", groups.get(2).getKey());    Assert.assertEquals("192.168.1.5", groups.get(3).getKey());    Assert.assertEquals("192.168.1.4", groups.get(4).getKey());    Assert.assertEquals("192.168.1.3", groups.get(5).getKey());    Assert.assertEquals("192.168.1.2", groups.get(6).getKey());    Assert.assertEquals("192.168.1.1", groups.get(7).getKey());}
0
public void group_by_returns_results_in_groups() throws Exception
{        GroupRequest request = JSONUtils.INSTANCE.load(groupByQuery, GroupRequest.class);    GroupResponse response = getIndexDao().group(request);    Assert.assertEquals("is_alert", response.getGroupedBy());    List<GroupResult> isAlertGroups = response.getGroupResults();    Assert.assertEquals(2, isAlertGroups.size());        GroupResult trueGroup = isAlertGroups.get(0);    Assert.assertEquals("true", trueGroup.getKey());    Assert.assertEquals(6, trueGroup.getTotal());    Assert.assertEquals("latitude", trueGroup.getGroupedBy());    Assert.assertEquals(198.0, trueGroup.getScore(), 0.00001);    List<GroupResult> trueLatitudeGroups = trueGroup.getGroupResults();    Assert.assertEquals(2, trueLatitudeGroups.size());        GroupResult trueLatitudeGroup2 = trueLatitudeGroups.get(0);    Assert.assertEquals(48.5839, Double.parseDouble(trueLatitudeGroup2.getKey()), 0.00001);    Assert.assertEquals(5, trueLatitudeGroup2.getTotal());    Assert.assertEquals(148.0, trueLatitudeGroup2.getScore(), 0.00001);        GroupResult trueLatitudeGroup1 = trueLatitudeGroups.get(1);    Assert.assertEquals(48.0001, Double.parseDouble(trueLatitudeGroup1.getKey()), 0.00001);    Assert.assertEquals(1, trueLatitudeGroup1.getTotal());    Assert.assertEquals(50.0, trueLatitudeGroup1.getScore(), 0.00001);        GroupResult falseGroup = isAlertGroups.get(1);    Assert.assertEquals("false", falseGroup.getKey());    Assert.assertEquals("latitude", falseGroup.getGroupedBy());    Assert.assertEquals(130.0, falseGroup.getScore(), 0.00001);    List<GroupResult> falseLatitudeGroups = falseGroup.getGroupResults();    Assert.assertEquals(2, falseLatitudeGroups.size());        GroupResult falseLatitudeGroup2 = falseLatitudeGroups.get(0);    Assert.assertEquals(48.5839, Double.parseDouble(falseLatitudeGroup2.getKey()), 0.00001);    Assert.assertEquals(3, falseLatitudeGroup2.getTotal());    Assert.assertEquals(80.0, falseLatitudeGroup2.getScore(), 0.00001);        GroupResult falseLatitudeGroup1 = falseLatitudeGroups.get(1);    Assert.assertEquals(48.0001, Double.parseDouble(falseLatitudeGroup1.getKey()), 0.00001);    Assert.assertEquals(1, falseLatitudeGroup1.getTotal());    Assert.assertEquals(50.0, falseLatitudeGroup1.getScore(), 0.00001);}
0
public void group_by_returns_results_in_sorted_groups() throws Exception
{        GroupRequest request = JSONUtils.INSTANCE.load(sortedGroupByQuery, GroupRequest.class);    GroupResponse response = getIndexDao().group(request);    Assert.assertEquals("is_alert", response.getGroupedBy());    List<GroupResult> isAlertGroups = response.getGroupResults();    Assert.assertEquals(2, isAlertGroups.size());        GroupResult falseGroup = isAlertGroups.get(0);    Assert.assertEquals(4, falseGroup.getTotal());    Assert.assertEquals("ip_src_addr", falseGroup.getGroupedBy());    List<GroupResult> falseIpSrcAddrGroups = falseGroup.getGroupResults();    Assert.assertEquals(4, falseIpSrcAddrGroups.size());        GroupResult falseIpSrcAddrGroup1 = falseIpSrcAddrGroups.get(0);    Assert.assertEquals("192.168.1.8", falseIpSrcAddrGroup1.getKey());    Assert.assertEquals(1, falseIpSrcAddrGroup1.getTotal());    Assert.assertNull(falseIpSrcAddrGroup1.getGroupedBy());    Assert.assertNull(falseIpSrcAddrGroup1.getGroupResults());        GroupResult falseIpSrcAddrGroup2 = falseIpSrcAddrGroups.get(1);    Assert.assertEquals("192.168.1.7", falseIpSrcAddrGroup2.getKey());    Assert.assertEquals(1, falseIpSrcAddrGroup2.getTotal());    Assert.assertNull(falseIpSrcAddrGroup2.getGroupedBy());    Assert.assertNull(falseIpSrcAddrGroup2.getGroupResults());        GroupResult falseIpSrcAddrGroup3 = falseIpSrcAddrGroups.get(2);    Assert.assertEquals("192.168.1.6", falseIpSrcAddrGroup3.getKey());    Assert.assertEquals(1, falseIpSrcAddrGroup3.getTotal());    Assert.assertNull(falseIpSrcAddrGroup3.getGroupedBy());    Assert.assertNull(falseIpSrcAddrGroup3.getGroupResults());        GroupResult falseIpSrcAddrGroup4 = falseIpSrcAddrGroups.get(3);    Assert.assertEquals("192.168.1.2", falseIpSrcAddrGroup4.getKey());    Assert.assertEquals(1, falseIpSrcAddrGroup4.getTotal());    Assert.assertNull(falseIpSrcAddrGroup4.getGroupedBy());    Assert.assertNull(falseIpSrcAddrGroup4.getGroupResults());        GroupResult trueGroup = isAlertGroups.get(1);    Assert.assertEquals(6, trueGroup.getTotal());    Assert.assertEquals("ip_src_addr", trueGroup.getGroupedBy());    List<GroupResult> trueIpSrcAddrGroups = trueGroup.getGroupResults();    Assert.assertEquals(4, trueIpSrcAddrGroups.size());        GroupResult trueIpSrcAddrGroup1 = trueIpSrcAddrGroups.get(0);    Assert.assertEquals("192.168.1.5", trueIpSrcAddrGroup1.getKey());    Assert.assertEquals(1, trueIpSrcAddrGroup1.getTotal());    Assert.assertNull(trueIpSrcAddrGroup1.getGroupedBy());    Assert.assertNull(trueIpSrcAddrGroup1.getGroupResults());        GroupResult trueIpSrcAddrGroup2 = trueIpSrcAddrGroups.get(1);    Assert.assertEquals("192.168.1.4", trueIpSrcAddrGroup2.getKey());    Assert.assertEquals(1, trueIpSrcAddrGroup2.getTotal());    Assert.assertNull(trueIpSrcAddrGroup2.getGroupedBy());    Assert.assertNull(trueIpSrcAddrGroup2.getGroupResults());        GroupResult trueIpSrcAddrGroup3 = trueIpSrcAddrGroups.get(2);    Assert.assertEquals("192.168.1.3", trueIpSrcAddrGroup3.getKey());    Assert.assertEquals(1, trueIpSrcAddrGroup3.getTotal());    Assert.assertNull(trueIpSrcAddrGroup3.getGroupedBy());    Assert.assertNull(trueIpSrcAddrGroup3.getGroupResults());        GroupResult trueIpSrcAddrGroup4 = trueIpSrcAddrGroups.get(3);    Assert.assertEquals("192.168.1.1", trueIpSrcAddrGroup4.getKey());    Assert.assertEquals(3, trueIpSrcAddrGroup4.getTotal());    Assert.assertNull(trueIpSrcAddrGroup4.getGroupedBy());    Assert.assertNull(trueIpSrcAddrGroup4.getGroupResults());}
0
public void queries_fields() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(fieldsQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(10, response.getTotal());    List<SearchResult> results = response.getResults();    for (int i = 0; i < 5; ++i) {        Map<String, Object> source = results.get(i).getSource();        Assert.assertEquals(1, source.size());        Assert.assertNotNull(source.get("ip_src_addr"));    }    for (int i = 5; i < 10; ++i) {        Map<String, Object> source = results.get(i).getSource();        Assert.assertEquals(1, source.size());        Assert.assertNotNull(source.get("ip_src_addr"));    }}
0
public void sort_by_guid() throws Exception
{    SearchRequest request = JSONUtils.INSTANCE.load(sortByGuidQuery, SearchRequest.class);    SearchResponse response = getIndexDao().search(request);    Assert.assertEquals(5, response.getTotal());    List<SearchResult> results = response.getResults();    for (int i = 0; i < 5; ++i) {        Map<String, Object> source = results.get(i).getSource();        Assert.assertEquals(1, source.size());        Assert.assertEquals(source.get("guid"), "bro_" + (i + 1));    }}
0
public static void stop()
{    indexComponent.stop();}
0
public void addOperationShouldAddValue()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.ADD.name());            put(PatchUtils.PATH, "/path");            put(PatchUtils.VALUE, "value");        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("path", "value");        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<>()));}
0
public void removeOperationShouldRemoveValue()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.REMOVE.name());            put(PatchUtils.PATH, "/remove/path");        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("path", "value");            put("remove", new HashMap<>());        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", "value");            put("remove", new HashMap<String, Object>() {                {                    put("path", "removeValue");                }            });        }    }));}
0
public void copyOperationShouldCopyValue()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.COPY.name());            put(PatchUtils.FROM, "/from");            put(PatchUtils.PATH, "/path");        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("from", "value");            put("path", "value");        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("from", "value");        }    }));}
0
public void copyOperationShouldCopyNestedValue()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.COPY.name());            put(PatchUtils.FROM, "/nested/from");            put(PatchUtils.PATH, "/nested/path");        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("nested", new HashMap<String, Object>() {                {                    put("from", "value");                    put("path", "value");                }            });        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("nested", new HashMap<String, Object>() {                {                    put("from", "value");                }            });        }    }));}
0
public void moveOperationShouldMoveValue()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.MOVE.name());            put(PatchUtils.FROM, "/from");            put(PatchUtils.PATH, "/path");        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("path", "value");        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("from", "value");        }    }));}
0
public void testOperationShouldCompareStrings()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.TEST.name());            put(PatchUtils.PATH, "/path");            put(PatchUtils.VALUE, "value");        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("path", "value");        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", "value");        }    }));}
0
public void testOperationShouldCompareNumbers()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.TEST.name());            put(PatchUtils.PATH, "/path");            put(PatchUtils.VALUE, 100);        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("path", 100);        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", 100);        }    }));}
0
public void testOperationShouldCompareArrays()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.TEST.name());            put(PatchUtils.PATH, "/path");            put(PatchUtils.VALUE, Arrays.asList(1, 2, 3));        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("path", Arrays.asList(1, 2, 3));        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", Arrays.asList(1, 2, 3));        }    }));}
0
public void testOperationShouldCompareObjects()
{    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.TEST.name());            put(PatchUtils.PATH, "/path");            put(PatchUtils.VALUE, new HashMap<String, Object>() {                {                    put("key", "value");                }            });        }    });    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("path", new HashMap<String, Object>() {                {                    put("key", "value");                }            });        }    };    Assert.assertEquals(expected, PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", new HashMap<String, Object>() {                {                    put("key", "value");                }            });        }    }));}
0
public void testOperationShouldThrowExceptionOnFailedCompare()
{    exception.expect(PatchException.class);    exception.expectMessage("TEST operation failed: supplied value [value1] != target value [value2]");    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.TEST.name());            put(PatchUtils.PATH, "/path");            put(PatchUtils.VALUE, "value1");        }    });    PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", "value2");        }    });}
0
public void shouldThrowExceptionOnInvalidPath()
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("Invalid path: /missing/path");    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, PatchOperation.REMOVE.name());            put(PatchUtils.PATH, "/missing/path");        }    });    PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", "value");        }    });}
0
public void shouldThrowExceptionOnInvalidOperation()
{    exception.expect(UnsupportedOperationException.class);    exception.expectMessage("The invalid operation is not supported");    List<Map<String, Object>> patches = new ArrayList<>();    patches.add(new HashMap<String, Object>() {        {            put(PatchUtils.OP, "invalid");            put(PatchUtils.PATH, "/path");        }    });    PatchUtils.INSTANCE.applyPatch(patches, new HashMap<String, Object>() {        {            put("path", "value");        }    });}
0
public void addCommentShouldThrowExceptionOnMissingAlert() throws Exception
{    exception.expect(IOException.class);    exception.expectMessage("Unable to add comment. Document with guid guid cannot be found.");    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");    getUpdateDao().addCommentToAlert(request, null);}
0
public void removeCommentShouldThrowExceptionOnMissingAlert() throws Exception
{    exception.expect(IOException.class);    exception.expectMessage("Unable to remove comment. Document with guid guid cannot be found.");    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");    getUpdateDao().removeCommentFromAlert(request, null);}
0
public void removeCommentShouldThrowExceptionOnEmptyComments() throws Exception
{    exception.expect(IOException.class);    exception.expectMessage("Unable to remove comment. Document with guid guid has no comments.");    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid("guid");    Document latest = new Document(new HashMap<>(), "guid", "bro", System.currentTimeMillis());    getUpdateDao().removeCommentFromAlert(request, latest);}
0
public void testUpdate() throws Exception
{        final String guid = UUID.randomUUID().toString();    final Long timestamp = 1526306463050L;    Document toUpdate = createDocument(guid, timestamp);        Document updated = getDao().update(toUpdate, Optional.of(SENSOR_NAME));    Assert.assertEquals(toUpdate, updated);        assertDocumentIndexed(toUpdate);}
0
public void testBatchUpdate() throws Exception
{    Map<Document, Optional<String>> toUpdate = new HashMap<>();        final String guid1 = UUID.randomUUID().toString();    final Long timestamp1 = 1526306463050L;    Document document1 = createDocument(guid1, timestamp1);    toUpdate.put(document1, Optional.of(SENSOR_NAME));        final String guid2 = UUID.randomUUID().toString();    final Long timestamp2 = 1526306463100L;    Document document2 = createDocument(guid2, timestamp2);    toUpdate.put(document2, Optional.of(SENSOR_NAME));        final String guid3 = UUID.randomUUID().toString();    final Long timestamp3 = 1526306463300L;    Document document3 = createDocument(guid3, timestamp3);    toUpdate.put(document3, Optional.of(SENSOR_NAME));        Map<Document, Optional<String>> updated = getDao().batchUpdate(toUpdate);    Assert.assertThat(updated.keySet(), hasItem(document1));    Assert.assertThat(updated.keySet(), hasItem(document2));    Assert.assertThat(updated.keySet(), hasItem(document3));        assertDocumentIndexed(document1);    assertDocumentIndexed(document2);    assertDocumentIndexed(document3);}
0
public void testAddComment() throws Exception
{    Document document = createAndIndexDocument("testAddCommentAndPatch");        String commentText = "New Comment";    String commentUser = "test_user";    long commentTimestamp = 152630493050L;    Document withComment = addAlertComment(document.getGuid(), commentText, commentUser, commentTimestamp);    {                List<AlertComment> comments = getComments(withComment);        Assert.assertEquals(1, comments.size());        Assert.assertEquals(commentText, comments.get(0).getComment());        Assert.assertEquals(commentUser, comments.get(0).getUsername());        Assert.assertEquals(commentTimestamp, comments.get(0).getTimestamp());    }    {                Document indexed = findUpdatedDoc(withComment.getDocument(), withComment.getGuid(), SENSOR_NAME);        List<AlertComment> comments = getComments(indexed);        Assert.assertEquals(1, comments.size());        Assert.assertEquals(commentText, comments.get(0).getComment());        Assert.assertEquals(commentUser, comments.get(0).getUsername());        Assert.assertEquals(commentTimestamp, comments.get(0).getTimestamp());    }}
0
public void testPatchDocumentThatHasComment() throws Exception
{    Document document = createAndIndexDocument("testPatchDocumentWithComment");        String commentText = "New Comment";    String commentUser = "test_user";    long commentTimestamp = 152630493050L;    Document withComment = addAlertComment(document.getGuid(), commentText, commentUser, commentTimestamp);        List<Map<String, Object>> patches = new ArrayList<>();    Map<String, Object> patch = new HashMap<>();    patch.put("op", "add");    patch.put("path", "/project");    patch.put("value", "metron");    patches.add(patch);    PatchRequest pr = new PatchRequest();    pr.setGuid(withComment.getGuid());    pr.setIndex(SENSOR_NAME);    pr.setSensorType(SENSOR_NAME);    pr.setPatch(patches);        Document patched = getDao().patch(getDao(), pr, Optional.of(withComment.getTimestamp()));    Assert.assertEquals("metron", patched.getDocument().get("project"));        Document indexed = findUpdatedDoc(patched.getDocument(), patched.getGuid(), SENSOR_NAME);    Assert.assertEquals("metron", indexed.getDocument().get("project"));}
0
public void testRemoveComments() throws Exception
{    String guid = "testRemoveComments";    createAndIndexDocument(guid);        Document withComments = addAlertComment(guid, "comment", "user1", 1526401584951L);    Assert.assertEquals(1, getComments(withComments).size());        Document indexedWithComments = findUpdatedDoc(withComments.getDocument(), withComments.getGuid(), withComments.getSensorType());    Assert.assertEquals(1, getComments(indexedWithComments).size());        AlertComment toRemove = getComments(withComments).get(0);    Document noComments = removeAlertComment(guid, toRemove.getComment(), toRemove.getUsername(), toRemove.getTimestamp());    Assert.assertEquals(0, getComments(noComments).size());        Document indexedNoComments = findUpdatedDoc(noComments.getDocument(), withComments.getGuid(), withComments.getSensorType());    Assert.assertEquals(0, getComments(indexedNoComments).size());}
0
protected Document addAlertComment(String guid, String comment, String username, long timestamp) throws IOException
{    CommentAddRemoveRequest request = buildAlertRequest(guid, comment, username, timestamp);    return getDao().addCommentToAlert(request);}
0
protected Document removeAlertComment(String guid, String comment, String username, long timestamp) throws IOException
{    CommentAddRemoveRequest request = buildAlertRequest(guid, comment, username, timestamp);    return getDao().removeCommentFromAlert(request);}
0
private CommentAddRemoveRequest buildAlertRequest(String guid, String comment, String username, long timestamp)
{    CommentAddRemoveRequest request = new CommentAddRemoveRequest();    request.setGuid(guid);    request.setComment(comment);    request.setUsername(username);    request.setTimestamp(timestamp);    request.setSensorType(SENSOR_NAME);    return request;}
0
private Document assertDocumentIndexed(Document expected) throws Exception
{        Document actual = findUpdatedDoc(expected.getDocument(), expected.getGuid(), expected.getSensorType());        Assert.assertEquals(expected.getGuid(), actual.getGuid());    Assert.assertEquals(expected.getTimestamp(), actual.getTimestamp());    Assert.assertEquals(expected.getSensorType(), actual.getSensorType());    Assert.assertEquals(expected.getDocument(), actual.getDocument());    if (expected.getDocumentID().isPresent()) {                Assert.assertEquals(expected.getDocumentID().get(), actual.getDocumentID());    } else {                Assert.assertNotNull(expected.getDocumentID());    }    return actual;}
0
private Document createAndIndexDocument(String guid) throws Exception
{        Long timestamp = 1526306463050L;    Document toCreate = createDocument(guid, timestamp);        Document created = getDao().update(toCreate, Optional.of(SENSOR_NAME));    Assert.assertEquals(toCreate, created);        return assertDocumentIndexed(created);}
0
protected Document createDocument(String guid, Long timestamp)
{    Map<String, Object> message1 = new HashMap<>();    message1.put(Constants.GUID, guid);    message1.put(Constants.SENSOR_TYPE, SENSOR_NAME);    message1.put(Constants.Fields.TIMESTAMP.getName(), timestamp);    return new Document(message1, guid, SENSOR_NAME, timestamp);}
0
private static List<AlertComment> getComments(Document withComment) throws ParseException
{    return getComments(withComment.getDocument());}
0
private static List<AlertComment> getComments(Map<String, Object> fields) throws ParseException
{    List<AlertComment> comments = new ArrayList<>();    boolean hasComments = fields.containsKey(COMMENTS_FIELD);    if (hasComments) {        List<Object> commentsField = List.class.cast(fields.get(COMMENTS_FIELD));        for (Object commentObject : commentsField) {            if (commentObject instanceof Map) {                                Map<String, Object> commentAsMap = (Map<String, Object>) commentObject;                comments.add(new AlertComment(commentAsMap));            } else if (commentObject instanceof String) {                                String commentAsString = (String) commentObject;                comments.add(new AlertComment(commentAsString));            } else {                throw new IllegalArgumentException(String.format("Unexpected comment value; %s", commentObject));            }        }    }    return comments;}
0
protected static void normalizeCommentsAsMap(Map<String, Object> fields)
{    @SuppressWarnings("unchecked")    List<Object> commentValues = (List<Object>) fields.get(COMMENTS_FIELD);    if (commentValues != null) {        try {            List<AlertComment> comments = getComments(fields);            if (comments.size() > 0) {                                List<Map<String, Object>> serializedComments = comments.stream().map(AlertComment::asMap).collect(Collectors.toList());                fields.put(COMMENTS_FIELD, serializedComments);            } else {                                fields.remove(COMMENTS_FIELD);            }        } catch (ParseException e) {            throw new IllegalStateException("Unable to parse comment", e);        }    }}
0
protected Document findUpdatedDoc(Map<String, Object> expected, String guid, String sensorType) throws InterruptedException, IOException, OriginalNotFoundException
{        normalizeCommentsAsMap(expected);    for (int t = 0; t < MAX_RETRIES; ++t, Thread.sleep(SLEEP_MS)) {        Document found = getDao().getLatest(guid, sensorType);        if (found != null && expected.equals(found.getDocument())) {            return found;        }        if (t == MAX_RETRIES - 1) {            MapUtils.debugPrint(System.out, "Expected", expected);            MapUtils.debugPrint(System.out, "Actual", found.getDocument());        }    }    throw new OriginalNotFoundException("Count not find " + guid + " after " + MAX_RETRIES + " tries");}
0
protected IndexDao getDao()
{    return dao;}
0
protected void setDao(IndexDao dao)
{    this.dao = dao;}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    return indexDao.getLatest(guid, sensorType);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    return indexDao.getAllLatest(getRequests);}
0
public void startHBase() throws Exception
{    AccessConfig accessConfig = new AccessConfig();    accessConfig.setMaxSearchResults(1000);    accessConfig.setMaxSearchGroups(1000);    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(HBASE_TABLE, TABLE_NAME);            put(HBASE_CF, COLUMN_FAMILY);        }    });    MockHBaseTableProvider.addToCache(TABLE_NAME, COLUMN_FAMILY);    accessConfig.setTableProvider(new MockHBaseTableProvider());    hbaseDao = new HBaseDao();    hbaseDao.init(accessConfig);}
0
public void clearTable() throws Exception
{    MockHBaseTableProvider.clear();}
0
public void testKeySerializationRemainsConstant() throws IOException
{    HBaseDao.Key k = new HBaseDao.Key("guid", "sensorType");    byte[] raw = k.toBytes();    Assert.assertArrayEquals(raw, expectedKeySerialization);}
0
public void testKeySerialization() throws Exception
{    HBaseDao.Key k = new HBaseDao.Key("guid", "sensorType");    Assert.assertEquals(k, HBaseDao.Key.fromBytes(HBaseDao.Key.toBytes(k)));}
0
public void testKeySerializationWithInvalidGuid() throws Exception
{    HBaseDao.Key k = new HBaseDao.Key(null, "sensorType");    Assert.assertEquals(k, HBaseDao.Key.fromBytes(HBaseDao.Key.toBytes(k)));}
0
public void testKeySerializationWithInvalidSensorType() throws Exception
{    HBaseDao.Key k = new HBaseDao.Key("guid", null);    Assert.assertEquals(k, HBaseDao.Key.fromBytes(HBaseDao.Key.toBytes(k)));}
0
public void shouldGetLatest() throws Exception
{        List<Document> alerts = buildAlerts(3);    Map<Document, Optional<String>> updates = alerts.stream().collect(Collectors.toMap(document -> document, document -> Optional.empty()));    hbaseDao.batchUpdate(updates);    Document actualDocument = hbaseDao.getLatest("message_1", SENSOR_TYPE);    Document expectedDocument = alerts.get(1);    Assert.assertEquals(expectedDocument, actualDocument);}
0
public void shouldGetLatestWithInvalidTimestamp() throws Exception
{        Document alert = buildAlerts(1).get(0);    hbaseDao.update(alert, Optional.empty());    Document actualDocument = hbaseDao.getLatest("message_0", SENSOR_TYPE);    Assert.assertEquals(alert, actualDocument);    alert.getDocument().put("field", "value");    alert.setTimestamp(0L);    hbaseDao.update(alert, Optional.empty());    actualDocument = hbaseDao.getLatest("message_0", SENSOR_TYPE);    Assert.assertEquals(alert.getDocument(), actualDocument.getDocument());}
0
public void shouldGetAllLatest() throws Exception
{        List<Document> alerts = buildAlerts(15);    alerts.stream().collect(Collectors.toMap(Document::getGuid, document -> Optional.empty()));    Map<Document, Optional<String>> updates = alerts.stream().collect(Collectors.toMap(document -> document, document -> Optional.empty()));    hbaseDao.batchUpdate(updates);    int expectedCount = 12;    List<GetRequest> getRequests = new ArrayList<>();    for (int i = 1; i < expectedCount + 1; i++) {        getRequests.add(new GetRequest("message_" + i, SENSOR_TYPE));    }    Iterator<Document> results = hbaseDao.getAllLatest(getRequests).iterator();    for (int i = 0; i < expectedCount; i++) {        Document expectedDocument = alerts.get(i + 1);        Document actualDocument = results.next();        Assert.assertEquals(expectedDocument, actualDocument);    }    Assert.assertFalse("Result size should be 12 but was greater", results.hasNext());}
0
protected List<Document> buildAlerts(int count) throws IOException
{    List<Document> alerts = new ArrayList<>();    for (int i = 0; i < count; ++i) {        String guid = "message_" + i;        String json = "{\"guid\":\"message_" + i + "\", \"source:type\":\"test\"}";        Document alert = new Document(json, guid, SENSOR_TYPE, System.currentTimeMillis());        alerts.add(alert);    }    return alerts;}
0
public void testRemoveComments() throws Exception
{    Map<String, Object> fields = new HashMap<>();    fields.put("guid", "add_comment");    fields.put("source.type", SENSOR_NAME);    Document document = new Document(fields, "add_comment", SENSOR_NAME, 1526401584951L);    hbaseDao.update(document, Optional.of(SENSOR_NAME));    findUpdatedDoc(document.getDocument(), "add_comment", SENSOR_NAME);    addAlertComment("add_comment", "New Comment", "test_user", 1526401584951L);        ArrayList<AlertComment> comments = new ArrayList<>();    comments.add(new AlertComment("New Comment", "test_user", 1526401584951L));    document.getDocument().put(COMMENTS_FIELD, comments.stream().map(AlertComment::asMap).collect(Collectors.toList()));    findUpdatedDoc(document.getDocument(), "add_comment", SENSOR_NAME);    addAlertComment("add_comment", "New Comment 2", "test_user_2", 1526401584952L);        comments.add(new AlertComment("New Comment 2", "test_user_2", 1526401584952L));    document.getDocument().put(COMMENTS_FIELD, comments.stream().map(AlertComment::asMap).collect(Collectors.toList()));    findUpdatedDoc(document.getDocument(), "add_comment", SENSOR_NAME);    removeAlertComment("add_comment", "New Comment 2", "test_user_2", 1526401584952L);        comments = new ArrayList<>();    comments.add(new AlertComment(commentOne));    document.getDocument().put(COMMENTS_FIELD, comments.stream().map(AlertComment::asMap).collect(Collectors.toList()));    findUpdatedDoc(document.getDocument(), "add_comment", SENSOR_NAME);    removeAlertComment("add_comment", "New Comment", "test_user", 1526401584951L);        document.getDocument().remove(COMMENTS_FIELD);    findUpdatedDoc(document.getDocument(), "add_comment", SENSOR_NAME);}
0
protected IndexDao getDao()
{    return hbaseDao;}
0
protected String getIndexName()
{    return null;}
0
protected void addTestData(String indexName, String sensorType, List<Map<String, Object>> docs)
{}
0
protected List<Map<String, Object>> getIndexedTestData(String indexName, String sensorType)
{    return null;}
0
public void getIndexLookupFunctionShouldReturnConfiguredIndex()
{    IndexingConfigurations indexingConfigs = mock(IndexingConfigurations.class);    ConfigurationsCache cache = mock(ConfigurationsCache.class);    Map<String, Object> broIndexingConfig = new HashMap<String, Object>() {        {            put("writer", new HashMap<String, Object>() {                {                    put("index", "bro_index");                }            });        }    };    when(indexingConfigs.getSensorIndexingConfig("bro")).thenReturn(broIndexingConfig);    when(cache.get(IndexingConfigurations.class)).thenReturn(indexingConfigs);    assertEquals("bro_index", IndexingCacheUtil.getIndexLookupFunction(cache, "writer").apply("bro"));}
0
public void getIndexLookupFunctionShouldDefaultToSensorType()
{    IndexingConfigurations indexingConfigs = mock(IndexingConfigurations.class);    ConfigurationsCache cache = mock(ConfigurationsCache.class);    Map<String, Object> broIndexingConfig = new HashMap<String, Object>() {        {            put("writer", new HashMap<String, Object>() {                {                    put("index", "bro_index");                }            });        }    };    when(indexingConfigs.getSensorIndexingConfig("bro")).thenReturn(broIndexingConfig);    when(cache.get(IndexingConfigurations.class)).thenReturn(indexingConfigs);    assertEquals("Should default to sensor type on missing sensor config", "snort", IndexingCacheUtil.getIndexLookupFunction(cache, "writer").apply("snort"));    assertEquals("Should default to sensor type on missing writer config", "bro", IndexingCacheUtil.getIndexLookupFunction(cache, "someWriter").apply("bro"));}
0
public static void cleanHdfsDir(String hdfsDirStr)
{    File hdfsDir = new File(hdfsDirStr);    Stack<File> fs = new Stack<>();    if (hdfsDir.exists()) {        fs.push(hdfsDir);        while (!fs.empty()) {            File f = fs.pop();            if (f.isDirectory()) {                for (File child : f.listFiles()) {                    fs.push(child);                }            } else {                if (f.getName().startsWith("enrichment") || f.getName().endsWith(".json")) {                    f.delete();                }            }        }    }}
0
public static List<Map<String, Object>> readDocsFromDisk(String hdfsDirStr) throws IOException
{    List<Map<String, Object>> ret = new ArrayList<>();    File hdfsDir = new File(hdfsDirStr);    Stack<File> fs = new Stack<>();    if (hdfsDir.exists()) {        fs.push(hdfsDir);        while (!fs.empty()) {            File f = fs.pop();            if (f.isDirectory()) {                for (File child : f.listFiles()) {                    fs.push(child);                }            } else {                System.out.println("Processed " + f);                if (f.getName().startsWith("enrichment") || f.getName().endsWith(".json")) {                    List<byte[]> data = TestUtils.readSampleData(f.getPath());                    Iterables.addAll(ret, Iterables.transform(data, bytes -> {                        String s = new String(bytes, StandardCharsets.UTF_8);                        try {                            return JSONUtils.INSTANCE.load(s, JSONUtils.MAP_SUPPLIER);                        } catch (IOException e) {                            throw new RuntimeException(e);                        }                    }));                }            }        }    }    return ret;}
0
protected void preTest()
{    cleanHdfsDir(hdfsDir);}
0
public Processor<List<Map<String, Object>>> getProcessor(List<byte[]> inputMessages)
{    return new Processor<List<Map<String, Object>>>() {        List<Map<String, Object>> docs = null;        List<byte[]> errors = null;        @Override        public ReadinessState process(ComponentRunner runner) {            KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);            try {                docs = readDocsFromDisk(hdfsDir);            } catch (IOException e) {                throw new IllegalStateException("Unable to retrieve indexed documents.", e);            }            if (docs.size() < inputMessages.size()) {                errors = kafkaComponent.readMessages(IndexingIntegrationTest.ERROR_TOPIC);                if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {                    return ReadinessState.READY;                }                return ReadinessState.NOT_READY;            } else {                return ReadinessState.READY;            }        }        @Override        public ProcessorResult<List<Map<String, Object>>> getResult() {            ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();            return builder.withResult(docs).withProcessErrors(errors).build();        }    };}
0
public ReadinessState process(ComponentRunner runner)
{    KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);    try {        docs = readDocsFromDisk(hdfsDir);    } catch (IOException e) {        throw new IllegalStateException("Unable to retrieve indexed documents.", e);    }    if (docs.size() < inputMessages.size()) {        errors = kafkaComponent.readMessages(IndexingIntegrationTest.ERROR_TOPIC);        if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {            return ReadinessState.READY;        }        return ReadinessState.NOT_READY;    } else {        return ReadinessState.READY;    }}
0
public ProcessorResult<List<Map<String, Object>>> getResult()
{    ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();    return builder.withResult(docs).withProcessErrors(errors).build();}
0
public FieldNameConverter getFieldNameConverter()
{    return originalField -> originalField;}
0
public InMemoryComponent getSearchComponent(Properties topologyProperties) throws Exception
{    return null;}
0
public void setAdditionalProperties(Properties topologyProperties)
{    topologyProperties.setProperty("batch_indexing_kafka_start", "UNCOMMITTED_EARLIEST");    topologyProperties.setProperty("batch_indexing_workers", "1");    topologyProperties.setProperty("batch_indexing_acker_executors", "0");    topologyProperties.setProperty("batch_indexing_topology_max_spout_pending", "");    topologyProperties.setProperty("batch_indexing_kafka_spout_parallelism", "1");    topologyProperties.setProperty("bolt_hdfs_rotation_policy", "org.apache.storm.hdfs.bolt.rotation.TimedRotationPolicy");    topologyProperties.setProperty("bolt_hdfs_rotation_policy_count", "1");    topologyProperties.setProperty("bolt_hdfs_rotation_policy_units", "DAYS");    topologyProperties.setProperty("metron_apps_indexed_hdfs_dir", hdfsDir);    topologyProperties.setProperty("hdfs_writer_parallelism", "1");}
0
public String cleanField(String field)
{    return field;}
0
public String getTemplatePath()
{    return "../metron-indexing-storm/src/main/config/hdfs.properties.j2";}
0
public String getFluxPath()
{    return "../metron-indexing-storm/src/main/flux/indexing/batch/remote.yaml";}
0
protected void preTest()
{}
0
public void test() throws Exception
{    final List<byte[]> inputMessages = TestUtils.readSampleData(sampleParsedPath);    final Properties topologyProperties = new Properties() {        {            setProperty("indexing_kafka_start", "UNCOMMITTED_EARLIEST");            setProperty("kafka_security_protocol", "PLAINTEXT");            setProperty("topology_auto_credentials", "[]");            setProperty("indexing_workers", "1");            setProperty("indexing_acker_executors", "0");            setProperty("indexing_topology_worker_childopts", "");            setProperty("indexing_topology_max_spout_pending", "");            setProperty("indexing_input_topic", Constants.INDEXING_TOPIC);            setProperty("indexing_error_topic", ERROR_TOPIC);            setProperty("indexing_kafka_spout_parallelism", "1");            setProperty("indexing_writer_parallelism", "1");        }    };    setAdditionalProperties(topologyProperties);    final ZKServerComponent zkServerComponent = getZKServerComponent(topologyProperties);    final KafkaComponent kafkaComponent = getKafkaComponent(topologyProperties, new ArrayList<KafkaComponent.Topic>() {        {            add(new KafkaComponent.Topic(Constants.INDEXING_TOPIC, 1));            add(new KafkaComponent.Topic(ERROR_TOPIC, 1));        }    });    List<Map<String, Object>> inputDocs = new ArrayList<>();    for (byte[] b : inputMessages) {        Map<String, Object> m = JSONUtils.INSTANCE.load(new String(b, StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER);        inputDocs.add(m);    }    final AtomicBoolean isLoaded = new AtomicBoolean(false);    ConfigUploadComponent configUploadComponent = new ConfigUploadComponent().withTopologyProperties(topologyProperties).withGlobalConfigsPath(sampleConfigPath).withEnrichmentConfigsPath(sampleConfigPath).withIndexingConfigsPath(sampleConfigPath).withPostStartCallback(component -> {        try {            waitForIndex(component.getTopologyProperties().getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY));        } catch (Exception e) {            e.printStackTrace();        }        isLoaded.set(true);    });    FluxTopologyComponent fluxComponent = new FluxTopologyComponent.Builder().withTopologyLocation(new File(getFluxPath())).withTopologyName("test").withTemplateLocation(new File(getTemplatePath())).withTopologyProperties(topologyProperties).build();    ComponentRunner runner = null;    InMemoryComponent searchComponent = getSearchComponent(topologyProperties);    ComponentRunner.Builder componentBuilder = new ComponentRunner.Builder();    componentBuilder = componentBuilder.withComponent("zk", zkServerComponent).withComponent("kafka", kafkaComponent).withComponent("config", configUploadComponent).withComponent("storm", fluxComponent).withMillisecondsBetweenAttempts(1500).withNumRetries(NUM_RETRIES).withMaxTimeMS(TOTAL_TIME_MS);    if (searchComponent != null) {        componentBuilder = componentBuilder.withComponent("search", getSearchComponent(topologyProperties)).withCustomShutdownOrder(new String[] { "search", "storm", "config", "kafka", "zk" });    } else {        componentBuilder = componentBuilder.withCustomShutdownOrder(new String[] { "storm", "config", "kafka", "zk" });    }    runner = componentBuilder.build();    try {        runner.start();        while (!isLoaded.get()) {            Thread.sleep(100);        }        fluxComponent.submitTopology();        kafkaComponent.writeMessages(Constants.INDEXING_TOPIC, inputMessages);        List<Map<String, Object>> docs = cleanDocs(runner.process(getProcessor(inputMessages)));        Assert.assertEquals(docs.size(), inputMessages.size());                        assertInputDocsMatchOutputs(inputDocs, docs, getFieldNameConverter());    } finally {        if (runner != null) {            runner.stop();        }    }}
0
private void waitForIndex(String zookeeperQuorum) throws Exception
{    try (CuratorFramework client = getClient(zookeeperQuorum)) {        client.start();        System.out.println("Waiting for zookeeper...");        byte[] bytes = null;        do {            try {                bytes = ConfigurationsUtils.readSensorIndexingConfigBytesFromZookeeper(testSensorType, client);                Thread.sleep(1000);            } catch (KeeperException.NoNodeException nne) {                        }        } while (bytes == null || bytes.length == 0);        System.out.println("Found index config in zookeeper...");    }}
0
public List<Map<String, Object>> cleanDocs(ProcessorResult<List<Map<String, Object>>> result)
{    List<Map<String, Object>> docs = result.getResult();    StringBuffer buffer = new StringBuffer();    boolean failed = false;    List<Map<String, Object>> ret = new ArrayList<>();    if (result.failed()) {        failed = true;        result.getBadResults(buffer);        buffer.append(String.format("%d Valid messages processed", docs.size())).append("\n");        for (Map<String, Object> doc : docs) {            Map<String, Object> msg = new HashMap<>();            for (Map.Entry<String, Object> kv : doc.entrySet()) {                                buffer.append(cleanField(kv.getKey())).append(kv.getValue().toString()).append("\n");            }        }        Assert.fail(buffer.toString());    } else {        for (Map<String, Object> doc : docs) {            Map<String, Object> msg = new HashMap<>();            for (Map.Entry<String, Object> kv : doc.entrySet()) {                                msg.put(cleanField(kv.getKey()), kv.getValue());            }            ret.add(msg);        }    }    return ret;}
0
public void assertInputDocsMatchOutputs(List<Map<String, Object>> inputDocs, List<Map<String, Object>> indexDocs, FieldNameConverter converter)
{    for (Map<String, Object> indexDoc : indexDocs) {        boolean foundMatch = false;        for (Map<String, Object> doc : inputDocs) {            if (docMatches(indexDoc, doc, converter)) {                foundMatch = true;                break;            }        }        if (!foundMatch) {            System.err.println("Unable to find: ");            printMessage(indexDoc);            dumpMessages("INPUT DOCS:", inputDocs);        }        Assert.assertTrue(foundMatch);    }}
0
private void printMessage(Map<String, Object> doc)
{    TreeMap<String, Object> d = new TreeMap<>(doc);    for (Map.Entry<String, Object> kv : d.entrySet()) {        System.err.println("  " + kv.getKey() + " -> " + kv.getValue());    }}
0
private void dumpMessages(String title, List<Map<String, Object>> docs)
{    System.err.println(title);    int cnt = 0;    for (Map<String, Object> doc : docs) {        System.err.println("MESSAGE " + cnt++);        printMessage(doc);    }}
0
 boolean docMatches(Map<String, Object> indexedDoc, Map<String, Object> inputDoc, FieldNameConverter converter)
{    String key = "original_string";    String indexKey = converter.convert(key);    String originalString = inputDoc.get(key).toString();    return originalString.equals(indexedDoc.get(indexKey).toString());}
0
protected static KafkaComponent getKafkaComponent(final Properties topologyProperties, List<KafkaComponent.Topic> topics)
{    return new KafkaComponent().withTopics(topics).withTopologyProperties(topologyProperties);}
0
protected static ZKServerComponent getZKServerComponent(final Properties topologyProperties)
{    return new ZKServerComponent().withPostStartCallback((zkComponent) -> {        topologyProperties.setProperty(ZKServerComponent.ZOOKEEPER_PROPERTY, zkComponent.getConnectionString());        topologyProperties.setProperty("kafka.zk", zkComponent.getConnectionString());    });}
0
public Builder withNumRetries(int numRetries)
{    this.numRetries = numRetries;    return this;}
0
public Builder withMaxTimeMS(long maxTimeMS)
{    this.maxTimeMS = maxTimeMS;    return this;}
0
public Builder withComponent(String name, InMemoryComponent component)
{    components.put(name, component);    return this;}
0
public Builder withCustomStartupOrder(String[] startupOrder)
{    this.startupOrder = startupOrder;    return this;}
0
public Builder withCustomShutdownOrder(String[] shutdownOrder)
{    this.shutdownOrder = shutdownOrder;    return this;}
0
public Builder withCustomResetOrder(String[] resetOrder)
{    this.resetOrder = resetOrder;    return this;}
0
public Builder withMillisecondsBetweenAttempts(long timeBetweenAttempts)
{    this.timeBetweenAttempts = timeBetweenAttempts;    return this;}
0
private static String[] toOrderedList(Map<String, InMemoryComponent> components)
{    String[] ret = new String[components.size()];    int i = 0;    for (String component : components.keySet()) {        ret[i++] = component;    }    return ret;}
0
public ComponentRunner build()
{    if (shutdownOrder == null) {        shutdownOrder = toOrderedList(components);    }    if (startupOrder == null) {        startupOrder = toOrderedList(components);    }    if (resetOrder == null) {                if (shutdownOrder != null) {            resetOrder = shutdownOrder;        } else {            resetOrder = toOrderedList(components);        }    }    return new ComponentRunner(components, startupOrder, shutdownOrder, resetOrder, timeBetweenAttempts, numRetries, maxTimeMS);}
0
public T getComponent(String name, Class<T> clazz)
{    return clazz.cast(getComponents().get(name));}
0
public LinkedHashMap<String, InMemoryComponent> getComponents()
{    return components;}
0
public void start() throws UnableToStartException
{    for (String componentName : startupOrder) {        components.get(componentName).start();    }}
0
public void stop()
{    for (String componentName : shutdownOrder) {        components.get(componentName).stop();    }}
0
public void reset()
{    for (String componentName : resetOrder) {        components.get(componentName).reset();    }}
0
public ProcessorResult<T> process(Processor<T> successState)
{    int retryCount = 0;    long start = System.currentTimeMillis();    while (true) {        long duration = System.currentTimeMillis() - start;        if (maxTimeMS > 0 && duration > maxTimeMS) {            throw new RuntimeException("Took too long to complete: " + duration + " > " + maxTimeMS);        }        ReadinessState state = successState.process(this);        if (state == ReadinessState.READY) {            return successState.getResult();        } else if (state == ReadinessState.NOT_READY) {            retryCount++;            if (numRetries > 0 && retryCount > numRetries) {                throw new RuntimeException("Too many retries: " + retryCount);            }        }        try {            Thread.sleep(timeBetweenAttempts);        } catch (InterruptedException e) {            throw new RuntimeException("Unable to sleep", e);        }    }}
0
public Builder withTopologyName(String name)
{    this.topologyName = name;    return this;}
0
public Builder withTopologyLocation(File location)
{    this.topologyLocation = location;    return this;}
0
public Builder withTemplateLocation(File location)
{    this.templateLocation = location;    return this;}
0
public Builder withTopologyProperties(Properties properties)
{    this.topologyProperties = properties;    this.topologyProperties.put("storm.home", "target");    return this;}
0
public FluxTopologyComponent build()
{    return new FluxTopologyComponent(topologyName, topologyLocation, templateLocation, topologyProperties);}
0
public LocalCluster getStormCluster()
{    return stormCluster;}
0
public String getTopologyName()
{    return topologyName;}
0
public File getTopologyLocation()
{    return topologyLocation;}
0
public File getTemplateLocation()
{    return templateLocation;}
0
public Properties getTopologyProperties()
{    return topologyProperties;}
0
public String getZookeeperConnectString()
{    return "localhost:2000";}
0
public void start() throws UnableToStartException
{    try {        stormCluster = new LocalCluster();        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);        try (CuratorFramework client = CuratorFrameworkFactory.newClient(getZookeeperConnectString(), retryPolicy)) {            client.start();            String root = "/storm/leader-lock";            Stat exists = client.checkExists().forPath(root);            if (exists == null) {                client.create().creatingParentsIfNeeded().forPath(root);            }        } catch (Exception e) {                    } finally {        }    } catch (Exception e) {        throw new UnableToStartException("Unable to start flux topology: " + getTopologyLocation(), e);    }}
1
public static void cleanupWorkerDir()
{    if (new File("logs/workers-artifacts").exists()) {        Path rootPath = Paths.get("logs");        Path destPath = Paths.get("target/logs");        try {            Files.move(rootPath, destPath);            Files.walk(destPath).sorted(Comparator.reverseOrder()).map(Path::toFile).forEach(File::delete);        } catch (IOException e) {            throw new IllegalStateException(e.getMessage(), e);        }    }}
0
public void stop()
{    if (stormCluster != null) {        try {            try {                                killTopology();                stormCluster.shutdown();            } catch (IllegalStateException ise) {                if (!(ise.getMessage().contains("It took over") && ise.getMessage().contains("to shut down slot"))) {                    throw ise;                } else {                                        assassinateSlots();                                    }            } catch (RuntimeException re) {                if (re.getCause() instanceof TProtocolException) {                                } else {                    throw re;                }            }        } catch (Throwable t) {                    } finally {            cleanupWorkerDir();        }    }}
1
public void reset()
{    if (stormCluster != null) {        killTopology();    }}
0
protected void killTopology()
{    KillOptions ko = new KillOptions();    ko.set_wait_secs(0);    stormCluster.killTopologyWithOpts(topologyName, ko);    try {                Thread.sleep(2000);    } catch (InterruptedException e) {        }}
0
public static void assassinateSlots()
{    /*    You might be wondering why I'm not just casting to slot here, but that's because the Slot class moved locations    and we're supporting multiple versions of storm.     */        Thread.getAllStackTraces().keySet().stream().filter(t -> t instanceof AutoCloseable && t.getName().toLowerCase().contains("slot")).forEach(t -> {                        try {            t.stop();                    } catch (Exception e) {                }    });}
1
public void submitTopology() throws NoSuchMethodException, IOException, InstantiationException, TException, IllegalAccessException, InvocationTargetException, ClassNotFoundException, NoSuchFieldException
{    startTopology(getTopologyName(), getTopologyLocation(), getTemplateLocation(), getTopologyProperties());}
0
private void startTopology(String topologyName, File topologyLoc, File templateFile, Properties properties) throws IOException, ClassNotFoundException, NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException, TException, NoSuchFieldException
{    TopologyDef topologyDef = loadYaml(topologyName, topologyLoc, templateFile, properties);    Config conf = FluxBuilder.buildConfig(topologyDef);    ExecutionContext context = new ExecutionContext(topologyDef, conf);    StormTopology topology = FluxBuilder.buildTopology(context);    Assert.assertNotNull(topology);    topology.validate();    try {        stormCluster.submitTopology(topologyName, conf, topology);    } catch (Exception nne) {        try {            Thread.sleep(2000);        } catch (InterruptedException e) {        }        stormCluster.submitTopology(topologyName, conf, topology);    }}
0
private static TopologyDef loadYaml(String topologyName, File yamlFile, File templateFile, Properties properties) throws IOException
{    File tmpFile = File.createTempFile(topologyName, "props");    tmpFile.deleteOnExit();    if (templateFile != null) {        try (Writer propWriter = new OutputStreamWriter(new FileOutputStream(tmpFile), StandardCharsets.UTF_8)) {            String templateContents = FileUtils.readFileToString(templateFile);            for (Map.Entry prop : properties.entrySet()) {                String replacePattern = String.format("{{%s}}", prop.getKey());                templateContents = templateContents.replaceAll(Pattern.quote(replacePattern), (String) prop.getValue());            }            propWriter.write(templateContents);            propWriter.flush();            return FluxParser.parseFile(yamlFile.getAbsolutePath(), false, true, tmpFile.getAbsolutePath(), false);        }    } else {        try (Writer propWriter = new OutputStreamWriter(new FileOutputStream(tmpFile), StandardCharsets.UTF_8)) {            properties.store(propWriter, topologyName + " properties");            return FluxParser.parseFile(yamlFile.getAbsolutePath(), false, true, tmpFile.getAbsolutePath(), false);        }    }}
0
public KafkaComponent withPostStartCallback(Function<KafkaComponent, Void> f)
{    postStartCallback = f;    return this;}
0
public KafkaComponent withExistingZookeeper(String zookeeperConnectString)
{    this.zookeeperConnectString = zookeeperConnectString;    return this;}
0
public KafkaComponent withTopologyProperties(Properties properties)
{    this.topologyProperties = properties;    return this;}
0
public KafkaComponent withBrokerPort(int brokerPort)
{    if (brokerPort <= 0) {        brokerPort = TestUtils.RandomPort();    }    this.brokerPort = brokerPort;    return this;}
0
public KafkaComponent withTopics(List<Topic> topics)
{    this.topics = topics;    return this;}
0
public List<Topic> getTopics()
{    return topics;}
0
public int getBrokerPort()
{    return brokerPort;}
0
public String getBrokerList()
{    return "localhost:" + brokerPort;}
0
public KafkaProducer<K, V> createProducer(Class<K> keyClass, Class<V> valueClass)
{    return createProducer(new HashMap<>(), keyClass, valueClass);}
0
public KafkaProducer<String, byte[]> createProducer()
{    return createProducer(String.class, byte[].class);}
0
public KafkaProducer<K, V> createProducer(Map<String, Object> properties, Class<K> keyClass, Class<V> valueClass)
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", getBrokerList());    producerConfig.put("key.serializer", "org.apache.kafka.common.serialization.ByteArraySerializer");    producerConfig.put("value.serializer", "org.apache.kafka.common.serialization.ByteArraySerializer");    producerConfig.put("request.required.acks", "-1");    producerConfig.put("fetch.message.max.bytes", "" + 1024 * 1024 * 10);    producerConfig.put("replica.fetch.max.bytes", "" + 1024 * 1024 * 10);    producerConfig.put("message.max.bytes", "" + 1024 * 1024 * 10);    producerConfig.put("message.send.max.retries", "10");    producerConfig.putAll(properties);    KafkaProducer<K, V> ret = new KafkaProducer<>(producerConfig);    producersCreated.add(ret);    return ret;}
0
public void start()
{        zookeeperConnectString = topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY);    zkClient = new ZkClient(zookeeperConnectString, ZK_SESSION_TIMEOUT_MS, ZK_CONNECTION_TIMEOUT_MS, ZKStringSerializer$.MODULE$);        Properties props = TestUtilsWrapper.createBrokerConfig(0, zookeeperConnectString, brokerPort);    props.setProperty("zookeeper.connection.timeout.ms", Integer.toString(KAFKA_ZOOKEEPER_TIMEOUT_MS));    KafkaConfig config = new KafkaConfig(props);    Time mock = new MockTime();    kafkaServer = TestUtils.createServer(config, mock);    org.apache.log4j.Level oldLevel = UnitTestHelper.getLog4jLevel(KafkaServer.class);    UnitTestHelper.setLog4jLevel(KafkaServer.class, org.apache.log4j.Level.OFF);        TestUtilsWrapper.waitUntilBrokerIsRunning(kafkaServer, "Timed out waiting for RunningAsBroker State", 100000);    for (Topic topic : getTopics()) {        try {            createTopic(topic.name, topic.numPartitions, KAFKA_PROPAGATE_TIMEOUT_MS);        } catch (InterruptedException e) {            throw new RuntimeException("Unable to create topic", e);        }    }    UnitTestHelper.setLog4jLevel(KafkaServer.class, oldLevel);    if (postStartCallback != null) {        postStartCallback.apply(this);    }}
0
public String getZookeeperConnect()
{    return zookeeperConnectString;}
0
public void stop()
{    shutdownConsumer();    shutdownProducers();    if (kafkaServer != null) {        try {            kafkaServer.shutdown();            kafkaServer.awaitShutdown();        } catch (Throwable fnf) {            if (!fnf.getMessage().contains("Error writing to highwatermark file")) {                throw fnf;            }        }    }    if (zkClient != null) {                for (Topic topic : topics) {            zkClient.deleteRecursive(ZkUtils.getTopicPath(topic.name));        }        zkClient.deleteRecursive(ZkUtils.BrokerIdsPath());        zkClient.deleteRecursive(ZkUtils.BrokerTopicsPath());        zkClient.deleteRecursive(ZkUtils.ConsumersPath());        zkClient.deleteRecursive(ZkUtils.ControllerPath());        zkClient.deleteRecursive(ZkUtils.ControllerEpochPath());        zkClient.deleteRecursive(ZkUtils.ReassignPartitionsPath());        zkClient.deleteRecursive(ZkUtils.DeleteTopicsPath());        zkClient.deleteRecursive(ZkUtils.PreferredReplicaLeaderElectionPath());        zkClient.deleteRecursive(ZkUtils.BrokerSequenceIdPath());        zkClient.deleteRecursive(ZkUtils.IsrChangeNotificationPath());        zkClient.deleteRecursive(ZkUtils.EntityConfigPath());        zkClient.deleteRecursive(ZkUtils.EntityConfigChangesPath());        zkClient.close();    }}
0
public void reset()
{            stop();    start();}
0
public List<byte[]> readMessages(String topic)
{    SimpleConsumer consumer = new SimpleConsumer("localhost", 6667, 100000, 64 * 1024, "consumer");    FetchRequest req = new FetchRequestBuilder().clientId("consumer").addFetch(topic, 0, 0, 100000).build();    FetchResponse fetchResponse = consumer.fetch(req);    Iterator<MessageAndOffset> results = fetchResponse.messageSet(topic, 0).iterator();    List<byte[]> messages = new ArrayList<>();    while (results.hasNext()) {        ByteBuffer payload = results.next().message().payload();        byte[] bytes = new byte[payload.limit()];        payload.get(bytes);        messages.add(bytes);    }    consumer.close();    return messages;}
0
public ConsumerIterator<byte[], byte[]> getStreamIterator(String topic)
{    return getStreamIterator(topic, "group0", "consumer0");}
0
public ConsumerIterator<byte[], byte[]> getStreamIterator(String topic, String group, String consumerName)
{        Properties consumerProperties = TestUtils.createConsumerProperties(zookeeperConnectString, group, consumerName, -1);    consumer = kafka.consumer.Consumer.createJavaConsumerConnector(new ConsumerConfig(consumerProperties));    Map<String, Integer> topicCountMap = new HashMap<String, Integer>();    topicCountMap.put(topic, 1);    Map<String, List<KafkaStream<byte[], byte[]>>> consumerMap = consumer.createMessageStreams(topicCountMap);    KafkaStream<byte[], byte[]> stream = consumerMap.get(topic).get(0);    ConsumerIterator<byte[], byte[]> iterator = stream.iterator();    return iterator;}
0
public void shutdownConsumer()
{    if (consumer != null) {        consumer.shutdown();    }}
0
public void shutdownProducers()
{    for (KafkaProducer kp : producersCreated) {        try {            kp.close();        } catch (Exception ex) {                    }    }}
1
public void createTopic(String name) throws InterruptedException
{    createTopic(name, 1, KAFKA_PROPAGATE_TIMEOUT_MS);}
0
public void waitUntilMetadataIsPropagated(String topic, int numPartitions, long timeOutMS)
{    List<KafkaServer> servers = new ArrayList<>();    servers.add(kafkaServer);    for (int part = 0; part < numPartitions; ++part) {        TestUtils.waitUntilMetadataIsPropagated(scala.collection.JavaConversions.asScalaBuffer(servers), topic, part, timeOutMS);    }}
0
public void createTopic(String name, int numPartitions, long waitThisLongForMetadataToPropagate) throws InterruptedException
{    ZkUtils zkUtils = null;    Level oldLevel = UnitTestHelper.getJavaLoggingLevel();    try {        UnitTestHelper.setJavaLoggingLevel(Level.OFF);        zkUtils = ZkUtils.apply(zookeeperConnectString, 30000, 30000, false);        AdminUtilsWrapper.createTopic(zkUtils, name, numPartitions, 1, new Properties());        if (waitThisLongForMetadataToPropagate > 0) {            waitUntilMetadataIsPropagated(name, numPartitions, waitThisLongForMetadataToPropagate);        }    } catch (TopicExistsException tee) {    } finally {        if (zkUtils != null) {            zkUtils.close();        }        UnitTestHelper.setJavaLoggingLevel(oldLevel);    }}
0
public void writeMessages(String topic, Collection<byte[]> messages)
{    try (KafkaProducer<String, byte[]> kafkaProducer = createProducer()) {        for (byte[] message : messages) {            kafkaProducer.send(new ProducerRecord<>(topic, message));        }    }}
0
public void writeMessages(String topic, String... messages)
{        List<byte[]> messagesAsBytes = Stream.of(messages).map(Bytes::toBytes).collect(Collectors.toList());    writeMessages(topic, messagesAsBytes);}
0
public void writeMessages(String topic, List<String> messages)
{    writeMessages(topic, messages.toArray(new String[] {}));}
0
public MRComponent withBasePath(String path)
{    basePath = new Path(path);    return this;}
0
public Configuration getConfiguration()
{    return configuration;}
0
public Path getBasePath()
{    return basePath;}
0
public void start()
{    configuration = new Configuration();    System.clearProperty(MiniDFSCluster.PROP_TEST_BUILD_DATA);    configuration.set(YarnConfiguration.YARN_MINICLUSTER_FIXED_PORTS, "true");    if (basePath == null) {        throw new RuntimeException("Unable to start cluster: You must specify the basepath");    }    configuration.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, basePath.toString());    try {        cluster = new MiniDFSCluster.Builder(configuration).build();    } catch (IOException e) {        throw new RuntimeException("Unable to start cluster", e);    }}
0
public void stop()
{    cluster.shutdown();}
0
public YarnComponent withApplicationMasterClass(Class clazz)
{    appmasterJar = JarFinder.getJar(clazz);    return this;}
0
public YarnComponent withTestName(String name)
{    this.testName = name;    return this;}
0
public String getAppMasterJar()
{    return appmasterJar;}
0
public YarnConfiguration getConfig()
{    return conf;}
0
public MiniYARNCluster getYARNCluster()
{    return yarnCluster;}
0
public void start() throws UnableToStartException
{    conf = new YarnConfiguration();    conf.setInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 128);    conf.set("yarn.log.dir", "target");    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);    conf.set(YarnConfiguration.RM_SCHEDULER, CapacityScheduler.class.getName());    conf.setBoolean(YarnConfiguration.NODE_LABELS_ENABLED, true);    try {        yarnCluster = new MiniYARNCluster(testName, 1, NUM_NMS, 1, 1, true);        yarnCluster.init(conf);        yarnCluster.start();        waitForNMsToRegister();        URL url = Thread.currentThread().getContextClassLoader().getResource("yarn-site.xml");        if (url == null) {            throw new RuntimeException("Could not find 'yarn-site.xml' dummy file in classpath");        }        Configuration yarnClusterConfig = yarnCluster.getConfig();        yarnClusterConfig.set("yarn.application.classpath", new File(url.getPath()).getParent());                        ByteArrayOutputStream bytesOut = new ByteArrayOutputStream();        yarnClusterConfig.writeXml(bytesOut);        bytesOut.close();                OutputStream os = new FileOutputStream(new File(url.getPath()));        os.write(bytesOut.toByteArray());        os.close();        FileContext fsContext = FileContext.getLocalFSFileContext();        fsContext.delete(new Path(conf.get("yarn.timeline-service.leveldb-timeline-store.path")), true);        try {            Thread.sleep(2000);        } catch (InterruptedException e) {        }    } catch (Exception e) {        throw new UnableToStartException("Exception setting up yarn cluster", e);    }}
0
public void stop()
{    if (yarnCluster != null) {        try {            yarnCluster.stop();        } finally {            yarnCluster = null;        }    }    try {        FileContext fsContext = FileContext.getLocalFSFileContext();        fsContext.delete(new Path(conf.get("yarn.timeline-service.leveldb-timeline-store.path")), true);    } catch (Exception e) {    }}
0
protected void waitForNMsToRegister() throws Exception
{    int sec = 60;    while (sec >= 0) {        if (yarnCluster.getResourceManager().getRMContext().getRMNodes().size() >= NUM_NMS) {            break;        }        Thread.sleep(1000);        sec--;    }}
0
public String getConnectionString()
{    return this.zookeeperUrl;}
0
public ZKServerComponent withPostStartCallback(Consumer<ZKServerComponent> f)
{    postStartCallback = Optional.ofNullable(f);    return this;}
0
public void start() throws UnableToStartException
{    try {        testZkServer = new TestingServer(true);        zookeeperUrl = testZkServer.getConnectString();        if (postStartCallback.isPresent()) {            postStartCallback.get().accept(this);        }    } catch (Exception e) {        throw new UnableToStartException("Unable to start TestingServer", e);    }}
0
public void stop()
{    try {        if (testZkServer != null) {            testZkServer.close();        }    } catch (Exception e) {        }}
0
public void reset()
{    if (testZkServer != null) {        try {            FileUtils.deleteDirectory(testZkServer.getTempDirectory());        } catch (IOException e) {                }    }}
0
 void reset()
{}
0
public Builder withResult(T result)
{    this.result = result;    return this;}
0
public Builder withProcessErrors(List<byte[]> processErrors)
{    this.processErrors = processErrors;    return this;}
0
public ProcessorResult<T> build()
{    return new ProcessorResult<T>(result, processErrors);}
0
public T getResult()
{    return result;}
0
public List<byte[]> getProcessErrors()
{    return processErrors;}
0
public boolean failed()
{    return processErrors.size() > 0;}
0
public void getBadResults(StringBuffer buffer)
{    if (buffer == null) {        return;    }    buffer.append(String.format("%d Errors", processErrors.size()));    for (byte[] outputMessage : processErrors) {        buffer.append(new String(outputMessage, StandardCharsets.UTF_8));    }    buffer.append("\n");}
0
public List<byte[]> getMessages()
{    return messages;}
0
public List<byte[]> getErrors()
{    return errors;}
0
public KafkaProcessor withKafkaComponentName(String name)
{    this.kafkaComponentName = name;    return this;}
0
public KafkaProcessor withReadTopic(String topicName)
{    this.readTopic = topicName;    return this;}
0
public KafkaProcessor withErrorTopic(String topicName)
{    this.errorTopic = topicName;    return this;}
0
public KafkaProcessor withValidateReadMessages(Function<KafkaMessageSet, Boolean> validate)
{    this.validateReadMessages = validate;    return this;}
0
public KafkaProcessor withProvideResult(Function<KafkaMessageSet, T> provide)
{    this.provideResult = provide;    return this;}
0
public ReadinessState process(ComponentRunner runner)
{    KafkaComponent kafkaComponent = runner.getComponent(kafkaComponentName, KafkaComponent.class);    LinkedList<byte[]> outputMessages = new LinkedList<>(kafkaComponent.readMessages(readTopic));    LinkedList<byte[]> outputErrors = null;    if (errorTopic != null) {        outputErrors = new LinkedList<>(kafkaComponent.readMessages(errorTopic));    }    Boolean validated = validateReadMessages.apply(new KafkaMessageSet(outputMessages, outputErrors));    if (validated == null) {        validated = false;    }    if (validated) {        messages.addAll(outputMessages);        errors.addAll(outputErrors);        outputMessages.clear();        outputErrors.clear();        return ReadinessState.READY;    }    return ReadinessState.NOT_READY;}
0
public ProcessorResult<T> getResult()
{    ProcessorResult.Builder<T> builder = new ProcessorResult.Builder();    return builder.withResult(provideResult.apply(new KafkaMessageSet(messages, errors))).withProcessErrors(errors).build();}
0
public static void setup()
{    component = new MRComponent().withBasePath("target");    component.start();    configuration = component.getConfiguration();    try {        FileSystem fs = FileSystem.newInstance(configuration);        fs.mkdirs(new Path("/classpath-resources"));        fs.copyFromLocalFile(new Path("src/test/classpath-resources/custom-1.0-SNAPSHOT.jar"), new Path("/classpath-resources"));    } catch (IOException e) {        throw new RuntimeException("Unable to start cluster", e);    }}
0
public static void teardown()
{    component.stop();}
0
public static ClasspathFunctionResolver create(Properties config)
{    ClasspathFunctionResolver resolver = new ClasspathFunctionResolver();    Context context = new Context.Builder().with(Context.Capabilities.STELLAR_CONFIG, () -> config).build();    resolver.initialize(context);    return resolver;}
0
public void test() throws Exception
{    Properties config = new Properties();    config.put(STELLAR_VFS_PATHS.param(), configuration.get("fs.defaultFS") + "/classpath-resources/.*.jar");    ClasspathFunctionResolver resolver = create(config);    HashSet<String> functions = new HashSet<>(Lists.newArrayList(resolver.getFunctions()));    Assert.assertTrue(functions.contains("NOW"));}
0
public static void runWithZK(ThrowingBiConsumer<TestZKServer, CuratorFramework> testFunc) throws Exception
{    try (TestZKServer zkServer = new TestZKServer();        CuratorFramework zkClient = zkServer.newClient()) {        zkClient.start();        testFunc.accept(zkServer, zkClient);    }}
0
public String getZookeeperUrl()
{    return zookeeperUrl;}
0
public CuratorFramework newClient()
{    return ConfigurationsUtils.getClient(zookeeperUrl);}
0
public void close()
{    testZkServer.stop();    testZkServer.reset();}
0
public static void send(Producer<K, V> producer, K key, V value, String topic)
{    ProducerRecord<K, V> record = new ProducerRecord<K, V>(topic, key, value);    producer.send(record);}
0
public static void send(Producer<K, V> producer, Iterable<Map.Entry<K, V>> messages, String topic, long sleepBetween) throws InterruptedException
{    for (Map.Entry<K, V> kv : messages) {        send(producer, kv.getKey(), kv.getValue(), topic);        if (sleepBetween > 0) {            Thread.sleep(sleepBetween);        }    }}
0
public static void assertEventually(Assertion assertion) throws Exception
{    assertEventually(assertion, MAX_ASSERT_WAIT_MS);}
0
public static void assertEventually(Assertion assertion, long msToWait) throws Exception
{    long delta = msToWait / 10;    for (int i = 0; i < 10; ++i) {        try {            assertion.apply();            return;        } catch (AssertionError t) {        }        Thread.sleep(delta);    }    assertion.apply();}
0
public static List<byte[]> readSampleData(String samplePath) throws IOException
{    BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(samplePath), StandardCharsets.UTF_8));    List<byte[]> ret = new ArrayList<>();    for (String line = null; (line = br.readLine()) != null; ) {        ret.add(line.getBytes(StandardCharsets.UTF_8));    }    br.close();    return ret;}
0
public static void write(File file, String[] contents) throws IOException
{    StringBuilder b = new StringBuilder();    for (String line : contents) {        b.append(line);        b.append(System.lineSeparator());    }    write(file, b.toString());}
0
public static File write(File file, String contents) throws IOException
{    com.google.common.io.Files.createParentDirs(file);    com.google.common.io.Files.write(contents, file, StandardCharsets.UTF_8);    return file;}
0
public static String read(File in) throws IOException
{    return read(in, StandardCharsets.UTF_8);}
0
public static String read(File in, Charset charset) throws IOException
{    byte[] bytes = Files.readAllBytes(Paths.get(in.getPath()));    return new String(bytes, charset);}
0
public static File createTempDir(String prefix) throws IOException
{    final Path tmpDir = Files.createTempDirectory(prefix);    Runtime.getRuntime().addShutdownHook(new Thread() {        @Override        public void run() {            try {                cleanDir(tmpDir);            } catch (IOException e) {                System.out.println("Warning: Unable to clean tmp folder.");            }        }    });    return tmpDir.toFile();}
0
public void run()
{    try {        cleanDir(tmpDir);    } catch (IOException e) {        System.out.println("Warning: Unable to clean tmp folder.");    }}
0
public static void cleanDir(Path dir) throws IOException
{    Files.walkFileTree(dir, new SimpleFileVisitor<Path>() {        @Override        public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {            if (exc == null) {                return FileVisitResult.CONTINUE;            } else {                throw exc;            }        }    });}
0
public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
0
public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
0
public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException
{    if (exc == null) {        return FileVisitResult.CONTINUE;    } else {        throw exc;    }}
0
public static File createDir(File parent, String child)
{    File newDir = new File(parent, child);    newDir.mkdirs();    return newDir;}
0
public JobStatus withJobId(String jobId)
{    this.jobId = jobId;    return this;}
0
public JobStatus withState(State state)
{    this.state = state;    return this;}
0
public JobStatus withPercentComplete(double percentComplete)
{    this.percentComplete = percentComplete;    return this;}
0
public JobStatus withDescription(String description)
{    this.description = description;    return this;}
0
public JobStatus withCompletionTime(long completionTime)
{    this.completionTime = completionTime;    return this;}
0
public JobStatus withFailureException(Throwable failureReason)
{    this.failureReason = failureReason;    return this;}
0
public String getJobId()
{    return jobId;}
0
public State getState()
{    return state;}
0
public double getPercentComplete()
{    return percentComplete;}
0
public String getDescription()
{    return description;}
0
public long getCompletionTime()
{    return completionTime;}
0
public Throwable getFailureReason()
{    return failureReason;}
0
public JobStatus submit(Supplier<Statusable<PAGE_T>> jobSupplier, String username) throws JobException
{    Map<String, Statusable<PAGE_T>> userJobs = getUserJobs(username);    Statusable<PAGE_T> job = jobSupplier.get();    userJobs.put(job.getStatus().getJobId(), job);    jobs.put(username, userJobs);    return job.getStatus();}
0
public JobStatus getStatus(String username, String jobId) throws JobException
{    return getJob(username, jobId).getStatus();}
0
public boolean done(String username, String jobId) throws JobException
{    return getJob(username, jobId).isDone();}
0
public void killJob(String username, String jobId) throws JobException
{    getJob(username, jobId).kill();}
0
public Statusable<PAGE_T> getJob(String username, String jobId) throws JobException
{    Map<String, Statusable<PAGE_T>> jobStatusables = getUserJobs(username);    if (jobStatusables.size() > 0 && jobStatusables.containsKey(jobId)) {        return jobStatusables.get(jobId);    }    throw new JobNotFoundException("Could not find job " + jobId + " for user " + username);}
0
private Map<String, Statusable<PAGE_T>> getUserJobs(String username)
{    return jobs.getOrDefault(username, Collections.synchronizedMap(new HashMap<>()));}
0
public List<Statusable<PAGE_T>> getJobs(String username) throws JobException
{    return new ArrayList<>(getUserJobs(username).values());}
0
public void clear()
{    jobs.clear();}
0
public void constructor_copies_from_existing_instance()
{    JobStatus original = new JobStatus().withState(State.SUCCEEDED).withCompletionTime(5000).withJobId("abc123").withDescription("All done").withPercentComplete(100.0);    JobStatus copied = new JobStatus(original);    assertThat(copied.getState(), equalTo(State.SUCCEEDED));    assertThat(copied.getCompletionTime(), equalTo(5000L));    assertThat(copied.getJobId(), equalTo("abc123"));    assertThat(copied.getDescription(), equalTo("All done"));    assertThat(copied.getPercentComplete(), equalTo(100.0));}
0
public void failure_info_provided()
{    JobException e = new JobException("The job blew up.");    JobStatus original = new JobStatus().withState(State.FAILED).withDescription("Failed").withFailureException(e);    assertThat(original.getFailureReason(), equalTo(e));}
0
public void setup() throws JobException
{    MockitoAnnotations.initMocks(this);    jm = new InMemoryJobManager<Path>();    config = new HashMap<>();    username1 = "user123";    username2 = "user456";    jobId1 = "job_abc_123";    jobId2 = "job_def_456";    jobId3 = "job_ghi_789";    emptyJobId = "";    basePath = tempDir.getRoot().getAbsolutePath();    when(job1.getJobType()).thenReturn(JobType.MAP_REDUCE);    when(job2.getJobType()).thenReturn(JobType.MAP_REDUCE);    when(job3.getJobType()).thenReturn(JobType.MAP_REDUCE);    when(job1.submit(finalizer, config)).thenReturn(job1);    when(job2.submit(finalizer, config)).thenReturn(job2);    when(job3.submit(finalizer, config)).thenReturn(job3);    when(finalizer.finalizeJob(any())).thenReturn(results);}
0
public void submits_job_and_returns_status() throws JobException
{    when(job1.getStatus()).thenReturn(new JobStatus().withState(State.RUNNING).withJobId(jobId1));    JobStatus status = jm.submit(newSupplier(job1), username1);    assertThat(status.getState(), equalTo(State.RUNNING));    assertThat(status.getJobId(), equalTo(jobId1));    when(job1.getStatus()).thenReturn(new JobStatus().withState(State.SUCCEEDED).withJobId(jobId1));    status = jm.getStatus(username1, status.getJobId());    assertThat(status.getState(), equalTo(State.SUCCEEDED));    assertThat(status.getJobId(), equalTo(jobId1));}
0
public void submits_multiple_jobs_and_returns_status() throws JobException
{    when(job1.getStatus()).thenReturn(new JobStatus().withState(State.RUNNING).withJobId(jobId1));    when(job2.getStatus()).thenReturn(new JobStatus().withState(State.RUNNING).withJobId(jobId2));    when(job3.getStatus()).thenReturn(new JobStatus().withState(State.RUNNING).withJobId(jobId3));        jm.submit(newSupplier(job1), username1);    assertThat(jm.getJob(username1, jobId1), equalTo(job1));        jm.submit(newSupplier(job2), username1);    assertThat(jm.getJob(username1, jobId1), equalTo(job1));    assertThat(jm.getJob(username1, jobId2), equalTo(job2));        jm.submit(newSupplier(job3), username1);    assertThat(jm.getJob(username1, jobId1), equalTo(job1));    assertThat(jm.getJob(username1, jobId2), equalTo(job2));    assertThat(jm.getJob(username1, jobId3), equalTo(job3));        jm.submit(newSupplier(job1), username2);    jm.submit(newSupplier(job2), username2);    jm.submit(newSupplier(job3), username2);        assertThat(jm.getJob(username1, jobId1), equalTo(job1));    assertThat(jm.getJob(username1, jobId2), equalTo(job2));    assertThat(jm.getJob(username1, jobId3), equalTo(job3));        assertThat(jm.getJob(username2, jobId1), equalTo(job1));    assertThat(jm.getJob(username2, jobId2), equalTo(job2));    assertThat(jm.getJob(username2, jobId3), equalTo(job3));}
0
public void empty_result_set_with_empty_jobId_shows_status() throws JobException
{    when(job1.getStatus()).thenReturn(new JobStatus().withState(State.SUCCEEDED).withJobId(emptyJobId));        jm.submit(newSupplier(job1), username1);    assertThat(jm.getJob(username1, emptyJobId), equalTo(job1));        when(job2.getStatus()).thenReturn(new JobStatus().withState(State.SUCCEEDED).withJobId(emptyJobId));    jm.submit(newSupplier(job2), username1);    assertThat(jm.getJob(username1, emptyJobId), equalTo(job2));}
0
public void returns_job_status() throws JobException
{    JobStatus expected = new JobStatus().withState(State.SUCCEEDED).withJobId(jobId1);    when(job1.getStatus()).thenReturn(expected);    jm.submit(newSupplier(job1), username1);    JobStatus status = jm.getStatus(username1, jobId1);    assertThat(status, equalTo(expected));}
0
public void returns_job_is_done() throws JobException
{    JobStatus expected = new JobStatus().withState(State.SUCCEEDED).withJobId(jobId1);    when(job1.getStatus()).thenReturn(expected);    when(job1.isDone()).thenReturn(true);    jm.submit(newSupplier(job1), username1);    boolean done = jm.done(username1, jobId1);    assertThat(done, equalTo(true));}
0
public void kills_job() throws JobException
{    when(job1.getStatus()).thenReturn(new JobStatus().withState(State.SUCCEEDED).withJobId(jobId1));    jm.submit(newSupplier(job1), username1);    jm.killJob(username1, jobId1);    verify(job1).kill();}
0
public void gets_list_of_user_jobs() throws JobException
{    when(job1.getStatus()).thenReturn(new JobStatus().withState(State.RUNNING).withJobId(jobId1));    when(job2.getStatus()).thenReturn(new JobStatus().withState(State.RUNNING).withJobId(jobId2));    when(job3.getStatus()).thenReturn(new JobStatus().withState(State.RUNNING).withJobId(jobId3));    jm.submit(newSupplier(job1), username1);    jm.submit(newSupplier(job2), username1);    jm.submit(newSupplier(job3), username1);    jm.submit(newSupplier(job1), username2);    jm.submit(newSupplier(job2), username2);    jm.submit(newSupplier(job3), username2);    List<Statusable<Path>> jobsUser1 = jm.getJobs(username1);    List<Statusable<Path>> jobsUser2 = jm.getJobs(username2);    assertThat("Wrong size", jobsUser1.size(), equalTo(3));    assertThat("Wrong size", jobsUser2.size(), equalTo(3));    assertThat("", jobsUser1.containsAll(Arrays.asList(job1, job2, job3)), equalTo(true));    assertThat("", jobsUser2.containsAll(Arrays.asList(job1, job2, job3)), equalTo(true));}
0
private Supplier<Statusable<Path>> newSupplier(Statusable<Path> job)
{    return () -> {        try {            return job.submit(finalizer, config);        } catch (JobException e) {            throw new RuntimeException("Something went wrong", e);        }    };}
0
private static CuratorFramework getZookeeperClient(Context context)
{    Optional<Object> clientOpt = context.getCapability(Context.Capabilities.ZOOKEEPER_CLIENT, true);    if (clientOpt.isPresent()) {        return (CuratorFramework) clientOpt.get();    } else {        throw new IllegalStateException("Missing ZOOKEEPER_CLIENT; zookeeper connection required");    }}
0
public static T getArg(int index, Class<T> clazz, List<Object> args)
{    if (index >= args.size()) {        throw new IllegalArgumentException(format("expected at least %d argument(s), found %d", index + 1, args.size()));    }    return ConversionUtils.convert(args.get(index), clazz);}
0
private static String toJSON(Object object)
{    if (object == null) {        return null;    }    try {        return JSONUtils.INSTANCE.toJSON(object, true);    } catch (JsonProcessingException e) {        throw new RuntimeException(e);    }}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String result;        String arg0 = getArg(0, String.class, args);    ConfigurationType type = ConfigurationType.valueOf(arg0);    try {        if (GLOBAL == type) {            result = getGlobalConfig(args);        } else if (PROFILER == type) {            result = getProfilerConfig(args);        } else if (ENRICHMENT == type) {            result = getEnrichmentConfig(args);        } else if (INDEXING == type) {            result = getIndexingConfig(args);        } else if (PARSER == type) {            result = getParserConfig(args);        } else {            throw new IllegalArgumentException("Unexpected configuration type: " + type);        }    } catch (Exception e) {        throw new RuntimeException(e);    }    return result;}
0
private String getGlobalConfig(List<Object> args) throws Exception
{    Map<String, Object> globals = readGlobalConfigFromZookeeper(zkClient);        if (globals == null && emptyIfNotPresent(args)) {        globals = new HashMap<>();    }    return toJSON(globals);}
0
private String getParserConfig(List<Object> args) throws Exception
{        String sensor = getArg(1, String.class, args);    SensorParserConfig sensorConfig = readSensorParserConfigFromZookeeper(sensor, zkClient);        if (sensorConfig == null && emptyIfNotPresent(args)) {        sensorConfig = new SensorParserConfig();    }    return toJSON(sensorConfig);}
0
private String getEnrichmentConfig(List<Object> args) throws Exception
{        String sensor = getArg(1, String.class, args);    SensorEnrichmentConfig sensorConfig = readSensorEnrichmentConfigFromZookeeper(sensor, zkClient);        if (sensorConfig == null && emptyIfNotPresent(args)) {        sensorConfig = new SensorEnrichmentConfig();    }    return toJSON(sensorConfig);}
0
private String getIndexingConfig(List<Object> args) throws Exception
{        String sensor = getArg(1, String.class, args);    Map<String, Object> sensorConfig = readSensorIndexingConfigFromZookeeper(sensor, zkClient);        if (sensorConfig == null && emptyIfNotPresent(args)) {        sensorConfig = Collections.emptyMap();    }    return toJSON(sensorConfig);}
0
private String getProfilerConfig(List<Object> args) throws Exception
{    ProfilerConfig profilerConfig = readProfilerConfigFromZookeeper(zkClient);        if (profilerConfig == null && emptyIfNotPresent(args)) {        profilerConfig = new ProfilerConfig();    }    return toJSON(profilerConfig);}
0
private boolean emptyIfNotPresent(List<Object> args)
{    boolean emptyIfNotPresent = true;    int lastIndex = args.size() - 1;        if (args.size() >= 2 && args.get(lastIndex) instanceof Boolean) {        emptyIfNotPresent = getArg(lastIndex, Boolean.class, args);    }    return emptyIfNotPresent;}
0
public void initialize(Context context)
{    zkClient = getZookeeperClient(context);}
0
public boolean isInitialized()
{    return initialized;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        String arg0 = getArg(0, String.class, args);    ConfigurationType type = ConfigurationType.valueOf(arg0);        String value = getArg(1, String.class, args);    if (value != null) {        CuratorFramework client = getZookeeperClient(context);        try {            if (GLOBAL == type) {                writeGlobalConfigToZookeeper(value.getBytes(StandardCharsets.UTF_8), client);            } else if (PROFILER == type) {                writeProfilerConfigToZookeeper(value.getBytes(StandardCharsets.UTF_8), client);            } else if (ENRICHMENT == type) {                String sensor = getArg(2, String.class, args);                writeSensorEnrichmentConfigToZookeeper(sensor, value.getBytes(StandardCharsets.UTF_8), client);            } else if (INDEXING == type) {                String sensor = getArg(2, String.class, args);                writeSensorIndexingConfigToZookeeper(sensor, value.getBytes(StandardCharsets.UTF_8), client);            } else if (PARSER == type) {                String sensor = getArg(2, String.class, args);                writeSensorParserConfigToZookeeper(sensor, value.getBytes(StandardCharsets.UTF_8), client);            }        } catch (Exception e) {                        throw new ParseException(e.getMessage());        }    }    return null;}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public static Map<String, Object> getStellarHandler(EnrichmentConfig enrichmentConfig)
{    Map<String, Object> fieldMap = enrichmentConfig.getFieldMap();    Map<String, Object> stellarHandler = (Map<String, Object>) fieldMap.getOrDefault("stellar", new HashMap<>());    fieldMap.put("stellar", stellarHandler);    stellarHandler.putIfAbsent("config", new LinkedHashMap<String, Object>());    return stellarHandler;}
0
public static EnrichmentConfig getConfig(SensorEnrichmentConfig sensorConfig, Type type)
{    EnrichmentConfig enrichmentConfig = null;    switch(type) {        case ENRICHMENT:            enrichmentConfig = sensorConfig.getEnrichment();            break;        case THREAT_INTEL:        case THREATINTEL:            enrichmentConfig = sensorConfig.getThreatIntel();    }    return enrichmentConfig;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String config = (String) args.get(0);    SensorEnrichmentConfig configObj;    String[] headers = new String[] { "Group", "Field", "Transformation" };    if (config == null || config.isEmpty()) {        return FlipTable.of(headers, new String[0][3]);    } else {        configObj = (SensorEnrichmentConfig) ENRICHMENT.deserialize(config);    }    Type type = Type.valueOf((String) args.get(1));    EnrichmentConfig enrichmentConfig = getConfig(configObj, type);    Map<String, Object> stellarHandler = getStellarHandler(enrichmentConfig);    Map<String, Object> transforms = (Map<String, Object>) stellarHandler.get("config");    List<String[]> objs = new ArrayList<>();    for (Map.Entry<String, Object> kv : transforms.entrySet()) {        if (kv.getValue() instanceof Map) {            Map<String, String> groupMap = (Map<String, String>) kv.getValue();            for (Map.Entry<String, String> groupKv : groupMap.entrySet()) {                objs.add(new String[] { kv.getKey(), groupKv.getKey(), groupKv.getValue().toString() });            }        } else {            objs.add(new String[] { "(default)", kv.getKey(), kv.getValue().toString() });        }    }    String[][] data = new String[objs.size()][3];    for (int i = 0; i < objs.size(); ++i) {        data[i] = objs.get(i);    }    return FlipTable.of(headers, data);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    int i = 0;    String config = (String) args.get(i++);    SensorEnrichmentConfig configObj;    if (config == null || config.isEmpty()) {        throw new IllegalStateException("Invalid config: " + config);    } else {        configObj = (SensorEnrichmentConfig) ENRICHMENT.deserialize(config);    }    Type type = Type.valueOf((String) args.get(i++));    EnrichmentConfig enrichmentConfig = getConfig(configObj, type);    Map<String, Object> stellarHandler = getStellarHandler(enrichmentConfig);    Map<String, String> transformsToAdd = (Map<String, String>) args.get(i++);    String group = null;    if (i < args.size()) {        group = (String) args.get(i++);    }    Map<String, Object> baseTransforms = (Map<String, Object>) stellarHandler.get("config");    Map<String, Object> groupMap = baseTransforms;    if (group != null) {        groupMap = (Map<String, Object>) baseTransforms.getOrDefault(group, new LinkedHashMap<>());        baseTransforms.put(group, groupMap);    }    for (Map.Entry<String, String> kv : transformsToAdd.entrySet()) {        groupMap.put(kv.getKey(), kv.getValue());    }    if (group != null && groupMap.isEmpty()) {        baseTransforms.remove(group);    }    try {        return JSONUtils.INSTANCE.toJSON(configObj, true);    } catch (JsonProcessingException e) {                return config;    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    int i = 0;    String config = (String) args.get(i++);    SensorEnrichmentConfig configObj;    if (config == null || config.isEmpty()) {        throw new IllegalStateException("Invalid config: " + config);    } else {        configObj = (SensorEnrichmentConfig) ENRICHMENT.deserialize(config);    }    Type type = Type.valueOf((String) args.get(i++));    EnrichmentConfig enrichmentConfig = getConfig(configObj, type);    Map<String, Object> stellarHandler = getStellarHandler(enrichmentConfig);    List<String> removals = (List<String>) args.get(i++);    String group = null;    if (i < args.size()) {        group = (String) args.get(i++);    }    Map<String, Object> baseTransforms = (Map<String, Object>) stellarHandler.get("config");    Map<String, Object> groupMap = baseTransforms;    if (group != null) {        groupMap = (Map<String, Object>) baseTransforms.getOrDefault(group, new LinkedHashMap<>());        baseTransforms.put(group, groupMap);    }    for (String remove : removals) {        groupMap.remove(remove);    }    if (group != null && groupMap.isEmpty()) {        baseTransforms.remove(group);    }    if (baseTransforms.isEmpty()) {        enrichmentConfig.getFieldMap().remove("stellar");    }    try {        return JSONUtils.INSTANCE.toJSON(configObj, true);    } catch (JsonProcessingException e) {                return config;    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public FileSystem getSystem() throws IOException
{    return _func.getSystem();}
0
public void initialize(Context context)
{    try {        fs = getter.getSystem();    } catch (IOException e) {        String message = "Unable to get FileSystem: " + e.getMessage();                throw new IllegalStateException(message, e);    }}
1
public boolean isInitialized()
{    return fs != null;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String path = (String) args.get(0);    if (path == null) {        return null;    }    try (FSDataInputStream is = fs.open(new Path(path))) {        return IOUtils.readLines(is);    } catch (IOException e) {        String message = "Unable to read " + path + ": " + e.getMessage();                return null;    }}
1
public Object apply(List<Object> args, Context context) throws ParseException
{    String path = (String) args.get(0);    if (path == null) {        return null;    }    try (FSDataInputStream is = fs.open(new Path(path))) {        return IOUtils.toString(is);    } catch (IOException e) {        String message = "Unable to read " + path + ": " + e.getMessage();                return null;    }}
1
public Object apply(List<Object> args, Context context) throws ParseException
{    String path = (String) args.get(0);    if (path == null) {        return false;    }    boolean recursive = false;    if (args.size() > 1) {        recursive = ConversionUtils.convert(args.get(1), Boolean.class);    }    try {        fs.delete(new Path(path), recursive);        return true;    } catch (IOException e) {        String message = "Unable to remove " + path + (recursive ? " recursively" : "") + ": " + e.getMessage();                return false;    }}
1
public Object apply(List<Object> args, Context context) throws ParseException
{    String content = (String) args.get(0);    if (content == null) {        return false;    }    String path = (String) args.get(1);    if (path == null) {        return false;    }    try (FSDataOutputStream os = fs.create(new Path(path))) {        os.writeBytes(content);        os.flush();        return true;    } catch (IOException e) {        String message = "Unable to write " + path + ": " + e.getMessage();                return false;    }}
1
protected DateFormat initialValue()
{    return DateFormat.getDateTimeInstance(DateFormat.DEFAULT, DateFormat.DEFAULT, Locale.getDefault());}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    Path path = null;    String[] headers = new String[] { "PERMISSION", "OWNER", "GROUP", "SIZE", "LAST MOD TIME", "NAME" };    if (args.size() == 0) {        path = fs.getHomeDirectory();    } else {        String pathStr = (String) args.get(0);        if (pathStr == null) {            return FlipTable.of(headers, new String[][] {});        } else {            try {                path = new Path(pathStr);            } catch (IllegalArgumentException iae) {                                return FlipTable.of(headers, new String[][] {});            }        }    }    try {        List<String[]> dataList = new ArrayList<>();        for (FileStatus status : fs.listStatus(path)) {            dataList.add(new String[] { status.getPermission().toString(), status.getOwner(), status.getGroup(), status.getLen() + "", dateFormat.get().format(new Date(status.getModificationTime())), status.getPath().getName() });        }        Collections.sort(dataList, (o1, o2) -> {            try {                Date left = dateFormat.get().parse(o1[4]);                Date right = dateFormat.get().parse(o2[4]);                int ret = left.compareTo(right);                                if (ret == 0) {                    return o1[5].compareTo(o2[5]);                } else {                    return ret;                }            } catch (java.text.ParseException e) {                String message = "Unable to parse " + Arrays.toString(o1) + " or " + Arrays.toString(o2) + " : " + e.getMessage();                                throw new IllegalStateException(message, e);            }        });        String[][] data = new String[dataList.size()][headers.length];        for (int i = 0; i < dataList.size(); ++i) {            data[i] = dataList.get(i);        }        return FlipTable.of(headers, data);    } catch (IOException e) {        String message = "Unable to list" + path + " : " + e.getMessage();                return FlipTable.of(headers, new String[][] {});    }}
1
public static T getArg(String argName, int index, Class<T> clazz, List<Object> args) throws ParseException
{    if (index >= args.size()) {        String msg = format("missing '%s'; expected at least %d argument(s), found %d", argName, index + 1, args.size());        throw new ParseException(msg);    }    return ConversionUtils.convert(args.get(index), clazz);}
0
public static boolean hasArg(String argName, int index, Class<T> clazz, List<Object> args)
{    boolean result = false;    if (args.size() > index) {        if (clazz.isAssignableFrom(args.get(index).getClass())) {            return true;        }    }    return result;}
0
public static CuratorFramework getZookeeperClient(Context context) throws ParseException
{    return context.getCapability(ZOOKEEPER_CLIENT, false).filter(CuratorFramework.class::isInstance).map(CuratorFramework.class::cast).orElseThrow(() -> new ParseException("Missing ZOOKEEPER_CLIENT; zookeeper connection required"));}
0
private static Grok getGrok(String grokExpr) throws GrokException
{    Grok grok = new Grok();    InputStream input = GrokFunctions.class.getResourceAsStream("/patterns/common");    if (input != null) {        grok.addPatternFromReader(new InputStreamReader(input, StandardCharsets.UTF_8));    }    if (grokExpr != null) {        grok.addPatternFromReader(new StringReader("pattern " + grokExpr));        grok.compile("%{pattern}");    }    return grok;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String grokExpression = (String) args.get(0);    Object arg = args.get(1);    if (grokExpression == null || arg == null) {        return null;    }    List<String> strs = null;    if (arg instanceof List) {        strs = (List<String>) arg;    } else if (arg instanceof String) {        strs = new ArrayList<>();        strs.add((String) arg);    } else {        return null;    }    Grok grok = null;    try {        grok = getGrok(grokExpression);    } catch (GrokException e) {                return null;    }    List<Map<String, Object>> outputMap = new ArrayList<>();    Set<String> keys = new TreeSet<>();    for (String str : strs) {        Match m = grok.match(str);        m.captures();        Map<String, Object> ret = m.toMap();        if (ret != null && ret.isEmpty()) {            outputMap.add(new HashMap<>());        } else {            ret.remove("pattern");            keys.addAll(ret.keySet());            outputMap.add(ret);        }    }    if (keys.isEmpty()) {        return "NO MATCH";    }    String[] headers = new String[keys.size()];    String[][] data = new String[outputMap.size()][keys.size()];    {        int i = 0;        for (String key : keys) {            headers[i++] = key;        }    }    int rowNum = 0;    for (Map<String, Object> output : outputMap) {        String[] row = new String[keys.size()];        int colNum = 0;        for (String key : keys) {            row[colNum++] = "" + output.getOrDefault(key, "MISSING");        }        data[rowNum++] = row;    }    return FlipTable.of(headers, data);}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String str = (String) args.get(0);    if (str == null) {        return null;    }    Grok grok = null;    try {        grok = getGrok(null);    } catch (GrokException e) {                return null;    }    return grok.discover(str);}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    int i = 0;    String config = (String) args.get(i++);    Map<String, Object> configObj;    if (config == null || config.isEmpty()) {        throw new IllegalStateException("Invalid config: " + config);    } else {        configObj = (Map<String, Object>) INDEXING.deserialize(config);    }    String writer = null;    if (args.size() > 1) {        writer = ConversionUtils.convert(args.get(i++), String.class);        if (!configObj.containsKey(writer)) {            configObj.put(writer, new HashMap<String, Object>());        }    }    if (writer == null) {        throw new IllegalStateException("Invalid writer name: " + config);    }    int batchSize = 1;    if (args.size() > 2) {        batchSize = ConversionUtils.convert(args.get(i++), Integer.class);        if (batchSize < 1) {            throw new IllegalArgumentException("Invalid batch size must be >= 1 : " + Integer.toString(batchSize));        }    }    configObj.put(writer, IndexingConfigurations.setBatchSize((Map<String, Object>) configObj.get(writer), batchSize));    int batchTimeout = 0;    if (args.size() > 3) {        batchTimeout = ConversionUtils.convert(args.get(i++), Integer.class);    }    configObj.put(writer, IndexingConfigurations.setBatchTimeout((Map<String, Object>) configObj.get(writer), batchTimeout));    try {        return JSONUtils.INSTANCE.toJSON(configObj, true);    } catch (JsonProcessingException e) {                return config;    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    int i = 0;    String config = (String) args.get(i++);    Map<String, Object> configObj;    if (config == null || config.isEmpty()) {        throw new IllegalStateException("Invalid config: " + config);    } else {        configObj = (Map<String, Object>) INDEXING.deserialize(config);    }    String writer = null;    if (args.size() > 1) {        writer = ConversionUtils.convert(args.get(i++), String.class);        if (!configObj.containsKey(writer)) {            configObj.put(writer, new HashMap<String, Object>());        }    }    if (writer == null) {        throw new IllegalStateException("Invalid writer name: " + config);    }    boolean enabled = true;    if (args.size() > 2) {        enabled = ConversionUtils.convert(args.get(i++), Boolean.class);    }    configObj.put(writer, IndexingConfigurations.setEnabled((Map<String, Object>) configObj.get(writer), enabled));    try {        return JSONUtils.INSTANCE.toJSON(configObj, true);    } catch (JsonProcessingException e) {                return config;    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    int i = 0;    String config = (String) args.get(i++);    Map<String, Object> configObj;    if (config == null || config.isEmpty()) {        throw new IllegalStateException("Invalid config: " + config);    } else {        configObj = (Map<String, Object>) INDEXING.deserialize(config);    }    String writer = null;    if (args.size() > 1) {        writer = ConversionUtils.convert(args.get(i++), String.class);        if (!configObj.containsKey(writer)) {            configObj.put(writer, new HashMap<String, Object>());        }    }    if (writer == null) {        throw new IllegalStateException("Invalid writer name: " + config);    }    String sensorName = ConversionUtils.convert(args.get(i++), String.class);    if (sensorName == null) {        throw new IllegalStateException("Invalid sensor name: " + config);    }    configObj.put(writer, IndexingConfigurations.setIndex((Map<String, Object>) configObj.get(writer), sensorName));    try {        return JSONUtils.INSTANCE.toJSON(configObj, true);    } catch (JsonProcessingException e) {                return config;    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        String topic = getArg("topic", 0, String.class, args);        int count = 1;    if (args.size() > 1) {        count = getArg("count", 1, Integer.class, args);    }        Map<String, String> overrides = new HashMap<>();    if (args.size() > 2) {        overrides = getArg("overrides", 2, Map.class, args);    }        Properties properties = buildKafkaProperties(overrides, context);    properties.put("max.poll.records", count);    return getMessages(topic, count, properties);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{        return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        String topic = getArg("topic", 0, String.class, args);        int count = 1;    if (args.size() > 1) {        count = getArg("count", 1, Integer.class, args);    }        Map<String, String> overrides = new HashMap<>();    if (args.size() > 2) {        overrides = getArg("overrides", 2, Map.class, args);    }    Properties properties = buildKafkaProperties(overrides, context);    properties.put("max.poll.records", count);    return tailMessages(topic, count, properties);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{        return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String topic = ConversionUtils.convert(args.get(0), String.class);    List<String> messages;    if (args.get(1) instanceof String) {                String msg = getArg("message(s)", 1, String.class, args);        messages = Collections.singletonList(msg);    } else {                messages = getArg("message(s)", 1, List.class, args);    }        Map<String, String> overrides = new HashMap<>();    if (args.size() > 2) {        overrides = getArg("overrides", 2, Map.class, args);    }        Properties properties = buildKafkaProperties(overrides, context);    List<RecordMetadata> records = putMessages(topic, messages, properties);        Object view = render(records, properties);    return view;}
0
private Object render(List<RecordMetadata> records, Properties properties)
{    Object view;    if (MESSAGE_VIEW_RICH.equals(getMessageView(properties))) {                List<Object> responses = new ArrayList<>();        for (RecordMetadata record : records) {                        Map<String, Object> richView = new HashMap<>();            richView.put("topic", record.topic());            richView.put("partition", record.partition());            richView.put("offset", record.offset());            richView.put("timestamp", record.timestamp());            responses.add(richView);        }                view = responses;    } else {                view = CollectionUtils.size(records);    }    return view;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{        return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        Map<String, String> overrides = new HashMap<>();    if (args.size() > 0) {        overrides = getArg("overrides", 0, Map.class, args);    }    return buildKafkaProperties(overrides, context);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{        return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        String topic = getArg("topic", 0, String.class, args);        LambdaExpression filter = getArg("filter", 1, LambdaExpression.class, args);        int count = 1;    if (args.size() > 2) {        count = getArg("count", 2, Integer.class, args);    }        Map<String, String> overrides = new HashMap<>();    if (args.size() > 3) {        overrides = getArg("overrides", 3, Map.class, args);    }    Properties properties = buildKafkaProperties(overrides, context);    properties.put("max.poll.records", 10 * count);    return findMessages(topic, filter, count, properties);}
0
public boolean isSatisfied(LambdaExpression expr, String message)
{    boolean result = false;    Map<String, Object> messageAsMap;    try {                messageAsMap = JSONUtils.INSTANCE.load(message, JSONUtils.MAP_SUPPLIER);                Object out = expr.apply(Collections.singletonList(messageAsMap));        if (out instanceof Boolean) {            result = (Boolean) out;        } else {                    }    } catch (IOException e) {            }    return result;}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{        return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        String topic = getArg("topic", 0, String.class, args);    int partition = getArg("partition", 1, Integer.class, args);    int offset = getArg("offset", 2, Integer.class, args);        Map<String, String> overrides = new HashMap<>();    if (args.size() > 3) {        overrides = getArg("overrides", 3, Map.class, args);    }    Properties properties = buildKafkaProperties(overrides, context);    return seek(topic, partition, offset, properties);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{        return true;}
0
private static Set<TopicPartition> manualPartitionAssignment(String topic, KafkaConsumer<String, String> consumer)
{        Set<TopicPartition> partitions = new HashSet<>();    for (PartitionInfo partition : consumer.partitionsFor(topic)) {        partitions.add(new TopicPartition(topic, partition.partition()));    }    if (partitions.size() == 0) {        throw new IllegalStateException(format("No partitions available for consumer assignment; topic=%s", topic));    }        consumer.assign(partitions);    return partitions;}
0
private static Properties buildKafkaProperties(Map<String, String> overrides, Context context)
{        Properties properties = new Properties();    properties.putAll(defaultProperties);        Optional<Object> globalCapability = context.getCapability(GLOBAL_CONFIG, false);    if (globalCapability.isPresent()) {        Map<String, Object> global = (Map<String, Object>) globalCapability.get();        properties.putAll(global);    }        properties.putAll(overrides);    return properties;}
0
private static int getMaxWait(Properties properties)
{    int maxWait = DEFAULT_MAX_WAIT;    Object value = properties.get(MAX_WAIT_PROPERTY);    if (value != null) {        maxWait = ConversionUtils.convert(value, Integer.class);    }    return maxWait;}
0
private static int getPollTimeout(Properties properties)
{    int pollTimeout = DEFAULT_POLL_TIMEOUT;    Object value = properties.get(POLL_TIMEOUT_PROPERTY);    if (value != null) {        pollTimeout = ConversionUtils.convert(value, Integer.class);    }    return pollTimeout;}
0
private static String getMessageView(Properties properties)
{        String messageView = MESSAGE_VIEW_SIMPLE;    if (properties.containsKey(MESSAGE_VIEW_PROPERTY)) {        messageView = ConversionUtils.convert(properties.get(MESSAGE_VIEW_PROPERTY), String.class);    }    return messageView;}
0
private static Properties defaultKafkaProperties()
{    Properties properties = new Properties();    properties.put("bootstrap.servers", "localhost:9092");    properties.put("group.id", "kafka-functions-stellar");    /*     * What to do when there is no initial offset in Kafka or if the current     * offset does not exist any more on the server (e.g. because that data has been deleted):     *     *  "earliest": automatically reset the offset to the earliest offset     *  "latest": automatically reset the offset to the latest offset     *  "none": throw exception to the consumer if no previous offset is found or the consumer's group     *  anything else: throw exception to the consumer.     */    properties.put("auto.offset.reset", "latest");        properties.put("max.poll.records", 1);        properties.put("key.deserializer", StringDeserializer.class.getName());    properties.put("value.deserializer", StringDeserializer.class.getName());        properties.put("key.serializer", StringSerializer.class.getName());    properties.put("value.serializer", StringSerializer.class.getName());        properties.put(MAX_WAIT_PROPERTY, DEFAULT_MAX_WAIT);        properties.put(POLL_TIMEOUT_PROPERTY, DEFAULT_POLL_TIMEOUT);        properties.put(MESSAGE_VIEW_PROPERTY, MESSAGE_VIEW_SIMPLE);    return properties;}
0
private static void pruneEmptyStellarTransformers(SensorParserConfig config)
{    List<FieldTransformer> toRemove = new ArrayList<>();    List<FieldTransformer> fieldTransformations = config.getFieldTransformations();    for (FieldTransformer transformer : fieldTransformations) {        if (transformer.getFieldTransformation().getClass().getName().equals(FieldTransformations.STELLAR.getMappingClass().getName()) && transformer.getConfig().isEmpty()) {            toRemove.add(transformer);        }    }    for (FieldTransformer t : toRemove) {        fieldTransformations.remove(t);    }}
0
private static FieldTransformer getStellarTransformer(SensorParserConfig config)
{    List<FieldTransformer> fieldTransformations = config.getFieldTransformations();    FieldTransformer stellarTransformer = null;    for (FieldTransformer transformer : fieldTransformations) {        if (transformer.getFieldTransformation().getClass().getName().equals(FieldTransformations.STELLAR.getMappingClass().getName())) {            stellarTransformer = transformer;        }    }    if (stellarTransformer == null) {        stellarTransformer = new FieldTransformer();        stellarTransformer.setConfig(new LinkedHashMap<>());        stellarTransformer.setTransformation(FieldTransformations.STELLAR.toString());        fieldTransformations.add(stellarTransformer);    }    return stellarTransformer;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String config = (String) args.get(0);    if (config == null) {        return null;    }    SensorParserConfig configObj = (SensorParserConfig) PARSER.deserialize(config);    FieldTransformer stellarTransformer = getStellarTransformer(configObj);    String[] headers = new String[] { "Field", "Transformation" };    String[][] data = new String[stellarTransformer.getConfig().size()][2];    int i = 0;    for (Map.Entry<String, Object> kv : stellarTransformer.getConfig().entrySet()) {        data[i++] = new String[] { kv.getKey(), kv.getValue().toString() };    }    return FlipTable.of(headers, data);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String config = (String) args.get(0);    if (config == null) {        return null;    }    SensorParserConfig configObj = (SensorParserConfig) PARSER.deserialize(config);    FieldTransformer stellarTransformer = getStellarTransformer(configObj);    List<String> removals = (List<String>) args.get(1);    if (removals == null || removals.isEmpty()) {        return config;    }    for (String removal : removals) {        stellarTransformer.getConfig().remove(removal);    }    List<String> output = new ArrayList<>();    output.addAll(stellarTransformer.getConfig().keySet());    stellarTransformer.setOutput(output);    pruneEmptyStellarTransformers(configObj);    try {        return JSONUtils.INSTANCE.toJSON(configObj, true);    } catch (JsonProcessingException e) {                return config;    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String config = (String) args.get(0);    if (config == null) {        return null;    }    SensorParserConfig configObj = (SensorParserConfig) PARSER.deserialize(config);    FieldTransformer stellarTransformer = getStellarTransformer(configObj);    Map<String, String> additionalTransforms = (Map<String, String>) args.get(1);    if (additionalTransforms == null || additionalTransforms.isEmpty()) {        return config;    }    for (Map.Entry<String, String> kv : additionalTransforms.entrySet()) {        stellarTransformer.getConfig().put(kv.getKey(), kv.getValue());    }    List<String> output = new ArrayList<>();    output.addAll(stellarTransformer.getConfig().keySet());    stellarTransformer.setOutput(output);    try {        return JSONUtils.INSTANCE.toJSON(configObj, true);    } catch (JsonProcessingException e) {                return config;    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String sensorType = getArg("sensorType", 0, String.class, args);    StellarParserRunner parser = new StellarParserRunner(sensorType);        String configArgName = "config";    if (args.size() == 1) {                SensorParserConfig config = readFromZookeeper(context, sensorType);        parser.withParserConfiguration(sensorType, config);    } else if (hasArg(configArgName, 1, String.class, args)) {                String arg = getArg(configArgName, 1, String.class, args);        parser.withParserConfiguration(arg);    } else if (hasArg(configArgName, 1, Map.class, args)) {                Map<String, Object> arg = getArg(configArgName, 1, Map.class, args);        parser.withParserConfiguration(arg);    } else {        throw new ParseException(format("unexpected '%s' argument; expected string or map", configArgName));    }        if (hasArg("globals", 1, Map.class, args)) {        Map<String, Object> globals = getArg("globals", 1, Map.class, args);        parser.withGlobals(globals);    }    return parser;}
0
private SensorParserConfig readFromZookeeper(Context context, String sensorType) throws ParseException
{    SensorParserConfig config;    try {        CuratorFramework zkClient = getZookeeperClient(context);        config = readSensorParserConfigFromZookeeper(sensorType, zkClient);    } catch (Exception e) {        throw new ParseException(ExceptionUtils.getRootCauseMessage(e), e);    }    if (config == null) {        throw new ParseException("Unable to read configuration from Zookeeper; sensorType = " + sensorType);    }    return config;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    StellarParserRunner parser = getArg("parser", 0, StellarParserRunner.class, args);    parser.withContext(context);    List<String> messages = getMessages(args);    return parser.parse(messages);}
0
private List<String> getMessages(List<Object> args)
{    String inputArgName = "input";    List<String> messages = new ArrayList<>();    if (hasArg(inputArgName, 1, String.class, args)) {                String msg = getArg(inputArgName, 1, String.class, args);        messages.add(msg);    } else if (hasArg(inputArgName, 1, List.class, args)) {                List<Object> arg1 = getArg(inputArgName, 1, List.class, args);        for (Object object : arg1) {            String msg = String.class.cast(object);            messages.add(msg);        }    } else {        throw new IllegalArgumentException(format("Expected a string or list of strings to parse."));    }    return messages;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args)
{    StellarParserRunner parser = getArg("parser", 0, StellarParserRunner.class, args);    return parser.toJSON();}
0
public List<JSONObject> parse(List<String> messages)
{    if (parserConfigurations == null) {        throw new IllegalArgumentException("Missing required parser configuration");    }    if (context == null) {        throw new IllegalArgumentException("Missing required context");    }    return doParse(messages);}
0
private List<JSONObject> doParse(List<String> messages)
{        HashSet<String> sensorTypes = new HashSet<>();    sensorTypes.add(sensorType);    ParserRunnerImpl runner = new ParserRunnerImpl(sensorTypes);    runner.init(() -> parserConfigurations, context);        List<ParserRunnerResults<JSONObject>> results = messages.stream().map(str -> str.getBytes(StandardCharsets.UTF_8)).map(bytes -> DEFAULT.get(emptyMap(), bytes, false, emptyMap())).map(msg -> runner.execute(sensorType, msg, parserConfigurations)).collect(Collectors.toList());        List<JSONObject> successes = results.stream().flatMap(result -> result.getMessages().stream()).collect(Collectors.toList());    successCount += successes.size();    List<JSONObject> errors = results.stream().flatMap(result -> result.getErrors().stream()).map(err -> err.getJSONObject()).collect(Collectors.toList());    errorCount += errors.size();        successes.addAll(errors);    return successes;}
0
public StellarParserRunner withParserConfiguration(String sensorConfig)
{    parserConfigurations = create(sensorConfig.getBytes(StandardCharsets.UTF_8));    return this;}
0
public StellarParserRunner withParserConfiguration(Map<String, Object> config)
{    parserConfigurations = create(new JSONObject(config).toJSONString().getBytes(StandardCharsets.UTF_8));    return this;}
0
public StellarParserRunner withParserConfiguration(String sensorType, SensorParserConfig config)
{    parserConfigurations = new ParserConfigurations();    parserConfigurations.updateSensorParserConfig(sensorType, config);    return this;}
0
public StellarParserRunner withContext(Context context)
{    this.context = context;    return this;}
0
public StellarParserRunner withGlobals(Map<String, Object> globals)
{    parserConfigurations.updateGlobalConfig(globals);    return this;}
0
public String toJSON()
{    try {        return parserConfigurations.getSensorParserConfig(sensorType).toJSON();    } catch (JsonProcessingException e) {        throw new RuntimeException(e);    }}
0
public ParserConfigurations getParserConfigurations()
{    return parserConfigurations;}
0
private ParserConfigurations create(byte[] sensorConfig)
{    try {        ParserConfigurations result = new ParserConfigurations();        result.updateSensorParserConfig(sensorType, SensorParserConfig.fromBytes(sensorConfig));        return result;    } catch (IOException e) {        throw new IllegalArgumentException(e);    }}
0
public String toString()
{        return String.format("Parser{%d successful, %d error(s)}", successCount, errorCount);}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    ThreatTriageProcessor processor;    SensorEnrichmentConfig config = new SensorEnrichmentConfig();        if (args.size() > 0) {        String json = Util.getArg(0, String.class, args);        if (json != null) {            config = (SensorEnrichmentConfig) ENRICHMENT.deserialize(json);        } else {            throw new IllegalArgumentException(format("Invalid configuration: unable to deserialize '%s'", json));        }    }    processor = new ThreatTriageProcessor(config, new ClasspathFunctionResolver(), context);    return processor;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        String arg0 = Util.getArg(0, String.class, args);    if (arg0 == null) {        throw new IllegalArgumentException(format("expected string, got null"));    }        JSONObject message;    try {        message = (JSONObject) parser.parse(arg0);    } catch (org.json.simple.parser.ParseException e) {        throw new IllegalArgumentException("invalid message", e);    }        ThreatTriageProcessor processor = Util.getArg(1, ThreatTriageProcessor.class, args);    if (processor == null) {        throw new IllegalArgumentException(format("expected threat triage engine; got null"));    }    ThreatScore score = processor.apply(message);    return transform(score, processor.getSensorConfig());}
0
private Map<String, Object> transform(ThreatScore score, SensorEnrichmentConfig config)
{    List<Map<String, Object>> scores = new ArrayList<>();    for (RuleScore ruleScore : score.getRuleScores()) {                Map<String, Object> map = new HashMap<>();        if (ruleScore.getRule().getName() != null) {            map.put(RULE_NAME_KEY, ruleScore.getRule().getName());        }        if (ruleScore.getRule().getRule() != null) {            map.put(RULE_EXPR_KEY, ruleScore.getRule().getRule());        }        if (ruleScore.getRule().getScoreExpression() != null) {            map.put(RULE_SCORE_KEY, ruleScore.getRule().getScoreExpression());        }        if (ruleScore.getReason() != null) {            map.put(RULE_REASON_KEY, ruleScore.getReason());        }        if (ruleScore.getRule().getComment() != null) {            map.put(RULE_COMMENT_KEY, ruleScore.getRule().getComment());        }        scores.add(map);    }        Map<String, Object> result = new HashMap<>();    result.put(SCORE_KEY, score.getScore());    result.put(RULES_KEY, scores);    result.put(AGG_KEY, config.getThreatIntel().getTriageConfig().getAggregator().toString());    return result;}
0
public void initialize(Context context)
{    parser = new JSONParser();}
0
public boolean isInitialized()
{    return parser != null;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{        ThreatTriageProcessor processor = Util.getArg(0, ThreatTriageProcessor.class, args);    if (processor == null) {        throw new IllegalArgumentException(format("expected threat triage engine; got null"));    }        SensorEnrichmentConfig config = processor.getSensorConfig();    return toJSON(config);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    SensorEnrichmentConfig config = getSensorEnrichmentConfig(args, 0);    ThreatIntelConfig tiConfig = (ThreatIntelConfig) getConfig(config, EnrichmentConfigFunctions.Type.THREAT_INTEL);    if (tiConfig == null) {        return "";    }    org.apache.metron.common.configuration.enrichment.threatintel.ThreatTriageConfig triageConfig = tiConfig.getTriageConfig();    if (triageConfig == null) {        return "";    }        List<RiskLevelRule> triageRules = ListUtils.emptyIfNull(triageConfig.getRiskLevelRules());    String[] headers = new String[] { "Name", "Comment", "Triage Rule", "Score", "Reason" };    String[][] data = new String[triageRules.size()][5];    int i = 0;    for (RiskLevelRule rule : triageRules) {        String score = rule.getScoreExpression();        String name = Optional.ofNullable(rule.getName()).orElse("");        String comment = Optional.ofNullable(rule.getComment()).orElse("");        String reason = Optional.ofNullable(rule.getReason()).orElse("");        data[i++] = new String[] { name, comment, rule.getRule(), score, reason };    }    String ret = FlipTable.of(headers, data);        if (!triageRules.isEmpty()) {        ret += "Aggregation: " + triageConfig.getAggregator().name();    }    return ret;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    SensorEnrichmentConfig config = getSensorEnrichmentConfig(args, 0);    ThreatIntelConfig tiConfig = (ThreatIntelConfig) getConfig(config, EnrichmentConfigFunctions.Type.THREAT_INTEL);    if (tiConfig == null) {        tiConfig = new ThreatIntelConfig();        config.setThreatIntel(tiConfig);    }    org.apache.metron.common.configuration.enrichment.threatintel.ThreatTriageConfig triageConfig = tiConfig.getTriageConfig();    if (triageConfig == null) {        triageConfig = new org.apache.metron.common.configuration.enrichment.threatintel.ThreatTriageConfig();        tiConfig.setTriageConfig(triageConfig);    }        List<RiskLevelRule> newRules = new ArrayList<>();    for (Map<String, Object> newRule : getNewRuleDefinitions(args)) {        if (newRule != null && newRule.containsKey("rule") && newRule.containsKey("score")) {                        RiskLevelRule ruleToAdd = new RiskLevelRule();            ruleToAdd.setRule((String) newRule.get(RULE_EXPR_KEY));            ruleToAdd.setScoreExpression(newRule.get(RULE_SCORE_KEY));                        if (newRule.containsKey(RULE_NAME_KEY)) {                ruleToAdd.setName((String) newRule.get(RULE_NAME_KEY));            }            if (newRule.containsKey(RULE_COMMENT_KEY)) {                ruleToAdd.setComment((String) newRule.get(RULE_COMMENT_KEY));            }            if (newRule.containsKey(RULE_REASON_KEY)) {                ruleToAdd.setReason((String) newRule.get(RULE_REASON_KEY));            }            newRules.add(ruleToAdd);        }    }        List<RiskLevelRule> allRules = ListUtils.union(triageConfig.getRiskLevelRules(), newRules);    triageConfig.setRiskLevelRules(allRules);    return toJSON(config);}
0
private List<Map<String, Object>> getNewRuleDefinitions(List<Object> args)
{    List<Map<String, Object>> newRules = new ArrayList<>();    Object arg1 = Util.getArg(1, Object.class, args);    if (arg1 instanceof Map) {        newRules.add((Map<String, Object>) arg1);    } else if (arg1 instanceof List) {        newRules.addAll((List<Map<String, Object>>) arg1);    } else {        throw new IllegalArgumentException(String.format("triage rule expected to be map or list, got %s", ClassUtils.getShortClassName(arg1, "null")));    }    return newRules;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    SensorEnrichmentConfig config = getSensorEnrichmentConfig(args, 0);    ThreatIntelConfig tiConfig = (ThreatIntelConfig) getConfig(config, EnrichmentConfigFunctions.Type.THREAT_INTEL);    if (tiConfig == null) {        tiConfig = new ThreatIntelConfig();        config.setThreatIntel(tiConfig);    }    org.apache.metron.common.configuration.enrichment.threatintel.ThreatTriageConfig triageConfig = tiConfig.getTriageConfig();    if (triageConfig == null) {        triageConfig = new org.apache.metron.common.configuration.enrichment.threatintel.ThreatTriageConfig();        tiConfig.setTriageConfig(triageConfig);    }    List<RiskLevelRule> triageRules = triageConfig.getRiskLevelRules();    if (triageRules == null) {        triageRules = new ArrayList<>();        triageConfig.setRiskLevelRules(triageRules);    }    Set<String> toRemove = new HashSet<>(Optional.ofNullable((List<String>) args.get(1)).orElse(new ArrayList<>()));    for (Iterator<RiskLevelRule> it = triageRules.iterator(); it.hasNext(); ) {        RiskLevelRule rule = it.next();        boolean remove = toRemove.contains(rule.getRule());        if (!remove && rule.getName() != null) {            remove = toRemove.contains(rule.getName());        }        if (remove) {            it.remove();        }    }    return toJSON(config);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    SensorEnrichmentConfig config = getSensorEnrichmentConfig(args, 0);    ThreatIntelConfig tiConfig = (ThreatIntelConfig) getConfig(config, EnrichmentConfigFunctions.Type.THREAT_INTEL);    if (tiConfig == null) {        tiConfig = new ThreatIntelConfig();        config.setThreatIntel(tiConfig);    }    org.apache.metron.common.configuration.enrichment.threatintel.ThreatTriageConfig triageConfig = tiConfig.getTriageConfig();    if (triageConfig == null) {        triageConfig = new org.apache.metron.common.configuration.enrichment.threatintel.ThreatTriageConfig();        tiConfig.setTriageConfig(triageConfig);    }    List<RiskLevelRule> triageRules = triageConfig.getRiskLevelRules();    if (triageRules == null) {        triageRules = new ArrayList<>();        triageConfig.setRiskLevelRules(triageRules);    }    String aggregator = (String) args.get(1);    triageConfig.setAggregator(aggregator);    if (args.size() > 2) {        Map<String, Object> aggConfig = (Map<String, Object>) args.get(2);        triageConfig.setAggregationConfig(aggConfig);    }    return toJSON(config);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
private static String toJSON(SensorEnrichmentConfig enrichmentConfig)
{    try {        return JSONUtils.INSTANCE.toJSON(enrichmentConfig, true);    } catch (JsonProcessingException e) {        throw new IllegalArgumentException("Unable to serialize enrichment config to JSON", e);    }}
0
private static SensorEnrichmentConfig getSensorEnrichmentConfig(List<Object> args, int position)
{    Object arg0 = Util.getArg(position, Object.class, args);    SensorEnrichmentConfig config = new SensorEnrichmentConfig();    if (arg0 instanceof String) {                String json = Util.getArg(0, String.class, args);        if (json != null) {            config = (SensorEnrichmentConfig) ENRICHMENT.deserialize(json);        }    } else if (arg0 instanceof ThreatTriageProcessor) {                ThreatTriageProcessor engine = Util.getArg(0, ThreatTriageProcessor.class, args);        config = engine.getSensorConfig();    } else {                throw new IllegalArgumentException(String.format("Unexpected type: got '%s'", ClassUtils.getShortClassName(arg0, "null")));    }    return config;}
0
public static void setupZookeeper() throws Exception
{        testZkServer = new TestingServer(true);    zookeeperUrl = testZkServer.getConnectString();        client = ConfigurationsUtils.getClient(zookeeperUrl);    client.start();}
0
public void setup() throws Exception
{    context = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client).build();    parser = new JSONParser();        pushConfigs(SAMPLE_CONFIG_PATH, zookeeperUrl);    pushConfigs(PARSER_CONFIGS_PATH, zookeeperUrl);    writeProfilerConfigToZookeeper(goodProfilerConfig.getBytes(StandardCharsets.UTF_8), client);}
0
private void deletePath(String path) throws Exception
{    client.delete().forPath(path);}
0
private JSONObject toJSONObject(String input) throws org.json.simple.parser.ParseException
{    if (input == null) {        return null;    }    return (JSONObject) parser.parse(input.trim());}
0
private static void pushConfigs(String inputPath, String zookeeperUrl) throws Exception
{    String[] args = new String[] { "-z", zookeeperUrl, "--mode", "PUSH", "--input_dir", inputPath };    CommandLine cli = ConfigurationManager.ConfigurationOptions.parse(new PosixParser(), args);    ConfigurationManager manager = new ConfigurationManager();    manager.run(cli);}
0
public void testGetParser() throws Exception
{    String out = (String) run("CONFIG_GET('PARSER', 'bro')", context);    SensorParserConfig actual = SensorParserConfig.fromBytes(out.getBytes(StandardCharsets.UTF_8));    SensorParserConfig expected = SensorParserConfig.fromBytes(goodBroParserConfig.getBytes(StandardCharsets.UTF_8));    assertEquals(expected, actual);}
0
public void testGetParserMissWithoutDefault()
{        Object out = run("CONFIG_GET('PARSER', 'sensor', false)", context);    assertNull(out);}
0
public void testGetParserMissWithDefault() throws Exception
{    SensorParserConfig expected = new SensorParserConfig();    {        Object out = run("CONFIG_GET('PARSER', 'sensor')", context);        SensorParserConfig actual = SensorParserConfig.fromBytes(out.toString().getBytes(StandardCharsets.UTF_8));        assertEquals(expected, actual);    }    {        Object out = run("CONFIG_GET('PARSER', 'sensor', true)", context);        SensorParserConfig actual = SensorParserConfig.fromBytes(out.toString().getBytes(StandardCharsets.UTF_8));        assertEquals(expected, actual);    }}
0
public void testGetEnrichment() throws Exception
{    String out = (String) run("CONFIG_GET('ENRICHMENT', 'test')", context);    SensorEnrichmentConfig actual = SensorEnrichmentConfig.fromBytes(out.getBytes(StandardCharsets.UTF_8));    SensorEnrichmentConfig expected = SensorEnrichmentConfig.fromBytes(goodTestEnrichmentConfig.getBytes(StandardCharsets.UTF_8));    assertEquals(expected, actual);}
0
public void testGetEnrichmentMissWithoutDefault()
{        Object out = run("CONFIG_GET('ENRICHMENT', 'sense', false)", context);    assertNull(out);}
0
public void testGetEnrichmentMissWithDefault() throws Exception
{        SensorEnrichmentConfig expected = new SensorEnrichmentConfig();    {        String out = (String) run("CONFIG_GET('ENRICHMENT', 'missing-sensor')", context);        SensorEnrichmentConfig actual = SensorEnrichmentConfig.fromBytes(out.getBytes(StandardCharsets.UTF_8));        assertEquals(expected, actual);    }    {        String out = (String) run("CONFIG_GET('ENRICHMENT', 'missing-sensor', true)", context);        SensorEnrichmentConfig actual = SensorEnrichmentConfig.fromBytes(out.getBytes(StandardCharsets.UTF_8));        assertEquals(expected, actual);    }}
0
public void testGetIndexing() throws Exception
{    String out = (String) run("CONFIG_GET('INDEXING', 'test')", context);    Map<String, Object> actual = toJSONObject(out);    Map<String, Object> expected = toJSONObject(goodTestIndexingConfig);    assertEquals(expected, actual);}
0
public void testGetIndexingMissWithoutDefault()
{        Object out = run("CONFIG_GET('INDEXING', 'sense', false)", context);    assertNull(out);}
0
public void testGetIndexingtMissWithDefault() throws Exception
{        Map<String, Object> expected = Collections.emptyMap();    {        String out = (String) run("CONFIG_GET('INDEXING', 'missing-sensor')", context);        Map<String, Object> actual = toJSONObject(out);        assertEquals(expected, actual);    }    {        String out = (String) run("CONFIG_GET('INDEXING', 'missing-sensor', true)", context);        Map<String, Object> actual = toJSONObject(out);        assertEquals(expected, actual);    }}
0
public void testGetProfiler() throws Exception
{    String out = (String) run("CONFIG_GET('PROFILER')", context);    ProfilerConfig actual = ProfilerConfig.fromBytes(out.getBytes(StandardCharsets.UTF_8));    ProfilerConfig expected = ProfilerConfig.fromBytes(goodProfilerConfig.getBytes(StandardCharsets.UTF_8));    assertEquals(expected, actual);}
0
public void testGetProfilerMissWithoutDefault() throws Exception
{    deletePath(PROFILER.getZookeeperRoot());        String out = (String) run("CONFIG_GET('PROFILER', false)", context);    assertNull(out);}
0
public void testGetProfilerMissWithDefault() throws Exception
{        deletePath(PROFILER.getZookeeperRoot());        ProfilerConfig expected = new ProfilerConfig();    {        String out = (String) run("CONFIG_GET('PROFILER', true)", context);        ProfilerConfig actual = ProfilerConfig.fromJSON(out);        assertEquals(expected, actual);    }    {        String out = (String) run("CONFIG_GET('PROFILER')", context);        ProfilerConfig actual = ProfilerConfig.fromJSON(out);        assertEquals(expected, actual);    }}
0
public void testGetGlobal() throws Exception
{    String out = (String) run("CONFIG_GET('GLOBAL')", context);    Map<String, Object> actual = toJSONObject(out);    Map<String, Object> expected = toJSONObject(goodGlobalConfig);    assertEquals(expected, actual);}
0
public void testGetGlobalMissWithoutDefault() throws Exception
{        deletePath(GLOBAL.getZookeeperRoot());        Object out = run("CONFIG_GET('GLOBAL', false)", context);    assertNull(out);}
0
public void testGetGlobalMissWithDefault() throws Exception
{        deletePath(GLOBAL.getZookeeperRoot());        Map<String, Object> expected = Collections.emptyMap();    {        String out = (String) run("CONFIG_GET('GLOBAL')", context);        Map<String, Object> actual = toJSONObject(out);        assertEquals(expected, actual);    }    {        String out = (String) run("CONFIG_GET('GLOBAL', true)", context);        Map<String, Object> actual = toJSONObject(out);        assertEquals(expected, actual);    }}
0
public void testPutGlobal() throws Exception
{    String out = (String) run("CONFIG_GET('GLOBAL')", context);    Map<String, Object> actual = toJSONObject(out);    Map<String, Object> expected = toJSONObject(goodGlobalConfig);    assertEquals(expected, actual);}
0
public void testPutGlobalBad()
{    {        UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.FATAL);        try {            run("CONFIG_PUT('GLOBAL', 'foo bar')", context);        } catch (ParseException e) {            UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.ERROR);            throw e;        }    }}
0
public void testPutIndexing() throws InterruptedException
{    String brop = (String) run("CONFIG_GET('INDEXING', 'testIndexingPut')", context);    run("CONFIG_PUT('INDEXING', config, 'testIndexingPut')", ImmutableMap.of("config", brop), context);    boolean foundMatch = false;    for (int i = 0; i < 10 && !foundMatch; ++i) {        String bropNew = (String) run("CONFIG_GET('INDEXING', 'testIndexingPut', false)", context);        foundMatch = brop.equals(bropNew);        if (foundMatch) {            break;        }        Thread.sleep(2000);    }    assertTrue(foundMatch);}
0
public void testPutIndexingBad() throws InterruptedException
{    {        {            UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.FATAL);            try {                run("CONFIG_PUT('INDEXING', config, 'brop')", ImmutableMap.of("config", "foo bar"), context);            } catch (ParseException e) {                UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.ERROR);                throw e;            }        }    }}
0
public void testPutEnrichment() throws InterruptedException
{    String config = (String) run("CONFIG_GET('ENRICHMENT', 'sensor')", context);    assertNotNull(config);    run("CONFIG_PUT('ENRICHMENT', config, 'sensor')", ImmutableMap.of("config", config), context);    boolean foundMatch = false;    for (int i = 0; i < 10 && !foundMatch; ++i) {        String newConfig = (String) run("CONFIG_GET('ENRICHMENT', 'sensor', false)", context);        foundMatch = config.equals(newConfig);        if (foundMatch) {            break;        }        Thread.sleep(2000);    }    assertTrue(foundMatch);}
0
public void testPutEnrichmentBad() throws InterruptedException
{    {        {            UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.FATAL);            try {                run("CONFIG_PUT('ENRICHMENT', config, 'brop')", ImmutableMap.of("config", "foo bar"), context);            } catch (ParseException e) {                UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.ERROR);                throw e;            }        }    }}
0
public void testPutParser() throws InterruptedException
{    String brop = (String) run("CONFIG_GET('PARSER', 'testParserPut')", context);    run("CONFIG_PUT('PARSER', config, 'testParserPut')", ImmutableMap.of("config", brop), context);    boolean foundMatch = false;    for (int i = 0; i < 10 && !foundMatch; ++i) {        String bropNew = (String) run("CONFIG_GET('PARSER', 'testParserPut', false)", context);        foundMatch = brop.equals(bropNew);        if (foundMatch) {            break;        }        Thread.sleep(2000);    }    assertTrue(foundMatch);}
0
public void testPutParserBad() throws InterruptedException
{    {        UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.FATAL);        try {            run("CONFIG_PUT('PARSER', config, 'brop')", ImmutableMap.of("config", "foo bar"), context);        } catch (ParseException e) {            UnitTestHelper.setLog4jLevel(ConfigurationFunctions.class, Level.ERROR);            throw e;        }    }}
0
public static String emptyTransformationsConfig()
{    SensorEnrichmentConfig config = new SensorEnrichmentConfig();    try {        return JSONUtils.INSTANCE.toJSON(config, true);    } catch (JsonProcessingException e) {        throw new IllegalStateException(e);    }}
0
public static Collection<Object[]> types()
{        return Arrays.asList(new Object[][] { { "ENRICHMENT", "group" }, { "ENRICHMENT", null }, { "THREAT_INTEL", "group" }, { "THREAT_INTEL", null } });}
0
public void setup()
{    variables = ImmutableMap.of("upper", VariableResult.withExpression("FOO", "TO_UPPER('foo')"), "lower", VariableResult.withExpression("foo", "TO_LOWER('FOO')"));    context = new Context.Builder().with(Context.Capabilities.SHELL_VARIABLES, () -> variables).build();}
0
 static Map<String, Object> toMap(String... k)
{    Map<String, Object> ret = new HashMap<>();    for (int i = 0; i < k.length; i += 2) {        ret.put(k[i], k[i + 1]);    }    return ret;}
0
private int size(Map<String, Object> stellarFunctions)
{    if (group == null) {        return stellarFunctions.size();    } else {        return ((Map<String, Object>) stellarFunctions.getOrDefault(group, new HashMap<>())).size();    }}
0
private Object get(Map<String, Object> stellarFunctions, String key)
{    if (group == null) {        return stellarFunctions.get(key);    } else {        return ((Map<String, Object>) stellarFunctions.get(group)).get(key);    }}
0
private EnrichmentConfig getEnrichmentConfig(String configStr)
{    SensorEnrichmentConfig sensorConfig = (SensorEnrichmentConfig) ENRICHMENT.deserialize(configStr);    switch(enrichmentType) {        case "ENRICHMENT":            return sensorConfig.getEnrichment();        case "THREAT_INTEL":            return sensorConfig.getThreatIntel();    }    return null;}
0
private static Map<String, Object> getStellarMappings(EnrichmentConfig config)
{    Map<String, Object> fieldMap = config.getFieldMap();    if (fieldMap == null) {        return new HashMap<>();    }    Map<String, Object> stellarMap = (Map<String, Object>) fieldMap.get("stellar");    if (stellarMap == null) {        return new HashMap<>();    }    return (Map<String, Object>) stellarMap.get("config");}
0
private Object run(String rule, Map<String, Object> variables)
{    StellarProcessor processor = new StellarProcessor();    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void testAddEmpty()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('upper'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    Map<String, Object> stellarFunctions = getStellarMappings(getEnrichmentConfig(newConfig));    Assert.assertEquals(1, size(stellarFunctions));    Assert.assertEquals(variables.get("upper").getExpression().get(), get(stellarFunctions, "upper"));}
0
public void testAddHasExisting()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('upper'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('lower'), group)", toMap("config", newConfig, "type", enrichmentType, "group", group));    Map<String, Object> stellarFunctions = getStellarMappings(getEnrichmentConfig(newConfig));    Assert.assertEquals(2, size(stellarFunctions));    Assert.assertEquals(variables.get("upper").getExpression().get(), get(stellarFunctions, "upper"));    Assert.assertEquals(variables.get("lower").getExpression().get(), get(stellarFunctions, "lower"));}
0
public void testAddMalformed()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('foo'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    Map<String, Object> stellarFunctions = getStellarMappings(getEnrichmentConfig(newConfig));    Assert.assertEquals(0, size(stellarFunctions));}
0
public void testAddDuplicate()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('upper'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('upper'), group)", toMap("config", newConfig, "type", enrichmentType, "group", group));    Map<String, Object> stellarFunctions = getStellarMappings(getEnrichmentConfig(newConfig));    Assert.assertEquals(1, size(stellarFunctions));    Assert.assertEquals(variables.get("upper").getExpression().get(), get(stellarFunctions, "upper"));}
0
public void testRemove()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('upper', 'lower'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_REMOVE(config, type, ['upper'], group)", toMap("config", newConfig, "type", enrichmentType, "group", group));    Map<String, Object> stellarFunctions = getStellarMappings(getEnrichmentConfig(newConfig));    Assert.assertEquals(1, size(stellarFunctions));    Assert.assertEquals(variables.get("lower").getExpression().get(), get(stellarFunctions, "lower"));}
0
public void testRemoveMultiple()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('upper', 'lower'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_REMOVE(config, type, ['upper', 'lower'], group)", toMap("config", newConfig, "type", enrichmentType, "group", group));    Map<String, Object> stellarFunctions = getStellarMappings(getEnrichmentConfig(newConfig));    Assert.assertEquals(0, size(stellarFunctions));}
0
public void testRemoveMissing()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('lower'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_REMOVE(config, type, ['upper'], group)", toMap("config", newConfig, "type", enrichmentType, "group", group));    Map<String, Object> stellarFunctions = getStellarMappings(getEnrichmentConfig(newConfig));    Assert.assertEquals(1, size(stellarFunctions));    Assert.assertEquals(variables.get("lower").getExpression().get(), get(stellarFunctions, "lower"));}
0
public void testPrint()
{    String newConfig = (String) run("ENRICHMENT_STELLAR_TRANSFORM_ADD(config, type, SHELL_VARS2MAP('upper'), group)", toMap("config", configStr, "type", enrichmentType, "group", group));    String out = (String) run("ENRICHMENT_STELLAR_TRANSFORM_PRINT(config, type)", toMap("config", newConfig, "type", enrichmentType));    if (group == null) {        Assert.assertEquals(testPrintExpectedWithoutGroup, out);    } else {        Assert.assertEquals(testPrintExpectedWithGroup, out);    }}
0
public void testPrintEmpty()
{    String out = (String) run("ENRICHMENT_STELLAR_TRANSFORM_PRINT(config, type)", toMap("config", configStr, "type", enrichmentType));    Assert.assertEquals(testPrintEmptyExpected, out);}
0
public void testPrintNull()
{    String out = (String) run("ENRICHMENT_STELLAR_TRANSFORM_PRINT(config, type)", toMap("config", configStr, "type", enrichmentType));    Assert.assertEquals(testPrintEmptyExpected, out);}
0
public static Collection<Object[]> types()
{    return Arrays.asList(new Object[][] { { FileSystemFunctions.FS_TYPE.HDFS }, { FileSystemFunctions.FS_TYPE.LOCAL } });}
0
public static void setupFS() throws IOException
{    {        hdfsBaseDir = Files.createTempDirectory("test_hdfs").toFile().getAbsoluteFile();        Configuration conf = new Configuration();        conf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR, hdfsBaseDir.getAbsolutePath());        MiniDFSCluster.Builder builder = new MiniDFSCluster.Builder(conf);        hdfsCluster = builder.build();        hdfsPrefix = "/";    }    {        localPrefix = "target/fsTest/";        if (new File(localPrefix).exists()) {            new File(localPrefix).delete();        }        new File(localPrefix).mkdirs();    }}
0
public void setup() throws IOException
{    if (type == FileSystemFunctions.FS_TYPE.HDFS) {        prefix = hdfsPrefix;        fsGetter = () -> hdfsCluster.getFileSystem();    } else {        prefix = localPrefix;        fsGetter = FileSystemFunctions.FS_TYPE.LOCAL;    }    get = new FileSystemFunctions.FileSystemGet(fsGetter);    get.initialize(null);    getList = new FileSystemFunctions.FileSystemGetList(fsGetter);    getList.initialize(null);    ls = new FileSystemFunctions.FileSystemLs(fsGetter);    ls.initialize(null);    put = new FileSystemFunctions.FileSystemPut(fsGetter);    put.initialize(null);    rm = new FileSystemFunctions.FileSystemRm(fsGetter);    rm.initialize(null);}
0
public static void teardown()
{    {        hdfsCluster.shutdown();        FileUtil.fullyDelete(hdfsBaseDir);    }    {        new File(localPrefix).delete();    }}
0
public void testHappyPath()
{    Object putOut = put.apply(Arrays.asList("foo", prefix + "testPut.dat"), null);    Assert.assertTrue((Boolean) putOut);    String getOut = (String) get.apply(Arrays.asList(prefix + "testPut.dat"), null);    Assert.assertEquals("foo", getOut);    String lsOut = (String) ls.apply(Arrays.asList(prefix), null);    Assert.assertFalse(lsOut.contains("(empty)"));    Boolean rmRet = (Boolean) rm.apply(Arrays.asList(prefix + "testPut.dat"), null);    Assert.assertTrue(rmRet);    lsOut = (String) ls.apply(Arrays.asList(prefix), null);    Assert.assertTrue(lsOut.contains("(empty)"));}
0
public void testGetList()
{    Object putOut = put.apply(Arrays.asList("foo\nbar", prefix + "testPut.dat"), null);    Assert.assertTrue((Boolean) putOut);    String getOut = (String) get.apply(Arrays.asList(prefix + "testPut.dat"), null);    Assert.assertEquals("foo\nbar", getOut);    List<String> list = (List<String>) getList.apply(Arrays.asList(prefix + "testPut.dat"), null);    Assert.assertEquals(2, list.size());    Assert.assertEquals("foo", list.get(0));    Assert.assertEquals("bar", list.get(1));}
0
public void testPutMissingFile()
{    Object o = put.apply(Arrays.asList("foo", null), null);    Assert.assertFalse((Boolean) o);    String lsOut = (String) ls.apply(Arrays.asList(prefix), null);    Assert.assertTrue(lsOut.contains("(empty)"));}
0
public void testRmTwice()
{    Object putOut = put.apply(Arrays.asList("foo", prefix + "testPut.dat"), null);    Assert.assertTrue((Boolean) putOut);    Boolean rmRet = (Boolean) rm.apply(Arrays.asList(prefix + "testPut.dat"), null);    Assert.assertTrue(rmRet);    rmRet = (Boolean) rm.apply(Arrays.asList(prefix + "testPut.dat"), null);    Assert.assertTrue(rmRet);    String lsOut = (String) ls.apply(Arrays.asList(prefix), null);    Assert.assertTrue(lsOut.contains("(empty)"));}
0
public void testRecursiveRm()
{    Object putOut = put.apply(Arrays.asList("foo", prefix + "blah/testPut.dat"), null);    Assert.assertTrue((Boolean) putOut);    putOut = put.apply(Arrays.asList("grok", prefix + "blah/testPut2.dat"), null);    Assert.assertTrue((Boolean) putOut);    Assert.assertEquals("foo", (String) get.apply(Arrays.asList(prefix + "blah/testPut.dat"), null));    Assert.assertEquals("grok", (String) get.apply(Arrays.asList(prefix + "blah/testPut2.dat"), null));    boolean rmRet = (Boolean) rm.apply(Arrays.asList(prefix + "blah", true), null);    Assert.assertTrue(rmRet);    String lsOut = (String) ls.apply(Arrays.asList(prefix), null);    Assert.assertTrue(lsOut.contains("(empty)"));}
0
public void testGrokEvalSingleMessage()
{    String message = "1474583120.343    142 127.0.0.1 TCP_MISS/301 494 GET http://cnn.com/ - DIRECT/157.166.226.26 text/html";    String out = (String) run("GROK_EVAL( grok, messages )", ImmutableMap.of("messages", ImmutableList.of(message), "grok", grokExpr), Context.EMPTY_CONTEXT());    Assert.assertTrue(out.contains("TCP_MISS"));    Assert.assertTrue(out.contains(" 494 "));    Assert.assertTrue(out.contains("157.166.226.26"));}
0
public void testGrokEvalMultiMessages()
{    String message = "1474583120.343    142 127.0.0.1 TCP_MISS/301 494 GET http://cnn.com/ - DIRECT/157.166.226.26 text/html";    String message2 = "1474583120.343    142 127.0.0.1 TCP_MISS/404 494 GET http://google.com/ - DIRECT/157.166.226.26 text/html";    String out = (String) run("GROK_EVAL( grok, messages )", ImmutableMap.of("messages", ImmutableList.of(message, message2), "grok", grokExpr), Context.EMPTY_CONTEXT());    Assert.assertTrue(out.contains("TCP_MISS"));    Assert.assertTrue(out.contains(" 494 "));    Assert.assertTrue(out.contains("157.166.226.26"));    Assert.assertTrue(out.contains("404"));}
0
public void testGrokEvalBadData()
{    String message = "1474583120.343    142 foo TCP_MISS/301 494 GET http://cnn.com/ - DIRECT/157.166.226.26 text/html";    String out = (String) run("GROK_EVAL( grok, message )", ImmutableMap.of("message", message, "grok", grokExpr), Context.EMPTY_CONTEXT());    Assert.assertEquals("NO MATCH", out);}
0
public void testGrokEvalBadDataMultiMessages()
{    String message = "1474583120.343    142 foo TCP_MISS/301 494 GET http://cnn.com/ - DIRECT/157.166.226.26 text/html";    String message2 = "1474583120.343    142 127.0.0.1 TCP_MISS/404 494 GET http://google.com/ - DIRECT/157.166.226.26 text/html";    String out = (String) run("GROK_EVAL( grok, messages )", ImmutableMap.of("messages", ImmutableList.of(message, message2), "grok", grokExpr), Context.EMPTY_CONTEXT());    Assert.assertTrue(out.contains("MISSING"));    Assert.assertTrue(out.contains("404"));}
0
public void testGrokDiscover()
{    String out = (String) run("GROK_PREDICT( '1474583120.343    142 127.0.0.1 TCP_MISS/301')", new HashMap<>(), Context.EMPTY_CONTEXT());    Assert.assertEquals("%{BASE10NUM}    142 %{IP} TCP_MISS%{PATH}", out);}
0
private Object run(String rule, Map<String, Object> variables)
{    StellarProcessor processor = new StellarProcessor();    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void setup()
{    variables = ImmutableMap.of("upper", VariableResult.withExpression("FOO", "TO_UPPER('foo')"), "lower", VariableResult.withExpression("foo", "TO_LOWER('FOO')"));    context = new Context.Builder().with(Context.Capabilities.SHELL_VARIABLES, () -> variables).build();}
0
public void testSetBatch()
{    String out = (String) run("INDEXING_SET_BATCH(config, 'hdfs', 10)", toMap("config", "{}"));    Map<String, Object> config = (Map<String, Object>) INDEXING.deserialize(out);    Assert.assertEquals(10, IndexingConfigurations.getBatchSize((Map<String, Object>) config.get("hdfs")));}
0
public void testSetBatchWithTimeout()
{    String out = (String) run("INDEXING_SET_BATCH(config, 'hdfs', 10, 2)", toMap("config", "{}"));    Map<String, Object> config = (Map<String, Object>) INDEXING.deserialize(out);    Assert.assertEquals(10, IndexingConfigurations.getBatchSize((Map<String, Object>) config.get("hdfs")));    Assert.assertEquals(2, IndexingConfigurations.getBatchTimeout((Map<String, Object>) config.get("hdfs")));}
0
public void testSetBatchBad()
{    Map<String, Object> variables = new HashMap<String, Object>() {        {            put("config", null);        }    };    run("INDEXING_SET_BATCH(config, 'hdfs', 10)", variables);}
0
public void testSetEnabled()
{    String out = (String) run("INDEXING_SET_ENABLED(config, 'hdfs', true)", toMap("config", "{}"));    Map<String, Object> config = (Map<String, Object>) INDEXING.deserialize(out);    Assert.assertTrue(IndexingConfigurations.isEnabled((Map<String, Object>) config.get("hdfs")));}
0
public void testSetEnabledBad()
{    Map<String, Object> variables = new HashMap<String, Object>() {        {            put("config", null);        }    };    run("INDEXING_SET_ENABLED(config, 'hdfs', 10)", variables);}
0
public void testSetIndex()
{    String out = (String) run("INDEXING_SET_INDEX(config, 'hdfs', 'foo')", toMap("config", "{}"));    Map<String, Object> config = (Map<String, Object>) INDEXING.deserialize(out);    Assert.assertEquals("foo", IndexingConfigurations.getIndex((Map<String, Object>) config.get("hdfs"), null));}
0
public void testSetIndexBad()
{    Map<String, Object> variables = new HashMap<String, Object>() {        {            put("config", null);        }    };    run("INDEXING_SET_INDEX(config, 'hdfs', NULL)", variables);}
0
public static void setupExecutor()
{    executor = Executors.newFixedThreadPool(2);}
0
public static void tearDownExecutor()
{    if (executor != null && !executor.isShutdown()) {        executor.shutdown();    }}
0
public static void setupKafka() throws Exception
{    Properties properties = new Properties();    zkServerComponent = getZKServerComponent(properties);    kafkaComponent = getKafkaComponent(properties, new ArrayList<>());    runner = new ComponentRunner.Builder().withComponent("zk", zkServerComponent).withComponent("kafka", kafkaComponent).withMillisecondsBetweenAttempts(5000).withNumRetries(5).withCustomShutdownOrder(new String[] { "kafka", "zk" }).build();    runner.start();}
0
public static void setupFunctionResolver()
{        functionResolver = new SimpleFunctionResolver().withClass(KafkaFunctions.KafkaGet.class).withClass(KafkaFunctions.KafkaPut.class).withClass(KafkaFunctions.KafkaProps.class).withClass(KafkaFunctions.KafkaTail.class).withClass(KafkaFunctions.KafkaFind.class).withClass(KafkaFunctions.KafkaSeek.class).withClass(MapFunctions.MapGet.class);}
0
public void setup()
{        variables = new HashMap<>();    variables.put("message1", message1);    variables.put("message2", message2);    variables.put("message3", message3);        global = new Properties();    global.put("bootstrap.servers", kafkaComponent.getBrokerList());        global.put("auto.offset.reset", "earliest");}
0
public static void tearDownAfterClass() throws Exception
{    runner.stop();}
0
public void tearDown()
{    runner.reset();}
0
public void testKafkaPut()
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        assertEquals(1, run("KAFKA_PUT(topic, [message1])"));        assertEquals(Collections.singletonList(message1), run("KAFKA_GET(topic)"));}
0
public void testKafkaPutMultipleMessages()
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        assertEquals(2, run("KAFKA_PUT(topic, [message1, message2])"));        List<String> expected = new ArrayList<String>() {        {            add(message1);            add(message2);        }    };    assertEquals(expected, run("KAFKA_GET(topic, 2)"));}
0
public void testKafkaPutOneMessagePassedAsString()
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, message1)");        Object actual = run("KAFKA_GET(topic)");        assertEquals(Collections.singletonList(message1), actual);}
0
public void testKafkaPutWithRichView()
{        global.put(KafkaFunctions.MESSAGE_VIEW_PROPERTY, KafkaFunctions.MESSAGE_VIEW_RICH);        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        Object actual = run("KAFKA_PUT(topic, message1)");        assertTrue(actual instanceof List);    List<Object> results = (List) actual;    assertEquals(1, results.size());        Map<String, Object> view = (Map) results.get(0);    assertEquals(topicName, view.get("topic"));    assertEquals(0, view.get("partition"));    assertEquals(0L, view.get("offset"));    assertNotNull(view.get("timestamp"));}
0
public void testKafkaGetWithRichView()
{        global.put(KafkaFunctions.MESSAGE_VIEW_PROPERTY, KafkaFunctions.MESSAGE_VIEW_RICH);        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, message1)");        Object actual = run("KAFKA_GET(topic)");        assertTrue(actual instanceof List);    List<Object> results = (List) actual;    assertEquals(1, results.size());        Map<String, Object> view = (Map) results.get(0);    assertNull(view.get("key"));    assertEquals(0L, view.get("offset"));    assertEquals(0, view.get("partition"));    assertEquals(topicName, view.get("topic"));    assertEquals(message1, view.get("value"));}
0
public void testKafkaPutThenGetWithMultipleMessages()
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [message1, message2, message3])");        Object actual = run("KAFKA_GET(topic, 3)");        List<String> expected = new ArrayList<String>() {        {            add(message1);            add(message2);            add(message3);        }    };    assertEquals(expected, actual);}
0
public void testKafkaGetWithSequentialReads()
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [message1, message2, message3])");        assertEquals(Collections.singletonList(message1), run("KAFKA_GET(topic, 1)"));        assertEquals(Collections.singletonList(message2), run("KAFKA_GET(topic, 1)"));        assertEquals(Collections.singletonList(message3), run("KAFKA_GET(topic, 1)"));        assertEquals(Collections.emptyList(), run("KAFKA_GET(topic, 1)"));}
0
public void testKafkaGetWithNonExistentTopic()
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        assertEquals(Collections.emptyList(), run("KAFKA_GET(topic, 1)"));}
0
public void testKafkaTail() throws Exception
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [message2, message2, message2])");        Future<Object> tailFuture = runAsync("KAFKA_TAIL(topic, 1)");        runAsyncAndWait(Collections.nCopies(10, "KAFKA_PUT(topic, [message1])"));        Object actual = tailFuture.get(10, TimeUnit.SECONDS);    List<String> expected = Collections.singletonList(message1);    assertEquals(expected, actual);}
0
public void testKafkaTailNone()
{        global.put(KafkaFunctions.MAX_WAIT_PROPERTY, 2000);        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [message1, message2, message3])");        assertEquals(Collections.emptyList(), run("KAFKA_TAIL(topic, 1)"));}
0
public void testKafkaTailWithRichView() throws Exception
{        global.put(KafkaFunctions.MESSAGE_VIEW_PROPERTY, KafkaFunctions.MESSAGE_VIEW_RICH);        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [message2, message2, message2])");        Future<Object> tailFuture = runAsync("KAFKA_TAIL(topic, 1)");        runAsyncAndWait(Collections.nCopies(10, "KAFKA_PUT(topic, [message1])"));        Object actual = tailFuture.get(10, TimeUnit.SECONDS);        assertTrue(actual instanceof List);    List<Object> results = (List) actual;    assertEquals(1, results.size());        Map<String, Object> view = (Map) results.get(0);    assertNull(view.get("key"));    assertEquals(0, view.get("partition"));    assertEquals(topicName, view.get("topic"));    assertEquals(message1, view.get("value"));    assertNotNull(view.get("offset"));}
0
public void testKafkaPropsWithGlobalOverride()
{        final String overriddenKey = "bootstrap.servers";    final String expected = "foo.global.override.com:9092";    global.setProperty(overriddenKey, expected);        Map<String, String> properties = (Map<String, String>) run("KAFKA_PROPS()");    assertEquals(expected, properties.get(overriddenKey));}
0
public void testKafkaPropsWithUserOverride()
{        final String overriddenKey = "bootstrap.servers";    global.setProperty(overriddenKey, "foo.global.override.com:9092");        final String expected = "foo.user.override.com:9092";    String expression = String.format("KAFKA_PROPS({ '%s' : '%s' })", overriddenKey, expected);        Map<String, String> properties = (Map<String, String>) run(expression);    assertEquals(expected, properties.get(overriddenKey));}
0
public void testKafkaFind() throws Exception
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        Future<Object> future = runAsync("KAFKA_FIND(topic, m -> MAP_GET('value', m) == 23)");        runAsyncAndWait(Collections.nCopies(10, "KAFKA_PUT(topic, [message2])"));        Object actual = future.get(10, TimeUnit.SECONDS);    List<String> expected = Collections.singletonList(message2);    assertEquals(expected, actual);}
0
public void testKafkaFindNone() throws Exception
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        Future<Object> future = runAsync("KAFKA_FIND(topic, m -> false)");        runAsyncAndWait(Collections.nCopies(10, "KAFKA_PUT(topic, [message1])"));        Object actual = future.get(10, TimeUnit.SECONDS);    List<String> expected = Collections.emptyList();    assertEquals(expected, actual);}
0
public void testKafkaFindWithRichView() throws Exception
{        global.put(KafkaFunctions.MESSAGE_VIEW_PROPERTY, KafkaFunctions.MESSAGE_VIEW_RICH);        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        Future<Object> future = runAsync("KAFKA_FIND(topic, m -> MAP_GET('value', m) == 23)");        runAsyncAndWait(Collections.nCopies(10, "KAFKA_PUT(topic, [message2])"));        Object actual = future.get(10, TimeUnit.SECONDS);    assertTrue(actual instanceof List);    List<Object> results = (List) actual;    assertEquals(1, results.size());        Map<String, Object> view = (Map) results.get(0);    assertNull(view.get("key"));    assertNotNull(view.get("offset"));    assertEquals(0, view.get("partition"));    assertEquals(topicName, view.get("topic"));    assertEquals(message2, view.get("value"));}
0
public void testKafkaFindMultiple() throws Exception
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        Future<Object> future = runAsync("KAFKA_FIND(topic, m -> true, 2)");        runAsyncAndWait(Collections.nCopies(10, "KAFKA_PUT(topic, [message2])"));        List<String> expected = new ArrayList<String>() {        {            add(message2);            add(message2);        }    };    Object actual = future.get(10, TimeUnit.SECONDS);    assertEquals(expected, actual);}
0
public void testKafkaFindExceedsMaxWait()
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [message1, message2, message3])");        long before = System.currentTimeMillis();    Object actual = run("KAFKA_FIND(topic, m -> false, 10, { 'stellar.kafka.max.wait.millis': 1000 })");        long wait = System.currentTimeMillis() - before;    assertTrue("Expected wait not to exceed max wait; actual wait = " + wait, wait < 2 * 1000);        List<String> expected = Collections.emptyList();    assertEquals(expected, actual);}
0
public void testKafkaSeek() throws Exception
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [ message1, message2, message3 ])");    {                Object actual = run("KAFKA_SEEK(topic, 0, 2)");        assertEquals(message3, actual);    }    {                Object actual = run("KAFKA_SEEK(topic, 0, 1)");        assertEquals(message2, actual);    }    {                Object actual = run("KAFKA_SEEK(topic, 0, 0)");        assertEquals(message1, actual);    }}
0
public void testKafkaSeekToMissingOffset() throws Exception
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [ message1, message2, message3 ])");        Object actual = run("KAFKA_SEEK(topic, 0, 9999)");    assertNull(actual);}
0
public void testKafkaSeekToMissingPartition() throws Exception
{        final String topicName = testName.getMethodName();    variables.put("topic", topicName);        run("KAFKA_PUT(topic, [ message1, message2, message3 ])");        Object actual = run("KAFKA_SEEK(topic, 99999, 0)");    assertNull(actual);}
0
public void testKafkaSeekWithRichView() throws Exception
{        global.put(KafkaFunctions.MESSAGE_VIEW_PROPERTY, KafkaFunctions.MESSAGE_VIEW_RICH);        final String topicName = testName.getMethodName();    variables.put("topic", topicName);    run("KAFKA_PUT(topic, [ message1, message2, message3 ])");    Object actual = run("KAFKA_SEEK(topic, 0, 0)");        assertTrue(actual instanceof Map);    Map<String, Object> view = (Map) actual;    assertNull(view.get("key"));    assertNotNull(view.get("offset"));    assertEquals(0, view.get("partition"));    assertEquals(topicName, view.get("topic"));    assertEquals(message1, view.get("value"));}
0
private Object run(String expression)
{        Context context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, () -> global).build();        StellarProcessor processor = new StellarProcessor();    return processor.parse(expression, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), functionResolver, context);}
0
private Future<Object> runAsync(String expression)
{    return executor.submit(() -> run(expression));}
0
private void runAsyncAndWait(Iterable<String> expressions) throws Exception
{        List<Future<Object>> putFutures = new ArrayList<>();    for (String expression : expressions) {        Future<Object> future = runAsync(expression);        putFutures.add(future);    }        for (Future<Object> future : putFutures) {        future.get(5, TimeUnit.SECONDS);    }}
0
public void setup()
{    variables = ImmutableMap.of("upper", VariableResult.withExpression("FOO", "TO_UPPER('foo')"), "lower", VariableResult.withExpression("foo", "TO_LOWER('FOO'"));    context = new Context.Builder().with(Context.Capabilities.SHELL_VARIABLES, () -> variables).build();}
0
public Map<String, Object> transform(String parserConfig)
{    return transform(parserConfig, new HashMap<>());}
0
public Map<String, Object> transform(String parserConfig, Map<String, Object> variables)
{    JSONObject ret = new JSONObject(variables);    SensorParserConfig sensorParserConfig = (SensorParserConfig) PARSER.deserialize(parserConfig);    sensorParserConfig.init();    for (FieldTransformer handler : sensorParserConfig.getFieldTransformations()) {        if (handler != null) {            handler.transformAndUpdate(ret, context, sensorParserConfig.getParserConfig());        }    }    return ret;}
0
public void testAddEmpty()
{    String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", emptyTransformationsConfig), context);    Map<String, Object> transformations = transform(newConfig);    Assert.assertEquals(1, transformations.size());    Assert.assertEquals("FOO", transformations.get("upper"));}
0
public void testAddHasExisting()
{    String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", existingTransformationsConfig), context);    Map<String, Object> transformations = transform(newConfig, ImmutableMap.of("url", "http://www.google.com"));        Assert.assertEquals(4, transformations.size());    Assert.assertEquals("FOO", transformations.get("upper"));}
0
public void testAddMalformed()
{    String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('blah'))", ImmutableMap.of("config", emptyTransformationsConfig), context);    Map<String, Object> transformations = transform(newConfig);    Assert.assertEquals(0, transformations.size());}
0
public void testAddDuplicate()
{    String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", emptyTransformationsConfig), context);    newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", newConfig), context);    Map<String, Object> transformations = transform(newConfig);    Assert.assertEquals(1, transformations.size());    Assert.assertEquals("FOO", transformations.get("upper"));}
0
public void testRemove()
{    String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", emptyTransformationsConfig), context);    newConfig = (String) run("PARSER_STELLAR_TRANSFORM_REMOVE(config, ['upper'])", ImmutableMap.of("config", newConfig), context);    Map<String, Object> transformations = transform(newConfig);    Assert.assertEquals(0, transformations.size());}
0
public void testRemoveMultiple()
{    String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper', 'lower'))", ImmutableMap.of("config", emptyTransformationsConfig), context);    newConfig = (String) run("PARSER_STELLAR_TRANSFORM_REMOVE(config, ['upper', 'lower'])", ImmutableMap.of("config", newConfig), context);    Map<String, Object> transformations = transform(newConfig);    Assert.assertEquals(0, transformations.size());}
0
public void testRemoveMissing()
{    {        String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", emptyTransformationsConfig), context);        newConfig = (String) run("PARSER_STELLAR_TRANSFORM_REMOVE(config, ['lower'])", ImmutableMap.of("config", newConfig), context);        Map<String, Object> transformations = transform(newConfig);        Assert.assertEquals(1, transformations.size());        Assert.assertEquals("FOO", transformations.get("upper"));    }    {        String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", emptyTransformationsConfig), context);        newConfig = (String) run("PARSER_STELLAR_TRANSFORM_REMOVE(config, [''])", ImmutableMap.of("config", newConfig), context);        Map<String, Object> transformations = transform(newConfig);        Assert.assertEquals(1, transformations.size());        Assert.assertEquals("FOO", transformations.get("upper"));    }}
0
public void testPrint()
{    String newConfig = (String) run("PARSER_STELLAR_TRANSFORM_ADD(config, SHELL_VARS2MAP('upper'))", ImmutableMap.of("config", emptyTransformationsConfig), context);    String out = (String) run("PARSER_STELLAR_TRANSFORM_PRINT(config )", ImmutableMap.of("config", newConfig), context);    Assert.assertEquals(testPrintExpected, out);}
0
public void testPrintEmpty()
{    String out = (String) run("PARSER_STELLAR_TRANSFORM_PRINT(config )", ImmutableMap.of("config", emptyTransformationsConfig), context);    Assert.assertEquals(testPrintEmptyExpected, out);}
0
public void testPrintNull()
{    Map<String, Object> variables = new HashMap<String, Object>() {        {            put("config", null);        }    };    String out = (String) run("PARSER_STELLAR_TRANSFORM_PRINT(config )", variables, context);    Assert.assertNull(out);}
0
public void setup()
{    variables = new HashMap<>();    functionResolver = new SimpleFunctionResolver().withClass(ParserFunctions.ParseFunction.class).withClass(ParserFunctions.InitializeFunction.class).withClass(ParserFunctions.ConfigFunction.class);    context = new Context.Builder().build();    executor = new DefaultStellarStatefulExecutor(functionResolver, context);}
0
public void testParseBroMessage()
{        set("config", broParserConfig);    assign("parser", "PARSER_INIT('bro', config)");        set("message", broMessage);    List<JSONObject> messages = execute("PARSER_PARSE(parser, message)", List.class);        Assert.assertEquals(1, messages.size());    JSONObject message = messages.get(0);    Assert.assertEquals("bro", message.get(Constants.SENSOR_TYPE));    Assert.assertEquals("10.122.196.204", message.get(SRC_ADDR.getName()));    Assert.assertEquals(33976L, message.get(SRC_PORT.getName()));    Assert.assertEquals("144.254.71.184", message.get(DST_ADDR.getName()));    Assert.assertEquals(53L, message.get(DST_PORT.getName()));    Assert.assertEquals("dns", message.get("protocol"));}
0
public void testParseMultipleMessages()
{        set("config", broParserConfig);    assign("parser", "PARSER_INIT('bro', config)");        set("msg1", broMessage);    set("msg2", broMessage);    set("msg3", broMessage);    List<JSONObject> messages = execute("PARSER_PARSE(parser, [msg1, msg2, msg3])", List.class);        Assert.assertEquals(3, messages.size());    for (JSONObject message : messages) {        Assert.assertEquals("bro", message.get(Constants.SENSOR_TYPE));        Assert.assertTrue(message.containsKey(Constants.GUID));        Assert.assertEquals("10.122.196.204", message.get(SRC_ADDR.getName()));        Assert.assertEquals(33976L, message.get(SRC_PORT.getName()));        Assert.assertEquals("144.254.71.184", message.get(DST_ADDR.getName()));        Assert.assertEquals(53L, message.get(DST_PORT.getName()));        Assert.assertEquals("dns", message.get("protocol"));    }}
0
public void testParseInvalidMessage()
{        set("config", broParserConfig);    assign("parser", "PARSER_INIT('bro', config)");        String invalidMessage = "{ this is an invalid message }}";    set("message", invalidMessage);    List<JSONObject> messages = execute("PARSER_PARSE(parser, message)", List.class);        Assert.assertEquals(1, messages.size());        JSONObject error = messages.get(0);    Assert.assertEquals(invalidMessage, error.get("raw_message"));    Assert.assertEquals(Constants.ERROR_TYPE, error.get(Constants.SENSOR_TYPE));    Assert.assertEquals("parser_error", error.get(ERROR_TYPE.getName()));    Assert.assertTrue(error.containsKey(MESSAGE.getName()));    Assert.assertTrue(error.containsKey(EXCEPTION.getName()));    Assert.assertTrue(error.containsKey(STACK.getName()));    Assert.assertTrue(error.containsKey(ERROR_HASH.getName()));    Assert.assertTrue(error.containsKey(Constants.GUID));}
0
public void testParseSomeGoodSomeBadMessages()
{        set("config", broParserConfig);    assign("parser", "PARSER_INIT('bro', config)");        String invalidMessage = "{ this is an invalid message }}";    set("msg1", broMessage);    set("msg2", invalidMessage);    List<JSONObject> messages = execute("PARSER_PARSE(parser, [msg1, msg2])", List.class);        Assert.assertEquals(2, messages.size());    Assert.assertEquals(1, messages.stream().filter(msg -> isBro(msg)).count());    Assert.assertEquals(1, messages.stream().filter(msg -> isError(msg)).count());}
0
public void testConfig() throws Exception
{        set("config", broParserConfig);    assign("parser", "PARSER_INIT('bro', config)");    String config = execute("PARSER_CONFIG(parser)", String.class);    Assert.assertNotNull(config);    Assert.assertNotNull(SensorParserConfig.fromBytes(config.getBytes(StandardCharsets.UTF_8)));}
0
public void testInitFromString() throws Exception
{    set("configAsString", broParserConfig);    StellarParserRunner runner = execute("PARSER_INIT('bro', configAsString)", StellarParserRunner.class);    Assert.assertNotNull(runner);    SensorParserConfig actual = runner.getParserConfigurations().getSensorParserConfig("bro");    SensorParserConfig expected = SensorParserConfig.fromBytes(broParserConfig.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(expected, actual);}
0
public void testInitFromMap() throws Exception
{    Map<String, Object> configAsMap = (JSONObject) new JSONParser().parse(broParserConfig);    set("configAsMap", configAsMap);    StellarParserRunner runner = execute("PARSER_INIT('bro', configAsMap)", StellarParserRunner.class);    Assert.assertNotNull(runner);    SensorParserConfig actual = runner.getParserConfigurations().getSensorParserConfig("bro");    SensorParserConfig expected = SensorParserConfig.fromBytes(broParserConfig.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(expected, actual);}
0
public void testInitFromInvalidValue() throws Exception
{    execute("PARSER_INIT('bro', 22)", StellarParserRunner.class);    Assert.fail("expected exception");}
0
public void testInitFromZookeeper() throws Exception
{    byte[] configAsBytes = broParserConfig.getBytes(StandardCharsets.UTF_8);    CuratorFramework zkClient = zkClientForPath("/metron/topology/parsers/bro", configAsBytes);    context.addCapability(Context.Capabilities.ZOOKEEPER_CLIENT, () -> zkClient);    StellarParserRunner runner = execute("PARSER_INIT('bro')", StellarParserRunner.class);    Assert.assertNotNull(runner);    SensorParserConfig actual = runner.getParserConfigurations().getSensorParserConfig("bro");    SensorParserConfig expected = SensorParserConfig.fromBytes(broParserConfig.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(expected, actual);}
0
public void testInitMissingFromZookeeper() throws Exception
{        CuratorFramework zkClient = zkClientMissingPath("/metron/topology/parsers/bro");    context.addCapability(Context.Capabilities.ZOOKEEPER_CLIENT, () -> zkClient);    execute("PARSER_INIT('bro')", StellarParserRunner.class);    Assert.fail("expected exception");}
0
private CuratorFramework zkClientForPath(String path, byte[] value) throws Exception
{    GetDataBuilder getDataBuilder = mock(GetDataBuilder.class);    when(getDataBuilder.forPath(path)).thenReturn(value);    CuratorFramework zkClient = mock(CuratorFramework.class);    when(zkClient.getData()).thenReturn(getDataBuilder);    return zkClient;}
0
private CuratorFramework zkClientMissingPath(String path) throws Exception
{    GetDataBuilder getDataBuilder = mock(GetDataBuilder.class);    when(getDataBuilder.forPath(path)).thenThrow(new KeeperException.NoNodeException(path));    CuratorFramework zkClient = mock(CuratorFramework.class);    when(zkClient.getData()).thenReturn(getDataBuilder);    return zkClient;}
0
private boolean isError(JSONObject message)
{    String sensorType = String.class.cast(message.get(Constants.SENSOR_TYPE));    return Constants.ERROR_TYPE.equals(sensorType);}
0
private boolean isBro(JSONObject message)
{    String sensorType = String.class.cast(message.get(Constants.SENSOR_TYPE));    return "bro".equals(sensorType);}
0
private void set(String var, Object value)
{    executor.assign(var, value);}
0
private Object assign(String var, String expression)
{    executor.assign(var, expression, Collections.emptyMap());    return executor.getState().get(var);}
0
private T execute(String expression, Class<T> clazz)
{    T results = executor.execute(expression, Collections.emptyMap(), clazz);        return results;}
1
public void testParseMessage()
{    List<String> toParse = new ArrayList<>();    toParse.add(broMessage);    toParse.add(broMessage);    toParse.add(broMessage);        StellarParserRunner runner = new StellarParserRunner("bro").withParserConfiguration(broParserConfig).withContext(Context.EMPTY_CONTEXT());    List<JSONObject> messages = runner.parse(toParse);        Assert.assertEquals(3, messages.size());    for (JSONObject message : messages) {        Assert.assertEquals("bro", message.get(Constants.SENSOR_TYPE));        Assert.assertTrue(message.containsKey(Constants.GUID));        Assert.assertEquals("10.122.196.204", message.get(SRC_ADDR.getName()));        Assert.assertEquals(33976L, message.get(SRC_PORT.getName()));        Assert.assertEquals("144.254.71.184", message.get(DST_ADDR.getName()));        Assert.assertEquals(53L, message.get(DST_PORT.getName()));        Assert.assertEquals("dns", message.get("protocol"));    }}
0
public void testParseInvalidMessage()
{    List<String> toParse = new ArrayList<>();    toParse.add("{DAS}");        StellarParserRunner runner = new StellarParserRunner("bro").withParserConfiguration(broParserConfig).withContext(Context.EMPTY_CONTEXT());    List<JSONObject> messages = runner.parse(toParse);        JSONObject error = messages.get(0);    Assert.assertEquals(toParse.get(0), error.get("raw_message"));    Assert.assertEquals(Constants.ERROR_TYPE, error.get(Constants.SENSOR_TYPE));    Assert.assertEquals("parser_error", error.get(ERROR_TYPE.getName()));    Assert.assertTrue(error.containsKey(MESSAGE.getName()));    Assert.assertTrue(error.containsKey(EXCEPTION.getName()));    Assert.assertTrue(error.containsKey(STACK.getName()));    Assert.assertTrue(error.containsKey(ERROR_HASH.getName()));    Assert.assertTrue(error.containsKey(Constants.GUID));}
0
public void testToString()
{    List<String> toParse = new ArrayList<>();    toParse.add(broMessage);    toParse.add("{DAS}");        StellarParserRunner runner = new StellarParserRunner("bro").withParserConfiguration(broParserConfig).withContext(Context.EMPTY_CONTEXT());    List<JSONObject> messages = runner.parse(toParse);        Assert.assertEquals("Parser{1 successful, 1 error(s)}", runner.toString());}
0
public void setup()
{    variables = ImmutableMap.of("less", VariableResult.withExpression(true, "1 < 2"), "greater", VariableResult.withExpression(false, "1 > 2"));    context = new Context.Builder().with(Context.Capabilities.SHELL_VARIABLES, () -> variables).build();}
0
public static List<RiskLevelRule> getTriageRules(String config)
{    SensorEnrichmentConfig sensorConfig = (SensorEnrichmentConfig) ENRICHMENT.deserialize(config);    return sensorConfig.getThreatIntel().getTriageConfig().getRiskLevelRules();}
0
private Object run(String rule, Map<String, Object> variables)
{    StellarProcessor processor = new StellarProcessor();    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
private Object run(String rule)
{    StellarProcessor processor = new StellarProcessor();    return processor.parse(rule, new MapVariableResolver(Collections.emptyMap()), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
private Object run(String... expressions)
{    Object result = null;    for (String expression : expressions) {        result = run(expression);    }    return result;}
0
public void testSetAggregation()
{    String newConfig = (String) run("THREAT_TRIAGE_SET_AGGREGATOR(config, 'MIN' )", toMap("config", configStr));    SensorEnrichmentConfig sensorConfig = (SensorEnrichmentConfig) ENRICHMENT.deserialize(newConfig);    Assert.assertEquals("MIN", sensorConfig.getThreatIntel().getTriageConfig().getAggregator().toString());}
0
public void testSetAggregationWithEngine()
{        ThreatTriageProcessor engine = (ThreatTriageProcessor) run("THREAT_TRIAGE_INIT()");    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);        String newConfig = (String) run("THREAT_TRIAGE_SET_AGGREGATOR(engine, 'MIN')", vars);        SensorEnrichmentConfig sensorConfig = (SensorEnrichmentConfig) ENRICHMENT.deserialize(newConfig);    Assert.assertEquals("MIN", sensorConfig.getThreatIntel().getTriageConfig().getAggregator().toString());        Assert.assertEquals("MIN", engine.getSensorConfig().getThreatIntel().getTriageConfig().getAggregator().toString());}
0
public void testAddEmpty()
{    String newConfig = (String) run("THREAT_TRIAGE_ADD(config, { 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 } )", toMap("config", configStr));    List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(1, triageRules.size());    RiskLevelRule rule = triageRules.get(0);    Assert.assertEquals(variables.get("less").getExpression().get(), rule.getRule());    Assert.assertEquals("10", rule.getScoreExpression());}
0
public void testAddEmptyWithEngine()
{        ThreatTriageProcessor engine = (ThreatTriageProcessor) run("THREAT_TRIAGE_INIT()");    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);    String newConfig = (String) run("THREAT_TRIAGE_ADD(engine, {'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 } )", vars);        List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(1, triageRules.size());        Assert.assertEquals(1, engine.getSensorConfig().getThreatIntel().getTriageConfig().getRiskLevelRules().size());}
0
public void testAddHasExisting()
{    String newConfig = (String) run("THREAT_TRIAGE_ADD(config, { 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10, 'reason' : '2 + 2' } )", toMap("config", configStr));    newConfig = (String) run("THREAT_TRIAGE_ADD(config, { 'rule' : SHELL_GET_EXPRESSION('greater'), 'score' : 20 } )", toMap("config", newConfig));    List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(2, triageRules.size());    RiskLevelRule less = triageRules.get(0);    Assert.assertEquals(variables.get("less").getExpression().get(), less.getRule());    Assert.assertEquals("10", less.getScoreExpression());    RiskLevelRule greater = triageRules.get(1);    Assert.assertEquals(variables.get("greater").getExpression().get(), greater.getRule());    Assert.assertEquals("20", greater.getScoreExpression());}
0
public void testAddMalformed()
{    Object o = run("THREAT_TRIAGE_ADD(config, { 'rule': SHELL_GET_EXPRESSION('foo'), 'score' : 10 } )", toMap("config", configStr));    Assert.assertEquals(configStr, o);}
0
public void testAddDuplicate()
{    String newConfig = (String) run("THREAT_TRIAGE_ADD(config, { 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 } )", toMap("config", configStr));    newConfig = (String) run("THREAT_TRIAGE_ADD(config, { 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 } )", toMap("config", newConfig));    List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(1, triageRules.size());    RiskLevelRule rule = triageRules.get(0);    Assert.assertEquals(variables.get("less").getExpression().get(), rule.getRule());    Assert.assertEquals("10", rule.getScoreExpression());}
0
public void testAddMultiple()
{        String newConfig = (String) run("THREAT_TRIAGE_ADD(config, { 'name':'rule1', 'rule':'value < 2', 'score':10 } )", toMap("config", configStr));        newConfig = (String) run("THREAT_TRIAGE_ADD(config, { 'name':'rule2', 'rule':'value < 4', 'score':10 } )", toMap("config", newConfig));    List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(2, triageRules.size());}
0
public void testAddMultipleWithEngine()
{        ThreatTriageProcessor engine = (ThreatTriageProcessor) run("THREAT_TRIAGE_INIT()");    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);        run("THREAT_TRIAGE_ADD(engine, { 'name':'rule1', 'rule':'value < 2', 'score':10 } )", vars);        run("THREAT_TRIAGE_ADD(engine, { 'name':'rule2', 'rule':'value < 4', 'score':10 } )", vars);    List<RiskLevelRule> triageRules = engine.getRiskLevelRules();    Assert.assertEquals(2, triageRules.size());}
0
public void testRemove()
{    String newConfig = (String) run("THREAT_TRIAGE_ADD(config, [ { 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 }, { 'rule' : SHELL_GET_EXPRESSION('greater'), 'score' : 20 } ] )", toMap("config", configStr));    newConfig = (String) run("THREAT_TRIAGE_REMOVE(config, [ SHELL_GET_EXPRESSION('greater')] )", toMap("config", newConfig));    List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(1, triageRules.size());    RiskLevelRule rule = triageRules.get(0);    Assert.assertEquals(variables.get("less").getExpression().get(), rule.getRule());    Assert.assertEquals("10", rule.getScoreExpression());}
0
public void testRemoveWithEngine()
{        ThreatTriageProcessor engine = (ThreatTriageProcessor) run("THREAT_TRIAGE_INIT()");        Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);        String newConfig = (String) run("THREAT_TRIAGE_ADD(engine, [" + "{ 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 }, " + "{ 'rule' : SHELL_GET_EXPRESSION('greater'), 'score' : 20 } ] )", vars);        newConfig = (String) run("THREAT_TRIAGE_REMOVE(engine, [ " + "SHELL_GET_EXPRESSION('greater')] )", vars);    List<RiskLevelRule> triageRules = engine.getRiskLevelRules();    Assert.assertEquals(1, triageRules.size());    RiskLevelRule rule = triageRules.get(0);    Assert.assertEquals(variables.get("less").getExpression().get(), rule.getRule());    Assert.assertEquals("10", rule.getScoreExpression());}
0
public void testRemoveMultiple()
{    String newConfig = (String) run("THREAT_TRIAGE_ADD(config, [ { 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 }, { 'rule' : SHELL_GET_EXPRESSION('greater'), 'score' : 20 } ] )", toMap("config", configStr));    newConfig = (String) run("THREAT_TRIAGE_REMOVE(config, [ SHELL_GET_EXPRESSION('less'), SHELL_GET_EXPRESSION('greater')] )", toMap("config", newConfig));    List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(0, triageRules.size());}
0
public void testRemoveMissing()
{    String newConfig = (String) run("THREAT_TRIAGE_ADD(config, [ { 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10 }, { 'rule' : SHELL_GET_EXPRESSION('greater'), 'score' : 20 } ] )", toMap("config", configStr));    newConfig = (String) run("THREAT_TRIAGE_REMOVE(config, [ SHELL_GET_EXPRESSION('foo'), SHELL_GET_EXPRESSION('bar')] )", toMap("config", newConfig));    List<RiskLevelRule> triageRules = getTriageRules(newConfig);    Assert.assertEquals(2, triageRules.size());    RiskLevelRule less = triageRules.get(0);    Assert.assertEquals(variables.get("less").getExpression().get(), less.getRule());    Assert.assertEquals("10", less.getScoreExpression());    RiskLevelRule greater = triageRules.get(1);    Assert.assertEquals(variables.get("greater").getExpression().get(), greater.getRule());    Assert.assertEquals("20", greater.getScoreExpression());}
0
public void testPrint()
{    String newConfig = (String) run("THREAT_TRIAGE_ADD(config, [ " + "{ 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10, 'reason' : '2 + 2' }, " + "{ 'rule' : SHELL_GET_EXPRESSION('greater'), 'score' : 20 } ] )", toMap("config", configStr));    String out = (String) run("THREAT_TRIAGE_PRINT(config)", toMap("config", newConfig));    Assert.assertEquals(testPrintExpected, out);}
0
public void testPrintWithEngine()
{        ThreatTriageProcessor engine = (ThreatTriageProcessor) run("THREAT_TRIAGE_INIT()");    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);        run("THREAT_TRIAGE_ADD(engine, [ " + "{ 'rule' : SHELL_GET_EXPRESSION('less'), 'score' : 10, 'reason' : '2 + 2' }, " + "{ 'rule' : SHELL_GET_EXPRESSION('greater'), 'score' : 20 } ] )", vars);        String out = (String) run("THREAT_TRIAGE_PRINT(engine)", vars);    Assert.assertEquals(testPrintExpected, out);}
0
public void testPrintEmpty()
{    String out = (String) run("THREAT_TRIAGE_PRINT(config)", toMap("config", configStr));    Assert.assertEquals(testPrintEmptyExpected, out);}
0
public void testPrintNull()
{    Map<String, Object> variables = new HashMap<String, Object>() {        {            put("config", null);        }    };    String out = (String) run("THREAT_TRIAGE_PRINT(config)", variables);    Assert.assertEquals(out, testPrintEmptyExpected);}
0
public void testTriageInitNoArg()
{    Object result = run("THREAT_TRIAGE_INIT()");    Assert.assertNotNull(result);    Assert.assertTrue(result instanceof ThreatTriageProcessor);        ThreatTriageProcessor engine = (ThreatTriageProcessor) result;    Assert.assertEquals(0, engine.getRiskLevelRules().size());}
0
public void testTriageInitWithArg()
{        String confWithRule = (String) run("THREAT_TRIAGE_ADD(conf, [{ 'rule': 'value > 0', 'score' : 10 } ])", toMap("conf", configStr));        Object result = run("THREAT_TRIAGE_INIT(confWithRule)", toMap("confWithRule", confWithRule));    Assert.assertNotNull(result);    Assert.assertTrue(result instanceof ThreatTriageProcessor);        ThreatTriageProcessor engine = (ThreatTriageProcessor) result;    Assert.assertEquals(1, engine.getRiskLevelRules().size());}
0
public void testTriageInitWithBadArg()
{    run("THREAT_TRIAGE_INIT(missing)");}
0
public void testTriageScoreWithNoRules()
{        Object engine = run("THREAT_TRIAGE_INIT()");    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);    vars.put("msg", message);        Object result = run("THREAT_TRIAGE_SCORE(msg, engine)", vars);    Assert.assertNotNull(result);    Assert.assertTrue(result instanceof Map);        Map<String, Object> score = (Map) result;    Assert.assertEquals(0, ((List) score.get(ThreatTriageFunctions.RULES_KEY)).size());        Object totalScore = score.get(ThreatTriageFunctions.SCORE_KEY);    Assert.assertTrue(totalScore instanceof Double);    Assert.assertEquals(0.0, (Double) totalScore, 0.001);}
0
public void testTriageScoreWithRules()
{        String confWithRule = (String) run("THREAT_TRIAGE_ADD(conf, [{ 'rule': 'value > 0', 'score' : 10 }])", toMap("conf", configStr));        Object engine = run("THREAT_TRIAGE_INIT(confWithRule)", toMap("confWithRule", confWithRule));    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);    vars.put("msg", message);        Object result = run("THREAT_TRIAGE_SCORE(msg, engine)", vars);    Assert.assertNotNull(result);    Assert.assertTrue(result instanceof Map);        Map<String, Object> score = (Map) result;    Assert.assertEquals(1, ((List) score.get(ThreatTriageFunctions.RULES_KEY)).size());        Object totalScore = score.get(ThreatTriageFunctions.SCORE_KEY);    Assert.assertTrue(totalScore instanceof Double);    Assert.assertEquals(10.0, (Double) totalScore, 0.001);        Assert.assertEquals("MAX", score.get(ThreatTriageFunctions.AGG_KEY));}
0
public void testTriageWithScoreExpression()
{        String confWithRule = (String) run("THREAT_TRIAGE_ADD(conf, [{ 'rule': 'value > 0', 'score' : 'value * 10' }])", toMap("conf", configStr));        Object engine = run("THREAT_TRIAGE_INIT(confWithRule)", toMap("confWithRule", confWithRule));    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);    vars.put("msg", message);        Object result = run("THREAT_TRIAGE_SCORE(msg, engine)", vars);    Assert.assertNotNull(result);    Assert.assertTrue(result instanceof Map);        Map<String, Object> score = (Map) result;    Assert.assertEquals(1, ((List) score.get(ThreatTriageFunctions.RULES_KEY)).size());        Object totalScore = score.get(ThreatTriageFunctions.SCORE_KEY);    Assert.assertTrue(totalScore instanceof Double);    Assert.assertEquals(220.0, (Double) totalScore, 0.001);        Assert.assertEquals("MAX", score.get(ThreatTriageFunctions.AGG_KEY));}
0
public void testTriageScoreWithNoMessage()
{        String confWithRule = (String) run("THREAT_TRIAGE_ADD(conf, [{ 'rule': 'value > 0', 'score' : 10 }])", toMap("conf", configStr));        Object engine = run("THREAT_TRIAGE_INIT(confWithRule)", toMap("confWithRule", confWithRule));    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);        run("THREAT_TRIAGE_SCORE(11, engine)", vars);}
0
public void testTriageConfig()
{        Object engine = run("THREAT_TRIAGE_INIT()");    Map<String, Object> vars = new HashMap<>();    vars.put("engine", engine);        Object result = run("THREAT_TRIAGE_CONFIG(engine)", vars);    Assert.assertNotNull(result);    Assert.assertTrue(result instanceof String);        String json = (String) result;    Assert.assertEquals(emptyTransformationsConfig(), json);}
0
public static String slurp(String loc)
{    try {        return Joiner.on("\n").join(Files.readLines(new File(loc), Charset.defaultCharset())).trim();    } catch (IOException e) {        throw new IllegalStateException(e);    }}
0
private void addGrok(String key, String pattern) throws GrokException
{    Grok grok = new Grok();    InputStream patternStream = this.getClass().getResourceAsStream("/patterns/asa");    grok.addPatternFromReader(new InputStreamReader(patternStream, StandardCharsets.UTF_8));    grok.compile("%{" + pattern + "}");    grokers.put(key, grok);}
0
public void init()
{    syslogGrok = new Grok();    InputStream syslogStream = this.getClass().getResourceAsStream("/patterns/asa");    try {        syslogGrok.addPatternFromReader(new InputStreamReader(syslogStream, StandardCharsets.UTF_8));        syslogGrok.compile(syslogPattern);    } catch (GrokException e) {                throw new RuntimeException(e.getMessage(), e);    }    for (Entry<String, String> pattern : patternMap.entrySet()) {        try {            addGrok(pattern.getKey(), pattern.getValue());        } catch (GrokException e) {                    }    }    }
1
protected NumberFormat initialValue()
{    return new DecimalFormat("0.0#####");}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);}
0
public void init()
{}
0
private Long convertToMillis(Double timestampSeconds)
{    return ((Double) (timestampSeconds * 1000)).longValue();}
0
private boolean replaceKey(JSONObject payload, String toKey, String[] fromKeys)
{    for (String fromKey : fromKeys) {        if (payload.containsKey(fromKey)) {            Object value = payload.remove(fromKey);            payload.put(toKey, value);            _LOG.trace("[Metron] Added {} to {}", toKey, payload);            return true;        }    }    return false;}
0
private boolean replaceKeyArray(JSONObject payload, String toKey, String[] fromKeys)
{    for (String fromKey : fromKeys) {        if (payload.containsKey(fromKey)) {            JSONArray value = (JSONArray) payload.remove(fromKey);            if (value != null && !value.isEmpty()) {                payload.put(toKey, value.get(0));                _LOG.trace("[Metron] Added {} to {}", toKey, payload);                return true;            }        }    }    return false;}
0
public JSONObject clean(String jsonString) throws ParseException
{    JSONParser parser = new JSONParser();    Map json = (Map) parser.parse(jsonString);    JSONObject output = new JSONObject();    Iterator iter = json.entrySet().iterator();    while (iter.hasNext()) {        Map.Entry entry = (Map.Entry) iter.next();        String key = ((String) entry.getKey()).replaceAll("[^\\._a-zA-Z0-9]+", "");        output.put(key, entry.getValue());    }    return output;}
0
public static void main(String[] args)
{    String jsonText = "{\"first_1\": 123, \"second\": [4, 5, 6], \"third\": 789}";    JSONCleaner cleaner = new JSONCleaner();    try {                Map obj = new HashMap();        obj.put("name", "foo");        obj.put("num", 100);        obj.put("balance", 1000.21);        obj.put("is_vip", true);        obj.put("nickname", null);        Map obj1 = new HashMap();        obj1.put("sourcefile", obj);        JSONObject json = new JSONObject(obj1);        System.out.println(json);        System.out.print(jsonText);    } catch (Exception e) {        e.printStackTrace();    }}
0
public void init()
{            String syslogTime = "(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\b +(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]) (?!<[0-9])(?:2[0123]|[01]?[0-9]):(?:[0-5][0-9])(?::(?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?))(?![0-9])?";    String syslogTime5424 = "(?:\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?(?:Z|[+-]\\d{2}:\\d{2}))";    String syslogPriority = "<(?:[0-9]+)>";    String syslogHost = "[a-z0-9\\.\\\\-_]+";    StringBuilder sb = new StringBuilder("");    sb.append("(?<syslogPriority>");    sb.append(syslogPriority);    sb.append(")?");    sb.append("(?<syslogTime>");    sb.append(syslogTime);    sb.append("|");    sb.append(syslogTime5424);    sb.append(")?");    sb.append("(?<syslogHost>");    sb.append(syslogHost);    sb.append(")?");    sb.append(".*");    sb.append("CEF: ?0\\|");    headerBlock("DeviceVendor", sb);    sb.append("\\|");    headerBlock("DeviceProduct", sb);    sb.append("\\|");    headerBlock("DeviceVersion", sb);    sb.append("\\|");    headerBlock("DeviceEvent", sb);    sb.append("\\|");    headerBlock("Name", sb);    sb.append("\\|");    headerBlock("Severity", sb);    sb.append("\\|");        sb.append("(?<extensions>.*)");    String pattern = sb.toString();    p = Pattern.compile(pattern);}
0
public static void parseExtensions(String ext, JSONObject obj)
{    Matcher m = patternExtensions.matcher(ext);    int index = 0;    String key = null;    String value = null;    Map<String, String> labelMap = new HashMap<String, String>();    while (m.find()) {        if (key == null) {            key = ext.substring(index, m.start());            index = m.end();            if (!m.find()) {                break;            }        }        value = ext.substring(index, m.start());        index = m.end();        int v = value.lastIndexOf(" ");        if (v > 0) {            String temp = value.substring(0, v).trim();            if (key.endsWith("Label")) {                labelMap.put(key.substring(0, key.length() - 5), temp);            } else {                obj.put(key, temp);            }            key = value.substring(v).trim();        }    }    value = ext.substring(index);        if (key.endsWith("Label")) {        labelMap.put(key.substring(0, key.length() - 5), value);    } else {        obj.put(key, value);    }        for (Entry<String, String> label : labelMap.entrySet()) {        mutate(obj, label.getKey(), label.getValue());    }}
0
public List<JSONObject> parse(byte[] rawMessage)
{    List<JSONObject> messages = new ArrayList<>();    String cefString = new String(rawMessage, getReadCharset());    Matcher matcher = p.matcher(cefString);    while (matcher.find()) {        JSONObject obj = new JSONObject();        if (matcher.matches()) {                        obj.put("DeviceVendor", matcher.group("DeviceVendor"));            obj.put("DeviceProduct", matcher.group("DeviceProduct"));            obj.put("DeviceVersion", matcher.group("DeviceVersion"));            obj.put("DeviceEvent", matcher.group("DeviceEvent"));            obj.put("Name", matcher.group("Name"));            obj.put("Severity", standardizeSeverity(matcher.group("Severity")));        }        parseExtensions(matcher.group("extensions"), obj);                obj = mutate(obj, "dst", "ip_dst_addr");        obj = mutate(obj, "dpt", "ip_dst_port");        obj = convertToInt(obj, "ip_dst_port");        obj = mutate(obj, "src", "ip_src_addr");        obj = mutate(obj, "spt", "ip_src_port");        obj = convertToInt(obj, "ip_src_port");        obj = mutate(obj, "act", "deviceAction");                obj = mutate(obj, "app", "protocol");        obj.put("original_string", cefString);        if (obj.containsKey("rt")) {            String rt = (String) obj.get("rt");            try {                obj.put("timestamp", DateUtils.parseMultiformat(rt, DateUtils.DATE_FORMATS_CEF));            } catch (java.text.ParseException e) {                throw new IllegalStateException("rt field present in CEF but cannot be parsed", e);            }        } else {            String logTimestamp = matcher.group("syslogTime");            if (!(logTimestamp == null || logTimestamp.isEmpty())) {                try {                    obj.put("timestamp", SyslogUtils.parseTimestampToEpochMillis(logTimestamp, Clock.systemUTC()));                } catch (ParseException e) {                    throw new IllegalStateException("Cannot parse syslog timestamp", e);                }            } else {                obj.put("timestamp", System.currentTimeMillis());            }        }                String host = matcher.group("syslogHost");        if (!(host == null || host.isEmpty())) {            obj.put("host", host);        }        messages.add(obj);    }    return messages;}
1
private JSONObject convertToInt(JSONObject obj, String key)
{    if (obj.containsKey(key)) {        obj.put(key, Integer.valueOf((String) obj.get(key)));    }    return obj;}
0
private void headerBlock(String name, StringBuilder sb)
{    sb.append("(?<").append(name).append(">").append(HEADER_CAPTURE_PATTERN).append(")");}
0
private Integer standardizeSeverity(String severity)
{    if (severity.length() < 3) {                return Integer.valueOf(severity);    } else {        switch(severity) {            case "Low":                return 2;            case "Medium":                return 5;            case "High":                return 8;            case "Very-High":                return 10;            default:                return 0;        }    }}
0
public void configure(Map<String, Object> config)
{    setReadCharset(config);}
0
private static JSONObject mutate(JSONObject json, String oldKey, String newKey)
{    if (json.containsKey(oldKey)) {        json.put(newKey, json.remove(oldKey));    }    return json;}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);}
0
public void init()
{}
0
public List<JSONObject> parse(byte[] rawMessage)
{    String toParse;    List<JSONObject> messages = new ArrayList<>();    try {        toParse = new String(rawMessage, getReadCharset());                                Matcher m = syslogPriorityPattern.matcher(toParse);        String delimiter = "";        while (m.find()) {            delimiter = m.group();        }        if (!StringUtils.isBlank(delimiter)) {            String[] tokens = toParse.split(delimiter);            if (tokens.length > 1) {                toParse = delimiter + tokens[1];            }        }                JSONObject toReturn = parseMessage(toParse);        toReturn.put("timestamp", getTimeStamp(toParse));        messages.add(toReturn);        return messages;    } catch (Exception e) {        String message = "Unable to parse " + new String(rawMessage, StandardCharsets.UTF_8) + ": " + e.getMessage();                throw new IllegalStateException(message, e);    }}
1
private long getTimeStamp(String toParse) throws ParseException
{    long timestamp = 0;    String month;    String day;    String time;    Matcher tsMatcher = tsPattern.matcher(toParse);    if (tsMatcher.find()) {        month = tsMatcher.group(1);        day = tsMatcher.group(2);        time = tsMatcher.group(3);        timestamp = ParserUtils.convertToEpoch(month, day, time, true);    } else {            }    return timestamp;}
1
private JSONObject parseMessage(String toParse)
{    JSONObject toReturn = new JSONObject();    String[] messageTokens = toParse.split("\\s+");    String id = messageTokens[4];                    String[] tokens = id.split("\\.");    if (tokens.length == 2) {        String[] array = Arrays.copyOfRange(messageTokens, 1, messageTokens.length - 1);        String syslog = Joiner.on(" ").join(array);        Multimap<String, String> multiMap = formatMain(syslog);        for (String key : multiMap.keySet()) {            String value = Joiner.on(",").join(multiMap.get(key));            toReturn.put(key, value.trim());        }    }    toReturn.put("original_string", toParse);    final String ipSrcAddr = (String) toReturn.get("dvc");    final String ipSrcPort = (String) toReturn.get("src_port");    final String ipDstDddr = (String) toReturn.get("dst_ip");    final String ipDstPort = (String) toReturn.get("dst_port");    if (ipSrcAddr != null) {        toReturn.put("ip_src_addr", ipSrcAddr);    }    if (ipSrcPort != null) {        toReturn.put("ip_src_port", ipSrcPort);    }    if (ipDstDddr != null) {        toReturn.put("ip_dst_addr", ipDstDddr);    }    if (ipDstPort != null) {        toReturn.put("ip_dst_port", ipDstPort);    }    return toReturn;}
0
private Multimap<String, String> formatMain(String in)
{    Multimap<String, String> multiMap = ArrayListMultimap.create();    String input = in.replaceAll("cn3", "dst_port").replaceAll("cs5", "cncHost").replaceAll("proto", "protocol").replaceAll("rt=", "timestamp=").replaceAll("cs1", "malware").replaceAll("dst=", "dst_ip=").replaceAll("shost", "src_hostname").replaceAll("dmac", "dst_mac").replaceAll("smac", "src_mac").replaceAll("spt", "src_port").replaceAll("\\bsrc\\b", "src_ip");    String[] tokens = input.split("\\|");    if (tokens.length > 0) {        String message = tokens[tokens.length - 1];        Matcher m = nvPattern.matcher(message);        while (m.find()) {            String[] str = m.group().split("=");            multiMap.put(str[0], str[1]);        }    }    return multiMap;}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);}
0
public void init()
{}
0
public boolean validate(JSONObject message)
{    return true;}
0
public JSONObject parseObject() throws ParseException
{    JSONObject toReturn = object();    if (!ensureEOF())        throw new IllegalStateException("Expected EOF, but still had content to parse");    return toReturn;}
0
public final boolean ensureEOF() throws ParseException
{    switch(jj_nt.kind) {        case COMMA:            jj_consume_token(COMMA);            break;        default:            jj_la1[0] = jj_gen;            ;    }    jj_consume_token(0);    {        if (true)            return true;    }    throw new Error("Missing return statement in function");}
0
public final JSONObject innerMap() throws ParseException
{    final JSONObject json = new JSONObject();    String key;    Object value;    key = objectKey();    jj_consume_token(EQUALS);    value = value();    json.put(key, value);    key = null;    value = null;    label_1: while (true) {        switch(jj_nt.kind) {            case SLASH:                ;                break;            default:                jj_la1[1] = jj_gen;                break label_1;        }        jj_consume_token(SLASH);        jj_consume_token(COMMA);        key = objectKey();        jj_consume_token(EQUALS);        value = value();        json.put(key, value);        key = null;        value = null;    }    {        if (true)            return json;    }    throw new Error("Missing return statement in function");}
0
public final JSONObject object() throws ParseException
{    final JSONObject json = new JSONObject();    String key;    Object value;    key = objectKey();    jj_consume_token(EQUALS);    value = value();    json.put(key, value);    key = null;    value = null;    label_2: while (true) {        if (jj_2_1(2)) {            ;        } else {            break label_2;        }        jj_consume_token(COMMA);        key = objectKey();        jj_consume_token(EQUALS);        value = value();        json.put(key, value);        key = null;        value = null;    }    {        if (true)            return json;    }    throw new Error("Missing return statement in function");}
0
public final String objectKey() throws ParseException
{    String k;    k = string();        {        if (true)            return k.trim();    }    throw new Error("Missing return statement in function");}
0
public final Object value() throws ParseException
{    Object x;    String eof = "EOF";    Map m = null;    if (jj_2_2(2147483647)) {        x = nullValue();    } else if (jj_2_3(2147483647)) {        x = innerMap();    } else {        switch(jj_nt.kind) {            case TAG:                x = tagString();                break;            default:                jj_la1[2] = jj_gen;                if (jj_2_4(2147483647)) {                    x = blankValue();                } else if (jj_2_5(2147483647)) {                    x = braced_string();                } else if (jj_2_6(2)) {                    x = string();                } else {                    jj_consume_token(-1);                    throw new ParseException();                }        }    }                {        if (true)            return x;    }    throw new Error("Missing return statement in function");}
0
public final String nullValue() throws ParseException
{    {        if (true)            return null;    }    throw new Error("Missing return statement in function");}
0
public final String tagString() throws ParseException
{    String output = "(tag=0)";    jj_consume_token(TAG);    jj_consume_token(STRING_BODY);    {        if (true)            return output + token.image;    }    throw new Error("Missing return statement in function");}
0
public final String blankValue() throws ParseException
{    {        if (true)            return null;    }    throw new Error("Missing return statement in function");}
0
public final String string() throws ParseException
{    String s;    jj_consume_token(STRING_BODY);    {        if (true)            return token.image.trim();    }    throw new Error("Missing return statement in function");}
0
public final String braced_string() throws ParseException
{    String s;    jj_consume_token(BRACED_STRING);        s = token.image;    jj_consume_token(COMMA);    {        if (true)            return s.trim();    }    throw new Error("Missing return statement in function");}
0
private boolean jj_2_1(int xla)
{    jj_la = xla;    jj_lastpos = jj_scanpos = token;    try {        return !jj_3_1();    } catch (LookaheadSuccess ls) {        return true;    } finally {        jj_save(0, xla);    }}
0
private boolean jj_2_2(int xla)
{    jj_la = xla;    jj_lastpos = jj_scanpos = token;    try {        return !jj_3_2();    } catch (LookaheadSuccess ls) {        return true;    } finally {        jj_save(1, xla);    }}
0
private boolean jj_2_3(int xla)
{    jj_la = xla;    jj_lastpos = jj_scanpos = token;    try {        return !jj_3_3();    } catch (LookaheadSuccess ls) {        return true;    } finally {        jj_save(2, xla);    }}
0
private boolean jj_2_4(int xla)
{    jj_la = xla;    jj_lastpos = jj_scanpos = token;    try {        return !jj_3_4();    } catch (LookaheadSuccess ls) {        return true;    } finally {        jj_save(3, xla);    }}
0
private boolean jj_2_5(int xla)
{    jj_la = xla;    jj_lastpos = jj_scanpos = token;    try {        return !jj_3_5();    } catch (LookaheadSuccess ls) {        return true;    } finally {        jj_save(4, xla);    }}
0
private boolean jj_2_6(int xla)
{    jj_la = xla;    jj_lastpos = jj_scanpos = token;    try {        return !jj_3_6();    } catch (LookaheadSuccess ls) {        return true;    } finally {        jj_save(5, xla);    }}
0
private boolean jj_3_5()
{    if (jj_3R_5())        return true;    return false;}
0
private boolean jj_3_4()
{    if (jj_scan_token(0))        return true;    return false;}
0
private boolean jj_3R_5()
{    if (jj_scan_token(BRACED_STRING))        return true;    if (jj_scan_token(COMMA))        return true;    return false;}
0
private boolean jj_3_3()
{    if (jj_3R_4())        return true;    return false;}
0
private boolean jj_3R_4()
{    if (jj_3R_3())        return true;    if (jj_scan_token(EQUALS))        return true;    if (jj_3R_7())        return true;    Token xsp;    while (true) {        xsp = jj_scanpos;        if (jj_3R_8()) {            jj_scanpos = xsp;            break;        }    }    return false;}
0
private boolean jj_3_2()
{    if (jj_scan_token(COMMA))        return true;    return false;}
0
private boolean jj_3_6()
{    if (jj_3R_6())        return true;    return false;}
0
private boolean jj_3_1()
{    if (jj_scan_token(COMMA))        return true;    if (jj_3R_3())        return true;    return false;}
0
private boolean jj_3R_13()
{    if (jj_3R_5())        return true;    return false;}
0
private boolean jj_3R_12()
{    if (jj_3R_16())        return true;    return false;}
0
private boolean jj_3R_11()
{    if (jj_3R_15())        return true;    return false;}
0
private boolean jj_3R_6()
{    if (jj_scan_token(STRING_BODY))        return true;    return false;}
0
private boolean jj_3R_10()
{    if (jj_3R_4())        return true;    return false;}
0
private boolean jj_3R_9()
{    if (jj_3R_14())        return true;    return false;}
0
private boolean jj_3R_7()
{    Token xsp;    xsp = jj_scanpos;    if (jj_3R_9()) {        jj_scanpos = xsp;        if (jj_3R_10()) {            jj_scanpos = xsp;            if (jj_3R_11()) {                jj_scanpos = xsp;                if (jj_3R_12()) {                    jj_scanpos = xsp;                    if (jj_3R_13()) {                        jj_scanpos = xsp;                        if (jj_3_6())                            return true;                    }                }            }        }    }    return false;}
0
private boolean jj_3R_16()
{    return false;}
0
private boolean jj_3R_15()
{    if (jj_scan_token(TAG))        return true;    if (jj_scan_token(STRING_BODY))        return true;    return false;}
0
private boolean jj_3R_3()
{    if (jj_3R_6())        return true;    return false;}
0
private boolean jj_3R_8()
{    if (jj_scan_token(SLASH))        return true;    if (jj_scan_token(COMMA))        return true;    if (jj_3R_3())        return true;    if (jj_scan_token(EQUALS))        return true;    if (jj_3R_7())        return true;    return false;}
0
private boolean jj_3R_14()
{    return false;}
0
private static void jj_la1_init_0()
{    jj_la1_0 = new int[] { 0x20, 0x80, 0x100 };}
0
public void ReInit(java.io.InputStream stream)
{    ReInit(stream, null);}
0
public void ReInit(java.io.InputStream stream, String encoding)
{    try {        jj_input_stream.ReInit(stream, encoding, 1, 1);    } catch (java.io.UnsupportedEncodingException e) {        throw new RuntimeException(e);    }    token_source.ReInit(jj_input_stream);    token = new Token();    token.next = jj_nt = token_source.getNextToken();    jj_gen = 0;    for (int i = 0; i < 3; i++) jj_la1[i] = -1;    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();}
0
public void ReInit(java.io.Reader stream)
{    jj_input_stream.ReInit(stream, 1, 1);    token_source.ReInit(jj_input_stream);    token = new Token();    token.next = jj_nt = token_source.getNextToken();    jj_gen = 0;    for (int i = 0; i < 3; i++) jj_la1[i] = -1;    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();}
0
public void ReInit(ISEParserTokenManager tm)
{    token_source = tm;    token = new Token();    token.next = jj_nt = token_source.getNextToken();    jj_gen = 0;    for (int i = 0; i < 3; i++) jj_la1[i] = -1;    for (int i = 0; i < jj_2_rtns.length; i++) jj_2_rtns[i] = new JJCalls();}
0
private Token jj_consume_token(int kind) throws ParseException
{    Token oldToken = token;    if ((token = jj_nt).next != null)        jj_nt = jj_nt.next;    else        jj_nt = jj_nt.next = token_source.getNextToken();    if (token.kind == kind) {        jj_gen++;        if (++jj_gc > 100) {            jj_gc = 0;            for (int i = 0; i < jj_2_rtns.length; i++) {                JJCalls c = jj_2_rtns[i];                while (c != null) {                    if (c.gen < jj_gen)                        c.first = null;                    c = c.next;                }            }        }        return token;    }    jj_nt = token;    token = oldToken;    jj_kind = kind;    throw generateParseException();}
0
private boolean jj_scan_token(int kind)
{    if (jj_scanpos == jj_lastpos) {        jj_la--;        if (jj_scanpos.next == null) {            jj_lastpos = jj_scanpos = jj_scanpos.next = token_source.getNextToken();        } else {            jj_lastpos = jj_scanpos = jj_scanpos.next;        }    } else {        jj_scanpos = jj_scanpos.next;    }    if (jj_rescan) {        int i = 0;        Token tok = token;        while (tok != null && tok != jj_scanpos) {            i++;            tok = tok.next;        }        if (tok != null)            jj_add_error_token(kind, i);    }    if (jj_scanpos.kind != kind)        return true;    if (jj_la == 0 && jj_scanpos == jj_lastpos)        throw jj_ls;    return false;}
0
public final Token getNextToken()
{    if ((token = jj_nt).next != null)        jj_nt = jj_nt.next;    else        jj_nt = jj_nt.next = token_source.getNextToken();    jj_gen++;    return token;}
0
public final Token getToken(int index)
{    Token t = token;    for (int i = 0; i < index; i++) {        if (t.next != null)            t = t.next;        else            t = t.next = token_source.getNextToken();    }    return t;}
0
private void jj_add_error_token(int kind, int pos)
{    if (pos >= 100)        return;    if (pos == jj_endpos + 1) {        jj_lasttokens[jj_endpos++] = kind;    } else if (jj_endpos != 0) {        jj_expentry = new int[jj_endpos];        for (int i = 0; i < jj_endpos; i++) {            jj_expentry[i] = jj_lasttokens[i];        }        jj_entries_loop: for (java.util.Iterator<?> it = jj_expentries.iterator(); it.hasNext(); ) {            int[] oldentry = (int[]) (it.next());            if (oldentry.length == jj_expentry.length) {                for (int i = 0; i < jj_expentry.length; i++) {                    if (oldentry[i] != jj_expentry[i]) {                        continue jj_entries_loop;                    }                }                jj_expentries.add(jj_expentry);                break jj_entries_loop;            }        }        if (pos != 0)            jj_lasttokens[(jj_endpos = pos) - 1] = kind;    }}
0
public ParseException generateParseException()
{    jj_expentries.clear();    boolean[] la1tokens = new boolean[11];    if (jj_kind >= 0) {        la1tokens[jj_kind] = true;        jj_kind = -1;    }    for (int i = 0; i < 3; i++) {        if (jj_la1[i] == jj_gen) {            for (int j = 0; j < 32; j++) {                if ((jj_la1_0[i] & (1 << j)) != 0) {                    la1tokens[j] = true;                }            }        }    }    for (int i = 0; i < 11; i++) {        if (la1tokens[i]) {            jj_expentry = new int[1];            jj_expentry[0] = i;            jj_expentries.add(jj_expentry);        }    }    jj_endpos = 0;    jj_rescan_token();    jj_add_error_token(0, 0);    int[][] exptokseq = new int[jj_expentries.size()][];    for (int i = 0; i < jj_expentries.size(); i++) {        exptokseq[i] = jj_expentries.get(i);    }    return new ParseException(token, exptokseq, tokenImage);}
0
public final void enable_tracing()
{}
0
public final void disable_tracing()
{}
0
private void jj_rescan_token()
{    jj_rescan = true;    for (int i = 0; i < 6; i++) {        try {            JJCalls p = jj_2_rtns[i];            do {                if (p.gen > jj_gen) {                    jj_la = p.arg;                    jj_lastpos = jj_scanpos = p.first;                    switch(i) {                        case 0:                            jj_3_1();                            break;                        case 1:                            jj_3_2();                            break;                        case 2:                            jj_3_3();                            break;                        case 3:                            jj_3_4();                            break;                        case 4:                            jj_3_5();                            break;                        case 5:                            jj_3_6();                            break;                    }                }                p = p.next;            } while (p != null);        } catch (LookaheadSuccess ls) {        }    }    jj_rescan = false;}
0
private void jj_save(int index, int xla)
{    JJCalls p = jj_2_rtns[index];    while (p.gen > jj_gen) {        if (p.next == null) {            p = p.next = new JJCalls();            break;        }        p = p.next;    }    p.gen = jj_gen + xla - jj_la;    p.first = token;    p.arg = xla;}
0
public void setDebugStream(java.io.PrintStream ds)
{    debugStream = ds;}
0
private final int jjStopStringLiteralDfa_0(int pos, long active0)
{    switch(pos) {        case 0:            if ((active0 & 0x100L) != 0L) {                jjmatchedKind = 9;                return 18;            }            if ((active0 & 0x80L) != 0L)                return 6;            return -1;        case 1:            if ((active0 & 0x100L) != 0L) {                jjmatchedKind = 9;                jjmatchedPos = 1;                return 18;            }            return -1;        case 2:            if ((active0 & 0x100L) != 0L) {                jjmatchedKind = 9;                jjmatchedPos = 2;                return 18;            }            return -1;        case 3:            if ((active0 & 0x100L) != 0L) {                jjmatchedKind = 9;                jjmatchedPos = 3;                return 18;            }            return -1;        case 4:            if ((active0 & 0x100L) != 0L) {                if (jjmatchedPos < 3) {                    jjmatchedKind = 9;                    jjmatchedPos = 3;                }                return -1;            }            return -1;        case 5:            if ((active0 & 0x100L) != 0L) {                if (jjmatchedPos < 3) {                    jjmatchedKind = 9;                    jjmatchedPos = 3;                }                return -1;            }            return -1;        default:            return -1;    }}
0
private final int jjStartNfa_0(int pos, long active0)
{    return jjMoveNfa_0(jjStopStringLiteralDfa_0(pos, active0), pos + 1);}
0
private int jjStopAtPos(int pos, int kind)
{    jjmatchedKind = kind;    jjmatchedPos = pos;    return pos + 1;}
0
private int jjMoveStringLiteralDfa0_0()
{    switch(curChar) {        case 40:            return jjMoveStringLiteralDfa1_0(0x100L);        case 44:            return jjStopAtPos(0, 5);        case 61:            return jjStopAtPos(0, 6);        case 92:            return jjStartNfaWithStates_0(0, 7, 6);        default:            return jjMoveNfa_0(0, 0);    }}
0
private int jjMoveStringLiteralDfa1_0(long active0)
{    try {        curChar = input_stream.readChar();    } catch (java.io.IOException e) {        jjStopStringLiteralDfa_0(0, active0);        return 1;    }    switch(curChar) {        case 84:        case 116:            return jjMoveStringLiteralDfa2_0(active0, 0x100L);        default:            break;    }    return jjStartNfa_0(0, active0);}
0
private int jjMoveStringLiteralDfa2_0(long old0, long active0)
{    if (((active0 &= old0)) == 0L)        return jjStartNfa_0(0, old0);    try {        curChar = input_stream.readChar();    } catch (java.io.IOException e) {        jjStopStringLiteralDfa_0(1, active0);        return 2;    }    switch(curChar) {        case 65:        case 97:            return jjMoveStringLiteralDfa3_0(active0, 0x100L);        default:            break;    }    return jjStartNfa_0(1, active0);}
0
private int jjMoveStringLiteralDfa3_0(long old0, long active0)
{    if (((active0 &= old0)) == 0L)        return jjStartNfa_0(1, old0);    try {        curChar = input_stream.readChar();    } catch (java.io.IOException e) {        jjStopStringLiteralDfa_0(2, active0);        return 3;    }    switch(curChar) {        case 71:        case 103:            return jjMoveStringLiteralDfa4_0(active0, 0x100L);        default:            break;    }    return jjStartNfa_0(2, active0);}
0
private int jjMoveStringLiteralDfa4_0(long old0, long active0)
{    if (((active0 &= old0)) == 0L)        return jjStartNfa_0(2, old0);    try {        curChar = input_stream.readChar();    } catch (java.io.IOException e) {        jjStopStringLiteralDfa_0(3, active0);        return 4;    }    switch(curChar) {        case 61:            return jjMoveStringLiteralDfa5_0(active0, 0x100L);        default:            break;    }    return jjStartNfa_0(3, active0);}
0
private int jjMoveStringLiteralDfa5_0(long old0, long active0)
{    if (((active0 &= old0)) == 0L)        return jjStartNfa_0(3, old0);    try {        curChar = input_stream.readChar();    } catch (java.io.IOException e) {        jjStopStringLiteralDfa_0(4, active0);        return 5;    }    switch(curChar) {        case 48:            return jjMoveStringLiteralDfa6_0(active0, 0x100L);        default:            break;    }    return jjStartNfa_0(4, active0);}
0
private int jjMoveStringLiteralDfa6_0(long old0, long active0)
{    if (((active0 &= old0)) == 0L)        return jjStartNfa_0(4, old0);    try {        curChar = input_stream.readChar();    } catch (java.io.IOException e) {        jjStopStringLiteralDfa_0(5, active0);        return 6;    }    switch(curChar) {        case 41:            if ((active0 & 0x100L) != 0L)                return jjStopAtPos(6, 8);            break;        default:            break;    }    return jjStartNfa_0(5, active0);}
0
private int jjStartNfaWithStates_0(int pos, int kind, int state)
{    jjmatchedKind = kind;    jjmatchedPos = pos;    try {        curChar = input_stream.readChar();    } catch (java.io.IOException e) {        return pos + 1;    }    return jjMoveNfa_0(state, pos + 1);}
0
private int jjMoveNfa_0(int startState, int curPos)
{    int startsAt = 0;    jjnewStateCnt = 18;    int i = 1;    jjstateSet[0] = startState;    int kind = 0x7fffffff;    for (; ; ) {        if (++jjround == 0x7fffffff)            ReInitRounds();        if (curChar < 64) {            long l = 1L << curChar;            do {                switch(jjstateSet[--i]) {                    case 18:                    case 4:                        if ((0xdfffeffbffffc9ffL & l) == 0L)                            break;                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        break;                    case 0:                        if ((0xdfffeffbffffc9ffL & l) != 0L) {                            if (kind > 9)                                kind = 9;                            jjCheckNAddTwoStates(4, 5);                        } else if ((0x3400L & l) != 0L) {                            if (kind > 4)                                kind = 4;                        }                        if (curChar == 47)                            jjAddStates(0, 1);                        else if (curChar == 35)                            jjCheckNAddTwoStates(1, 2);                        break;                    case 6:                        if ((0xdfffeffbffffc9ffL & l) != 0L) {                            if (kind > 9)                                kind = 9;                            jjCheckNAddTwoStates(4, 5);                        }                        if ((0x900400000000L & l) != 0L) {                            if (kind > 9)                                kind = 9;                            jjCheckNAddTwoStates(4, 5);                        }                        break;                    case 1:                        if ((0xffffffffffffcbffL & l) != 0L)                            jjCheckNAddTwoStates(1, 2);                        break;                    case 2:                        if ((0x3400L & l) != 0L && kind > 3)                            kind = 3;                        break;                    case 3:                        if ((0x3400L & l) != 0L && kind > 4)                            kind = 4;                        break;                    case 8:                        jjAddStates(2, 3);                        break;                    case 10:                        if (curChar == 47)                            jjAddStates(0, 1);                        break;                    case 11:                        if (curChar == 47)                            jjCheckNAddTwoStates(12, 13);                        break;                    case 12:                        if ((0xffffffffffffcbffL & l) != 0L)                            jjCheckNAddTwoStates(12, 13);                        break;                    case 13:                        if ((0x3400L & l) != 0L && kind > 1)                            kind = 1;                        break;                    case 14:                        if (curChar == 42)                            jjCheckNAddTwoStates(15, 17);                        break;                    case 15:                        jjCheckNAddTwoStates(15, 17);                        break;                    case 16:                        if (curChar == 47 && kind > 2)                            kind = 2;                        break;                    case 17:                        if (curChar == 42)                            jjstateSet[jjnewStateCnt++] = 16;                        break;                    default:                        break;                }            } while (i != startsAt);        } else if (curChar < 128) {            long l = 1L << (curChar & 077);            do {                switch(jjstateSet[--i]) {                    case 18:                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        if (curChar == 92)                            jjstateSet[jjnewStateCnt++] = 6;                        break;                    case 0:                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        if (curChar == 123)                            jjCheckNAdd(8);                        else if (curChar == 92)                            jjstateSet[jjnewStateCnt++] = 6;                        break;                    case 6:                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        if ((0x14404410144044L & l) != 0L) {                            if (kind > 9)                                kind = 9;                            jjCheckNAddTwoStates(4, 5);                        }                        if (curChar == 92)                            jjstateSet[jjnewStateCnt++] = 6;                        break;                    case 1:                        jjAddStates(4, 5);                        break;                    case 4:                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        break;                    case 5:                        if (curChar == 92)                            jjstateSet[jjnewStateCnt++] = 6;                        break;                    case 7:                        if (curChar == 123)                            jjCheckNAdd(8);                        break;                    case 8:                        if ((0xd7ffffffffffffffL & l) != 0L)                            jjCheckNAddTwoStates(8, 9);                        break;                    case 9:                        if (curChar == 125 && kind > 10)                            kind = 10;                        break;                    case 12:                        jjAddStates(6, 7);                        break;                    case 15:                        jjAddStates(8, 9);                        break;                    default:                        break;                }            } while (i != startsAt);        } else {            int hiByte = (int) (curChar >> 8);            int i1 = hiByte >> 6;            long l1 = 1L << (hiByte & 077);            int i2 = (curChar & 0xff) >> 6;            long l2 = 1L << (curChar & 077);            do {                switch(jjstateSet[--i]) {                    case 18:                    case 4:                        if (!jjCanMove_0(hiByte, i1, i2, l1, l2))                            break;                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        break;                    case 0:                        if (!jjCanMove_0(hiByte, i1, i2, l1, l2))                            break;                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        break;                    case 6:                        if (!jjCanMove_0(hiByte, i1, i2, l1, l2))                            break;                        if (kind > 9)                            kind = 9;                        jjCheckNAddTwoStates(4, 5);                        break;                    case 1:                        if (jjCanMove_0(hiByte, i1, i2, l1, l2))                            jjAddStates(4, 5);                        break;                    case 8:                        if (jjCanMove_0(hiByte, i1, i2, l1, l2))                            jjAddStates(2, 3);                        break;                    case 12:                        if (jjCanMove_0(hiByte, i1, i2, l1, l2))                            jjAddStates(6, 7);                        break;                    case 15:                        if (jjCanMove_0(hiByte, i1, i2, l1, l2))                            jjAddStates(8, 9);                        break;                    default:                        break;                }            } while (i != startsAt);        }        if (kind != 0x7fffffff) {            jjmatchedKind = kind;            jjmatchedPos = curPos;            kind = 0x7fffffff;        }        ++curPos;        if ((i = jjnewStateCnt) == (startsAt = 18 - (jjnewStateCnt = startsAt)))            return curPos;        try {            curChar = input_stream.readChar();        } catch (java.io.IOException e) {            return curPos;        }    }}
0
private static final boolean jjCanMove_0(int hiByte, int i1, int i2, long l1, long l2)
{    switch(hiByte) {        case 0:            return ((jjbitVec2[i2] & l2) != 0L);        default:            if ((jjbitVec0[i1] & l1) != 0L)                return true;            return false;    }}
0
public void ReInit(JavaCharStream stream)
{    jjmatchedPos = jjnewStateCnt = 0;    curLexState = defaultLexState;    input_stream = stream;    ReInitRounds();}
0
private void ReInitRounds()
{    int i;    jjround = 0x80000001;    for (i = 18; i-- > 0; ) jjrounds[i] = 0x80000000;}
0
public void ReInit(JavaCharStream stream, int lexState)
{    ReInit(stream);    SwitchTo(lexState);}
0
public void SwitchTo(int lexState)
{    if (lexState >= 1 || lexState < 0)        throw new TokenMgrError("Error: Ignoring invalid lexical state : " + lexState + ". State unchanged.", TokenMgrError.INVALID_LEXICAL_STATE);    else        curLexState = lexState;}
0
protected Token jjFillToken()
{    final Token t;    final String curTokenImage;    final int beginLine;    final int endLine;    final int beginColumn;    final int endColumn;    String im = jjstrLiteralImages[jjmatchedKind];    curTokenImage = (im == null) ? input_stream.GetImage() : im;    beginLine = input_stream.getBeginLine();    beginColumn = input_stream.getBeginColumn();    endLine = input_stream.getEndLine();    endColumn = input_stream.getEndColumn();    t = Token.newToken(jjmatchedKind, curTokenImage);    t.beginLine = beginLine;    t.endLine = endLine;    t.beginColumn = beginColumn;    t.endColumn = endColumn;    return t;}
0
public Token getNextToken()
{    Token matchedToken;    int curPos = 0;    EOFLoop: for (; ; ) {        try {            curChar = input_stream.BeginToken();        } catch (java.io.IOException e) {            jjmatchedKind = 0;            matchedToken = jjFillToken();            return matchedToken;        }        jjmatchedKind = 0x7fffffff;        jjmatchedPos = 0;        curPos = jjMoveStringLiteralDfa0_0();        if (jjmatchedKind != 0x7fffffff) {            if (jjmatchedPos + 1 < curPos)                input_stream.backup(curPos - jjmatchedPos - 1);            if ((jjtoToken[jjmatchedKind >> 6] & (1L << (jjmatchedKind & 077))) != 0L) {                matchedToken = jjFillToken();                return matchedToken;            } else {                continue EOFLoop;            }        }        int error_line = input_stream.getEndLine();        int error_column = input_stream.getEndColumn();        String error_after = null;        boolean EOFSeen = false;        try {            input_stream.readChar();            input_stream.backup(1);        } catch (java.io.IOException e1) {            EOFSeen = true;            error_after = curPos <= 1 ? "" : input_stream.GetImage();            if (curChar == '\n' || curChar == '\r') {                error_line++;                error_column = 0;            } else                error_column++;        }        if (!EOFSeen) {            input_stream.backup(1);            error_after = curPos <= 1 ? "" : input_stream.GetImage();        }        throw new TokenMgrError(EOFSeen, curLexState, error_line, error_column, error_after, curChar, TokenMgrError.LEXICAL_ERROR);    }}
0
private void jjCheckNAdd(int state)
{    if (jjrounds[state] != jjround) {        jjstateSet[jjnewStateCnt++] = state;        jjrounds[state] = jjround;    }}
0
private void jjAddStates(int start, int end)
{    do {        jjstateSet[jjnewStateCnt++] = jjnextStates[start];    } while (start++ != end);}
0
private void jjCheckNAddTwoStates(int state1, int state2)
{    jjCheckNAdd(state1);    jjCheckNAdd(state2);}
0
 static final int hexval(char c) throws java.io.IOException
{    switch(c) {        case '0':            return 0;        case '1':            return 1;        case '2':            return 2;        case '3':            return 3;        case '4':            return 4;        case '5':            return 5;        case '6':            return 6;        case '7':            return 7;        case '8':            return 8;        case '9':            return 9;        case 'a':        case 'A':            return 10;        case 'b':        case 'B':            return 11;        case 'c':        case 'C':            return 12;        case 'd':        case 'D':            return 13;        case 'e':        case 'E':            return 14;        case 'f':        case 'F':            return 15;    }        throw new java.io.IOException();}
0
protected void setTabSize(int i)
{    tabSize = i;}
0
protected int getTabSize(int i)
{    return tabSize;}
0
protected void ExpandBuff(boolean wrapAround)
{    char[] newbuffer = new char[bufsize + 2048];    int[] newbufline = new int[bufsize + 2048];    int[] newbufcolumn = new int[bufsize + 2048];    try {        if (wrapAround) {            System.arraycopy(buffer, tokenBegin, newbuffer, 0, bufsize - tokenBegin);            System.arraycopy(buffer, 0, newbuffer, bufsize - tokenBegin, bufpos);            buffer = newbuffer;            System.arraycopy(bufline, tokenBegin, newbufline, 0, bufsize - tokenBegin);            System.arraycopy(bufline, 0, newbufline, bufsize - tokenBegin, bufpos);            bufline = newbufline;            System.arraycopy(bufcolumn, tokenBegin, newbufcolumn, 0, bufsize - tokenBegin);            System.arraycopy(bufcolumn, 0, newbufcolumn, bufsize - tokenBegin, bufpos);            bufcolumn = newbufcolumn;            bufpos += (bufsize - tokenBegin);        } else {            System.arraycopy(buffer, tokenBegin, newbuffer, 0, bufsize - tokenBegin);            buffer = newbuffer;            System.arraycopy(bufline, tokenBegin, newbufline, 0, bufsize - tokenBegin);            bufline = newbufline;            System.arraycopy(bufcolumn, tokenBegin, newbufcolumn, 0, bufsize - tokenBegin);            bufcolumn = newbufcolumn;            bufpos -= tokenBegin;        }    } catch (Throwable t) {        throw new Error(t.getMessage());    }    available = (bufsize += 2048);    tokenBegin = 0;}
0
protected void FillBuff() throws java.io.IOException
{    int i;    if (maxNextCharInd == 4096)        maxNextCharInd = nextCharInd = 0;    try {        if ((i = inputStream.read(nextCharBuf, maxNextCharInd, 4096 - maxNextCharInd)) == -1) {            inputStream.close();            throw new java.io.IOException();        } else            maxNextCharInd += i;        return;    } catch (java.io.IOException e) {        if (bufpos != 0) {            --bufpos;            backup(0);        } else {            bufline[bufpos] = line;            bufcolumn[bufpos] = column;        }        throw e;    }}
0
protected char ReadByte() throws java.io.IOException
{    if (++nextCharInd >= maxNextCharInd)        FillBuff();    return nextCharBuf[nextCharInd];}
0
public char BeginToken() throws java.io.IOException
{    if (inBuf > 0) {        --inBuf;        if (++bufpos == bufsize)            bufpos = 0;        tokenBegin = bufpos;        return buffer[bufpos];    }    tokenBegin = 0;    bufpos = -1;    return readChar();}
0
protected void AdjustBuffSize()
{    if (available == bufsize) {        if (tokenBegin > 2048) {            bufpos = 0;            available = tokenBegin;        } else            ExpandBuff(false);    } else if (available > tokenBegin)        available = bufsize;    else if ((tokenBegin - available) < 2048)        ExpandBuff(true);    else        available = tokenBegin;}
0
protected void UpdateLineColumn(char c)
{    column++;    if (prevCharIsLF) {        prevCharIsLF = false;        line += (column = 1);    } else if (prevCharIsCR) {        prevCharIsCR = false;        if (c == '\n') {            prevCharIsLF = true;        } else            line += (column = 1);    }    switch(c) {        case '\r':            prevCharIsCR = true;            break;        case '\n':            prevCharIsLF = true;            break;        case '\t':            column--;            column += (tabSize - (column % tabSize));            break;        default:            break;    }    bufline[bufpos] = line;    bufcolumn[bufpos] = column;}
0
public char readChar() throws java.io.IOException
{    if (inBuf > 0) {        --inBuf;        if (++bufpos == bufsize)            bufpos = 0;        return buffer[bufpos];    }    char c;    if (++bufpos == available)        AdjustBuffSize();    if ((buffer[bufpos] = c = ReadByte()) == '\\') {        UpdateLineColumn(c);        int backSlashCnt = 1;        for (; ; )         {            if (++bufpos == available)                AdjustBuffSize();            try {                if ((buffer[bufpos] = c = ReadByte()) != '\\') {                    UpdateLineColumn(c);                                        if ((c == 'u') && ((backSlashCnt & 1) == 1)) {                        if (--bufpos < 0)                            bufpos = bufsize - 1;                        break;                    }                    backup(backSlashCnt);                    return '\\';                }            } catch (java.io.IOException e) {                                if (backSlashCnt > 1)                    backup(backSlashCnt - 1);                return '\\';            }            UpdateLineColumn(c);            backSlashCnt++;        }                try {            while ((c = ReadByte()) == 'u') ++column;            buffer[bufpos] = c = (char) (hexval(c) << 12 | hexval(ReadByte()) << 8 | hexval(ReadByte()) << 4 | hexval(ReadByte()));            column += 4;        } catch (java.io.IOException e) {            throw new Error("Invalid escape character at line " + line + " column " + column + ".");        }        if (backSlashCnt == 1)            return c;        else {            backup(backSlashCnt - 1);            return '\\';        }    } else {        UpdateLineColumn(c);        return c;    }}
0
public int getColumn()
{    return bufcolumn[bufpos];}
0
public int getLine()
{    return bufline[bufpos];}
0
public int getEndColumn()
{    return bufcolumn[bufpos];}
0
public int getEndLine()
{    return bufline[bufpos];}
0
public int getBeginColumn()
{    return bufcolumn[tokenBegin];}
0
public int getBeginLine()
{    return bufline[tokenBegin];}
0
public void backup(int amount)
{    inBuf += amount;    if ((bufpos -= amount) < 0)        bufpos += bufsize;}
0
public void ReInit(java.io.Reader dstream, int startline, int startcolumn, int buffersize)
{    inputStream = dstream;    line = startline;    column = startcolumn - 1;    if (buffer == null || buffersize != buffer.length) {        available = bufsize = buffersize;        buffer = new char[buffersize];        bufline = new int[buffersize];        bufcolumn = new int[buffersize];        nextCharBuf = new char[4096];    }    prevCharIsLF = prevCharIsCR = false;    tokenBegin = inBuf = maxNextCharInd = 0;    nextCharInd = bufpos = -1;}
0
public void ReInit(java.io.Reader dstream, int startline, int startcolumn)
{    ReInit(dstream, startline, startcolumn, 4096);}
0
public void ReInit(java.io.Reader dstream)
{    ReInit(dstream, 1, 1, 4096);}
0
public void ReInit(java.io.InputStream dstream, String encoding, int startline, int startcolumn, int buffersize) throws java.io.UnsupportedEncodingException
{    ReInit(encoding == null ? new java.io.InputStreamReader(dstream, StandardCharsets.UTF_8) : new java.io.InputStreamReader(dstream, encoding), startline, startcolumn, buffersize);}
0
public void ReInit(java.io.InputStream dstream, int startline, int startcolumn, int buffersize)
{    ReInit(new java.io.InputStreamReader(dstream, StandardCharsets.UTF_8), startline, startcolumn, buffersize);}
0
public void ReInit(java.io.InputStream dstream, String encoding, int startline, int startcolumn) throws java.io.UnsupportedEncodingException
{    ReInit(dstream, encoding, startline, startcolumn, 4096);}
0
public void ReInit(java.io.InputStream dstream, int startline, int startcolumn)
{    ReInit(dstream, startline, startcolumn, 4096);}
0
public void ReInit(java.io.InputStream dstream, String encoding) throws java.io.UnsupportedEncodingException
{    ReInit(dstream, encoding, 1, 1, 4096);}
0
public void ReInit(java.io.InputStream dstream)
{    ReInit(dstream, 1, 1, 4096);}
0
public String GetImage()
{    if (bufpos >= tokenBegin)        return new String(buffer, tokenBegin, bufpos - tokenBegin + 1);    else        return new String(buffer, tokenBegin, bufsize - tokenBegin) + new String(buffer, 0, bufpos + 1);}
0
public char[] GetSuffix(int len)
{    char[] ret = new char[len];    if ((bufpos + 1) >= len)        System.arraycopy(buffer, bufpos - len + 1, ret, 0, len);    else {        System.arraycopy(buffer, bufsize - (len - bufpos - 1), ret, 0, len - bufpos - 1);        System.arraycopy(buffer, 0, ret, len - bufpos - 1, bufpos + 1);    }    return ret;}
0
public void Done()
{    nextCharBuf = null;    buffer = null;    bufline = null;    bufcolumn = null;}
0
public void adjustBeginLineColumn(int newLine, int newCol)
{    int start = tokenBegin;    int len;    if (bufpos >= tokenBegin) {        len = bufpos - tokenBegin + inBuf + 1;    } else {        len = bufsize - tokenBegin + bufpos + 1 + inBuf;    }    int i = 0, j = 0, k = 0;    int nextColDiff = 0, columnDiff = 0;    while (i < len && bufline[j = start % bufsize] == bufline[k = ++start % bufsize]) {        bufline[j] = newLine;        nextColDiff = columnDiff + bufcolumn[k] - bufcolumn[j];        bufcolumn[j] = newCol + columnDiff;        columnDiff = nextColDiff;        i++;    }    if (i < len) {        bufline[j] = newLine++;        bufcolumn[j] = newCol + columnDiff;        while (i++ < len) {            if (bufline[j = start % bufsize] != bufline[++start % bufsize])                bufline[j] = newLine++;            else                bufline[j] = newLine;        }    }    line = bufline[j];    column = bufcolumn[j];}
0
private static String initialise(Token currentToken, int[][] expectedTokenSequences, String[] tokenImage)
{    String eol = System.getProperty("line.separator", "\n");    StringBuffer expected = new StringBuffer();    int maxSize = 0;    for (int i = 0; i < expectedTokenSequences.length; i++) {        if (maxSize < expectedTokenSequences[i].length) {            maxSize = expectedTokenSequences[i].length;        }        for (int j = 0; j < expectedTokenSequences[i].length; j++) {            expected.append(tokenImage[expectedTokenSequences[i][j]]).append(' ');        }        if (expectedTokenSequences[i][expectedTokenSequences[i].length - 1] != 0) {            expected.append("...");        }        expected.append(eol).append("    ");    }    String retval = "Encountered \"";    Token tok = currentToken.next;    for (int i = 0; i < maxSize; i++) {        if (i != 0)            retval += " ";        if (tok.kind == 0) {            retval += tokenImage[0];            break;        }        retval += " " + tokenImage[tok.kind];        retval += " \"";        retval += add_escapes(tok.image);        retval += " \"";        tok = tok.next;    }    retval += "\" at line " + currentToken.next.beginLine + ", column " + currentToken.next.beginColumn;    retval += "." + eol;    if (expectedTokenSequences.length == 1) {        retval += "Was expecting:" + eol + "    ";    } else {        retval += "Was expecting one of:" + eol + "    ";    }    retval += expected.toString();    return retval;}
0
 static String add_escapes(String str)
{    StringBuffer retval = new StringBuffer();    char ch;    for (int i = 0; i < str.length(); i++) {        switch(str.charAt(i)) {            case 0:                continue;            case '\b':                retval.append("\\b");                continue;            case '\t':                retval.append("\\t");                continue;            case '\n':                retval.append("\\n");                continue;            case '\f':                retval.append("\\f");                continue;            case '\r':                retval.append("\\r");                continue;            case '\"':                retval.append("\\\"");                continue;            case '\'':                retval.append("\\\'");                continue;            case '\\':                retval.append("\\\\");                continue;            default:                if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {                    String s = "0000" + Integer.toString(ch, 16);                    retval.append("\\u" + s.substring(s.length() - 4, s.length()));                } else {                    retval.append(ch);                }                continue;        }    }    return retval.toString();}
0
public Object getValue()
{    return null;}
0
public String toString()
{    return image;}
0
public static Token newToken(int ofKind, String image)
{    switch(ofKind) {        default:            return new Token(ofKind, image);    }}
0
public static Token newToken(int ofKind)
{    return newToken(ofKind, null);}
0
protected static final String addEscapes(String str)
{    StringBuffer retval = new StringBuffer();    char ch;    for (int i = 0; i < str.length(); i++) {        switch(str.charAt(i)) {            case 0:                continue;            case '\b':                retval.append("\\b");                continue;            case '\t':                retval.append("\\t");                continue;            case '\n':                retval.append("\\n");                continue;            case '\f':                retval.append("\\f");                continue;            case '\r':                retval.append("\\r");                continue;            case '\"':                retval.append("\\\"");                continue;            case '\'':                retval.append("\\\'");                continue;            case '\\':                retval.append("\\\\");                continue;            default:                if ((ch = str.charAt(i)) < 0x20 || ch > 0x7e) {                    String s = "0000" + Integer.toString(ch, 16);                    retval.append("\\u" + s.substring(s.length() - 4, s.length()));                } else {                    retval.append(ch);                }                continue;        }    }    return retval.toString();}
0
protected static String LexicalError(boolean EOFSeen, int lexState, int errorLine, int errorColumn, String errorAfter, char curChar)
{    return ("Lexical error at line " + errorLine + ", column " + errorColumn + ".  Encountered: " + (EOFSeen ? "<EOF> " : ("\"" + addEscapes(String.valueOf(curChar)) + "\"") + " (" + (int) curChar + "), ") + "after : \"" + addEscapes(errorAfter) + "\"");}
0
public String getMessage()
{    return super.getMessage();}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);}
0
public void init()
{}
0
public String getName()
{    return name;}
0
public void init()
{        String syslogTime = "(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\b +(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]) (?!<[0-9])(?:2[0123]|[01]?[0-9]):(?:[0-5][0-9])(?::(?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?))(?![0-9])?";    String syslogTime5424 = "(?:\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?(?:Z|[+-]\\d{2}:\\d{2}))";    String syslogPriority = "<(?:[0-9]+)>";    String syslogHost = "[a-z0-9\\.\\\\-_]+";    StringBuilder sb = new StringBuilder("");    sb.append("(?<syslogPriority>");    sb.append(syslogPriority);    sb.append(")?");    sb.append("(?<syslogTime>");    sb.append(syslogTime);    sb.append("|");    sb.append(syslogTime5424);    sb.append(")?");    sb.append("(?<syslogHost>");    sb.append(syslogHost);    sb.append(")?");    sb.append(".*");    sb.append("LEEF:(?<");    sb.append(HeaderFields.VERSION.getName());    sb.append(">1.0|2.0|0)?\\|");    headerBlock(HeaderFields.DEVICE_VENDOR.getName(), sb);    sb.append("\\|");    headerBlock(HeaderFields.DEVICE_PRODUCT.getName(), sb);    sb.append("\\|");    headerBlock(HeaderFields.DEVICE_VERSION.getName(), sb);    sb.append("\\|");    headerBlock(HeaderFields.DEVICE_EVENT.getName(), sb);    sb.append("\\|");        sb.append("(");    headerBlock(HeaderFields.DELIMITER.getName(), sb);    sb.append("\\|");    sb.append(")?");        sb.append(" ?(?<extensions>.*)");    pattern = Pattern.compile(sb.toString());}
0
public Optional<MessageParserResult<JSONObject>> parseOptionalResult(byte[] rawMessage)
{    List<JSONObject> messages = new ArrayList<>();    Map<Object, Throwable> errors = new HashMap<>();    String originalMessage = null;    try (BufferedReader reader = new BufferedReader(new StringReader(new String(rawMessage, getReadCharset())))) {        while ((originalMessage = reader.readLine()) != null) {            Matcher matcher = pattern.matcher(originalMessage);            while (matcher.find()) {                JSONObject obj = new JSONObject();                if (!matcher.matches()) {                    break;                }                                obj.put(HeaderFields.DEVICE_VENDOR.getName(), matcher.group(HeaderFields.DEVICE_VENDOR.getName()));                obj.put(HeaderFields.DEVICE_PRODUCT.getName(), matcher.group(HeaderFields.DEVICE_PRODUCT.getName()));                obj.put(HeaderFields.DEVICE_VERSION.getName(), matcher.group(HeaderFields.DEVICE_VERSION.getName()));                obj.put(HeaderFields.DEVICE_EVENT.getName(), matcher.group(HeaderFields.DEVICE_EVENT.getName()));                String ext = matcher.group("extensions");                                String version = matcher.group(HeaderFields.VERSION.getName());                if (version.equals("2.0")) {                    String delimiter = matcher.group(HeaderFields.DELIMITER.getName());                    if (delimiter == null || delimiter.length() == 0) {                        delimiter = "\\t";                    }                    delimiter = "(?<!\\\\)[" + delimiter.replace("^", "\\^").replace("\t", "\\t") + "]";                    String[] kvs = ext.split(delimiter);                    for (String kv : kvs) {                        String[] a = kv.split("=");                        obj.put(a[0], a[1]);                    }                } else if (version.equals("1.0") || version.isEmpty()) {                    String delimiter = "\t";                    String[] kvs = ext.split(delimiter);                    for (String kv : kvs) {                        String[] a = kv.split("=");                        obj.put(a[0], a[1]);                    }                } else {                                                                                CEFParser.parseExtensions(ext, obj);                }                                obj = mutate(obj, "dst", Fields.DST_ADDR.getName());                obj = mutate(obj, "dstPort", Fields.DST_PORT.getName());                obj = convertToInt(obj, Fields.DST_PORT.getName());                obj = mutate(obj, "src", Fields.SRC_ADDR.getName());                obj = mutate(obj, "srcPort", Fields.SRC_PORT.getName());                obj = convertToInt(obj, Fields.SRC_PORT.getName());                obj.put(Fields.ORIGINAL.getName(), originalMessage);                                String host = matcher.group("syslogHost");                if (!(host == null || host.isEmpty())) {                    obj.put("host", host);                }                                if (obj.containsKey(DEV_TIME)) {                    String devTime = (String) obj.get(DEV_TIME);                    try {                                                                                                                                                                        final String devTimeFormat = (String) obj.get(DEV_TIME_FORMAT);                        List<SimpleDateFormat> formats = (obj.containsKey(DEV_TIME_FORMAT)) ? new ArrayList<SimpleDateFormat>() {                            {                                add(new SimpleDateFormat(devTimeFormat));                            }                        } : DateUtils.DATE_FORMATS_LEEF;                        obj.put(Fields.TIMESTAMP.getName(), DateUtils.parseMultiformat(devTime, formats));                    } catch (java.text.ParseException e) {                        errors.put(originalMessage, new IllegalStateException("devTime field present in LEEF but cannot be parsed", e));                        continue;                    }                } else {                    String logTimestamp = matcher.group("syslogTime");                    if (!(logTimestamp == null || logTimestamp.isEmpty())) {                        try {                            obj.put(Fields.TIMESTAMP.getName(), SyslogUtils.parseTimestampToEpochMillis(logTimestamp, Clock.systemUTC()));                        } catch (ParseException e) {                            errors.put(originalMessage, new IllegalStateException("Cannot parse syslog timestamp", e));                            continue;                        }                    } else {                        obj.put(Fields.TIMESTAMP.getName(), System.currentTimeMillis());                    }                }                messages.add(obj);            }        }    } catch (IOException e) {                Exception innerException = new IllegalStateException("LEEF parser Error: " + e.getMessage() + " on " + originalMessage, e);        return Optional.of(new DefaultMessageParserResult<>(innerException));    }    return Optional.of(new DefaultMessageParserResult<>(messages, errors));}
1
private JSONObject convertToInt(JSONObject obj, String key)
{    if (obj.containsKey(key)) {        obj.put(key, Integer.valueOf((String) obj.get(key)));    }    return obj;}
0
private void headerBlock(String name, StringBuilder sb)
{    sb.append("(?<").append(name).append(">").append(HEADER_CAPTURE_PATTERN).append(")");}
0
public void configure(Map<String, Object> config)
{    setReadCharset(config);}
0
private JSONObject mutate(JSONObject json, String oldKey, String newKey)
{    if (json.containsKey(oldKey)) {        json.put(newKey, json.remove(oldKey));    }    return json;}
0
public void configure(Map<String, Object> parserConfig)
{}
0
public void init()
{}
0
public List<JSONObject> parse(byte[] raw_message)
{    List<JSONObject> messages = new ArrayList<>();    try {        /*			 * We need to create a new JSONParser each time because its 			 * not serializable and the parser is created on the storm nimbus			 * node, then transfered to the workers.			 */        JSONParser jsonParser = new JSONParser();        String rawString = new String(raw_message, StandardCharsets.UTF_8);        JSONObject rawJson = (JSONObject) jsonParser.parse(rawString);                rawJson.remove("@version");        rawJson.remove("type");        rawJson.remove("host");        rawJson.remove("tags");                rawJson = mutate(rawJson, "message", "original_string");        rawJson = mutate(rawJson, "src_ip", "ip_src_addr");        rawJson = mutate(rawJson, "dst_ip", "ip_dst_addr");        rawJson = mutate(rawJson, "src_port", "ip_src_port");        rawJson = mutate(rawJson, "dst_port", "ip_dst_port");        rawJson = mutate(rawJson, "src_ip", "ip_src_addr");                long timestamp = LogstashToEpoch((String) rawJson.remove("@timestamp"));        rawJson.put("timestamp", timestamp);        messages.add(rawJson);        return messages;    } catch (Exception e) {        e.printStackTrace();        return null;    }}
0
private JSONObject mutate(JSONObject json, String oldKey, String newKey)
{    if (json.containsKey(oldKey)) {        json.put(newKey, json.remove(oldKey));    }    return json;}
0
private long LogstashToEpoch(String timestamp) throws java.text.ParseException
{    SimpleDateFormat logstashDateFormat = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS'Z'");    return logstashDateFormat.parse(timestamp).getTime();}
0
private static boolean empty_attribute(final String s)
{    return s == null || s.trim().isEmpty() || s.equals("\"\"");}
0
private static String unquoted_attribute(String s)
{    s = s.trim();    if (s.startsWith("\"") && s.endsWith("\""))        return s.substring(1, s.length() - 1);    return s;}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);}
0
public void init()
{}
0
private void parseMessage(String message, JSONObject outputMessage)
{    String[] tokens = Iterables.toArray(Splitter.on(Pattern.compile(",(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)")).split(message), String.class);    int parser_version = 0;    String type = tokens[3].trim();        if (!type.equals(LogTypeConfig) && !type.equals(LogTypeThreat) && !type.equals(LogTypeTraffic) && !type.equals(LogTypeSystem)) {        throw new UnsupportedOperationException("Unsupported log type.");    }        if (!empty_attribute(tokens[0]))        outputMessage.put(PaloAltoDomain, tokens[0].trim());    if (!empty_attribute(tokens[1]))        outputMessage.put(ReceiveTime, tokens[1].trim());    if (!empty_attribute(tokens[2]))        outputMessage.put(SerialNum, tokens[2].trim());    outputMessage.put(Type, type);    if (!empty_attribute(tokens[4]))        outputMessage.put(ThreatContentType, unquoted_attribute(tokens[4]));    if (!empty_attribute(tokens[5]))        outputMessage.put(ConfigVersion, tokens[5].trim());    if (!empty_attribute(tokens[6]))        outputMessage.put(GenerateTime, tokens[6].trim());    if (LogTypeConfig.equals(type.toUpperCase())) {                if (tokens.length == 16 || tokens.length == 18)            parser_version = 61;        else if (tokens.length == 22 || tokens.length == 24)            parser_version = 80;        if (parser_version >= 61) {            if (!empty_attribute(tokens[7]))                outputMessage.put(HOST, tokens[7].trim());            if (!empty_attribute(tokens[8]))                outputMessage.put(VirtualSystem, tokens[8].trim());            if (!empty_attribute(tokens[9]))                outputMessage.put(Command, tokens[9].trim());            if (!empty_attribute(tokens[10]))                outputMessage.put(Admin, tokens[10].trim());            if (!empty_attribute(tokens[11]))                outputMessage.put(Client, unquoted_attribute(tokens[11]));            if (!empty_attribute(tokens[12]))                outputMessage.put(Result, unquoted_attribute(tokens[12]));            if (!empty_attribute(tokens[13]))                outputMessage.put(ConfigurationPath, unquoted_attribute(tokens[13]));        }        if (parser_version == 61) {            if (!empty_attribute(tokens[14]))                outputMessage.put(Seqno, unquoted_attribute(tokens[14]));            if (!empty_attribute(tokens[15]))                outputMessage.put(ActionFlags, unquoted_attribute(tokens[15]));            if (tokens.length == 18) {                if (!empty_attribute(tokens[16]))                    outputMessage.put(BeforeChangeDetail, unquoted_attribute(tokens[16]));                if (!empty_attribute(tokens[17]))                    outputMessage.put(AfterChangeDetail, unquoted_attribute(tokens[17]));            }        }        if (parser_version >= 70) {            int custom_fields_offset = 0;            if (tokens.length == 24) {                if (!empty_attribute(tokens[14])) {                    outputMessage.put(BeforeChangeDetail, unquoted_attribute(tokens[14 + custom_fields_offset]));                }                if (!empty_attribute(tokens[15])) {                    outputMessage.put(AfterChangeDetail, unquoted_attribute(tokens[15 + custom_fields_offset]));                }                custom_fields_offset = 2;            }            if (!empty_attribute(tokens[14 + custom_fields_offset])) {                outputMessage.put(Seqno, unquoted_attribute(tokens[14 + custom_fields_offset]));            }            if (!empty_attribute(tokens[15 + custom_fields_offset])) {                outputMessage.put(ActionFlags, unquoted_attribute(tokens[15 + custom_fields_offset]));            }            if (!empty_attribute(tokens[16 + custom_fields_offset])) {                outputMessage.put(DGH1, unquoted_attribute(tokens[16 + custom_fields_offset]));            }            if (!empty_attribute(tokens[17 + custom_fields_offset])) {                outputMessage.put(DGH2, unquoted_attribute(tokens[17 + custom_fields_offset]));            }            if (!empty_attribute(tokens[18 + custom_fields_offset])) {                outputMessage.put(DGH3, unquoted_attribute(tokens[18 + custom_fields_offset]));            }            if (!empty_attribute(tokens[19 + custom_fields_offset])) {                outputMessage.put(DGH4, unquoted_attribute(tokens[19 + custom_fields_offset]));            }            if (!empty_attribute(tokens[20 + custom_fields_offset])) {                outputMessage.put(VSYSName, unquoted_attribute(tokens[20 + custom_fields_offset]));            }            if (!empty_attribute(tokens[21 + custom_fields_offset])) {                outputMessage.put(DeviceName, unquoted_attribute(tokens[21 + custom_fields_offset]));            }        }    } else if (LogTypeSystem.equals(type.toUpperCase())) {        if (tokens.length == 17)            parser_version = 61;        else if (tokens.length == 23)            parser_version = 80;        if (parser_version >= 61) {            if (!empty_attribute(tokens[7]))                outputMessage.put(VirtualSystem, tokens[7].trim());            if (!empty_attribute(tokens[8]))                outputMessage.put(EventId, tokens[8].trim());            if (!empty_attribute(tokens[9]))                outputMessage.put(Object, tokens[9].trim());            if (!empty_attribute(tokens[12]))                outputMessage.put(Module, tokens[12].trim());            if (!empty_attribute(tokens[13]))                outputMessage.put(Severity, unquoted_attribute(tokens[13]));            if (!empty_attribute(tokens[14]))                outputMessage.put(Description, unquoted_attribute(tokens[14]));            if (!empty_attribute(tokens[15]))                outputMessage.put(Seqno, unquoted_attribute(tokens[15]));            if (!empty_attribute(tokens[16]))                outputMessage.put(ActionFlags, unquoted_attribute(tokens[16]));        }        if (parser_version == 80) {            if (!empty_attribute(tokens[17]))                outputMessage.put(DGH1, tokens[17].trim());            if (!empty_attribute(tokens[18]))                outputMessage.put(DGH2, tokens[18].trim());            if (!empty_attribute(tokens[19]))                outputMessage.put(DGH3, tokens[19].trim());            if (!empty_attribute(tokens[20]))                outputMessage.put(DGH4, tokens[20].trim());            if (!empty_attribute(tokens[21]))                outputMessage.put(VSYSName, unquoted_attribute(tokens[21]));            if (!empty_attribute(tokens[22]))                outputMessage.put(DeviceName, unquoted_attribute(tokens[22]));        }    } else if (LogTypeThreat.equals(type.toUpperCase()) || LogTypeTraffic.equals(type.toUpperCase())) {        if (!empty_attribute(tokens[7]))            outputMessage.put(SourceAddress, tokens[7].trim());        if (!empty_attribute(tokens[8]))            outputMessage.put(DestinationAddress, tokens[8].trim());        if (!empty_attribute(tokens[9]))            outputMessage.put(NATSourceIP, tokens[9].trim());        if (!empty_attribute(tokens[10]))            outputMessage.put(NATDestinationIP, tokens[10].trim());        if (!empty_attribute(tokens[11]))            outputMessage.put(Rule, unquoted_attribute(tokens[11]));        if (!empty_attribute(tokens[12]))            outputMessage.put(SourceUser, unquoted_attribute(tokens[12]));        if (!empty_attribute(tokens[13]))            outputMessage.put(DestinationUser, unquoted_attribute(tokens[13]));        if (!empty_attribute(tokens[14]))            outputMessage.put(Application, unquoted_attribute(tokens[14]));        if (!empty_attribute(tokens[15]))            outputMessage.put(VirtualSystem, unquoted_attribute(tokens[15]));        if (!empty_attribute(tokens[16]))            outputMessage.put(SourceZone, unquoted_attribute(tokens[16]));        if (!empty_attribute(tokens[17]))            outputMessage.put(DestinationZone, unquoted_attribute(tokens[17]));        if (!empty_attribute(tokens[18]))            outputMessage.put(InboundInterface, unquoted_attribute(tokens[18]));        if (!empty_attribute(tokens[19]))            outputMessage.put(OutboundInterface, unquoted_attribute(tokens[19]));        if (!empty_attribute(tokens[20]))            outputMessage.put(LogAction, unquoted_attribute(tokens[20]));        if (!empty_attribute(tokens[21]))            outputMessage.put(TimeLogged, tokens[21].trim());        if (!empty_attribute(tokens[22]))            outputMessage.put(SessionID, tokens[22].trim());        if (!empty_attribute(tokens[23]))            outputMessage.put(RepeatCount, tokens[23].trim());        if (!empty_attribute(tokens[24]))            outputMessage.put(SourcePort, tokens[24].trim());        if (!empty_attribute(tokens[25]))            outputMessage.put(DestinationPort, tokens[25].trim());        if (!empty_attribute(tokens[26]))            outputMessage.put(NATSourcePort, tokens[26].trim());        if (!empty_attribute(tokens[27]))            outputMessage.put(NATDestinationPort, tokens[27].trim());        if (!empty_attribute(tokens[28]))            outputMessage.put(Flags, tokens[28].trim());        if (!empty_attribute(tokens[29]))            outputMessage.put(IPProtocol, unquoted_attribute(tokens[29]));        if (!empty_attribute(tokens[30]))            outputMessage.put(Action, unquoted_attribute(tokens[30]));        if (LogTypeThreat.equals(type.toUpperCase())) {            int p1_offset = 0;            if (tokens.length == 45)                parser_version = 60;            else if (tokens.length == 53)                parser_version = 61;            else if (tokens.length == 61) {                parser_version = 70;                p1_offset = 1;            } else if (tokens.length == 72) {                parser_version = 80;                p1_offset = 1;            }            if (!empty_attribute(tokens[31])) {                outputMessage.put(URL, unquoted_attribute(tokens[31]));                try {                    URL url = new URL(unquoted_attribute(tokens[31]));                    outputMessage.put(HOST, url.getHost());                } catch (MalformedURLException e) {                }            }            if (!empty_attribute(tokens[32]))                outputMessage.put(ThreatID, tokens[32].trim());            if (!empty_attribute(tokens[33]))                outputMessage.put(Category, unquoted_attribute(tokens[33]));            if (!empty_attribute(tokens[34]))                outputMessage.put(Severity, unquoted_attribute(tokens[34]));            if (!empty_attribute(tokens[35]))                outputMessage.put(Direction, unquoted_attribute(tokens[35]));            if (!empty_attribute(tokens[36]))                outputMessage.put(Seqno, tokens[36].trim());            if (!empty_attribute(tokens[37]))                outputMessage.put(ActionFlags, unquoted_attribute(tokens[37]));            if (!empty_attribute(tokens[38]))                outputMessage.put(SourceLocation, unquoted_attribute(tokens[38]));            if (!empty_attribute(tokens[39]))                outputMessage.put(DestinationLocation, unquoted_attribute(tokens[39]));            if (!empty_attribute(tokens[41]))                outputMessage.put(ContentType, unquoted_attribute(tokens[41]));            if (!empty_attribute(tokens[42]))                outputMessage.put(PCAPID, tokens[42].trim());            if (!empty_attribute(tokens[43]))                outputMessage.put(WFFileDigest, unquoted_attribute(tokens[43]));            if (!empty_attribute(tokens[44]))                outputMessage.put(WFCloud, unquoted_attribute(tokens[44]));            if (parser_version >= 61) {                if (!empty_attribute(tokens[(45 + p1_offset)]))                    outputMessage.put(UserAgent, unquoted_attribute(tokens[(45 + p1_offset)]));                if (!empty_attribute(tokens[(46 + p1_offset)]))                    outputMessage.put(WFFileType, unquoted_attribute(tokens[(46 + p1_offset)]));                if (!empty_attribute(tokens[(47 + p1_offset)]))                    outputMessage.put(XForwardedFor, unquoted_attribute(tokens[(47 + p1_offset)]));                if (!empty_attribute(tokens[(48 + p1_offset)]))                    outputMessage.put(Referer, unquoted_attribute(tokens[(48 + p1_offset)]));                if (!empty_attribute(tokens[(49 + p1_offset)]))                    outputMessage.put(WFSender, unquoted_attribute(tokens[(49 + p1_offset)]));                if (!empty_attribute(tokens[(50 + p1_offset)]))                    outputMessage.put(WFSubject, unquoted_attribute(tokens[(50 + p1_offset)]));                if (!empty_attribute(tokens[(51 + p1_offset)]))                    outputMessage.put(WFRecipient, unquoted_attribute(tokens[(51 + p1_offset)]));                if (!empty_attribute(tokens[(52 + p1_offset)]))                    outputMessage.put(WFReportID, unquoted_attribute(tokens[(52 + p1_offset)]));            }            if (parser_version >= 70) {                if (!empty_attribute(tokens[45]))                    outputMessage.put(URLIndex, tokens[45].trim());                if (!empty_attribute(tokens[54]))                    outputMessage.put(DGH1, tokens[54].trim());                if (!empty_attribute(tokens[55]))                    outputMessage.put(DGH2, tokens[55].trim());                if (!empty_attribute(tokens[56]))                    outputMessage.put(DGH3, tokens[56].trim());                if (!empty_attribute(tokens[57]))                    outputMessage.put(DGH4, tokens[57].trim());                if (!empty_attribute(tokens[58]))                    outputMessage.put(VSYSName, unquoted_attribute(tokens[58]));                if (!empty_attribute(tokens[59]))                    outputMessage.put(DeviceName, unquoted_attribute(tokens[59]));            }            if (parser_version >= 80) {                if (!empty_attribute(tokens[61]))                    outputMessage.put(SourceVmUuid, tokens[61].trim());                if (!empty_attribute(tokens[62]))                    outputMessage.put(DestinationVmUuid, tokens[62].trim());                if (!empty_attribute(tokens[63]))                    outputMessage.put(HTTPMethod, tokens[63].trim());                if (!empty_attribute(tokens[64]))                    outputMessage.put(TunnelId, tokens[64].trim());                if (!empty_attribute(tokens[65]))                    outputMessage.put(MonitorTag, tokens[65].trim());                if (!empty_attribute(tokens[66]))                    outputMessage.put(ParentSessionId, tokens[66].trim());                if (!empty_attribute(tokens[67]))                    outputMessage.put(ParentSessionStartTime, tokens[67].trim());                if (!empty_attribute(tokens[68]))                    outputMessage.put(TunnelType, tokens[68].trim());                if (!empty_attribute(tokens[69]))                    outputMessage.put(ThreatCategory, tokens[69].trim());                if (!empty_attribute(tokens[70]))                    outputMessage.put(ContentVersion, tokens[70].trim());            }        } else if (LogTypeTraffic.equals(type.toUpperCase())) {            if (tokens.length == 46)                parser_version = 60;            else if (tokens.length == 47)                parser_version = 61;            else if (tokens.length == 54)                parser_version = 70;            else if (tokens.length == 61)                parser_version = 80;            if (!empty_attribute(tokens[31]))                outputMessage.put(Bytes, tokens[31].trim());            if (!empty_attribute(tokens[32]))                outputMessage.put(BytesSent, tokens[32].trim());            if (!empty_attribute(tokens[33]))                outputMessage.put(BytesReceived, tokens[33].trim());            if (!empty_attribute(tokens[34]))                outputMessage.put(Packets, tokens[34].trim());            if (!empty_attribute(tokens[35]))                outputMessage.put(StartTime, tokens[35].trim());            if (!empty_attribute(tokens[36]))                outputMessage.put(ElapsedTimeInSec, tokens[36].trim());            if (!empty_attribute(tokens[37]))                outputMessage.put(Category, unquoted_attribute(tokens[37]));            if (!empty_attribute(tokens[39]))                outputMessage.put(Seqno, tokens[39].trim());            if (!empty_attribute(tokens[40]))                outputMessage.put(ActionFlags, unquoted_attribute(tokens[40]));            if (!empty_attribute(tokens[41]))                outputMessage.put(SourceLocation, unquoted_attribute(tokens[41]));            if (!empty_attribute(tokens[42]))                outputMessage.put(DestinationLocation, unquoted_attribute(tokens[42]));            if (!empty_attribute(tokens[44]))                outputMessage.put(PktsSent, tokens[44].trim());            if (!empty_attribute(tokens[45]))                outputMessage.put(PktsReceived, tokens[45].trim());            if (parser_version >= 61) {                if (!empty_attribute(tokens[46]))                    outputMessage.put(EndReason, unquoted_attribute(tokens[46]));            }            if (parser_version >= 70) {                if (!empty_attribute(tokens[47]))                    outputMessage.put(DGH1, tokens[47].trim());                if (!empty_attribute(tokens[48]))                    outputMessage.put(DGH2, tokens[48].trim());                if (!empty_attribute(tokens[49]))                    outputMessage.put(DGH3, tokens[49].trim());                if (!empty_attribute(tokens[50]))                    outputMessage.put(DGH4, tokens[50].trim());                if (!empty_attribute(tokens[51]))                    outputMessage.put(VSYSName, unquoted_attribute(tokens[51]));                if (!empty_attribute(tokens[52]))                    outputMessage.put(DeviceName, unquoted_attribute(tokens[52]));                if (!empty_attribute(tokens[53]))                    outputMessage.put(ActionSource, unquoted_attribute(tokens[53]));            }            if (parser_version >= 80) {                if (!empty_attribute(tokens[54]))                    outputMessage.put(SourceVmUuid, tokens[54].trim());                if (!empty_attribute(tokens[55]))                    outputMessage.put(DestinationVmUuid, tokens[55].trim());                if (!empty_attribute(tokens[56]))                    outputMessage.put(TunnelId, tokens[56].trim());                if (!empty_attribute(tokens[57]))                    outputMessage.put(MonitorTag, tokens[57].trim());                if (!empty_attribute(tokens[58]))                    outputMessage.put(ParentSessionId, tokens[58].trim());                if (!empty_attribute(tokens[59]))                    outputMessage.put(ParentSessionStartTime, tokens[59].trim());                if (!empty_attribute(tokens[60]))                    outputMessage.put(TunnelType, tokens[60].trim());            }        }    }    outputMessage.put(ParserVersion, parser_version);    if (parser_version == 0) {        outputMessage.put(Tokens, tokens.length);    }}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);    dateTimeFormatter = getDateFormatter(parserConfig);    dateTimeFormatter = getDateFormatterWithZone(dateTimeFormatter, parserConfig);    init();}
0
public void init()
{    if (converter == null) {        converter = new CSVConverter();        Map<String, Object> config = new HashMap<>();        config.put(CSVConverter.SEPARATOR_KEY, recordDelimiter);        config.put(CSVConverter.COLUMNS_KEY, Lists.newArrayList(fieldNames));        converter.initialize(config);    }}
0
private long toEpoch(String snortDatetime) throws ParseException
{    ZonedDateTime zonedDateTime = ZonedDateTime.parse(snortDatetime.trim(), dateTimeFormatter);    return zonedDateTime.toInstant().toEpochMilli();}
0
public String getRecordDelimiter()
{    return this.recordDelimiter;}
0
public void setRecordDelimiter(String recordDelimiter)
{    this.recordDelimiter = recordDelimiter;}
0
public String[] getFieldNames()
{    return this.fieldNames;}
0
public void setFieldNames(String[] fieldNames)
{    this.fieldNames = fieldNames;}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);}
0
public void init()
{}
0
protected long formatTimestamp(Object value)
{    long epochTimestamp = System.currentTimeMillis();    if (value != null) {        try {            epochTimestamp = toEpoch(Calendar.getInstance().get(Calendar.YEAR) + " " + value);        } catch (ParseException e) {                }    }    return epochTimestamp;}
0
protected void postParse(JSONObject message)
{    removeEmptyFields(message);    message.remove("timestamp_string");    if (message.containsKey("message")) {        String messageValue = (String) message.get("message");        if (messageValue.contains("logged into")) {            parseLoginMessage(message);        } else if (messageValue.contains("logged out")) {            parseLogoutMessage(message);        } else if (messageValue.contains("rbm(")) {            parseRBMMessage(message);        } else {            parseOtherMessage(message);        }    }}
0
private void removeEmptyFields(JSONObject json)
{    Iterator<Object> keyIter = json.keySet().iterator();    while (keyIter.hasNext()) {        Object key = keyIter.next();        Object value = json.get(key);        if (null == value || "".equals(value.toString())) {            keyIter.remove();        }    }}
0
private void parseLoginMessage(JSONObject json)
{    json.put("event_subtype", "login");    String message = (String) json.get("message");    if (message.contains(":")) {        String[] parts = message.split(":");        String user = parts[0];        String ip_src_addr = parts[1];        if (user.contains("user(") && user.contains(")")) {            user = user.substring(user.indexOf("user(") + "user(".length());            user = user.substring(0, user.indexOf(")"));            json.put("username", user);        }        if (ip_src_addr.contains("[") && ip_src_addr.contains("]")) {            ip_src_addr = ip_src_addr.substring(ip_src_addr.indexOf("[") + 1);            ip_src_addr = ip_src_addr.substring(0, ip_src_addr.indexOf("]"));            json.put("ip_src_addr", ip_src_addr);        }        json.remove("message");    }}
0
private void parseLogoutMessage(JSONObject json)
{    json.put("event_subtype", "logout");    String message = (String) json.get("message");    if (message.matches(".*'.*'.*'.*'.*")) {        String[] parts = message.split("'");        String ip_src_addr = parts[0];        if (ip_src_addr.contains("[") && ip_src_addr.contains("]")) {            ip_src_addr = ip_src_addr.substring(ip_src_addr.indexOf("[") + 1);            ip_src_addr = ip_src_addr.substring(0, ip_src_addr.indexOf("]"));            json.put("ip_src_addr", ip_src_addr);        }        json.put("username", parts[1]);        json.put("security_domain", parts[3]);        json.remove("message");    }}
0
private void parseRBMMessage(JSONObject json)
{    String message = (String) json.get("message");    if (message.contains("(")) {        json.put("process", message.substring(0, message.indexOf("(")));        if (message.contains(":")) {            json.put("message", message.substring(message.indexOf(":") + 2));        }    }}
0
private void parseOtherMessage(JSONObject json)
{    String message = (String) json.get("message");    if (message.contains("(")) {        json.put("process", message.substring(0, message.indexOf("(")));        if (message.contains(":")) {            json.put("message", message.substring(message.indexOf(":") + 2));        }    }}
0
public void testDefault()
{    Assert.assertNull(Filters.get("DEFAULT", null));}
0
public void testSingleQueryFilter() throws Exception
{    {        Map<String, Object> config = new HashMap<String, Object>() {            {                put("filter.query", "exists(foo)");            }        };        MessageFilter<JSONObject> filter = Filters.get(Filters.STELLAR.name(), config);        Assert.assertTrue(filter.emit(new JSONObject(ImmutableMap.of("foo", 1)), Context.EMPTY_CONTEXT()));        Assert.assertFalse(filter.emit(new JSONObject(ImmutableMap.of("bar", 1)), Context.EMPTY_CONTEXT()));    }}
0
public void setUp() throws Exception
{    parserConfig = new HashMap<>();    asaParser = new BasicAsaParser();    asaParser.configure(parserConfig);    asaParser.init();}
0
public void testConfigureDefault()
{    BasicAsaParser testParser = new BasicAsaParser();    testParser.configure(parserConfig);    testParser.init();    assertTrue(testParser.deviceClock.getZone().equals(ZoneOffset.UTC));}
0
public void testConfigureTimeZoneOffset()
{    parserConfig.put("deviceTimeZone", "UTC-05:00");    BasicAsaParser testParser = new BasicAsaParser();    testParser.configure(parserConfig);    testParser.init();    ZonedDateTime deviceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), testParser.deviceClock.getZone());    ZonedDateTime referenceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), ZoneOffset.ofHours(-5));    assertTrue(deviceTime.isEqual(referenceTime));}
0
public void testConfigureTimeZoneText()
{    parserConfig.put("deviceTimeZone", "America/New_York");    BasicAsaParser testParser = new BasicAsaParser();    testParser.configure(parserConfig);    testParser.init();    ZonedDateTime deviceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), testParser.deviceClock.getZone());    ZonedDateTime referenceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), ZoneOffset.ofHours(-5));    assertTrue(deviceTime.isEqual(referenceTime));}
0
public void testCISCOFW106023()
{    String rawMessage = "<164>Aug 05 2016 01:01:34: %ASA-4-106023: Deny tcp src Inside:10.30.9.121/54580 dst Outside:192.168.135.51/42028 by access-group \"Inside_access_in\" [0x962df600, 0x0]";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals(asaJson.get("original_string"), rawMessage);    assertTrue(asaJson.get("ip_src_addr").equals("10.30.9.121"));    assertTrue(asaJson.get("ip_dst_addr").equals("192.168.135.51"));    assertTrue(asaJson.get("ip_src_port").equals(54580));    assertTrue(asaJson.get("ip_dst_port").equals(42028));    assertTrue((long) asaJson.get("timestamp") == 1470358894000L);}
0
public void testCISCOFW106006()
{    String rawMessage = "<162>Aug 05 2016 01:02:25: %ASA-2-106006: Deny inbound UDP from 10.25.177.164/63279 to 10.2.52.71/161 on interface Inside";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals(asaJson.get("original_string"), rawMessage);    assertTrue(asaJson.get("ip_src_addr").equals("10.25.177.164"));    assertTrue(asaJson.get("ip_dst_addr").equals("10.2.52.71"));    assertTrue(asaJson.get("ip_src_port").equals(63279));    assertTrue(asaJson.get("ip_dst_port").equals(161));    assertTrue((long) asaJson.get("timestamp") == 1470358945000L);}
0
public void testShortTimestamp()
{    String rawMessage = "<174>Jan  5 14:52:35 10.22.8.212 %ASA-6-302015: Built inbound UDP connection 76245506 for outside:10.22.8.110/49886 (10.22.8.110/49886) to inside:192.111.72.8/8612 (192.111.72.8/8612) (user.name)";    ZonedDateTime fixedInstant = ZonedDateTime.of(2016, 1, 6, 1, 30, 30, 0, ZoneOffset.UTC);    Clock fixedClock = Clock.fixed(fixedInstant.toInstant(), fixedInstant.getZone());    BasicAsaParser fixedClockParser = new BasicAsaParser();    fixedClockParser.deviceClock = fixedClock;    fixedClockParser.init();    JSONObject asaJson = fixedClockParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals(asaJson.get("original_string"), rawMessage);    assertTrue(asaJson.get("ip_src_addr").equals("10.22.8.110"));    assertTrue(asaJson.get("ip_dst_addr").equals("192.111.72.8"));    assertTrue(asaJson.get("ip_src_port").equals(49886));    assertTrue(asaJson.get("ip_dst_port").equals(8612));    assertTrue((long) asaJson.get("timestamp") == 1452005555000L);}
0
public void testNoPatternForTag()
{    String rawMessage = "<165>Aug 16 2016 04:08:36: %ASA-5-713049: Group = 172.22.136.20, IP = 172.22.136.20, Security negotiation complete for LAN-to-LAN Group (172.22.136.20)  Initiator, Inbound SPI = 0x891fb03f, Outbound SPI = 0xbe4b5d8d";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals(asaJson.get("original_string"), rawMessage);    assertTrue((long) asaJson.get("timestamp") == 1471320516000L);}
0
public void testInvalidIpAddr()
{    String rawMessage = "<164>Aug 05 2016 01:01:34: %ASA-4-106023: Deny tcp src Inside:10.30.9.121/54580 dst Outside:192.168.256.51/42028 by access-group \"Inside_access_in\" [0x962df600, 0x0]";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals(asaJson.get("original_string"), rawMessage);    assertTrue((long) asaJson.get("timestamp") == 1470358894000L);    assertNull(asaJson.get("ip_dst_addr"));}
0
public void testIp6Addr()
{    String rawMessage = "<174>Jan 05 2016 14:52:35 10.22.8.212 %ASA-6-302015: Built inbound UDP connection 76245506 for outside:2001:db8:85a3::8a2e:370:7334/49886 (10.22.8.110/49886) to inside:2001:0db8:85a3:0000:0000:8a2e:0370:7334/8612 (192.111.72.8/8612) (user.name)";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals(rawMessage, asaJson.get("original_string"));    assertEquals("2001:db8:85a3::8a2e:370:7334", asaJson.get("ip_src_addr"));    assertEquals("2001:0db8:85a3:0000:0000:8a2e:0370:7334", asaJson.get("ip_dst_addr"));    assertEquals(49886, asaJson.get("ip_src_port"));    assertEquals(8612, asaJson.get("ip_dst_port"));    assertEquals(1452005555000L, asaJson.get("timestamp"));}
0
public void testSyslogIpHost()
{    String rawMessage = "<174>Jan  5 14:52:35 10.22.8.212 %ASA-6-302015: Built inbound UDP connection 76245506 for outside:10.22.8.110/49886 (10.22.8.110/49886) to inside:192.111.72.8/8612 (192.111.72.8/8612) (user.name)";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals("10.22.8.212", asaJson.get("syslog_host"));}
0
public void testSyslogHost()
{    String rawMessage = "<174>Jan  5 14:52:35 hostname-2 %ASA-6-302015: Built inbound UDP connection 76245506 for outside:10.22.8.110/49886 (10.22.8.110/49886) to inside:192.111.72.8/8612 (192.111.72.8/8612) (user.name)";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals("hostname-2", asaJson.get("syslog_host"));}
0
public void testSyslogHostAndProg()
{    String rawMessage = "<174>Jan  5 14:52:35 hostname-2 progName-2 %ASA-6-302015: Built inbound UDP connection 76245506 for outside:10.22.8.110/49886 (10.22.8.110/49886) to inside:192.111.72.8/8612 (192.111.72.8/8612) (user.name)";    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertEquals("hostname-2", asaJson.get("syslog_host"));    assertEquals("progName-2", asaJson.get("syslog_prog"));}
0
public void testUnexpectedMessage()
{    String rawMessage = "-- MARK --";    UnitTestHelper.setLog4jLevel(BasicAsaParser.class, Level.FATAL);    thrown.expect(RuntimeException.class);    thrown.expectMessage(startsWith("[Metron] Message '-- MARK --'"));    JSONObject asaJson = asaParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);    UnitTestHelper.setLog4jLevel(BasicAsaParser.class, Level.ERROR);}
0
public void getsReadCharsetFromConfig()
{    parserConfig.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    asaParser.configure(parserConfig);    assertThat(asaParser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    asaParser.configure(parserConfig);    assertThat(asaParser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public static void setup()
{    UnitTestHelper.setLog4jLevel(BasicBroParser.class, Level.FATAL);}
0
public static void teardown()
{    UnitTestHelper.setLog4jLevel(BasicBroParser.class, Level.ERROR);}
0
public void testDecimalFormatAssumptions()
{    Pair[] pairs = { Pair.of(12345678d, "12345678.0"), Pair.of(12345678.0d, "12345678.0"), Pair.of(12345678.1d, "12345678.1"), Pair.of(12345678.11d, "12345678.11"), Pair.of(12345678.111d, "12345678.111"), Pair.of(12345678.1111d, "12345678.1111"), Pair.of(12345678.11111d, "12345678.11111"), Pair.of(12345678.111111d, "12345678.111111") };    for (Pair pair : pairs) {        Assert.assertEquals("Format did not match", pair.getRight(), BasicBroParser.DECIMAL_FORMAT.get().format(pair.getLeft()));    }}
0
public void testUnwrappedBroMessage() throws ParseException
{    JSONObject rawJson = (JSONObject) jsonParser.parse(unwrappedBroMessage);    JSONObject broJson = broParser.parse(unwrappedBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1449511228.474";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1449511228474";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port"), rawJson.get("id.orig_p"));    Assert.assertEquals(broJson.get("ip_dst_port"), rawJson.get("id.resp_p"));    Assert.assertEquals(broJson.get("uid").toString(), rawJson.get("uid").toString());    Assert.assertEquals(broJson.get("trans_id").toString(), rawJson.get("trans_id").toString());    Assert.assertEquals(broJson.get("sensor").toString(), rawJson.get("sensor").toString());    Assert.assertEquals(broJson.get("type").toString(), rawJson.get("type").toString());    Assert.assertEquals(broJson.get("rcode").toString(), rawJson.get("rcode").toString());    Assert.assertEquals(broJson.get("rcode_name").toString(), rawJson.get("rcode_name").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("DNS"));}
0
public void testHttpBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(httpBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(httpBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1402307733.473";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1402307733473";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("uid").toString(), rawJson.get("uid").toString());    Assert.assertEquals(broJson.get("method").toString(), rawJson.get("method").toString());    Assert.assertEquals(broJson.get("host").toString(), rawJson.get("host").toString());    Assert.assertEquals(broJson.get("resp_mime_types").toString(), rawJson.get("resp_mime_types").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("HTTP"));}
0
public void testHttpBroMessageWithZeroDecimalTruncation() throws ParseException
{    {        String rawMessage = "{\"http\": {\"ts\":1467657279,\"uid\":\"CMYLzP3PKiwZAgBa51\",\"id.orig_h\":\"192.168.138.158\",\"id.orig_p\":49206,\"id.resp_h\":\"95.163.121.204\"," + "\"id.resp_p\":80,\"trans_depth\":2,\"method\":\"GET\",\"host\":\"7oqnsnzwwnm6zb7y.gigapaysun.com\",\"uri\":\"/img/flags/it.png\",\"referrer\":\"http://7oqnsnzwwnm6zb7y.gigapaysun.com/11iQmfg\",\"user_agent\":\"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)\",\"request_body_len\":0,\"response_body_len\":552,\"status_code\":200,\"status_msg\":\"OK\",\"tags\":[],\"resp_fuids\":[\"F3m7vB2RjUe4n01aqj\"],\"resp_mime_types\":[\"image/png\"]}}";        Map rawMessageMap = (Map) jsonParser.parse(rawMessage);        JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());        JSONObject broJson = broParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);        String expectedTimestamp = "1467657279000";        Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);        String expectedBroTimestamp = "1467657279.0";        Assert.assertEquals(broJson.get("bro_timestamp").toString(), expectedBroTimestamp);    }    {        String rawMessage = "{\"http\": {\"ts\":1467657279.0,\"uid\":\"CMYLzP3PKiwZAgBa51\",\"id.orig_h\":\"192.168.138.158\",\"id.orig_p\":49206,\"id.resp_h\":\"95.163.121.204\"," + "\"id.resp_p\":80,\"trans_depth\":2,\"method\":\"GET\",\"host\":\"7oqnsnzwwnm6zb7y.gigapaysun.com\",\"uri\":\"/img/flags/it.png\",\"referrer\":\"http://7oqnsnzwwnm6zb7y.gigapaysun.com/11iQmfg\",\"user_agent\":\"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)\",\"request_body_len\":0,\"response_body_len\":552,\"status_code\":200,\"status_msg\":\"OK\",\"tags\":[],\"resp_fuids\":[\"F3m7vB2RjUe4n01aqj\"],\"resp_mime_types\":[\"image/png\"]}}";        Map rawMessageMap = (Map) jsonParser.parse(rawMessage);        JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());        JSONObject broJson = broParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);        String expectedTimestamp = "1467657279000";        Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);        String expectedBroTimestamp = "1467657279.0";        Assert.assertEquals(broJson.get("bro_timestamp").toString(), expectedBroTimestamp);    }    {        String rawMessage = "{\"http\": {\"ts\":1467657279.1,\"uid\":\"CMYLzP3PKiwZAgBa51\",\"id.orig_h\":\"192.168.138.158\",\"id.orig_p\":49206,\"id.resp_h\":\"95.163.121.204\"," + "\"id.resp_p\":80,\"trans_depth\":2,\"method\":\"GET\",\"host\":\"7oqnsnzwwnm6zb7y.gigapaysun.com\",\"uri\":\"/img/flags/it.png\",\"referrer\":\"http://7oqnsnzwwnm6zb7y.gigapaysun.com/11iQmfg\",\"user_agent\":\"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)\",\"request_body_len\":0,\"response_body_len\":552,\"status_code\":200,\"status_msg\":\"OK\",\"tags\":[],\"resp_fuids\":[\"F3m7vB2RjUe4n01aqj\"],\"resp_mime_types\":[\"image/png\"]}}";        Map rawMessageMap = (Map) jsonParser.parse(rawMessage);        JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());        JSONObject broJson = broParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);        String expectedTimestamp = "1467657279100";        Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);        String expectedBroTimestamp = "1467657279.1";        Assert.assertEquals(broJson.get("bro_timestamp").toString(), expectedBroTimestamp);    }    {        String rawMessage = "{\"http\": {\"ts\":1467657279.11,\"uid\":\"CMYLzP3PKiwZAgBa51\",\"id.orig_h\":\"192.168.138.158\",\"id.orig_p\":49206,\"id.resp_h\":\"95.163.121.204\"," + "\"id.resp_p\":80,\"trans_depth\":2,\"method\":\"GET\",\"host\":\"7oqnsnzwwnm6zb7y.gigapaysun.com\",\"uri\":\"/img/flags/it.png\",\"referrer\":\"http://7oqnsnzwwnm6zb7y.gigapaysun.com/11iQmfg\",\"user_agent\":\"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)\",\"request_body_len\":0,\"response_body_len\":552,\"status_code\":200,\"status_msg\":\"OK\",\"tags\":[],\"resp_fuids\":[\"F3m7vB2RjUe4n01aqj\"],\"resp_mime_types\":[\"image/png\"]}}";        Map rawMessageMap = (Map) jsonParser.parse(rawMessage);        JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());        JSONObject broJson = broParser.parse(rawMessage.getBytes(StandardCharsets.UTF_8)).get(0);        String expectedTimestamp = "1467657279110";        Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);        String expectedBroTimestamp = "1467657279.11";        Assert.assertEquals(broJson.get("bro_timestamp").toString(), expectedBroTimestamp);    }}
0
public void testHttpBroDecimalMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(httpBroDecimalMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(httpBroDecimalMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1457149494.166991";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1457149494166";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("uid").toString(), rawJson.get("uid").toString());    Assert.assertEquals(broJson.get("method").toString(), rawJson.get("method").toString());    Assert.assertEquals(broJson.get("host").toString(), rawJson.get("host").toString());    Assert.assertEquals(broJson.get("resp_mime_types").toString(), rawJson.get("resp_mime_types").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("HTTP"));}
0
public void testDnsBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(dnsBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(dnsBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1402308259.609";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1402308259609";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("qtype").toString(), rawJson.get("qtype").toString());    Assert.assertEquals(broJson.get("trans_id").toString(), rawJson.get("trans_id").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("DNS"));}
0
public void testFilesBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(filesBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(filesBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1425845251.334";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1425845251334";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), ((JSONArray) rawJson.get("tx_hosts")).get(0).toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), ((JSONArray) rawJson.get("rx_hosts")).get(0).toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("fuid").toString(), rawJson.get("fuid").toString());    Assert.assertEquals(broJson.get("md5").toString(), rawJson.get("md5").toString());    Assert.assertEquals(broJson.get("analyzers").toString(), rawJson.get("analyzers").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("FILES"));}
0
public void testConnBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(connBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(connBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1166289883.163553";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1166289883163";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("proto").toString(), rawJson.get("proto").toString());    Assert.assertEquals(broJson.get("service").toString(), rawJson.get("service").toString());    Assert.assertEquals(broJson.get("duration").toString(), rawJson.get("duration").toString());    Assert.assertEquals(broJson.get("orig_bytes").toString(), rawJson.get("orig_bytes").toString());    Assert.assertEquals(broJson.get("resp_bytes").toString(), rawJson.get("resp_bytes").toString());    Assert.assertEquals(broJson.get("conn_state").toString(), rawJson.get("conn_state").toString());    Assert.assertEquals(broJson.get("missed_bytes").toString(), rawJson.get("missed_bytes").toString());    Assert.assertEquals(broJson.get("history").toString(), rawJson.get("history").toString());    Assert.assertEquals(broJson.get("orig_pkts").toString(), rawJson.get("orig_pkts").toString());    Assert.assertEquals(broJson.get("orig_ip_bytes").toString(), rawJson.get("orig_ip_bytes").toString());    Assert.assertEquals(broJson.get("resp_pkts").toString(), rawJson.get("resp_pkts").toString());    Assert.assertEquals(broJson.get("resp_ip_bytes").toString(), rawJson.get("resp_ip_bytes").toString());    Assert.assertEquals(broJson.get("tunnel_parents").toString(), rawJson.get("tunnel_parents").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("CONN"));}
0
public void testDpdBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(dpdBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(dpdBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216704078.712276";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216704078712";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("proto").toString(), rawJson.get("proto").toString());    Assert.assertEquals(broJson.get("analyzer").toString(), rawJson.get("analyzer").toString());    Assert.assertEquals(broJson.get("failure_reason").toString(), rawJson.get("failure_reason").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("DPD"));}
0
public void testFtpBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(ftpBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(ftpBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1166289883.164645";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1166289883164";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("user").toString(), rawJson.get("user").toString());    Assert.assertEquals(broJson.get("password").toString(), rawJson.get("password").toString());    Assert.assertEquals(broJson.get("command").toString(), rawJson.get("command").toString());    Assert.assertEquals(broJson.get("arg").toString(), rawJson.get("arg").toString());    Assert.assertEquals(broJson.get("mime_type").toString(), rawJson.get("mime_type").toString());    Assert.assertEquals(broJson.get("file_size").toString(), rawJson.get("file_size").toString());    Assert.assertEquals(broJson.get("reply_code").toString(), rawJson.get("reply_code").toString());    Assert.assertEquals(broJson.get("reply_msg").toString(), rawJson.get("reply_msg").toString());    Assert.assertEquals(broJson.get("fuid").toString(), rawJson.get("fuid").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("FTP"));}
0
public void testKnownCertsBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(knownCertsBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(knownCertsBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216706999.896836";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216706999896";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("host").toString(), rawJson.get("host").toString());    Assert.assertEquals(broJson.get("port_num").toString(), rawJson.get("port_num").toString());    Assert.assertEquals(broJson.get("subject").toString(), rawJson.get("subject").toString());    Assert.assertEquals(broJson.get("issuer_subject").toString(), rawJson.get("issuer_subject").toString());    Assert.assertEquals(broJson.get("serial").toString(), rawJson.get("serial").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("KNOWN_CERTS"));}
0
public void testSmtpBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(smtpBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(smtpBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1258568059.130219";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1258568059130";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("trans_depth").toString(), rawJson.get("trans_depth").toString());    Assert.assertEquals(broJson.get("helo").toString(), rawJson.get("helo").toString());    Assert.assertEquals(broJson.get("last_reply").toString(), rawJson.get("last_reply").toString());    Assert.assertEquals(broJson.get("path").toString(), rawJson.get("path").toString());    Assert.assertEquals(broJson.get("tls").toString(), rawJson.get("tls").toString());    Assert.assertEquals(broJson.get("fuids").toString(), rawJson.get("fuids").toString());    Assert.assertEquals(broJson.get("is_webmail").toString(), rawJson.get("is_webmail").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("SMTP"));}
0
public void testSslBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(sslBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(sslBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216706999.444925";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216706999444";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("version").toString(), rawJson.get("version").toString());    Assert.assertEquals(broJson.get("cipher").toString(), rawJson.get("cipher").toString());    Assert.assertEquals(broJson.get("server_name").toString(), rawJson.get("server_name").toString());    Assert.assertEquals(broJson.get("resumed").toString(), rawJson.get("resumed").toString());    Assert.assertEquals(broJson.get("established").toString(), rawJson.get("established").toString());    Assert.assertEquals(broJson.get("cert_chain_fuids").toString(), rawJson.get("cert_chain_fuids").toString());    Assert.assertEquals(broJson.get("client_cert_chain_fuids").toString(), rawJson.get("client_cert_chain_fuids").toString());    Assert.assertEquals(broJson.get("subject").toString(), rawJson.get("subject").toString());    Assert.assertEquals(broJson.get("issuer").toString(), rawJson.get("issuer").toString());    Assert.assertEquals(broJson.get("validation_status").toString(), rawJson.get("validation_status").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("SSL"));}
0
public void testWeirdBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(weirdBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(weirdBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216706886.239896";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216706886239";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("name").toString(), rawJson.get("name").toString());    Assert.assertEquals(broJson.get("notice").toString(), rawJson.get("notice").toString());    Assert.assertEquals(broJson.get("peer").toString(), rawJson.get("peer").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("WEIRD"));}
0
public void testNoticeBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(noticeBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(noticeBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216706377.196728";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216706377196";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("proto").toString(), rawJson.get("proto").toString());    Assert.assertEquals(broJson.get("note").toString(), rawJson.get("note").toString());    Assert.assertEquals(broJson.get("msg").toString(), rawJson.get("msg").toString());    Assert.assertEquals(broJson.get("sub").toString(), rawJson.get("sub").toString());    Assert.assertEquals(broJson.get("src").toString(), rawJson.get("src").toString());    Assert.assertEquals(broJson.get("dst").toString(), rawJson.get("dst").toString());    Assert.assertEquals(broJson.get("p").toString(), rawJson.get("p").toString());    Assert.assertEquals(broJson.get("peer_descr").toString(), rawJson.get("peer_descr").toString());    Assert.assertEquals(broJson.get("actions").toString(), rawJson.get("actions").toString());    Assert.assertEquals(broJson.get("suppress_for").toString(), rawJson.get("suppress_for").toString());    Assert.assertEquals(broJson.get("dropped").toString(), rawJson.get("dropped").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("NOTICE"));}
0
public void testDhcpBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(dhcpBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(dhcpBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1258567562.944638";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1258567562944";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("mac").toString(), rawJson.get("mac").toString());    Assert.assertEquals(broJson.get("assigned_ip").toString(), rawJson.get("assigned_ip").toString());    Assert.assertEquals(broJson.get("lease_time").toString(), rawJson.get("lease_time").toString());    Assert.assertEquals(broJson.get("trans_id").toString(), rawJson.get("trans_id").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("DHCP"));}
0
public void testSshBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(sshBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(sshBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1320435870.747967";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1320435870747";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("version").toString(), rawJson.get("version").toString());    Assert.assertEquals(broJson.get("auth_success").toString(), rawJson.get("auth_success").toString());    Assert.assertEquals(broJson.get("client").toString(), rawJson.get("client").toString());    Assert.assertEquals(broJson.get("server").toString(), rawJson.get("server").toString());    Assert.assertEquals(broJson.get("cipher_alg").toString(), rawJson.get("cipher_alg").toString());    Assert.assertEquals(broJson.get("mac_alg").toString(), rawJson.get("mac_alg").toString());    Assert.assertEquals(broJson.get("compression_alg").toString(), rawJson.get("compression_alg").toString());    Assert.assertEquals(broJson.get("kex_alg").toString(), rawJson.get("kex_alg").toString());    Assert.assertEquals(broJson.get("host_key_alg").toString(), rawJson.get("host_key_alg").toString());    Assert.assertEquals(broJson.get("host_key").toString(), rawJson.get("host_key").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("SSH"));}
0
public void testSoftwareBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(softwareBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(softwareBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216707079.49066";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216707079490";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("host").toString(), rawJson.get("host").toString());    Assert.assertEquals(broJson.get("host_p").toString(), rawJson.get("host_p").toString());    Assert.assertEquals(broJson.get("software_type").toString(), rawJson.get("software_type").toString());    Assert.assertEquals(broJson.get("name").toString(), rawJson.get("name").toString());    Assert.assertEquals(broJson.get("version.major").toString(), rawJson.get("version.major").toString());    Assert.assertEquals(broJson.get("version.minor").toString(), rawJson.get("version.minor").toString());    Assert.assertEquals(broJson.get("version.minor2").toString(), rawJson.get("version.minor2").toString());    Assert.assertEquals(broJson.get("unparsed_version").toString(), rawJson.get("unparsed_version").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("SOFTWARE"));}
0
public void testSoftwareBroMessage2() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(softwareBroMessage2);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(softwareBroMessage2.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216707079.518447";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216707079518";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("host").toString(), rawJson.get("host").toString());    Assert.assertEquals(broJson.get("host_p").toString(), rawJson.get("host_p").toString());    Assert.assertEquals(broJson.get("software_type").toString(), rawJson.get("software_type").toString());    Assert.assertEquals(broJson.get("name").toString(), rawJson.get("name").toString());    Assert.assertEquals(broJson.get("unparsed_version").toString(), rawJson.get("unparsed_version").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("SOFTWARE"));}
0
public void testRadiusBroMessageFailed() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(radiusBroMessageFailed);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(radiusBroMessageFailed.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1440447766.441298";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1440447766441";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("username").toString(), rawJson.get("username").toString());    Assert.assertEquals(broJson.get("result").toString(), rawJson.get("result").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("RADIUS"));}
0
public void testRadiusBroMessageSuccess() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(radiusBroMessageSuccess);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(radiusBroMessageSuccess.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1440447839.947956";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1440447839947";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("username").toString(), rawJson.get("username").toString());    Assert.assertEquals(broJson.get("result").toString(), rawJson.get("result").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("RADIUS"));}
0
public void testX509BroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(x509BroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(x509BroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216706999.661483";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216706999661";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("id").toString(), rawJson.get("id").toString());    Assert.assertEquals(broJson.get("certificate.version").toString(), rawJson.get("certificate.version").toString());    Assert.assertEquals(broJson.get("certificate.serial").toString(), rawJson.get("certificate.serial").toString());    Assert.assertEquals(broJson.get("certificate.subject").toString(), rawJson.get("certificate.subject").toString());    Assert.assertEquals(broJson.get("certificate.issuer").toString(), rawJson.get("certificate.issuer").toString());    Assert.assertEquals(broJson.get("certificate.not_valid_before").toString(), rawJson.get("certificate.not_valid_before").toString());    Assert.assertEquals(broJson.get("certificate.not_valid_after").toString(), rawJson.get("certificate.not_valid_after").toString());    Assert.assertEquals(broJson.get("certificate.key_alg").toString(), rawJson.get("certificate.key_alg").toString());    Assert.assertEquals(broJson.get("certificate.sig_alg").toString(), rawJson.get("certificate.sig_alg").toString());    Assert.assertEquals(broJson.get("certificate.key_type").toString(), rawJson.get("certificate.key_type").toString());    Assert.assertEquals(broJson.get("certificate.key_length").toString(), rawJson.get("certificate.key_length").toString());    Assert.assertEquals(broJson.get("certificate.exponent").toString(), rawJson.get("certificate.exponent").toString());    Assert.assertEquals(broJson.get("basic_constraints.ca").toString(), rawJson.get("basic_constraints.ca").toString());    Assert.assertEquals(broJson.get("basic_constraints.path_len").toString(), rawJson.get("basic_constraints.path_len").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("X509"));}
0
public void testKnownDevicesBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(knownDevicesBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(knownDevicesBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1258532046.693816";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1258532046693";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("mac").toString(), rawJson.get("mac").toString());    Assert.assertEquals(broJson.get("dhcp_host_name").toString(), rawJson.get("dhcp_host_name").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("KNOWN_DEVICES"));}
0
public void testRfbBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(rfbBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(rfbBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1328634261.675248";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1328634261675";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("uid").toString(), rawJson.get("uid").toString());    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertEquals(broJson.get("client_major_version").toString(), rawJson.get("client_major_version").toString());    Assert.assertEquals(broJson.get("client_minor_version").toString(), rawJson.get("client_minor_version").toString());    Assert.assertEquals(broJson.get("server_major_version").toString(), rawJson.get("server_major_version").toString());    Assert.assertEquals(broJson.get("server_minor_version").toString(), rawJson.get("server_minor_version").toString());    Assert.assertEquals(broJson.get("authentication_method").toString(), rawJson.get("authentication_method").toString());    Assert.assertEquals(broJson.get("auth").toString(), rawJson.get("auth").toString());    Assert.assertEquals(broJson.get("share_flag").toString(), rawJson.get("share_flag").toString());    Assert.assertEquals(broJson.get("desktop_name").toString(), rawJson.get("desktop_name").toString());    Assert.assertEquals(broJson.get("width").toString(), rawJson.get("width").toString());    Assert.assertEquals(broJson.get("height").toString(), rawJson.get("height").toString());}
0
public void testStatsBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(statsBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(statsBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1440447766.440305";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1440447766440";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("peer").toString(), rawJson.get("peer").toString());    Assert.assertEquals(broJson.get("mem").toString(), rawJson.get("mem").toString());    Assert.assertEquals(broJson.get("pkts_proc").toString(), rawJson.get("pkts_proc").toString());    Assert.assertEquals(broJson.get("bytes_recv").toString(), rawJson.get("bytes_recv").toString());    Assert.assertEquals(broJson.get("events_proc").toString(), rawJson.get("events_proc").toString());    Assert.assertEquals(broJson.get("events_queued").toString(), rawJson.get("events_queued").toString());    Assert.assertEquals(broJson.get("active_tcp_conns").toString(), rawJson.get("active_tcp_conns").toString());    Assert.assertEquals(broJson.get("active_udp_conns").toString(), rawJson.get("active_udp_conns").toString());    Assert.assertEquals(broJson.get("active_icmp_conns").toString(), rawJson.get("active_icmp_conns").toString());    Assert.assertEquals(broJson.get("tcp_conns").toString(), rawJson.get("tcp_conns").toString());    Assert.assertEquals(broJson.get("udp_conns").toString(), rawJson.get("udp_conns").toString());    Assert.assertEquals(broJson.get("icmp_conns").toString(), rawJson.get("icmp_conns").toString());    Assert.assertEquals(broJson.get("timers").toString(), rawJson.get("timers").toString());    Assert.assertEquals(broJson.get("active_timers").toString(), rawJson.get("active_timers").toString());    Assert.assertEquals(broJson.get("files").toString(), rawJson.get("files").toString());    Assert.assertEquals(broJson.get("active_files").toString(), rawJson.get("active_files").toString());    Assert.assertEquals(broJson.get("dns_requests").toString(), rawJson.get("dns_requests").toString());    Assert.assertEquals(broJson.get("active_dns_requests").toString(), rawJson.get("active_dns_requests").toString());    Assert.assertEquals(broJson.get("reassem_tcp_size").toString(), rawJson.get("reassem_tcp_size").toString());    Assert.assertEquals(broJson.get("reassem_file_size").toString(), rawJson.get("reassem_file_size").toString());    Assert.assertEquals(broJson.get("reassem_frag_size").toString(), rawJson.get("reassem_frag_size").toString());    Assert.assertEquals(broJson.get("reassem_unknown_size").toString(), rawJson.get("reassem_unknown_size").toString());}
0
public void testCaptureLossBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(captureLossBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(captureLossBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1320435958.419451";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1320435958419";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("ts_delta").toString(), rawJson.get("ts_delta").toString());    Assert.assertEquals(broJson.get("peer").toString(), rawJson.get("peer").toString());    Assert.assertEquals(broJson.get("gaps").toString(), rawJson.get("gaps").toString());    Assert.assertEquals(broJson.get("acks").toString(), rawJson.get("acks").toString());    Assert.assertEquals(broJson.get("percent_lost").toString(), rawJson.get("percent_lost").toString());}
0
public void testSipBroMessage() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(sipBroMessage);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(sipBroMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1216698441.346819";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1216698441346";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertTrue(broJson.get("original_string").toString().startsWith(rawMessageMap.keySet().iterator().next().toString().toUpperCase()));    Assert.assertEquals(broJson.get("uid").toString(), rawJson.get("uid").toString());    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertEquals(broJson.get("trans_depth").toString(), rawJson.get("trans_depth").toString());    Assert.assertEquals(broJson.get("method").toString(), rawJson.get("method").toString());    Assert.assertEquals(broJson.get("uri").toString(), rawJson.get("uri").toString());    Assert.assertEquals(broJson.get("request_from").toString(), rawJson.get("request_from").toString());    Assert.assertEquals(broJson.get("request_to").toString(), rawJson.get("request_to").toString());    Assert.assertEquals(broJson.get("response_from").toString(), rawJson.get("response_from").toString());    Assert.assertEquals(broJson.get("response_to").toString(), rawJson.get("response_to").toString());    Assert.assertEquals(broJson.get("call_id").toString(), rawJson.get("call_id").toString());    Assert.assertEquals(broJson.get("seq").toString(), rawJson.get("seq").toString());    Assert.assertEquals(broJson.get("request_path").toString(), rawJson.get("request_path").toString());    Assert.assertEquals(broJson.get("response_path").toString(), rawJson.get("response_path").toString());    Assert.assertEquals(broJson.get("user_agent").toString(), rawJson.get("user_agent").toString());    Assert.assertEquals(broJson.get("status_code").toString(), rawJson.get("status_code").toString());    Assert.assertEquals(broJson.get("status_msg").toString(), rawJson.get("status_msg").toString());    Assert.assertEquals(broJson.get("request_body_len").toString(), rawJson.get("request_body_len").toString());    Assert.assertEquals(broJson.get("response_body_len").toString(), rawJson.get("response_body_len").toString());}
0
public void testProtocolKeyCleanedUp() throws ParseException
{    Map rawMessageMap = (Map) jsonParser.parse(protocolKeyCleanedUp);    JSONObject rawJson = (JSONObject) rawMessageMap.get(rawMessageMap.keySet().iterator().next());    JSONObject broJson = broParser.parse(protocolKeyCleanedUp.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedBroTimestamp = "1402307733.473";    Assert.assertEquals(broJson.get("bro_timestamp"), expectedBroTimestamp);    String expectedTimestamp = "1402307733473";    Assert.assertEquals(broJson.get("timestamp").toString(), expectedTimestamp);    Assert.assertEquals(broJson.get("ip_src_addr").toString(), rawJson.get("id.orig_h").toString());    Assert.assertEquals(broJson.get("ip_dst_addr").toString(), rawJson.get("id.resp_h").toString());    Assert.assertEquals(broJson.get("ip_src_port").toString(), rawJson.get("id.orig_p").toString());    Assert.assertEquals(broJson.get("ip_dst_port").toString(), rawJson.get("id.resp_p").toString());    Assert.assertTrue(broJson.get("original_string").toString().startsWith("HTTP"));}
0
public void testBadMessage() throws ParseException
{    broParser.parse("{ \"foo\" : \"bar\"}".getBytes(StandardCharsets.UTF_8));}
0
public void testBadMessageNonJson()
{    broParser.parse("foo bar".getBytes(StandardCharsets.UTF_8));}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    broParser.configure(config);    assertThat(broParser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    broParser.configure(config);    assertThat(broParser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void setUp()
{    parser = new CEFParser();    parser.init();}
0
public void testInvalid()
{    List<JSONObject> obj = parse("test test test nonsense\n");    Assert.assertEquals(0, obj.size());}
0
public void testEscaping()
{    for (JSONObject obj : parse("Sep 19 08:26:10 host CEF:0|security|threatmanager|1.0|100|detected a \\ in packet|10|src=10.0.0.1 act=blocked a \\ dst=1.1.1.1")) {        Assert.assertEquals("10.0.0.1", obj.get(Fields.SRC_ADDR.getName()));        Assert.assertEquals("blocked a \\", obj.get("deviceAction"));        Assert.assertEquals("1.1.1.1", obj.get(Fields.DST_ADDR.getName()));    }}
0
public void testBasicHeader()
{    for (JSONObject obj : parse("CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 dst=2.1.2.2 spt=1232")) {        Assert.assertEquals("Security", obj.get("DeviceVendor"));        Assert.assertEquals("threatmanager", obj.get("DeviceProduct"));        Assert.assertEquals("1.0", obj.get("DeviceVersion"));        Assert.assertEquals("100", obj.get("DeviceEvent"));        Assert.assertEquals("worm successfully stopped", obj.get("Name"));        Assert.assertEquals(10, obj.get("Severity"));    }}
0
public void testBasicExtensions()
{    for (JSONObject obj : parse("CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 dst=2.1.2.2 spt=1232")) {        Assert.assertEquals("10.0.0.1", obj.get(Fields.SRC_ADDR.getName()));        Assert.assertEquals("2.1.2.2", obj.get(Fields.DST_ADDR.getName()));        Assert.assertEquals(1232, obj.get(Fields.SRC_PORT.getName()));    }}
0
public void testCustomLabelWithSpace()
{    for (JSONObject obj : parse("CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 dst=2.1.2.2 spt=1232 custom=Text with space customLabel=Label with space")) {        Assert.assertEquals(true, obj.containsKey("Label with space"));        Assert.assertEquals("Text with space", obj.get("Label with space"));    }}
0
public void testTimestampPriority() throws java.text.ParseException
{    long correctTime = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSz").parse("2016-05-01T09:29:11.356-0400").getTime();    SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSz");    for (JSONObject obj : parse("CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 rt=May 1 2016 09:29:11.356 -0400 dst=2.1.2.2 spt=1232")) {        Assert.assertEquals(new Date(correctTime), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(correctTime, obj.get(Fields.TIMESTAMP.getName()));    }    for (JSONObject obj : parse("2016-06-01T09:29:11.356-04:00 host CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 rt=May 1 2016 09:29:11.356 -0400 dst=2.1.2.2 spt=1232")) {        Assert.assertEquals(new Date(correctTime), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(correctTime, obj.get(Fields.TIMESTAMP.getName()));    }    for (JSONObject obj : parse("2016-05-01T09:29:11.356-04:00 host CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 dst=2.1.2.2 spt=1232")) {        Assert.assertEquals(new Date(correctTime), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(correctTime, obj.get(Fields.TIMESTAMP.getName()));    }    for (JSONObject obj : parse("CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 dst=2.1.2.2 spt=1232")) {        Assert.assertNotNull(obj.get(Fields.TIMESTAMP.getName()));    }}
0
public void testRtValueAsEpochTimestamp() throws java.text.ParseException
{    long correctTime = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSz").parse("2016-05-01T09:29:11.356-0400").getTime();    for (JSONObject obj : parse("CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 rt=" + String.valueOf(correctTime) + " dst=2.1.2.2 spt=1232")) {        Assert.assertEquals(new Date(correctTime), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(correctTime, obj.get(Fields.TIMESTAMP.getName()));    }}
0
private void runMissingYear(Calendar expected, Calendar input)
{    SimpleDateFormat sdf = new SimpleDateFormat("MMM dd HH:mm:ss.SSS");    for (JSONObject obj : parse("CEF:0|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.1 rt=" + sdf.format(input.getTime()) + " dst=2.1.2.2 spt=1232")) {        Assert.assertEquals(expected.getTimeInMillis(), obj.get(Fields.TIMESTAMP.getName()));        Assert.assertEquals(expected.getTime(), new Date((long) obj.get(Fields.TIMESTAMP.getName())));    }}
0
public void testMissingYearFromDate() throws java.text.ParseException
{    Calendar current = Calendar.getInstance();    Calendar correct = Calendar.getInstance();    correct.setTimeInMillis(current.getTimeInMillis());    runMissingYear(correct, current);}
0
public void testFourDayFutureBecomesPast()
{    Calendar current = Calendar.getInstance();    Calendar correct = Calendar.getInstance();    current.add(Calendar.DAY_OF_MONTH, 5);        correct.setTimeInMillis(current.getTimeInMillis());    correct.add(Calendar.YEAR, -1);    runMissingYear(correct, current);}
0
public void testCEFParserAdallom() throws Exception
{    runTest("adallom", Resources.readLines(Resources.getResource(getClass(), "adallom.cef"), StandardCharsets.UTF_8), Resources.toString(Resources.getResource(getClass(), "adallom.schema"), StandardCharsets.UTF_8));}
0
public void testCEFParserCyberArk() throws Exception
{    runTest("cyberark", Resources.readLines(Resources.getResource(getClass(), "cyberark.cef"), StandardCharsets.UTF_8), Resources.toString(Resources.getResource(getClass(), "cyberark.schema"), StandardCharsets.UTF_8), Resources.toString(Resources.getResource(getClass(), "cyberark.json"), StandardCharsets.UTF_8));}
0
public void testCEFParserWAF() throws Exception
{    URL waf_url = Resources.getResource(getClass(), "waf.cef");    runTest("waf", Resources.readLines(waf_url, StandardCharsets.UTF_8), Resources.toString(Resources.getResource(getClass(), "waf.schema"), StandardCharsets.UTF_8));}
0
public void testPaloAltoCEF() throws Exception
{    URL palo_url = Resources.getResource(getClass(), "palo.cef");    runTest("palo", Resources.readLines(palo_url, StandardCharsets.UTF_8), Resources.toString(Resources.getResource(getClass(), "palo.schema"), StandardCharsets.UTF_8));}
0
private void runTest(String name, List<String> lines, String schema) throws Exception
{    runTest(name, lines, schema, "");}
0
private void runTest(String name, List<String> lines, String schema, String targetJson) throws Exception
{    for (String inputString : lines) {        JSONObject parsed = parse(inputString).get(0);        Assert.assertNotNull(parsed);        Assert.assertNotNull(parsed.get(Fields.TIMESTAMP.getName()));        Assert.assertTrue((long) parsed.get(Fields.TIMESTAMP.getName()) > 0);        JSONParser parser = new JSONParser();        Map<?, ?> json = null;        json = (Map<?, ?>) parser.parse(parsed.toJSONString());        Assert.assertEquals(true, validateJsonData(schema, json.toString()));    }}
0
public void testSuccessfulWhenCEFContainsJSON() throws JsonProcessingException, IOException
{    List<JSONObject> parse = parse(sample);    JSONObject obj = parse.get(0);    Assert.assertEquals("TestVendor", obj.get("DeviceVendor"));    Assert.assertEquals(1423441663000L, obj.get(Fields.TIMESTAMP.getName()));    Assert.assertEquals("9223372036854775807", obj.get("Test Long"));    Assert.assertEquals(obj.get("Test FP Number"), String.valueOf(1.234F));    Assert.assertEquals("00:00:0c:07:ac:00", obj.get("smac"));    Assert.assertEquals("2001:cdba::3257:9652", obj.get("Test IPv6"));    Assert.assertEquals("test test test chocolate", obj.get("Test String"));    Assert.assertEquals("123.123.123.123", obj.get("destinationTranslatedAddress"));    JsonNode inner = new ObjectMapper().readTree((String) obj.get("JSON payload"));    Assert.assertEquals("chocolate!", inner.get("test_test_test").asText());}
0
protected boolean validateJsonData(final String jsonSchema, final String jsonData) throws Exception
{    final JsonNode d = JsonLoader.fromString(jsonData);    final JsonNode s = JsonLoader.fromString(jsonSchema);    final JsonSchemaFactory factory = JsonSchemaFactory.byDefault();    JsonValidator v = factory.getValidator();    ProcessingReport report = v.validate(s, d);    return report.toString().contains("success");}
0
private List<JSONObject> parse(String string)
{    List<JSONObject> parse = parser.parse(string.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(parse);    return parse;}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void setUp() throws Exception
{    inputStrings = super.readTestDataFromFile("src/test/resources/logData/FireEyeParserTest.txt");    parser = new BasicFireEyeParser();}
0
public void testParse() throws ParseException
{    for (String inputString : inputStrings) {        JSONObject parsed = parser.parse(inputString.getBytes(StandardCharsets.UTF_8)).get(0);        Assert.assertNotNull(parsed);        JSONParser parser = new JSONParser();        Map json = (Map) parser.parse(parsed.toJSONString());        Assert.assertNotNull(json);        Assert.assertFalse(json.isEmpty());        for (Object o : json.entrySet()) {            Entry entry = (Entry) o;            String key = (String) entry.getKey();            String value = json.get(key).toString();            Assert.assertNotNull(value);        }    }}
0
public void testTimestampParsing() throws ParseException
{    JSONObject parsed = parser.parse(fireeyeMessage.getBytes(StandardCharsets.UTF_8)).get(0);    JSONParser parser = new JSONParser();    Map json = (Map) parser.parse(parsed.toJSONString());    long expectedTimestamp = ZonedDateTime.of(Year.now(ZoneOffset.UTC).getValue(), 3, 19, 5, 24, 39, 0, ZoneOffset.UTC).toInstant().toEpochMilli();    Assert.assertEquals(expectedTimestamp, json.get("timestamp"));}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void setUp() throws Exception
{    inputStrings = super.readTestDataFromFile("src/test/resources/logData/IseParserTest.txt");    parser = new BasicIseParser();    URL schema_url = getClass().getClassLoader().getResource("TestSchemas/IseSchema.json");    super.setSchemaJsonString(super.readSchemaFromFile(schema_url));}
0
public void testParse() throws org.json.simple.parser.ParseException, IOException, ProcessingException
{    for (String inputString : inputStrings) {        JSONObject parsed = parser.parse(inputString.getBytes(StandardCharsets.UTF_8)).get(0);        Assert.assertNotNull(parsed);        JSONParser parser = new JSONParser();        Map<?, ?> json = (Map<?, ?>) parser.parse(parsed.toJSONString());        Assert.assertTrue(validateJsonData(getSchemaJsonString(), json.toString()));    }}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void setUp() throws Exception
{    inputStrings = super.readTestDataFromFile("src/test/resources/logData/LancopeParserTest.txt");    parser = new BasicLancopeParser();    URL schema_url = getClass().getClassLoader().getResource("TestSchemas/LancopeSchema.json");    super.setSchemaJsonString(super.readSchemaFromFile(schema_url));}
0
public void testParse() throws ParseException, IOException, ProcessingException
{    for (String inputString : inputStrings) {        JSONObject parsed = parser.parse(inputString.getBytes(StandardCharsets.UTF_8)).get(0);        Assert.assertNotNull(parsed);        JSONParser parser = new JSONParser();        Map<?, ?> json = (Map<?, ?>) parser.parse(parsed.toJSONString());        Assert.assertTrue(validateJsonData(getSchemaJsonString(), json.toString()));    }}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void setUp()
{    parser = new LEEFParser();    parser.init();}
0
public void testInvalid()
{    List<JSONObject> obj = parse("test test test nonsense\n");    Assert.assertEquals(0, obj.size());}
0
public void testTimestampPriority() throws java.text.ParseException
{    long correctTime = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSz").parse("2016-05-01T09:29:11.356-0400").getTime();    SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSz");    for (JSONObject obj : parse("LEEF:2.0|Lancope|StealthWatch|1.0|41|src=10.0.0.1\tdevTime=May 1 2016 09:29:11.356 -0400\tdst=2.1.2.2\tspt=1232")) {        Assert.assertEquals(new Date(correctTime), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(correctTime, obj.get(Fields.TIMESTAMP.getName()));    }    for (JSONObject obj : parse("2016-06-01T09:29:11.356-04:00 host LEEF:2.0|Lancope|StealthWatch|1.0|41|src=10.0.0.1\tdevTime=May 1 2016 09:29:11.356 -0400\tdst=2.1.2.2\tspt=1232")) {        Assert.assertEquals(new Date(correctTime), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(correctTime, obj.get(Fields.TIMESTAMP.getName()));    }    for (JSONObject obj : parse("2016-05-01T09:29:11.356-04:00 host LEEF:2.0|Lancope|StealthWatch|1.0|41|src=10.0.0.1\tdevTime=May 1 2016 09:29:11.356 -0400\tdst=2.1.2.2\tspt=1232")) {        Assert.assertEquals(new Date(correctTime), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(correctTime, obj.get(Fields.TIMESTAMP.getName()));    }    for (JSONObject obj : parse("LEEF:2.0|Lancope|StealthWatch|1.0|41|src=10.0.0.1\tdevTime=May 1 2016 09:29:11.356 -0400\tdst=2.1.2.2\tspt=1232")) {        Assert.assertNotNull(obj.get(Fields.TIMESTAMP.getName()));    }}
0
private void runMissingYear(Calendar expected, Calendar input)
{    SimpleDateFormat sdf = new SimpleDateFormat("MMM dd HH:mm:ss.SSS");    for (JSONObject obj : parse("LEEF:2.0|Lancope|StealthWatch|1.0|41|\t|src=10.0.0.1\tdevTime=" + sdf.format(input.getTime()) + "\tdevTimeFormat=MMM dd HH:mm:ss.SSS" + "\tdst=2.1.2.2\tspt=1232")) {        Assert.assertEquals(expected.getTime(), new Date((long) obj.get(Fields.TIMESTAMP.getName())));        Assert.assertEquals(expected.getTimeInMillis(), obj.get(Fields.TIMESTAMP.getName()));    }}
0
public void testMissingYearFromDate() throws java.text.ParseException
{    Calendar current = Calendar.getInstance();    Calendar correct = Calendar.getInstance();    correct.setTimeInMillis(current.getTimeInMillis());    runMissingYear(correct, current);}
0
public void testFourDayFutureBecomesPast()
{    Calendar current = Calendar.getInstance();    Calendar correct = Calendar.getInstance();    current.add(Calendar.DAY_OF_MONTH, 5);        correct.setTimeInMillis(current.getTimeInMillis());    correct.add(Calendar.YEAR, -1);    runMissingYear(correct, current);}
0
public void testLEEF_CEFlikeSample()
{    List<JSONObject> parse = parse("LEEF:0|Incapsula|SIEMintegration|0|SQL Injection| fileId=3412364560000000008 sourceServiceName=test56111115.incaptest.co siteid=1333546 suid=300656 requestClientApplication=Mozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0 popName=mia cs2=true cs2Label=Javascript Support cs3=true cs3Label=CO Support cs1=NA cs1Label=Cap Support cs4=936e64c2-bdd1-4719-9bd0-2d882a72f30d cs4Label=VID cs5=bab1712be85b00ab21d20bf0d7b5db82701f27f53fbac19a4252efc722ac9131fdc60c0da620282b02dfb8051e7a60f9 cs5Label=clappsig dproc=Browser cs6=Firefox cs6Label=clapp calCountryOrRegion=IL cicode=Rehovot cs7=31.8969 cs7Label=latitude cs8=34.8186 cs8Label=longitude Customer=siemtest start=1460303291788 url=test56111115.incaptest.co/ requestMethod=GET qstr=keywords\\=3%29%29%29%20AND%203434%3d%28%27%3amvc%3a%27%7c%7c%28SELECT%20CASE%203434%20WHEN%203434%20THEN%201%20ELSE%200%20END%20FROM%20RDB%24DATABASE%29%7c%7c%27%3aqvi%3a%27%29%20AND%20%28%28%283793%3d3793 cn1=200 proto=HTTP cat=REQ_PASSED deviceExternalId=2323800832649 dst=54.195.35.43 dstPort=80 in=406 xff=127.0.0.1 srcPort=443 src=127.0.0.1 protoVer=TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 fileType=12999,50999,50037,50044, filePermission=37,20,1,1, cs9=,High Risk SQL Expressions,,SQL SELECT Expression, cs9Label=Rule name");    JSONObject obj = parse.get(0);    Assert.assertNotNull(obj);    Assert.assertEquals("3412364560000000008", obj.get("fileId"));    Assert.assertEquals("Mozilla/5.0 (Windows NT 6.1; WOW64; rv:38.0) Gecko/20100101 Firefox/38.0", obj.get("requestClientApplication"));    Assert.assertTrue(obj.containsKey("longitude"));    Assert.assertFalse(obj.containsKey("cs8"));    Assert.assertFalse(obj.containsKey("cs8Label"));}
0
public void testLEEFParserSample() throws Exception
{    runTest("sample", Resources.readLines(Resources.getResource(getClass(), "sample.leef"), StandardCharsets.UTF_8), Resources.toString(Resources.getResource(getClass(), "sample.schema"), StandardCharsets.UTF_8));}
0
private void runTest(String name, List<String> lines, String schema) throws Exception
{    runTest(name, lines, schema, "");}
0
private void runTest(String name, List<String> lines, String schema, String targetJson) throws Exception
{    for (String inputString : lines) {        JSONObject parsed = parse(inputString).get(0);        Assert.assertNotNull(parsed);        Assert.assertNotNull(parsed.get(Fields.TIMESTAMP.getName()));        Assert.assertTrue((long) parsed.get(Fields.TIMESTAMP.getName()) > 0);        JSONParser parser = new JSONParser();        Map<?, ?> json = null;        json = (Map<?, ?>) parser.parse(parsed.toJSONString());        Assert.assertEquals(true, validateJsonData(schema, json.toString()));    }}
0
private void assertSimpleSample(List<JSONObject> parse)
{    JSONObject obj = parse.get(0);    Assert.assertNotNull(obj);    Assert.assertTrue(obj.containsKey(Fields.SRC_ADDR.getName()));    Assert.assertEquals("192.0.2.0", obj.get(Fields.SRC_ADDR.getName()));}
0
public void testLEEF_1_0_versionIncluded()
{    List<JSONObject> parse = parse("LEEF:1.0|Microsoft|MSExchange|4.0 SP1|15345| src=192.0.2.0\tdst=172.50.123.1\tsev=5\tcat=anomaly\tsrcPort=81\tdstPort=21\tusrName=joe.black");    assertSimpleSample(parse);}
0
public void testLEEF_2_0()
{    List<JSONObject> parse = parse("LEEF:2.0|Vendor|Product|Version|EventID| src=192.0.2.0\tdst=172.50.123.1\tsev=5\tcat=anomaly\tsrcPort=81\tdstPort=21\tusrName=joe.black");    assertSimpleSample(parse);}
0
public void testLEEF_2_0_delimiterSpecified()
{    List<JSONObject> parse = parse("LEEF:2.0|Lancope|StealthWatch|1.0|41|^| src=192.0.2.0^dst=172.50.123.1^sev=5^cat=anomaly^srcPort=81^dstPort=21^usrName=joe.black");    assertSimpleSample(parse);}
0
public void testLEEF_2_0_delimiterUsedIncorrectly()
{    List<JSONObject> parse = parse("LEEF:2.0|Lancope|StealthWatch|1.0|41|^| src=192.0.2.0\tdst=172.50.123.1\tsev=5\tcat=anomaly\tsrcPort=81\tdstPort=21\tusrName=joe.black");    assertFalse(parse.get(0).containsKey(Fields.DST_ADDR));}
0
public void testLEEFMultiLine()
{    List<JSONObject> parse = parse("LEEF:2.0|Vendor|Product|Version|EventID| src=192.0.2.0\tdst=172.50.123.1\tsev=5\tcat=anomaly\tsrcPort=81\tdstPort=21\tusrName=line1" + "\nLEEF:2.0|Vendor|Product|Version|EventID| src=192.0.2.1\tdst=172.50.123.2\tsev=6\tcat=anomaly\tsrcPort=82\tdstPort=22\tusrName=line2");    assertSimpleSample(parse);    assertEquals(2, parse.size());}
0
public void testLEEFcustomdevTimeFormat()
{    String customFormat = "yyyy-MM-dd HH:mm:ss.SSS zzz";    Date customDate = new Date();    DateFormat customFormatter = new SimpleDateFormat(customFormat);    List<JSONObject> parse = parse("LEEF:2.0|Lancope|StealthWatch|1.0|41|^| src=192.0.2.0^dst=172.50.123.1^sev=5^cat=anomaly^srcPort=81^dstPort=21^usrName=joe.black^devTime=" + customFormatter.format(customDate) + "^devTimeFormat=" + customFormat);    JSONObject obj = parse.get(0);    assertEquals(obj.get(Fields.TIMESTAMP.getName()), customDate.getTime());}
0
public void testLEEFdevTimeWithNoCustomFormat()
{    String standardFormat = "MMM dd yyyy HH:mm:ss.SSS zzz";    Date customDate = new Date();    long expected = customDate.getTime();    DateFormat customFormatter = new SimpleDateFormat(standardFormat);    List<JSONObject> parse = parse("LEEF:2.0|Lancope|StealthWatch|1.0|41|^| src=192.0.2.0^dst=172.50.123.1^sev=5^cat=anomaly^srcPort=81^dstPort=21^usrName=joe.black^devTime=" + customFormatter.format(customDate));    JSONObject obj = parse.get(0);    assertEquals(obj.get(Fields.TIMESTAMP.getName()), expected);}
0
protected boolean validateJsonData(final String jsonSchema, final String jsonData) throws Exception
{    final JsonNode d = JsonLoader.fromString(jsonData);    final JsonNode s = JsonLoader.fromString(jsonSchema);    final JsonSchemaFactory factory = JsonSchemaFactory.byDefault();    JsonValidator v = factory.getValidator();    ProcessingReport report = v.validate(s, d);    return report.toString().contains("success");}
0
private List<JSONObject> parse(String string)
{    Optional<MessageParserResult<JSONObject>> parse = parser.parseOptionalResult(string.getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(parse.isPresent());    return parse.get().getMessages();}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void setUp() throws Exception
{    parser = new BasicPaloAltoFirewallParser();}
0
public void testParseSystem61() throws ParseException
{    final String SYSTEM_61 = "1,2017/08/11 12:37:58,008900008659,SYSTEM,general,1,2017/08/11 11:37:58,vsys1,eventId_test,object_test,Futureuse1_test,futureuse2_test,management,high,Description_test,1354,0x0";    JSONObject actual = parser.parse(SYSTEM_61.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/08/11 12:37:58");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "008900008659");    expected.put(BasicPaloAltoFirewallParser.Type, "SYSTEM");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "general");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/08/11 11:37:58");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.EventId, "eventId_test");    expected.put(BasicPaloAltoFirewallParser.Object, "object_test");    expected.put(BasicPaloAltoFirewallParser.Module, "management");    expected.put(BasicPaloAltoFirewallParser.Severity, "high");    expected.put(BasicPaloAltoFirewallParser.Description, "Description_test");    expected.put(BasicPaloAltoFirewallParser.Seqno, "1354");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 61);    expected.put("original_string", SYSTEM_61);    expected.put("timestamp", actual.get("timestamp"));    assertEquals(expected, actual);}
0
public void testParseSystem80() throws ParseException
{    final String SYSTEM_80 = "1,2017/08/11 12:37:58,008900008659,SYSTEM,general,1,2017/08/11 11:37:58,vsys1,eventId_test,object_test,Futureuse1_test,futureuse2_test,management,high,Description_test,1354,0x0,12,34,45,0,virSys1,dev-something200-01";    JSONObject actual = parser.parse(SYSTEM_80.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/08/11 12:37:58");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "008900008659");    expected.put(BasicPaloAltoFirewallParser.Type, "SYSTEM");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "general");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/08/11 11:37:58");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.EventId, "eventId_test");    expected.put(BasicPaloAltoFirewallParser.Object, "object_test");    expected.put(BasicPaloAltoFirewallParser.Module, "management");    expected.put(BasicPaloAltoFirewallParser.Severity, "high");    expected.put(BasicPaloAltoFirewallParser.Description, "Description_test");    expected.put(BasicPaloAltoFirewallParser.Seqno, "1354");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.DGH1, "12");    expected.put(BasicPaloAltoFirewallParser.DGH2, "34");    expected.put(BasicPaloAltoFirewallParser.DGH3, "45");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.VSYSName, "virSys1");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "dev-something200-01");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 80);    expected.put("original_string", SYSTEM_80);    expected.put("timestamp", actual.get("timestamp"));    assertEquals(expected, actual);}
0
public void testParseConfig61NoCustomFields() throws ParseException
{    final String CONFIG_61_customFields = "1,2017/08/11 12:37:58,008900008659,CONFIG,0,1,2017/08/11 11:37:58,192.168.14.162,vsys1,edit,admin,Web,Succeeded, config shared log-settings config,1354,0x0";    JSONObject actual = parser.parse(CONFIG_61_customFields.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/08/11 12:37:58");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "008900008659");    expected.put(BasicPaloAltoFirewallParser.Type, "CONFIG");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "0");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/08/11 11:37:58");    expected.put(BasicPaloAltoFirewallParser.HOST, "192.168.14.162");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.Command, "edit");    expected.put(BasicPaloAltoFirewallParser.Admin, "admin");    expected.put(BasicPaloAltoFirewallParser.Client, "Web");    expected.put(BasicPaloAltoFirewallParser.Result, "Succeeded");    expected.put(BasicPaloAltoFirewallParser.ConfigurationPath, "config shared log-settings config");    expected.put(BasicPaloAltoFirewallParser.Seqno, "1354");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 61);    expected.put("original_string", CONFIG_61_customFields);    expected.put("timestamp", actual.get("timestamp"));    assertEquals(expected, actual);}
0
public void testParseConfig61CustomFields() throws ParseException
{    final String CONFIG_61_noCustomFields = "1,2017/08/11 12:37:58,008900008659,CONFIG,0,1,2017/08/11 11:37:58,192.168.14.162,vsys1,edit,admin,Web,Succeeded, config shared log-settings config,1354,0x0,/FatherNode/KidNode/GrandsonNode1,/FatherNode/KidNode/GrandsonNode2";    JSONObject actual = parser.parse(CONFIG_61_noCustomFields.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/08/11 12:37:58");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "008900008659");    expected.put(BasicPaloAltoFirewallParser.Type, "CONFIG");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "0");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/08/11 11:37:58");    expected.put(BasicPaloAltoFirewallParser.HOST, "192.168.14.162");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.Command, "edit");    expected.put(BasicPaloAltoFirewallParser.Admin, "admin");    expected.put(BasicPaloAltoFirewallParser.Client, "Web");    expected.put(BasicPaloAltoFirewallParser.Result, "Succeeded");    expected.put(BasicPaloAltoFirewallParser.ConfigurationPath, "config shared log-settings config");    expected.put(BasicPaloAltoFirewallParser.Seqno, "1354");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.BeforeChangeDetail, "/FatherNode/KidNode/GrandsonNode1");    expected.put(BasicPaloAltoFirewallParser.AfterChangeDetail, "/FatherNode/KidNode/GrandsonNode2");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 61);    expected.put("original_string", CONFIG_61_noCustomFields);    expected.put("timestamp", actual.get("timestamp"));    assertEquals(expected, actual);}
0
public void testParseConfig70And80NoCustomFields() throws ParseException
{    final String CONFIG_70_80_noCustomFields = "1,2017/08/11 12:37:58,008900008659,CONFIG,0,1,2017/08/11 11:37:58,192.168.14.162,vsys1,edit,admin,Web,Succeeded, config shared log-settings config,1354,0x0,12,34,45,0,virSys1,dev-something200-01";    JSONObject actual = parser.parse(CONFIG_70_80_noCustomFields.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/08/11 12:37:58");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "008900008659");    expected.put(BasicPaloAltoFirewallParser.Type, "CONFIG");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "0");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/08/11 11:37:58");    expected.put(BasicPaloAltoFirewallParser.HOST, "192.168.14.162");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.Command, "edit");    expected.put(BasicPaloAltoFirewallParser.Admin, "admin");    expected.put(BasicPaloAltoFirewallParser.Client, "Web");    expected.put(BasicPaloAltoFirewallParser.Result, "Succeeded");    expected.put(BasicPaloAltoFirewallParser.ConfigurationPath, "config shared log-settings config");    expected.put(BasicPaloAltoFirewallParser.Seqno, "1354");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.DGH1, "12");    expected.put(BasicPaloAltoFirewallParser.DGH2, "34");    expected.put(BasicPaloAltoFirewallParser.DGH3, "45");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.VSYSName, "virSys1");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "dev-something200-01");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 80);    expected.put("original_string", CONFIG_70_80_noCustomFields);    expected.put("timestamp", actual.get("timestamp"));    assertEquals(expected, actual);}
0
public void testParseConfig70And80CustomFields() throws ParseException
{    final String CONFIG_70_80_customFields = "1,2017/08/11 12:37:58,008900008659,CONFIG,0,1,2017/08/11 11:37:58,192.168.14.162,vsys1,edit,admin,Web,Succeeded,config shared log-settings config,/FatherNode/KidNode/GrandsonNode1,/FatherNode/KidNode/GrandsonNode2,1354,0x0,12,34,45,0,virSys1,dev-something200-01";    JSONObject actual = parser.parse(CONFIG_70_80_customFields.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/08/11 12:37:58");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "008900008659");    expected.put(BasicPaloAltoFirewallParser.Type, "CONFIG");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "0");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/08/11 11:37:58");    expected.put(BasicPaloAltoFirewallParser.HOST, "192.168.14.162");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.Command, "edit");    expected.put(BasicPaloAltoFirewallParser.Admin, "admin");    expected.put(BasicPaloAltoFirewallParser.Client, "Web");    expected.put(BasicPaloAltoFirewallParser.Result, "Succeeded");    expected.put(BasicPaloAltoFirewallParser.ConfigurationPath, "config shared log-settings config");    expected.put(BasicPaloAltoFirewallParser.BeforeChangeDetail, "/FatherNode/KidNode/GrandsonNode1");    expected.put(BasicPaloAltoFirewallParser.AfterChangeDetail, "/FatherNode/KidNode/GrandsonNode2");    expected.put(BasicPaloAltoFirewallParser.Seqno, "1354");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.DGH1, "12");    expected.put(BasicPaloAltoFirewallParser.DGH2, "34");    expected.put(BasicPaloAltoFirewallParser.DGH3, "45");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.VSYSName, "virSys1");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "dev-something200-01");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 80);    expected.put("original_string", CONFIG_70_80_customFields);    expected.put("timestamp", actual.get("timestamp"));    assertEquals(expected, actual);}
0
public void testParseThreat60() throws ParseException
{    JSONObject actual = parser.parse(THREAT_60.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "reset-both");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.Application, "web-browsing");    expected.put(BasicPaloAltoFirewallParser.Category, "any");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.Direction, "client-to-server");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "US");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x80004000");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "internal");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "ethernet1/2");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "216.0.10.198");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "80");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "10.0.0.115");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "54180");    expected.put(BasicPaloAltoFirewallParser.LogAction, "LOG-Default");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "0");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "0.0.0.0");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "0");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "0.0.0.0");    expected.put("original_string", THREAT_60);    expected.put(BasicPaloAltoFirewallParser.OutboundInterface, "ethernet1/1");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 60);    expected.put(BasicPaloAltoFirewallParser.PCAPID, "1200568889751109656");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "tcp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2015/01/05 05:38:58");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "EX-Allow");    expected.put(BasicPaloAltoFirewallParser.Seqno, "347368099");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "0006C110285");    expected.put(BasicPaloAltoFirewallParser.SessionID, "12031");    expected.put(BasicPaloAltoFirewallParser.Severity, "high");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "10.0.0.0-10.255.255.255");    expected.put(BasicPaloAltoFirewallParser.SourceUser, "example\\user.name");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2015/01/05 05:38:58");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "vulnerability");    expected.put(BasicPaloAltoFirewallParser.ThreatID, "HTTP: IIS Denial Of Service Attempt(40019)");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2015/01/05 05:38:58");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "external");    expected.put(BasicPaloAltoFirewallParser.Type, "THREAT");    expected.put(BasicPaloAltoFirewallParser.URL, "ad.aspx?f=300x250&id=12;tile=1;ord=67AF705D60B1119C0F18BEA336F9");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    assertEquals(expected, actual);}
0
public void testParseTraffic60() throws ParseException
{    JSONObject actual = parser.parse(TRAFFIC_60.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "allow");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.Application, "ms-ds-smb");    expected.put(BasicPaloAltoFirewallParser.Bytes, "2229");    expected.put(BasicPaloAltoFirewallParser.BytesReceived, "942");    expected.put(BasicPaloAltoFirewallParser.BytesSent, "1287");    expected.put(BasicPaloAltoFirewallParser.Category, "any");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "10.0.0.0-10.255.255.255");    expected.put(BasicPaloAltoFirewallParser.DestinationUser, "example\\\\user.name");    expected.put(BasicPaloAltoFirewallParser.ElapsedTimeInSec, "30");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x401a");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "v_external");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "ethernet1/2");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "10.1.0.163");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "445");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "10.0.0.39");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "52688");    expected.put(BasicPaloAltoFirewallParser.LogAction, "LOG-Default");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "0");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "0.0.0.0");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "0");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "0.0.0.0");    expected.put("original_string", TRAFFIC_60);    expected.put(BasicPaloAltoFirewallParser.OutboundInterface, "ethernet1/1");    expected.put(BasicPaloAltoFirewallParser.Packets, "10");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 60);    expected.put(BasicPaloAltoFirewallParser.PktsSent, "6");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "tcp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2015/01/05 12:51:33");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "EX-Allow");    expected.put(BasicPaloAltoFirewallParser.Seqno, "17754932062");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "0011C103117");    expected.put(BasicPaloAltoFirewallParser.SessionID, "33760927");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "10.0.0.0-10.255.255.255");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2015/01/05 12:51:01");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "end");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2015/01/05 12:51:33");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "v_internal");    expected.put(BasicPaloAltoFirewallParser.Type, "TRAFFIC");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    assertEquals(expected, actual);}
0
public void testParseThreat70() throws ParseException
{    JSONObject actual = parser.parse(THREAT_70.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "reset-both");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.Application, "web-browsing");    expected.put(BasicPaloAltoFirewallParser.Category, "computer-and-internet-info");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "0");    expected.put(BasicPaloAltoFirewallParser.Direction, "server-to-client");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "10.0.0.0-10.255.255.255");    expected.put(BasicPaloAltoFirewallParser.DestinationUser, "user");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x400000");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "Untrust");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "ethernet1/1");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "10.1.8.7");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "51787");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "217.1.2.3");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "80");    expected.put(BasicPaloAltoFirewallParser.LogAction, "Std-Log-Forward");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "25025");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "214.123.1.2");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "80");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "217.1.2.3");    expected.put("original_string", THREAT_70);    expected.put(BasicPaloAltoFirewallParser.OutboundInterface, "vlan.1");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 70);    expected.put(BasicPaloAltoFirewallParser.PCAPID, "0");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "tcp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/05/24 09:53:10");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "WLAN-Internet");    expected.put(BasicPaloAltoFirewallParser.Seqno, "329423829");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "001801000001");    expected.put(BasicPaloAltoFirewallParser.SessionID, "49567");    expected.put(BasicPaloAltoFirewallParser.Severity, "medium");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "DE");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2017/05/24 09:53:10");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "virus");    expected.put(BasicPaloAltoFirewallParser.ThreatID, "Virus/Win32.WGeneric.lumeo(2457399)");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/05/24 09:53:10");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "wifi_zone");    expected.put(BasicPaloAltoFirewallParser.Type, "THREAT");    expected.put(BasicPaloAltoFirewallParser.URL, "abcdef310.exe");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.URLIndex, "1");    expected.put(BasicPaloAltoFirewallParser.WFReportID, "0");    expected.put(BasicPaloAltoFirewallParser.DGH1, "19");    expected.put(BasicPaloAltoFirewallParser.DGH2, "0");    expected.put(BasicPaloAltoFirewallParser.DGH3, "0");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "PAN1");    assertEquals(expected, actual);}
0
public void testParseTraffic70() throws ParseException
{    JSONObject actual = parser.parse(TRAFFIC_70.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "deny");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.ActionSource, "from-policy");    expected.put(BasicPaloAltoFirewallParser.Application, "not-applicable");    expected.put(BasicPaloAltoFirewallParser.Bytes, "114");    expected.put(BasicPaloAltoFirewallParser.BytesReceived, "0");    expected.put(BasicPaloAltoFirewallParser.BytesSent, "114");    expected.put(BasicPaloAltoFirewallParser.Category, "any");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "DE");    expected.put(BasicPaloAltoFirewallParser.ElapsedTimeInSec, "0");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x0");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "intern");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "vlan.1");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "192.168.1.10");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "137");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "10.2.1.8");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "137");    expected.put(BasicPaloAltoFirewallParser.LogAction, "Std-Log-Forward");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "0");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "0.0.0.0");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "0");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "0.0.0.0");    expected.put("original_string", TRAFFIC_70);    expected.put(BasicPaloAltoFirewallParser.Packets, "1");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 70);    expected.put(BasicPaloAltoFirewallParser.PktsReceived, "0");    expected.put(BasicPaloAltoFirewallParser.PktsSent, "1");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "udp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/05/25 21:38:13");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "DropLog");    expected.put(BasicPaloAltoFirewallParser.Seqno, "9953744");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "001606000003");    expected.put(BasicPaloAltoFirewallParser.EndReason, "policy-deny");    expected.put(BasicPaloAltoFirewallParser.SessionID, "0");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "192.168.0.0-192.168.255.255");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2017/05/25 21:38:12");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "drop");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/05/25 21:38:13");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "VPN");    expected.put(BasicPaloAltoFirewallParser.Type, "TRAFFIC");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.DGH1, "19");    expected.put(BasicPaloAltoFirewallParser.DGH2, "0");    expected.put(BasicPaloAltoFirewallParser.DGH3, "0");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "PAN1");    assertEquals(expected, actual);}
0
public void testParseTraffic71() throws ParseException
{    JSONObject actual = parser.parse(TRAFFIC_71.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "deny");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.ActionSource, "from-policy");    expected.put(BasicPaloAltoFirewallParser.Application, "not-applicable");    expected.put(BasicPaloAltoFirewallParser.Bytes, "60");    expected.put(BasicPaloAltoFirewallParser.BytesReceived, "0");    expected.put(BasicPaloAltoFirewallParser.BytesSent, "60");    expected.put(BasicPaloAltoFirewallParser.Category, "any");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "0");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "DE");    expected.put(BasicPaloAltoFirewallParser.ElapsedTimeInSec, "0");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x0");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "untrust");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "vlan.1");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "201.1.4.5");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "123");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "185.94.1.1");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "59836");    expected.put(BasicPaloAltoFirewallParser.LogAction, "Standard-Syslog");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "0");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "0.0.0.0");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "0");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "0.0.0.0");    expected.put("original_string", TRAFFIC_71);    expected.put(BasicPaloAltoFirewallParser.Packets, "1");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 70);    expected.put(BasicPaloAltoFirewallParser.PktsReceived, "0");    expected.put(BasicPaloAltoFirewallParser.PktsSent, "1");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "udp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/05/31 23:59:57");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "DropLog");    expected.put(BasicPaloAltoFirewallParser.Seqno, "3433072193");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "0006C000005");    expected.put(BasicPaloAltoFirewallParser.EndReason, "policy-deny");    expected.put(BasicPaloAltoFirewallParser.SessionID, "0");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "RU");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2017/05/31 23:59:57");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "drop");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/05/31 23:59:57");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "untrust");    expected.put(BasicPaloAltoFirewallParser.Type, "TRAFFIC");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.DGH1, "16");    expected.put(BasicPaloAltoFirewallParser.DGH2, "11");    expected.put(BasicPaloAltoFirewallParser.DGH3, "0");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "PAN1");    assertEquals(expected, actual);}
0
public void testParseThreat71() throws ParseException
{    JSONObject actual = parser.parse(THREAT_71.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "alert");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.Application, "ssl");    expected.put(BasicPaloAltoFirewallParser.Category, "computer-and-internet-info");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "0");    expected.put(BasicPaloAltoFirewallParser.Direction, "client-to-server");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "IE");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x40b000");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "mgmt");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "vlan.199");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "140.177.26.29");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "443");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "192.168.1.7");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "56059");    expected.put(BasicPaloAltoFirewallParser.LogAction, "Standard-Syslog");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "443");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "140.177.26.29");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "14810");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "201.1.4.5");    expected.put("original_string", THREAT_71);    expected.put(BasicPaloAltoFirewallParser.OutboundInterface, "vlan.1");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 70);    expected.put(BasicPaloAltoFirewallParser.PCAPID, "0");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "tcp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2017/05/25 19:31:13");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "ms_out");    expected.put(BasicPaloAltoFirewallParser.Seqno, "10030265");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "0006C000005");    expected.put(BasicPaloAltoFirewallParser.SessionID, "50556");    expected.put(BasicPaloAltoFirewallParser.Severity, "informational");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "192.168.0.0-192.168.255.255");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2017/05/25 19:31:13");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "url");    expected.put(BasicPaloAltoFirewallParser.ThreatID, "(9999)");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2017/05/25 19:31:13");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "untrust");    expected.put(BasicPaloAltoFirewallParser.Type, "THREAT");    expected.put(BasicPaloAltoFirewallParser.URL, "settings-win.data.microsoft.com/");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.URLIndex, "0");    expected.put(BasicPaloAltoFirewallParser.WFReportID, "0");    expected.put(BasicPaloAltoFirewallParser.DGH1, "16");    expected.put(BasicPaloAltoFirewallParser.DGH2, "11");    expected.put(BasicPaloAltoFirewallParser.DGH3, "0");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "PAN1");    assertEquals(expected, actual);}
0
public void testParseThreat80() throws ParseException
{    JSONObject actual = parser.parse(THREAT_80.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "reset-server");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.Application, "web-browsing");    expected.put(BasicPaloAltoFirewallParser.Category, "computer-and-internet-info");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.ContentVersion, "AppThreat-771-4450");    expected.put(BasicPaloAltoFirewallParser.Direction, "server-to-client");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "172.16.0.0-172.31.255.255");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x402000");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "internet");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "ethernet1/1");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "172.16.2.6");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "53161");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "213.211.198.62");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "80");    expected.put(BasicPaloAltoFirewallParser.LogAction, "test");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "32812");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "192.168.178.202");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "80");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "213.211.198.62");    expected.put("original_string", THREAT_80);    expected.put(BasicPaloAltoFirewallParser.OutboundInterface, "ethernet1/2.2");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParentSessionId, "0");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 80);    expected.put(BasicPaloAltoFirewallParser.PCAPID, "0");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "tcp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2018/02/01 21:29:03");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "Outgoing");    expected.put(BasicPaloAltoFirewallParser.Seqno, "27438839");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "001606000007");    expected.put(BasicPaloAltoFirewallParser.SessionID, "18720");    expected.put(BasicPaloAltoFirewallParser.Severity, "medium");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "Germany");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2018/02/01 21:29:03");    expected.put(BasicPaloAltoFirewallParser.ThreatCategory, "code-execution");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "vulnerability");    expected.put(BasicPaloAltoFirewallParser.ThreatID, "Eicar File Detected(39040)");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2018/02/01 21:29:03");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "guest");    expected.put(BasicPaloAltoFirewallParser.TunnelId, "0");    expected.put(BasicPaloAltoFirewallParser.TunnelType, "N/A");    expected.put(BasicPaloAltoFirewallParser.Type, "THREAT");    expected.put(BasicPaloAltoFirewallParser.URL, "www.eicar.org/download/eicar.com");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.URLIndex, "9");    expected.put(BasicPaloAltoFirewallParser.WFReportID, "0");    expected.put(BasicPaloAltoFirewallParser.DGH1, "0");    expected.put(BasicPaloAltoFirewallParser.DGH2, "0");    expected.put(BasicPaloAltoFirewallParser.DGH3, "0");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "PAN1");    assertEquals(expected, actual);}
0
public void testParseTraffic80() throws ParseException
{    JSONObject actual = parser.parse(TRAFFIC_80.getBytes(StandardCharsets.UTF_8)).get(0);    JSONObject expected = new JSONObject();    expected.put(BasicPaloAltoFirewallParser.Action, "allow");    expected.put(BasicPaloAltoFirewallParser.ActionFlags, "0x0");    expected.put(BasicPaloAltoFirewallParser.ActionSource, "from-policy");    expected.put(BasicPaloAltoFirewallParser.Application, "ssl");    expected.put(BasicPaloAltoFirewallParser.Bytes, "7936");    expected.put(BasicPaloAltoFirewallParser.BytesReceived, "6205");    expected.put(BasicPaloAltoFirewallParser.BytesSent, "1731");    expected.put(BasicPaloAltoFirewallParser.Category, "computer-and-internet-info");    expected.put(BasicPaloAltoFirewallParser.ConfigVersion, "1");    expected.put(BasicPaloAltoFirewallParser.DestinationLocation, "United States");    expected.put(BasicPaloAltoFirewallParser.ElapsedTimeInSec, "1395");    expected.put(BasicPaloAltoFirewallParser.Flags, "0x40001c");    expected.put(BasicPaloAltoFirewallParser.SourceZone, "guest");    expected.put(BasicPaloAltoFirewallParser.InboundInterface, "ethernet1/2.2");    expected.put(BasicPaloAltoFirewallParser.DestinationAddress, "134.19.6.22");    expected.put(BasicPaloAltoFirewallParser.DestinationPort, "443");    expected.put(BasicPaloAltoFirewallParser.SourceAddress, "172.16.2.31");    expected.put(BasicPaloAltoFirewallParser.SourcePort, "41537");    expected.put(BasicPaloAltoFirewallParser.LogAction, "test");    expected.put(BasicPaloAltoFirewallParser.NATDestinationPort, "443");    expected.put(BasicPaloAltoFirewallParser.NATDestinationIP, "134.19.6.22");    expected.put(BasicPaloAltoFirewallParser.NATSourcePort, "12211");    expected.put(BasicPaloAltoFirewallParser.NATSourceIP, "192.168.18.2");    expected.put("original_string", TRAFFIC_80);    expected.put(BasicPaloAltoFirewallParser.OutboundInterface, "ethernet1/1");    expected.put(BasicPaloAltoFirewallParser.Packets, "24");    expected.put(BasicPaloAltoFirewallParser.PaloAltoDomain, "1");    expected.put(BasicPaloAltoFirewallParser.ParentSessionId, "0");    expected.put(BasicPaloAltoFirewallParser.ParserVersion, 80);    expected.put(BasicPaloAltoFirewallParser.PktsReceived, "10");    expected.put(BasicPaloAltoFirewallParser.PktsSent, "14");    expected.put(BasicPaloAltoFirewallParser.IPProtocol, "tcp");    expected.put(BasicPaloAltoFirewallParser.ReceiveTime, "2018/02/01 21:24:11");    expected.put(BasicPaloAltoFirewallParser.RepeatCount, "1");    expected.put(BasicPaloAltoFirewallParser.Rule, "Outgoing");    expected.put(BasicPaloAltoFirewallParser.Seqno, "62977478");    expected.put(BasicPaloAltoFirewallParser.SerialNum, "001606000007");    expected.put(BasicPaloAltoFirewallParser.EndReason, "tcp-rst-from-client");    expected.put(BasicPaloAltoFirewallParser.SessionID, "19468");    expected.put(BasicPaloAltoFirewallParser.SourceLocation, "172.16.0.0-172.31.255.255");    expected.put(BasicPaloAltoFirewallParser.StartTime, "2018/02/01 21:00:42");    expected.put(BasicPaloAltoFirewallParser.ThreatContentType, "end");    expected.put(BasicPaloAltoFirewallParser.GenerateTime, "2018/02/01 21:24:11");    expected.put("timestamp", actual.get("timestamp"));    expected.put(BasicPaloAltoFirewallParser.DestinationZone, "internet");    expected.put(BasicPaloAltoFirewallParser.TunnelId, "0");    expected.put(BasicPaloAltoFirewallParser.TunnelType, "N/A");    expected.put(BasicPaloAltoFirewallParser.Type, "TRAFFIC");    expected.put(BasicPaloAltoFirewallParser.VirtualSystem, "vsys1");    expected.put(BasicPaloAltoFirewallParser.DGH1, "0");    expected.put(BasicPaloAltoFirewallParser.DGH2, "0");    expected.put(BasicPaloAltoFirewallParser.DGH3, "0");    expected.put(BasicPaloAltoFirewallParser.DGH4, "0");    expected.put(BasicPaloAltoFirewallParser.DeviceName, "PAN1");    assertEquals(expected, actual);}
0
public void testParseInvalidLogTypeMessage() throws ParseException
{    final String unsupportedLogTypeMessage = "1,2017/08/11 12:37:58,008900008659,INVALIDlogType,0,1,2017/08/11 11:37:58,192.168.14.162,vsys1,edit,admin,Web,Succeeded, config shared log-settings config,1354,0x0";    List<JSONObject> actual = parser.parse(unsupportedLogTypeMessage.getBytes(StandardCharsets.UTF_8));    assertNull(actual);}
0
public void testParseInvalidVersionMessage() throws ParseException
{    final String invalidLengthMessage = "1,2017/08/11 12:37:58,008900008659,CONFIG,0,1,2017/08/11 11:37:58,192.168.14.162,vsys1,edit,admin,Web,Succeeded, config shared log-settings config";    JSONObject actual = parser.parse(invalidLengthMessage.getBytes(StandardCharsets.UTF_8)).get(0);    String expectedParserVersion = actual.get(BasicPaloAltoFirewallParser.ParserVersion).toString();    assertEquals(expectedParserVersion, "0");}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void testGoodMessage()
{    BasicSnortParser parser = new BasicSnortParser();    parser.configure(new HashMap());    Map out = parser.parse(goodMessage.getBytes(StandardCharsets.UTF_8)).get(0);    Assert.assertEquals(out.get("msg"), "Consecutive TCP small segments, exceeding threshold");    Assert.assertEquals(out.get("sig_rev"), "1");    Assert.assertEquals(out.get("ip_dst_addr"), "10.0.2.15");    Assert.assertEquals(out.get("ip_dst_port"), "22");    Assert.assertEquals(out.get("ethsrc"), "52:54:00:12:35:02");    Assert.assertEquals(out.get("tcpseq"), "0x9AFF3D7");    Assert.assertEquals(out.get("dgmlen"), "64");    Assert.assertEquals(out.get("icmpid"), "");    Assert.assertEquals(out.get("tcplen"), "");    Assert.assertEquals(out.get("tcpwindow"), "0xFFFF");    Assert.assertEquals(out.get("icmpseq").toString().trim(), "");    Assert.assertEquals(out.get("tcpack"), "0xC8761D52");    Assert.assertEquals(out.get("icmpcode"), "");    Assert.assertEquals(out.get("tos"), "0");    Assert.assertEquals(out.get("id"), "59677");    Assert.assertEquals(out.get("ethdst"), "08:00:27:7F:93:2D");    Assert.assertEquals(out.get("ip_src_addr"), "10.0.2.2");    Assert.assertEquals(out.get("ttl"), "64");    Assert.assertEquals(out.get("ethlen"), "0x4E");    Assert.assertEquals(out.get("iplen"), "65536");    Assert.assertEquals(out.get("icmptype"), "");    Assert.assertEquals(out.get("protocol"), "TCP");    Assert.assertEquals(out.get("ip_src_port"), "56642");    Assert.assertEquals(out.get("tcpflags"), "***AP***");    Assert.assertEquals(out.get("sig_id"), "12");    Assert.assertEquals(out.get("sig_generator"), "129");    Assert.assertEquals(out.get("is_alert"), "true");}
0
public void testBadMessage()
{    thrown.expect(IllegalStateException.class);    BasicSnortParser parser = new BasicSnortParser();    parser.init();    UnitTestHelper.setLog4jLevel(BasicSnortParser.class, Level.FATAL);    parser.parse("foo bar".getBytes(StandardCharsets.UTF_8));    UnitTestHelper.setLog4jLevel(BasicSnortParser.class, Level.ERROR);}
0
public void parses_timestamp_as_local_zone_by_default()
{        TimeZone defaultTimeZone = TimeZone.getDefault();    try {        TimeZone.setDefault(TimeZone.getTimeZone(ZoneId.of("America/New_York")));        BasicSnortParser parser = new BasicSnortParser();        parser.configure(new HashMap());        Map out = parser.parse(goodMessage.getBytes(StandardCharsets.UTF_8)).get(0);        Assert.assertEquals(out.get("timestamp"), 1453928464877L);    } finally {                TimeZone.setDefault(defaultTimeZone);    }}
0
public void uses_configuration_to_parse()
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("dateFormat", "MM/dd/yyyy-HH:mm:ss.SSSSSS");    parserConfig.put("timeZone", "America/New_York");    BasicSnortParser parser = new BasicSnortParser();    parser.configure(parserConfig);    Map result = parser.parse(dateFormattedMessage.getBytes(StandardCharsets.UTF_8)).get(0);    assertThat("timestamp should match", result.get(Constants.Fields.TIMESTAMP.getName()), equalTo(1453928464877L));}
0
public void throws_exception_on_bad_config_timezone()
{    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage(startsWith("Unable to find ZoneId"));    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("dateFormat", "MM/dd/yyyy-HH:mm:ss.SSSSSS");    parserConfig.put("timeZone", "blahblahBADZONE");    BasicSnortParser parser = new BasicSnortParser();    parser.configure(parserConfig);}
0
public void throws_exception_on_bad_config_date_format()
{    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage(startsWith("Unknown pattern letter:"));    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("dateFormat", "BADFORMAT");    BasicSnortParser parser = new BasicSnortParser();    parser.configure(parserConfig);}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    BasicSnortParser parser = new BasicSnortParser();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    BasicSnortParser parser = new BasicSnortParser();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void setUp() throws Exception
{    inputStrings = super.readTestDataFromFile("src/test/resources/logData/SourcefireParserTest.txt");    parser = new BasicSourcefireParser();}
0
public void testParse() throws ParseException
{    for (String inputString : inputStrings) {        byte[] srcBytes = inputString.getBytes(StandardCharsets.UTF_8);        JSONObject parsed = parser.parse(inputString.getBytes(StandardCharsets.UTF_8)).get(0);        Assert.assertNotNull(parsed);        JSONParser parser = new JSONParser();        Map json = (Map) parser.parse(parsed.toJSONString());        for (Object o : json.entrySet()) {            Entry entry = (Entry) o;            String key = (String) entry.getKey();            String value = json.get("original_string").toString();            Assert.assertNotNull(value);        }    }}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public Map<String, String> getTestData()
{    String input1 = "1461576382.642    161 127.0.0.1 TCP_MISS/200 103701 GET http://www.cnn.com/ - DIRECT/199.27.79.73 text/html";    String input2 = "1469539185.270      0 139.196.181.68 TCP_DENIED/403 3617 CONNECT search.yahoo.com:443 - NONE/- text/html";    HashMap testData = new HashMap<String, String>();    testData.put(input1, result1);    testData.put(input2, result2);    return testData;}
0
public String getMultiLine()
{    return "false";}
0
public String getGrokPath()
{    return "../metron-parsers/src/main/resources/patterns/squid";}
0
public String getGrokPatternLabel()
{    return "SQUID_DELIMITED";}
0
public List<String> getTimeFields()
{    return new ArrayList<>();}
0
public String getDateFormat()
{    return null;}
0
public String getTimestampField()
{    return "timestamp";}
0
public void setup()
{    parserConfig = new HashMap<>();    parserConfig.put("grokPath", "src/main/resources/patterns/websphere");    parserConfig.put("patternLabel", "WEBSPHERE");    parserConfig.put("timestampField", "timestamp_string");    parserConfig.put("dateFormat", "yyyy MMM dd HH:mm:ss");    parser = new GrokWebSphereParser();    parser.configure(parserConfig);}
0
public void testParseLoginLine() throws Exception
{    String testString = "<133>Apr 15 17:47:28 ABCXML1413 [rojOut][0x81000033][auth][notice] user(rick007): " + "[120.43.200.6]: User logged into 'cohlOut'.";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 17, 47, 28, 0, UTC).toInstant().toEpochMilli();        assertEquals(133, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("ABCXML1413", parsedJSON.get("hostname"));    assertEquals("rojOut", parsedJSON.get("security_domain"));    assertEquals("0x81000033", parsedJSON.get("event_code"));    assertEquals("auth", parsedJSON.get("event_type"));    assertEquals("notice", parsedJSON.get("severity"));    assertEquals("login", parsedJSON.get("event_subtype"));    assertEquals("rick007", parsedJSON.get("username"));    assertEquals("120.43.200.6", parsedJSON.get("ip_src_addr"));}
0
public void testParseLogoutLine() throws Exception
{    String testString = "<134>Apr 15 18:02:27 PHIXML3RWD [0x81000019][auth][info] [14.122.2.201]: " + "User 'hjpotter' logged out from 'default'.";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 18, 2, 27, 0, UTC).toInstant().toEpochMilli();        assertEquals(134, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("PHIXML3RWD", parsedJSON.get("hostname"));    assertEquals("0x81000019", parsedJSON.get("event_code"));    assertEquals("auth", parsedJSON.get("event_type"));    assertEquals("info", parsedJSON.get("severity"));    assertEquals("14.122.2.201", parsedJSON.get("ip_src_addr"));    assertEquals("hjpotter", parsedJSON.get("username"));    assertEquals("default", parsedJSON.get("security_domain"));}
0
public void testParseRBMLine() throws Exception
{    String testString = "<131>Apr 15 17:36:35 ROBXML3QRS [0x80800018][auth][error] rbm(RBM-Settings): " + "trans(3502888135)[request] gtid(3502888135): RBM: Resource access denied.";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 17, 36, 35, 0, UTC).toInstant().toEpochMilli();        assertEquals(131, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("ROBXML3QRS", parsedJSON.get("hostname"));    assertEquals("0x80800018", parsedJSON.get("event_code"));    assertEquals("auth", parsedJSON.get("event_type"));    assertEquals("error", parsedJSON.get("severity"));    assertEquals("rbm", parsedJSON.get("process"));    assertEquals("trans(3502888135)[request] gtid(3502888135): RBM: Resource access denied.", parsedJSON.get("message"));}
0
public void testParseOtherLine() throws Exception
{    String testString = "<134>Apr 15 17:17:34 SAGPXMLQA333 [0x8240001c][audit][info] trans(191): (admin:default:system:*): " + "ntp-service 'NTP Service' - Operational state down";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 17, 17, 34, 0, UTC).toInstant().toEpochMilli();        assertEquals(134, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("SAGPXMLQA333", parsedJSON.get("hostname"));    assertEquals("0x8240001c", parsedJSON.get("event_code"));    assertEquals("audit", parsedJSON.get("event_type"));    assertEquals("info", parsedJSON.get("severity"));    assertEquals("trans", parsedJSON.get("process"));    assertEquals("(admin:default:system:*): ntp-service 'NTP Service' - Operational state down", parsedJSON.get("message"));}
0
public void testParseMalformedLoginLine() throws Exception
{    String testString = "<133>Apr 15 17:47:28 ABCXML1413 [rojOut][0x81000033][auth][notice] rick007): " + "[120.43.200. User logged into 'cohlOut'.";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 17, 47, 28, 0, UTC).toInstant().toEpochMilli();        assertEquals(133, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("ABCXML1413", parsedJSON.get("hostname"));    assertEquals("rojOut", parsedJSON.get("security_domain"));    assertEquals("0x81000033", parsedJSON.get("event_code"));    assertEquals("auth", parsedJSON.get("event_type"));    assertEquals("notice", parsedJSON.get("severity"));    assertEquals("login", parsedJSON.get("event_subtype"));    assertEquals(null, parsedJSON.get("username"));    assertEquals(null, parsedJSON.get("ip_src_addr"));}
0
public void testParseMalformedLogoutLine() throws Exception
{    String testString = "<134>Apr 15 18:02:27 PHIXML3RWD [0x81000019][auth][info] [14.122.2.201: " + "User 'hjpotter' logged out from 'default.";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 18, 2, 27, 0, UTC).toInstant().toEpochMilli();        assertEquals(134, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("PHIXML3RWD", parsedJSON.get("hostname"));    assertEquals("0x81000019", parsedJSON.get("event_code"));    assertEquals("auth", parsedJSON.get("event_type"));    assertEquals("info", parsedJSON.get("severity"));    assertEquals(null, parsedJSON.get("ip_src_addr"));    assertEquals(null, parsedJSON.get("username"));    assertEquals(null, parsedJSON.get("security_domain"));}
0
public void testParseMalformedRBMLine() throws Exception
{    String testString = "<131>Apr 15 17:36:35 ROBXML3QRS [0x80800018][auth][error] rbmRBM-Settings): " + "trans3502888135)[request] gtid3502888135) RBM: Resource access denied.";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 17, 36, 35, 0, UTC).toInstant().toEpochMilli();        assertEquals(131, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("ROBXML3QRS", parsedJSON.get("hostname"));    assertEquals("0x80800018", parsedJSON.get("event_code"));    assertEquals("auth", parsedJSON.get("event_type"));    assertEquals("error", parsedJSON.get("severity"));    assertEquals(null, parsedJSON.get("process"));    assertEquals("rbmRBM-Settings): trans3502888135)[request] gtid3502888135) RBM: Resource access denied.", parsedJSON.get("message"));}
0
public void testParseMalformedOtherLine() throws Exception
{    String testString = "<134>Apr 15 17:17:34 SAGPXMLQA333 [0x8240001c][audit][info] trans 191)  admindefaultsystem*): " + "ntp-service 'NTP Service' - Operational state down:";    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(testString.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> result = resultOptional.get().getMessages();    JSONObject parsedJSON = result.get(0);    long expectedTimestamp = ZonedDateTime.of(Year.now(UTC).getValue(), 4, 15, 17, 17, 34, 0, UTC).toInstant().toEpochMilli();        assertEquals(134, parsedJSON.get("priority"));    assertEquals(expectedTimestamp, parsedJSON.get("timestamp"));    assertEquals("SAGPXMLQA333", parsedJSON.get("hostname"));    assertEquals("0x8240001c", parsedJSON.get("event_code"));    assertEquals("audit", parsedJSON.get("event_type"));    assertEquals("info", parsedJSON.get("severity"));    assertEquals(null, parsedJSON.get("process"));    assertEquals("trans 191)  admindefaultsystem*): ntp-service 'NTP Service' - Operational state down:", parsedJSON.get("message"));}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public Map getTestData()
{    Map testData = new HashMap<String, String>();    String input = "2016-01-28 15:29:48.512|2016-01-28 15:29:48.512|   0.000|   0.000|  6|                          216.21.170.221|   80|                               10.0.2.15|39468|      AS|       0|       0|       0|22efa001|00000000|000|000|       1|      44|       0|       0|    0|idle";    testData.put(input, result);    return testData;}
0
public String getMultiLine()
{    return "false";}
0
public String getGrokPath()
{    return "../metron-parsers/src/main/resources/patterns/yaf";}
0
public String getGrokPatternLabel()
{    return "YAF_DELIMITED";}
0
public List<String> getTimeFields()
{    return new ArrayList<String>() {        {            add("start_time");            add("end_time");        }    };}
0
public String getDateFormat()
{    return "yyyy-MM-dd HH:mm:ss.S";}
0
public String getTimestampField()
{    return "start_time";}
0
public boolean validate(JSONObject message)
{    JSONObject value = message;    final String invalidMessageTemplate = "[Metron] Message does not have {}: {}";    if (!(value.containsKey(ORIGINAL.getName()))) {        LOG.trace(invalidMessageTemplate, ORIGINAL.getName(), message);        return false;    } else if (!(value.containsKey(TIMESTAMP.getName()))) {        LOG.trace(invalidMessageTemplate, TIMESTAMP.getName(), message);        return false;    } else {        LOG.trace("[Metron] Message conforms to schema: {}", message);        return true;    }}
0
public String getKey(JSONObject value)
{    try {        String ipSrcAddr = null;        String ipDstAddr = null;        if (value.containsKey(SRC_ADDR.getName()))            ipSrcAddr = value.get(SRC_ADDR.getName()).toString();        if (value.containsKey(DST_ADDR.getName()))            ipDstAddr = value.get(DST_ADDR.getName()).toString();        if (ipSrcAddr == null && ipDstAddr == null)            return "0";        if (ipSrcAddr == null || ipSrcAddr.length() == 0)            return ipDstAddr;        if (ipDstAddr == null || ipDstAddr.length() == 0)            return ipSrcAddr;        double ip1 = Double.parseDouble(ipSrcAddr.replace(".", ""));        double ip2 = Double.parseDouble(ipDstAddr.replace(".", ""));        return String.valueOf(ip1 + ip2);    } catch (Exception e) {        return "0";    }}
0
public void setReadCharset(Map<String, Object> config)
{    if (config.containsKey(READ_CHARSET)) {        readCharset = Charset.forName((String) config.get(READ_CHARSET));    } else {        readCharset = MessageParser.super.getReadCharset();    }}
0
public Charset getReadCharset()
{    return null == this.readCharset ? MessageParser.super.getReadCharset() : this.readCharset;}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);    converter = new CSVConverter();    converter.initialize(parserConfig);    Object tsFormatObj = parserConfig.get(TIMESTAMP_FORMAT_CONF);    if (tsFormatObj != null) {        timestampFormat = new SimpleDateFormat(tsFormatObj.toString());    }}
0
public void init()
{}
0
public List<JSONObject> parse(byte[] rawMessage)
{    try {        String msg = new String(rawMessage, getReadCharset());        Map<String, String> value = converter.toMap(msg);        if (value != null) {            value.put("original_string", msg);            Object timestampObj = value.get("timestamp");            Long timestamp = null;            if (timestampObj == null) {                timestamp = System.currentTimeMillis();            } else {                if (timestampFormat == null) {                    timestamp = ConversionUtils.convert(timestampObj, Long.class);                } else {                    try {                        timestamp = timestampFormat.parse(timestampObj.toString()).getTime();                    } catch (Exception e) {                                            }                }            }            JSONObject jsonVal = new JSONObject(value);            if (timestamp != null) {                jsonVal.put("timestamp", timestamp);            }            return ImmutableList.of(jsonVal);        } else {            return Collections.emptyList();        }    } catch (Throwable e) {        String message = "Unable to parse " + new String(rawMessage, getReadCharset()) + ": " + e.getMessage();                throw new IllegalStateException(message, e);    }}
1
public void addMessage(T message)
{    messages.add(message);}
0
public void addError(Object message, Throwable throwable)
{    errors.put(message, throwable);}
0
public List<T> getMessages()
{    return messages;}
0
public Map<Object, Throwable> getMessageThrowables()
{    return errors;}
0
public Optional<Throwable> getMasterThrowable()
{    return Optional.ofNullable(masterThrowable);}
0
public List<JSONObject> getMessages()
{    return messages;}
0
public List<MetronError> getErrors()
{    return errors;}
0
public void addMessage(JSONObject message)
{    this.messages.add(message);}
0
public void addError(MetronError error)
{    this.errors.add(error);}
0
public void addErrors(List<MetronError> errors)
{    this.errors.addAll(errors);}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ParserRunnerResults parserResult = (ParserRunnerResults) o;    return Objects.equals(messages, parserResult.getMessages()) && Objects.equals(errors, parserResult.getErrors());}
0
public int hashCode()
{    int result = messages != null ? messages.hashCode() : 0;    result = 31 * result + (errors != null ? errors.hashCode() : 0);    return result;}
0
public void configure(Map<String, Object> config)
{    Object protocolsObj = config.get("bro.filter.source.known.protocols");    Object keyObj = config.get("bro.filter.source.key");    if (keyObj != null) {        _key = keyObj.toString();    }    if (protocolsObj != null) {        if (protocolsObj instanceof String) {            _known_protocols.clear();            _known_protocols.add(protocolsObj.toString());        } else if (protocolsObj instanceof List) {            _known_protocols.clear();            for (Object o : (List) protocolsObj) {                _known_protocols.add(o.toString());            }        }    }}
0
public boolean emit(JSONObject message, Context context)
{    String protocol = (String) message.get(_key);    return _known_protocols.contains(protocol);}
0
public static MessageFilter<JSONObject> get(String filterName, Map<String, Object> config)
{    if (filterName == null || filterName.trim().isEmpty()) {        return null;    }    Class<? extends MessageFilter> filterClass;    try {        Filters f = Filters.valueOf(filterName);        filterClass = f.clazz;    } catch (Exception ex) {        try {            filterClass = (Class<? extends MessageFilter>) Class.forName(filterName);        } catch (ClassNotFoundException e) {            throw new IllegalStateException("Unable to find class " + filterName, e);        }    }    if (filterClass != null) {        MessageFilter<JSONObject> filter = ReflectionUtils.createInstance(filterClass);        filter.configure(config);        return filter;    }    return null;}
0
public void configure(Map<String, Object> config)
{    Object o = config.get(QUERY_STRING_CONF);    if (o instanceof String) {        query = o.toString();    }    Context stellarContext = (Context) config.get("stellarContext");    if (stellarContext == null) {        stellarContext = Context.EMPTY_CONTEXT();    }    processor.validate(query, true, stellarContext);}
0
public boolean emit(JSONObject message, Context context)
{    VariableResolver resolver = new MapVariableResolver(message);    return processor.parse(query, resolver, functionResolver, context);}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);    this.grokPath = (String) parserConfig.get("grokPath");    String multiLineString = (String) parserConfig.get("multiLine");    if (!StringUtils.isBlank(multiLineString)) {        multiLine = Boolean.parseBoolean(multiLineString);    }    this.patternLabel = (String) parserConfig.get("patternLabel");    this.timestampField = (String) parserConfig.get("timestampField");    List<String> timeFieldsParam = (List<String>) parserConfig.get("timeFields");    if (timeFieldsParam != null) {        this.timeFields = timeFieldsParam;    }    String dateFormatParam = (String) parserConfig.get("dateFormat");    if (dateFormatParam != null) {        this.dateFormat = new SimpleDateFormat(dateFormatParam);    }    String timeZoneParam = (String) parserConfig.get("timeZone");    if (timeZoneParam != null) {        dateFormat.setTimeZone(TimeZone.getTimeZone(timeZoneParam));            } else {        dateFormat.setTimeZone(TimeZone.getTimeZone("UTC"));            }}
1
public InputStream openInputStream(String streamName) throws IOException
{    FileSystem fs = FileSystem.get(new Configuration());    Path path = new Path(streamName);    if (fs.exists(path)) {                return fs.open(path);    } else {                return getClass().getResourceAsStream(streamName);    }}
1
public void init()
{    grok = new Grok();    try {        InputStream commonInputStream = openInputStream(patternsCommonDir);                if (commonInputStream == null) {            throw new RuntimeException("Unable to initialize grok parser: Unable to load " + patternsCommonDir + " from either classpath or HDFS");        }        grok.addPatternFromReader(new InputStreamReader(commonInputStream, getReadCharset()));                InputStream patterInputStream = openInputStream(grokPath);        if (patterInputStream == null) {            throw new RuntimeException("Grok parser unable to initialize grok parser: Unable to load " + grokPath + " from either classpath or HDFS");        }        grok.addPatternFromReader(new InputStreamReader(patterInputStream, getReadCharset()));                String grokPattern = "%{" + patternLabel + "}";        grok.compile(grokPattern);            } catch (Throwable e) {                throw new RuntimeException("Grok parser Error: " + e.getMessage(), e);    }}
1
public Optional<MessageParserResult<JSONObject>> parseOptionalResult(byte[] rawMessage)
{    if (grok == null) {        init();    }    if (multiLine) {        return parseMultiLine(rawMessage);    }    return parseSingleLine(rawMessage);}
0
private Optional<MessageParserResult<JSONObject>> parseMultiLine(byte[] rawMessage)
{    List<JSONObject> messages = new ArrayList<>();    Map<Object, Throwable> errors = new HashMap<>();    String originalMessage = null;        try (BufferedReader reader = new BufferedReader(new StringReader(new String(rawMessage, getReadCharset())))) {        while ((originalMessage = reader.readLine()) != null) {                        try {                Match gm = grok.match(originalMessage);                gm.captures();                JSONObject message = new JSONObject();                message.putAll(gm.toMap());                if (message.size() == 0) {                    Throwable rte = new RuntimeException("Grok statement produced a null message. Original message was: " + originalMessage + " and the parsed message was: " + message + " . Check the pattern at: " + grokPath);                    errors.put(originalMessage, rte);                    continue;                }                message.put("original_string", originalMessage);                for (String timeField : timeFields) {                    String fieldValue = (String) message.get(timeField);                    if (fieldValue != null) {                        message.put(timeField, toEpoch(fieldValue));                    }                }                if (timestampField != null) {                    message.put(Constants.Fields.TIMESTAMP.getName(), formatTimestamp(message.get(timestampField)));                }                message.remove(patternLabel);                postParse(message);                messages.add(message);                            } catch (Exception e) {                                errors.put(originalMessage, e);            }        }    } catch (IOException e) {                Exception innerException = new IllegalStateException("Grok parser Error: " + e.getMessage() + " on " + originalMessage, e);        return Optional.of(new DefaultMessageParserResult<>(innerException));    }    return Optional.of(new DefaultMessageParserResult<>(messages, errors));}
1
private Optional<MessageParserResult<JSONObject>> parseSingleLine(byte[] rawMessage)
{    List<JSONObject> messages = new ArrayList<>();    Map<Object, Throwable> errors = new HashMap<>();    String originalMessage = null;    try {        originalMessage = new String(rawMessage, StandardCharsets.UTF_8);                Match gm = grok.match(originalMessage);        gm.captures();        JSONObject message = new JSONObject();        message.putAll(gm.toMap());        if (message.size() == 0) {            Throwable rte = new RuntimeException("Grok statement produced a null message. Original message was: " + originalMessage + " and the parsed message was: " + message + " . Check the pattern at: " + grokPath);            errors.put(originalMessage, rte);        } else {            message.put("original_string", originalMessage);            for (String timeField : timeFields) {                String fieldValue = (String) message.get(timeField);                if (fieldValue != null) {                    message.put(timeField, toEpoch(fieldValue));                }            }            if (timestampField != null) {                message.put(Constants.Fields.TIMESTAMP.getName(), formatTimestamp(message.get(timestampField)));            }            message.remove(patternLabel);            postParse(message);            messages.add(message);                    }    } catch (Exception e) {                Exception innerException = new IllegalStateException("Grok parser Error: " + e.getMessage() + " on " + originalMessage, e);        return Optional.of(new DefaultMessageParserResult<>(innerException));    }    return Optional.of(new DefaultMessageParserResult<JSONObject>(messages, errors));}
1
public boolean validate(JSONObject message)
{        Object timestampObject = message.get(Constants.Fields.TIMESTAMP.getName());    if (timestampObject instanceof Long) {        Long timestamp = (Long) timestampObject;        if (timestamp > 0) {                        return true;        }    }        return false;}
1
protected void postParse(JSONObject message)
{}
0
protected long toEpoch(String datetime) throws ParseException
{            Date date = dateFormat.parse(datetime);        return date.getTime();}
1
protected long formatTimestamp(Object value)
{        if (value == null) {        throw new RuntimeException(patternLabel + " pattern does not include field " + timestampField);    }    if (value instanceof Number) {        return ((Number) value).longValue();    } else {        return Long.parseLong(Joiner.on("").join(Splitter.on('.').split(value + "")));    }}
1
public void setReadCharset(Map<String, Object> config)
{    if (config.containsKey(READ_CHARSET)) {        readCharset = Charset.forName((String) config.get(READ_CHARSET));    } else {        readCharset = MessageParser.super.getReadCharset();    }}
0
public Charset getReadCharset()
{    return null == this.readCharset ? MessageParser.super.getReadCharset() : this.readCharset;}
0
 List<T> parse(byte[] rawMessage)
{    throw new NotImplementedException("parse is not implemented");}
0
 Optional<List<T>> parseOptional(byte[] parseMessage)
{    return Optional.ofNullable(parse(parseMessage));}
0
 Optional<MessageParserResult<T>> parseOptionalResult(byte[] parseMessage)
{    Optional<MessageParserResult<T>> result = Optional.empty();    try {        Optional<List<T>> optionalMessages = parseOptional(parseMessage);        if (optionalMessages.isPresent()) {            result = Optional.of(new DefaultMessageParserResult<>(optionalMessages.get()));        }    } catch (Throwable t) {        return Optional.of(new DefaultMessageParserResult<>(t));    }    return result;}
0
 Charset getReadCharset()
{    return StandardCharsets.UTF_8;}
0
private static JSONObject recursiveUnfold(String key, Map value, JSONObject obj)
{    Set<Map.Entry<Object, Object>> entrySet = value.entrySet();    for (Map.Entry<Object, Object> kv : entrySet) {        String newKey = Joiner.on(".").join(key, kv.getKey().toString());        if (kv.getValue() instanceof Map) {            recursiveUnfold(newKey, (Map) kv.getValue(), obj);        } else {            obj.put(newKey, kv.getValue());        }    }    return obj;}
0
public JSONObject handle(String key, Map value, JSONObject obj)
{    return handler.handle(key, value, obj);}
0
public void configure(Map<String, Object> config)
{    setReadCharset(config);    String strategyStr = (String) config.getOrDefault(MAP_STRATEGY_CONFIG, MapStrategy.DROP.name());    mapStrategy = MapStrategy.valueOf(strategyStr);    overrideOriginalString = (Boolean) config.getOrDefault(OVERRIDE_ORIGINAL_STRING, false);    if (config.containsKey(JSONP_QUERY)) {        typeRef = new TypeRef<List<Map<String, Object>>>() {        };        jsonpQuery = (String) config.get(JSONP_QUERY);        if (!StringUtils.isBlank(jsonpQuery) && config.containsKey(WRAP_JSON)) {            Object wrapObject = config.get(WRAP_JSON);            if (wrapObject instanceof String) {                wrapJson = Boolean.valueOf((String) wrapObject);            } else if (wrapObject instanceof Boolean) {                wrapJson = (Boolean) config.get(WRAP_JSON);            }            String entityName = (String) config.get(WRAP_ENTITY_NAME);            if (!StringUtils.isBlank(entityName)) {                wrapEntityName = entityName;            }        }        Configuration.setDefaults(new Configuration.Defaults() {            private final JsonProvider jsonProvider = new JacksonJsonProvider();            private final MappingProvider mappingProvider = new JacksonMappingProvider();            @Override            public JsonProvider jsonProvider() {                return jsonProvider;            }            @Override            public MappingProvider mappingProvider() {                return mappingProvider;            }            @Override            public Set<Option> options() {                return EnumSet.of(Option.SUPPRESS_EXCEPTIONS);            }        });        if (CacheProvider.getCache() == null) {            CacheProvider.setCache(new LRUCache(100));        }    }}
0
public JsonProvider jsonProvider()
{    return jsonProvider;}
0
public MappingProvider mappingProvider()
{    return mappingProvider;}
0
public Set<Option> options()
{    return EnumSet.of(Option.SUPPRESS_EXCEPTIONS);}
0
public void init()
{}
0
public List<JSONObject> parse(byte[] rawMessage)
{    try {        String rawString = new String(rawMessage, getReadCharset());        List<Map<String, Object>> messages = new ArrayList<>();                if (wrapJson) {            rawString = wrapMessageJson(rawString);        }        if (!StringUtils.isEmpty(jsonpQuery)) {            Object parsedObject = JsonPath.parse(rawString).read(jsonpQuery, typeRef);            if (parsedObject != null) {                messages.addAll((List<Map<String, Object>>) parsedObject);            }        } else {            messages.add(JSONUtils.INSTANCE.load(rawString, JSONUtils.MAP_SUPPLIER));        }        ArrayList<JSONObject> parsedMessages = new ArrayList<>();        for (Map<String, Object> rawMessageMap : messages) {            JSONObject ret = normalizeJson(rawMessageMap);            if (overrideOriginalString) {                                                JSONObject originalJsonObject = new JSONObject(rawMessageMap);                ret.put("original_string", originalJsonObject.toJSONString());            }            if (!ret.containsKey("timestamp")) {                ret.put("timestamp", System.currentTimeMillis());            }            parsedMessages.add(ret);        }        return Collections.unmodifiableList(parsedMessages);    } catch (Throwable e) {        String message = "Unable to parse " + new String(rawMessage, getReadCharset()) + ": " + e.getMessage();                throw new IllegalStateException(message, e);    }}
1
private JSONObject normalizeJson(Map<String, Object> map)
{    JSONObject ret = new JSONObject();    for (Map.Entry<String, Object> kv : map.entrySet()) {        if (kv.getValue() instanceof Map) {            mapStrategy.handle(kv.getKey(), (Map) kv.getValue(), ret);        } else {            ret.put(kv.getKey(), kv.getValue());        }    }    return ret;}
0
private String wrapMessageJson(String jsonMessage)
{    String base = new StringBuilder(String.format(WRAP_START_FMT, wrapEntityName)).append(jsonMessage).toString().trim();    if (base.endsWith(",")) {        base = base.substring(0, base.length() - 1);    }    return base + WRAP_END;}
0
public MessageParser<JSONObject> getMessageParser()
{    return messageParser;}
0
public MessageFilter<JSONObject> getFilter()
{    return filter;}
0
public void setMessageParser(MessageParser<JSONObject> messageParser)
{    this.messageParser = messageParser;}
0
public void setFilter(MessageFilter<JSONObject> filter)
{    this.filter = filter;}
0
public JSONObject getMessage()
{    return message;}
0
public MetronError getError()
{    return error;}
0
public boolean isError()
{    return error != null;}
0
public Map<String, ParserComponent> getSensorToParserComponentMap()
{    return sensorToParserComponentMap;}
0
public void setSensorToParserComponentMap(Map<String, ParserComponent> sensorToParserComponentMap)
{    this.sensorToParserComponentMap = sensorToParserComponentMap;}
0
public Context getStellarContext()
{    return stellarContext;}
0
public Set<String> getSensorTypes()
{    return sensorTypes;}
0
public void init(Supplier<ParserConfigurations> parserConfigSupplier, Context stellarContext)
{    if (parserConfigSupplier == null) {        throw new IllegalStateException("A parser config supplier must be set before initializing the ParserRunner.");    }    if (stellarContext == null) {        throw new IllegalStateException("A stellar context must be set before initializing the ParserRunner.");    }    this.stellarContext = stellarContext;    initializeParsers(parserConfigSupplier);}
0
public ParserRunnerResults<JSONObject> execute(String sensorType, RawMessage rawMessage, ParserConfigurations parserConfigurations)
{    DefaultParserRunnerResults parserRunnerResults = new DefaultParserRunnerResults();    SensorParserConfig sensorParserConfig = parserConfigurations.getSensorParserConfig(sensorType);    if (sensorParserConfig != null) {        MessageParser<JSONObject> parser = sensorToParserComponentMap.get(sensorType).getMessageParser();        Optional<MessageParserResult<JSONObject>> optionalMessageParserResult = parser.parseOptionalResult(rawMessage.getMessage());        if (optionalMessageParserResult.isPresent()) {            MessageParserResult<JSONObject> messageParserResult = optionalMessageParserResult.get();                        messageParserResult.getMessages().forEach(message -> {                Optional<ProcessResult> processResult = processMessage(sensorType, message, rawMessage, parser, parserConfigurations);                if (processResult.isPresent()) {                    if (processResult.get().isError()) {                        parserRunnerResults.addError(processResult.get().getError());                    } else {                        parserRunnerResults.addMessage(processResult.get().getMessage());                    }                }            });                        messageParserResult.getMasterThrowable().ifPresent(throwable -> parserRunnerResults.addError(new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(throwable).withSensorType(Collections.singleton(sensorType)).withMetadata(rawMessage.getMetadata()).addRawMessage(rawMessage.getMessage())));                        parserRunnerResults.addErrors(messageParserResult.getMessageThrowables().entrySet().stream().map(entry -> new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(entry.getValue()).withSensorType(Collections.singleton(sensorType)).withMetadata(rawMessage.getMetadata()).addRawMessage(entry.getKey())).collect(Collectors.toList()));        }    } else {        throw new IllegalStateException(String.format("Could not execute parser.  Cannot find configuration for sensor %s.", sensorType));    }    return parserRunnerResults;}
0
private void initializeParsers(Supplier<ParserConfigurations> parserConfigSupplier)
{        sensorToParserComponentMap = new HashMap<>();    for (String sensorType : sensorTypes) {        if (parserConfigSupplier.get().getSensorParserConfig(sensorType) == null) {            throw new IllegalStateException(String.format("Could not initialize parsers.  Cannot find configuration for sensor %s.", sensorType));        }        SensorParserConfig parserConfig = parserConfigSupplier.get().getSensorParserConfig(sensorType);                        MessageParser<JSONObject> parser = ReflectionUtils.createInstance(parserConfig.getParserClassName());                MessageFilter<JSONObject> filter = null;        parserConfig.getParserConfig().putIfAbsent("stellarContext", stellarContext);        if (!StringUtils.isEmpty(parserConfig.getFilterClassName())) {            filter = Filters.get(parserConfig.getFilterClassName(), parserConfig.getParserConfig());        }        parser.configure(parserConfig.getParserConfig());        parser.init();        sensorToParserComponentMap.put(sensorType, new ParserComponent(parser, filter));    }}
1
protected Optional<ProcessResult> processMessage(String sensorType, JSONObject message, RawMessage rawMessage, MessageParser<JSONObject> parser, ParserConfigurations parserConfigurations)
{    Optional<ProcessResult> processResult = Optional.empty();    SensorParserConfig sensorParserConfig = parserConfigurations.getSensorParserConfig(sensorType);    sensorParserConfig.getRawMessageStrategy().mergeMetadata(message, rawMessage.getMetadata(), sensorParserConfig.getMergeMetadata(), sensorParserConfig.getRawMessageStrategyConfig());    message.put(Constants.SENSOR_TYPE, sensorType);    applyFieldTransformations(message, rawMessage, sensorParserConfig);    if (!message.containsKey(Constants.GUID)) {        message.put(Constants.GUID, UUID.randomUUID().toString());    }    message.putIfAbsent(Fields.ORIGINAL.getName(), new String(rawMessage.getMessage(), parser.getReadCharset()));    MessageFilter<JSONObject> filter = sensorToParserComponentMap.get(sensorType).getFilter();    if (filter == null || filter.emit(message, stellarContext)) {        boolean isInvalid = !parser.validate(message);        List<FieldValidator> failedValidators = null;        if (!isInvalid) {            failedValidators = getFailedValidators(message, parserConfigurations);            isInvalid = !failedValidators.isEmpty();        }        if (isInvalid) {            MetronError error = new MetronError().withErrorType(Constants.ErrorType.PARSER_INVALID).withSensorType(Collections.singleton(sensorType)).withMetadata(rawMessage.getMetadata()).addRawMessage(message);            Set<String> errorFields = failedValidators == null ? null : failedValidators.stream().flatMap(fieldValidator -> fieldValidator.getInput().stream()).collect(Collectors.toSet());            if (errorFields != null && !errorFields.isEmpty()) {                error.withErrorFields(errorFields);            }            processResult = Optional.of(new ProcessResult(error));        } else {            processResult = Optional.of(new ProcessResult(message));        }    }    return processResult;}
0
private void applyFieldTransformations(JSONObject message, RawMessage rawMessage, SensorParserConfig sensorParserConfig)
{    for (FieldTransformer handler : sensorParserConfig.getFieldTransformations()) {        if (handler != null) {            if (!sensorParserConfig.getMergeMetadata()) {                                handler.transformAndUpdate(message, stellarContext, sensorParserConfig.getParserConfig(), rawMessage.getMetadata());            } else {                handler.transformAndUpdate(message, stellarContext, sensorParserConfig.getParserConfig());            }        }    }}
0
private List<FieldValidator> getFailedValidators(JSONObject message, ParserConfigurations parserConfigurations)
{    List<FieldValidator> fieldValidations = parserConfigurations.getFieldValidations();    List<FieldValidator> failedValidators = new ArrayList<>();    for (FieldValidator validator : fieldValidations) {        if (!validator.isValid(message, parserConfigurations.getGlobalConfig(), stellarContext)) {            failedValidators.add(validator);        }    }    return failedValidators;}
0
public List<JSONObject> parse(byte[] rawMessage)
{    String originalMessage = null;    try {        originalMessage = new String(rawMessage, getReadCharset()).trim();                if (originalMessage.isEmpty()) {                        return Arrays.asList(new JSONObject());        }    } catch (Exception e) {                throw new RuntimeException(e.getMessage(), e);    }    JSONObject parsedJson = new JSONObject();    if (messageHeaderPatternsMap.size() > 0) {        parsedJson.putAll(extractHeaderFields(originalMessage));    }    parsedJson.putAll(parse(originalMessage));    parsedJson.put(Constants.Fields.ORIGINAL.getName(), originalMessage);    /**     * Populate the output json with default timestamp.     */    parsedJson.put(Constants.Fields.TIMESTAMP.getName(), System.currentTimeMillis());    applyFieldTransformations(parsedJson);    return Arrays.asList(parsedJson);}
1
private void applyFieldTransformations(JSONObject parsedJson)
{    if (getParserConfig().get(ParserConfigConstants.CONVERT_CAMELCASE_TO_UNDERSCORE.getName()) != null && (Boolean) getParserConfig().get(ParserConfigConstants.CONVERT_CAMELCASE_TO_UNDERSCORE.getName())) {        convertCamelCaseToUnderScore(parsedJson);    }}
0
public void configure(Map<String, Object> parserConfig)
{    setReadCharset(parserConfig);    setParserConfig(parserConfig);    setFields((List<Map<String, Object>>) getParserConfig().get(ParserConfigConstants.FIELDS.getName()));    String recordTypeRegex = (String) getParserConfig().get(ParserConfigConstants.RECORD_TYPE_REGEX.getName());    if (StringUtils.isBlank(recordTypeRegex)) {                throw new IllegalStateException("Invalid config :recordTypeRegex is missing in parserConfig");    }    setRecordTypePattern(recordTypeRegex);    recordTypePatternNamedGroups.addAll(getNamedGroups(recordTypeRegex));    List<Map<String, Object>> fields = (List<Map<String, Object>>) getParserConfig().get(ParserConfigConstants.FIELDS.getName());    try {        configureRecordTypePatterns(fields);        configureMessageHeaderPattern();    } catch (PatternSyntaxException e) {                throw new IllegalStateException("Invalid config : " + e.getMessage());    }    validateConfig();}
1
private void configureMessageHeaderPattern()
{    if (getParserConfig().get(ParserConfigConstants.MESSAGE_HEADER.getName()) != null) {        if (getParserConfig().get(ParserConfigConstants.MESSAGE_HEADER.getName()) instanceof List) {            List<String> messageHeaderPatternList = (List<String>) getParserConfig().get(ParserConfigConstants.MESSAGE_HEADER.getName());            for (String messageHeaderPatternStr : messageHeaderPatternList) {                messageHeaderPatternsMap.put(Pattern.compile(messageHeaderPatternStr), getNamedGroups(messageHeaderPatternStr));            }        } else if (getParserConfig().get(ParserConfigConstants.MESSAGE_HEADER.getName()) instanceof String) {            String messageHeaderPatternStr = (String) getParserConfig().get(ParserConfigConstants.MESSAGE_HEADER.getName());            if (StringUtils.isNotBlank(messageHeaderPatternStr)) {                messageHeaderPatternsMap.put(Pattern.compile(messageHeaderPatternStr), getNamedGroups(messageHeaderPatternStr));            }        }    }}
0
private void configureRecordTypePatterns(List<Map<String, Object>> fields)
{    for (Map<String, Object> field : fields) {        if (field.get(ParserConfigConstants.RECORD_TYPE.getName()) != null && field.get(ParserConfigConstants.REGEX.getName()) != null) {            String recordType = ((String) field.get(ParserConfigConstants.RECORD_TYPE.getName())).toLowerCase();            recordTypePatternMap.put(recordType, new LinkedHashMap<>());            if (field.get(ParserConfigConstants.REGEX.getName()) instanceof List) {                List<String> regexList = (List<String>) field.get(ParserConfigConstants.REGEX.getName());                regexList.forEach(s -> {                    recordTypePatternMap.get(recordType).put(Pattern.compile(s), getNamedGroups(s));                });            } else if (field.get(ParserConfigConstants.REGEX.getName()) instanceof String) {                recordTypePatternMap.get(recordType).put(Pattern.compile((String) field.get(ParserConfigConstants.REGEX.getName())), getNamedGroups((String) field.get(ParserConfigConstants.REGEX.getName())));            }        }    }}
0
private void setRecordTypePattern(String recordTypeRegex)
{    if (recordTypeRegex != null) {        recordTypePattern = Pattern.compile(recordTypeRegex);    }}
0
private JSONObject parse(String originalMessage)
{    JSONObject parsedJson = new JSONObject();    Optional<String> recordIdentifier = getField(recordTypePattern, originalMessage);    if (recordIdentifier.isPresent()) {        extractNamedGroups(parsedJson, recordIdentifier.get(), originalMessage);    }    /*         * Extract fields(named groups) from record type regular expression         */    Matcher matcher = recordTypePattern.matcher(originalMessage);    if (matcher.find()) {        for (String namedGroup : recordTypePatternNamedGroups) {            if (matcher.group(namedGroup) != null) {                parsedJson.put(namedGroup, matcher.group(namedGroup).trim());            }        }    }    return parsedJson;}
0
private void extractNamedGroups(Map<String, Object> json, String recordType, String originalMessage)
{    Map<Pattern, Set<String>> patternMap = recordTypePatternMap.get(recordType.toLowerCase());    if (patternMap != null) {        for (Map.Entry<Pattern, Set<String>> entry : patternMap.entrySet()) {            Pattern pattern = entry.getKey();            Set<String> namedGroups = entry.getValue();            if (pattern != null && namedGroups != null && namedGroups.size() > 0) {                Matcher m = pattern.matcher(originalMessage);                if (m.matches()) {                                        for (String namedGroup : namedGroups) {                        if (m.group(namedGroup) != null) {                            json.put(namedGroup, m.group(namedGroup).trim());                        }                    }                    break;                }            }        }    } else {            }}
1
public Optional<String> getField(Pattern pattern, String originalMessage)
{    Matcher matcher = pattern.matcher(originalMessage);    while (matcher.find()) {        return Optional.of(matcher.group());    }    return Optional.empty();}
0
private Set<String> getNamedGroups(String regex)
{    Set<String> namedGroups = new TreeSet<>();    Matcher matcher = namedGroupPattern.matcher(regex);    while (matcher.find()) {        namedGroups.add(matcher.group(1));    }    return namedGroups;}
0
private Map<String, Object> extractHeaderFields(String originalMessage)
{    Map<String, Object> messageHeaderJson = new JSONObject();    for (Map.Entry<Pattern, Set<String>> syslogPatternEntry : messageHeaderPatternsMap.entrySet()) {        Matcher m = syslogPatternEntry.getKey().matcher(originalMessage);        if (m.find()) {            for (String namedGroup : syslogPatternEntry.getValue()) {                if (StringUtils.isNotBlank(m.group(namedGroup))) {                    messageHeaderJson.put(namedGroup, m.group(namedGroup).trim());                }            }            break;        }    }    return messageHeaderJson;}
0
public void init()
{    }
1
public void validateConfig()
{    if (getFields() == null) {                throw new IllegalStateException("Invalid config :fields is missing in parserConfig");    }}
1
private void convertCamelCaseToUnderScore(Map<String, Object> json)
{    Map<String, String> oldKeyNewKeyMap = new HashMap<>();    for (Map.Entry<String, Object> entry : json.entrySet()) {        if (capitalLettersPattern.matcher(entry.getKey()).matches()) {            oldKeyNewKeyMap.put(entry.getKey(), CaseFormat.UPPER_CAMEL.to(CaseFormat.LOWER_UNDERSCORE, entry.getKey()));        }    }    oldKeyNewKeyMap.forEach((oldKey, newKey) -> json.put(newKey, json.remove(oldKey)));}
0
public List<Map<String, Object>> getFields()
{    return fields;}
0
public void setFields(List<Map<String, Object>> fields)
{    this.fields = fields;}
0
public Map<String, Object> getParserConfig()
{    return parserConfig;}
0
public void setParserConfig(Map<String, Object> parserConfig)
{    this.parserConfig = parserConfig;}
0
public String getName()
{    return name;}
0
public static ParserConfigConstants fromString(String fieldName)
{    return nameToField.get(fieldName);}
0
protected void setSyslogParser(SyslogParser syslogParser)
{    this.syslogParser = syslogParser;}
0
protected void setMessageProcessor(Consumer<JSONObject> function)
{    this.messageProcessorOptional = Optional.of(function);}
0
public void init()
{}
0
public boolean validate(JSONObject message)
{    if (!(message.containsKey("original_string"))) {        LOG.trace("[Metron] Message does not have original_string: {}", message);        return false;    } else if (!(message.containsKey("timestamp"))) {        LOG.trace("[Metron] Message does not have timestamp: {}", message);        return false;    } else {        LOG.trace("[Metron] Message conforms to schema: {}", message);        return true;    }}
0
public Optional<MessageParserResult<JSONObject>> parseOptionalResult(byte[] rawMessage)
{    try {        if (rawMessage == null || rawMessage.length == 0) {            return Optional.empty();        }        String originalString = new String(rawMessage, getReadCharset());        final List<JSONObject> returnList = new ArrayList<>();        Map<Object, Throwable> errorMap = new HashMap<>();        try (Reader reader = new BufferedReader(new StringReader(originalString))) {            syslogParser.parseLines(reader, (m) -> {                JSONObject jsonObject = new JSONObject(m);                                                jsonObject.put("original_string", originalString);                try {                    setTimestamp(jsonObject);                } catch (ParseException pe) {                    errorMap.put(originalString, pe);                    return;                }                messageProcessorOptional.ifPresent((c) -> c.accept(jsonObject));                returnList.add(jsonObject);            }, errorMap::put);            return Optional.of(new DefaultMessageParserResult<JSONObject>(returnList, errorMap));        }    } catch (IOException e) {        String message = "Unable to read buffer " + new String(rawMessage, StandardCharsets.UTF_8) + ": " + e.getMessage();                return Optional.of(new DefaultMessageParserResult<JSONObject>(new IllegalStateException(message, e)));    }}
1
private void setTimestamp(JSONObject message) throws ParseException
{    String timeStampString = (String) message.get(SyslogFieldKeys.HEADER_TIMESTAMP.getField());    if (!StringUtils.isBlank(timeStampString) && !timeStampString.equals("-")) {        message.put("timestamp", SyslogUtils.parseTimestampToEpochMillis(timeStampString, deviceClock));    } else {        message.put("timestamp", LocalDateTime.now().toEpochSecond(ZoneOffset.UTC));    }}
0
public void setReadCharset(Map<String, Object> config)
{    if (config.containsKey(READ_CHARSET)) {        readCharset = Charset.forName((String) config.get(READ_CHARSET));    } else {        readCharset = MessageParser.super.getReadCharset();    }}
0
public Charset getReadCharset()
{    return null == this.readCharset ? MessageParser.super.getReadCharset() : this.readCharset;}
0
public SyslogParser buildSyslogParser(Map<String, Object> config)
{    return new SyslogParserBuilder().forSpecification(SyslogSpecification.RFC_3164).withDeviations(EnumSet.of(AllowableDeviations.PRIORITY, AllowableDeviations.VERSION)).build();}
0
public SyslogParser buildSyslogParser(Map<String, Object> config)
{            String nilPolicyStr = (String) config.getOrDefault(NIL_POLICY_CONFIG, NilPolicy.OMIT.name());    NilPolicy nilPolicy = NilPolicy.valueOf(nilPolicyStr);    return new SyslogParserBuilder().forSpecification(SyslogSpecification.RFC_5424).withNilPolicy(nilPolicy).withDeviations(EnumSet.of(AllowableDeviations.PRIORITY, AllowableDeviations.VERSION)).build();}
0
public static long parseMultiformat(String candidate, List<SimpleDateFormat> validPatterns) throws ParseException
{    if (StringUtils.isNumeric(candidate)) {        return Long.valueOf(candidate);    } else {        for (SimpleDateFormat pattern : validPatterns) {            try {                Calendar cal = Calendar.getInstance();                cal.setTime(pattern.parse(candidate));                Calendar current = Calendar.getInstance();                if (cal.get(Calendar.YEAR) == 1970) {                    cal.set(Calendar.YEAR, current.get(Calendar.YEAR));                }                current.add(Calendar.DAY_OF_MONTH, 4);                if (cal.after(current)) {                    cal.add(Calendar.YEAR, -1);                }                return cal.getTimeInMillis();            } catch (ParseException e) {                continue;            }        }        throw new ParseException("Failed to parse any of the given date formats", 0);    }}
0
public static File stream2file(InputStream in) throws IOException
{    final File tempFile = File.createTempFile(PREFIX, SUFFIX);    tempFile.deleteOnExit();    try (FileOutputStream out = new FileOutputStream(tempFile)) {        IOUtils.copy(in, out);    }    return tempFile;}
0
public static Long convertToEpoch(String m, String d, String ts, boolean adjust_timezone) throws ParseException
{    d = d.trim();    if (d.length() <= 2) {        d = "0" + d;    }    Date date = new SimpleDateFormat("MMM", Locale.ENGLISH).parse(m);    Calendar cal = Calendar.getInstance();    cal.setTime(date);    String month = String.valueOf(cal.get(Calendar.MONTH) + 1);    int year = Calendar.getInstance().get(Calendar.YEAR);    if (month.length() <= 2) {        month = "0" + month;    }    String coglomerated_ts = year + "-" + month + "-" + d + " " + ts;    SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");    if (adjust_timezone) {        sdf.setTimeZone(TimeZone.getTimeZone("GMT"));    }    date = sdf.parse(coglomerated_ts);    long timeInMillisSinceEpoch = date.getTime();    return timeInMillisSinceEpoch;}
0
public static long parseTimestampToEpochMillis(String logTimestamp, Clock deviceClock) throws ParseException
{    ZoneId deviceTimeZone = deviceClock.getZone();        if (Pattern.matches("[A-Z][a-z]{2}(?:(?:\\s{2}\\d)|(?:\\s\\d{2}))\\s\\d{2}:\\d{2}:\\d{2}", logTimestamp)) {        DateTimeFormatter inputFormat = DateTimeFormatter.ofPattern("MMM ppd HH:mm:ss").withZone(deviceTimeZone);        TemporalAccessor inputDate = inputFormat.parse(logTimestamp);        int inputMonth = inputDate.get(MONTH_OF_YEAR);        int inputDay = inputDate.get(DAY_OF_MONTH);        int inputHour = inputDate.get(HOUR_OF_DAY);        int inputMinute = inputDate.get(MINUTE_OF_HOUR);        int inputSecond = inputDate.get(SECOND_OF_MINUTE);        ZonedDateTime currentDate = ZonedDateTime.now(deviceClock);        int currentYear = currentDate.getYear();        ZonedDateTime inputDateWithCurrentYear = ZonedDateTime.of(currentYear, inputMonth, inputDay, inputHour, inputMinute, inputSecond, 0, deviceTimeZone);                if (inputDateWithCurrentYear.isAfter(currentDate.plusDays(4L))) {            ZonedDateTime inputDateWithPreviousYear = ZonedDateTime.of(currentYear - 1, inputMonth, inputDay, inputHour, inputMinute, inputSecond, 0, deviceTimeZone);            return inputDateWithPreviousYear.toInstant().toEpochMilli();        } else            return inputDateWithCurrentYear.toInstant().toEpochMilli();    } else     if (Pattern.matches("[A-Z][a-z]{2}\\s\\d{2}\\s\\d{4}\\s\\d{2}:\\d{2}:\\d{2}", logTimestamp))        return convertToEpochMillis(logTimestamp, DateTimeFormatter.ofPattern("MMM dd yyyy HH:mm:ss").withZone(deviceTimeZone));    else     if (Pattern.matches("\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?(?:Z|[+-]\\d{2}:\\d{2})", logTimestamp))        return convertToEpochMillis(logTimestamp, DateTimeFormatter.ISO_OFFSET_DATE_TIME);    else        throw new ParseException(String.format("Unsupported date format: '%s'", logTimestamp));}
0
private static long convertToEpochMillis(String logTimestamp, DateTimeFormatter logTimeFormat)
{    ZonedDateTime timestamp = ZonedDateTime.parse(logTimestamp, logTimeFormat);    return timestamp.toInstant().toEpochMilli();}
0
public static String getSeverityFromPriority(int priority)
{    int severity = priority & 0x07;    switch(severity) {        case 0:            return "emerg";        case 1:            return "alert";        case 2:            return "crit";        case 3:            return "err";        case 4:            return "warn";        case 5:            return "notice";        case 6:            return "info";        case 7:            return "debug";        default:            return "unknown";    }}
0
public static String getFacilityFromPriority(int priority)
{    int facility = priority >> 3;    switch(facility) {        case 0:            return "kern";        case 1:            return "user";        case 2:            return "mail";        case 3:            return "daemon";        case 4:            return "auth";        case 5:            return "syslog";        case 6:            return "lpr";        case 7:            return "news";        case 8:            return "uucp";                case 10:            return "authpriv";        case 11:            return "ftp";                case 15:            return "cron";        case 16:            return "local0";        case 17:            return "local1";        case 18:            return "local2";        case 19:            return "local3";        case 20:            return "local4";        case 21:            return "local5";        case 22:            return "local6";        case 23:            return "local7";        default:            return "unknown";    }}
0
public void testDefault()
{    Assert.assertNull(Filters.get("DEFAULT", null));}
0
public void testSingleQueryFilter() throws Exception
{    {        Map<String, Object> config = new HashMap<String, Object>() {            {                put("filter.query", "exists(foo)");            }        };        MessageFilter<JSONObject> filter = Filters.get(Filters.STELLAR.name(), config);        Assert.assertTrue(filter.emit(new JSONObject(ImmutableMap.of("foo", 1)), Context.EMPTY_CONTEXT()));        Assert.assertFalse(filter.emit(new JSONObject(ImmutableMap.of("bar", 1)), Context.EMPTY_CONTEXT()));    }}
0
protected boolean validateJsonData(final String jsonSchema, final String jsonData) throws IOException, ProcessingException
{    final JsonNode d = JsonLoader.fromString(jsonData);    final JsonNode s = JsonLoader.fromString(jsonSchema);    final JsonSchemaFactory factory = JsonSchemaFactory.byDefault();    JsonValidator v = factory.getValidator();    ProcessingReport report = v.validate(s, d);    return report.toString().contains("success");}
0
protected String readSchemaFromFile(URL schema_url) throws Exception
{    BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(schema_url.getFile()), StandardCharsets.UTF_8));    String line;    StringBuilder sb = new StringBuilder();    while ((line = br.readLine()) != null) {        sb.append(line);    }    br.close();    String schema_string = sb.toString().replaceAll("\n", "");    schema_string = schema_string.replaceAll(" ", "");    return schema_string;}
0
protected String[] readTestDataFromFile(String test_data_url) throws Exception
{    BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(test_data_url), StandardCharsets.UTF_8));    ArrayList<String> inputDataLines = new ArrayList<>();    String line;    while ((line = br.readLine()) != null) {        inputDataLines.add(line.replaceAll("\n", ""));    }    br.close();    String[] inputData = new String[inputDataLines.size()];    inputData = inputDataLines.toArray(inputData);    return inputData;}
0
public void setSchemaJsonString(String schemaJsonString)
{    this.schemaJsonString = schemaJsonString;}
0
public String getSchemaJsonString()
{    return this.schemaJsonString;}
0
public void init()
{}
0
public void configure(Map<String, Object> config)
{    setReadCharset(config);}
0
public Optional<MessageParserResult<JSONObject>> parseOptionalResult(byte[] parseMessage)
{    String message = new String(parseMessage, getReadCharset());    Map<String, Object> out = new HashMap<>();    out.put(KEY1, message);    MessageParserResult<JSONObject> result = new DefaultMessageParserResult<JSONObject>(Arrays.asList(new JSONObject(out)));    return Optional.of(result);}
0
public void configure(Map<String, Object> config)
{}
0
public void setup() throws IOException, InterruptedException
{    tempFolder.create();    parserWithCharset = new SomeParserWithCharset();    parserNoCharset = new SomeParserNoCharset();    parserConfig = new HashMap<>();    fileUTF_16 = new File(tempFolder.getRoot(), "fileUTF-16");    fileUTF_8 = new File(tempFolder.getRoot(), "fileUTF-8");    writeDataEncodedAs(fileUTF_16, SAMPLE_DATA, StandardCharsets.UTF_16);    writeDataEncodedAs(fileUTF_8, SAMPLE_DATA, StandardCharsets.UTF_8);}
0
private void writeDataEncodedAs(File file, String data, Charset charset) throws IOException
{    byte[] bytes = data.getBytes(charset);    FileUtils.writeByteArrayToFile(file, bytes);}
0
public void verify_encoding_translation_assumptions() throws IOException
{                String utf16_8 = readDataEncodedAs(fileUTF_16, StandardCharsets.UTF_8);    String utf16_16 = readDataEncodedAs(fileUTF_16, StandardCharsets.UTF_16);    File utf16_16_8 = new File(tempFolder.getRoot(), "outUTF-8");    writeDataEncodedAs(utf16_16_8, utf16_16, StandardCharsets.UTF_8);    String utf8_8 = readDataEncodedAs(utf16_16_8, StandardCharsets.UTF_8);    assertThat(utf8_8, equalTo(utf16_16));    assertThat(utf8_8, not(equalTo(utf16_8)));    assertThat(utf8_8, equalTo(utf16_16));    assertThat(utf8_8, not(equalTo(utf16_8)));}
0
private String readDataEncodedAs(File file, Charset charset) throws IOException
{    return FileUtils.readFileToString(file, charset);}
0
public void parses_with_specified_encoding()
{    parserConfig.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parserWithCharset.configure(parserConfig);    Optional<MessageParserResult<JSONObject>> result = parserWithCharset.parseOptionalResult(SAMPLE_DATA.getBytes(StandardCharsets.UTF_16));    MessageParserResult<JSONObject> json = result.get();    assertThat(json.getMessages().size(), equalTo(1));    assertThat(json.getMessages().get(0).get(KEY1), equalTo(SAMPLE_DATA));}
0
public void values_will_not_match_when_specified_encoding_is_wrong()
{    parserConfig.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_8.toString());    parserWithCharset.configure(parserConfig);    Optional<MessageParserResult<JSONObject>> result = parserWithCharset.parseOptionalResult(SAMPLE_DATA.getBytes(StandardCharsets.UTF_16));    MessageParserResult<JSONObject> json = result.get();    assertThat(json.getMessages().size(), equalTo(1));    assertThat(json.getMessages().get(0).get(KEY1), not(equalTo(SAMPLE_DATA)));}
0
public void parses_with_default_encoding_when_not_configured()
{    parserWithCharset.configure(parserConfig);    Optional<MessageParserResult<JSONObject>> result = parserWithCharset.parseOptionalResult(SAMPLE_DATA.getBytes(StandardCharsets.UTF_8));    MessageParserResult<JSONObject> json = result.get();    assertThat(json.getMessages().size(), equalTo(1));    assertThat(json.getMessages().get(0).get(KEY1), equalTo(SAMPLE_DATA));}
0
public void parses_with_default_encoding_from_basic_parser()
{    parserNoCharset.configure(parserConfig);    Optional<MessageParserResult<JSONObject>> result = parserNoCharset.parseOptionalResult(SAMPLE_DATA.getBytes(StandardCharsets.UTF_8));    MessageParserResult<JSONObject> json = result.get();    assertThat(json.getMessages().size(), equalTo(1));    assertThat(json.getMessages().get(0).get(KEY1), equalTo(SAMPLE_DATA));}
0
public void test() throws IOException
{    CSVParser parser = new CSVParser();    SensorParserConfig config = JSONUtils.INSTANCE.load(parserConfig, SensorParserConfig.class);    parser.init();    parser.configure(config.getParserConfig());    {        String line = "#foo,bar,grok";        Assert.assertEquals(0, parser.parse(Bytes.toBytes(line)).size());    }    {        String line = "";        Assert.assertEquals(0, parser.parse(Bytes.toBytes(line)).size());    }    {        String line = "foo,bar,grok";        List<JSONObject> results = parser.parse(Bytes.toBytes(line));        Assert.assertEquals(1, results.size());        JSONObject o = results.get(0);        Assert.assertTrue(parser.validate(o));        Assert.assertEquals(5, o.size());        Assert.assertEquals("foo", o.get("col1"));        Assert.assertEquals("bar", o.get("col2"));        Assert.assertEquals("grok", o.get("col3"));    }    {        String line = "\"foo\", \"bar\",\"grok\"";        List<JSONObject> results = parser.parse(Bytes.toBytes(line));        Assert.assertEquals(1, results.size());        JSONObject o = results.get(0);        Assert.assertTrue(parser.validate(o));        Assert.assertEquals(5, o.size());        Assert.assertEquals("foo", o.get("col1"));        Assert.assertEquals("bar", o.get("col2"));        Assert.assertEquals("grok", o.get("col3"));    }    {        String line = "foo, bar, grok";        List<JSONObject> results = parser.parse(Bytes.toBytes(line));        Assert.assertEquals(1, results.size());        JSONObject o = results.get(0);        Assert.assertTrue(parser.validate(o));        Assert.assertEquals(5, o.size());        Assert.assertEquals("foo", o.get("col1"));        Assert.assertEquals("bar", o.get("col2"));        Assert.assertEquals("grok", o.get("col3"));    }    {        String line = " foo , bar , grok ";        List<JSONObject> results = parser.parse(Bytes.toBytes(line));        Assert.assertEquals(1, results.size());        JSONObject o = results.get(0);        Assert.assertTrue(parser.validate(o));        Assert.assertEquals(5, o.size());        Assert.assertEquals("foo", o.get("col1"));        Assert.assertEquals("bar", o.get("col2"));        Assert.assertEquals("grok", o.get("col3"));        Assert.assertEquals(null, o.get(" col2"));        Assert.assertEquals(null, o.get("col3 "));    }    {        UnitTestHelper.setLog4jLevel(CSVParser.class, Level.FATAL);        String line = "foo";        try {            List<JSONObject> results = parser.parse(Bytes.toBytes(line));            Assert.fail("Expected exception");        } catch (IllegalStateException iae) {        }        UnitTestHelper.setLog4jLevel(CSVParser.class, Level.ERROR);    }}
0
public void getsReadCharsetFromConfig() throws IOException
{    SensorParserConfig config = JSONUtils.INSTANCE.load(parserConfig, SensorParserConfig.class);    CSVParser parser = new CSVParser();    parser.init();    config.getParserConfig().put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config.getParserConfig());    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault() throws IOException
{    SensorParserConfig config = JSONUtils.INSTANCE.load(parserConfig, SensorParserConfig.class);    CSVParser parser = new CSVParser();    parser.init();    parser.configure(config.getParserConfig());    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void test() throws IOException, ParseException
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("grokPath", getGrokPath());    parserConfig.put("patternLabel", getGrokPatternLabel());    parserConfig.put("timestampField", getTimestampField());    parserConfig.put("dateFormat", getDateFormat());    parserConfig.put("timeFields", getTimeFields());    GrokParser grokParser = new GrokParser();    grokParser.configure(parserConfig);    grokParser.init();    JSONParser jsonParser = new JSONParser();    Map<String, String> testData = getTestData();    for (Map.Entry<String, String> e : testData.entrySet()) {        JSONObject expected = (JSONObject) jsonParser.parse(e.getValue());        byte[] rawMessage = e.getKey().getBytes(StandardCharsets.UTF_8);        Optional<MessageParserResult<JSONObject>> resultOptional = grokParser.parseOptionalResult(rawMessage);        Assert.assertNotNull(resultOptional);        Assert.assertTrue(resultOptional.isPresent());        List<JSONObject> parsedList = resultOptional.get().getMessages();        Assert.assertEquals(1, parsedList.size());        compare(expected, parsedList.get(0));    }}
0
public boolean compare(JSONObject expected, JSONObject actual)
{    MapDifference mapDifferences = Maps.difference(expected, actual);    if (mapDifferences.entriesOnlyOnLeft().size() > 0)        Assert.fail("Expected JSON has extra parameters: " + mapDifferences.entriesOnlyOnLeft());    if (mapDifferences.entriesOnlyOnRight().size() > 0)        Assert.fail("Actual JSON has extra parameters: " + mapDifferences.entriesOnlyOnRight());    Map actualDifferences = new HashMap();    if (mapDifferences.entriesDiffering().size() > 0) {        Map differences = Collections.unmodifiableMap(mapDifferences.entriesDiffering());        for (Object key : differences.keySet()) {            Object expectedValueObject = expected.get(key);            Object actualValueObject = actual.get(key);            if (expectedValueObject instanceof Long || expectedValueObject instanceof Integer) {                Long expectedValue = Long.parseLong(expectedValueObject.toString());                Long actualValue = Long.parseLong(actualValueObject.toString());                if (!expectedValue.equals(actualValue)) {                    actualDifferences.put(key, differences.get(key));                }            } else {                actualDifferences.put(key, differences.get(key));            }        }    }    if (actualDifferences.size() > 0)        Assert.fail("Expected and Actual JSON values don't match: " + actualDifferences);    return true;}
0
public void testEnvelopedData(ParserDriver driver) throws IOException
{    Map<String, Object> inputRecord = new HashMap<String, Object>() {        {            put(Constants.Fields.ORIGINAL.getName(), "real_original_string");            put("data", "field1_val,100");            put("metadata_field", "metadata_val");        }    };    ProcessorResult<List<byte[]>> results = driver.run(ImmutableList.of(JSONUtils.INSTANCE.toJSONPretty(inputRecord)));    Assert.assertFalse(results.failed());    List<byte[]> resultList = results.getResult();    Assert.assertEquals(1, resultList.size());    Map<String, Object> outputRecord = JSONUtils.INSTANCE.load(new String(resultList.get(0), StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER);    Assert.assertEquals("field1_val", outputRecord.get("field1"));    Assert.assertEquals(inputRecord.get(Constants.Fields.ORIGINAL.getName()), outputRecord.get(Constants.Fields.ORIGINAL.getName()));    Assert.assertEquals(inputRecord.get(MetadataUtil.METADATA_PREFIX + ".metadata_field"), outputRecord.get("metadata_field"));}
0
public void testEnvelopedData_withMetadataPrefix(ParserDriver driver) throws IOException
{    Map<String, Object> inputRecord = new HashMap<String, Object>() {        {            put(Constants.Fields.ORIGINAL.getName(), "real_original_string");            put("data", "field1_val,100");            put("metadata_field", "metadata_val");        }    };    ProcessorResult<List<byte[]>> results = driver.run(ImmutableList.of(JSONUtils.INSTANCE.toJSONPretty(inputRecord)));    Assert.assertFalse(results.failed());    List<byte[]> resultList = results.getResult();    Assert.assertEquals(1, resultList.size());    Map<String, Object> outputRecord = JSONUtils.INSTANCE.load(new String(resultList.get(0), StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER);    Assert.assertEquals("field1_val", outputRecord.get("field1"));    Assert.assertEquals(inputRecord.get(Constants.Fields.ORIGINAL.getName()), outputRecord.get(Constants.Fields.ORIGINAL.getName()));    Assert.assertEquals(inputRecord.get("metadata_field"), outputRecord.get("metadata_field"));}
0
public void testEnvelopedData_noMergeMetadata(ParserDriver driver) throws IOException
{    Map<String, Object> inputRecord = new HashMap<String, Object>() {        {            put(Constants.Fields.ORIGINAL.getName(), "real_original_string");            put("data", "field1_val,100");            put("metadata_field", "metadata_val");        }    };    ProcessorResult<List<byte[]>> results = driver.run(ImmutableList.of(JSONUtils.INSTANCE.toJSONPretty(inputRecord)));    Assert.assertFalse(results.failed());    List<byte[]> resultList = results.getResult();    Assert.assertEquals(1, resultList.size());    Map<String, Object> outputRecord = JSONUtils.INSTANCE.load(new String(resultList.get(0), StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER);    Assert.assertEquals("field1_val", outputRecord.get("field1"));    Assert.assertEquals(inputRecord.get(Constants.Fields.ORIGINAL.getName()), outputRecord.get(Constants.Fields.ORIGINAL.getName()));    Assert.assertFalse(outputRecord.containsKey(MetadataUtil.METADATA_PREFIX + ".metadata_field"));}
0
public void testCiscoPixEnvelopingCisco302020(ParserDriver syslogDriver, ParserDriver driver) throws Exception
{    byte[] envelopedData = null;    String inputRecord = "Mar 29 2004 09:54:18: %PIX-6-302005: Built UDP connection for faddr 198.207.223.240/53337 gaddr 10.0.0.187/53 laddr 192.168.0.2/53";    ProcessorResult<List<byte[]>> syslogResult = syslogDriver.run(ImmutableList.of(inputRecord.getBytes(StandardCharsets.UTF_8)));    Assert.assertFalse(syslogResult.failed());    List<byte[]> syslogResultList = syslogResult.getResult();    envelopedData = syslogResultList.get(0);    ProcessorResult<List<byte[]>> results = driver.run(ImmutableList.of(envelopedData));    Assert.assertFalse(results.failed());    List<byte[]> resultList = results.getResult();    Assert.assertEquals(1, resultList.size());    Map<String, Object> result = JSONUtils.INSTANCE.load(new String(resultList.get(0), StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER);    Assert.assertEquals("UDP", result.get("protocol"));    Assert.assertTrue((long) result.get("timestamp") > 1000);}
0
protected String readGlobalConfig() throws IOException
{    File configsRoot = new File("../" + TestConstants.SAMPLE_CONFIG_PATH);    return new String(Files.readAllBytes(new File(configsRoot, "global.json").toPath()), StandardCharsets.UTF_8);}
0
protected String readSensorConfig(String sensorType) throws IOException
{        File configsRoot = new File("../" + TestConstants.PARSER_COMMON_CONFIGS_PATH);    File parsersRoot = new File(configsRoot, "parsers");    System.out.println("Workspace: " + System.getProperty("user.dir"));    System.out.println("Parsers root: " + parsersRoot);    if (!Files.exists(new File(parsersRoot, sensorType + ".json").toPath())) {                configsRoot = new File("../" + TestConstants.PARSER_CONFIGS_PATH);        parsersRoot = new File(configsRoot, "parsers");    }    return new String(Files.readAllBytes(new File(parsersRoot, sensorType + ".json").toPath()), StandardCharsets.UTF_8);}
0
public void runTest(ParserDriver driver) throws Exception
{    String sensorType = driver.getSensorType();    inputMessages = TestUtils.readSampleData(SampleDataUtils.getSampleDataPath("..", sensorType, TestDataType.RAW));    ProcessorResult<List<byte[]>> result = driver.run(inputMessages);    List<byte[]> outputMessages = result.getResult();    StringBuffer buffer = new StringBuffer();    if (result.failed()) {        result.getBadResults(buffer);        buffer.append(String.format("%d Valid Messages Processed", outputMessages.size())).append("\n");        dumpParsedMessages(outputMessages, buffer);        Assert.fail(buffer.toString());    } else {        List<ParserValidation> validations = getValidations();        if (validations == null || validations.isEmpty()) {            buffer.append("No validations configured for sensorType ").append(sensorType).append(".  Dumping parsed messages").append("\n");            dumpParsedMessages(outputMessages, buffer);            Assert.fail(buffer.toString());        } else {            for (ParserValidation validation : validations) {                System.out.println("Running " + validation.getName() + " on sensorType " + sensorType);                validation.validate(sensorType, outputMessages);            }        }    }}
0
public void dumpParsedMessages(List<byte[]> outputMessages, StringBuffer buffer)
{    for (byte[] outputMessage : outputMessages) {        buffer.append(new String(outputMessage, StandardCharsets.UTF_8)).append("\n");    }}
0
public String getSensorType()
{    return sensorType;}
0
public String getName()
{    return "Sample Data Validation";}
0
public void validate(String sensorType, List<byte[]> actualMessages) throws Exception
{    List<byte[]> expectedMessages = TestUtils.readSampleData(SampleDataUtils.getSampleDataPath("..", sensorType, TestDataType.PARSED));    Assert.assertEquals(expectedMessages.size(), actualMessages.size());    for (int i = 0; i < actualMessages.size(); i++) {        String expectedMessage = new String(expectedMessages.get(i), StandardCharsets.UTF_8);        String actualMessage = new String(actualMessages.get(i), StandardCharsets.UTF_8);        try {            ValidationUtils.assertJsonEqual(expectedMessage, actualMessage);        } catch (Throwable t) {            System.out.println("expected: " + expectedMessage);            System.out.println("actual: " + actualMessage);            throw t;        }    }}
0
public void testHappyPath()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$.foo");        }    });    List<JSONObject> output = parser.parse(JSON_LIST.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(2, output.size());    JSONObject message = output.get(0);        Assert.assertEquals(4, message.size());    Assert.assertEquals("foo1", message.get("name"));    Assert.assertEquals("bar", message.get("value"));    Assert.assertEquals(1.0, message.get("number"));    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertNotNull(message.get("number"));    Assert.assertTrue(message.get("number") instanceof Number);    Assert.assertThat("original_string should be handled external to the parser by default", message.containsKey(Fields.ORIGINAL.getName()), equalTo(false));    message = output.get(1);        Assert.assertEquals(4, message.size());    Assert.assertEquals("foo2", message.get("name"));    Assert.assertEquals("baz", message.get("value"));    Assert.assertEquals(2.0, message.get("number"));    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertNotNull(message.get("number"));    Assert.assertTrue(message.get("number") instanceof Number);    Assert.assertThat("original_string should be handled external to the parser by default", message.containsKey(Fields.ORIGINAL.getName()), equalTo(false));}
0
public void testOriginalStringHandledByParser()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$.foo");            put(JSONMapParser.OVERRIDE_ORIGINAL_STRING, true);        }    });    List<JSONObject> output = parser.parse(JSON_LIST.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(2, output.size());    JSONObject message = output.get(0);        Assert.assertEquals(5, message.size());    Assert.assertEquals("foo1", message.get("name"));    Assert.assertEquals("bar", message.get("value"));    Assert.assertEquals(1.0, message.get("number"));    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertNotNull(message.get("number"));    Assert.assertTrue(message.get("number") instanceof Number);    Assert.assertThat("original_string should have been handled by the parser", message.get(Fields.ORIGINAL.getName()), equalTo("{\"name\":\"foo1\",\"number\":1.0,\"value\":\"bar\"}"));    message = output.get(1);        Assert.assertEquals(5, message.size());    Assert.assertEquals("foo2", message.get("name"));    Assert.assertEquals("baz", message.get("value"));    Assert.assertEquals(2.0, message.get("number"));    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertNotNull(message.get("number"));    Assert.assertTrue(message.get("number") instanceof Number);    Assert.assertThat("original_string should have been handled by the parser", message.get(Fields.ORIGINAL.getName()), equalTo("{\"name\":\"foo2\",\"number\":2.0,\"value\":\"baz\"}"));}
0
public void testInvalidJSONPathThrows()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$$..$$SDSE$#$#.");        }    });    List<JSONObject> output = parser.parse(JSON_LIST.getBytes(StandardCharsets.UTF_8));}
0
public void testNoMatchesNoExceptions()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$.foo");        }    });    List<JSONObject> output = parser.parse(JSON_SINGLE.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(0, output.size());}
0
public void testCollectionHandlingDrop()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$.foo");        }    });    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 2);        Assert.assertEquals(output.get(0).size(), 1);    JSONObject message = output.get(0);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    message = output.get(1);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void testCollectionHandlingError()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.ERROR.name(), JSONMapParser.JSONP_QUERY, "$.foo"));    UnitTestHelper.setLog4jLevel(BasicParser.class, Level.FATAL);    parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    UnitTestHelper.setLog4jLevel(BasicParser.class, Level.ERROR);}
0
public void testCollectionHandlingAllow()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.ALLOW.name(), JSONMapParser.JSONP_QUERY, "$.foo"));    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 2);    Assert.assertEquals(output.get(0).size(), 2);    JSONObject message = output.get(0);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertEquals(output.get(1).size(), 2);    message = output.get(1);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void testCollectionHandlingUnfold()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.UNFOLD.name(), JSONMapParser.JSONP_QUERY, "$.foo"));    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 2);    Assert.assertEquals(output.get(0).size(), 5);    JSONObject message = output.get(0);    Assert.assertEquals(message.get("collection.blah"), 7);    Assert.assertEquals(message.get("collection.blah2"), "foo");    Assert.assertEquals(message.get("collection.bigblah.innerBlah"), "baz");    Assert.assertEquals(message.get("collection.bigblah.reallyInnerBlah.color"), "grey");    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertEquals(output.get(1).size(), 5);    message = output.get(1);    Assert.assertEquals(message.get("collection.blah"), 8);    Assert.assertEquals(message.get("collection.blah2"), "bar");    Assert.assertEquals(message.get("collection.bigblah.innerBlah"), "baz2");    Assert.assertEquals(message.get("collection.bigblah.reallyInnerBlah.color"), "blue");    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void setup()
{    parser = new JSONMapParser();}
0
public void testHappyPath()
{    List<JSONObject> output = parser.parse(happyPathJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 1);        Assert.assertEquals(output.get(0).size(), 4);    JSONObject message = output.get(0);    Assert.assertEquals("bar", message.get("foo"));    Assert.assertEquals("blah", message.get("blah"));    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertNotNull(message.get("number"));    Assert.assertTrue(message.get("number") instanceof Number);}
0
public void testCollectionHandlingDrop()
{    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 1);        Assert.assertEquals(output.get(0).size(), 1);    JSONObject message = output.get(0);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void testCollectionHandlingError()
{    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.ERROR.name()));    UnitTestHelper.setLog4jLevel(BasicParser.class, Level.FATAL);    parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    UnitTestHelper.setLog4jLevel(BasicParser.class, Level.ERROR);}
0
public void testCollectionHandlingAllow()
{    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.ALLOW.name()));    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 1);        Assert.assertEquals(output.get(0).size(), 2);    JSONObject message = output.get(0);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void testCollectionHandlingUnfold()
{    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.UNFOLD.name()));    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 1);        Assert.assertEquals(output.get(0).size(), 5);    JSONObject message = output.get(0);    Assert.assertEquals(message.get("collection.blah"), 7);    Assert.assertEquals(message.get("collection.blah2"), "foo");    Assert.assertEquals(message.get("collection.bigblah.innerBlah"), "baz");    Assert.assertEquals(message.get("collection.bigblah.reallyInnerBlah.color"), "grey");    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void testMixedCollectionHandlingUnfold()
{    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.UNFOLD.name()));    List<JSONObject> output = parser.parse(mixCollectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.get(0).size(), 3);    JSONObject message = output.get(0);    Assert.assertEquals(message.get("collection.key"), "value");    Assert.assertEquals(message.get("key"), "value");    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void getsReadCharsetFromConfig()
{    Map<String, Object> config = new HashMap<>();    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault()
{    Map<String, Object> config = new HashMap<>();    parser.configure(config);    assertThat(parser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public void testHappyPath()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.WRAP_JSON, true);            put(JSONMapParser.WRAP_ENTITY_NAME, "foo");            put(JSONMapParser.JSONP_QUERY, "$.foo");        }    });    List<JSONObject> output = parser.parse(JSON_LIST.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 2);        Assert.assertEquals(output.get(0).size(), 4);    JSONObject message = output.get(0);    Assert.assertEquals("foo1", message.get("name"));    Assert.assertEquals("bar", message.get("value"));    Assert.assertEquals(1.0, message.get("number"));    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertNotNull(message.get("number"));    Assert.assertTrue(message.get("number") instanceof Number);    message = output.get(1);    Assert.assertEquals("foo2", message.get("name"));    Assert.assertEquals("baz", message.get("value"));    Assert.assertEquals(2.0, message.get("number"));    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertNotNull(message.get("number"));    Assert.assertTrue(message.get("number") instanceof Number);}
0
public void testInvalidJSONPathThrows()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$$..$$SDSE$#$#.");        }    });    List<JSONObject> output = parser.parse(JSON_LIST.getBytes(StandardCharsets.UTF_8));}
0
public void testNoMatchesNoExceptions()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$.foo");        }    });    List<JSONObject> output = parser.parse(JSON_SINGLE.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(0, output.size());}
0
public void testCollectionHandlingDrop()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(new HashMap<String, Object>() {        {            put(JSONMapParser.JSONP_QUERY, "$.foo");        }    });    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 2);        Assert.assertEquals(output.get(0).size(), 1);    JSONObject message = output.get(0);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    message = output.get(1);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void testCollectionHandlingError()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.ERROR.name(), JSONMapParser.JSONP_QUERY, "$.foo"));    UnitTestHelper.setLog4jLevel(BasicParser.class, Level.FATAL);    parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    UnitTestHelper.setLog4jLevel(BasicParser.class, Level.ERROR);}
0
public void testCollectionHandlingAllow()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.ALLOW.name(), JSONMapParser.JSONP_QUERY, "$.foo"));    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 2);    Assert.assertEquals(output.get(0).size(), 2);    JSONObject message = output.get(0);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertEquals(output.get(1).size(), 2);    message = output.get(1);    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void testCollectionHandlingUnfold()
{    JSONMapParser parser = new JSONMapParser();    parser.configure(ImmutableMap.of(JSONMapParser.MAP_STRATEGY_CONFIG, JSONMapParser.MapStrategy.UNFOLD.name(), JSONMapParser.JSONP_QUERY, "$.foo"));    List<JSONObject> output = parser.parse(collectionHandlingJSON.getBytes(StandardCharsets.UTF_8));    Assert.assertEquals(output.size(), 2);    Assert.assertEquals(output.get(0).size(), 5);    JSONObject message = output.get(0);    Assert.assertEquals(message.get("collection.blah"), 7);    Assert.assertEquals(message.get("collection.blah2"), "foo");    Assert.assertEquals(message.get("collection.bigblah.innerBlah"), "baz");    Assert.assertEquals(message.get("collection.bigblah.reallyInnerBlah.color"), "grey");    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);    Assert.assertEquals(output.get(1).size(), 5);    message = output.get(1);    Assert.assertEquals(message.get("collection.blah"), 8);    Assert.assertEquals(message.get("collection.blah2"), "bar");    Assert.assertEquals(message.get("collection.bigblah.innerBlah"), "baz2");    Assert.assertEquals(message.get("collection.bigblah.reallyInnerBlah.color"), "blue");    Assert.assertNotNull(message.get("timestamp"));    Assert.assertTrue(message.get("timestamp") instanceof Number);}
0
public void init()
{}
0
public boolean validate(JSONObject message)
{    return false;}
0
public void configure(Map<String, Object> config)
{}
0
public void testNullable() throws Exception
{    MessageParser parser = new TestMessageParser() {        @Override        public List<JSONObject> parse(byte[] rawMessage) {            return null;        }    };    Assert.assertNotNull(parser.parseOptionalResult(null));    Assert.assertFalse(parser.parseOptionalResult(null).isPresent());}
0
public List<JSONObject> parse(byte[] rawMessage)
{    return null;}
0
public void testNotNullable() throws Exception
{    MessageParser<JSONObject> parser = new TestMessageParser() {        @Override        public List<JSONObject> parse(byte[] rawMessage) {            return new ArrayList<>();        }    };    Assert.assertNotNull(parser.parseOptionalResult(null));    Optional<MessageParserResult<JSONObject>> ret = parser.parseOptionalResult(null);    Assert.assertTrue(ret.isPresent());    Assert.assertEquals(0, ret.get().getMessages().size());}
0
public List<JSONObject> parse(byte[] rawMessage)
{    return new ArrayList<>();}
0
public void testParse()
{    JSONObject message = new JSONObject();    MessageParser<JSONObject> parser = new TestMessageParser() {        @Override        public List<JSONObject> parse(byte[] rawMessage) {            return Collections.singletonList(message);        }    };    Optional<MessageParserResult<JSONObject>> ret = parser.parseOptionalResult("message".getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(ret.isPresent());    Assert.assertEquals(1, ret.get().getMessages().size());    Assert.assertEquals(message, ret.get().getMessages().get(0));}
0
public List<JSONObject> parse(byte[] rawMessage)
{    return Collections.singletonList(message);}
0
public void testParseOptional()
{    JSONObject message = new JSONObject();    MessageParser<JSONObject> parser = new TestMessageParser() {        @Override        public Optional<List<JSONObject>> parseOptional(byte[] rawMessage) {            return Optional.of(Collections.singletonList(message));        }    };    Optional<MessageParserResult<JSONObject>> ret = parser.parseOptionalResult("message".getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(ret.isPresent());    Assert.assertEquals(1, ret.get().getMessages().size());    Assert.assertEquals(message, ret.get().getMessages().get(0));}
0
public Optional<List<JSONObject>> parseOptional(byte[] rawMessage)
{    return Optional.of(Collections.singletonList(message));}
0
public void testParseException()
{    MessageParser<JSONObject> parser = new TestMessageParser() {        @Override        public List<JSONObject> parse(byte[] rawMessage) {            throw new RuntimeException("parse exception");        }    };    Optional<MessageParserResult<JSONObject>> ret = parser.parseOptionalResult("message".getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(ret.isPresent());    Assert.assertTrue(ret.get().getMasterThrowable().isPresent());    Assert.assertEquals("parse exception", ret.get().getMasterThrowable().get().getMessage());}
0
public List<JSONObject> parse(byte[] rawMessage)
{    throw new RuntimeException("parse exception");}
0
public void testParseOptionalException()
{    MessageParser<JSONObject> parser = new TestMessageParser() {        @Override        public Optional<List<JSONObject>> parseOptional(byte[] rawMessage) {            throw new RuntimeException("parse exception");        }    };    Optional<MessageParserResult<JSONObject>> ret = parser.parseOptionalResult("message".getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(ret.isPresent());    Assert.assertTrue(ret.get().getMasterThrowable().isPresent());    Assert.assertEquals("parse exception", ret.get().getMasterThrowable().get().getMessage());}
0
public Optional<List<JSONObject>> parseOptional(byte[] rawMessage)
{    throw new RuntimeException("parse exception");}
0
public void testLegacyInterfaceReturnsMultiline() throws IOException, ParseException
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("grokPath", getGrokPath());    parserConfig.put("patternLabel", getGrokPatternLabel());    parserConfig.put("timestampField", getTimestampField());    parserConfig.put("dateFormat", getDateFormat());    parserConfig.put("timeFields", getTimeFields());    parserConfig.put("multiLine", getMultiLine());    GrokParser grokParser = new GrokParser();    grokParser.configure(parserConfig);    grokParser.init();    JSONParser jsonParser = new JSONParser();    Map<String, String> testData = getTestData();    for (Map.Entry<String, String> e : testData.entrySet()) {        byte[] rawMessage = e.getKey().getBytes(StandardCharsets.UTF_8);        Optional<MessageParserResult<JSONObject>> resultOptional = grokParser.parseOptionalResult(rawMessage);        Assert.assertNotNull(resultOptional);        Assert.assertTrue(resultOptional.isPresent());        List<JSONObject> parsedList = resultOptional.get().getMessages();        Assert.assertEquals(10, parsedList.size());    }}
0
public void testOptionalResultReturnsMultiline() throws IOException, ParseException
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("grokPath", getGrokPath());    parserConfig.put("patternLabel", getGrokPatternLabel());    parserConfig.put("timestampField", getTimestampField());    parserConfig.put("dateFormat", getDateFormat());    parserConfig.put("timeFields", getTimeFields());    parserConfig.put("multiLine", getMultiLine());    GrokParser grokParser = new GrokParser();    grokParser.configure(parserConfig);    grokParser.init();    JSONParser jsonParser = new JSONParser();    Map<String, String> testData = getTestData();    for (Map.Entry<String, String> e : testData.entrySet()) {        byte[] rawMessage = e.getKey().getBytes(StandardCharsets.UTF_8);        Optional<MessageParserResult<JSONObject>> resultOptional = grokParser.parseOptionalResult(rawMessage);        Assert.assertTrue(resultOptional.isPresent());        Optional<Throwable> throwableOptional = resultOptional.get().getMasterThrowable();        List<JSONObject> resultList = resultOptional.get().getMessages();        Map<Object, Throwable> errorMap = resultOptional.get().getMessageThrowables();        Assert.assertFalse(throwableOptional.isPresent());        Assert.assertEquals(0, errorMap.size());        Assert.assertEquals(10, resultList.size());    }}
0
public Map getTestData()
{    Map testData = new HashMap<String, String>();    String input;    try (FileInputStream stream = new FileInputStream(new File("src/test/resources/logData/multi_elb_log.txt"))) {        input = IOUtils.toString(stream);    } catch (IOException ioe) {        throw new IllegalStateException("failed to open file", ioe);    }        testData.put(input, "");    return testData;}
0
public String getMultiLine()
{    return "true";}
0
public String getGrokPath()
{    return "../../metron-integration-test/src/main/sample/patterns/test";}
0
public String getGrokPatternLabel()
{    return "ELBACCESSLOGS";}
0
public List<String> getTimeFields()
{    return new ArrayList<String>() {        {            add("timestamp");        }    };}
0
public String getDateFormat()
{    return "yyyy-MM-dd'T'HH:mm:ss.S'Z'";}
0
public String getTimestampField()
{    return "timestamp";}
0
public void testLegacyInterfaceThrowsOneExceptionWithMultiline() throws IOException, ParseException
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("grokPath", getGrokPath());    parserConfig.put("patternLabel", getGrokPatternLabel());    parserConfig.put("timestampField", getTimestampField());    parserConfig.put("dateFormat", getDateFormat());    parserConfig.put("timeFields", getTimeFields());    parserConfig.put("multiLine", getMultiLine());    GrokParser grokParser = new GrokParser();    grokParser.configure(parserConfig);    grokParser.init();    JSONParser jsonParser = new JSONParser();    Map<String, String> testData = getTestData();    for (Map.Entry<String, String> e : testData.entrySet()) {        byte[] rawMessage = e.getKey().getBytes(StandardCharsets.UTF_8);        List<JSONObject> parsedList = grokParser.parse(rawMessage);    }}
0
public void testResultInterfaceReturnsErrorsAndMessagesWithMultiline() throws IOException, ParseException
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("grokPath", getGrokPath());    parserConfig.put("patternLabel", getGrokPatternLabel());    parserConfig.put("timestampField", getTimestampField());    parserConfig.put("dateFormat", getDateFormat());    parserConfig.put("timeFields", getTimeFields());    parserConfig.put("multiLine", getMultiLine());    GrokParser grokParser = new GrokParser();    grokParser.configure(parserConfig);    grokParser.init();    JSONParser jsonParser = new JSONParser();    Map<String, String> testData = getTestData();    for (Map.Entry<String, String> e : testData.entrySet()) {        byte[] rawMessage = e.getKey().getBytes(StandardCharsets.UTF_8);        Optional<MessageParserResult<JSONObject>> resultOptional = grokParser.parseOptionalResult(rawMessage);        Assert.assertTrue(resultOptional.isPresent());        Optional<Throwable> throwableOptional = resultOptional.get().getMasterThrowable();        List<JSONObject> resultList = resultOptional.get().getMessages();        Map<Object, Throwable> errorMap = resultOptional.get().getMessageThrowables();        Assert.assertFalse(throwableOptional.isPresent());        Assert.assertEquals(3, errorMap.size());        Assert.assertEquals(10, resultList.size());    }}
0
public Map getTestData()
{    Map testData = new HashMap<String, String>();    String input;    try (FileInputStream stream = new FileInputStream(new File("src/test/resources/logData/multi_elb_with_errors_log.txt"))) {        input = IOUtils.toString(stream);    } catch (IOException ioe) {        throw new IllegalStateException("failed to open file", ioe);    }        testData.put(input, "");    return testData;}
0
public String getGrokPath()
{    return "../../metron-integration-test/src/main/sample/patterns/test";}
0
public String getGrokPatternLabel()
{    return "ELBACCESSLOGS";}
0
public List<String> getTimeFields()
{    return new ArrayList<String>() {        {            add("timestamp");        }    };}
0
public String getMultiLine()
{    return "true";}
0
public String getDateFormat()
{    return "yyyy-MM-dd'T'HH:mm:ss.S'Z'";}
0
public String getTimestampField()
{    return "timestamp";}
0
public void setup() throws IOException
{    parserConfigurations = new ParserConfigurations();    SensorParserConfig broConfig = SensorParserConfig.fromBytes(broConfigString.getBytes(StandardCharsets.UTF_8));    SensorParserConfig snortConfig = SensorParserConfig.fromBytes(snortConfigString.getBytes(StandardCharsets.UTF_8));    parserConfigurations.updateSensorParserConfig("bro", broConfig);    parserConfigurations.updateSensorParserConfig("snort", snortConfig);    parserConfigurations.updateGlobalConfig(JSONUtils.INSTANCE.load(globalConfigString, JSONUtils.MAP_SUPPLIER));    parserRunner = new ParserRunnerImpl(new HashSet<>(Arrays.asList("bro", "snort")));    broParser = mock(MessageParser.class);    snortParser = mock(MessageParser.class);    stellarFilter = mock(StellarFilter.class);    mockStatic(ReflectionUtils.class);    mockStatic(Filters.class);    when(broParser.getReadCharset()).thenReturn(StandardCharsets.UTF_8);    when(ReflectionUtils.createInstance("org.apache.metron.parsers.bro.BasicBroParser")).thenReturn(broParser);    when(ReflectionUtils.createInstance("org.apache.metron.parsers.snort.BasicSnortParser")).thenReturn(snortParser);    when(Filters.get("org.apache.metron.parsers.filters.StellarFilter", broConfig.getParserConfig())).thenReturn(stellarFilter);}
0
public void shouldThrowExceptionOnEmptyParserSupplier()
{    exception.expect(IllegalStateException.class);    exception.expectMessage("A parser config supplier must be set before initializing the ParserRunner.");    parserRunner.init(null, null);}
0
public void shouldThrowExceptionOnEmptyStellarContext()
{    exception.expect(IllegalStateException.class);    exception.expectMessage("A stellar context must be set before initializing the ParserRunner.");    parserRunner.init(() -> parserConfigurations, null);}
0
public void initShouldThrowExceptionOnMissingSensorParserConfig()
{    exception.expect(IllegalStateException.class);    exception.expectMessage("Could not initialize parsers.  Cannot find configuration for sensor test.");    parserRunner = new ParserRunnerImpl(new HashSet<String>() {        {            add("test");        }    });    parserRunner.init(() -> parserConfigurations, mock(Context.class));}
0
public void executeShouldThrowExceptionOnMissingSensorParserConfig()
{    exception.expect(IllegalStateException.class);    exception.expectMessage("Could not execute parser.  Cannot find configuration for sensor test.");    parserRunner = new ParserRunnerImpl(new HashSet<String>() {        {            add("test");        }    });    parserRunner.execute("test", mock(RawMessage.class), parserConfigurations);}
0
public void shouldInit() throws Exception
{    Context stellarContext = mock(Context.class);    Map<String, Object> broParserConfig = parserConfigurations.getSensorParserConfig("bro").getParserConfig();    Map<String, Object> snortParserConfig = parserConfigurations.getSensorParserConfig("snort").getParserConfig();    parserRunner.init(() -> parserConfigurations, stellarContext);    {                Assert.assertEquals(stellarContext, parserRunner.getStellarContext());    }    Map<String, ParserComponent> sensorToParserComponentMap = parserRunner.getSensorToParserComponentMap();    {                Assert.assertEquals(2, sensorToParserComponentMap.size());        ParserComponent broComponent = sensorToParserComponentMap.get("bro");        Assert.assertEquals(broParser, broComponent.getMessageParser());        Assert.assertEquals(stellarFilter, broComponent.getFilter());        verify(broParser, times(1)).init();        verify(broParser, times(1)).configure(broParserConfig);        verifyNoMoreInteractions(broParser);        verifyNoMoreInteractions(stellarFilter);    }    {                ParserComponent snortComponent = sensorToParserComponentMap.get("snort");        Assert.assertEquals(snortParser, snortComponent.getMessageParser());        Assert.assertNull(snortComponent.getFilter());        verify(snortParser, times(1)).init();        verify(snortParser, times(1)).configure(snortParserConfig);        verifyNoMoreInteractions(snortParser);    }}
0
public void shouldExecute()
{    parserRunner = spy(parserRunner);    RawMessage rawMessage = new RawMessage("raw_message".getBytes(StandardCharsets.UTF_8), new HashMap<>());    JSONObject parsedMessage1 = new JSONObject();    parsedMessage1.put("field", "parsedMessage1");    JSONObject parsedMessage2 = new JSONObject();    parsedMessage2.put("field", "parsedMessage2");    Object rawMessage1 = new RawMessage("raw_message1".getBytes(StandardCharsets.UTF_8), new HashMap<>());    Object rawMessage2 = new RawMessage("raw_message2".getBytes(StandardCharsets.UTF_8), new HashMap<>());    Throwable throwable1 = mock(Throwable.class);    Throwable throwable2 = mock(Throwable.class);    MessageParserResult<JSONObject> messageParserResult = new DefaultMessageParserResult<>(Arrays.asList(parsedMessage1, parsedMessage2), new HashMap<Object, Throwable>() {        {            put(rawMessage1, throwable1);            put(rawMessage2, throwable2);        }    });    JSONObject processedMessage = new JSONObject();    processedMessage.put("field", "processedMessage1");    MetronError processedError = new MetronError().withMessage("processedError");    ProcessResult processedMessageResult = mock(ProcessResult.class);    ProcessResult processedErrorResult = mock(ProcessResult.class);    when(broParser.parseOptionalResult(rawMessage.getMessage())).thenReturn(Optional.of(messageParserResult));    when(processedMessageResult.getMessage()).thenReturn(processedMessage);    when(processedErrorResult.isError()).thenReturn(true);    when(processedErrorResult.getError()).thenReturn(processedError);    doReturn(Optional.of(processedMessageResult)).when(parserRunner).processMessage("bro", parsedMessage1, rawMessage, broParser, parserConfigurations);    doReturn(Optional.of(processedErrorResult)).when(parserRunner).processMessage("bro", parsedMessage2, rawMessage, broParser, parserConfigurations);    MetronError expectedParseError1 = new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(throwable1).withSensorType(Collections.singleton("bro")).addRawMessage(rawMessage1);    MetronError expectedParseError2 = new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(throwable2).withSensorType(Collections.singleton("bro")).addRawMessage(rawMessage2);    parserRunner.setSensorToParserComponentMap(new HashMap<String, ParserComponent>() {        {            put("bro", new ParserComponent(broParser, stellarFilter));        }    });    ParserRunnerResults<JSONObject> parserRunnerResults = parserRunner.execute("bro", rawMessage, parserConfigurations);    Assert.assertEquals(1, parserRunnerResults.getMessages().size());    Assert.assertTrue(parserRunnerResults.getMessages().contains(processedMessage));    Assert.assertEquals(3, parserRunnerResults.getErrors().size());    Assert.assertTrue(parserRunnerResults.getErrors().contains(processedError));    Assert.assertTrue(parserRunnerResults.getErrors().contains(expectedParseError1));    Assert.assertTrue(parserRunnerResults.getErrors().contains(expectedParseError2));}
0
public void shouldExecuteWithMasterThrowable()
{    parserRunner = spy(parserRunner);    RawMessage rawMessage = new RawMessage("raw_message".getBytes(StandardCharsets.UTF_8), new HashMap<>());    Throwable masterThrowable = mock(Throwable.class);    MessageParserResult<JSONObject> messageParserResult = new DefaultMessageParserResult<>(masterThrowable);    when(broParser.parseOptionalResult(rawMessage.getMessage())).thenReturn(Optional.of(messageParserResult));    parserRunner.setSensorToParserComponentMap(new HashMap<String, ParserComponent>() {        {            put("bro", new ParserComponent(broParser, stellarFilter));        }    });    ParserRunnerResults<JSONObject> parserRunnerResults = parserRunner.execute("bro", rawMessage, parserConfigurations);    verify(parserRunner, times(0)).processMessage(any(), any(), any(), any(), any());    MetronError expectedError = new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(masterThrowable).withSensorType(Collections.singleton("bro")).addRawMessage(rawMessage.getMessage());    Assert.assertEquals(1, parserRunnerResults.getErrors().size());    Assert.assertTrue(parserRunnerResults.getErrors().contains(expectedError));}
0
public void shouldPopulateMessagesOnProcessMessage()
{    JSONObject inputMessage = new JSONObject();    inputMessage.put("guid", "guid");    inputMessage.put("ip_src_addr", "192.168.1.1");    inputMessage.put("ip_dst_addr", "192.168.1.2");    RawMessage rawMessage = new RawMessage("raw_message_for_testing".getBytes(StandardCharsets.UTF_8), new HashMap<>());    JSONObject expectedOutput = new JSONObject();    expectedOutput.put("guid", "guid");    expectedOutput.put("source.type", "bro");    expectedOutput.put("ip_src_addr", "192.168.1.1");    expectedOutput.put("ip_dst_addr", "192.168.1.2");    expectedOutput.put(Fields.ORIGINAL.getName(), "raw_message_for_testing");    when(stellarFilter.emit(expectedOutput, parserRunner.getStellarContext())).thenReturn(true);    when(broParser.validate(expectedOutput)).thenReturn(true);    parserRunner.setSensorToParserComponentMap(new HashMap<String, ParserComponent>() {        {            put("bro", new ParserComponent(broParser, stellarFilter));        }    });    Optional<ParserRunnerImpl.ProcessResult> processResult = parserRunner.processMessage("bro", inputMessage, rawMessage, broParser, parserConfigurations);    Assert.assertTrue(processResult.isPresent());    Assert.assertFalse(processResult.get().isError());    Assert.assertEquals(expectedOutput, processResult.get().getMessage());}
0
public void shouldNotOverwriteOriginalStringAddedByParser()
{    JSONObject inputMessage = new JSONObject();    inputMessage.put("guid", "guid");    inputMessage.put("ip_src_addr", "192.168.1.1");    inputMessage.put("ip_dst_addr", "192.168.1.2");    inputMessage.put(Fields.ORIGINAL.getName(), "original_string_added_by_parser");    RawMessage rawMessage = new RawMessage("raw_message_for_testing".getBytes(StandardCharsets.UTF_8), new HashMap<>());    JSONObject expectedOutput = new JSONObject();    expectedOutput.put("guid", "guid");    expectedOutput.put("source.type", "bro");    expectedOutput.put("ip_src_addr", "192.168.1.1");    expectedOutput.put("ip_dst_addr", "192.168.1.2");    expectedOutput.put(Fields.ORIGINAL.getName(), "original_string_added_by_parser");    when(stellarFilter.emit(expectedOutput, parserRunner.getStellarContext())).thenReturn(true);    when(broParser.validate(expectedOutput)).thenReturn(true);    parserRunner.setSensorToParserComponentMap(new HashMap<String, ParserComponent>() {        {            put("bro", new ParserComponent(broParser, stellarFilter));        }    });    Optional<ParserRunnerImpl.ProcessResult> processResult = parserRunner.processMessage("bro", inputMessage, rawMessage, broParser, parserConfigurations);    Assert.assertTrue(processResult.isPresent());    Assert.assertFalse(processResult.get().isError());    Assert.assertEquals(expectedOutput, processResult.get().getMessage());}
0
public void shouldReturnMetronErrorOnInvalidMessage()
{    Map<String, Object> metadata = new HashMap<>();    metadata.put("metron.metadata.topic", "bro");    metadata.put("metron.metadata.partition", 0);    metadata.put("metron.metadata.offset", 123);    JSONObject inputMessage = new JSONObject();    inputMessage.put("guid", "guid");    RawMessage rawMessage = new RawMessage("raw_message".getBytes(StandardCharsets.UTF_8), metadata);    JSONObject expectedOutput = new JSONObject();    expectedOutput.put("guid", "guid");    expectedOutput.put("source.type", "bro");    expectedOutput.put(Fields.ORIGINAL.getName(), "raw_message");    MetronError expectedMetronError = new MetronError().withErrorType(Constants.ErrorType.PARSER_INVALID).withSensorType(Collections.singleton("bro")).withMetadata(metadata).addRawMessage(inputMessage);    when(stellarFilter.emit(expectedOutput, parserRunner.getStellarContext())).thenReturn(true);        when(broParser.validate(expectedOutput)).thenReturn(false);    parserRunner.setSensorToParserComponentMap(new HashMap<String, ParserComponent>() {        {            put("bro", new ParserComponent(broParser, stellarFilter));        }    });    Optional<ParserRunnerImpl.ProcessResult> processResult = parserRunner.processMessage("bro", inputMessage, rawMessage, broParser, parserConfigurations);    Assert.assertTrue(processResult.isPresent());    Assert.assertTrue(processResult.get().isError());    Assert.assertEquals(expectedMetronError, processResult.get().getError());}
0
public void shouldReturnMetronErrorOnFailedFieldValidator()
{    Map<String, Object> metadata = new HashMap<>();    metadata.put("metron.metadata.topic", "bro");    metadata.put("metron.metadata.partition", 0);    metadata.put("metron.metadata.offset", 123);    JSONObject inputMessage = new JSONObject();    inputMessage.put("guid", "guid");    inputMessage.put("ip_src_addr", "test");    inputMessage.put("ip_dst_addr", "test");    RawMessage rawMessage = new RawMessage("raw_message".getBytes(StandardCharsets.UTF_8), metadata);    JSONObject expectedOutput = new JSONObject();    expectedOutput.put("guid", "guid");    expectedOutput.put("ip_src_addr", "test");    expectedOutput.put("ip_dst_addr", "test");    expectedOutput.put("source.type", "bro");    expectedOutput.put(Fields.ORIGINAL.getName(), "raw_message");    MetronError expectedMetronError = new MetronError().withErrorType(Constants.ErrorType.PARSER_INVALID).withSensorType(Collections.singleton("bro")).addRawMessage(inputMessage).withMetadata(metadata).withErrorFields(new HashSet<>(Arrays.asList("ip_src_addr", "ip_dst_addr")));    when(stellarFilter.emit(expectedOutput, parserRunner.getStellarContext())).thenReturn(true);    when(broParser.validate(expectedOutput)).thenReturn(true);    parserRunner.setSensorToParserComponentMap(new HashMap<String, ParserComponent>() {        {            put("bro", new ParserComponent(broParser, stellarFilter));        }    });    Optional<ParserRunnerImpl.ProcessResult> processResult = parserRunner.processMessage("bro", inputMessage, rawMessage, broParser, parserConfigurations);    Assert.assertTrue(processResult.isPresent());    Assert.assertTrue(processResult.get().isError());    Assert.assertEquals(expectedMetronError, processResult.get().getError());}
0
public void setUp() throws Exception
{    regularExpressionsParser = new RegularExpressionsParser();}
0
public void testSSHDParse() throws Exception
{    String message = "<38>Jun 20 15:01:17 deviceName sshd[11672]: Accepted publickey for prod from 22.22.22.22 port 55555 ssh2";    JSONObject parserConfig = (JSONObject) new JSONParser().parse(parserConfig1);    regularExpressionsParser.configure(parserConfig);    JSONObject parsed = parse(message);        Map<String, Object> expectedJson = new HashMap<>();    Assert.assertEquals(parsed.get("device_name"), "deviceName");    Assert.assertEquals(parsed.get("dst_process_name"), "sshd");    Assert.assertEquals(parsed.get("dst_process_id"), "11672");    Assert.assertEquals(parsed.get("dst_user_id"), "prod");    Assert.assertEquals(parsed.get("ip_src_addr"), "22.22.22.22");    Assert.assertEquals(parsed.get("ip_src_port"), "55555");    Assert.assertEquals(parsed.get("app_protocol"), "ssh2");    Assert.assertEquals(parsed.get("original_string"), "<38>Jun 20 15:01:17 deviceName sshd[11672]: Accepted publickey for prod from 22.22.22.22 port 55555 ssh2");    Assert.assertTrue(parsed.containsKey("timestamp"));}
0
public void testNoMessageHeaderRegex() throws Exception
{    String message = "<38>Jun 20 15:01:17 deviceName sshd[11672]: Accepted publickey for prod from 22.22.22.22 port 55555 ssh2";    JSONObject parserConfig = (JSONObject) new JSONParser().parse(parserConfigNoMessageHeader);    regularExpressionsParser.configure(parserConfig);    JSONObject parsed = parse(message);        Assert.assertEquals(parsed.get("dst_process_name"), "sshd");    Assert.assertEquals(parsed.get("dst_process_id"), "11672");    Assert.assertEquals(parsed.get("dst_user_id"), "prod");    Assert.assertEquals(parsed.get("ip_src_addr"), "22.22.22.22");    Assert.assertEquals(parsed.get("ip_src_port"), "55555");    Assert.assertEquals(parsed.get("app_protocol"), "ssh2");    Assert.assertEquals(parsed.get("original_string"), "<38>Jun 20 15:01:17 deviceName sshd[11672]: Accepted publickey for prod from 22.22.22.22 port 55555 ssh2");    Assert.assertTrue(parsed.containsKey("timestamp"));}
0
public void testMalformedRegex() throws Exception
{    String message = "<38>Jun 20 15:01:17 deviceName sshd[11672]: Accepted publickey for prod from 22.22.22.22 port 55555 ssh2";    JSONObject parserConfig = (JSONObject) new JSONParser().parse(invalidParserConfig);    regularExpressionsParser.configure(parserConfig);    parse(message);}
0
public void testNoRecordTypeRegex() throws Exception
{    String message = "<38>Jun 20 15:01:17 deviceName sshd[11672]: Accepted publickey for prod from 22.22.22.22 port 55555 ssh2";    JSONObject parserConfig = (JSONObject) new JSONParser().parse(noRecordTypeParserConfig);    regularExpressionsParser.configure(parserConfig);    parse(message);}
0
private JSONObject parse(String message) throws Exception
{    List<JSONObject> result = regularExpressionsParser.parse(message.getBytes(StandardCharsets.UTF_8));    if (result.size() > 0) {        return result.get(0);    }    throw new Exception("Could not parse : " + message);}
0
public void getsReadCharsetFromConfig() throws ParseException
{    JSONObject config = (JSONObject) new JSONParser().parse(parserConfig1);    config.put(MessageParser.READ_CHARSET, StandardCharsets.UTF_16.toString());    regularExpressionsParser.configure(config);    assertThat(regularExpressionsParser.getReadCharset(), equalTo(StandardCharsets.UTF_16));}
0
public void getsReadCharsetFromDefault() throws ParseException
{    JSONObject config = (JSONObject) new JSONParser().parse(parserConfig1);    regularExpressionsParser.configure(config);    assertThat(regularExpressionsParser.getReadCharset(), equalTo(StandardCharsets.UTF_8));}
0
public Map getTestData()
{    Map testData = new HashMap<String, String>();    String input = "1453994987000|2016-01-28 15:29:48|   0.000|   0.000|  6|                          216.21.170.221|   80|                               10.0.2.15|39468|      AS|       0|       0|       0|22efa001|00000000|000|000|       1|      44|       0|       0|    0|idle";    testData.put(input, result);    return testData;}
0
public String getMultiLine()
{    return "false";}
0
public String getGrokPath()
{    return "../../metron-integration-test/src/main/sample/patterns/test";}
0
public String getGrokPatternLabel()
{    return "YAF_DELIMITED";}
0
public List<String> getTimeFields()
{    return new ArrayList<String>() {        {            add("end_time");        }    };}
0
public String getDateFormat()
{    return "yyyy-MM-dd HH:mm:ss";}
0
public String getTimestampField()
{    return "start_time";}
0
public void testConfigureDefault()
{    Map<String, Object> parserConfig = new HashMap<>();    Syslog3164Parser testParser = new Syslog3164Parser();    testParser.configure(parserConfig);    testParser.init();    assertTrue(testParser.deviceClock.getZone().equals(ZoneOffset.UTC));}
0
public void testConfigureTimeZoneOffset()
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("deviceTimeZone", "UTC-05:00");    Syslog3164Parser testParser = new Syslog3164Parser();    testParser.configure(parserConfig);    testParser.init();    ZonedDateTime deviceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), testParser.deviceClock.getZone());    ZonedDateTime referenceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), ZoneOffset.ofHours(-5));    assertTrue(deviceTime.isEqual(referenceTime));}
0
public void testConfigureTimeZoneText()
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("deviceTimeZone", "America/New_York");    Syslog3164Parser testParser = new Syslog3164Parser();    testParser.configure(parserConfig);    testParser.init();    ZonedDateTime deviceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), testParser.deviceClock.getZone());    ZonedDateTime referenceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), ZoneOffset.ofHours(-5));    assertTrue(deviceTime.isEqual(referenceTime));}
0
public void testHappyPath()
{    test(expectedMessage1, (message) -> Assert.assertEquals(expectedHostNameOne, message.get(SyslogFieldKeys.HEADER_HOSTNAME.getField())));}
0
public void testNotValid()
{    test("not valid", (message) -> Assert.assertTrue(false));}
0
public void test(String line, Consumer<JSONObject> msgIdChecker)
{    Syslog3164Parser parser = new Syslog3164Parser();    Map<String, Object> config = new HashMap<>();    parser.configure(config);    parser.parseOptionalResult(line.getBytes(StandardCharsets.UTF_8));}
0
public void testReadMultiLine() throws Exception
{    Syslog3164Parser parser = new Syslog3164Parser();    Map<String, Object> config = new HashMap<>();    parser.configure(config);    StringBuilder builder = new StringBuilder();    builder.append(SYSLOG_LINE_ALL).append("\n").append(SYSLOG_LINE_MISSING).append("\n").append(SYSLOG_LINE_ALL);    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(builder.toString().getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> parsedList = resultOptional.get().getMessages();    Assert.assertEquals(3, parsedList.size());}
0
public void testReadMultiLineWithErrors() throws Exception
{    Syslog3164Parser parser = new Syslog3164Parser();    Map<String, Object> config = new HashMap<>();    parser.configure(config);    StringBuilder builder = new StringBuilder();    builder.append("HEREWEGO!!!!\n").append(SYSLOG_LINE_ALL).append("\n").append(SYSLOG_LINE_MISSING).append("\n").append("BOOM!\n").append(SYSLOG_LINE_ALL).append("\nOHMY!");    Optional<MessageParserResult<JSONObject>> output = parser.parseOptionalResult(builder.toString().getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(output.isPresent());    Assert.assertEquals(3, output.get().getMessages().size());    Assert.assertEquals(3, output.get().getMessageThrowables().size());}
0
public void testConfigureDefault()
{    Map<String, Object> parserConfig = new HashMap<>();    Syslog5424Parser testParser = new Syslog5424Parser();    testParser.configure(parserConfig);    testParser.init();    assertTrue(testParser.deviceClock.getZone().equals(ZoneOffset.UTC));}
0
public void testConfigureTimeZoneOffset()
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("deviceTimeZone", "UTC-05:00");    Syslog5424Parser testParser = new Syslog5424Parser();    testParser.configure(parserConfig);    testParser.init();    ZonedDateTime deviceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), testParser.deviceClock.getZone());    ZonedDateTime referenceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), ZoneOffset.ofHours(-5));    assertTrue(deviceTime.isEqual(referenceTime));}
0
public void testConfigureTimeZoneText()
{    Map<String, Object> parserConfig = new HashMap<>();    parserConfig.put("deviceTimeZone", "America/New_York");    Syslog5424Parser testParser = new Syslog5424Parser();    testParser.configure(parserConfig);    testParser.init();    ZonedDateTime deviceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), testParser.deviceClock.getZone());    ZonedDateTime referenceTime = ZonedDateTime.ofInstant(Instant.ofEpochSecond(1475323200), ZoneOffset.ofHours(-5));    assertTrue(deviceTime.isEqual(referenceTime));}
0
public void testHappyPath()
{    test(null, SYSLOG_LINE_ALL, (message) -> Assert.assertEquals(expectedMessageId, message.get(SyslogFieldKeys.HEADER_MSGID.getField())));}
0
public void testOmit()
{    test(NilPolicy.OMIT, SYSLOG_LINE_MISSING, (message) -> Assert.assertFalse(message.containsKey(SyslogFieldKeys.HEADER_MSGID)));}
0
public void testDash()
{    test(NilPolicy.DASH, SYSLOG_LINE_MISSING, (message) -> Assert.assertEquals("-", message.get(SyslogFieldKeys.HEADER_MSGID.getField())));}
0
public void testNull()
{    test(NilPolicy.NULL, SYSLOG_LINE_MISSING, (message) -> {        Assert.assertTrue(message.containsKey(SyslogFieldKeys.HEADER_MSGID.getField()));        Assert.assertNull(message.get(SyslogFieldKeys.HEADER_MSGID.getField()));    });}
0
public void testNotValid()
{    test(null, "not valid", (message) -> Assert.assertTrue(false));}
0
public void test(NilPolicy nilPolicy, String line, Consumer<JSONObject> msgIdChecker)
{    Syslog5424Parser parser = new Syslog5424Parser();    Map<String, Object> config = new HashMap<>();    if (nilPolicy != null) {        config.put(Syslog5424Parser.NIL_POLICY_CONFIG, nilPolicy.name());    }    parser.configure(config);    parser.parseOptionalResult(line.getBytes(StandardCharsets.UTF_8));}
0
public void testReadMultiLine() throws Exception
{    Syslog5424Parser parser = new Syslog5424Parser();    Map<String, Object> config = new HashMap<>();    config.put(Syslog5424Parser.NIL_POLICY_CONFIG, NilPolicy.DASH.name());    parser.configure(config);    StringBuilder builder = new StringBuilder();    builder.append(SYSLOG_LINE_ALL).append("\n").append(SYSLOG_LINE_MISSING).append("\n").append(SYSLOG_LINE_ALL);    Optional<MessageParserResult<JSONObject>> resultOptional = parser.parseOptionalResult(builder.toString().getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(resultOptional);    Assert.assertTrue(resultOptional.isPresent());    List<JSONObject> parsedList = resultOptional.get().getMessages();    Assert.assertEquals(3, parsedList.size());}
0
public void testReadMultiLineWithErrors() throws Exception
{    Syslog5424Parser parser = new Syslog5424Parser();    Map<String, Object> config = new HashMap<>();    config.put(Syslog5424Parser.NIL_POLICY_CONFIG, NilPolicy.DASH.name());    parser.configure(config);    StringBuilder builder = new StringBuilder();    builder.append("HEREWEGO!!!!\n").append(SYSLOG_LINE_ALL).append("\n").append(SYSLOG_LINE_MISSING).append("\n").append("BOOM!\n").append(SYSLOG_LINE_ALL).append("\nOHMY!");    Optional<MessageParserResult<JSONObject>> output = parser.parseOptionalResult(builder.toString().getBytes(StandardCharsets.UTF_8));    Assert.assertTrue(output.isPresent());    Assert.assertEquals(3, output.get().getMessages().size());    Assert.assertEquals(3, output.get().getMessageThrowables().size());}
0
public void testMissingTimestamp()
{    Syslog5424Parser parser = new Syslog5424Parser();    Map<String, Object> config = new HashMap<>();    String timeStampString = null;    config.put(Syslog5424Parser.NIL_POLICY_CONFIG, NilPolicy.DASH.name());    parser.configure(config);    Optional<MessageParserResult<JSONObject>> output = parser.parseOptionalResult(SYSLOG_LINE_MISSING_DATE.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(output);    Assert.assertTrue(output.isPresent());    Assert.assertNotNull(output.get().getMessages().get(0).get("timestamp").toString());    config.clear();    config.put(Syslog5424Parser.NIL_POLICY_CONFIG, NilPolicy.NULL.name());    parser.configure(config);    output = parser.parseOptionalResult(SYSLOG_LINE_MISSING_DATE.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(output);    Assert.assertTrue(output.isPresent());    timeStampString = output.get().getMessages().get(0).get("timestamp").toString();    Assert.assertNotNull(timeStampString);    config.clear();    config.put(Syslog5424Parser.NIL_POLICY_CONFIG, NilPolicy.OMIT.name());    parser.configure(config);    output = parser.parseOptionalResult(SYSLOG_LINE_MISSING_DATE.getBytes(StandardCharsets.UTF_8));    Assert.assertNotNull(output);    Assert.assertTrue(output.isPresent());}
0
public void testConvertToEpoch() throws ParseException
{    Boolean adjustTimezone = true;    String[] timeToTest = { "Mar", "2", "05:24:39" };    int year = Calendar.getInstance().get(Calendar.YEAR);    String timeToTestWithYear = String.valueOf(year) + " " + timeToTest[0] + " " + timeToTest[1] + " " + timeToTest[2];    SimpleDateFormat sdf = new SimpleDateFormat("yyyy MMM d HH:mm:ss", Locale.ENGLISH);    sdf.setTimeZone(TimeZone.getTimeZone("GMT"));    Date date = sdf.parse(timeToTestWithYear);    Long expectedTs = date.getTime();    Long ts = ParserUtils.convertToEpoch(timeToTest[0], timeToTest[1], timeToTest[2], adjustTimezone);    assertEquals(expectedTs, ts);}
0
public void testRfc3164Timestamp() throws ParseException
{    String originalTimestamp = "Oct  9 13:42:11";        ZonedDateTime fixedInstant = ZonedDateTime.of(2016, 10, 8, 18, 30, 30, 0, ZoneOffset.UTC);    Clock fixedClock = Clock.fixed(fixedInstant.toInstant(), fixedInstant.getZone());    assertEquals(SyslogUtils.parseTimestampToEpochMillis(originalTimestamp, fixedClock), 1476020531000L);}
0
public void testRfc3164TimestampBackDate() throws ParseException
{    String originalTimestamp = "Oct  9 13:42:11";        ZonedDateTime fixedInstant = ZonedDateTime.of(2016, 10, 1, 18, 30, 30, 0, ZoneOffset.UTC);    Clock fixedClock = Clock.fixed(fixedInstant.toInstant(), fixedInstant.getZone());    assertEquals(SyslogUtils.parseTimestampToEpochMillis(originalTimestamp, fixedClock), 1444398131000L);}
0
public void testCiscoTimestamp() throws ParseException
{    String originalTimestamp = "Oct 09 2015 13:42:11";    assertEquals(getParsedEpochMillis(originalTimestamp), 1444398131000L);}
0
public void testRfc5424TimestampUTC() throws ParseException
{    String originalTimestamp = "2015-10-09T13:42:11.52Z";    assertEquals(getParsedEpochMillis(originalTimestamp), 1444398131520L);}
0
public void testRfc5424TimestampWithOffset() throws ParseException
{    String originalTimestamp = "2015-10-09T08:42:11.52-05:00";    assertEquals(getParsedEpochMillis(originalTimestamp), 1444398131520L);}
0
private long getParsedEpochMillis(String originalTimestamp) throws ParseException
{    return SyslogUtils.parseTimestampToEpochMillis(originalTimestamp, Clock.systemUTC());}
0
public ParserBolt withBatchTimeoutDivisor(int batchTimeoutDivisor)
{    if (batchTimeoutDivisor <= 0) {        throw new IllegalArgumentException(String.format("batchTimeoutDivisor must be positive. Value provided was %s", batchTimeoutDivisor));    }    this.batchTimeoutDivisor = batchTimeoutDivisor;    return this;}
0
public int getBatchTimeoutDivisor()
{    return batchTimeoutDivisor;}
0
protected void setSensorToWriterMap(Map<String, WriterHandler> sensorToWriterMap)
{    this.sensorToWriterMap = sensorToWriterMap;}
0
protected Map<String, String> getTopicToSensorMap()
{    return topicToSensorMap;}
0
protected void setTopicToSensorMap(Map<String, String> topicToSensorMap)
{    this.topicToSensorMap = topicToSensorMap;}
0
public void setMessageGetStrategy(MessageGetStrategy messageGetStrategy)
{    this.messageGetStrategy = messageGetStrategy;}
0
public void setOutputCollector(OutputCollector collector)
{    this.collector = collector;}
0
public void setAckTuplesPolicy(AckTuplesPolicy ackTuplesPolicy)
{    this.ackTuplesPolicy = ackTuplesPolicy;}
0
public Map<String, Object> getComponentConfiguration()
{                Function<WriterConfiguration, WriterConfiguration> configurationXform;    WriterHandler writer = sensorToWriterMap.entrySet().iterator().next().getValue();    if (writer.isWriterToBulkWriter()) {        configurationXform = WriterToBulkWriter.TRANSFORMATION;    } else {        configurationXform = x -> x;    }    WriterConfiguration writerconf = configurationXform.apply(getConfigurationStrategy().createWriterConfig(writer.getBulkMessageWriter(), getConfigurations()));    BatchTimeoutHelper timeoutHelper = new BatchTimeoutHelper(writerconf::getAllConfiguredTimeouts, batchTimeoutDivisor);    this.requestedTickFreqSecs = timeoutHelper.getRecommendedTickInterval();        this.maxBatchTimeout = timeoutHelper.getMaxBatchTimeout();    Map<String, Object> conf = super.getComponentConfiguration();    if (conf == null) {        conf = new HashMap<>();    }    conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, requestedTickFreqSecs);        return conf;}
1
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)
{    super.prepare(stormConf, context, collector);    messageGetStrategy = MessageGetters.DEFAULT_BYTES_FROM_POSITION.get();    this.collector = collector;    this.parserRunner.init(this::getConfigurations, initializeStellar());    ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);        for (Map.Entry<String, WriterHandler> entry : sensorToWriterMap.entrySet()) {        String sensor = entry.getKey();        SensorParserConfig config = getSensorParserConfig(sensor);        if (config != null) {            config.init();            topicToSensorMap.put(config.getSensorTopic(), sensor);        } else {            throw new IllegalStateException("Unable to retrieve a parser config for " + sensor);        }        WriterHandler writer = sensorToWriterMap.get(sensor);        if (maxBatchTimeout == 0) {                                    WriterConfiguration writerConfig = getConfigurationStrategy().createWriterConfig(writer.getBulkMessageWriter(), getConfigurations());            BatchTimeoutHelper timeoutHelper = new BatchTimeoutHelper(writerConfig::getAllConfiguredTimeouts, batchTimeoutDivisor);            maxBatchTimeout = timeoutHelper.getMaxBatchTimeout();        }        writer.init(stormConf, context, collector, getConfigurations(), ackTuplesPolicy, maxBatchTimeout);    }}
0
public void execute(Tuple tuple)
{    if (TupleUtils.isTick(tuple)) {        handleTickTuple(tuple);        return;    }    byte[] originalMessage = (byte[]) messageGetStrategy.get(tuple);    String topic = tuple.getStringByField(FieldsConfiguration.TOPIC.getFieldName());    String sensorType = topicToSensorMap.get(topic);    try {        ParserConfigurations parserConfigurations = getConfigurations();        SensorParserConfig sensorParserConfig = parserConfigurations.getSensorParserConfig(sensorType);        RawMessage rawMessage = RawMessageUtil.INSTANCE.getRawMessage(sensorParserConfig.getRawMessageStrategy(), tuple, originalMessage, sensorParserConfig.getReadMetadata(), sensorParserConfig.getRawMessageStrategyConfig());        ParserRunnerResults<JSONObject> parserRunnerResults = parserRunner.execute(sensorType, rawMessage, parserConfigurations);        parserRunnerResults.getErrors().forEach(error -> handleError(collector, error));        WriterHandler writer = sensorToWriterMap.get(sensorType);        int numWritten = 0;        List<JSONObject> messages = parserRunnerResults.getMessages();        List<String> messageIds = messages.stream().map(MessageUtils::getGuid).collect(Collectors.toList());        ackTuplesPolicy.addTupleMessageIds(tuple, messageIds);        for (int i = 0; i < messages.size(); i++) {            String messageId = messageIds.get(i);            JSONObject message = messages.get(i);            try {                writer.write(sensorType, new BulkMessage<>(messageId, message), getConfigurations());                numWritten++;            } catch (Exception ex) {                handleError(sensorType, originalMessage, tuple, ex, collector);            }        }        if (numWritten == 0) {            collector.ack(tuple);        }    } catch (Throwable ex) {        handleError(sensorType, originalMessage, tuple, ex, collector);        collector.ack(tuple);    }}
0
protected Context initializeStellar()
{    Map<String, Object> cacheConfig = new HashMap<>();    for (String sensorType : this.parserRunner.getSensorTypes()) {        SensorParserConfig config = getSensorParserConfig(sensorType);        if (config != null) {            cacheConfig.putAll(config.getCacheConfig());        }    }    Cache<CachingStellarProcessor.Key, Object> cache = CachingStellarProcessor.createCache(cacheConfig);    Context.Builder builder = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client).with(Context.Capabilities.GLOBAL_CONFIG, () -> getConfigurations().getGlobalConfig()).with(Context.Capabilities.STELLAR_CONFIG, () -> getConfigurations().getGlobalConfig());    if (cache != null) {        builder = builder.with(Context.Capabilities.CACHE, () -> cache);    }    Context stellarContext = builder.build();    StellarFunctions.initialize(stellarContext);    return stellarContext;}
0
protected void handleTickTuple(Tuple tuple)
{    try {        for (Entry<String, WriterHandler> entry : sensorToWriterMap.entrySet()) {            entry.getValue().flush(getConfigurations(), messageGetStrategy);        }    } catch (Exception e) {        throw new RuntimeException("This should have been caught in the writerHandler.  If you see this, file a JIRA", e);    } finally {        collector.ack(tuple);    }}
0
protected void handleError(String sensorType, byte[] originalMessage, Tuple tuple, Throwable ex, OutputCollector collector)
{    MetronError error = new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(ex).withSensorType(Collections.singleton(sensorType)).addRawMessage(originalMessage);    handleError(collector, error);}
0
protected void handleError(OutputCollector collector, MetronError error)
{    StormErrorUtils.handleError(collector, error);}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    declarer.declareStream(Constants.ERROR_STREAM, new Fields("message"));}
0
public WriterBolt withErrorType(Constants.ErrorType errorType)
{    this.errorType = errorType;    return this;}
0
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)
{    this.collector = collector;    messageGetStrategy = MessageGetters.DEFAULT_JSON_FROM_FIELD.get();    ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);    handler.init(stormConf, context, collector, configuration, ackTuplesPolicy, UNINITIALIZED_MAX_BATCH_TIMEOUT);}
0
private JSONObject getMessage(Tuple tuple)
{    Object ret = tuple.getValueByField("message");    if (ret != null) {        ret = tuple.getValue(0);    }    if (ret != null) {        return (JSONObject) ((JSONObject) ret).clone();    } else {        return null;    }}
0
public void execute(Tuple tuple)
{    JSONObject message = null;    try {        message = (JSONObject) messageGetStrategy.get(tuple);        String messageId = MessageUtils.getGuid(message);        ackTuplesPolicy.addTupleMessageIds(tuple, Collections.singleton(messageId));        handler.write(sensorType, new BulkMessage<>(messageId, message), configuration);    } catch (Throwable e) {        MetronError error = new MetronError().withErrorType(errorType).withThrowable(e).withSensorType(Collections.singleton(sensorType)).addRawMessage(message);        StormErrorUtils.handleError(collector, error);        collector.ack(tuple);    }}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{}
0
public boolean isWriterToBulkWriter()
{    return messageWriter instanceof WriterToBulkWriter;}
0
public BulkMessageWriter getBulkMessageWriter()
{    return messageWriter;}
0
public void init(Map stormConf, TopologyContext topologyContext, OutputCollector collector, ParserConfigurations configurations, AckTuplesPolicy ackTuplesPolicy, int maxBatchTimeout)
{    if (isBulk) {        writerTransformer = config -> configStrategy.createWriterConfig(messageWriter, config);    } else {        writerTransformer = config -> new SingleBatchConfigurationFacade(configStrategy.createWriterConfig(messageWriter, config));    }    try {        messageWriter.init(stormConf, writerTransformer.apply(configurations));    } catch (Exception e) {        throw new IllegalStateException("Unable to initialize message writer", e);    }    this.writerComponent = new BulkWriterComponent<>(maxBatchTimeout);    this.writerComponent.addFlushPolicy(ackTuplesPolicy);}
0
public void write(String sensorType, BulkMessage<JSONObject> bulkWriterMessage, ParserConfigurations configurations) throws Exception
{    writerComponent.write(sensorType, bulkWriterMessage, messageWriter, writerTransformer.apply(configurations));}
0
public void flush(ParserConfigurations configurations, MessageGetStrategy messageGetStrategy) throws Exception
{    if (!(messageWriter instanceof WriterToBulkWriter)) {                        writerComponent.flushAll(messageWriter, writerTransformer.apply(configurations));    }}
1
public Config getConfig()
{    return config;}
0
public String getArg()
{    return arg;}
0
public Config apply(Arg arg)
{    if (arg.getArg() != null) {        arg.getConfig().setNumWorkers(Integer.parseInt(arg.getArg()));    }    return arg.getConfig();}
0
public Config apply(Arg arg)
{    if (arg.getArg() != null) {        arg.getConfig().setNumAckers(Integer.parseInt(arg.getArg()));    }    return arg.getConfig();}
0
public Config apply(Arg arg)
{    if (arg.getArg() != null) {        arg.getConfig().setMaxTaskParallelism(Integer.parseInt(arg.getArg()));    }    return arg.getConfig();}
0
public Config apply(Arg arg)
{    if (arg.getArg() != null) {        arg.getConfig().setMessageTimeoutSecs(Integer.parseInt(arg.getArg()));    }    return arg.getConfig();}
0
public Config apply(Arg arg)
{    if (arg.getArg() != null) {        File inputFile = new File(arg.getArg());        String json = null;        if (inputFile.exists()) {            try {                json = FileUtils.readFileToString(inputFile);            } catch (IOException e) {                throw new IllegalStateException("Unable to process JSON file " + inputFile, e);            }        } else {            json = arg.getArg();        }        try {            arg.getConfig().putAll(JSONUtils.INSTANCE.load(json, JSONUtils.MAP_SUPPLIER));        } catch (IOException e) {            throw new IllegalStateException("Unable to process JSON snippet.", e);        }    }    return arg.getConfig();}
0
public void transform(InputStream input, OutputStream output) throws IOException
{    String extraJars = System.getenv().get(EXTRA_JARS_ENV);    if (extraJars == null || extraJars.length() == 0) {        underlyingTransformer.transform(input, output);        return;    }    File tmpFile = File.createTempFile("metron", "jar");    tmpFile.deleteOnExit();    Set<String> entries = new HashSet<>();    try (JarOutputStream jout = new JarOutputStream(new BufferedOutputStream(new FileOutputStream(tmpFile)))) {        try (JarInputStream jin = new JarInputStream(new BufferedInputStream(input))) {            copy(jin, jout, entries);        }        for (String fileStr : Splitter.on(",").split(extraJars)) {            File f = new File(fileStr);            if (!f.exists()) {                continue;            }                        try (JarInputStream jin = new JarInputStream(new BufferedInputStream(new FileInputStream(f)))) {                copy(jin, jout, entries);            }        }    }    underlyingTransformer.transform(new BufferedInputStream(new FileInputStream(tmpFile)), output);}
1
private Set<String> copy(JarInputStream jin, JarOutputStream jout, Set<String> entries) throws IOException
{    byte[] buffer = new byte[1024];    for (JarEntry entry = jin.getNextJarEntry(); entry != null; entry = jin.getNextJarEntry()) {        if (entries.contains(entry.getName())) {            continue;        }                entries.add(entry.getName());        jout.putNextEntry(entry);        int len = 0;        while ((len = jin.read(buffer)) > 0) {            jout.write(buffer, 0, len);        }    }    return entries;}
1
public TopologyBuilder getBuilder()
{    return builder;}
0
public Config getTopologyConfig()
{    return topologyConfig;}
0
public static ParserTopology build(String zookeeperUrl, Optional<String> brokerUrl, List<String> sensorTypes, ValueSupplier<List> spoutParallelismSupplier, ValueSupplier<List> spoutNumTasksSupplier, ValueSupplier<Integer> parserParallelismSupplier, ValueSupplier<Integer> parserNumTasksSupplier, ValueSupplier<Integer> errorWriterParallelismSupplier, ValueSupplier<Integer> errorWriterNumTasksSupplier, ValueSupplier<List> kafkaSpoutConfigSupplier, ValueSupplier<String> securityProtocolSupplier, ValueSupplier<String> outputTopicSupplier, ValueSupplier<String> errorTopicSupplier, ValueSupplier<Config> stormConfigSupplier) throws Exception
{        ParserConfigurations configs = new ParserConfigurations();    Map<String, SensorParserConfig> sensorToParserConfigs = getSensorParserConfig(zookeeperUrl, sensorTypes, configs);    Collection<SensorParserConfig> parserConfigs = sensorToParserConfigs.values();    @SuppressWarnings("unchecked")    List<Integer> spoutParallelism = (List<Integer>) spoutParallelismSupplier.get(parserConfigs, List.class);    @SuppressWarnings("unchecked")    List<Integer> spoutNumTasks = (List<Integer>) spoutNumTasksSupplier.get(parserConfigs, List.class);    int parserParallelism = parserParallelismSupplier.get(parserConfigs, Integer.class);    int parserNumTasks = parserNumTasksSupplier.get(parserConfigs, Integer.class);    int errorWriterParallelism = errorWriterParallelismSupplier.get(parserConfigs, Integer.class);    int errorWriterNumTasks = errorWriterNumTasksSupplier.get(parserConfigs, Integer.class);    String outputTopic = outputTopicSupplier.get(parserConfigs, String.class);    List<Map<String, Object>> kafkaSpoutConfig = kafkaSpoutConfigSupplier.get(parserConfigs, List.class);    Optional<String> securityProtocol = Optional.ofNullable(securityProtocolSupplier.get(parserConfigs, String.class));        TopologyBuilder builder = new TopologyBuilder();    int i = 0;    List<String> spoutIds = new ArrayList<>();    for (Entry<String, SensorParserConfig> entry : sensorToParserConfigs.entrySet()) {        KafkaSpout kafkaSpout = createKafkaSpout(zookeeperUrl, entry.getKey(), securityProtocol, Optional.ofNullable(kafkaSpoutConfig.get(i)), entry.getValue());        String spoutId = sensorToParserConfigs.size() > 1 ? "kafkaSpout-" + entry.getKey() : "kafkaSpout";        builder.setSpout(spoutId, kafkaSpout, spoutParallelism.get(i)).setNumTasks(spoutNumTasks.get(i));        spoutIds.add(spoutId);        ++i;    }        ParserBolt parserBolt = createParserBolt(zookeeperUrl, brokerUrl, sensorToParserConfigs, securityProtocol, configs, Optional.ofNullable(outputTopic));    BoltDeclarer boltDeclarer = builder.setBolt("parserBolt", parserBolt, parserParallelism).setNumTasks(parserNumTasks);    for (String spoutId : spoutIds) {        boltDeclarer.localOrShuffleGrouping(spoutId);    }        if (errorWriterNumTasks > 0) {        String errorTopic = errorTopicSupplier.get(parserConfigs, String.class);        WriterBolt errorBolt = createErrorBolt(zookeeperUrl, brokerUrl, sensorTypes.get(0), securityProtocol, configs, parserConfigs.iterator().next(), errorTopic);        builder.setBolt("errorMessageWriter", errorBolt, errorWriterParallelism).setNumTasks(errorWriterNumTasks).localOrShuffleGrouping("parserBolt", Constants.ERROR_STREAM);    }    return new ParserTopology(builder, stormConfigSupplier.get(parserConfigs, Config.class));}
0
private static StormKafkaSpout<Object, Object> createKafkaSpout(String zkQuorum, String sensorType, Optional<String> securityProtocol, Optional<Map<String, Object>> kafkaConfigOptional, SensorParserConfig parserConfig)
{    Map<String, Object> kafkaSpoutConfigOptions = kafkaConfigOptional.orElse(new HashMap<>());    String inputTopic = parserConfig.getSensorTopic() != null ? parserConfig.getSensorTopic() : sensorType;    kafkaSpoutConfigOptions.putIfAbsent(SpoutConfiguration.FIRST_POLL_OFFSET_STRATEGY.key, KafkaSpoutConfig.FirstPollOffsetStrategy.UNCOMMITTED_EARLIEST.name());    kafkaSpoutConfigOptions.putIfAbsent(ConsumerConfig.GROUP_ID_CONFIG, inputTopic + "_parser");    if (securityProtocol.isPresent()) {        kafkaSpoutConfigOptions.putIfAbsent("security.protocol", KafkaUtils.INSTANCE.normalizeProtocol(securityProtocol.get()));    }    return SimpleStormKafkaBuilder.create(inputTopic, zkQuorum, Arrays.asList(SimpleStormKafkaBuilder.FieldsConfiguration.VALUE.getFieldName(), SimpleStormKafkaBuilder.FieldsConfiguration.KEY.getFieldName(), SimpleStormKafkaBuilder.FieldsConfiguration.TOPIC.getFieldName()), kafkaSpoutConfigOptions);}
0
protected static KafkaWriter createKafkaWriter(Optional<String> broker, String zkQuorum, Optional<String> securityProtocol)
{    KafkaWriter writer = new KafkaWriter();        if (broker.isPresent()) {        writer.withBrokerUrl(broker.get());    } else {        writer.withZkQuorum(zkQuorum);    }        if (securityProtocol.isPresent()) {        HashMap<String, Object> config = new HashMap<>();        config.put("security.protocol", securityProtocol.get());        writer.withProducerConfigs(config);    }    return writer;}
0
private static ParserBolt createParserBolt(String zookeeperUrl, Optional<String> brokerUrl, Map<String, SensorParserConfig> sensorTypeToParserConfig, Optional<String> securityProtocol, ParserConfigurations configs, Optional<String> outputTopic)
{    Map<String, WriterHandler> writerConfigs = createWriterConfigs(zookeeperUrl, brokerUrl, sensorTypeToParserConfig, securityProtocol, configs, outputTopic);    return new ParserBolt(zookeeperUrl, new ParserRunnerImpl(new HashSet<>(sensorTypeToParserConfig.keySet())), writerConfigs);}
0
protected static Map<String, WriterHandler> createWriterConfigs(String zookeeperUrl, Optional<String> brokerUrl, Map<String, SensorParserConfig> sensorTypeToParserConfig, Optional<String> securityProtocol, ParserConfigurations configs, Optional<String> outputTopic)
{    Map<String, WriterHandler> writerConfigs = new HashMap<>();    for (Entry<String, SensorParserConfig> entry : sensorTypeToParserConfig.entrySet()) {        String sensorType = entry.getKey();        SensorParserConfig parserConfig = entry.getValue();                AbstractWriter writer;        if (parserConfig.getWriterClassName() == null) {                        writer = createKafkaWriter(brokerUrl, zookeeperUrl, securityProtocol).withTopic(outputTopic.orElse(parserConfig.getOutputTopic() != null ? parserConfig.getOutputTopic() : Constants.ENRICHMENT_TOPIC));        } else {            writer = ReflectionUtils.createInstance(parserConfig.getWriterClassName());        }                writer.configure(sensorType, new ParserWriterConfiguration(configs));                WriterHandler writerHandler = createWriterHandler(writer);        writerConfigs.put(sensorType, writerHandler);    }    return writerConfigs;}
0
private static WriterBolt createErrorBolt(String zookeeperUrl, Optional<String> brokerUrl, String sensorType, Optional<String> securityProtocol, ParserConfigurations configs, SensorParserConfig parserConfig, String errorTopic)
{        AbstractWriter writer;    if (parserConfig.getErrorWriterClassName() == null) {        if (errorTopic == null) {            errorTopic = (String) configs.getGlobalConfig().get(Constants.PARSER_ERROR_TOPIC_GLOBALS_KEY);        }                writer = createKafkaWriter(brokerUrl, zookeeperUrl, securityProtocol).withTopic(errorTopic).withConfigPrefix("error");    } else {        writer = ReflectionUtils.createInstance(parserConfig.getWriterClassName());    }        writer.configure(sensorType, new ParserWriterConfiguration(configs));        WriterHandler writerHandler = createWriterHandler(writer);    return new WriterBolt(writerHandler, configs, sensorType).withErrorType(Constants.ErrorType.PARSER_ERROR);}
0
private static Map<String, SensorParserConfig> getSensorParserConfig(String zookeeperUrl, List<String> sensorTypes, ParserConfigurations configs) throws Exception
{    Map<String, SensorParserConfig> parserConfigs = new HashMap<>();    try (CuratorFramework client = ConfigurationsUtils.getClient(zookeeperUrl)) {        client.start();        ConfigurationsUtils.updateParserConfigsFromZookeeper(configs, client);        for (String sensorType : sensorTypes) {            SensorParserConfig parserConfig = configs.getSensorParserConfig(sensorType);            if (parserConfig == null) {                throw new IllegalStateException("Cannot find the parser configuration in zookeeper for " + sensorType + "." + "  Please check that it exists in zookeeper by using the 'zk_load_configs.sh -m DUMP' command.");            }            parserConfigs.put(sensorType, parserConfig);        }    }    return parserConfigs;}
0
private static WriterHandler createWriterHandler(AbstractWriter writer)
{    if (writer instanceof BulkMessageWriter) {        return new WriterHandler((BulkMessageWriter<JSONObject>) writer);    } else if (writer instanceof MessageWriter) {        return new WriterHandler((MessageWriter<JSONObject>) writer);    } else {        throw new IllegalStateException("Unable to create parser bolt: writer must be a MessageWriter or a BulkMessageWriter");    }}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public String get(CommandLine cli, String def)
{    return has(cli) ? cli.getOptionValue(shortCode) : def;}
0
public static Optional<Config> getConfig(CommandLine cli)
{    return getConfig(cli, new Config());}
0
public static Optional<Config> getConfig(CommandLine cli, Config config)
{    if (EXTRA_OPTIONS.has(cli)) {        Map<String, Object> extraOptions = readJSONMapFromFile(new File(EXTRA_OPTIONS.get(cli)));        config.putAll(extraOptions);    }    for (ParserOptions option : ParserOptions.values()) {        config = option.configHandler.apply(new Arg(config, option.get(cli)));    }    return config.isEmpty() ? Optional.empty() : Optional.of(config);}
0
public static CommandLine parse(CommandLineParser parser, String[] args) throws ParseException
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        throw e;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("ParserTopologyCLI", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (ParserOptions o : ParserOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
private static CommandLine parse(Options options, String[] args)
{    /*     * The general gist is that in order to pass args to storm jar,     * we have to disregard options that we don't know about in the CLI.     * Storm will ignore our args, we have to do the same.     */    CommandLineParser parser = new PosixParser() {        @Override        protected void processOption(String arg, ListIterator iter) throws ParseException {            if (getOptions().hasOption(arg)) {                super.processOption(arg, iter);            }        }    };    try {        return ParserOptions.parse(parser, args);    } catch (ParseException pe) {        pe.printStackTrace();        final HelpFormatter usageFormatter = new HelpFormatter();        usageFormatter.printHelp("ParserTopologyCLI", null, options, null, true);        System.exit(-1);        return null;    }}
0
protected void processOption(String arg, ListIterator iter) throws ParseException
{    if (getOptions().hasOption(arg)) {        super.processOption(arg, iter);    }}
0
public ParserTopologyBuilder.ParserTopology createParserTopology(final CommandLine cmd) throws Exception
{    String zookeeperUrl = ParserOptions.ZK_QUORUM.get(cmd);    Optional<String> brokerUrl = ParserOptions.BROKER_URL.has(cmd) ? Optional.of(ParserOptions.BROKER_URL.get(cmd)) : Optional.empty();    String sensorTypeRaw = ParserOptions.SENSOR_TYPES.get(cmd);    List<String> sensorTypes = Arrays.stream(sensorTypeRaw.split(TOPOLOGY_OPTION_SEPARATOR)).map(String::trim).collect(Collectors.toList());    /*     * It bears mentioning why we're creating this ValueSupplier indirection here.     * As a separation of responsibilities, the CLI class defines the order of precedence     * for the various topological and structural properties for creating a parser.  This is     * desirable because there are now (i.e. integration tests)     * and may be in the future (i.e. a REST service to start parsers without using the CLI)     * other mechanisms to construct parser topologies.  It's sensible to split those concerns..     *     * Unfortunately, determining the structural parameters for a parser requires interacting with     * external services (e.g. zookeeper) that are set up well within the ParserTopology class.     * Rather than pulling the infrastructure to interact with those services out and moving it into the     * CLI class and breaking that separation of concerns, we've created a supplier     * indirection where are providing the logic as to how to create precedence in the CLI class     * without owning the responsibility of constructing the infrastructure where the values are     * necessarily supplied.     *     */        ValueSupplier<List> spoutParallelism = (parserConfigs, clazz) -> {        if (ParserOptions.SPOUT_PARALLELISM.has(cmd)) {                        if (parserConfigs.size() == 1) {                return Collections.singletonList(Integer.parseInt(ParserOptions.SPOUT_PARALLELISM.get(cmd, "1")));            }                        String parallelismRaw = ParserOptions.SPOUT_PARALLELISM.get(cmd, "1");            List<String> parallelisms = Arrays.stream(parallelismRaw.split(TOPOLOGY_OPTION_SEPARATOR)).map(String::trim).collect(Collectors.toList());            if (parallelisms.size() != parserConfigs.size()) {                throw new IllegalArgumentException("Spout parallelism should match number of sensors 1:1");            }            List<Integer> spoutParallelisms = new ArrayList<>();            for (String s : parallelisms) {                spoutParallelisms.add(Integer.parseInt(s));            }            return spoutParallelisms;        }        List<Integer> spoutParallelisms = new ArrayList<>();        for (SensorParserConfig parserConfig : parserConfigs) {            spoutParallelisms.add(parserConfig.getSpoutParallelism());        }        return spoutParallelisms;    };        ValueSupplier<List> spoutNumTasks = (parserConfigs, clazz) -> {        if (ParserOptions.SPOUT_NUM_TASKS.has(cmd)) {                        if (parserConfigs.size() == 1) {                return Collections.singletonList(Integer.parseInt(ParserOptions.SPOUT_NUM_TASKS.get(cmd, "1")));            }                        String numTasksRaw = ParserOptions.SPOUT_NUM_TASKS.get(cmd, "1");            List<String> numTasks = Arrays.stream(numTasksRaw.split(TOPOLOGY_OPTION_SEPARATOR)).map(String::trim).collect(Collectors.toList());            if (numTasks.size() != parserConfigs.size()) {                throw new IllegalArgumentException("Spout num tasks should match number of sensors 1:1");            }            List<Integer> spoutTasksList = new ArrayList<>();            for (String s : numTasks) {                spoutTasksList.add(Integer.parseInt(s));            }            return spoutTasksList;        }        List<Integer> numTasks = new ArrayList<>();        for (SensorParserConfig parserConfig : parserConfigs) {            numTasks.add(parserConfig.getSpoutNumTasks());        }        return numTasks;    };        ValueSupplier<Integer> parserParallelism = (parserConfigs, clazz) -> {        if (ParserOptions.PARSER_PARALLELISM.has(cmd)) {            return Integer.parseInt(ParserOptions.PARSER_PARALLELISM.get(cmd, "1"));        }        int retValue = 1;        for (SensorParserConfig config : parserConfigs) {            Integer configValue = config.getParserParallelism();            retValue = configValue == null ? retValue : configValue;        }        return retValue;    };        ValueSupplier<Integer> parserNumTasks = (parserConfigs, clazz) -> {        if (ParserOptions.PARSER_NUM_TASKS.has(cmd)) {            return Integer.parseInt(ParserOptions.PARSER_NUM_TASKS.get(cmd, "1"));        }        int retValue = 1;        for (SensorParserConfig config : parserConfigs) {            Integer configValue = config.getParserNumTasks();            retValue = configValue == null ? retValue : configValue;        }        return retValue;    };        ValueSupplier<Integer> errorParallelism = (parserConfigs, clazz) -> {        if (ParserOptions.ERROR_WRITER_PARALLELISM.has(cmd)) {            return Integer.parseInt(ParserOptions.ERROR_WRITER_PARALLELISM.get(cmd, "1"));        }        int retValue = 1;        for (SensorParserConfig config : parserConfigs) {            Integer configValue = config.getErrorWriterParallelism();            retValue = configValue == null ? retValue : configValue;        }        return retValue;    };        ValueSupplier<Integer> errorNumTasks = (parserConfigs, clazz) -> {        if (ParserOptions.ERROR_WRITER_NUM_TASKS.has(cmd)) {            return Integer.parseInt(ParserOptions.ERROR_WRITER_NUM_TASKS.get(cmd, "1"));        }        int retValue = 1;        for (SensorParserConfig config : parserConfigs) {            Integer configValue = config.getErrorWriterNumTasks();            retValue = configValue == null ? retValue : configValue;        }        return retValue;    };        ValueSupplier<List> spoutConfig = (parserConfigs, clazz) -> {        if (ParserOptions.SPOUT_CONFIG.has(cmd)) {            return Collections.singletonList(readJSONMapFromFile(new File(ParserOptions.SPOUT_CONFIG.get(cmd))));        }        List<Map<String, Object>> retValue = new ArrayList<>();        for (SensorParserConfig config : parserConfigs) {            retValue.add(config.getSpoutConfig());        }        return retValue;    };        ValueSupplier<String> securityProtocol = (parserConfigs, clazz) -> {        Optional<String> sp = Optional.empty();        if (ParserOptions.SECURITY_PROTOCOL.has(cmd)) {            sp = Optional.of(ParserOptions.SECURITY_PROTOCOL.get(cmd));        }                if (!sp.isPresent()) {            sp = getSecurityProtocol(sp, spoutConfig.get(parserConfigs, List.class));        }                String parserConfigSp = SecurityProtocol.PLAINTEXT.name;        for (SensorParserConfig config : parserConfigs) {            String configSp = config.getSecurityProtocol();            if (!SecurityProtocol.PLAINTEXT.name.equals(configSp)) {                                parserConfigSp = configSp;            }        }        return sp.orElse(Optional.ofNullable(parserConfigSp).orElse(null));    };        ValueSupplier<Config> stormConf = (parserConfigs, clazz) -> {                Config finalConfig = new Config();        for (SensorParserConfig parserConfig : parserConfigs) {            Map<String, Object> c = parserConfig.getStormConfig();            if (c != null && !c.isEmpty()) {                finalConfig.putAll(c);            }            if (parserConfig.getNumAckers() != null) {                Config.setNumAckers(finalConfig, parserConfig.getNumAckers());            }            if (parserConfig.getNumWorkers() != null) {                Config.setNumWorkers(finalConfig, parserConfig.getNumWorkers());            }        }        return ParserOptions.getConfig(cmd, finalConfig).orElse(finalConfig);    };        ValueSupplier<String> outputTopic = (parserConfigs, clazz) -> {        String topic = null;        if (ParserOptions.OUTPUT_TOPIC.has(cmd)) {            topic = ParserOptions.OUTPUT_TOPIC.get(cmd);        }        return topic;    };        ValueSupplier<String> errorTopic = (parserConfigs, clazz) -> {                String topic = null;        for (SensorParserConfig parserConfig : parserConfigs) {            String currentTopic = parserConfig.getErrorTopic();            if (topic != null && !topic.equals(currentTopic)) {                throw new IllegalArgumentException("Parser Aggregation specified with differing error topics");            }            topic = currentTopic;        }        return topic;    };    return getParserTopology(zookeeperUrl, brokerUrl, sensorTypes, spoutParallelism, spoutNumTasks, parserParallelism, parserNumTasks, errorParallelism, errorNumTasks, spoutConfig, securityProtocol, stormConf, outputTopic, errorTopic);}
0
protected ParserTopologyBuilder.ParserTopology getParserTopology(String zookeeperUrl, Optional<String> brokerUrl, List<String> sensorTypes, ValueSupplier<List> spoutParallelism, ValueSupplier<List> spoutNumTasks, ValueSupplier<Integer> parserParallelism, ValueSupplier<Integer> parserNumTasks, ValueSupplier<Integer> errorParallelism, ValueSupplier<Integer> errorNumTasks, ValueSupplier<List> spoutConfig, ValueSupplier<String> securityProtocol, ValueSupplier<Config> stormConf, ValueSupplier<String> outputTopic, ValueSupplier<String> errorTopic) throws Exception
{    return ParserTopologyBuilder.build(zookeeperUrl, brokerUrl, sensorTypes, spoutParallelism, spoutNumTasks, parserParallelism, parserNumTasks, errorParallelism, errorNumTasks, spoutConfig, securityProtocol, outputTopic, errorTopic, stormConf);}
0
public static void main(String[] args)
{    try {        Options options = new Options();        final CommandLine cmd = parse(options, args);        if (cmd.hasOption("h")) {            final HelpFormatter usageFormatter = new HelpFormatter();            usageFormatter.printHelp("ParserTopologyCLI", null, options, null, true);            System.exit(0);        }        ParserTopologyCLI cli = new ParserTopologyCLI();        ParserTopologyBuilder.ParserTopology topology = cli.createParserTopology(cmd);        String sensorTypes = ParserOptions.SENSOR_TYPES.get(cmd);        String topologyName = sensorTypes.replaceAll(TOPOLOGY_OPTION_SEPARATOR, STORM_JOB_SEPARATOR);        if (ParserOptions.TEST.has(cmd)) {            topology.getTopologyConfig().put(Config.TOPOLOGY_DEBUG, true);            LocalCluster cluster = new LocalCluster();            cluster.submitTopology(topologyName, topology.getTopologyConfig(), topology.getBuilder().createTopology());            Utils.sleep(300000);            cluster.shutdown();        } else {            StormSubmitter.submitTopology(topologyName, topology.getTopologyConfig(), topology.getBuilder().createTopology());        }    } catch (Exception e) {        e.printStackTrace();        System.exit(-1);    }}
0
private static Optional<String> getSecurityProtocol(Optional<String> protocol, List<Map<String, Object>> spoutConfig)
{    Optional<String> ret = protocol;    if (ret.isPresent() && protocol.get().equalsIgnoreCase(SecurityProtocol.PLAINTEXT.name)) {        ret = Optional.empty();    }    if (!ret.isPresent()) {                String spoutConfigSp = null;        for (Map<String, Object> config : spoutConfig) {            String configSp = (String) config.get(KafkaUtils.SECURITY_PROTOCOL);            if (configSp != null && !SecurityProtocol.PLAINTEXT.name.equals(configSp)) {                                spoutConfigSp = configSp;            } else if (configSp != null) {                                spoutConfigSp = configSp;            }        }        ret = Optional.ofNullable(spoutConfigSp);    }    if (ret.isPresent() && ret.get().equalsIgnoreCase(SecurityProtocol.PLAINTEXT.name)) {        ret = Optional.empty();    }    return ret;}
0
private static Map<String, Object> readJSONMapFromFile(File inputFile)
{    String json = null;    if (inputFile.exists()) {        try {            json = FileUtils.readFileToString(inputFile);        } catch (IOException e) {            throw new IllegalStateException("Unable to process JSON file " + inputFile, e);        }    } else {        throw new IllegalArgumentException("Unable to load JSON file at " + inputFile.getAbsolutePath());    }    try {        return JSONUtils.INSTANCE.load(json, JSONUtils.MAP_SUPPLIER);    } catch (IOException e) {        throw new IllegalStateException("Unable to process JSON.", e);    }}
0
public ParserRunnerResults<JSONObject> execute(String sensorType, RawMessage rawMessage, ParserConfigurations parserConfigurations)
{    DefaultParserRunnerResults parserRunnerResults = new DefaultParserRunnerResults();    this.rawMessage = rawMessage;    for (JSONObject message : messages) {        if (!isInvalid) {            parserRunnerResults.addMessage(message);        } else {            MetronError error = new MetronError().withErrorType(Constants.ErrorType.PARSER_INVALID).withSensorType(Collections.singleton(sensorType)).addRawMessage(message);            parserRunnerResults.addError(error);        }    }    return parserRunnerResults;}
0
protected void setInvalid(boolean isInvalid)
{    this.isInvalid = isInvalid;}
0
protected void setMessages(List<JSONObject> messages)
{    this.messages = messages;}
0
protected RawMessage getRawMessage()
{    return rawMessage;}
0
public void withBatchTimeoutDivisorShouldSetBatchTimeoutDivisor()
{    ParserBolt parserBolt = new ParserBolt("zookeeperUrl", parserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }).withBatchTimeoutDivisor(5);    Assert.assertEquals(5, parserBolt.getBatchTimeoutDivisor());}
0
public void shouldThrowExceptionOnInvalidBatchTimeoutDivisor()
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("batchTimeoutDivisor must be positive. Value provided was -1");    ParserBolt parserBolt = new ParserBolt("zookeeperUrl", parserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }).withBatchTimeoutDivisor(-1);}
0
public void shouldGetComponentConfiguration()
{    ParserBolt parserBolt = new ParserBolt("zookeeperUrl", parserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        public ParserConfigurations getConfigurations() {            ParserConfigurations configurations = new ParserConfigurations();            SensorParserConfig sensorParserConfig = new SensorParserConfig();            sensorParserConfig.setParserConfig(new HashMap<String, Object>() {                {                    put(IndexingConfigurations.BATCH_SIZE_CONF, 10);                }            });            configurations.updateSensorParserConfig("yaf", sensorParserConfig);            return configurations;        }    };    Map<String, Object> componentConfiguration = parserBolt.getComponentConfiguration();    Assert.assertEquals(1, componentConfiguration.size());    Assert.assertEquals(14, componentConfiguration.get(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS));}
0
public ParserConfigurations getConfigurations()
{    ParserConfigurations configurations = new ParserConfigurations();    SensorParserConfig sensorParserConfig = new SensorParserConfig();    sensorParserConfig.setParserConfig(new HashMap<String, Object>() {        {            put(IndexingConfigurations.BATCH_SIZE_CONF, 10);        }    });    configurations.updateSensorParserConfig("yaf", sensorParserConfig);    return configurations;}
0
public void shouldPrepare()
{    Map stormConf = mock(Map.class);    SensorParserConfig yafConfig = mock(SensorParserConfig.class);    when(yafConfig.getSensorTopic()).thenReturn("yafTopic");    when(yafConfig.getParserConfig()).thenReturn(new HashMap<String, Object>() {        {            put(IndexingConfigurations.BATCH_SIZE_CONF, 10);        }    });    ParserConfigurations parserConfigurations = mock(ParserConfigurations.class);    ParserBolt parserBolt = spy(new ParserBolt("zookeeperUrl", parserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        protected SensorParserConfig getSensorParserConfig(String sensorType) {            if ("yaf".equals(sensorType)) {                return yafConfig;            }            return null;        }        @Override        public ParserConfigurations getConfigurations() {            return parserConfigurations;        }    });    doReturn(stellarContext).when(parserBolt).initializeStellar();    parserBolt.setCuratorFramework(client);    parserBolt.setZKCache(cache);    parserBolt.prepare(stormConf, topologyContext, outputCollector);    verify(parserRunner, times(1)).init(any(Supplier.class), eq(stellarContext));    verify(yafConfig, times(1)).init();    Map<String, String> topicToSensorMap = parserBolt.getTopicToSensorMap();    Assert.assertEquals(1, topicToSensorMap.size());    Assert.assertEquals("yaf", topicToSensorMap.get("yafTopic"));    verify(writerHandler).init(eq(stormConf), eq(topologyContext), eq(outputCollector), eq(parserConfigurations), any(AckTuplesPolicy.class), eq(14));}
0
protected SensorParserConfig getSensorParserConfig(String sensorType)
{    if ("yaf".equals(sensorType)) {        return yafConfig;    }    return null;}
0
public ParserConfigurations getConfigurations()
{    return parserConfigurations;}
0
public void shouldThrowExceptionOnMissingConfig()
{    exception.expect(IllegalStateException.class);    exception.expectMessage("Unable to retrieve a parser config for yaf");    Map stormConf = mock(Map.class);    ParserBolt parserBolt = new ParserBolt("zookeeperUrl", parserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    });    parserBolt.setCuratorFramework(client);    parserBolt.setZKCache(cache);    parserBolt.prepare(stormConf, topologyContext, outputCollector);}
0
public void executeShouldHandleTickTuple() throws Exception
{    when(t1.getSourceComponent()).thenReturn("__system");    when(t1.getSourceStreamId()).thenReturn("__tick");    ParserConfigurations parserConfigurations = mock(ParserConfigurations.class);    ParserBolt parserBolt = new ParserBolt("zookeeperUrl", parserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        public ParserConfigurations getConfigurations() {            return parserConfigurations;        }    };    parserBolt.setMessageGetStrategy(messageGetStrategy);    parserBolt.setOutputCollector(outputCollector);    parserBolt.execute(t1);    verify(writerHandler, times(1)).flush(parserConfigurations, messageGetStrategy);    verify(outputCollector, times(1)).ack(t1);}
0
public ParserConfigurations getConfigurations()
{    return parserConfigurations;}
0
public void shouldExecuteOnSuccess() throws Exception
{    when(messageGetStrategy.get(t1)).thenReturn("originalMessage".getBytes(StandardCharsets.UTF_8));    when(t1.getStringByField(FieldsConfiguration.TOPIC.getFieldName())).thenReturn("yafTopic");    MockParserRunner mockParserRunner = new MockParserRunner(new HashSet<String>() {        {            add("yaf");        }    });    ParserConfigurations parserConfigurations = new ParserConfigurations();    parserConfigurations.updateSensorParserConfig("yaf", new SensorParserConfig());    ParserBolt parserBolt = spy(new ParserBolt("zookeeperUrl", mockParserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        public ParserConfigurations getConfigurations() {            return parserConfigurations;        }    });    parserBolt.setMessageGetStrategy(messageGetStrategy);    parserBolt.setOutputCollector(outputCollector);    parserBolt.setTopicToSensorMap(new HashMap<String, String>() {        {            put("yafTopic", "yaf");        }    });    parserBolt.setAckTuplesPolicy(bulkWriterResponseHandler);    JSONObject message = new JSONObject();    message.put(Constants.GUID, "messageId");    message.put("field", "value");    mockParserRunner.setMessages(Collections.singletonList(message));    RawMessage expectedRawMessage = new RawMessage("originalMessage".getBytes(StandardCharsets.UTF_8), new HashMap<>());    {        parserBolt.execute(t1);        Assert.assertEquals(expectedRawMessage, mockParserRunner.getRawMessage());        verify(bulkWriterResponseHandler).addTupleMessageIds(t1, Collections.singletonList("messageId"));        verify(writerHandler, times(1)).write("yaf", new BulkMessage<>("messageId", message), parserConfigurations);    }}
0
public ParserConfigurations getConfigurations()
{    return parserConfigurations;}
0
public void shouldExecuteOnSuccessWithMultipleMessages() throws Exception
{    when(messageGetStrategy.get(t1)).thenReturn("originalMessage".getBytes(StandardCharsets.UTF_8));    when(t1.getStringByField(FieldsConfiguration.TOPIC.getFieldName())).thenReturn("yafTopic");    MockParserRunner mockParserRunner = new MockParserRunner(new HashSet<String>() {        {            add("yaf");        }    });    ParserConfigurations parserConfigurations = new ParserConfigurations();    parserConfigurations.updateSensorParserConfig("yaf", new SensorParserConfig());    ParserBolt parserBolt = spy(new ParserBolt("zookeeperUrl", mockParserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        public ParserConfigurations getConfigurations() {            return parserConfigurations;        }    });    parserBolt.setMessageGetStrategy(messageGetStrategy);    parserBolt.setOutputCollector(outputCollector);    parserBolt.setTopicToSensorMap(new HashMap<String, String>() {        {            put("yafTopic", "yaf");        }    });    parserBolt.setAckTuplesPolicy(bulkWriterResponseHandler);    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    for (int i = 0; i < 5; i++) {        String messageId = String.format("messageId%s", i + 1);        JSONObject message = new JSONObject();        message.put(Constants.GUID, messageId);        message.put("field", String.format("value%s", i + 1));        messages.add(new BulkMessage<>(messageId, message));    }    mockParserRunner.setMessages(messages.stream().map(BulkMessage::getMessage).collect(Collectors.toList()));    RawMessage expectedRawMessage = new RawMessage("originalMessage".getBytes(StandardCharsets.UTF_8), new HashMap<>());    {                parserBolt.execute(t1);        Assert.assertEquals(expectedRawMessage, mockParserRunner.getRawMessage());        InOrder inOrder = inOrder(bulkWriterResponseHandler, writerHandler);        inOrder.verify(bulkWriterResponseHandler).addTupleMessageIds(t1, Arrays.asList("messageId1", "messageId2", "messageId3", "messageId4", "messageId5"));        inOrder.verify(writerHandler, times(1)).write("yaf", messages.get(0), parserConfigurations);        inOrder.verify(writerHandler, times(1)).write("yaf", messages.get(1), parserConfigurations);        inOrder.verify(writerHandler, times(1)).write("yaf", messages.get(2), parserConfigurations);        inOrder.verify(writerHandler, times(1)).write("yaf", messages.get(3), parserConfigurations);        inOrder.verify(writerHandler, times(1)).write("yaf", messages.get(4), parserConfigurations);    }    verifyNoMoreInteractions(writerHandler, bulkWriterResponseHandler, outputCollector);}
0
public ParserConfigurations getConfigurations()
{    return parserConfigurations;}
0
public void shouldExecuteOnError() throws Exception
{    when(messageGetStrategy.get(t1)).thenReturn("originalMessage".getBytes(StandardCharsets.UTF_8));    when(t1.getStringByField(FieldsConfiguration.TOPIC.getFieldName())).thenReturn("yafTopic");    MockParserRunner mockParserRunner = new MockParserRunner(new HashSet<String>() {        {            add("yaf");        }    });    mockParserRunner.setInvalid(true);    ParserConfigurations parserConfigurations = new ParserConfigurations();    parserConfigurations.updateSensorParserConfig("yaf", new SensorParserConfig());    ParserBolt parserBolt = new ParserBolt("zookeeperUrl", mockParserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        public ParserConfigurations getConfigurations() {            return parserConfigurations;        }    };    parserBolt.setMessageGetStrategy(messageGetStrategy);    parserBolt.setOutputCollector(outputCollector);    parserBolt.setTopicToSensorMap(new HashMap<String, String>() {        {            put("yafTopic", "yaf");        }    });    JSONObject message = new JSONObject();    message.put("field", "value");    mockParserRunner.setMessages(Collections.singletonList(message));    RawMessage expectedRawMessage = new RawMessage("originalMessage".getBytes(StandardCharsets.UTF_8), new HashMap<>());    MetronError error = new MetronError().withErrorType(Constants.ErrorType.PARSER_INVALID).withSensorType(Collections.singleton("yaf")).addRawMessage(message);    parserBolt.execute(t1);    Assert.assertEquals(expectedRawMessage, mockParserRunner.getRawMessage());    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), argThat(new MetronErrorJSONMatcher(error.getJSONObject())));    verify(outputCollector, times(1)).ack(t1);}
0
public ParserConfigurations getConfigurations()
{    return parserConfigurations;}
0
public void shouldThrowExceptionOnFailedExecute()
{    when(messageGetStrategy.get(t1)).thenReturn("originalMessage".getBytes(StandardCharsets.UTF_8));    when(t1.getStringByField(FieldsConfiguration.TOPIC.getFieldName())).thenReturn("yafTopic");    ParserConfigurations parserConfigurations = new ParserConfigurations();    parserConfigurations.updateSensorParserConfig("yaf", new SensorParserConfig());    doThrow(new IllegalStateException("parserRunner.execute failed")).when(parserRunner).execute(eq("yaf"), any(), eq(parserConfigurations));    ParserBolt parserBolt = new ParserBolt("zookeeperUrl", parserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        public ParserConfigurations getConfigurations() {            return parserConfigurations;        }    };    parserBolt.setMessageGetStrategy(messageGetStrategy);    parserBolt.setOutputCollector(outputCollector);    parserBolt.setTopicToSensorMap(new HashMap<String, String>() {        {            put("yafTopic", "yaf");        }    });    MetronError error = new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(new IllegalStateException("parserRunner.execute failed")).withSensorType(Collections.singleton("yaf")).addRawMessage("originalMessage".getBytes(StandardCharsets.UTF_8));    parserBolt.execute(t1);    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), argThat(new MetronErrorJSONMatcher(error.getJSONObject())));    verify(outputCollector, times(1)).reportError(any(IllegalStateException.class));    verify(outputCollector, times(1)).ack(t1);}
0
public ParserConfigurations getConfigurations()
{    return parserConfigurations;}
0
public void shouldThrowExceptionOnFailedWrite() throws Exception
{    when(messageGetStrategy.get(t1)).thenReturn("originalMessage".getBytes(StandardCharsets.UTF_8));    when(t1.getStringByField(FieldsConfiguration.TOPIC.getFieldName())).thenReturn("yafTopic");    MockParserRunner mockParserRunner = new MockParserRunner(new HashSet<String>() {        {            add("yaf");        }    });    ParserConfigurations parserConfigurations = new ParserConfigurations();    parserConfigurations.updateSensorParserConfig("yaf", new SensorParserConfig());    doThrow(new IllegalStateException("write failed")).when(writerHandler).write(any(), any(), any());    ParserBolt parserBolt = spy(new ParserBolt("zookeeperUrl", mockParserRunner, new HashMap<String, WriterHandler>() {        {            put("yaf", writerHandler);        }    }) {        @Override        public ParserConfigurations getConfigurations() {            return parserConfigurations;        }    });    parserBolt.setMessageGetStrategy(messageGetStrategy);    parserBolt.setOutputCollector(outputCollector);    parserBolt.setTopicToSensorMap(new HashMap<String, String>() {        {            put("yafTopic", "yaf");        }    });    parserBolt.setAckTuplesPolicy(bulkWriterResponseHandler);    JSONObject message = new JSONObject();    message.put(Constants.GUID, "messageId");    message.put("field", "value");    mockParserRunner.setMessages(Collections.singletonList(message));    MetronError error = new MetronError().withErrorType(Constants.ErrorType.PARSER_ERROR).withThrowable(new IllegalStateException("write failed")).withSensorType(Collections.singleton("yaf")).addRawMessage("originalMessage".getBytes(StandardCharsets.UTF_8));    parserBolt.execute(t1);    verify(bulkWriterResponseHandler, times(1)).addTupleMessageIds(t1, Collections.singletonList("messageId"));    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), argThat(new MetronErrorJSONMatcher(error.getJSONObject())));    verify(outputCollector, times(1)).reportError(any(IllegalStateException.class));    verify(outputCollector, times(1)).ack(t1);}
0
public ParserConfigurations getConfigurations()
{    return parserConfigurations;}
0
private ParserConfigurations getConfigurations(int batchSize)
{    return new ParserConfigurations() {        @Override        public SensorParserConfig getSensorParserConfig(String sensorType) {            return new SensorParserConfig() {                @Override                public Map<String, Object> getParserConfig() {                    return new HashMap<String, Object>() {                        {                            put(IndexingConfigurations.BATCH_SIZE_CONF, batchSize);                        }                    };                }            };        }    };}
0
public SensorParserConfig getSensorParserConfig(String sensorType)
{    return new SensorParserConfig() {        @Override        public Map<String, Object> getParserConfig() {            return new HashMap<String, Object>() {                {                    put(IndexingConfigurations.BATCH_SIZE_CONF, batchSize);                }            };        }    };}
0
public Map<String, Object> getParserConfig()
{    return new HashMap<String, Object>() {        {            put(IndexingConfigurations.BATCH_SIZE_CONF, batchSize);        }    };}
0
public void testBatchHappyPath() throws Exception
{    ParserConfigurations configurations = getConfigurations(5);    String sensorType = "test";    WriterBolt bolt = spy(new WriterBolt(new WriterHandler(batchWriter), configurations, sensorType));    List<Tuple> tuples = new ArrayList<>();    List<MessageId> messageIds = new ArrayList<>();    for (int i = 0; i < 5; ++i) {        Tuple t = mock(Tuple.class);        String messageId = String.format(MESSAGE_ID_FORMAT, i + 1);        messageIds.add(new MessageId(messageId));        JSONObject message = new JSONObject();        message.put(Constants.GUID, messageId);        message.put("value", String.format(MESSAGE_FORMAT, i + 1));        when(t.getValueByField(eq("message"))).thenReturn(message);        tuples.add(t);    }    bolt.prepare(new HashMap(), topologyContext, outputCollector);    verify(batchWriter, times(1)).init(any(), any());    for (int i = 0; i < 4; ++i) {        Tuple t = tuples.get(i);        bolt.execute(t);        verify(outputCollector, times(0)).ack(t);        verify(batchWriter, times(0)).write(eq(sensorType), any(), any());    }        BulkWriterResponse writerResponse = new BulkWriterResponse();    writerResponse.addAllSuccesses(messageIds);    when(batchWriter.write(any(), any(), any())).thenReturn(writerResponse);    bolt.execute(tuples.get(4));    for (Tuple t : tuples) {        verify(outputCollector, times(1)).ack(t);    }    verify(batchWriter, times(1)).write(eq(sensorType), any(), any());    verify(outputCollector, times(0)).reportError(any());    verify(outputCollector, times(0)).fail(any());}
0
public void testNonBatchHappyPath() throws Exception
{    ParserConfigurations configurations = getConfigurations(1);    String sensorType = "test";    Tuple t = mock(Tuple.class);    when(t.getValueByField(eq("message"))).thenReturn(new JSONObject());    WriterBolt bolt = new WriterBolt(new WriterHandler(writer), configurations, sensorType);    bolt.prepare(new HashMap(), topologyContext, outputCollector);    verify(writer, times(1)).init();    bolt.execute(t);    verify(outputCollector, times(1)).ack(t);    verify(writer, times(1)).write(eq(sensorType), any(), any());    verify(outputCollector, times(0)).reportError(any());    verify(outputCollector, times(0)).fail(any());}
0
public void testNonBatchErrorPath() throws Exception
{    ParserConfigurations configurations = getConfigurations(1);    String sensorType = "test";    Tuple t = mock(Tuple.class);    when(t.getValueByField(eq("message"))).thenThrow(new IllegalStateException());    WriterBolt bolt = new WriterBolt(new WriterHandler(writer), configurations, sensorType);    bolt.prepare(new HashMap(), topologyContext, outputCollector);    verify(writer, times(1)).init();    bolt.execute(t);    verify(outputCollector, times(1)).ack(t);    verify(writer, times(0)).write(eq(sensorType), any(), any());    verify(outputCollector, times(1)).reportError(any());    verify(outputCollector, times(0)).fail(any());}
0
public void testNonBatchErrorPathErrorInWrite() throws Exception
{    ParserConfigurations configurations = getConfigurations(1);    String sensorType = "test";    Tuple t = mock(Tuple.class);    when(t.toString()).thenReturn("tuple");    when(t.getValueByField(eq("message"))).thenReturn(new JSONObject());    WriterBolt bolt = new WriterBolt(new WriterHandler(writer), configurations, sensorType);    bolt.prepare(new HashMap(), topologyContext, outputCollector);    doThrow(new Exception("write error")).when(writer).write(any(), any(), any());    verify(writer, times(1)).init();    bolt.execute(t);    verify(outputCollector, times(1)).ack(t);    verify(writer, times(1)).write(eq(sensorType), any(), any());    verify(outputCollector, times(1)).reportError(any());    verify(outputCollector, times(0)).fail(any());    MetronError error = new MetronError().withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(new Exception("write error")).withSensorType(Collections.singleton(sensorType)).addRawMessage(new JSONObject());    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), argThat(new MetronErrorJSONMatcher(error.getJSONObject())));}
0
public void testBatchErrorPath() throws Exception
{    ParserConfigurations configurations = getConfigurations(5);    String sensorType = "test";    WriterBolt bolt = spy(new WriterBolt(new WriterHandler(batchWriter), configurations, sensorType));    List<Tuple> tuples = new ArrayList<>();    List<MessageId> messageIds = new ArrayList<>();    for (int i = 0; i < 4; ++i) {        Tuple t = mock(Tuple.class);        String messageId = String.format(MESSAGE_ID_FORMAT, i + 1);        messageIds.add(new MessageId(messageId));        JSONObject message = new JSONObject();        message.put("value", String.format(MESSAGE_FORMAT, i + 1));        when(t.getValueByField(eq("message"))).thenReturn(message);        tuples.add(t);    }    Tuple errorTuple = mock(Tuple.class);    Tuple goodTuple = mock(Tuple.class);    when(goodTuple.getValueByField(eq("message"))).thenReturn(new JSONObject());    when(errorTuple.getValueByField(eq("message"))).thenThrow(new IllegalStateException());    bolt.prepare(new HashMap(), topologyContext, outputCollector);    verify(batchWriter, times(1)).init(any(), any());    for (int i = 0; i < 4; ++i) {        Tuple t = tuples.get(i);        bolt.execute(t);        verify(outputCollector, times(0)).ack(t);        verify(batchWriter, times(0)).write(eq(sensorType), any(), any());    }        BulkWriterResponse writerResponse = new BulkWriterResponse();    writerResponse.addAllSuccesses(messageIds);    writerResponse.addSuccess(new MessageId("goodMessage"));    when(batchWriter.write(any(), any(), any())).thenReturn(writerResponse);    bolt.execute(errorTuple);    for (Tuple t : tuples) {        verify(outputCollector, times(0)).ack(t);    }    bolt.execute(goodTuple);    for (Tuple t : tuples) {        verify(outputCollector, times(1)).ack(t);    }    verify(outputCollector, times(1)).ack(goodTuple);    verify(batchWriter, times(1)).write(eq(sensorType), any(), any());    verify(outputCollector, times(1)).reportError(any());    verify(outputCollector, times(0)).fail(any());}
0
public void testBatchErrorWriteFailure() throws Exception
{    ParserConfigurations configurations = getConfigurations(6);    String sensorType = "test";    WriterBolt bolt = spy(new WriterBolt(new WriterHandler(batchWriter), configurations, sensorType));    List<Tuple> tuples = new ArrayList<>();    List<MessageId> messageIds = new ArrayList<>();    for (int i = 0; i < 4; ++i) {        Tuple t = mock(Tuple.class);        String messageId = String.format(MESSAGE_ID_FORMAT, i + 1);        messageIds.add(new MessageId(messageId));        JSONObject message = new JSONObject();        message.put(Constants.GUID, messageId);        message.put("value", String.format(MESSAGE_FORMAT, i + 1));        when(t.getValueByField(eq("message"))).thenReturn(message);        tuples.add(t);    }    Tuple errorTuple = mock(Tuple.class);    Tuple goodTuple = mock(Tuple.class);    JSONObject goodMessage = new JSONObject();    goodMessage.put(Constants.GUID, "goodMessageId");    goodMessage.put("value", "goodMessage");    JSONObject errorMessage = new JSONObject();    goodMessage.put(Constants.GUID, "errorMessageId");    errorMessage.put("value", "errorMessage");    when(goodTuple.getValueByField(eq("message"))).thenReturn(goodMessage);    when(errorTuple.getValueByField(eq("message"))).thenReturn(errorMessage);    bolt.prepare(new HashMap(), topologyContext, outputCollector);    verify(batchWriter, times(1)).init(any(), any());    for (int i = 0; i < 4; ++i) {        Tuple t = tuples.get(i);        bolt.execute(t);        verify(outputCollector, times(0)).ack(t);        verify(batchWriter, times(0)).write(eq(sensorType), any(), any());    }        BulkWriterResponse writerResponse = new BulkWriterResponse();    writerResponse.addAllSuccesses(messageIds);    writerResponse.addSuccess(new MessageId("goodMessageId"));    writerResponse.addError(new IllegalStateException(), new MessageId("errorMessageId"));    when(batchWriter.write(any(), any(), any())).thenReturn(writerResponse);    bolt.execute(errorTuple);    for (Tuple t : tuples) {        verify(outputCollector, times(0)).ack(t);    }    UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.FATAL);    bolt.execute(goodTuple);    UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.ERROR);    for (Tuple t : tuples) {        verify(outputCollector, times(1)).ack(t);    }    verify(outputCollector, times(1)).ack(goodTuple);    verify(batchWriter, times(1)).write(eq(sensorType), any(), any());    verify(outputCollector, times(1)).reportError(any());    verify(outputCollector, times(0)).fail(any());}
0
public void testBatchErrorPathExceptionInWrite() throws Exception
{    ParserConfigurations configurations = getConfigurations(5);    String sensorType = "test";    WriterBolt bolt = spy(new WriterBolt(new WriterHandler(batchWriter), configurations, sensorType));    List<Tuple> tuples = new ArrayList<>();    List<String> messageIds = new ArrayList<>();    for (int i = 0; i < 4; ++i) {        Tuple t = mock(Tuple.class);        String messageId = String.format(MESSAGE_ID_FORMAT, i + 1);        messageIds.add(messageId);        JSONObject message = new JSONObject();        message.put("value", String.format(MESSAGE_FORMAT, i + 1));        when(t.getValueByField(eq("message"))).thenReturn(message);        tuples.add(t);    }    Tuple goodTuple = mock(Tuple.class);    when(goodTuple.getValueByField(eq("message"))).thenReturn(new JSONObject());    bolt.prepare(new HashMap(), topologyContext, outputCollector);    doThrow(new Exception()).when(batchWriter).write(any(), any(), any());    verify(batchWriter, times(1)).init(any(), any());    for (int i = 0; i < 4; ++i) {        Tuple t = tuples.get(i);        bolt.execute(t);        verify(outputCollector, times(0)).ack(t);        verify(batchWriter, times(0)).write(eq(sensorType), any(), any());    }    UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.FATAL);    bolt.execute(goodTuple);    UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.ERROR);    for (Tuple t : tuples) {        verify(outputCollector, times(1)).ack(t);    }    verify(batchWriter, times(1)).write(eq(sensorType), any(), any());    verify(outputCollector, times(1)).ack(goodTuple);    verify(outputCollector, times(1)).reportError(any());    verify(outputCollector, times(0)).fail(any());}
0
public Builder withTopologyProperties(Properties topologyProperties)
{    this.topologyProperties = topologyProperties;    return this;}
0
public Builder withBrokerUrl(String brokerUrl)
{    this.brokerUrl = brokerUrl;    return this;}
0
public Builder withSensorTypes(List<String> sensorTypes)
{    this.sensorTypes = sensorTypes;    return this;}
0
public Builder withOutputTopic(String topic)
{    this.outputTopic = topic;    return this;}
0
public Builder withErrorTopic(String topic)
{    this.errorTopic = topic;    return this;}
0
public ParserTopologyComponent build()
{    if (sensorTypes == null || sensorTypes.isEmpty()) {        throw new IllegalArgumentException("The sensor type must be defined.");    }    if (outputTopic == null) {        throw new IllegalArgumentException("The output topic must be defined.");    }    return new ParserTopologyComponent(topologyProperties, brokerUrl, sensorTypes, outputTopic, errorTopic);}
0
public void updateSensorTypes(List<String> sensorTypes)
{    this.sensorTypes = sensorTypes;}
0
public void start() throws UnableToStartException
{    try {        final Map<String, Object> stormConf = new HashMap<>();        stormConf.put(Config.TOPOLOGY_DEBUG, true);        ParserTopologyBuilder.ParserTopology topologyBuilder = ParserTopologyBuilder.build(topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY), Optional.ofNullable(brokerUrl), sensorTypes, (x, y) -> Collections.nCopies(sensorTypes.size(), 1), (x, y) -> Collections.nCopies(sensorTypes.size(), 1), (x, y) -> 1, (x, y) -> 1, (x, y) -> 1, (x, y) -> 1, (x, y) -> Collections.nCopies(sensorTypes.size(), new HashMap<>()), (x, y) -> null, (x, y) -> outputTopic, (x, y) -> errorTopic, (x, y) -> {            Config c = new Config();            c.putAll(stormConf);            return c;        });        stormCluster = new LocalCluster();        stormCluster.submitTopology(getTopologyName(), stormConf, topologyBuilder.getBuilder().createTopology());    } catch (Exception e) {        throw new UnableToStartException("Unable to start parser topology for sensorTypes: " + sensorTypes, e);    }}
0
public void stop()
{    if (stormCluster != null) {        try {            try {                                killTopology();                stormCluster.shutdown();            } catch (IllegalStateException ise) {                if (!(ise.getMessage().contains("It took over") && ise.getMessage().contains("to shut down slot"))) {                    throw ise;                } else {                    assassinateSlots();                                    }            }        } catch (Throwable t) {                    } finally {            cleanupWorkerDir();        }    }}
1
public void reset()
{    if (stormCluster != null) {        killTopology();    }}
0
protected void killTopology()
{    KillOptions ko = new KillOptions();    ko.set_wait_secs(0);    stormCluster.killTopologyWithOpts(getTopologyName(), ko);    try {                Thread.sleep(2000);    } catch (InterruptedException e) {        }}
0
protected String getTopologyName()
{    return StringUtils.join(sensorTypes, "__");}
0
public static Iterable<String> data()
{    return sensorTypes;}
0
public void test() throws Exception
{    ParserDriver driver = new StormParserDriver(sensorType, readSensorConfig(sensorType), readGlobalConfig());    runTest(driver);}
0
 List<ParserValidation> getValidations()
{    return new ArrayList<ParserValidation>() {        {            add(new SampleDataValidation());        }    };}
0
public void init(Map stormConf, WriterConfiguration config) throws Exception
{}
0
public BulkWriterResponse write(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    messages.forEach(bulkWriterMessage -> output.add(bulkWriterMessage.getMessage().toJSONString().getBytes(StandardCharsets.UTF_8)));    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    BulkWriterResponse bulkWriterResponse = new BulkWriterResponse();    bulkWriterResponse.addAllSuccesses(ids);    return bulkWriterResponse;}
0
public String getName()
{    return "collecting";}
0
public void close() throws Exception
{}
0
public List<byte[]> getOutput()
{    return output;}
0
public ParserConfigurations getConfigurations()
{    config.getSensorParserConfig(sensorType).getParserConfig().putIfAbsent(IndexingConfigurations.BATCH_SIZE_CONF, 1);    return config;}
0
protected void prepCache()
{}
0
protected void handleError(String sensorType, byte[] originalMessage, Tuple tuple, Throwable ex, OutputCollector collector)
{    errors.add(originalMessage);    }
1
protected void handleError(OutputCollector collector, MetronError error)
{    for (Object rawMessage : error.getRawMessages()) {        errors.add((byte[]) rawMessage);    }    if (error.getThrowable().isPresent()) {        Throwable throwable = error.getThrowable().get();            }}
1
public ProcessorResult<List<byte[]>> getResults()
{    return new ProcessorResult.Builder<List<byte[]>>().withProcessErrors(errors).withResult(output).build();}
0
public ProcessorResult<List<byte[]>> run(Iterable<byte[]> in)
{    ShimParserBolt bolt = new ShimParserBolt(new ArrayList<>());    byte[] b = SerializationUtils.serialize(bolt);    ShimParserBolt b2 = (ShimParserBolt) SerializationUtils.deserialize(b);    OutputCollector collector = mock(OutputCollector.class);    bolt.prepare(null, null, collector);    for (byte[] record : in) {        Tuple tuple = toTuple(record);        bolt.execute(tuple);        verify(collector, times(1)).ack(tuple);    }    return bolt.getResults();}
0
public Tuple toTuple(byte[] record)
{    Tuple ret = mock(Tuple.class);    when(ret.getStringByField("topic")).thenReturn(sensorType);    when(ret.getBinary(eq(0))).thenReturn(record);    return ret;}
0
public void setup()
{    spy(ParserTopologyBuilder.class);    when(ParserTopologyBuilder.createKafkaWriter(Optional.of("brokerUrl"), "zookeeperUrl", Optional.of("securityProtocol"))).thenReturn(kafkaWriter);}
0
public void shouldCreateWriterConfig()
{    SensorParserConfig broConfig = new SensorParserConfig();    broConfig.setSensorTopic("bro");    when(configs.getSensorParserConfig("bro")).thenReturn(broConfig);    KafkaWriter enrichmentWriter = mock(KafkaWriter.class);    when(kafkaWriter.withTopic(Constants.ENRICHMENT_TOPIC)).thenReturn(enrichmentWriter);    Map<String, SensorParserConfig> sensorTypeToParserConfig = new HashMap<String, SensorParserConfig>() {        {            put("bro", broConfig);        }    };    Map<String, WriterHandler> writerConfigs = ParserTopologyBuilder.createWriterConfigs("zookeeperUrl", Optional.of("brokerUrl"), sensorTypeToParserConfig, Optional.of("securityProtocol"), configs, Optional.empty());    assertEquals(1, writerConfigs.size());    assertEquals(enrichmentWriter, writerConfigs.get("bro").getBulkMessageWriter());    verify(enrichmentWriter, times(1)).configure(eq("bro"), any(ParserWriterConfiguration.class));    verifyNoMoreInteractions(enrichmentWriter);}
0
public void shouldCreateWriterConfigWithSensorParserConfigOutputTopic()
{    SensorParserConfig snortConfig = new SensorParserConfig();    snortConfig.setSensorTopic("snort");    snortConfig.setOutputTopic("snort_topic");    when(configs.getSensorParserConfig("snort")).thenReturn(snortConfig);    KafkaWriter snortTestWriter = mock(KafkaWriter.class);    when(kafkaWriter.withTopic("snort_topic")).thenReturn(snortTestWriter);    Map<String, SensorParserConfig> sensorTypeToParserConfig = new HashMap<String, SensorParserConfig>() {        {            put("snort", snortConfig);        }    };    Map<String, WriterHandler> writerConfigs = ParserTopologyBuilder.createWriterConfigs("zookeeperUrl", Optional.of("brokerUrl"), sensorTypeToParserConfig, Optional.of("securityProtocol"), configs, Optional.empty());    assertEquals(1, writerConfigs.size());    assertEquals(snortTestWriter, writerConfigs.get("snort").getBulkMessageWriter());    verify(snortTestWriter, times(1)).configure(eq("snort"), any(ParserWriterConfiguration.class));    verifyNoMoreInteractions(snortTestWriter);}
0
public void shouldCreateWriterConfigWithSuppliedOutputTopic()
{    SensorParserConfig snortConfig = new SensorParserConfig();    snortConfig.setSensorTopic("snort");    when(configs.getSensorParserConfig("snort")).thenReturn(snortConfig);    KafkaWriter suppliedTopicWriter = mock(KafkaWriter.class);    when(kafkaWriter.withTopic("supplied_topic")).thenReturn(suppliedTopicWriter);    Map<String, SensorParserConfig> sensorTypeToParserConfig = new HashMap<String, SensorParserConfig>() {        {            put("snort", snortConfig);        }    };    Map<String, WriterHandler> writerConfigs = ParserTopologyBuilder.createWriterConfigs("zookeeperUrl", Optional.of("brokerUrl"), sensorTypeToParserConfig, Optional.of("securityProtocol"), configs, Optional.of("supplied_topic"));    assertEquals(1, writerConfigs.size());    assertEquals(suppliedTopicWriter, writerConfigs.get("snort").getBulkMessageWriter());    verify(suppliedTopicWriter, times(1)).configure(eq("snort"), any(ParserWriterConfiguration.class));    verifyNoMoreInteractions(suppliedTopicWriter);}
0
public void shouldCreateWriterConfigWithWriterClassName()
{    SensorParserConfig yafConfig = new SensorParserConfig();    yafConfig.setSensorTopic("yaf");    yafConfig.setWriterClassName("org.apache.metron.writer.NoopWriter");    when(configs.getSensorParserConfig("yaf")).thenReturn(yafConfig);    Map<String, SensorParserConfig> sensorTypeToParserConfig = new HashMap<String, SensorParserConfig>() {        {            put("yaf", yafConfig);        }    };    Map<String, WriterHandler> writerConfigs = ParserTopologyBuilder.createWriterConfigs("zookeeperUrl", Optional.of("brokerUrl"), sensorTypeToParserConfig, Optional.of("securityProtocol"), configs, Optional.empty());    assertEquals(1, writerConfigs.size());    assertTrue(writerConfigs.get("yaf").getBulkMessageWriter() instanceof NoopWriter);}
0
public CLIBuilder with(ParserTopologyCLI.ParserOptions option, String val)
{    map.put(option, val);    return this;}
0
public CLIBuilder with(ParserTopologyCLI.ParserOptions option)
{    map.put(option, null);    return this;}
0
public CommandLine build(boolean longOpt) throws ParseException
{    return getCLI(map, longOpt);}
0
private CommandLine getCLI(EnumMap<ParserTopologyCLI.ParserOptions, String> options, boolean longOpt) throws ParseException
{    ArrayList<String> args = new ArrayList<>();    for (Map.Entry<ParserTopologyCLI.ParserOptions, String> option : options.entrySet()) {        boolean hasLongOpt = option.getKey().option.hasLongOpt();        if (hasLongOpt && longOpt) {            args.add("--" + option.getKey().option.getLongOpt());            if (option.getKey().option.hasArg() && option.getValue() != null) {                args.add(option.getValue());            }        } else if (hasLongOpt && !longOpt) {            args.add("-" + option.getKey().shortCode);            if (option.getKey().option.hasArg() && option.getValue() != null) {                args.add(option.getValue());            }        }    }    return ParserTopologyCLI.ParserOptions.parse(new PosixParser(), args.toArray(new String[args.size()]));}
0
public void testNoOverlappingArgs() throws Exception
{    Set<String> optionStrs = new HashSet<>();    for (ParserTopologyCLI.ParserOptions option : ParserTopologyCLI.ParserOptions.values()) {        if (optionStrs.contains(option.option.getLongOpt())) {            throw new IllegalStateException("Reused long option: " + option.option.getLongOpt());        }        if (optionStrs.contains(option.shortCode)) {            throw new IllegalStateException("Reused short option: " + option.shortCode);        }        optionStrs.add(option.option.getLongOpt());        optionStrs.add(option.shortCode);    }}
0
public void testKafkaOffset_happyPath() throws ParseException
{    kafkaOffset(true);    kafkaOffset(false);}
0
public void kafkaOffset(boolean longOpt) throws ParseException
{    CommandLine cli = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").with(ParserTopologyCLI.ParserOptions.SENSOR_TYPES, "mysensor").build(longOpt);    Assert.assertEquals("myzk", ParserTopologyCLI.ParserOptions.ZK_QUORUM.get(cli));    Assert.assertEquals("mybroker", ParserTopologyCLI.ParserOptions.BROKER_URL.get(cli));    Assert.assertEquals("mysensor", ParserTopologyCLI.ParserOptions.SENSOR_TYPES.get(cli));}
0
public void testCLI_happyPath() throws ParseException
{    happyPath(true);    happyPath(false);}
0
public void testCLI_insufficientArg() throws ParseException
{    UnitTestHelper.setLog4jLevel(Parser.class, Level.FATAL);    CommandLine cli = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").build(true);    UnitTestHelper.setLog4jLevel(Parser.class, Level.ERROR);}
0
public void happyPath(boolean longOpt) throws ParseException
{    CommandLine cli = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").with(ParserTopologyCLI.ParserOptions.SENSOR_TYPES, "mysensor").build(longOpt);    Assert.assertEquals("myzk", ParserTopologyCLI.ParserOptions.ZK_QUORUM.get(cli));    Assert.assertEquals("mybroker", ParserTopologyCLI.ParserOptions.BROKER_URL.get(cli));    Assert.assertEquals("mysensor", ParserTopologyCLI.ParserOptions.SENSOR_TYPES.get(cli));}
0
public void testConfig_noExtra() throws ParseException
{    testConfig_noExtra(true);    testConfig_noExtra(false);}
0
public void testConfig_noExtra(boolean longOpt) throws ParseException
{    CommandLine cli = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").with(ParserTopologyCLI.ParserOptions.SENSOR_TYPES, "mysensor").with(ParserTopologyCLI.ParserOptions.NUM_WORKERS, "1").with(ParserTopologyCLI.ParserOptions.NUM_ACKERS, "2").with(ParserTopologyCLI.ParserOptions.NUM_MAX_TASK_PARALLELISM, "3").with(ParserTopologyCLI.ParserOptions.MESSAGE_TIMEOUT, "4").build(longOpt);    Optional<Config> configOptional = ParserTopologyCLI.ParserOptions.getConfig(cli);    Config config = configOptional.get();    Assert.assertEquals(1, config.get(Config.TOPOLOGY_WORKERS));    Assert.assertEquals(2, config.get(Config.TOPOLOGY_ACKER_EXECUTORS));    Assert.assertEquals(3, config.get(Config.TOPOLOGY_MAX_TASK_PARALLELISM));    Assert.assertEquals(4, config.get(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS));}
0
public void testOutputTopic() throws Exception
{    testOutputTopic(true);    testOutputTopic(false);}
0
public void testOutputTopic(boolean longOpt) throws ParseException
{    CommandLine cli = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").with(ParserTopologyCLI.ParserOptions.SENSOR_TYPES, "mysensor").with(ParserTopologyCLI.ParserOptions.OUTPUT_TOPIC, "my_topic").build(longOpt);    Assert.assertEquals("my_topic", ParserTopologyCLI.ParserOptions.OUTPUT_TOPIC.get(cli));}
0
public void testConfig_extra() throws Exception
{    testConfig_extra(true);    testConfig_extra(false);}
0
public void testConfig_extra(boolean longOpt) throws IOException, ParseException
{    File extraFile = File.createTempFile("extra", "json");    try {        FileUtils.write(extraFile, extraConfig);        CommandLine cli = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").with(ParserTopologyCLI.ParserOptions.SENSOR_TYPES, "mysensor").with(ParserTopologyCLI.ParserOptions.MESSAGE_TIMEOUT, "4").with(ParserTopologyCLI.ParserOptions.EXTRA_OPTIONS, extraFile.getAbsolutePath()).build(longOpt);        Optional<Config> configOptional = ParserTopologyCLI.ParserOptions.getConfig(cli);        Config config = configOptional.get();        Assert.assertEquals(4, config.get(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS));        Assert.assertEquals("foo", config.get("string"));        Assert.assertEquals(1, config.get("integer"));    } finally {        extraFile.deleteOnExit();    }}
0
public List<Integer> getSpoutParallelism()
{    return spoutParallelism;}
0
public List<Integer> getSpoutNumTasks()
{    return spoutNumTasks;}
0
public Integer getParserParallelism()
{    return parserParallelism;}
0
public Integer getParserNumTasks()
{    return parserNumTasks;}
0
public Integer getErrorParallelism()
{    return errorParallelism;}
0
public Integer getErrorNumTasks()
{    return errorNumTasks;}
0
public List<Map<String, Object>> getSpoutConfig()
{    return spoutConfig;}
0
public String getSecurityProtocol()
{    return securityProtocol;}
0
public Config getStormConf()
{    return stormConf;}
0
public String getOutputTopic()
{    return outputTopic;}
0
public String getErrorTopic()
{    return errorTopic;}
0
private static SensorParserConfig getBaseConfig()
{    try {        return JSONUtils.INSTANCE.load(baseConfig, SensorParserConfig.class);    } catch (IOException e) {        throw new IllegalStateException(e.getMessage(), e);    }}
0
public void testSpoutParallelism() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.SPOUT_PARALLELISM, "10", input -> input.getSpoutParallelism().equals(Collections.singletonList(10)), () -> {        SensorParserConfig config = getBaseConfig();        config.setSpoutParallelism(20);        return Collections.singletonList(config);    }, input -> input.getSpoutParallelism().equals(Collections.singletonList(20)));}
0
public void testSpoutParallelismMultiple() throws Exception
{            List<Integer> spoutParCli = new ArrayList<>();    spoutParCli.add(10);    spoutParCli.add(12);    List<Integer> spoutParConfig = new ArrayList<>();    spoutParConfig.add(20);    spoutParConfig.add(30);    testConfigOption(ParserTopologyCLI.ParserOptions.SPOUT_PARALLELISM, "10,12", input -> input.getSpoutParallelism().equals(spoutParCli), () -> {        SensorParserConfig config = getBaseConfig();        config.setSpoutParallelism(20);        SensorParserConfig config2 = getBaseConfig();        config2.setSpoutParallelism(30);        List<SensorParserConfig> configs = new ArrayList<>();        configs.add(config);        configs.add(config2);        return configs;    }, input -> input.getSpoutParallelism().equals(spoutParConfig));}
0
public void testSpoutNumTasks() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.SPOUT_NUM_TASKS, "10", input -> input.getSpoutNumTasks().equals(Collections.singletonList(10)), () -> {        SensorParserConfig config = getBaseConfig();        config.setSpoutNumTasks(20);        return Collections.singletonList(config);    }, input -> input.getSpoutNumTasks().equals(Collections.singletonList(20)));}
0
public void testSpoutNumTasksMultiple() throws Exception
{        List<Integer> numTasksCli = new ArrayList<>();    numTasksCli.add(10);    numTasksCli.add(12);    List<Integer> numTasksConfig = new ArrayList<>();    numTasksConfig.add(20);    numTasksConfig.add(30);    testConfigOption(ParserTopologyCLI.ParserOptions.SPOUT_NUM_TASKS, "10,12", input -> input.getSpoutNumTasks().equals(numTasksCli), () -> {        SensorParserConfig config = getBaseConfig();        config.setSpoutNumTasks(20);        SensorParserConfig config2 = getBaseConfig();        config2.setSpoutNumTasks(30);        List<SensorParserConfig> configs = new ArrayList<>();        configs.add(config);        configs.add(config2);        return configs;    }, input -> input.getSpoutNumTasks().equals(numTasksConfig));}
0
public void testParserParallelism() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.PARSER_PARALLELISM, "10", input -> input.getParserParallelism().equals(10), () -> {        SensorParserConfig config = getBaseConfig();        config.setParserParallelism(20);        return Collections.singletonList(config);    }, input -> input.getParserParallelism().equals(20));}
0
public void testParserParallelismMultiple() throws Exception
{        testConfigOption(ParserTopologyCLI.ParserOptions.PARSER_PARALLELISM, "10", input -> input.getParserParallelism().equals(10), () -> {        SensorParserConfig config = getBaseConfig();        config.setParserParallelism(20);        SensorParserConfig config2 = getBaseConfig();        config2.setParserParallelism(30);        List<SensorParserConfig> configs = new ArrayList<>();        configs.add(config);        configs.add(config2);        return configs;    }, input -> input.getParserParallelism().equals(30));}
0
public void testParserNumTasks() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.PARSER_NUM_TASKS, "10", input -> input.getParserNumTasks().equals(10), () -> {        SensorParserConfig config = getBaseConfig();        config.setParserNumTasks(20);        SensorParserConfig config2 = getBaseConfig();        config2.setParserNumTasks(30);        List<SensorParserConfig> configs = new ArrayList<>();        configs.add(config);        configs.add(config2);        return configs;    }, input -> input.getParserNumTasks().equals(30));}
0
public void testParserNumTasksMultiple() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.PARSER_NUM_TASKS, "10", input -> input.getParserNumTasks().equals(10), () -> {        SensorParserConfig config = getBaseConfig();        config.setParserNumTasks(20);        return Collections.singletonList(config);    }, input -> input.getParserNumTasks().equals(20));}
0
public void testErrorParallelism() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.ERROR_WRITER_PARALLELISM, "10", input -> input.getErrorParallelism().equals(10), () -> {        SensorParserConfig config = getBaseConfig();        config.setErrorWriterParallelism(20);        return Collections.singletonList(config);    }, input -> input.getErrorParallelism().equals(20));}
0
public void testErrorNumTasks() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.ERROR_WRITER_NUM_TASKS, "10", input -> input.getErrorNumTasks().equals(10), () -> {        SensorParserConfig config = getBaseConfig();        config.setErrorWriterNumTasks(20);        return Collections.singletonList(config);    }, input -> input.getErrorNumTasks().equals(20));}
0
public void testSecurityProtocol_fromCLI() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.SECURITY_PROTOCOL, "PLAINTEXT", input -> input.getSecurityProtocol().equals("PLAINTEXT"), () -> {        SensorParserConfig config = getBaseConfig();        config.setSecurityProtocol("KERBEROS");        return Collections.singletonList(config);    }, input -> input.getSecurityProtocol().equals("KERBEROS"));}
0
public void testSecurityProtocol_fromCLIMultipleUniform() throws Exception
{    testConfigOption(ParserTopologyCLI.ParserOptions.SECURITY_PROTOCOL, "PLAINTEXT", input -> input.getSecurityProtocol().equals("PLAINTEXT"), () -> {        SensorParserConfig config = getBaseConfig();        config.setSecurityProtocol("PLAINTEXT");        SensorParserConfig config2 = getBaseConfig();        config2.setSecurityProtocol("PLAINTEXT");        List<SensorParserConfig> configs = new ArrayList<>();        configs.add(config);        configs.add(config2);        return configs;    }, input -> input.getSecurityProtocol().equals("PLAINTEXT"));}
0
public void testSecurityProtocol_fromCLIMultipleMixed() throws Exception
{        testConfigOption(ParserTopologyCLI.ParserOptions.SECURITY_PROTOCOL, "PLAINTEXT", input -> input.getSecurityProtocol().equals("PLAINTEXT"), () -> {        SensorParserConfig config = getBaseConfig();        config.setSecurityProtocol("PLAINTEXT");        SensorParserConfig config2 = getBaseConfig();        config2.setSecurityProtocol("KERBEROS");        SensorParserConfig config3 = getBaseConfig();        config3.setSecurityProtocol("PLAINTEXT");        List<SensorParserConfig> configs = new ArrayList<>();        configs.add(config);        configs.add(config2);        configs.add(config3);        return configs;    }, input -> input.getSecurityProtocol().equals("KERBEROS"));}
0
public void testSecurityProtocol_fromSpout() throws Exception
{        File extraConfig = File.createTempFile("spoutConfig", "json");    extraConfig.deleteOnExit();    writeMap(extraConfig, new HashMap<String, Object>() {        {            put("security.protocol", "PLAINTEXTSASL");        }    });    {                testConfigOption(new EnumMap<ParserTopologyCLI.ParserOptions, String>(ParserTopologyCLI.ParserOptions.class) {            {                put(ParserTopologyCLI.ParserOptions.SPOUT_CONFIG, extraConfig.getAbsolutePath());                put(ParserTopologyCLI.ParserOptions.SECURITY_PROTOCOL, "PLAINTEXT");            }        }, input -> input.getSecurityProtocol().equals("PLAINTEXT"), () -> {            SensorParserConfig config = getBaseConfig();            config.setSecurityProtocol("PLAINTEXTSASL_FROM_ZK");            return Collections.singletonList(config);        }, input -> input.getSecurityProtocol().equals("PLAINTEXTSASL_FROM_ZK"));    }    {                testConfigOption(new EnumMap<ParserTopologyCLI.ParserOptions, String>(ParserTopologyCLI.ParserOptions.class) {            {                put(ParserTopologyCLI.ParserOptions.SPOUT_CONFIG, extraConfig.getAbsolutePath());            }        }, input -> input.getSecurityProtocol().equals("PLAINTEXTSASL"), () -> {            SensorParserConfig config = getBaseConfig();            config.setSecurityProtocol("PLAINTEXTSASL_FROM_ZK");            return Collections.singletonList(config);        }, input -> input.getSecurityProtocol().equals("PLAINTEXTSASL_FROM_ZK"));    }}
0
public void testTopologyConfig_fromConfigExplicitly() throws Exception
{    testConfigOption(new EnumMap<ParserTopologyCLI.ParserOptions, String>(ParserTopologyCLI.ParserOptions.class) {        {            put(ParserTopologyCLI.ParserOptions.NUM_WORKERS, "10");            put(ParserTopologyCLI.ParserOptions.NUM_ACKERS, "20");        }    }, input -> {        Config c = input.getStormConf();        return (int) c.get(Config.TOPOLOGY_WORKERS) == 10 && (int) c.get(Config.TOPOLOGY_ACKER_EXECUTORS) == 20;    }, () -> {        SensorParserConfig config = getBaseConfig();        config.setNumWorkers(100);        config.setNumAckers(200);        return Collections.singletonList(config);    }, input -> {        Config c = input.getStormConf();        return (int) c.get(Config.TOPOLOGY_WORKERS) == 100 && (int) c.get(Config.TOPOLOGY_ACKER_EXECUTORS) == 200;    });}
0
public void testTopologyConfig() throws Exception
{    File extraConfig = File.createTempFile("topologyConfig", "json");    extraConfig.deleteOnExit();    writeMap(extraConfig, new HashMap<String, Object>() {        {            put(Config.TOPOLOGY_DEBUG, true);        }    });    testConfigOption(new EnumMap<ParserTopologyCLI.ParserOptions, String>(ParserTopologyCLI.ParserOptions.class) {        {            put(ParserTopologyCLI.ParserOptions.NUM_WORKERS, "10");            put(ParserTopologyCLI.ParserOptions.NUM_ACKERS, "20");            put(ParserTopologyCLI.ParserOptions.EXTRA_OPTIONS, extraConfig.getAbsolutePath());        }    }, input -> {        Config c = input.getStormConf();        return (int) c.get(Config.TOPOLOGY_WORKERS) == 10 && (int) c.get(Config.TOPOLOGY_ACKER_EXECUTORS) == 20 && (boolean) c.get(Config.TOPOLOGY_DEBUG);    }, () -> {        SensorParserConfig config = getBaseConfig();        config.setStormConfig(new HashMap<String, Object>() {            {                put(Config.TOPOLOGY_WORKERS, 100);                put(Config.TOPOLOGY_ACKER_EXECUTORS, 200);            }        });        return Collections.singletonList(config);    }, input -> {        Config c = input.getStormConf();        return (int) c.get(Config.TOPOLOGY_WORKERS) == 100 && (int) c.get(Config.TOPOLOGY_ACKER_EXECUTORS) == 200 && !c.containsKey(Config.TOPOLOGY_DEBUG);    });}
0
public void testSpoutConfig() throws Exception
{    File extraConfig = File.createTempFile("spoutConfig", "json");    extraConfig.deleteOnExit();    writeMap(extraConfig, new HashMap<String, Object>() {        {            put("extra_config", "from_file");        }    });    EnumMap<ParserTopologyCLI.ParserOptions, String> cliOptions = new EnumMap<ParserTopologyCLI.ParserOptions, String>(ParserTopologyCLI.ParserOptions.class) {        {            put(ParserTopologyCLI.ParserOptions.SPOUT_CONFIG, extraConfig.getAbsolutePath());        }    };    Predicate<ParserInput> cliOverrideExpected = input -> {        return input.getSpoutConfig().get(0).get("extra_config").equals("from_file");    };    Predicate<ParserInput> configOverrideExpected = input -> {        return input.getSpoutConfig().get(0).get("extra_config").equals("from_zk");    };    Supplier<List<SensorParserConfig>> configSupplier = () -> {        SensorParserConfig config = getBaseConfig();        config.setSpoutConfig(new HashMap<String, Object>() {            {                put("extra_config", "from_zk");            }        });        return Collections.singletonList(config);    };    testConfigOption(cliOptions, cliOverrideExpected, configSupplier, configOverrideExpected);}
0
private void writeMap(File outFile, Map<String, Object> config) throws IOException
{    FileUtils.write(outFile, JSONUtils.INSTANCE.toJSON(config, true));}
0
private void testConfigOption(ParserTopologyCLI.ParserOptions option, String cliOverride, Predicate<ParserInput> cliOverrideCondition, Supplier<List<SensorParserConfig>> configSupplier, Predicate<ParserInput> configOverrideCondition) throws Exception
{    testConfigOption(new EnumMap<ParserTopologyCLI.ParserOptions, String>(ParserTopologyCLI.ParserOptions.class) {        {            put(option, cliOverride);        }    }, cliOverrideCondition, configSupplier, configOverrideCondition);}
0
private void testConfigOption(EnumMap<ParserTopologyCLI.ParserOptions, String> options, Predicate<ParserInput> cliOverrideCondition, Supplier<List<SensorParserConfig>> configSupplier, Predicate<ParserInput> configOverrideCondition) throws Exception
{        List<SensorParserConfig> configs = configSupplier.get();    {        CLIBuilder builder = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").with(ParserTopologyCLI.ParserOptions.SENSOR_TYPES, "mysensor");        for (Map.Entry<ParserTopologyCLI.ParserOptions, String> entry : options.entrySet()) {            builder.with(entry.getKey(), entry.getValue());        }        CommandLine cmd = builder.build(true);        ParserInput input = getInput(cmd, configs);        Assert.assertTrue(cliOverrideCondition.test(input));    }        {        CLIBuilder builder = new CLIBuilder().with(ParserTopologyCLI.ParserOptions.BROKER_URL, "mybroker").with(ParserTopologyCLI.ParserOptions.ZK_QUORUM, "myzk").with(ParserTopologyCLI.ParserOptions.SENSOR_TYPES, "mysensor");        CommandLine cmd = builder.build(true);        ParserInput input = getInput(cmd, configs);        Assert.assertTrue(configOverrideCondition.test(input));    }}
0
private static ParserInput getInput(CommandLine cmd, List<SensorParserConfig> configs) throws Exception
{    final ParserInput[] parserInput = new ParserInput[] { null };    new ParserTopologyCLI() {        @Override        protected ParserTopologyBuilder.ParserTopology getParserTopology(String zookeeperUrl, Optional<String> brokerUrl, List<String> sensorType, ValueSupplier<List> spoutParallelism, ValueSupplier<List> spoutNumTasks, ValueSupplier<Integer> parserParallelism, ValueSupplier<Integer> parserNumTasks, ValueSupplier<Integer> errorParallelism, ValueSupplier<Integer> errorNumTasks, ValueSupplier<List> spoutConfig, ValueSupplier<String> securityProtocol, ValueSupplier<Config> stormConf, ValueSupplier<String> outputTopic, ValueSupplier<String> errorTopic) throws Exception {            parserInput[0] = new ParserInput(spoutParallelism, spoutNumTasks, parserParallelism, parserNumTasks, errorParallelism, errorNumTasks, spoutConfig, securityProtocol, stormConf, outputTopic, errorTopic, configs);            return null;        }    }.createParserTopology(cmd);    return parserInput[0];}
0
protected ParserTopologyBuilder.ParserTopology getParserTopology(String zookeeperUrl, Optional<String> brokerUrl, List<String> sensorType, ValueSupplier<List> spoutParallelism, ValueSupplier<List> spoutNumTasks, ValueSupplier<Integer> parserParallelism, ValueSupplier<Integer> parserNumTasks, ValueSupplier<Integer> errorParallelism, ValueSupplier<Integer> errorNumTasks, ValueSupplier<List> spoutConfig, ValueSupplier<String> securityProtocol, ValueSupplier<Config> stormConf, ValueSupplier<String> outputTopic, ValueSupplier<String> errorTopic) throws Exception
{    parserInput[0] = new ParserInput(spoutParallelism, spoutNumTasks, parserParallelism, parserNumTasks, errorParallelism, errorNumTasks, spoutConfig, securityProtocol, stormConf, outputTopic, errorTopic, configs);    return null;}
0
public void test() throws UnableToStartException, IOException
{    final String sensorType = "dummy";        final List<byte[]> inputMessages = new ArrayList<byte[]>() {        {            add(Bytes.toBytes("col11,col12,col13"));            add(Bytes.toBytes("col21,col22,col23"));            add(Bytes.toBytes("col31,col32,col33"));        }    };        MockHBaseTableProvider.addToCache(sensorType, "cf");    final Properties topologyProperties = new Properties();    final ZKServerComponent zkServerComponent = getZKServerComponent(topologyProperties);    final KafkaComponent kafkaComponent = getKafkaComponent(topologyProperties, new ArrayList<KafkaComponent.Topic>() {        {            add(new KafkaComponent.Topic(sensorType, 1));        }    });    topologyProperties.setProperty("kafka.broker", kafkaComponent.getBrokerList());    SensorParserConfig parserConfig = JSONUtils.INSTANCE.load(parserConfigJSON, SensorParserConfig.class);    System.out.println("Workspace: " + System.getProperty("user.dir"));    System.out.println("Configs path: ../" + TestConstants.SAMPLE_CONFIG_PATH);    ConfigUploadComponent configUploadComponent = new ConfigUploadComponent().withTopologyProperties(topologyProperties).withGlobalConfigsPath("../" + TestConstants.SAMPLE_CONFIG_PATH).withParserSensorConfig(sensorType, parserConfig);    ParserTopologyComponent parserTopologyComponent = new ParserTopologyComponent.Builder().withSensorTypes(Collections.singletonList(sensorType)).withTopologyProperties(topologyProperties).withBrokerUrl(kafkaComponent.getBrokerList()).withOutputTopic(parserConfig.getOutputTopic()).build();    ComponentRunner runner = new ComponentRunner.Builder().withComponent("zk", zkServerComponent).withComponent("kafka", kafkaComponent).withComponent("config", configUploadComponent).withComponent("org/apache/storm", parserTopologyComponent).withMillisecondsBetweenAttempts(5000).withCustomShutdownOrder(new String[] { "org/apache/storm", "config", "kafka", "zk" }).withNumRetries(10).build();    try {        runner.start();        kafkaComponent.writeMessages(sensorType, inputMessages);        ProcessorResult<List<LookupKV<EnrichmentKey, EnrichmentValue>>> result = runner.process(new Processor<List<LookupKV<EnrichmentKey, EnrichmentValue>>>() {            List<LookupKV<EnrichmentKey, EnrichmentValue>> messages = null;            @Override            public ReadinessState process(ComponentRunner runner) {                MockHTable table = (MockHTable) MockHBaseTableProvider.getFromCache(sensorType);                if (table != null && table.size() == inputMessages.size()) {                    EnrichmentConverter converter = new EnrichmentConverter();                    messages = new ArrayList<>();                    try {                        for (Result r : table.getScanner(Bytes.toBytes("cf"))) {                            messages.add(converter.fromResult(r, "cf"));                        }                    } catch (IOException e) {                    }                    return ReadinessState.READY;                }                return ReadinessState.NOT_READY;            }            @Override            public ProcessorResult<List<LookupKV<EnrichmentKey, EnrichmentValue>>> getResult() {                ProcessorResult.Builder<List<LookupKV<EnrichmentKey, EnrichmentValue>>> builder = new ProcessorResult.Builder();                return builder.withResult(messages).build();            }        });        Set<String> validIndicators = new HashSet<>(ImmutableList.of("col12", "col22", "col32"));        Map<String, Map<String, String>> validMetadata = new HashMap<String, Map<String, String>>() {            {                put("col12", new HashMap<String, String>() {                    {                        put("col1", "col11");                        put("col3", "col13");                    }                });                put("col22", new HashMap<String, String>() {                    {                        put("col1", "col21");                        put("col3", "col23");                    }                });                put("col32", new HashMap<String, String>() {                    {                        put("col1", "col31");                        put("col3", "col33");                    }                });            }        };        for (LookupKV<EnrichmentKey, EnrichmentValue> kv : result.getResult()) {            Assert.assertTrue(validIndicators.contains(kv.getKey().indicator));            Assert.assertEquals(kv.getValue().getMetadata().get("source.type"), "dummy");            Assert.assertNotNull(kv.getValue().getMetadata().get("timestamp"));            Assert.assertNotNull(kv.getValue().getMetadata().get("original_string"));            Map<String, String> metadata = validMetadata.get(kv.getKey().indicator);            for (Map.Entry<String, String> x : metadata.entrySet()) {                Assert.assertEquals(kv.getValue().getMetadata().get(x.getKey()), x.getValue());            }            Assert.assertEquals(metadata.size() + 4, kv.getValue().getMetadata().size());        }    } finally {        if (runner != null) {            runner.stop();        }    }}
0
public ReadinessState process(ComponentRunner runner)
{    MockHTable table = (MockHTable) MockHBaseTableProvider.getFromCache(sensorType);    if (table != null && table.size() == inputMessages.size()) {        EnrichmentConverter converter = new EnrichmentConverter();        messages = new ArrayList<>();        try {            for (Result r : table.getScanner(Bytes.toBytes("cf"))) {                messages.add(converter.fromResult(r, "cf"));            }        } catch (IOException e) {        }        return ReadinessState.READY;    }    return ReadinessState.NOT_READY;}
0
public ProcessorResult<List<LookupKV<EnrichmentKey, EnrichmentValue>>> getResult()
{    ProcessorResult.Builder<List<LookupKV<EnrichmentKey, EnrichmentValue>>> builder = new ProcessorResult.Builder();    return builder.withResult(messages).build();}
0
public void testEnvelopedData() throws IOException
{    ParserDriver driver = new StormParserDriver("test", parserConfig_default, "{}");    super.testEnvelopedData(driver);}
0
public void testEnvelopedData_withMetadataPrefix() throws IOException
{    ParserDriver driver = new StormParserDriver("test", parserConfig_withPrefix, "{}");    super.testEnvelopedData_withMetadataPrefix(driver);}
0
public void testEnvelopedData_noMergeMetadata() throws IOException
{    ParserDriver driver = new StormParserDriver("test", parserConfig_nomerge, "{}");    super.testEnvelopedData_noMergeMetadata(driver);}
0
public void testCiscoPixEnvelopingCisco302020() throws Exception
{    ParserDriver syslogDriver = new StormParserDriver("ciscoPix", ciscoPixSyslogConfig, "{}");    ParserDriver driver = new StormParserDriver("cisco302020", cisco302020Config, "{}");    super.testCiscoPixEnvelopingCisco302020(syslogDriver, driver);}
0
public boolean isValid(Map<String, Object> input, Map<String, Object> validationConfig, Map<String, Object> globalConfig, Context context)
{    if (input.get("action") != null && input.get("action").equals("invalid")) {        return false;    }    return true;}
0
public void initialize(Map<String, Object> validationConfig, Map<String, Object> globalConfig)
{}
0
public void test_topic_redirection() throws Exception
{    final String sensorType = "dummy";    SensorParserConfig parserConfig = JSONUtils.INSTANCE.load(parserConfigJSONKafkaRedirection, SensorParserConfig.class);    final List<byte[]> inputMessages = new ArrayList<byte[]>() {        {            add(Bytes.toBytes("metron,foo"));            add(Bytes.toBytes("notmetron,foo"));            add(Bytes.toBytes("metron,bar"));            add(Bytes.toBytes("metron,baz"));        }    };    final Properties topologyProperties = new Properties();    ComponentRunner runner = setupTopologyComponents(topologyProperties, Collections.singletonList(sensorType), Collections.singletonList(parserConfig), globalConfigWithValidation);    try {        runner.start();        kafkaComponent.writeMessages(sensorType, inputMessages);        KafkaProcessor<Map<String, List<JSONObject>>> kafkaProcessor = getKafkaProcessor(parserConfig.getOutputTopic(), parserConfig.getErrorTopic(), kafkaMessageSet -> kafkaMessageSet.getMessages().size() == 3 && kafkaMessageSet.getErrors().isEmpty());        ProcessorResult<Map<String, List<JSONObject>>> result = runner.process(kafkaProcessor);                Map<String, List<JSONObject>> outputMessages = result.getResult();        for (JSONObject j : outputMessages.get(Constants.ENRICHMENT_TOPIC)) {            Assert.assertEquals("metron", j.get("name"));            Assert.assertEquals("output", j.get("route_field"));            Assert.assertTrue(ImmutableSet.of("foo", "bar", "baz").contains(j.get("dummy")));        }    } finally {        if (runner != null) {            runner.stop();        }    }}
0
public void parser_with_global_validations_writes_bad_records_to_error_topic() throws Exception
{    final String sensorType = "dummy";    SensorParserConfig parserConfig = JSONUtils.INSTANCE.load(parserConfigJSON, SensorParserConfig.class);    final List<byte[]> inputMessages = new ArrayList<byte[]>() {        {            add(Bytes.toBytes("valid,foo"));            add(Bytes.toBytes("invalid,foo"));            add(Bytes.toBytes("error"));        }    };    final Properties topologyProperties = new Properties();    ComponentRunner runner = setupTopologyComponents(topologyProperties, Collections.singletonList(sensorType), Collections.singletonList(parserConfig), globalConfigWithValidation);    try {        runner.start();        kafkaComponent.writeMessages(sensorType, inputMessages);        KafkaProcessor<Map<String, List<JSONObject>>> kafkaProcessor = getKafkaProcessor(parserConfig.getOutputTopic(), parserConfig.getErrorTopic());        ProcessorResult<Map<String, List<JSONObject>>> result = runner.process(kafkaProcessor);                Map<String, List<JSONObject>> outputMessages = result.getResult();        Assert.assertEquals(2, outputMessages.size());        Assert.assertEquals(1, outputMessages.get(Constants.ENRICHMENT_TOPIC).size());        Assert.assertEquals("valid", outputMessages.get(Constants.ENRICHMENT_TOPIC).get(0).get("action"));        Assert.assertEquals(2, outputMessages.get(parserConfig.getErrorTopic()).size());                JSONObject invalidMessage = outputMessages.get(parserConfig.getErrorTopic()).get(0);        Assert.assertEquals(Constants.ErrorType.PARSER_INVALID.getType(), invalidMessage.get(Constants.ErrorFields.ERROR_TYPE.getName()));        JSONObject rawMessage = JSONUtils.INSTANCE.load((String) invalidMessage.get(Constants.ErrorFields.RAW_MESSAGE.getName()), JSONObject.class);        Assert.assertEquals("foo", rawMessage.get("dummy"));        Assert.assertEquals("invalid", rawMessage.get("action"));                JSONObject errorMessage = outputMessages.get(parserConfig.getErrorTopic()).get(1);        Assert.assertEquals(Constants.ErrorType.PARSER_ERROR.getType(), errorMessage.get(Constants.ErrorFields.ERROR_TYPE.getName()));        Assert.assertEquals("error", errorMessage.get(Constants.ErrorFields.RAW_MESSAGE.getName()));    } finally {        if (runner != null) {            runner.stop();        }    }}
0
public ComponentRunner setupTopologyComponents(Properties topologyProperties, List<String> sensorTypes, List<SensorParserConfig> parserConfigs, String globalConfig)
{    zkServerComponent = getZKServerComponent(topologyProperties);    List<KafkaComponent.Topic> topics = new ArrayList<>();    for (String sensorType : sensorTypes) {        topics.add(new KafkaComponent.Topic(sensorType, 1));    }    topics.add(new KafkaComponent.Topic(Constants.ENRICHMENT_TOPIC, 1));    kafkaComponent = getKafkaComponent(topologyProperties, topics);    topologyProperties.setProperty("kafka.broker", kafkaComponent.getBrokerList());    configUploadComponent = new ConfigUploadComponent().withTopologyProperties(topologyProperties).withGlobalConfig(globalConfig);    for (int i = 0; i < sensorTypes.size(); ++i) {        configUploadComponent.withParserSensorConfig(sensorTypes.get(i), parserConfigs.get(i));    }    parserTopologyComponent = new ParserTopologyComponent.Builder().withSensorTypes(sensorTypes).withTopologyProperties(topologyProperties).withBrokerUrl(kafkaComponent.getBrokerList()).withErrorTopic(parserConfigs.get(0).getErrorTopic()).withOutputTopic(parserConfigs.get(0).getOutputTopic()).build();    return new ComponentRunner.Builder().withComponent("zk", zkServerComponent).withComponent("kafka", kafkaComponent).withComponent("config", configUploadComponent).withComponent("org/apache/storm", parserTopologyComponent).withMillisecondsBetweenAttempts(5000).withNumRetries(10).withCustomShutdownOrder(new String[] { "org/apache/storm", "config", "kafka", "zk" }).build();}
0
private KafkaProcessor<Map<String, List<JSONObject>>> getKafkaProcessor(String outputTopic, String errorTopic)
{    return getKafkaProcessor(outputTopic, errorTopic, messageSet -> (messageSet.getMessages().size() == 1) && (messageSet.getErrors().size() == 2));}
0
private KafkaProcessor<Map<String, List<JSONObject>>> getKafkaProcessor(String outputTopic, String errorTopic, Predicate<KafkaMessageSet> predicate)
{    return new KafkaProcessor<>().withKafkaComponentName("kafka").withReadTopic(outputTopic).withErrorTopic(errorTopic).withValidateReadMessages(new Function<KafkaMessageSet, Boolean>() {        @Nullable        @Override        public Boolean apply(@Nullable KafkaMessageSet messageSet) {            return predicate.test(messageSet);        }    }).withProvideResult(new Function<KafkaMessageSet, Map<String, List<JSONObject>>>() {        @Nullable        @Override        public Map<String, List<JSONObject>> apply(@Nullable KafkaMessageSet messageSet) {            return new HashMap<String, List<JSONObject>>() {                {                    put(Constants.ENRICHMENT_TOPIC, loadMessages(messageSet.getMessages()));                    put(errorTopic, loadMessages(messageSet.getErrors()));                }            };        }    });}
0
public Boolean apply(@Nullable KafkaMessageSet messageSet)
{    return predicate.test(messageSet);}
0
public Map<String, List<JSONObject>> apply(@Nullable KafkaMessageSet messageSet)
{    return new HashMap<String, List<JSONObject>>() {        {            put(Constants.ENRICHMENT_TOPIC, loadMessages(messageSet.getMessages()));            put(errorTopic, loadMessages(messageSet.getErrors()));        }    };}
0
private static List<JSONObject> loadMessages(List<byte[]> outputMessages)
{    List<JSONObject> tmp = new ArrayList<>();    Iterables.addAll(tmp, Iterables.transform(outputMessages, message -> {        try {            return new JSONObject(JSONUtils.INSTANCE.load(new String(message, StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER));        } catch (Exception ex) {            throw new IllegalStateException(ex);        }    }));    return tmp;}
0
public void commits_kafka_offsets_for_empty_objects() throws Exception
{    final String sensorType = "emptyobjectparser";    SensorParserConfig parserConfig = JSONUtils.INSTANCE.load(offsetParserConfigJSON, SensorParserConfig.class);    final List<byte[]> inputMessages = new ArrayList<byte[]>() {        {            add(Bytes.toBytes("foo"));            add(Bytes.toBytes("bar"));            add(Bytes.toBytes("baz"));        }    };    final Properties topologyProperties = new Properties();    ComponentRunner runner = setupTopologyComponents(topologyProperties, Collections.singletonList(sensorType), Collections.singletonList(parserConfig), globalConfigEmpty);    try {        runner.start();        kafkaComponent.writeMessages(sensorType, inputMessages);        Processor allResultsProcessor = new AllResultsProcessor(inputMessages, Constants.ENRICHMENT_TOPIC);        ProcessorResult<Set<JSONObject>> result = runner.process(allResultsProcessor);                assertThat("size should match", result.getResult().size(), equalTo(inputMessages.size()));        for (JSONObject record : result.getResult()) {            assertThat("record should have a guid", record.containsKey("guid"), equalTo(true));            assertThat("record should have correct source.type", record.get("source.type"), equalTo(sensorType));        }    } finally {        if (runner != null) {            runner.stop();        }    }}
0
public void test_multiple_sensors() throws Exception
{        final String emptyObjectSensorType = "emptyobjectparser";    SensorParserConfig emptyObjectParserConfig = JSONUtils.INSTANCE.load(offsetParserConfigJSON, SensorParserConfig.class);    final List<byte[]> emptyObjectInputMessages = new ArrayList<byte[]>() {        {            add(Bytes.toBytes("foo"));            add(Bytes.toBytes("bar"));            add(Bytes.toBytes("baz"));        }    };        final String dummySensorType = "dummyobjectparser";    SensorParserConfig dummyParserConfig = JSONUtils.INSTANCE.load(dummyParserConfigJSON, SensorParserConfig.class);    final List<byte[]> dummyInputMessages = new ArrayList<byte[]>() {        {            add(Bytes.toBytes("dummy_foo"));            add(Bytes.toBytes("dummy_bar"));            add(Bytes.toBytes("dummy_baz"));        }    };    final Properties topologyProperties = new Properties();    List<String> sensorTypes = new ArrayList<>();    sensorTypes.add(emptyObjectSensorType);    sensorTypes.add(dummySensorType);    List<SensorParserConfig> parserConfigs = new ArrayList<>();    parserConfigs.add(emptyObjectParserConfig);    parserConfigs.add(dummyParserConfig);    ComponentRunner runner = setupTopologyComponents(topologyProperties, sensorTypes, parserConfigs, globalConfigEmpty);    try {        runner.start();        kafkaComponent.writeMessages(emptyObjectSensorType, emptyObjectInputMessages);        kafkaComponent.writeMessages(dummySensorType, dummyInputMessages);        final List<byte[]> allInputMessages = new ArrayList<>();        allInputMessages.addAll(emptyObjectInputMessages);        allInputMessages.addAll(dummyInputMessages);        Processor allResultsProcessor = new AllResultsProcessor(allInputMessages, Constants.ENRICHMENT_TOPIC);        @SuppressWarnings("unchecked")        ProcessorResult<Set<JSONObject>> result = runner.process(allResultsProcessor);                assertThat("size should match", result.getResult().size(), equalTo(allInputMessages.size()));        for (JSONObject record : result.getResult()) {            assertThat("record should have a guid", record.containsKey("guid"), equalTo(true));        }    } finally {        if (runner != null) {            runner.stop();        }    }}
0
public void init()
{}
0
public List<JSONObject> parse(byte[] bytes)
{    return ImmutableList.of(new JSONObject());}
0
public boolean validate(JSONObject message)
{    return true;}
0
public void configure(Map<String, Object> map)
{}
0
public void init()
{}
0
public List<JSONObject> parse(byte[] bytes)
{    JSONObject dummy = new JSONObject();    dummy.put("dummy_key", "dummy_value");    return ImmutableList.of(dummy);}
0
public boolean validate(JSONObject message)
{    return true;}
0
public void configure(Map<String, Object> map)
{}
0
public ReadinessState process(ComponentRunner runner)
{    KafkaComponent kc = runner.getComponent("kafka", KafkaComponent.class);    outputMessages.addAll(readMessagesFromKafka(kc, outputKafkaTopic));    return calcReadiness(inputMessages.size(), outputMessages.size());}
0
private Set<JSONObject> readMessagesFromKafka(KafkaComponent kc, String topic)
{    Set<JSONObject> out = new HashSet<>();    for (byte[] b : kc.readMessages(topic)) {        try {            JSONObject m = new JSONObject(JSONUtils.INSTANCE.load(new String(b, StandardCharsets.UTF_8), JSONUtils.MAP_SUPPLIER));            out.add(m);        } catch (IOException e) {            throw new IllegalStateException(e);        }    }    return out;}
0
private ReadinessState calcReadiness(int in, int out)
{    return in == out ? ReadinessState.READY : ReadinessState.NOT_READY;}
0
public ProcessorResult<Set<JSONObject>> getResult()
{    return new ProcessorResult<>(outputMessages, null);}
0
public Map<String, String> getFixedFields()
{    return PcapOptions.FIELDS.get(this, Map.class);}
0
public void setFixedFields(Map<String, String> fixedFields)
{    PcapOptions.FIELDS.put(this, fixedFields);}
0
public void putFixedField(String key, String value)
{    Map<String, String> fixedFields = PcapOptions.FIELDS.get(this, Map.class);    String trimmedVal = value != null ? value.trim() : null;    if (!isNullOrEmpty(trimmedVal)) {        fixedFields.put(key, value);    }}
0
public Object getOption(ConfigOption option)
{    Object o = get(option.getKey());    return option.transform().apply(option.getKey(), o);}
0
public String getFinalFilenamePrefix()
{    return PcapOptions.FINAL_FILENAME_PREFIX.get(this, String.class);}
0
public void setFinalFilenamePrefix(String prefix)
{    PcapOptions.FINAL_FILENAME_PREFIX.put(this, prefix);}
0
public int getNumReducers()
{    return PcapOptions.NUM_REDUCERS.get(this, Integer.class);}
0
public boolean showHelp()
{    return showHelp;}
0
public void setShowHelp(boolean showHelp)
{    this.showHelp = showHelp;}
0
public boolean printJobStatus()
{    return PcapOptions.PRINT_JOB_STATUS.get(this, Boolean.class);}
0
public void setPrintJobStatus(boolean printJobStatus)
{    PcapOptions.PRINT_JOB_STATUS.put(this, printJobStatus);}
0
public String getBasePath()
{    return PcapOptions.BASE_PATH.get(this, String.class);}
0
public String getBaseInterimResultPath()
{    return PcapOptions.BASE_INTERIM_RESULT_PATH.get(this, String.class);}
0
public long getStartTimeMs()
{    return PcapOptions.START_TIME_MS.get(this, Long.class);}
0
public long getEndTimeMs()
{    return PcapOptions.END_TIME_MS.get(this, Long.class);}
0
public void setBasePath(String basePath)
{    PcapOptions.BASE_PATH.put(this, basePath);}
0
public void setBaseInterimResultPath(String baseOutputPath)
{    PcapOptions.BASE_INTERIM_RESULT_PATH.put(this, baseOutputPath);}
0
public void setStartTimeMs(long startTime)
{    PcapOptions.START_TIME_MS.put(this, startTime);}
0
public void setEndTimeMs(long endTime)
{    PcapOptions.END_TIME_MS.put(this, endTime);}
0
public boolean isNullOrEmpty(String val)
{    return StringUtils.isEmpty(val);}
0
public void setDateFormat(String dateFormat)
{    this.dateFormat = new SimpleDateFormat(dateFormat);}
0
public DateFormat getDateFormat()
{    return dateFormat;}
0
public void setNumReducers(int numReducers)
{    PcapOptions.NUM_REDUCERS.put(this, numReducers);}
0
public int getNumRecordsPerFile()
{    return PcapOptions.NUM_RECORDS_PER_FILE.get(this, Integer.class);}
0
public void setNumRecordsPerFile(int numRecordsPerFile)
{    PcapOptions.NUM_RECORDS_PER_FILE.put(this, numRecordsPerFile);}
0
public void setYarnQueue(String yarnQueue)
{    this.yarnQueue = yarnQueue;}
0
public Optional<String> getYarnQueue()
{    return Optional.ofNullable(yarnQueue);}
0
public void setFinalizerThreadpoolSize(String numThreads)
{    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(this, numThreads);}
0
public String getKey()
{    return key;}
0
public BiFunction<String, Object, Object> transform()
{    return transform;}
0
public String getQuery()
{    return PcapOptions.FIELDS.get(this, String.class);}
0
public void setQuery(String query)
{    PcapOptions.FIELDS.put(this, query);}
0
public void addToConfig(Map<String, String> fields, Configuration conf)
{    for (Map.Entry<String, String> kv : fields.entrySet()) {        conf.set(kv.getKey(), kv.getValue());    }    conf.set(PCAP_FILTER_NAME_CONF, PcapFilters.FIXED.name());}
0
public String queryToString(Map<String, String> fields)
{    return (fields == null ? "" : Joiner.on("_").join(fields.values()).replaceAll("\\s", "_"));}
0
public void configure(Iterable<Map.Entry<String, String>> config)
{    for (Map.Entry<String, String> kv : config) {        if (kv.getKey().equals(Constants.Fields.DST_ADDR.getName())) {            System.out.println("Processing: " + kv.getKey() + " => " + kv.getValue());            this.dstAddr = kv.getValue();            doHeaderFiltering = true;        }        if (kv.getKey().equals(Constants.Fields.SRC_ADDR.getName())) {            System.out.println("Processing: " + kv.getKey() + " => " + kv.getValue());            this.srcAddr = kv.getValue();            doHeaderFiltering = true;        }        if (kv.getKey().equals(Constants.Fields.DST_PORT.getName())) {            System.out.println("Processing: " + kv.getKey() + " => " + kv.getValue());            this.dstPort = Integer.parseInt(kv.getValue());            doHeaderFiltering = true;        }        if (kv.getKey().equals(Constants.Fields.SRC_PORT.getName())) {            System.out.println("Processing: " + kv.getKey() + " => " + kv.getValue());            this.srcPort = Integer.parseInt(kv.getValue());            doHeaderFiltering = true;        }        if (kv.getKey().equals(Constants.Fields.PROTOCOL.getName())) {            System.out.println("Processing: " + kv.getKey() + " => " + kv.getValue());            this.protocol = kv.getValue();            doHeaderFiltering = true;        }        if (kv.getKey().equals(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName())) {            System.out.println("Processing: " + kv.getKey() + " => " + kv.getValue());            this.includesReverseTraffic = Boolean.parseBoolean(kv.getValue());        }        if (kv.getKey().equals(PcapHelper.PacketFields.PACKET_FILTER.getName())) {            System.out.println("Processing: " + kv.getKey() + " => " + kv.getValue());            this.packetFilter = kv.getValue();        }    }}
0
public boolean test(PacketInfo pi)
{    Map<String, Object> fields = packetToFields(pi);    VariableResolver resolver = new MapVariableResolver(fields);    String srcAddrIn = (String) resolver.resolve(Constants.Fields.SRC_ADDR.getName());    Integer srcPortIn = (Integer) resolver.resolve(Constants.Fields.SRC_PORT.getName());    String dstAddrIn = (String) resolver.resolve(Constants.Fields.DST_ADDR.getName());    Integer dstPortIn = (Integer) resolver.resolve(Constants.Fields.DST_PORT.getName());    String protocolIn = "" + resolver.resolve(Constants.Fields.PROTOCOL.getName());    if (!doHeaderFiltering || testHeader(srcAddrIn, srcPortIn, dstAddrIn, dstPortIn, protocolIn)) {                if (packetFilter != null) {                        byte[] data = (byte[]) resolver.resolve(PcapHelper.PacketFields.PACKET_DATA.getName());            try {                return ByteArrayMatchingUtil.INSTANCE.match(packetFilter, data);            } catch (ExecutionException e) {                throw new IllegalStateException("Unable to perform binary filter: " + packetFilter + " on " + DatatypeConverter.printHexBinary(data), e);            }        } else if (!doHeaderFiltering) {                        return true;        } else {                        return true;        }    } else {                return false;    }}
0
private boolean testHeader(String srcAddrIn, Integer srcPortIn, String dstAddrIn, Integer dstPortIn, String protocolIn)
{    if (areMatch(protocol, protocolIn)) {        if (matchesSourceAndDestination(srcAddrIn, srcPortIn, dstAddrIn, dstPortIn)) {            return true;        } else if (includesReverseTraffic) {            return matchesReverseSourceAndDestination(srcAddrIn, srcPortIn, dstAddrIn, dstPortIn);        }    }    return false;}
0
private boolean areMatch(Integer filter, Integer input)
{    return filter == null || areMatch(Integer.toUnsignedString(filter), input == null ? null : Integer.toUnsignedString(input));}
0
private boolean areMatch(String filter, String input)
{    if (filter != null) {        return input != null && input.equals(filter);    } else {        return true;    }}
0
protected Map<String, Object> packetToFields(PacketInfo pi)
{    return PcapHelper.packetToFields(pi);}
0
private boolean matchesSourceAndDestination(String srcAddrComp, Integer srcPortComp, String dstAddrComp, Integer dstPortComp)
{    boolean isMatch = true;    isMatch &= areMatch(this.srcAddr, srcAddrComp);    isMatch &= areMatch(this.srcPort, srcPortComp);    isMatch &= areMatch(this.dstAddr, dstAddrComp);    isMatch &= areMatch(this.dstPort, dstPortComp);    return isMatch;}
0
private boolean matchesReverseSourceAndDestination(String srcAddr, Integer srcPort, String dstAddr, Integer dstPort)
{    return matchesSourceAndDestination(dstAddr, dstPort, srcAddr, srcPort);}
0
public Object resolve(String variable)
{    if (variable.equals(VariableResolver.ALL_FIELDS)) {        return new ConcatMap(ImmutableList.of(fieldsMap));    }    return fieldsMap.get(variable);}
0
public boolean exists(String variable)
{    return fieldsMap.containsKey(variable);}
0
public PcapFilter create()
{    return creator.create();}
0
public PcapFilter create()
{    return new FixedPcapFilter();}
0
public PcapFilter create()
{    return new QueryPcapFilter();}
0
public void addToConfig(String query, Configuration conf)
{    conf.set(QUERY_STR_CONFIG, query);    conf.set(PCAP_FILTER_NAME_CONF, PcapFilters.QUERY.name());}
0
public String queryToString(String fields)
{    return (fields == null ? "" : fields.trim().replaceAll("\\s", "_"));}
0
public void configure(Iterable<Map.Entry<String, String>> config)
{    for (Map.Entry<String, String> entry : config) {        if (entry.getKey().equals(QUERY_STR_CONFIG)) {            queryString = entry.getValue();        }    }    predicateProcessor.validate(queryString);}
0
public boolean test(PacketInfo input)
{    Map<String, Object> fields = packetToFields(input);    VariableResolver resolver = new MapVariableResolver(fields);    return predicateProcessor.parse(queryString, resolver, StellarFunctions.FUNCTION_RESOLVER(), Context.EMPTY_CONTEXT());}
0
protected Map<String, Object> packetToFields(PacketInfo pi)
{    return PcapHelper.packetToFields(pi);}
0
protected void write(PcapResultsWriter resultsWriter, Configuration hadoopConfig, List<byte[]> data, Path outputPath) throws IOException
{    resultsWriter.writeLocal(data, outputPath.toString());}
0
protected Path getOutputPath(Map<String, Object> config, int partition)
{    Path finalOutputPath = PcapOptions.FINAL_OUTPUT_PATH.get(config, PcapOptions.STRING_TO_PATH, Path.class);    String prefix = PcapOptions.FINAL_FILENAME_PREFIX.get(config, String.class);    return new Path(String.format(PCAP_CLI_FILENAME_FORMAT, finalOutputPath, prefix, partition));}
0
protected PcapResultsWriter getResultsWriter()
{    return resultsWriter;}
0
public Pageable<Path> finalizeJob(Map<String, Object> config) throws JobException
{    Configuration hadoopConfig = PcapOptions.HADOOP_CONF.get(config, Configuration.class);    int recPerFile = PcapOptions.NUM_RECORDS_PER_FILE.getOrDefault(config, Integer.class, NUM_RECORDS_PER_FILE_DEFAULT);    Path interimResultPath = PcapOptions.INTERIM_RESULT_PATH.get(config, PcapOptions.STRING_TO_PATH, Path.class);    FileSystem fs = PcapOptions.FILESYSTEM.get(config, FileSystem.class);    int parallelism = getNumThreads(PcapOptions.FINALIZER_THREADPOOL_SIZE.get(config, String.class));        SequenceFileIterable interimResults = null;    try {        interimResults = readInterimResults(interimResultPath, hadoopConfig, fs);    } catch (IOException e) {        throw new JobException("Unable to read interim job results while finalizing", e);    }    List<Path> outFiles = new ArrayList<>();    try {        Iterable<List<byte[]>> partitions = Iterables.partition(interimResults, recPerFile);        Map<Path, List<byte[]>> toWrite = new HashMap<>();        int part = 1;        if (partitions.iterator().hasNext()) {            for (List<byte[]> data : partitions) {                Path outputPath = getOutputPath(config, part++);                toWrite.put(outputPath, data);            }            outFiles = writeParallel(hadoopConfig, toWrite, parallelism);        } else {                    }    } catch (IOException e) {        throw new JobException("Failed to finalize results", e);    } finally {        try {            interimResults.cleanup();        } catch (IOException e) {                    }    }        return new PcapPages(outFiles);}
1
private static int getNumThreads(String numThreads) throws JobException
{    String numThreadsStr = ((String) numThreads).trim().toUpperCase();    try {        if (numThreadsStr.endsWith("C")) {            Integer factor = Integer.parseInt(numThreadsStr.replace("C", ""));            return factor * Runtime.getRuntime().availableProcessors();        } else {            return Integer.parseInt(numThreadsStr);        }    } catch (NumberFormatException e) {        throw new JobException(format("Unable to set number of threads for finalizing from property value '%s'", numThreads));    }}
0
protected List<Path> writeParallel(Configuration hadoopConfig, Map<Path, List<byte[]>> toWrite, int parallelism) throws IOException
{    List<Path> outFiles = Collections.synchronizedList(new ArrayList<>());    ForkJoinPool tp = new ForkJoinPool(parallelism);    try {        tp.submit(() -> {            toWrite.entrySet().parallelStream().forEach(e -> {                Path path = e.getKey();                List<byte[]> data = e.getValue();                if (data.size() > 0) {                    try {                        write(getResultsWriter(), hadoopConfig, data, path);                    } catch (IOException ioe) {                        throw new RuntimeException(String.format("Failed to write results to path '%s'", path.toString()), ioe);                    }                    outFiles.add(path);                }            });        }).get();    } catch (InterruptedException | ExecutionException e) {        throw new IOException("Error finalizing results.", e);    } catch (RuntimeException e) {        throw new IOException(e.getMessage(), e.getCause());    }    outFiles.sort((o1, o2) -> o1.getName().compareTo(o2.getName()));    return outFiles;}
0
protected SequenceFileIterable readInterimResults(Path interimResultPath, Configuration config, FileSystem fs) throws IOException
{    List<Path> files = new ArrayList<>();    for (RemoteIterator<LocatedFileStatus> it = fs.listFiles(interimResultPath, false); it.hasNext(); ) {        Path p = it.next().getPath();        if (p.getName().equals("_SUCCESS")) {            fs.delete(p, false);            continue;        }        files.add(p);    }    if (files.size() == 0) {            } else {                Collections.sort(files, (o1, o2) -> o1.getName().compareTo(o2.getName()));    }    return new SequenceFileIterable(files, config);}
1
public Pageable<Path> finalizeJob(Map<String, Object> config) throws JobException
{    return finalizer.finalizeJob(config);}
0
protected void write(PcapResultsWriter resultsWriter, Configuration hadoopConfig, List<byte[]> data, Path outputPath) throws IOException
{    resultsWriter.write(hadoopConfig, data, outputPath.toString());}
0
protected Path getOutputPath(Map<String, Object> config, int partition)
{    String finalOutputPath = PcapOptions.FINAL_OUTPUT_PATH.getOrDefault(config, String.class, FINAL_OUTPUT_PATH_DEFAULT);    String user = PcapOptions.USERNAME.get(config, String.class);    String jobId = PcapOptions.JOB_ID.get(config, String.class);    return new Path(String.format(PCAP_REST_FILEPATH_FORMAT, finalOutputPath, user, jobType, jobId, partition));}
0
public int getPriorityCodePoint()
{    return priorityCodePoint;}
0
public int getDropEligibleIndicator()
{    return dropEligibleIndicator;}
0
public int getvLANIdentifier()
{    return vLANIdentifier;}
0
public void register(EthernetProcessor processor)
{    this.callbacks.add(processor);}
0
public void register(int type, EthernetProcessor processor)
{    Set<EthernetProcessor> processors = typeCallbacks.get(type);    if (processors == null) {        processors = new HashSet<EthernetProcessor>();        typeCallbacks.put(type, processors);    }    processors.add(processor);}
0
public void unregister(EthernetProcessor processor)
{    this.callbacks.remove(processor);}
0
public void unregister(int type, EthernetProcessor processor)
{    Set<EthernetProcessor> processors = typeCallbacks.get(type);    if (processors == null)        return;    processors.remove(processor);}
0
public void decode(PcapPacket packet)
{        MacAddress destination = getMacAddress(packet.getPacketData());    MacAddress source = getMacAddress(packet.getPacketData());    int type = getEtherType(packet.getPacketData());    if (type == 0x8100) {                IEEE_802_1Q iee802_1qTag = get802_1qTag(packet.getPacketData());                type = getEtherType(packet.getPacketData());    }    Buffer buffer = packet.getPacketData();    buffer.discardReadBytes();    EthernetFrame frame = new EthernetFrame(source, destination, type, buffer);    frame.setPcapPacket(packet);    dispatch(frame);}
0
private MacAddress getMacAddress(Buffer data)
{    byte[] mac = new byte[6];    data.gets(mac, 0, 6);    return new MacAddress(mac);}
0
private int getEtherType(Buffer data)
{    return ((int) data.getShort()) & 0x0000FFFF;}
0
private IEEE_802_1Q get802_1qTag(Buffer data)
{            byte[] b802_1qTag = new byte[2];    data.gets(b802_1qTag, 0, 2);    BitSet bits = BitSet.valueOf(b802_1qTag);    int pcp = convertBitToInt(bits.get(0, 3));    int dei = convertBitToInt(bits.get(3, 4));    int vid = convertBitToInt(bits.get(4, 16));    return new IEEE_802_1Q(pcp, dei, vid);}
0
public static int convertBitToInt(BitSet bits)
{    int value = 0;    for (int i = 0; i < bits.length(); ++i) {        value += bits.get(i) ? (1 << i) : 0;    }    return value;}
0
private void dispatch(EthernetFrame frame)
{    for (EthernetProcessor processor : callbacks) processor.process(frame);    Set<EthernetProcessor> processors = typeCallbacks.get(frame.getType());    if (processors == null)        return;    for (EthernetProcessor processor : processors) processor.process(frame.dup());}
0
public String format(long beginNS, long endNS, String query)
{    return sanitize(Joiner.on("_").join(beginNS, endNS, query, UUID.randomUUID().toString()));}
0
private String sanitize(String path)
{    return path.replace(".", "-").replace("'", "").replace(":", "");}
0
public int getPartition(LongWritable longWritable, BytesWritable bytesWritable, int numPartitions)
{    if (start == null) {        initialize();    }    long x = longWritable.get();    int ret = (int) Long.divideUnsigned(x - start, width);    if (ret > numPartitions) {        throw new IllegalArgumentException(String.format("Bad partition: key=%s, width=%d, partition=%d, numPartitions=%d", Long.toUnsignedString(x), width, ret, numPartitions));    }    return ret;}
0
private void initialize()
{    start = Long.parseUnsignedLong(configuration.get(START_TS_CONF));    end = Long.parseUnsignedLong(configuration.get(END_TS_CONF));    width = Long.parseLong(configuration.get(WIDTH_CONF));}
0
public void setConf(Configuration conf)
{    this.configuration = conf;}
0
public Configuration getConf()
{    return configuration;}
0
protected void setup(Context context) throws IOException, InterruptedException
{    super.setup(context);    filter = PcapFilters.valueOf(context.getConfiguration().get(PcapFilterConfigurator.PCAP_FILTER_NAME_CONF)).create();    filter.configure(context.getConfiguration());    start = Long.parseUnsignedLong(context.getConfiguration().get(START_TS_CONF));    end = Long.parseUnsignedLong(context.getConfiguration().get(END_TS_CONF));}
0
protected void map(LongWritable key, BytesWritable value, Context context) throws IOException, InterruptedException
{    if (greaterThanOrEqualTo(key.get(), start) && lessThanOrEqualTo(key.get(), end)) {                                        List<PacketInfo> packetInfos;        try {            packetInfos = PcapHelper.toPacketInfo(value.copyBytes());        } catch (Exception e) {                        context.getCounter(PCAP_COUNTER.MALFORMED_PACKET_COUNT).increment(1);            return;        }        boolean send = filteredPacketInfo(packetInfos).findAny().isPresent();        if (send) {            context.write(key, value);        }    }}
0
private Stream<PacketInfo> filteredPacketInfo(List<PacketInfo> packetInfos) throws IOException
{    return packetInfos.stream().filter(filter);}
0
protected void reduce(LongWritable key, Iterable<BytesWritable> values, Context context) throws IOException, InterruptedException
{    for (BytesWritable value : values) {        context.write(key, value);    }}
0
public void setStatusInterval(long interval)
{    statusInterval = interval;}
0
public void setCompleteCheckInterval(long interval)
{    completeCheckInterval = interval;}
0
public Statusable<Path> submit(Finalizer<Path> finalizer, Map<String, Object> config) throws JobException
{    this.finalizer = finalizer;    this.configuration = config;    Optional<String> jobName = Optional.ofNullable(PcapOptions.JOB_NAME.get(configuration, String.class));    Configuration hadoopConf = PcapOptions.HADOOP_CONF.get(configuration, Configuration.class);    FileSystem fileSystem = PcapOptions.FILESYSTEM.get(configuration, FileSystem.class);    Path basePath = PcapOptions.BASE_PATH.getTransformed(configuration, Path.class);    Path baseInterimResultPath = PcapOptions.BASE_INTERIM_RESULT_PATH.getTransformedOrDefault(configuration, Path.class, new Path(PcapGlobalDefaults.BASE_INTERIM_RESULT_PATH_DEFAULT));    long startTimeNs;    if (configuration.containsKey(PcapOptions.START_TIME_NS.getKey())) {        startTimeNs = PcapOptions.START_TIME_NS.getOrDefault(configuration, Long.class, 0L);    } else {        startTimeNs = TimestampConverters.MILLISECONDS.toNanoseconds(PcapOptions.START_TIME_MS.getOrDefault(configuration, Long.class, 0L));    }    long endTimeNs;    if (configuration.containsKey(PcapOptions.END_TIME_NS.getKey())) {        endTimeNs = PcapOptions.END_TIME_NS.getOrDefault(configuration, Long.class, TimestampConverters.MILLISECONDS.toNanoseconds(System.currentTimeMillis()));    } else {        endTimeNs = TimestampConverters.MILLISECONDS.toNanoseconds(PcapOptions.END_TIME_MS.getOrDefault(configuration, Long.class, System.currentTimeMillis()));    }    int numReducers = PcapOptions.NUM_REDUCERS.getOrDefault(configuration, Integer.class, NUM_REDUCERS_DEFAULT);    T fields = (T) PcapOptions.FIELDS.get(configuration, Object.class);    PcapFilterConfigurator<T> filterImpl = PcapOptions.FILTER_IMPL.get(configuration, PcapFilterConfigurator.class);    try {        Statusable<Path> statusable = query(jobName, basePath, baseInterimResultPath, startTimeNs, endTimeNs, numReducers, fields,         new Configuration(hadoopConf), fileSystem, filterImpl);        PcapOptions.JOB_ID.put(configuration, statusable.getStatus().getJobId());        return statusable;    } catch (IOException | InterruptedException | ClassNotFoundException e) {        throw new JobException("Failed to run pcap query.", e);    }}
0
public Statusable<Path> query(Optional<String> jobName, Path basePath, Path baseInterimResultPath, long beginNS, long endNS, int numReducers, T fields, Configuration conf, FileSystem fs, PcapFilterConfigurator<T> filterImpl) throws IOException, ClassNotFoundException, InterruptedException
{    String outputDirName = outputDirFormatter.format(beginNS, endNS, filterImpl.queryToString(fields));    if (LOG.isDebugEnabled()) {        DateFormat format = SimpleDateFormat.getDateTimeInstance(SimpleDateFormat.LONG, SimpleDateFormat.LONG);        String from = format.format(new Date(Long.divideUnsigned(beginNS, 1000000)));        String to = format.format(new Date(Long.divideUnsigned(endNS, 1000000)));            }    Path interimResultPath = new Path(baseInterimResultPath, outputDirName);    PcapOptions.INTERIM_RESULT_PATH.put(configuration, interimResultPath);    mrJob = createJob(jobName, basePath, interimResultPath, beginNS, endNS, numReducers, fields, conf, fs, filterImpl);    if (mrJob == null) {                try {            setFinalResults(input -> new PcapPages(), configuration);            jobStatus.withState(State.SUCCEEDED).withDescription("No results in specified date range.").withPercentComplete(100.0);        } catch (JobException e) {                        jobStatus.withState(State.FAILED).withDescription("Unable to finalize empty job.").withFailureException(e);        }        return this;    }    synchronized (this) {                                        mrJob.submit();        jobStatus.withState(State.SUBMITTED).withDescription("Job submitted").withJobId(mrJob.getJobID().toString());    }    startJobStatusTimerThread(statusInterval);    return this;}
1
private void startJobStatusTimerThread(long interval)
{    getTimer().scheduleAtFixedRate(new TimerTask() {        @Override        public void run() {            if (!updateStatus()) {                                cancel();            }        }    }, interval, interval);}
0
public void run()
{    if (!updateStatus()) {                cancel();    }}
0
public void setTimer(Timer timer)
{    this.timer = timer;}
0
private Timer getTimer()
{    return timer;}
0
private boolean updateStatus()
{    JobStatus tempStatus = null;        final float mrJobFraction = 0.75f;    synchronized (this) {        tempStatus = new JobStatus(jobStatus);    }    boolean keepUpdating = true;    try {        boolean mrJobComplete = false;        org.apache.hadoop.mapreduce.JobStatus.State mrJobState = null;        String mrJobFailureInfo = null;        float mapProg = 0.0f;        float reduceProg = 0.0f;        synchronized (this) {            mrJobComplete = mrJob.isComplete();            org.apache.hadoop.mapreduce.JobStatus mrJobStatus = mrJob.getStatus();            mrJobState = mrJobStatus.getState();            mrJobFailureInfo = mrJobStatus.getFailureInfo();            mapProg = mrJob.mapProgress();            reduceProg = mrJob.reduceProgress();        }        if (mrJobComplete) {            switch(mrJobState) {                case SUCCEEDED:                    tempStatus.withPercentComplete(100.0 * mrJobFraction).withState(State.FINALIZING).withDescription("Finalizing job.");                    try {                        synchronized (this) {                                                        jobStatus = new JobStatus(tempStatus);                        }                        setFinalResults(finalizer, configuration);                        tempStatus.withPercentComplete(100.0).withState(State.SUCCEEDED).withDescription("Job completed.");                    } catch (JobException je) {                        tempStatus.withPercentComplete(100.0).withState(State.FAILED).withDescription("Job finalize failed.").withFailureException(je);                    }                    break;                case FAILED:                    tempStatus.withPercentComplete(100.0).withState(State.FAILED).withDescription(mrJobFailureInfo);                    break;                case KILLED:                    tempStatus.withPercentComplete(100.0).withState(State.KILLED).withDescription(mrJobFailureInfo);                    break;            }            keepUpdating = false;        } else {            float mrJobProgress = ((mapProg / 2) + (reduceProg / 2)) * 100;            float totalProgress = mrJobProgress * mrJobFraction;            String description = String.format("map: %s%%, reduce: %s%%", mapProg * 100, reduceProg * 100);            tempStatus.withPercentComplete(totalProgress).withState(State.RUNNING).withDescription(description);        }    } catch (InterruptedException | IOException e) {        tempStatus.withPercentComplete(100.0).withState(State.FAILED).withFailureException(e);        keepUpdating = false;    }    synchronized (this) {        jobStatus = new JobStatus(tempStatus);    }    return keepUpdating;}
0
private void setFinalResults(Finalizer<Path> finalizer, Map<String, Object> configuration) throws JobException
{    Pageable<Path> results = finalizer.finalizeJob(configuration);    if (results == null) {        results = new PcapPages();    }    synchronized (this) {        finalResults = results;    }}
0
public Job createJob(Optional<String> jobName, Path basePath, Path jobOutputPath, long beginNS, long endNS, int numReducers, T fields, Configuration conf, FileSystem fs, PcapFilterConfigurator<T> filterImpl) throws IOException
{    Iterable<String> filteredPaths = FileFilterUtil.getPathsInTimeRange(beginNS, endNS, listFiles(fs, basePath));    String inputPaths = Joiner.on(',').join(filteredPaths);    if (StringUtils.isEmpty(inputPaths)) {        return null;    }    conf.set(START_TS_CONF, Long.toUnsignedString(beginNS));    conf.set(END_TS_CONF, Long.toUnsignedString(endNS));    conf.set(WIDTH_CONF, "" + findWidth(beginNS, endNS, numReducers));    filterImpl.addToConfig(fields, conf);    Job job = Job.getInstance(conf);    jobName.ifPresent(job::setJobName);    job.setJarByClass(PcapJob.class);    job.setMapperClass(PcapJob.PcapMapper.class);    job.setMapOutputKeyClass(LongWritable.class);    job.setMapOutputValueClass(BytesWritable.class);    job.setNumReduceTasks(numReducers);    job.setReducerClass(PcapReducer.class);    job.setPartitionerClass(PcapPartitioner.class);    job.setOutputKeyClass(LongWritable.class);    job.setOutputValueClass(BytesWritable.class);    SequenceFileInputFormat.addInputPaths(job, inputPaths);    job.setInputFormatClass(SequenceFileInputFormat.class);    job.setOutputFormatClass(SequenceFileOutputFormat.class);    SequenceFileOutputFormat.setOutputPath(job, jobOutputPath);    return job;}
0
public static long findWidth(long start, long end, int numReducers)
{    return Long.divideUnsigned(end - start, numReducers) + 1;}
0
protected Iterable<Path> listFiles(FileSystem fs, Path basePath) throws IOException
{    List<Path> ret = new ArrayList<>();    RemoteIterator<LocatedFileStatus> filesIt = fs.listFiles(basePath, true);    while (filesIt.hasNext()) {        ret.add(filesIt.next().getPath());    }    return ret;}
0
public JobType getJobType()
{    return JobType.MAP_REDUCE;}
0
public synchronized JobStatus getStatus() throws JobException
{    return new JobStatus(jobStatus);}
0
protected void setJobStatus(JobStatus jobStatus)
{    this.jobStatus = jobStatus;}
0
protected void setMrJob(Job mrJob)
{    this.mrJob = mrJob;}
0
public Pageable<Path> get() throws JobException, InterruptedException
{    if (PcapOptions.PRINT_JOB_STATUS.getOrDefault(configuration, Boolean.class, false) && mrJob != null) {        try {            mrJob.monitorAndPrintJob();        } catch (IOException e) {            throw new JobException("Could not monitor job status", e);        }    }    for (; ; ) {        JobStatus status = getStatus();        if (status.getState() == State.SUCCEEDED || status.getState() == State.KILLED || status.getState() == State.FAILED) {            return getFinalResults();        } else {                    }        Thread.sleep(completeCheckInterval);    }}
1
private synchronized Pageable<Path> getFinalResults()
{    return new PcapPages(finalResults);}
0
public boolean isDone()
{    State jobState = null;    synchronized (this) {        jobState = jobStatus.getState();    }    return (jobState == State.SUCCEEDED || jobState == State.KILLED || jobState == State.FAILED);}
0
public void kill() throws JobException
{    try {        synchronized (this) {            mrJob.killJob();        }    } catch (IOException e) {        throw new JobException("Unable to kill pcap job.", e);    }}
0
public boolean validate(Map<String, Object> configuration)
{        return true;}
0
public Map<String, Object> getConfiguration()
{    return new HashMap<>(this.configuration);}
0
protected void setConfiguration(Map<String, Object> configuration)
{    this.configuration = configuration;}
0
public GlobalHeader getGlobalHeader()
{    return globalHeader;}
0
public byte[] getPacketBytes()
{    return packetBytes;}
0
public PacketHeader getPacketHeader()
{    return packetHeader;}
0
public PcapPacket getPacket()
{    return packet;}
0
public Ipv4Packet getIpv4Packet()
{    return ipv4Packet;}
0
public TcpPacket getTcpPacket()
{    return tcpPacket;}
0
public UdpPacket getUdpPacket()
{    return udpPacket;}
0
public String getKey()
{    int sourcePort = 0;    int destinationPort = 0;    if (Constants.PROTOCOL_UDP == ipv4Packet.getProtocol()) {        sourcePort = udpPacket.getSourcePort();        destinationPort = udpPacket.getDestinationPort();    } else if (Constants.PROTOCOL_TCP == ipv4Packet.getProtocol()) {        sourcePort = tcpPacket.getSourcePort();        destinationPort = tcpPacket.getDestinationPort();    }    return PcapUtils.getSessionKey(ipv4Packet.getSourceAddress().getHostAddress(), ipv4Packet.getDestinationAddress().getHostAddress(), ipv4Packet.getProtocol(), sourcePort, destinationPort, ipv4Packet.getId(), ipv4Packet.getFragmentOffset());}
0
public String getShortKey()
{    int sourcePort = 0;    int destinationPort = 0;    if (Constants.PROTOCOL_UDP == ipv4Packet.getProtocol()) {        sourcePort = udpPacket.getSourcePort();        destinationPort = udpPacket.getDestinationPort();    } else if (Constants.PROTOCOL_TCP == ipv4Packet.getProtocol()) {        sourcePort = tcpPacket.getSourcePort();        destinationPort = tcpPacket.getDestinationPort();    }    return PcapUtils.getShortSessionKey(ipv4Packet.getSourceAddress().getHostAddress(), ipv4Packet.getDestinationAddress().getHostAddress(), ipv4Packet.getProtocol(), sourcePort, destinationPort);}
0
public String getJsonDoc()
{    return getJsonDocUsingSBAppend();}
0
public String getJsonIndexDoc()
{    return getJsonIndexDocUsingSBAppend();}
0
private String getJsonDocUsingSBAppend()
{    StringBuffer jsonSb = new StringBuffer(1024);        jsonSb.append("{\"global_header\":{\"pcap_id\":\"").append(getKey());    jsonSb.append("\",\"inc_len\":").append(packetHeader.getInclLen());    jsonSb.append(",\"orig_len\":").append(packetHeader.getOrigLen());    jsonSb.append(",\"ts_sec\":").append(packetHeader.getTsSec());    jsonSb.append(",\"ts_usec\":").append(packetHeader.getTsUsec());        jsonSb.append("},");        jsonSb.append("\"ipv4_header\":{");    jsonSb.append("\"ip_dst\":").append(ipv4Packet.getDestination());    jsonSb.append(",\"ip_dst_addr\":\"").append(ipv4Packet.getDestinationAddress().getHostAddress());    jsonSb.append("\",\"ip_flags\":").append(ipv4Packet.getFlags());    jsonSb.append(",\"ip_fragment_offset\":").append(ipv4Packet.getFragmentOffset());    jsonSb.append(",\"ip_header_checksum\":").append(ipv4Packet.getHeaderChecksum());    jsonSb.append(",\"ip_id\":").append(ipv4Packet.getId());    jsonSb.append(",\"ip_header_length\":").append(ipv4Packet.getIhl());    jsonSb.append(",\"ip_protocol\":").append(ipv4Packet.getProtocol());    jsonSb.append(",\"ip_src\":").append(ipv4Packet.getSource());    jsonSb.append(",\"ip_src_addr\":\"").append(ipv4Packet.getSourceAddress().getHostAddress());    jsonSb.append("\",\"ip_tos\":").append(ipv4Packet.getTos());    jsonSb.append(",\"ip_total_length\":").append(ipv4Packet.getTotalLength());    jsonSb.append(",\"ip_ttl\":").append(ipv4Packet.getTtl());    jsonSb.append(",\"ip_version\":").append(ipv4Packet.getVersion());    jsonSb.append('}');        if (tcpPacket != null) {        jsonSb.append(",\"tcp_header\":{\"ack\":").append(tcpPacket.getAck());        jsonSb.append(",\"checksum\":").append(tcpPacket.getChecksum());        jsonSb.append(",\"data_length\":").append(tcpPacket.getDataLength());        jsonSb.append(",\"data_offset\":").append(tcpPacket.getDataOffset());        jsonSb.append(",\"dst_addr\":\"").append(tcpPacket.getDestinationAddress().getHostAddress());        jsonSb.append("\",\"dst_port\":").append(tcpPacket.getDestinationPort());        jsonSb.append(",\"direction\":").append(tcpPacket.getDirection());        jsonSb.append(",\"flags\":").append(tcpPacket.getFlags());        jsonSb.append(",\"reassembled_length \":").append(tcpPacket.getReassembledLength());        jsonSb.append(",\"relative_ack\":").append(tcpPacket.getRelativeAck());        jsonSb.append(",\"relative_seq\":").append(tcpPacket.getRelativeSeq());        jsonSb.append(",\"seq\":").append(tcpPacket.getSeq());        jsonSb.append(",\"session_key\":\"").append(tcpPacket.getSessionKey());        jsonSb.append("\",\"src_addr\":\"").append(tcpPacket.getSourceAddress().getHostAddress());        jsonSb.append("\",\"src_port\":").append(tcpPacket.getSourcePort());        jsonSb.append(",\"total_length\":").append(tcpPacket.getTotalLength());        jsonSb.append(",\"urgent_pointer\":").append(tcpPacket.getUrgentPointer());        jsonSb.append(",\"window\":").append(tcpPacket.getWindow());        jsonSb.append('}');    }        if (udpPacket != null) {        jsonSb.append(",\"udp_header\":{\"checksum\":").append(udpPacket.getChecksum());        jsonSb.append(",\"dst_port\":").append(udpPacket.getDestinationPort());        jsonSb.append(",\"length\":").append(udpPacket.getLength());        jsonSb.append(",\"src_port\":").append(udpPacket.getSourcePort());        jsonSb.append(",\"dst_addr\":\"").append(udpPacket.getDestination().getAddress().getHostAddress());        jsonSb.append("\",\"src_addr\":\"").append(udpPacket.getSource().getAddress().getHostAddress());        jsonSb.append("\"}");    }    jsonSb.append('}');    return jsonSb.toString();}
0
private String getJsonDocUsingMessageFormat()
{    StringBuffer jsonSb = new StringBuffer(600);    jsonSb.append(MessageFormat.format(globalHeaderJsonTemplateString, getKey(), packetHeader.getInclLen(), packetHeader.getOrigLen(), packetHeader.getTsSec(), packetHeader.getTsUsec()));    jsonSb.append(MessageFormat.format(ipv4HeaderJsonTemplateString, ipv4Packet.getDestination(), ipv4Packet.getDestinationAddress().getHostAddress(), ipv4Packet.getFlags(), ipv4Packet.getFragmentOffset(), ipv4Packet.getHeaderChecksum(), ipv4Packet.getId(), ipv4Packet.getIhl(), ipv4Packet.getProtocol(), ipv4Packet.getSource(), ipv4Packet.getSourceAddress().getHostAddress(), ipv4Packet.getTos(), ipv4Packet.getTotalLength(), ipv4Packet.getTtl(), ipv4Packet.getVersion()));        if (tcpPacket != null) {        jsonSb.append(MessageFormat.format(tcpHeaderJsonTemplateString, tcpPacket.getAck(), tcpPacket.getChecksum(), tcpPacket.getDataLength(), tcpPacket.getDataOffset(), tcpPacket.getDestinationAddress().getHostAddress(), tcpPacket.getDestinationPort(), tcpPacket.getDirection(), tcpPacket.getFlags(), tcpPacket.getReassembledLength(), tcpPacket.getRelativeAck(), tcpPacket.getRelativeSeq(), tcpPacket.getSeq(), tcpPacket.getSessionKey(), tcpPacket.getSourceAddress().getHostAddress(), tcpPacket.getSourcePort(), tcpPacket.getTotalLength(), tcpPacket.getUrgentPointer(), tcpPacket.getWindow()));    } else     if (udpPacket != null) {        jsonSb.append(MessageFormat.format(udpHeaderJsonTemplateString, udpPacket.getChecksum(), udpPacket.getDestinationPort(), udpPacket.getLength(), udpPacket.getSourcePort(), udpPacket.getDestination().getAddress().getHostAddress(), udpPacket.getSource().getAddress().getHostAddress()));    } else {        jsonSb.append('}');    }    return jsonSb.toString().replace('<', '{').replace('>', '}');}
0
private String getJsonIndexDocUsingSBAppend()
{    Long ts_micro = getPacketTimeInNanos() / 1000L;    StringBuffer jsonSb = new StringBuffer(175);    jsonSb.append("{\"pcap_id\":\"").append(getShortKey());    jsonSb.append("\",\"ip_protocol\":").append(ipv4Packet.getProtocol());    jsonSb.append(",\"ip_id\":").append(ipv4Packet.getId());    jsonSb.append(",\"frag_offset\":").append(ipv4Packet.getFragmentOffset());    jsonSb.append(",\"ts_micro\":").append(ts_micro);        if (tcpPacket != null) {        jsonSb.append(",\"ip_src_addr\":\"").append(tcpPacket.getSourceAddress().getHostAddress());        jsonSb.append("\",\"ip_src_port\":").append(tcpPacket.getSourcePort());        jsonSb.append(",\"ip_dst_addr\":\"").append(tcpPacket.getDestinationAddress().getHostAddress());        jsonSb.append("\",\"ip_dst_port\":").append(tcpPacket.getDestinationPort());    }        if (udpPacket != null) {        jsonSb.append(",\"ip_src_addr\":\"").append(udpPacket.getSource().getAddress().getHostAddress());        jsonSb.append("\",\"ip_src_port\":").append(udpPacket.getSourcePort());        jsonSb.append(",\"ip_dst_addr\":\"").append(udpPacket.getDestination().getAddress().getHostAddress());        jsonSb.append("\",\"ip_dst_port\":").append(udpPacket.getDestinationPort());    }    jsonSb.append('}');    return jsonSb.toString();}
0
public long getPacketTimeInNanos()
{    if (getGlobalHeader().getMagicNumber() == 0xa1b2c3d4 || getGlobalHeader().getMagicNumber() == 0xd4c3b2a1) {                        return getPacketHeader().getTsSec() * 1000000000L + getPacketHeader().getTsUsec() * 1000L;    } else if (getGlobalHeader().getMagicNumber() == 0xa1b23c4d || getGlobalHeader().getMagicNumber() == 0x4d3cb2a1) {                        return getPacketHeader().getTsSec() * 1000000000L + getPacketHeader().getTsUsec();    }            return getPacketHeader().getTsSec() * 1000000000L + getPacketHeader().getTsUsec() * 1000L;}
1
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() != 2) {        return new IllegalStateException("Expected 2 arguments: regex and data");    }    String regex = (String) args.get(0);    byte[] data = (byte[]) args.get(1);    try {        return ByteArrayMatchingUtil.INSTANCE.match(regex, data);    } catch (ExecutionException e) {        throw new IllegalStateException("Unable to process " + regex + " against " + DatatypeConverter.printHexBinary(data));    }}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Searcher<SequenceMatcher> load(String pattern) throws Exception
{    return new HorspoolFinalFlagSearcher(compile(pattern));}
0
private SequenceMatcher compile(String pattern) throws CompileException
{    return compiler.compile(pattern);}
0
public boolean match(String pattern, byte[] data) throws ExecutionException
{    if (pattern == null) {        return false;    }    Searcher<SequenceMatcher> searcher = sequenceMatchers.get(pattern);    if (data == null) {        return false;    } else {        return !searcher.searchForwards(data).isEmpty();    }}
0
public PcapPacket getPacket() throws IOException
{    return readPacket(globalHeader.getMagicNumber());}
0
public GlobalHeader getGlobalHeader()
{    return globalHeader;}
0
private void readGlobalHeader() throws IOException
{    int magic = is.readInt();    short major = is.readShort();    short minor = is.readShort();    int tz = is.readInt();    int sigfigs = is.readInt();    int snaplen = is.readInt();    int network = is.readInt();    globalHeader = new GlobalHeader(magic, major, minor, tz, sigfigs, snaplen, network);    if (globalHeader.getMagicNumber() == 0xD4C3B2A1) {        globalHeader.swapByteOrder();    }}
0
private PcapPacket readPacket(int magicNumber) throws IOException
{    PacketHeader packetHeader = readPacketHeader(magicNumber);    Buffer packetData = readPacketData(packetHeader.getInclLen());    return new PcapPacket(packetHeader, packetData);}
0
private PacketHeader readPacketHeader(int magicNumber) throws IOException
{    int tsSec = is.readInt();    int tsUsec = is.readInt();    int inclLen = is.readInt();    int origLen = is.readInt();    if (magicNumber == 0xD4C3B2A1) {        tsSec = ByteOrderConverter.swap(tsSec);        tsUsec = ByteOrderConverter.swap(tsUsec);        inclLen = ByteOrderConverter.swap(inclLen);        origLen = ByteOrderConverter.swap(origLen);    }    return new PacketHeader(tsSec, tsUsec, inclLen, origLen);}
0
private Buffer readPacketData(int packetLength) throws IOException
{    byte[] packets = new byte[packetLength];    is.read(packets);    Buffer payload = new ChainBuffer();    payload.addLast(packets);    return payload;}
0
public void close() throws IOException
{        is.close();}
0
private void createGlobalHeader()
{    /* magic number(swapped) */    list.add((byte) 0xd4);    list.add((byte) 0xc3);    list.add((byte) 0xb2);    list.add((byte) 0xa1);    /* major version number */    list.add((byte) 0x02);    list.add((byte) 0x00);    /* minor version number */    list.add((byte) 0x04);    list.add((byte) 0x00);    /* GMT to local correction */    list.add((byte) 0x00);    list.add((byte) 0x00);    list.add((byte) 0x00);    list.add((byte) 0x00);    /* accuracy of timestamps */    list.add((byte) 0x00);    list.add((byte) 0x00);    list.add((byte) 0x00);    list.add((byte) 0x00);    /* max length of captured packets, in octets */    list.add((byte) 0xff);    list.add((byte) 0xff);    list.add((byte) 0x00);    list.add((byte) 0x00);    /* data link type(ethernet) */    list.add((byte) 0x01);    list.add((byte) 0x00);    list.add((byte) 0x00);    list.add((byte) 0x00);}
0
private void copyGlobalHeader(GlobalHeader header)
{    final byte[] magicNumber = intToByteArray(header.getMagicNumber());    final byte[] majorVersion = shortToByteArray(header.getMajorVersion());    final byte[] minorVersion = shortToByteArray(header.getMinorVersion());    final byte[] zone = intToByteArray(header.getThiszone());    final byte[] sigFigs = intToByteArray(header.getSigfigs());    final byte[] snapLen = intToByteArray(header.getSnaplen());    final byte[] network = intToByteArray(header.getNetwork());    list.add(magicNumber[0]);    list.add(magicNumber[1]);    list.add(magicNumber[2]);    list.add(magicNumber[3]);    list.add(majorVersion[1]);    list.add(majorVersion[0]);    list.add(minorVersion[1]);    list.add(minorVersion[0]);    list.add(zone[3]);    list.add(zone[2]);    list.add(zone[1]);    list.add(zone[0]);    list.add(sigFigs[3]);    list.add(sigFigs[2]);    list.add(sigFigs[1]);    list.add(sigFigs[0]);    list.add(snapLen[3]);    list.add(snapLen[2]);    list.add(snapLen[1]);    list.add(snapLen[0]);    list.add(network[3]);    list.add(network[2]);    list.add(network[1]);    list.add(network[0]);}
0
public void write(PcapPacket packet) throws IOException
{    PacketHeader packetHeader = packet.getPacketHeader();    int tsSec = packetHeader.getTsSec();    int tsUsec = packetHeader.getTsUsec();    int inclLen = packetHeader.getInclLen();    int origLen = packetHeader.getOrigLen();    addInt(tsSec);    addInt(tsUsec);    addInt(inclLen);    addInt(origLen);    Buffer payload = packet.getPacketData();    try {        payload.mark();        while (true) {            list.add(payload.get());        }    } catch (BufferUnderflowException e) {                payload.reset();    }    cachedPacketNum++;    if (cachedPacketNum == MAX_CACHED_PACKET_NUMBER) {        flush();    }}
0
private void addInt(int number)
{    list.add((byte) (number & 0xff));    list.add((byte) ((number & 0xff00) >> 8));    list.add((byte) ((number & 0xff0000) >> 16));    list.add((byte) ((number & 0xff000000) >> 24));}
0
private byte[] intToByteArray(int number)
{    return new byte[] { (byte) (number >>> 24), (byte) (number >>> 16), (byte) (number >>> 8), (byte) number };}
0
private byte[] shortToByteArray(short number)
{    return new byte[] { (byte) (number >>> 8), (byte) number };}
0
public void flush() throws IOException
{    byte[] fileBinary = new byte[list.size()];    for (int i = 0; i < fileBinary.length; i++) {        fileBinary[i] = list.get(i);    }    list.clear();    baos.write(fileBinary);    cachedPacketNum = 0;}
0
public void close() throws IOException
{    flush();        baos.close();}
0
public static String getKafkaTopic(String pcapFilename)
{    String[] tokens = stripPrefix(pcapFilename).split("_");    return String.join("_", Arrays.copyOfRange(tokens, 0, tokens.length - 3));}
0
private static String stripPrefix(String s)
{    return s.substring(PREFIX.length());}
0
public static Long getTimestamp(String pcapFilename)
{    String[] tokens = stripPrefix(pcapFilename).split("_");    try {        return Long.parseUnsignedLong(tokens[tokens.length - 3]);    } catch (NumberFormatException e) {        return null;    }}
0
public static Integer getKafkaPartition(String pcapFilename)
{    String[] tokens = stripPrefix(pcapFilename).split("_");    try {        return Integer.parseInt(tokens[tokens.length - 2]);    } catch (NumberFormatException e) {        return null;    }}
0
public static String getUUID(String pcapFilename)
{    String[] tokens = stripPrefix(pcapFilename).split("_");    return tokens[tokens.length - 1];}
0
public String getName()
{    return name;}
0
protected MetronEthernetDecoder initialValue()
{    return createDecoder();}
0
public static String toFilename(String topic, long timestamp, String partition, String uuid)
{    return Joiner.on("_").join("pcap", topic, Long.toUnsignedString(timestamp), partition, uuid);}
0
public static boolean swapBytes(org.apache.metron.spout.pcap.Endianness endianness)
{    return endianness == org.apache.metron.spout.pcap.Endianness.LITTLE;}
0
public static byte[] getPcapGlobalHeader(Endianness endianness)
{    if (swapBytes(endianness)) {                return new byte[] {         (byte) 0xd4,         (byte) 0xc3,         (byte) 0xb2,         (byte) 0xa1,         0x02,         0x00,         0x04,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         (byte) 0xff,         (byte) 0xff,         0x00,         0x00,         0x01,         0x00,         0x00,         0x00 };    } else {                return new byte[] {         (byte) 0xa1,         (byte) 0xb2,         (byte) 0xc3,         (byte) 0xd4,         0x00,         0x02,         0x00,         0x04,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         0x00,         (byte) 0xff,         (byte) 0xff,         0x00,         0x00,         0x00,         0x01 };    }}
0
public static Long getTimestamp(byte[] pcap)
{    return getTimestamp(pcap, 0, pcap.length);}
0
public static Long getTimestamp(byte[] pcap, int offset, int length)
{    PcapByteInputStream pcapByteInputStream = null;    try {        pcapByteInputStream = new PcapByteInputStream(pcap, offset, length);        PcapPacket packet = pcapByteInputStream.getPacket();        GlobalHeader globalHeader = pcapByteInputStream.getGlobalHeader();        PacketHeader packetHeader = packet.getPacketHeader();        if (globalHeader.getMagicNumber() == 0xa1b2c3d4 || globalHeader.getMagicNumber() == 0xd4c3b2a1) {                                    return packetHeader.getTsSec() * 1000000000L + packetHeader.getTsUsec() * 1000L;        } else if (globalHeader.getMagicNumber() == 0xa1b23c4d || globalHeader.getMagicNumber() == 0x4d3cb2a1) {                                    return packetHeader.getTsSec() * 1000000000L + packetHeader.getTsUsec();        }                        return packetHeader.getTsSec() * 1000000000L + packetHeader.getTsUsec() * 1000L;    } catch (IOException ioe) {                    } finally {        if (pcapByteInputStream != null) {            try {                pcapByteInputStream.close();            } catch (IOException e) {                            }        }    }    return null;}
1
public static byte[] addHeaders(long tsNano, byte[] packet, Endianness endianness)
{    byte[] ret = new byte[GLOBAL_HEADER_SIZE + PACKET_HEADER_SIZE + packet.length];    byte[] globalHeader = getPcapGlobalHeader(endianness);    int offset = 0;    System.arraycopy(globalHeader, 0, ret, offset, GLOBAL_HEADER_SIZE);    offset += globalHeader.length;    {        boolean swapBytes = swapBytes(endianness);        long micros = Long.divideUnsigned(tsNano, 1000);        int secs = (int) (micros / 1000000);        int usec = (int) (micros % 1000000);        int capLen = packet.length;        {            byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(secs) : secs);            System.arraycopy(b, 0, ret, offset, Integer.BYTES);            offset += Integer.BYTES;        }        {            byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(usec) : usec);            System.arraycopy(b, 0, ret, offset, Integer.BYTES);            offset += Integer.BYTES;        }        {            byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(capLen) : capLen);            System.arraycopy(b, 0, ret, offset, Integer.BYTES);            offset += Integer.BYTES;        }        {            byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(capLen) : capLen);            System.arraycopy(b, 0, ret, offset, Integer.BYTES);            offset += Integer.BYTES;        }    }    System.arraycopy(packet, 0, ret, offset, packet.length);    return ret;}
0
public static byte[] addGlobalHeader(byte[] packet, Endianness endianness)
{    byte[] globalHeader = getPcapGlobalHeader(endianness);    byte[] ret = new byte[packet.length + GLOBAL_HEADER_SIZE];    int offset = 0;    System.arraycopy(globalHeader, 0, ret, offset, GLOBAL_HEADER_SIZE);    offset += globalHeader.length;    System.arraycopy(packet, 0, ret, offset, packet.length);    return ret;}
0
public static byte[] addPacketHeader(long tsNano, byte[] packet, Endianness endianness)
{    boolean swapBytes = swapBytes(endianness);    long micros = Long.divideUnsigned(tsNano, 1000);    int secs = (int) (micros / 1000000);    int usec = (int) (micros % 1000000);    int capLen = packet.length;    byte[] ret = new byte[PACKET_HEADER_SIZE + packet.length];    int offset = 0;    {        byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(secs) : secs);        System.arraycopy(b, 0, ret, offset, Integer.BYTES);        offset += Integer.BYTES;    }    {        byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(usec) : usec);        System.arraycopy(b, 0, ret, offset, Integer.BYTES);        offset += Integer.BYTES;    }    {        byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(capLen) : capLen);        System.arraycopy(b, 0, ret, offset, Integer.BYTES);        offset += Integer.BYTES;    }    {        byte[] b = Bytes.toBytes(swapBytes ? ByteOrderConverter.swap(capLen) : capLen);        System.arraycopy(b, 0, ret, offset, Integer.BYTES);        offset += Integer.BYTES;    }    System.arraycopy(packet, 0, ret, offset, packet.length);    return ret;}
0
public static Map<String, Object> packetToFields(PacketInfo pi)
{    Map<String, Object> ret = new HashMap<>();    ret.put(PacketFields.PACKET_DATA.getName(), pi.getPacketBytes());    if (pi.getTcpPacket() != null) {        if (pi.getTcpPacket().getSourceAddress() != null) {            ret.put(org.apache.metron.common.Constants.Fields.SRC_ADDR.getName(), pi.getTcpPacket().getSourceAddress().getHostAddress());        }        if (pi.getTcpPacket().getSource() != null) {            ret.put(org.apache.metron.common.Constants.Fields.SRC_PORT.getName(), pi.getTcpPacket().getSource().getPort());        }        if (pi.getTcpPacket().getDestinationAddress() != null) {            ret.put(org.apache.metron.common.Constants.Fields.DST_ADDR.getName(), pi.getTcpPacket().getDestinationAddress().getHostAddress());        }        if (pi.getTcpPacket().getDestination() != null) {            ret.put(org.apache.metron.common.Constants.Fields.DST_PORT.getName(), pi.getTcpPacket().getDestination().getPort());        }    }    if (pi.getUdpPacket() != null) {        if (pi.getUdpPacket().getSource() != null) {            if (pi.getUdpPacket().getSource().getAddress() != null) {                ret.put(org.apache.metron.common.Constants.Fields.SRC_ADDR.getName(), pi.getUdpPacket().getSource().getAddress().getHostAddress());            }            ret.put(org.apache.metron.common.Constants.Fields.SRC_PORT.getName(), pi.getUdpPacket().getSource().getPort());        }        if (pi.getUdpPacket().getDestination() != null) {            if (pi.getUdpPacket().getDestination().getAddress() != null) {                ret.put(org.apache.metron.common.Constants.Fields.DST_ADDR.getName(), pi.getUdpPacket().getDestination().getAddress().getHostAddress());            }            ret.put(org.apache.metron.common.Constants.Fields.DST_PORT.getName(), pi.getUdpPacket().getDestination().getPort());        }    }    if (pi.getIpv4Packet() != null) {        ret.put(org.apache.metron.common.Constants.Fields.PROTOCOL.getName(), pi.getIpv4Packet().getProtocol());    }    return ret;}
0
public static List<PacketInfo> toPacketInfo(byte[] packet) throws IOException
{    return toPacketInfo(ETHERNET_DECODER.get(), packet);}
0
public static MetronEthernetDecoder createDecoder()
{    MetronEthernetDecoder ethernetDecoder = new MetronEthernetDecoder();    IpDecoder ipDecoder = new IpDecoder();    ethernetDecoder.register(EthernetType.IPV4, ipDecoder);    return ethernetDecoder;}
0
public static List<PacketInfo> toPacketInfo(MetronEthernetDecoder decoder, byte[] pcap) throws IOException
{    List<PacketInfo> packetInfoList = new ArrayList<>();    PcapByteInputStream pcapByteInputStream = new PcapByteInputStream(pcap);    GlobalHeader globalHeader = pcapByteInputStream.getGlobalHeader();    while (true) {        try {            PcapPacket packet = pcapByteInputStream.getPacket();                                                TcpPacket tcpPacket = null;            UdpPacket udpPacket = null;                        int sourcePort = 0;            int destinationPort = 0;                                    decoder.decode(packet);            PacketHeader packetHeader = packet.getPacketHeader();            Ipv4Packet ipv4Packet = Ipv4Packet.parse(packet.getPacketData());            if (ipv4Packet.getProtocol() == Constants.PROTOCOL_TCP) {                tcpPacket = TcpPacket.parse(ipv4Packet);            }            if (ipv4Packet.getProtocol() == Constants.PROTOCOL_UDP) {                Buffer packetDataBuffer = ipv4Packet.getData();                sourcePort = packetDataBuffer.getUnsignedShort();                destinationPort = packetDataBuffer.getUnsignedShort();                udpPacket = new UdpPacket(ipv4Packet, sourcePort, destinationPort);                udpPacket.setLength(packetDataBuffer.getUnsignedShort());                udpPacket.setChecksum(packetDataBuffer.getUnsignedShort());                packetDataBuffer.discardReadBytes();                udpPacket.setData(packetDataBuffer);            }            packetInfoList.add(new PacketInfo(globalHeader, packetHeader, packet, ipv4Packet, tcpPacket, udpPacket, pcap));        } catch (NegativeArraySizeException ignored) {                    } catch (EOFException eof) {                        break;        }    }    return packetInfoList;}
1
public static List<JSONObject> toJSON(List<PacketInfo> packetInfoList)
{    List<JSONObject> messages = new ArrayList<>();    for (PacketInfo packetInfo : packetInfoList) {        JSONObject message = (JSONObject) JSONValue.parse(packetInfo.getJsonIndexDoc());        messages.add(message);    }    return messages;}
0
public static boolean greaterThanOrEqualTo(long a, long b)
{    return Long.compareUnsigned(a, b) >= 0;}
0
public static boolean lessThanOrEqualTo(long a, long b)
{    return Long.compareUnsigned(a, b) <= 0;}
0
public static void merge(ByteArrayOutputStream baos, List<byte[]> pcaps) throws IOException
{    PcapByteInputStream is = null;    PcapByteOutputStream os = null;    ByteArrayOutputStream unsortedBaos = new ByteArrayOutputStream();    try {        int i = 1;        for (byte[] pcap : pcaps) {            is = new PcapByteInputStream(pcap);            if (i == 1) {                os = new PcapByteOutputStream(unsortedBaos, is.getGlobalHeader());            }            writePacket(is, os);            i++;            closeInput(is);        }    } finally {        if (unsortedBaos != null) {            unsortedBaos.close();        }        closeOutput(os);        sort(baos, unsortedBaos.toByteArray());    }}
0
public static void merge(ByteArrayOutputStream baos, byte[]... pcaps) throws IOException
{    merge(baos, Arrays.asList(pcaps));}
0
private static void sort(ByteArrayOutputStream baos, byte[] unsortedBytes) throws IOException
{    PcapByteInputStream pcapIs = new PcapByteInputStream(unsortedBytes);    PcapByteOutputStream pcapOs = new PcapByteOutputStream(baos, pcapIs.getGlobalHeader());    PcapPacket packet;    ArrayList<PcapPacket> packetList = new ArrayList<PcapPacket>();    try {        while (true) {            packet = pcapIs.getPacket();            if (packet == null)                break;            packetList.add(packet);                    }    } catch (EOFException e) {        }    Collections.sort(packetList, PCAP_PACKET_COMPARATOR);    for (PcapPacket p : packetList) {        pcapOs.write(p);            }    pcapOs.close();}
1
private static void writePacket(PcapByteInputStream is, PcapByteOutputStream os) throws IOException
{    PcapPacket packet = null;    try {        while (true) {            packet = is.getPacket();            if (packet == null) {                break;            }            os.write(packet);        }    } catch (EOFException e) {        }}
0
private static void closeInput(PcapByteInputStream is)
{    if (is == null) {        return;    }    try {                is.close();    } catch (IOException e) {            }}
1
private static void closeOutput(PcapByteOutputStream os)
{    if (os == null) {        return;    }    try {        os.close();    } catch (IOException e) {            }}
1
public static void main(String[] args) throws IOException
{    byte[] b1 = FileUtils.readFileToByteArray(new File("/Users/sheetal/Downloads/constructedTcpDump.1.pcap"));    byte[] b2 = FileUtils.readFileToByteArray(new File("/Users/sheetal/Downloads/constructedTcpDump.2.pcap"));    byte[] b3 = FileUtils.readFileToByteArray(new File("/Users/sheetal/Downloads/constructedTcpDump.3.pcap"));        ByteArrayOutputStream boas = new ByteArrayOutputStream();        PcapMerger.merge(boas, b1, b2, b3);    FileUtils.writeByteArrayToFile(new File("/Users/sheetal/Downloads/constructedTcpDump.automerged.1.2.pcap"), boas.toByteArray(), false);}
0
public int compare(PcapPacket p1, PcapPacket p2)
{    long p1time = p1.getPacketHeader().getTsSec() * 1000000L + p1.getPacketHeader().getTsUsec();    long p2time = p2.getPacketHeader().getTsSec() * 1000000L + p2.getPacketHeader().getTsUsec();        return Long.compare(p1time, p2time);}
1
public Path getPage(int num)
{    return files.get(num);}
0
public int getSize()
{    return files.size();}
0
public Iterator<Path> iterator()
{    return new PcapIterator(files.iterator());}
0
public boolean hasNext()
{    return delegateIt.hasNext();}
0
public Path next()
{    return delegateIt.next();}
0
public static Iterable<String> getPathsInTimeRange(long beginTs, long endTs, Iterable<Path> files)
{    Map<Integer, List<Path>> filesByPartition = getFilesByPartition(files);    List<String> filteredFiles = filterByTimestampLT(beginTs, endTs, filesByPartition);        return filteredFiles;}
1
public static Map<Integer, List<Path>> getFilesByPartition(Iterable<Path> files)
{    Iterator<Path> filesIt = files.iterator();    Map<Integer, List<Path>> filesByPartition = new HashMap<>();    while (filesIt.hasNext()) {        Path p = filesIt.next();        Integer partition = PcapFilenameHelper.getKafkaPartition(p.getName());        if (!filesByPartition.containsKey(partition)) {            filesByPartition.put(partition, new ArrayList<>());        }        filesByPartition.get(partition).add(p);    }    return filesByPartition;}
0
public static List<String> filterByTimestampLT(long beginTs, long endTs, Map<Integer, List<Path>> filesByPartition)
{    List<String> filteredFiles = new ArrayList<>();    for (Integer key : filesByPartition.keySet()) {        List<Path> paths = filesByPartition.get(key);        filteredFiles.addAll(filterByTimestampLT(beginTs, endTs, paths));    }    return filteredFiles;}
0
public static List<String> filterByTimestampLT(long beginTs, long endTs, List<Path> paths)
{    List<String> filteredFiles = new ArrayList<>();        Collections.sort(paths);    Iterator<Path> filesIt = paths.iterator();    Path leftTrailing = filesIt.hasNext() ? filesIt.next() : null;    if (leftTrailing == null) {        return filteredFiles;    }    boolean first = true;    Long fileTS = PcapFilenameHelper.getTimestamp(leftTrailing.getName());    if (fileTS != null && greaterThanOrEqualTo(fileTS, beginTs) && lessThanOrEqualTo(fileTS, endTs)) {        filteredFiles.add(leftTrailing.toString());        first = false;    }    if (first && !filesIt.hasNext()) {        filteredFiles.add(leftTrailing.toString());        return filteredFiles;    }    while (filesIt.hasNext()) {        Path p = filesIt.next();        fileTS = PcapFilenameHelper.getTimestamp(p.getName());        if (fileTS != null && greaterThanOrEqualTo(fileTS, beginTs) && lessThanOrEqualTo(fileTS, endTs)) {            if (first) {                filteredFiles.add(leftTrailing.toString());                first = false;            }            filteredFiles.add(p.toString());        } else {            leftTrailing = p;        }    }    return filteredFiles;}
0
public static String convertIpv4IpToHex(String ipAddress)
{    StringBuffer hexIp = new StringBuffer(64);    String[] ipSegments = ipAddress.split("\\.");    for (String ipSegment : ipSegments) {        hexIp.append(convertIpSegmentToHex(ipSegment));    }    return hexIp.toString();}
0
public static String convertHexToIpv4Ip(String hex)
{    List<Integer> ipSegments = new ArrayList<>();    for (int i = 0; i < hex.length(); i += 2) {        String segment = hex.substring(i, i + 2);        ipSegments.add(Integer.parseInt(segment, 16));    }    return Joiner.on(".").join(ipSegments);}
0
public static String getSessionKey(String srcIp, String dstIp, String protocol, String srcPort, String dstPort)
{    return getSessionKey(srcIp, dstIp, protocol, srcPort, dstPort, null, null);}
0
public static String getSessionKey(String srcIp, String dstIp, String protocol, String srcPort, String dstPort, String ipId, String fragmentOffset)
{    StringBuffer sb = new StringBuffer(40);    sb.append(convertIpv4IpToHex(srcIp)).append(SESSION_KEY_SEPERATOR).append(convertIpv4IpToHex(dstIp)).append(SESSION_KEY_SEPERATOR).append(protocol == null ? "0" : protocol).append(SESSION_KEY_SEPERATOR).append(srcPort == null ? "0" : srcPort).append(SESSION_KEY_SEPERATOR).append(dstPort == null ? "0" : dstPort).append(SESSION_KEY_SEPERATOR).append(ipId == null ? "0" : ipId).append(SESSION_KEY_SEPERATOR).append(fragmentOffset == null ? "0" : fragmentOffset);    return sb.toString();}
0
public static String getSessionKey(JSONObject message)
{    String srcIp = (String) message.get("ip_src_addr");    String dstIp = (String) message.get("ip_dst_addr");    Long protocol = (Long) message.get("ip_protocol");    Long srcPort = (Long) message.get("ip_src_port");    Long dstPort = (Long) message.get("ip_dst_port");    Long ipId = (Long) message.get("ip_id");    String ipIdString = ipId == null ? null : ipId.toString();    Long fragmentOffset = (Long) message.get("frag_offset");    String fragmentOffsetString = fragmentOffset == null ? null : fragmentOffset.toString();    return PcapUtils.getSessionKey(srcIp, dstIp, protocol.toString(), srcPort.toString(), dstPort.toString(), ipIdString, fragmentOffsetString);}
0
public static String getPartialSessionKey(String srcIp, String dstIp, String protocol, String srcPort, String dstPort)
{    StringBuffer sb = new StringBuffer(40);    sb.append(convertIpv4IpToHex(srcIp)).append(SESSION_KEY_SEPERATOR).append(convertIpv4IpToHex(dstIp)).append(SESSION_KEY_SEPERATOR).append(protocol == null ? "0" : protocol).append(SESSION_KEY_SEPERATOR).append(srcPort == null ? "0" : srcPort).append(SESSION_KEY_SEPERATOR).append(dstPort == null ? "0" : dstPort);    return sb.toString();}
0
public static String getSessionKey(String srcIp, String dstIp, int protocol, int srcPort, int dstPort, int ipId, int fragmentOffset)
{    String keySeperator = "-";    StringBuffer sb = new StringBuffer(40);    sb.append(convertIpv4IpToHex(srcIp)).append(keySeperator).append(convertIpv4IpToHex(dstIp)).append(keySeperator).append(protocol).append(keySeperator).append(srcPort).append(keySeperator).append(dstPort).append(keySeperator).append(ipId).append(keySeperator).append(fragmentOffset);    return sb.toString();}
0
public static String getShortSessionKey(String srcIp, String dstIp, int protocol, int srcPort, int dstPort)
{    String keySeperator = "-";    StringBuffer sb = new StringBuffer(40);    sb.append(convertIpv4IpToHex(srcIp)).append(keySeperator).append(convertIpv4IpToHex(dstIp)).append(keySeperator).append(protocol).append(keySeperator).append(srcPort).append(keySeperator).append(dstPort);    return sb.toString();}
0
public static String convertIpSegmentToHex(String ipSegment)
{    return convertIpSegmentToHex(Integer.valueOf(ipSegment));}
0
public static String convertIpSegmentToHex(int ipSegment)
{    return convertToHex(ipSegment, 2);}
0
public static String convertToHex(int number, int length)
{    return StringUtils.leftPad(Integer.toHexString(number), length, '0');}
0
public static String getProtocolNameFromId(int protocolNumber)
{    String protocolName = protocolIdToNameMap.get(protocolNumber);    if (protocolName == null) {        protocolName = String.valueOf(protocolNumber);    }    return protocolName;}
0
public static int getProtocolIdFromName(String protocolName)
{    Integer protocolNumber = protocolNameToIdMap.get(protocolName.toUpperCase());    if (protocolNumber == null) {        protocolNumber = -1;    }    return protocolNumber;}
0
private static Map<V, K> invertMap(Map<K, V> map)
{    Map<V, K> inv = new HashMap<V, K>();    for (Entry<K, V> entry : map.entrySet()) inv.put(entry.getValue(), entry.getKey());    return inv;}
0
public void write(Configuration config, List<byte[]> pcaps, String outPath) throws IOException
{    HDFSUtils.write(config, mergePcaps(pcaps), outPath);}
0
public void writeLocal(List<byte[]> pcaps, String outPath) throws IOException
{    File out = new File(outPath);    try (FileOutputStream fos = new FileOutputStream(out)) {        fos.write(mergePcaps(pcaps));    }}
0
public byte[] mergePcaps(List<byte[]> pcaps) throws IOException
{    if (pcaps == null) {        return new byte[] {};    }    if (pcaps.size() == 1) {        return pcaps.get(0);    }    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, pcaps);    return baos.toByteArray();}
0
public static Endianness getNativeEndianness()
{    if (ByteOrder.nativeOrder().equals(ByteOrder.BIG_ENDIAN)) {        return BIG;    } else {        return LITTLE;    }}
0
public void string_representation_of_query_gets_formatted() throws Exception
{    final LinkedHashMap<String, String> fields = new LinkedHashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), "0");            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), "1");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");        }    };    String actual = new FixedPcapFilter.Configurator().queryToString(fields);    String expected = "src_ip_0_dst_ip_1_false";    Assert.assertThat("string representation did not match", actual, equalTo(expected));}
0
public void string_representation_of_empty_fields_empty() throws Exception
{    {        final LinkedHashMap<String, String> fields = new LinkedHashMap<String, String>();        String actual = new FixedPcapFilter.Configurator().queryToString(fields);        String expected = "";        Assert.assertThat("string representation did not match", actual, equalTo(expected));    }    {        String actual = new FixedPcapFilter.Configurator().queryToString(null);        String expected = "";        Assert.assertThat("string representation did not match", actual, equalTo(expected));    }    {        final LinkedHashMap<String, String> fields = new LinkedHashMap<String, String>() {            {                put(Constants.Fields.SRC_ADDR.getName(), "");                put(Constants.Fields.SRC_PORT.getName(), "");            }        };        String actual = new FixedPcapFilter.Configurator().queryToString(fields);        String expected = "_";        Assert.assertThat("string representation did not match", actual, equalTo(expected));    }}
0
public void testTrivialEquality() throws Exception
{    Configuration config = new Configuration();    final Map<String, String> fields = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), "0");            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), "1");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");        }    };    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected Map<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }}
0
protected Map<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testReverseTraffic() throws Exception
{    Configuration config = new Configuration();    final Map<String, String> fields = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), "0");            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), "1");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "true");        }    };    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected Map<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected Map<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "dst_ip");                        put(Constants.Fields.SRC_PORT.getName(), 1);                        put(Constants.Fields.DST_ADDR.getName(), "src_ip");                        put(Constants.Fields.DST_PORT.getName(), 0);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected Map<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "dst_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "src_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertFalse(filter.test(null));    }}
0
protected Map<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
protected Map<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "dst_ip");            put(Constants.Fields.SRC_PORT.getName(), 1);            put(Constants.Fields.DST_ADDR.getName(), "src_ip");            put(Constants.Fields.DST_PORT.getName(), 0);        }    };}
0
protected Map<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "dst_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "src_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testMissingDstAddr() throws Exception
{    Configuration config = new Configuration();    final HashMap<String, String> fields = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), "0");            put(Constants.Fields.DST_PORT.getName(), "1");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");        }    };    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip1");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertFalse(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip1");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testMissingDstPort() throws Exception
{    Configuration config = new Configuration();    final HashMap<String, String> fields = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), "0");            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");        }    };    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 100);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 100);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 100);                    }                };            }        };        filter.configure(config);        Assert.assertFalse(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 100);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 100);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 100);        }    };}
0
public void testMissingSrcAddr() throws Exception
{    Configuration config = new Configuration();    final HashMap<String, String> fields = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_PORT.getName(), "0");            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), "1");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");        }    };    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testMissingSrcPort() throws Exception
{    Configuration config = new Configuration();    final HashMap<String, String> fields = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), "1");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");        }    };    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new FixedPcapFilter.Configurator().addToConfig(fields, config);    {        FixedPcapFilter filter = new FixedPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 100);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 100);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void creates_pcap_filters() throws Exception
{    Assert.assertThat("filter type should be Fixed", PcapFilters.FIXED.create(), instanceOf(FixedPcapFilter.class));    Assert.assertThat("filter type should be Query", PcapFilters.QUERY.create(), instanceOf(QueryPcapFilter.class));}
0
public void string_representation_of_query_gets_formatted() throws Exception
{    String query = "ip_src_addr == 'srcIp' and ip_src_port == '80' and ip_dst_addr == 'dstIp' and ip_dst_port == '100' and protocol == 'protocol'";    String actual = new QueryPcapFilter.Configurator().queryToString(query);    String expected = "ip_src_addr_==_'srcIp'_and_ip_src_port_==_'80'_and_ip_dst_addr_==_'dstIp'_and_ip_dst_port_==_'100'_and_protocol_==_'protocol'";    Assert.assertThat("string representation did not match", actual, equalTo(expected));}
0
public void string_representation_of_empty_query_empty() throws Exception
{    {        String query = "";        String actual = new QueryPcapFilter.Configurator().queryToString(query);        String expected = "";        Assert.assertThat("string representation did not match", actual, equalTo(expected));    }    {        String query = " ";        String actual = new QueryPcapFilter.Configurator().queryToString(query);        String expected = "";        Assert.assertThat("string representation did not match", actual, equalTo(expected));    }    {        String query = null;        String actual = new QueryPcapFilter.Configurator().queryToString(query);        String expected = "";        Assert.assertThat("string representation did not match", actual, equalTo(expected));    }}
0
public void testEmptyQueryFilter() throws Exception
{    Configuration config = new Configuration();    String query = "";    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        PcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testTrivialEquality() throws Exception
{    Configuration config = new Configuration();    String query = "ip_src_addr == 'src_ip' and ip_src_port == 0 and ip_dst_addr == 'dst_ip' and ip_dst_port == 1";    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        PcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testMissingDstAddr() throws Exception
{    Configuration config = new Configuration();    String query = "ip_src_addr == 'src_ip' and ip_src_port == 0 and ip_dst_port == 1";    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip_no_match");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertFalse(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip_no_match");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testMissingDstPort() throws Exception
{    Configuration config = new Configuration();    String query = "ip_src_addr == 'src_ip' and ip_src_port == 0 and ip_dst_addr == 'dst_ip'";    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 100);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 100);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 100);                    }                };            }        };        filter.configure(config);        Assert.assertFalse(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 100);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 100);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 100);        }    };}
0
public void testMissingSrcAddr() throws Exception
{    Configuration config = new Configuration();    String query = "ip_src_port == 0 and ip_dst_addr == 'dst_ip' and ip_dst_port == 1";    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void testMissingSrcPort() throws Exception
{    Configuration config = new Configuration();    String query = "ip_src_addr == 'src_ip' and ip_dst_addr == 'dst_ip' and ip_dst_port == 1";    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 0);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }    new QueryPcapFilter.Configurator().addToConfig(query, config);    {        QueryPcapFilter filter = new QueryPcapFilter() {            @Override            protected HashMap<String, Object> packetToFields(PacketInfo pi) {                return new HashMap<String, Object>() {                    {                        put(Constants.Fields.SRC_ADDR.getName(), "src_ip");                        put(Constants.Fields.SRC_PORT.getName(), 100);                        put(Constants.Fields.DST_ADDR.getName(), "dst_ip");                        put(Constants.Fields.DST_PORT.getName(), 1);                    }                };            }        };        filter.configure(config);        Assert.assertTrue(filter.test(null));    }}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 0);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
protected HashMap<String, Object> packetToFields(PacketInfo pi)
{    return new HashMap<String, Object>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "src_ip");            put(Constants.Fields.SRC_PORT.getName(), 100);            put(Constants.Fields.DST_ADDR.getName(), "dst_ip");            put(Constants.Fields.DST_PORT.getName(), 1);        }    };}
0
public void setup()
{    filesIn = new ArrayList<>();    filesIn.add(new Path("/apath/pcap_pcap5_1495135372055519000_2_pcap-9-1495134910"));    filesIn.add(new Path("/apath/pcap_pcap5_1495135372168719000_1_pcap-9-1495134910"));    filesIn.add(new Path("/apath/pcap_pcap5_1495135377055375000_0_pcap-9-1495134910"));    filesIn.add(new Path("/apath/pcap_pcap5_1495135512102506000_4_pcap-9-1495134910"));    filesIn.add(new Path("/apath/pcap_pcap5_1495135512123943000_3_pcap-9-1495134910"));}
0
public void returns_files_by_partition()
{    Map<Integer, List<Path>> filesByPartition = FileFilterUtil.getFilesByPartition(filesIn);    Map<Integer, List<Path>> expectedFilesPartitioned = new HashMap() {        {            put(0, toList("/apath/pcap_pcap5_1495135377055375000_0_pcap-9-1495134910"));            put(1, toList("/apath/pcap_pcap5_1495135372168719000_1_pcap-9-1495134910"));            put(2, toList("/apath/pcap_pcap5_1495135372055519000_2_pcap-9-1495134910"));            put(3, toList("/apath/pcap_pcap5_1495135512123943000_3_pcap-9-1495134910"));            put(4, toList("/apath/pcap_pcap5_1495135512102506000_4_pcap-9-1495134910"));        }    };    assertThat(filesByPartition, equalTo(expectedFilesPartitioned));}
0
private List<Path> toList(String... items)
{    return Arrays.asList(items).stream().map(i -> new Path(i)).collect(Collectors.toList());}
0
public void returns_left_trailing_filtered_list()
{    Map<Integer, List<Path>> filesByPartition = new HashMap() {        {            put(0, toList("/apath/pcap_pcap5_1495135377055375000_0_pcap-9-1495134910"));            put(1, toList("/apath/pcap_pcap5_1495135372168719000_1_pcap-9-1495134910"));            put(2, toList("/apath/pcap_pcap5_1495135372055519000_2_pcap-9-1495134910"));            put(3, toList("/apath/pcap_pcap5_1495135512123943000_3_pcap-9-1495134910"));            put(4, toList("/apath/pcap_pcap5_1495135512102506000_4_pcap-9-1495134910"));        }    };    List<String> lt = FileFilterUtil.filterByTimestampLT(1495135377055375000L, 1495135512124943000L, filesByPartition);    List<String> expectedFiles = Arrays.asList("/apath/pcap_pcap5_1495135377055375000_0_pcap-9-1495134910", "/apath/pcap_pcap5_1495135372168719000_1_pcap-9-1495134910", "/apath/pcap_pcap5_1495135372055519000_2_pcap-9-1495134910", "/apath/pcap_pcap5_1495135512123943000_3_pcap-9-1495134910", "/apath/pcap_pcap5_1495135512102506000_4_pcap-9-1495134910");    assertThat(lt, equalTo(expectedFiles));}
0
public void returns_left_trailing_filtered_list_from_paths()
{    Iterable<String> paths = FileFilterUtil.getPathsInTimeRange(1495135377055375000L, 1495135512124943000L, filesIn);    List<String> expectedFiles = Arrays.asList("/apath/pcap_pcap5_1495135377055375000_0_pcap-9-1495134910", "/apath/pcap_pcap5_1495135372168719000_1_pcap-9-1495134910", "/apath/pcap_pcap5_1495135372055519000_2_pcap-9-1495134910", "/apath/pcap_pcap5_1495135512123943000_3_pcap-9-1495134910", "/apath/pcap_pcap5_1495135512102506000_4_pcap-9-1495134910");    assertThat(paths, equalTo(expectedFiles));}
0
public void test_getPaths_NoFiles() throws Exception
{    final List<Path> inputFiles = new ArrayList<Path>();    Iterable<String> paths = FileFilterUtil.getPathsInTimeRange(0, 1000, inputFiles);    Assert.assertTrue(Iterables.isEmpty(paths));}
0
public void test_getPaths_leftEdge() throws Exception
{    final long firstFileTSNanos = 1461589332993573000L;    final long secondFileTSNanos = 1561589332993573000L;    final List<Path> inputFiles = new ArrayList<Path>() {        {            add(new Path("/apps/metron/pcap/pcap_pcap_" + firstFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));            add(new Path("/apps/metron/pcap/pcap_pcap_" + secondFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));        }    };    Iterable<String> paths = FileFilterUtil.getPathsInTimeRange(0, secondFileTSNanos - 1L, inputFiles);    Assert.assertEquals(1, Iterables.size(paths));}
0
public void test_getPaths_rightEdge() throws Exception
{    final long firstFileTSNanos = 1461589332993573000L;    final long secondFileTSNanos = 1461589333993573000L;    final long thirdFileTSNanos = 1461589334993573000L;    {        final List<Path> inputFiles = new ArrayList<Path>() {            {                add(new Path("/apps/metron/pcap/pcap0_pcap_" + firstFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));                add(new Path("/apps/metron/pcap/pcap1_pcap_" + secondFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));            }        };        Iterable<String> paths = FileFilterUtil.getPathsInTimeRange(secondFileTSNanos - 1L, secondFileTSNanos + 1L, inputFiles);        Assert.assertEquals(2, Iterables.size(paths));    }    {        final List<Path> inputFiles = new ArrayList<Path>() {            {                add(new Path("/apps/metron/pcap/pcap0_pcap_" + firstFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));                add(new Path("/apps/metron/pcap/pcap1_pcap_" + secondFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));                add(new Path("/apps/metron/pcap/pcap1_pcap_" + thirdFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));            }        };        Iterable<String> paths = FileFilterUtil.getPathsInTimeRange(thirdFileTSNanos - 1L, thirdFileTSNanos + 1L, inputFiles);        Assert.assertEquals(2, Iterables.size(paths));    }}
0
public void test_getPaths_bothEdges() throws Exception
{    final long firstFileTSNanos = 1461589332993573000L;    final long secondFileTSNanos = 1461589333993573000L;    final long thirdFileTSNanos = 1461589334993573000L;    final List<Path> inputFiles = new ArrayList<Path>() {        {            add(new Path("/apps/metron/pcap/pcap_pcap_" + firstFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));            add(new Path("/apps/metron/pcap/pcap_pcap_" + secondFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));            add(new Path("/apps/metron/pcap/pcap1_pcap_" + thirdFileTSNanos + "_0_73686171-64a1-46e5-9e67-66cf603fb094"));        }    };    Iterable<String> paths = FileFilterUtil.getPathsInTimeRange(0, thirdFileTSNanos + 1L, inputFiles);    Assert.assertEquals(3, Iterables.size(paths));}
0
public void formats_directory_name_for_query_filter_types() throws Exception
{    long beginNS = TimestampConverters.MILLISECONDS.toNanoseconds(System.currentTimeMillis());    long endNS = TimestampConverters.MILLISECONDS.toNanoseconds(System.currentTimeMillis());    String query = "ip_dst_addr == '207.28.210.1' and protocol == 'PROTOCOL: ICMP(1)";    String queryFilterString = new QueryPcapFilter.Configurator().queryToString(query);    OutputDirFormatter formatter = new OutputDirFormatter();    String actual = formatter.format(beginNS, endNS, queryFilterString);    assertThat("Formatted directory names did not match.", actual, containsString("_ip_dst_addr_==_207-28-210-1_and_protocol_==_PROTOCOL_ICMP(1)_"));        new Path(actual);}
0
public void formats_directory_name_for_fixed_filter_types() throws Exception
{    long beginNS = TimestampConverters.MILLISECONDS.toNanoseconds(System.currentTimeMillis());    long endNS = TimestampConverters.MILLISECONDS.toNanoseconds(System.currentTimeMillis());    Map<String, String> fields = new HashMap<>();    fields.put("ip_src_address", "207.28.210.1");    fields.put("protocol", "PROTOCOL: ICMP(1)");    String fixedFilterString = new FixedPcapFilter.Configurator().queryToString(fields);    OutputDirFormatter formatter = new OutputDirFormatter();    String actual = formatter.format(beginNS, endNS, fixedFilterString);    assertThat("Formatted directory names did not match.", actual, containsString("PROTOCOL_ICMP(1)_207-28-210-1"));        new Path(actual);}
0
public void setup() throws IOException
{    MockitoAnnotations.initMocks(this);    basePath = new Path("basepath");    baseOutPath = new Path("outpath");    startTime = 100;    endTime = 200;    numReducers = 5;    numRecordsPerFile = 5;    fixedFields = new HashMap<>();    fixedFields.put("ip_src_addr", "192.168.1.1");    hadoopConfig = new Configuration();    fileSystem = FileSystem.get(hadoopConfig);    finalOutputPath = new Path("finaloutpath");    when(jobId.toString()).thenReturn(jobIdVal);    when(mrStatus.getJobID()).thenReturn(jobId);    when(mrJob.getJobID()).thenReturn(jobId);    pageableResult = new PcapPages();    timer = new TestTimer();        config = new FixedPcapConfig(clock -> "clockprefix");    PcapOptions.HADOOP_CONF.put(config, hadoopConfig);    PcapOptions.FILESYSTEM.put(config, FileSystem.get(hadoopConfig));    PcapOptions.BASE_PATH.put(config, basePath);    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, baseOutPath);    PcapOptions.START_TIME_NS.put(config, startTime);    PcapOptions.END_TIME_NS.put(config, endTime);    PcapOptions.NUM_REDUCERS.put(config, numReducers);    PcapOptions.FIELDS.put(config, fixedFields);    PcapOptions.FILTER_IMPL.put(config, new FixedPcapFilter.Configurator());    PcapOptions.NUM_RECORDS_PER_FILE.put(config, numRecordsPerFile);    PcapOptions.FINAL_OUTPUT_PATH.put(config, finalOutputPath);    testJob = new TestJob<>(mrJob);    testJob.setStatusInterval(1);    testJob.setCompleteCheckInterval(1);    testJob.setTimer(timer);}
0
public Job createJob(Optional<String> jobName, Path basePath, Path outputPath, long beginNS, long endNS, int numReducers, T fields, Configuration conf, FileSystem fs, PcapFilterConfigurator<T> filterImpl) throws IOException
{    return mrJob;}
0
public void scheduleAtFixedRate(TimerTask task, long delay, long period)
{    this.task = task;}
0
public void updateJobStatus()
{    task.run();}
0
public void partition_gives_value_in_range() throws Exception
{    long start = 1473897600000000000L;    long end = TimestampConverters.MILLISECONDS.toNanoseconds(1473995927455L);    Configuration conf = new Configuration();    conf.set(PcapJob.START_TS_CONF, toUnsignedString(start));    conf.set(PcapJob.END_TS_CONF, toUnsignedString(end));    conf.set(PcapJob.WIDTH_CONF, "" + PcapJob.findWidth(start, end, 10));    PcapJob.PcapPartitioner partitioner = new PcapJob.PcapPartitioner();    partitioner.setConf(conf);    Assert.assertThat("Partition not in range", partitioner.getPartition(new LongWritable(1473978789181189000L), new BytesWritable(), 10), equalTo(8));}
0
public void job_succeeds_synchronously() throws Exception
{    pageableResult = new PcapPages(Arrays.asList(new Path("1.txt"), new Path("2.txt"), new Path("3.txt")));    when(finalizer.finalizeJob(any())).thenReturn(pageableResult);    when(mrJob.isComplete()).thenReturn(true);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED);    when(mrJob.getStatus()).thenReturn(mrStatus);    Statusable<Path> statusable = testJob.submit(finalizer, config);    timer.updateJobStatus();    Pageable<Path> results = statusable.get();    Assert.assertThat(results.getSize(), equalTo(3));    JobStatus status = statusable.getStatus();    Assert.assertThat(status.getState(), equalTo(State.SUCCEEDED));    Assert.assertThat(status.getPercentComplete(), equalTo(100.0));    Assert.assertThat(status.getJobId(), equalTo(jobIdVal));}
0
public void job_fails_synchronously() throws Exception
{    when(mrJob.isComplete()).thenReturn(true);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.FAILED);    when(mrJob.getStatus()).thenReturn(mrStatus);    Statusable<Path> statusable = testJob.submit(finalizer, config);    timer.updateJobStatus();    Pageable<Path> results = statusable.get();    JobStatus status = statusable.getStatus();    Assert.assertThat(status.getState(), equalTo(State.FAILED));    Assert.assertThat(status.getPercentComplete(), equalTo(100.0));    Assert.assertThat(results.getSize(), equalTo(0));}
0
public void job_fails_with_killed_status_synchronously() throws Exception
{    when(mrJob.isComplete()).thenReturn(true);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.KILLED);    when(mrJob.getStatus()).thenReturn(mrStatus);    Statusable<Path> statusable = testJob.submit(finalizer, config);    timer.updateJobStatus();    Pageable<Path> results = statusable.get();    JobStatus status = statusable.getStatus();    Assert.assertThat(status.getState(), equalTo(State.KILLED));    Assert.assertThat(status.getPercentComplete(), equalTo(100.0));    Assert.assertThat(results.getSize(), equalTo(0));}
0
public void job_succeeds_asynchronously() throws Exception
{    when(mrJob.isComplete()).thenReturn(true);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED);    when(mrJob.getStatus()).thenReturn(mrStatus);    Statusable<Path> statusable = testJob.submit(finalizer, config);    timer.updateJobStatus();    JobStatus status = statusable.getStatus();    Assert.assertThat(status.getState(), equalTo(State.SUCCEEDED));    Assert.assertThat(status.getPercentComplete(), equalTo(100.0));}
0
public void job_reports_percent_complete() throws Exception
{    when(mrJob.isComplete()).thenReturn(false);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.RUNNING);    when(mrJob.getStatus()).thenReturn(mrStatus);    when(mrJob.mapProgress()).thenReturn(0.5f);    when(mrJob.reduceProgress()).thenReturn(0f);    Statusable<Path> statusable = testJob.submit(finalizer, config);    timer.updateJobStatus();    JobStatus status = statusable.getStatus();    Assert.assertThat(status.getState(), equalTo(State.RUNNING));    Assert.assertThat(status.getDescription(), equalTo("map: 50.0%, reduce: 0.0%"));    Assert.assertThat(status.getPercentComplete(), equalTo(25.0 * 0.75));    when(mrJob.mapProgress()).thenReturn(1.0f);    when(mrJob.reduceProgress()).thenReturn(0.5f);    timer.updateJobStatus();    status = statusable.getStatus();    Assert.assertThat(status.getDescription(), equalTo("map: 100.0%, reduce: 50.0%"));    Assert.assertThat(status.getPercentComplete(), equalTo(75.0 * 0.75));    when(mrJob.mapProgress()).thenReturn(1.0f);    when(mrJob.reduceProgress()).thenReturn(1.0f);    timer.updateJobStatus();    status = statusable.getStatus();    Assert.assertThat(status.getDescription(), equalTo("map: 100.0%, reduce: 100.0%"));    Assert.assertThat(status.getPercentComplete(), equalTo(75.0));    when(mrJob.isComplete()).thenReturn(true);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED);    when(mrJob.mapProgress()).thenReturn(1.0f);    when(mrJob.reduceProgress()).thenReturn(1.0f);    timer.updateJobStatus();    status = statusable.getStatus();    Assert.assertThat(status.getDescription(), equalTo("Job completed."));    Assert.assertThat(status.getPercentComplete(), equalTo(100.0));}
0
public void killing_job_causes_status_to_return_KILLED_state() throws Exception
{    when(mrJob.isComplete()).thenReturn(false);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.RUNNING);    when(mrJob.getStatus()).thenReturn(mrStatus);    Statusable<Path> statusable = testJob.submit(finalizer, config);    statusable.kill();    when(mrJob.isComplete()).thenReturn(true);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.KILLED);    timer.updateJobStatus();    JobStatus status = statusable.getStatus();    Assert.assertThat(status.getState(), equalTo(State.KILLED));}
0
public void handles_null_values_with_defaults() throws Exception
{    PcapOptions.START_TIME_NS.put(config, null);    PcapOptions.END_TIME_NS.put(config, null);    PcapOptions.NUM_REDUCERS.put(config, null);    PcapOptions.NUM_RECORDS_PER_FILE.put(config, null);    pageableResult = new PcapPages(Arrays.asList(new Path("1.txt"), new Path("2.txt"), new Path("3.txt")));    when(finalizer.finalizeJob(any())).thenReturn(pageableResult);    when(mrJob.isComplete()).thenReturn(true);    when(mrStatus.getState()).thenReturn(org.apache.hadoop.mapreduce.JobStatus.State.SUCCEEDED);    when(mrJob.getStatus()).thenReturn(mrStatus);    Statusable<Path> statusable = testJob.submit(finalizer, config);    timer.updateJobStatus();    Pageable<Path> results = statusable.get();    Assert.assertThat(results.getSize(), equalTo(3));    JobStatus status = statusable.getStatus();    Assert.assertThat(status.getState(), equalTo(State.SUCCEEDED));    Assert.assertThat(status.getPercentComplete(), equalTo(100.0));    Assert.assertThat(status.getJobId(), equalTo(jobIdVal));}
0
public void get_should_print_status() throws Exception
{    Map<String, Object> configuration = new HashMap<>();    testJob.setConfiguration(configuration);    testJob.setMrJob(mrJob);    testJob.setJobStatus(new JobStatus().withState(State.SUCCEEDED));    testJob.get();    verify(mrJob, times(0)).monitorAndPrintJob();    PcapOptions.PRINT_JOB_STATUS.put(configuration, true);    testJob.get();    verify(mrJob, times(1)).monitorAndPrintJob();    verifyNoMoreInteractions(mrJob);}
0
public boolean evaluate(String pattern, byte[] data)
{    return evaluator.evaluate(pattern, data);}
0
public static Collection<Object[]> strategies()
{    List<Object[]> strategies = new ArrayList<>();    for (EvaluationStrategy s : EvaluationStrategy.values()) {        strategies.add(new Object[] { s });    }    return strategies;}
0
public void testStringMatch() throws ExecutionException
{    Assert.assertTrue(strategy.evaluate("`metron`", "metron".getBytes(StandardCharsets.UTF_8)));    Assert.assertTrue(strategy.evaluate("`metron`", "metron example".getBytes(StandardCharsets.UTF_8)));    Assert.assertTrue(strategy.evaluate("`metron`", "edward metron example".getBytes(StandardCharsets.UTF_8)));    Assert.assertFalse(strategy.evaluate("`metron`", "apache".getBytes(StandardCharsets.UTF_8)));}
0
public void testBytesMatch() throws ExecutionException
{    Assert.assertTrue(strategy.evaluate("2f56abd814bc56420489ca38e7faf8cec3d4", REALPACKET));    Assert.assertTrue(strategy.evaluate("2f56..14bc56420489ca38e7faf8cec3d4", REALPACKET));    Assert.assertTrue(strategy.evaluate("(2f56)(.){2}(14bc56420489ca38e7faf8cec3d4)", REALPACKET));    Assert.assertFalse(strategy.evaluate("(3f56)(.){2}(14bc56420489ca38e7faf8cec3d4)", REALPACKET));    Assert.assertFalse(strategy.evaluate("3f56abd814bc56420489ca38e7faf8cec3d4", REALPACKET));    Assert.assertTrue(strategy.evaluate("deadbeef", join(DEADBEEF, "metron".getBytes(StandardCharsets.UTF_8))));    Assert.assertTrue(strategy.evaluate("deadbeef", join(DEADBEEF, "metron".getBytes(StandardCharsets.UTF_8))));    Assert.assertTrue(strategy.evaluate("deadbeef `metron`", join(DEADBEEF, "metron".getBytes(StandardCharsets.UTF_8))));    Assert.assertTrue(strategy.evaluate("deadbeef `metron`", join(DEADBEEF, "metronjones".getBytes(StandardCharsets.UTF_8))));    Assert.assertTrue(strategy.evaluate("deadbeef `metron`", join(DEADBEEF, "metronjones".getBytes(StandardCharsets.UTF_8), DEADBEEF)));    Assert.assertTrue(strategy.evaluate("([ff]){4}", ALLFS));    Assert.assertFalse(strategy.evaluate("([ff]){6}", ALLFS));    Assert.assertTrue(strategy.evaluate("[^ff]", new byte[] { (byte) 0x00 }));    Assert.assertTrue(strategy.evaluate("&01", new byte[] { (byte) 0x07 }));    Assert.assertFalse(strategy.evaluate("&01", new byte[] { (byte) 0x00 }));    Assert.assertTrue(strategy.evaluate("&01", new byte[] { (byte) 0x00, (byte) 0x01 }));    Assert.assertTrue(strategy.evaluate("(dead).{2}(beef)", DEADBEEF_DONUTHOLE));}
0
public byte[] join(byte[]... array)
{    byte[] ret;    int size = 0;    for (int i = 0; i < array.length; ++i) {        size += array[i].length;    }    ret = new byte[size];    int j = 0;    for (int i = 0; i < array.length; ++i) {        for (int k = 0; k < array[i].length; ++k, ++j) {            ret[j] = array[i][k];        }    }    return ret;}
0
public void extracts_info_from_filename()
{    {        String pcapFilename = "pcap_pcap128_1494962815457986000_18_pcap-63-1495027314";        assertThat(PcapFilenameHelper.getKafkaTopic(pcapFilename), equalTo("pcap128"));        assertThat(Long.compareUnsigned(PcapFilenameHelper.getTimestamp(pcapFilename), 1494962815457986000L), equalTo(0));        assertThat(PcapFilenameHelper.getKafkaPartition(pcapFilename), equalTo(18));        assertThat(PcapFilenameHelper.getUUID(pcapFilename), equalTo("pcap-63-1495027314"));    }    {        String pcapFilename = "pcap_pcap-128_1494962815457986000_18_pcap-63-1495027314";        assertThat(PcapFilenameHelper.getKafkaTopic(pcapFilename), equalTo("pcap-128"));        assertThat(Long.compareUnsigned(PcapFilenameHelper.getTimestamp(pcapFilename), 1494962815457986000L), equalTo(0));    }    {        String pcapFilename = "pcap_pcap_128_1494962815457986000_18_pcap-63-1495027314";        assertThat(PcapFilenameHelper.getKafkaTopic(pcapFilename), equalTo("pcap_128"));        assertThat(Long.compareUnsigned(PcapFilenameHelper.getTimestamp(pcapFilename), 1494962815457986000L), equalTo(0));    }    {        String pcapFilename = "pcap_pcap___128___1494962815457986000_18_pcap-63-1495027314";        assertThat(PcapFilenameHelper.getKafkaTopic(pcapFilename), equalTo("pcap___128__"));        assertThat(Long.compareUnsigned(PcapFilenameHelper.getTimestamp(pcapFilename), 1494962815457986000L), equalTo(0));    }    {        String pcapFilename = "pcap___pcap___128___1494962815457986000_18_pcap-63-1495027314";        assertThat(PcapFilenameHelper.getKafkaTopic(pcapFilename), equalTo("__pcap___128__"));        assertThat(Long.compareUnsigned(PcapFilenameHelper.getTimestamp(pcapFilename), 1494962815457986000L), equalTo(0));    }}
0
public void extracts_null_info_from_bad_filename_parts()
{    String pcapFilename = "pcap_pcap128_AAA4962815457986000_BB_pcap-63-1495027314";    assertThat(PcapFilenameHelper.getTimestamp(pcapFilename), equalTo(null));    assertThat(PcapFilenameHelper.getKafkaPartition(pcapFilename), equalTo(null));}
0
public static List<byte[]> readSamplePackets(String pcapLoc) throws IOException
{    SequenceFile.Reader reader = new SequenceFile.Reader(new Configuration(), SequenceFile.Reader.file(new Path(pcapLoc)));    List<byte[]> ret = new ArrayList<>();    IntWritable key = new IntWritable();    BytesWritable value = new BytesWritable();    while (reader.next(key, value)) {        byte[] pcapWithHeader = value.copyBytes();        ret.add(pcapWithHeader);    }    return ret;}
0
public static byte[] stripHeaders(byte[] pcap)
{    byte[] ret = new byte[pcap.length - PcapHelper.GLOBAL_HEADER_SIZE - PcapHelper.PACKET_HEADER_SIZE];    int offset = PcapHelper.GLOBAL_HEADER_SIZE + PcapHelper.PACKET_HEADER_SIZE;    System.arraycopy(pcap, offset, ret, 0, ret.length);    return ret;}
0
public void testLittleEndianHeaderization() throws Exception
{    String pcapSampleFiles = "../metron-integration-test/src/main/sample/data/SampleInput/PCAPExampleOutput";    List<byte[]> pcaps = readSamplePackets(pcapSampleFiles);    for (byte[] pcap : pcaps) {        long ts = PcapHelper.getTimestamp(pcap);        byte[] stripped = stripHeaders(pcap);        byte[] reconstitutedPacket = PcapHelper.addGlobalHeader(PcapHelper.addPacketHeader(ts, stripped, Endianness.getNativeEndianness()), Endianness.getNativeEndianness());        if (!Arrays.equals(reconstitutedPacket, pcap)) {            int eSecs = Bytes.toInt(pcap, 25);            int rSec = Bytes.toInt(reconstitutedPacket, 25);            System.out.println(eSecs + " vs " + rSec);            for (int i = 0; i < reconstitutedPacket.length; ++i) {                System.out.println((i + 1) + ". " + String.format("%02X", pcap[i]) + " = " + String.format("%02X", reconstitutedPacket[i]));            }            Assert.assertArrayEquals(reconstitutedPacket, pcap);        }    }}
0
public void packetToFieldsShouldProperlyParserTcpPackets() throws Exception
{    PacketInfo packetInfo = mock(PacketInfo.class);    when(packetInfo.getPacketBytes()).thenReturn("packet bytes".getBytes(StandardCharsets.UTF_8));    TcpPacket tcpPacket = mock(TcpPacket.class);        InetAddress tcpSourceInetAddress = mock(InetAddress.class);    when(tcpSourceInetAddress.getHostAddress()).thenReturn("tcp source address");    when(tcpPacket.getSourceAddress()).thenReturn(tcpSourceInetAddress);    InetSocketAddress tcpSourceInetSocketAddress = new InetSocketAddress(22);    when(tcpPacket.getSource()).thenReturn(tcpSourceInetSocketAddress);        InetAddress tcpDestinationInetAddress = mock(InetAddress.class);    when(tcpDestinationInetAddress.getHostAddress()).thenReturn("tcp destination address");    when(tcpPacket.getDestinationAddress()).thenReturn(tcpDestinationInetAddress);    InetSocketAddress tcpDestinationInetSocketAddress = new InetSocketAddress(55791);    when(tcpPacket.getDestination()).thenReturn(tcpDestinationInetSocketAddress);    when(packetInfo.getTcpPacket()).thenReturn(tcpPacket);    Ipv4Packet ipv4Packet = mock(Ipv4Packet.class);    when(ipv4Packet.getProtocol()).thenReturn(6);    when(packetInfo.getIpv4Packet()).thenReturn(ipv4Packet);    Map<String, Object> actualFields = PcapHelper.packetToFields(packetInfo);    Assert.assertArrayEquals("packet bytes".getBytes(StandardCharsets.UTF_8), (byte[]) actualFields.get(PcapHelper.PacketFields.PACKET_DATA.getName()));    Assert.assertEquals("tcp source address", actualFields.get(Fields.SRC_ADDR.getName()));    Assert.assertEquals(22, actualFields.get(Fields.SRC_PORT.getName()));    Assert.assertEquals("tcp destination address", actualFields.get(Fields.DST_ADDR.getName()));    Assert.assertEquals(55791, actualFields.get(Fields.DST_PORT.getName()));    Assert.assertEquals(6, actualFields.get(Fields.PROTOCOL.getName()));}
0
public void packetToFieldsShouldProperlyParserUdpPackets() throws Exception
{    PacketInfo packetInfo = mock(PacketInfo.class);    when(packetInfo.getPacketBytes()).thenReturn("packet bytes".getBytes(StandardCharsets.UTF_8));    UdpPacket udpPacket = mock(UdpPacket.class);        InetAddress udpSourceInetAddress = mock(InetAddress.class);    when(udpSourceInetAddress.getHostAddress()).thenReturn("udp source address");    InetSocketAddress udpSourceInetSocketAddress = new InetSocketAddress(udpSourceInetAddress, 68);    when(udpPacket.getSource()).thenReturn(udpSourceInetSocketAddress);        InetAddress udpDestinationInetAddress = mock(InetAddress.class);    when(udpDestinationInetAddress.getHostAddress()).thenReturn("udp destination address");    InetSocketAddress udpDestinationInetSocketAddress = new InetSocketAddress(udpDestinationInetAddress, 67);    when(udpPacket.getDestination()).thenReturn(udpDestinationInetSocketAddress);    when(packetInfo.getUdpPacket()).thenReturn(udpPacket);    Ipv4Packet ipv4Packet = mock(Ipv4Packet.class);    when(ipv4Packet.getProtocol()).thenReturn(17);    when(packetInfo.getIpv4Packet()).thenReturn(ipv4Packet);    Map<String, Object> actualFields = PcapHelper.packetToFields(packetInfo);    Assert.assertArrayEquals("packet bytes".getBytes(StandardCharsets.UTF_8), (byte[]) actualFields.get(PcapHelper.PacketFields.PACKET_DATA.getName()));    Assert.assertEquals("udp source address", actualFields.get(Fields.SRC_ADDR.getName()));    Assert.assertEquals(68, actualFields.get(Fields.SRC_PORT.getName()));    Assert.assertEquals("udp destination address", actualFields.get(Fields.DST_ADDR.getName()));    Assert.assertEquals(67, actualFields.get(Fields.DST_PORT.getName()));    Assert.assertEquals(17, actualFields.get(Fields.PROTOCOL.getName()));}
0
public void testEqual() throws ParseException
{    PacketHeader ph = new PacketHeader((int) JULY_26_SECONDS, 0, 0, 0);    PcapPacket packet = new PcapPacket(ph, EMPTY_PAYLOAD);    PacketHeader ph2 = new PacketHeader((int) JULY_26_SECONDS, 0, 0, 0);    PcapPacket packet2 = new PcapPacket(ph2, EMPTY_PAYLOAD);    assertEquals("Timestamps should be equal", comp.compare(packet, packet2), 0);    assertEquals("Timestamps should be equal", comp.compare(packet2, packet), 0);}
0
public void testDifferingSeconds() throws ParseException
{    PacketHeader ph = new PacketHeader((int) JULY_26_SECONDS, 0, 0, 0);    PcapPacket earlier = new PcapPacket(ph, EMPTY_PAYLOAD);    PacketHeader ph2 = new PacketHeader((int) JULY_26_PLUS_ONE_SECOND_SECONDS, 0, 0, 0);    PcapPacket later = new PcapPacket(ph2, EMPTY_PAYLOAD);    PcapPacketComparator comp = new PcapPacketComparator();    assertTrue("Earlier should be less than later", comp.compare(earlier, later) < 0);    assertTrue("Later should be greater than earlier", comp.compare(later, earlier) > 0);}
0
public void testDifferingMicroseconds() throws ParseException
{    PacketHeader ph = new PacketHeader((int) JULY_26_SECONDS, 0, 0, 0);    PcapPacket earlier = new PcapPacket(ph, EMPTY_PAYLOAD);    PacketHeader ph2 = new PacketHeader((int) JULY_26_SECONDS, 1, 0, 0);    PcapPacket later = new PcapPacket(ph2, EMPTY_PAYLOAD);    PcapPacketComparator comp = new PcapPacketComparator();    assertTrue("Earlier should be less than later", comp.compare(earlier, later) < 0);    assertTrue("Later should be greater than earlier", comp.compare(later, earlier) > 0);}
0
public void testBothSmallDifferences() throws ParseException
{    PacketHeader ph = new PacketHeader((int) JULY_26_SECONDS, 0, 0, 0);    PcapPacket earlier = new PcapPacket(ph, EMPTY_PAYLOAD);    PacketHeader ph2 = new PacketHeader((int) JULY_26_PLUS_ONE_SECOND_SECONDS, 1, 0, 0);    PcapPacket later = new PcapPacket(ph2, EMPTY_PAYLOAD);    PcapPacketComparator comp = new PcapPacketComparator();    assertTrue("Earlier should be less than later", comp.compare(earlier, later) < 0);    assertTrue("Later should be greater than earlier", comp.compare(later, earlier) > 0);}
0
public void testLargeDifference() throws ParseException
{    PacketHeader ph = new PacketHeader((int) JULY_26_SECONDS, 0, 0, 0);    PcapPacket earlier = new PcapPacket(ph, EMPTY_PAYLOAD);    PacketHeader ph2 = new PacketHeader((int) JULY_26_PLUS_TWENTY_YEARS_SECONDS, 999999, 0, 0);    PcapPacket later = new PcapPacket(ph2, EMPTY_PAYLOAD);    PcapPacketComparator comp = new PcapPacketComparator();    assertTrue("Earlier should be less than later", comp.compare(earlier, later) < 0);    assertTrue("Later should be greater than earlier", comp.compare(later, earlier) > 0);}
0
public void iterates_paths()
{    Path path1 = new Path("/1.txt");    Path path2 = new Path("/2.txt");    Path path3 = new Path("/3.txt");    List<Path> paths = new ArrayList<>();    paths.add(path1);    paths.add(path2);    paths.add(path3);    PcapPages pages = new PcapPages(paths);    assertThat("Wrong num pages.", pages.getSize(), equalTo(3));    for (int i = 0; i < pages.getSize(); i++) {        assertThat("Page should be equal", pages.getPage(i).toString(), equalTo(paths.get(i).toString()));    }}
0
public void clones_with_copy_constructor()
{    Path path1 = new Path("/1.txt");    Path path2 = new Path("/2.txt");    Path path3 = new Path("/3.txt");    List<Path> paths = new ArrayList<>();    paths.add(path1);    paths.add(path2);    paths.add(path3);    PcapPages pages = new PcapPages(paths);    PcapPages clonedPages = new PcapPages(pages);    assertThat(clonedPages, notNullValue());    assertThat(clonedPages.getSize(), equalTo(3));    assertThat(clonedPages, not(sameInstance(pages)));    for (int i = 0; i < pages.getSize(); i++) {        assertThat("Page should be different instance.", pages.getPage(i), not(sameInstance(clonedPages.getPage(i))));        assertThat("Page should be same path.", pages.getPage(i), equalTo(clonedPages.getPage(i)));    }}
0
public void testConvertHexToIpv4Ip()
{    String hex = "c0a88a9e";    String ipAddress = PcapUtils.convertHexToIpv4Ip(hex);    Assert.assertEquals("192.168.138.158", ipAddress);}
0
public Options buildOptions()
{    Options options = new Options();    options.addOption(newOption("h", "help", false, "Display help"));    options.addOption(newOption("bp", "base_path", true, String.format("Base PCAP data path. Default is '%s'", BASE_INPUT_PATH_DEFAULT)));    options.addOption(newOption("bop", "base_output_path", true, String.format("Query result output path. Default is '%s'", BASE_INTERIM_RESULT_PATH_DEFAULT)));    options.addOption(newOption("st", "start_time", true, "(required) Packet start time range.", true));    options.addOption(newOption("nr", "num_reducers", true, String.format("Number of reducers to use (defaults to %s)", NUM_REDUCERS_DEFAULT)));    options.addOption(newOption("rpf", "records_per_file", true, String.format("Number of records to include in each output pcap file (defaults to %s)", NUM_RECORDS_PER_FILE_DEFAULT)));    options.addOption(newOption("et", "end_time", true, "Packet end time range. Default is current system time."));    options.addOption(newOption("df", "date_format", true, "Date format to use for parsing start_time and end_time. Default is to use time in millis since the epoch."));    options.addOption(newOption("yq", "yarn_queue", true, "Yarn queue this job will be submitted to"));    options.addOption(newOption("ft", "finalizer_threads", true, "Number of threads to use for the final output writing."));    return options;}
0
protected Option newOption(String opt, String longOpt, boolean hasArg, String desc)
{    return newOption(opt, longOpt, hasArg, desc, false);}
0
protected Option newOption(String opt, String longOpt, boolean hasArg, String desc, boolean required)
{    Option option = new Option(opt, longOpt, hasArg, desc);    option.setRequired(required);    return option;}
0
public void parse(CommandLine commandLine, PcapConfig config) throws java.text.ParseException
{    if (commandLine.hasOption("help")) {        config.setShowHelp(true);    }    if (commandLine.hasOption("date_format")) {        config.setDateFormat(commandLine.getOptionValue("date_format"));    }    if (commandLine.hasOption("base_path")) {        config.setBasePath(commandLine.getOptionValue("base_path"));    } else {        config.setBasePath(BASE_INPUT_PATH_DEFAULT);    }    if (commandLine.hasOption("base_output_path")) {        config.setBaseInterimResultPath(commandLine.getOptionValue("base_output_path"));    } else {        config.setBaseInterimResultPath(BASE_INTERIM_RESULT_PATH_DEFAULT);    }    if (commandLine.hasOption("start_time")) {        try {            if (commandLine.hasOption("date_format")) {                long startTime = config.getDateFormat().parse(commandLine.getOptionValue("start_time")).getTime();                config.setStartTimeMs(startTime);            } else {                long startTime = Long.parseLong(commandLine.getOptionValue("start_time"));                config.setStartTimeMs(startTime);            }        } catch (NumberFormatException nfe) {                }    }    if (commandLine.hasOption("num_reducers")) {        int numReducers = Integer.parseInt(commandLine.getOptionValue("num_reducers"));        config.setNumReducers(numReducers);    } else {        config.setNumReducers(NUM_REDUCERS_DEFAULT);    }    if (commandLine.hasOption("records_per_file")) {        int numRecordsPerFile = Integer.parseInt(commandLine.getOptionValue("records_per_file"));        config.setNumRecordsPerFile(numRecordsPerFile);    } else {        config.setNumRecordsPerFile(NUM_RECORDS_PER_FILE_DEFAULT);    }    if (commandLine.hasOption("end_time")) {        try {            if (commandLine.hasOption("date_format")) {                long endTime = config.getDateFormat().parse(commandLine.getOptionValue("end_time")).getTime();                config.setEndTimeMs(endTime);            } else {                long endTime = Long.parseLong(commandLine.getOptionValue("end_time"));                config.setEndTimeMs(endTime);            }        } catch (NumberFormatException nfe) {                }    }    if (commandLine.hasOption("yarn_queue")) {        config.setYarnQueue(commandLine.getOptionValue("yarn_queue"));    }    if (commandLine.hasOption("finalizer_threads")) {        String numThreads = commandLine.getOptionValue("finalizer_threads");        config.setFinalizerThreadpoolSize(numThreads);    } else {        config.setFinalizerThreadpoolSize(NUM_FINALIZER_THREADS_DEFAULT);    }}
0
public void printHelp(String msg, Options opts)
{    new HelpFormatter().printHelp(msg, opts);}
0
protected CommandLineParser getParser()
{    return parser;}
0
private Options buildFixedOptions()
{    Options options = buildOptions();    options.addOption(newOption("sa", "ip_src_addr", true, "Source IP address"));    options.addOption(newOption("da", "ip_dst_addr", true, "Destination IP address"));    options.addOption(newOption("sp", "ip_src_port", true, "Source port"));    options.addOption(newOption("dp", "ip_dst_port", true, "Destination port"));    options.addOption(newOption("p", "protocol", true, "IP Protocol"));    options.addOption(newOption("pf", "packet_filter", true, "Packet Filter regex"));    options.addOption(newOption("pre", "prefix", true, "Result file prefix to use"));    options.addOption(newOption("ir", "include_reverse", false, "Indicates if filter should check swapped src/dest addresses and IPs"));    return options;}
0
public FixedPcapConfig parse(String[] args) throws ParseException, java.text.ParseException
{    CommandLine commandLine = getParser().parse(fixedOptions, args);    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    super.parse(commandLine, config);    config.putFixedField(Constants.Fields.SRC_ADDR.getName(), commandLine.getOptionValue("ip_src_addr"));    config.putFixedField(Constants.Fields.DST_ADDR.getName(), commandLine.getOptionValue("ip_dst_addr"));    config.putFixedField(Constants.Fields.SRC_PORT.getName(), commandLine.getOptionValue("ip_src_port"));    config.putFixedField(Constants.Fields.DST_PORT.getName(), commandLine.getOptionValue("ip_dst_port"));    config.putFixedField(Constants.Fields.PROTOCOL.getName(), commandLine.getOptionValue("protocol"));    config.putFixedField(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), Boolean.toString(commandLine.hasOption("include_reverse")));    config.putFixedField(PcapHelper.PacketFields.PACKET_FILTER.getName(), commandLine.getOptionValue("packet_filter"));    if (commandLine.hasOption("prefix")) {        config.setFinalFilenamePrefix(commandLine.getOptionValue("prefix"));    }    return config;}
0
public void printHelp()
{    super.printHelp("Fixed filter options", fixedOptions);}
0
public static void main(String[] args)
{    int status = new PcapCli(new PcapJob(), PREFIX_STRATEGY).run(args);    System.exit(status);}
0
public int run(String[] args)
{    if (args.length < 1) {        printBasicHelp();        return -1;    }    String jobType = args[0];    String[] commandArgs = Arrays.copyOfRange(args, 1, args.length);    Configuration hadoopConf = new Configuration();    String[] otherArgs = null;    try {        otherArgs = new GenericOptionsParser(hadoopConf, commandArgs).getRemainingArgs();    } catch (IOException e) {                return -1;    }    PcapConfig commonConfig = null;    Pageable<Path> results;        String execDir = System.getProperty("user.dir");    if ("fixed".equals(jobType)) {        FixedCliParser fixedParser = new FixedCliParser(prefixStrategy);        FixedPcapConfig config = null;        try {            config = fixedParser.parse(otherArgs);            commonConfig = config;            PcapOptions.FINAL_OUTPUT_PATH.put(commonConfig, new Path(execDir));        } catch (ParseException | java.text.ParseException e) {            System.err.println(e.getMessage());            System.err.flush();            fixedParser.printHelp();            return -1;        }        if (config.showHelp()) {            fixedParser.printHelp();            return 0;        }        PcapOptions.FILTER_IMPL.put(commonConfig, new FixedPcapFilter.Configurator());        config.getYarnQueue().ifPresent(s -> hadoopConf.set(MRJobConfig.QUEUE_NAME, s));        PcapOptions.HADOOP_CONF.put(commonConfig, hadoopConf);        try {            PcapOptions.FILESYSTEM.put(commonConfig, FileSystem.get(hadoopConf));            results = jobRunner.submit(PcapFinalizerStrategies.CLI, commonConfig).get();        } catch (IOException | InterruptedException | JobException e) {                        return -1;        }    } else if ("query".equals(jobType)) {        QueryCliParser queryParser = new QueryCliParser(prefixStrategy);        QueryPcapConfig config = null;        try {            config = queryParser.parse(otherArgs);            commonConfig = config;            PcapOptions.FINAL_OUTPUT_PATH.put(commonConfig, new Path(execDir));        } catch (ParseException | java.text.ParseException e) {            System.err.println(e.getMessage());            queryParser.printHelp();            return -1;        }        if (config.showHelp()) {            queryParser.printHelp();            return 0;        }        PcapOptions.FILTER_IMPL.put(commonConfig, new FixedPcapFilter.Configurator());        config.getYarnQueue().ifPresent(s -> hadoopConf.set(MRJobConfig.QUEUE_NAME, s));        PcapOptions.HADOOP_CONF.put(commonConfig, hadoopConf);        try {            PcapOptions.FILESYSTEM.put(commonConfig, FileSystem.get(hadoopConf));            results = jobRunner.submit(PcapFinalizerStrategies.CLI, commonConfig).get();        } catch (IOException | InterruptedException | JobException e) {                        return -1;        }    } else {        printBasicHelp();        return -1;    }    return 0;}
1
private Pair<Long, Long> timeAsNanosecondsSinceEpoch(long start, long end)
{    long revisedStart = start;    if (revisedStart < 0) {        revisedStart = 0L;    }    long revisedEnd = end;    if (revisedEnd < 0) {        revisedEnd = System.currentTimeMillis();    }        revisedStart = TimestampConverters.MILLISECONDS.toNanoseconds(revisedStart);    revisedEnd = TimestampConverters.MILLISECONDS.toNanoseconds(revisedEnd);    return Pair.of(revisedStart, revisedEnd);}
0
public void printBasicHelp()
{    System.out.println("Usage: [fixed|query]");}
0
private Options setupOptions()
{    Options options = buildOptions();    options.addOption(newOption("q", "query", true, "Query string to use as a filter"));    options.addOption(newOption("pre", "prefix", true, "Result file prefix to use"));    return options;}
0
public QueryPcapConfig parse(String[] args) throws ParseException, java.text.ParseException
{    CommandLine commandLine = getParser().parse(queryOptions, args);    QueryPcapConfig config = new QueryPcapConfig(prefixStrategy);    super.parse(commandLine, config);    if (commandLine.hasOption("query")) {        config.setQuery(commandLine.getOptionValue("query"));    }    if (commandLine.hasOption("prefix")) {        config.setFinalFilenamePrefix(commandLine.getOptionValue("prefix"));    }    return config;}
0
public void printHelp()
{    super.printHelp("Query filter options", queryOptions);}
0
public static KeyValueDeserializer create(String scheme, TimestampConverter converter)
{    try {        Deserializers ts = Deserializers.valueOf(scheme.toUpperCase());        return ts.creator.apply(converter);    } catch (IllegalArgumentException iae) {        return Deserializers.FROM_KEY.creator.apply(converter);    }}
0
public static KeyValueDeserializer create(String scheme, String converter)
{    return create(scheme, TimestampConverters.getConverter(converter));}
0
public Result deserializeKeyValue(byte[] key, byte[] value)
{    if (key == null) {        throw new IllegalArgumentException("Expected a key but none provided");    }    long ts = converter.toNanoseconds(fromBytes(key));    return new Result(ts, PcapHelper.addHeaders(ts, value, endianness), true);}
0
private static long fromBytes(byte[] data)
{    long value = 0L;    int len = data.length;    for (int i = 0; i < len; ++i) {        byte b = data[i];                value <<= 8;                value |= (long) (b & 255);    }    return value;}
0
public Result deserializeKeyValue(byte[] key, byte[] value)
{    Long ts = PcapHelper.getTimestamp(value);    if (ts != null) {        return new Result(ts, value, true);    } else {        return new Result(ts, value, false);    }}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Partition partition1 = (Partition) o;    if (partition != partition1.partition)        return false;    return topic != null ? topic.equals(partition1.topic) : partition1.topic == null;}
0
public int hashCode()
{    int result = topic != null ? topic.hashCode() : 0;    result = 31 * result + partition;    return result;}
0
public String toString()
{    return "Partition{" + "topic='" + topic + '\'' + ", partition=" + partition + '}';}
0
public HDFSWriterCallback withConfig(HDFSWriterConfig config)
{        this.config = config;    return this;}
1
public List<Object> apply(List<Object> tuple, EmitContext context)
{    byte[] key = (byte[]) tuple.get(0);    byte[] value = (byte[]) tuple.get(1);    long tsDeserializeStart = System.nanoTime();    KeyValueDeserializer.Result result = config.getDeserializer().deserializeKeyValue(key, value);    long tsDeserializeEnd = System.nanoTime();    if (LOG.isDebugEnabled() && !result.foundTimestamp) {        List<String> debugStatements = new ArrayList<>();        if (key != null) {            debugStatements.add("Key length: " + key.length);            debugStatements.add("Key: " + DatatypeConverter.printHexBinary(key));        } else {            debugStatements.add("Key is null!");        }        if (value != null) {            debugStatements.add("Value length: " + value.length);            debugStatements.add("Value: " + DatatypeConverter.printHexBinary(value));        } else {            debugStatements.add("Value is null!");        }            }    long tsWriteStart = System.nanoTime();    try {        getWriter(new Partition(topic, context.get(EmitContext.Type.PARTITION))).handle(result.key, result.value);    } catch (IOException e) {                }    long tsWriteEnd = System.nanoTime();    if (LOG.isDebugEnabled() && (Math.random() < 0.001 || !inited)) {                    }    inited = true;    return tuple;}
1
private PartitionHDFSWriter getWriter(Partition partition)
{        if (lastWriter != null && lastWriter.getTopic().equals(partition.topic) && lastWriter.getPartition() == partition.partition) {        return lastWriter;    }    lastWriter = writers.get(partition);    if (lastWriter == null) {        lastWriter = new PartitionHDFSWriter(partition.topic, partition.partition, context.get(EmitContext.Type.UUID), config);        writers.put(partition, lastWriter);    }    return lastWriter;}
0
public void initialize(EmitContext context)
{    this.context = context;    KafkaSpoutConfig spoutConfig = context.get(EmitContext.Type.SPOUT_CONFIG);    if (spoutConfig != null && spoutConfig.getSubscription() != null) {        this.topic = spoutConfig.getSubscription().getTopicsString();        if (this.topic.length() > 0) {            int len = this.topic.length();            if (this.topic.charAt(0) == '[' && this.topic.charAt(len - 1) == ']') {                this.topic = this.topic.substring(1, len - 1);            }        }    } else {        throw new IllegalStateException("Unable to initialize, because spout config is not correctly specified");    }}
0
public void close() throws Exception
{    for (PartitionHDFSWriter writer : writers.values()) {        writer.close();    }}
0
public HDFSWriterConfig withDeserializer(String deserializer, String timestampConverter)
{    this.deserializer = Deserializers.create(deserializer, timestampConverter);    return this;}
0
public HDFSWriterConfig withOutputPath(String path)
{    outputPath = path;    return this;}
0
public HDFSWriterConfig withNumPackets(long n)
{    numPackets = n;    return this;}
0
public HDFSWriterConfig withSyncEvery(int n)
{    syncEvery = n;    return this;}
0
public HDFSWriterConfig withHDFSConfig(Map<String, Object> config)
{    hdfsConfig = config;    return this;}
0
public HDFSWriterConfig withReplicationFactor(int n)
{    replicationFactor = n;    return this;}
0
public HDFSWriterConfig withMaxTimeMS(long t)
{    maxTimeNS = TimestampConverters.MILLISECONDS.toNanoseconds(t);    return this;}
0
public HDFSWriterConfig withZookeeperQuorum(String zookeeperQuorum)
{    this.zookeeperQuorum = zookeeperQuorum;    return this;}
0
public List<String> getZookeeperServers()
{    List<String> out = new ArrayList<>();    if (zookeeperQuorum != null) {        for (String hostPort : Splitter.on(',').split(zookeeperQuorum)) {            Iterable<String> tokens = Splitter.on(':').split(hostPort);            String host = Iterables.getFirst(tokens, null);            if (host != null) {                out.add(host);            }        }    }    return out;}
0
public Map<String, Object> getHDFSConfig()
{    return hdfsConfig;}
0
public Integer getZookeeperPort()
{    if (zookeeperQuorum != null) {        String hostPort = Iterables.getFirst(Splitter.on(',').split(zookeeperQuorum), null);        String portStr = Iterables.getLast(Splitter.on(':').split(hostPort));        return Integer.parseInt(portStr);    }    return null;}
0
public int getSyncEvery()
{    return syncEvery;}
0
public int getReplicationFactor()
{    return replicationFactor;}
0
public KeyValueDeserializer getDeserializer()
{    return deserializer;}
0
public String getOutputPath()
{    return outputPath;}
0
public long getNumPackets()
{    return numPackets;}
0
public long getMaxTimeNS()
{    return maxTimeNS;}
0
public String toString()
{    return "HDFSWriterConfig{" + "numPackets=" + numPackets + ", maxTimeNS=" + maxTimeNS + ", outputPath='" + outputPath + '\'' + '}';}
0
protected List<Object> initialValue()
{    return new ArrayList<>();}
0
protected Callback createCallback(Class<? extends Callback> callbackClass)
{    return new HDFSWriterCallback().withConfig(config);}
0
private void clearMessagesToBeAcked()
{    for (Object messageId : messagesToBeAcked.get()) {        super.ack(messageId);    }    messagesToBeAcked.get().clear();}
0
public void nextTuple()
{    /*    This bears some explanation; nextTuple for a spout-only topology sans ackers, will ack as part of the emit method.    The unfortunate part about this is that this will prevent the internal bookeeping of the KafkaSpout to keep add the     message ID to the offsets to commit.  This is because it thinks it is not emitted by the time it gets to ack (because     ack is called *within* emit).  The result is that no offsets are acked.     What we have here is a correction.  The ack method will add the message ID to a queue to be acked and then at the end     of nextTuple, we will clear the cache and ack.  The net result is that the contract is adhered to for spout-only topologies,     ack happens in nextTuple().     */    super.nextTuple();    clearMessagesToBeAcked();}
0
public void ack(Object messageId)
{    messagesToBeAcked.get().add(messageId);}
0
public void close()
{    try {        clearMessagesToBeAcked();    } finally {        super.close();    }}
0
private SyncHandler getHandler()
{    return func;}
0
public void sync(FSDataOutputStream input)
{    try {        func.sync(input);    } catch (IOException ioe) {            }}
1
public void sync(FSDataOutputStream outputStream) throws IOException
{    outputStream.hflush();    outputStream.hsync();}
0
public void sync(FSDataOutputStream outputStream) throws IOException
{    outputStream.hflush();    outputStream.hsync();    ((HdfsDataOutputStream) outputStream).hsync(EnumSet.of(HdfsDataOutputStream.SyncFlag.UPDATE_LENGTH));}
0
public void sync(FSDataOutputStream outputStream) throws IOException
{    outputStream.getWrappedStream().flush();    outputStream.getWrappedStream();}
0
public String timestampToString(long ts)
{    return Long.toUnsignedString(ts);}
0
public void handle(long ts, byte[] value) throws IOException
{    turnoverIfNecessary(ts);    BytesWritable bw = new BytesWritable(value);    try {        writer.append(new LongWritable(ts), bw);    } catch (ArrayIndexOutOfBoundsException aioobe) {            }    numWritten++;    if (numWritten % config.getSyncEvery() == 0) {        syncHandler.sync(outputStream);    }}
1
public String getTopic()
{    return topic;}
0
public int getPartition()
{    return partition;}
0
public void close() throws IOException
{    if (writer != null) {        writer.close();    }    if (outputStream != null) {        outputStream.close();    }}
0
private Path getPath(long ts)
{    String fileName = PcapHelper.toFilename(topic, ts, partition + "", uuid);    return new Path(config.getOutputPath(), fileName);}
0
private void turnoverIfNecessary(long ts) throws IOException
{    turnoverIfNecessary(ts, false);}
0
private void turnoverIfNecessary(long ts, boolean force) throws IOException
{    long duration = ts - batchStartTime;    boolean initial = outputStream == null;    boolean overDuration = config.getMaxTimeNS() <= 0 ? false : Long.compareUnsigned(duration, config.getMaxTimeNS()) >= 0;    boolean tooManyPackets = numWritten >= config.getNumPackets();    if (force || initial || overDuration || tooManyPackets) {                Path path = getPath(ts);        close();        if (fs instanceof LocalFileSystem) {            outputStream = new FSDataOutputStream(new FileOutputStream(new File(path.toString())));            syncHandler = SyncHandlers.LOCAL.getHandler();        } else {            outputStream = fs.create(path, true);            if (outputStream instanceof HdfsDataOutputStream) {                if (initial) {                                    }                syncHandler = SyncHandlers.HDFS.getHandler();            } else {                if (initial) {                                    }                syncHandler = SyncHandlers.DEFAULT.getHandler();            }        }        writer = SequenceFile.createWriter(this.fsConfig, SequenceFile.Writer.keyClass(LongWritable.class), SequenceFile.Writer.valueClass(BytesWritable.class), SequenceFile.Writer.stream(outputStream), SequenceFile.Writer.compression(SequenceFile.CompressionType.NONE));                        batchStartTime = ts;        numWritten = 0;    }}
1
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (InspectorOptions.HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("PcapInspector", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (InspectorOptions o : InspectorOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public Option apply(@Nullable String s)
{    return new Option(s, "help", false, "Generate Help screen");}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "input", true, "Input sequence file on HDFS");    o.setArgName("SEQ_FILE");    o.setRequired(true);    return o;}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "num_packets", true, "Number of packets to dump");    o.setArgName("N");    o.setRequired(false);    return o;}
0
public static void main(String... argv) throws IOException
{    Configuration conf = new Configuration();    String[] otherArgs = new GenericOptionsParser(conf, argv).getRemainingArgs();    CommandLine cli = InspectorOptions.parse(new PosixParser(), otherArgs);    Path inputPath = new Path(InspectorOptions.INPUT.get(cli));    int n = -1;    if (InspectorOptions.NUM.has(cli)) {        n = Integer.parseInt(InspectorOptions.NUM.get(cli));    }    SequenceFile.Reader reader = new SequenceFile.Reader(new Configuration(), SequenceFile.Reader.file(inputPath));    LongWritable key = new LongWritable();    BytesWritable value = new BytesWritable();    for (int i = 0; (n < 0 || i < n) && reader.next(key, value); ++i) {        long millis = Long.divideUnsigned(key.get(), 1000000);        String ts = DATE_FORMAT.format(new Date(millis));        try {            for (PacketInfo pi : PcapHelper.toPacketInfo(value.copyBytes())) {                Map<String, Object> result = PcapHelper.packetToFields(pi);                List<String> fieldResults = new ArrayList<String>() {                    {                        add("TS: " + ts);                    }                };                for (Constants.Fields field : Constants.Fields.values()) {                    if (result.containsKey(field.getName())) {                        fieldResults.add(field.getName() + ": " + result.get(field.getName()));                    }                }                System.out.println(Joiner.on(",").join(fieldResults));            }        } catch (Exception e) {            System.out.println(String.format("Error: malformed packet #=%s, ts=%s, error msg=%s", i + 1, ts, e.getMessage()));        }    }}
0
private static void clearOutDirs(File... dirs) throws IOException
{    for (File dir : dirs) {        for (File f : dir.listFiles()) {            if (f.isDirectory()) {                FileUtils.deleteDirectory(f);            } else {                f.delete();            }        }    }}
0
private static int numFiles(File outDir, Configuration config)
{    return outDir.list(new FilenameFilter() {        @Override        public boolean accept(File dir, String name) {            return !name.endsWith(".crc");        }    }).length;}
0
public boolean accept(File dir, String name)
{    return !name.endsWith(".crc");}
0
public void testTimestampInPacket() throws Exception
{    setupTopology(new Function<Properties, Void>() {        @Nullable        @Override        public Void apply(@Nullable Properties input) {            input.setProperty("kafka.pcap.ts_scheme", Deserializers.FROM_PACKET.toString());            return null;        }    }, (kafkaComponent, pcapEntries) -> kafkaComponent.writeMessages(KAFKA_TOPIC, Collections2.transform(pcapEntries, input -> input.getValue())), true);}
0
public Void apply(@Nullable Properties input)
{    input.setProperty("kafka.pcap.ts_scheme", Deserializers.FROM_PACKET.toString());    return null;}
0
public static void setupAll() throws Exception
{    System.out.println("Setting up test components");    withHeaders = false;    setupTopology(new Function<Properties, Void>() {        @Nullable        @Override        public Void apply(@Nullable Properties input) {            input.setProperty("kafka.pcap.ts_scheme", Deserializers.FROM_KEY.toString());            return null;        }    }, new SendEntries() {        @Override        public void send(KafkaComponent kafkaComponent, List<Map.Entry<byte[], byte[]>> pcapEntries) throws Exception {            Producer<byte[], byte[]> producer = kafkaComponent.createProducer(byte[].class, byte[].class);            KafkaUtil.send(producer, pcapEntries, KAFKA_TOPIC, 2);            System.out.println("Sent pcap data: " + pcapEntries.size());            {                int numMessages = 0;                ConsumerIterator<?, ?> it = kafkaComponent.getStreamIterator(KAFKA_TOPIC);                for (int i = 0; i < pcapEntries.size(); ++i, it.next()) {                    numMessages++;                }                Assert.assertEquals(pcapEntries.size(), numMessages);                System.out.println("Wrote " + pcapEntries.size() + " to kafka");            }        }    }, withHeaders);    System.out.println("Done with setup.");}
0
public Void apply(@Nullable Properties input)
{    input.setProperty("kafka.pcap.ts_scheme", Deserializers.FROM_KEY.toString());    return null;}
0
public void send(KafkaComponent kafkaComponent, List<Map.Entry<byte[], byte[]>> pcapEntries) throws Exception
{    Producer<byte[], byte[]> producer = kafkaComponent.createProducer(byte[].class, byte[].class);    KafkaUtil.send(producer, pcapEntries, KAFKA_TOPIC, 2);    System.out.println("Sent pcap data: " + pcapEntries.size());    {        int numMessages = 0;        ConsumerIterator<?, ?> it = kafkaComponent.getStreamIterator(KAFKA_TOPIC);        for (int i = 0; i < pcapEntries.size(); ++i, it.next()) {            numMessages++;        }        Assert.assertEquals(pcapEntries.size(), numMessages);        System.out.println("Wrote " + pcapEntries.size() + " to kafka");    }}
0
private static File getDir(String targetDir, String childDir)
{    File directory = new File(new File(targetDir), childDir);    if (!directory.exists()) {        directory.mkdirs();    }    return directory;}
0
public static void teardownAll() throws Exception
{    System.out.println("Tearing down test infrastructure");    System.out.println("Stopping runner");    runner.stop();    System.out.println("Done stopping runner");    System.out.println("Clearing output directories");    clearOutDirs(inputDir, interimResultDir, outputDir);    System.out.println("Finished");}
0
private static long getTimestamp(int offset, List<Map.Entry<byte[], byte[]>> entries)
{    return Bytes.toLong(entries.get(offset).getKey());}
0
public static void setupTopology(Function<Properties, Void> updatePropertiesCallback, SendEntries sendPcapEntriesCallback, boolean withHeaders) throws Exception
{    if (!new File(topologiesDir).exists()) {        topologiesDir = UnitTestHelper.findDir("topologies");    }    targetDir = UnitTestHelper.findDir("target");    inputDir = getDir(targetDir, DATA_DIR);    interimResultDir = getDir(targetDir, INTERIM_RESULT);    outputDir = getDir(targetDir, OUTPUT_DIR);    clearOutDirs(inputDir, interimResultDir, outputDir);    File baseDir = new File(new File(targetDir), BASE_DIR);        Assert.assertNotNull(topologiesDir);    Assert.assertNotNull(targetDir);    Path pcapFile = new Path("../metron-integration-test/src/main/sample/data/SampleInput/PCAPExampleOutput");    pcapEntries = Lists.newArrayList(readPcaps(pcapFile, withHeaders));    Assert.assertTrue(Iterables.size(pcapEntries) > 0);    final Properties topologyProperties = new Properties() {        {            setProperty("topology.workers", "1");            setProperty("topology.worker.childopts", "");            setProperty("spout.kafka.topic.pcap", KAFKA_TOPIC);            setProperty("kafka.pcap.start", "EARLIEST");            setProperty("kafka.pcap.out", inputDir.getAbsolutePath());            setProperty("kafka.pcap.numPackets", "2");            setProperty("kafka.pcap.maxTimeMS", "200000000");            setProperty("kafka.pcap.ts_granularity", "NANOSECONDS");            setProperty("kafka.spout.parallelism", "1");            setProperty("topology.auto-credentials", "[]");            setProperty("kafka.security.protocol", "PLAINTEXT");            setProperty("hdfs.sync.every", "1");            setProperty("hdfs.replication.factor", "-1");        }    };    updatePropertiesCallback.apply(topologyProperties);    final ZKServerComponent zkServerComponent = getZKServerComponent(topologyProperties);    final KafkaComponent kafkaComponent = getKafkaComponent(topologyProperties, Collections.singletonList(new KafkaComponent.Topic(KAFKA_TOPIC, 1)));    final MRComponent mr = new MRComponent().withBasePath(baseDir.getAbsolutePath());    FluxTopologyComponent fluxComponent = new FluxTopologyComponent.Builder().withTopologyLocation(new File(topologiesDir + "/pcap/remote.yaml")).withTopologyName("pcap").withTopologyProperties(topologyProperties).build();        runner = new ComponentRunner.Builder().withComponent("mr", mr).withComponent("zk", zkServerComponent).withComponent("kafka", kafkaComponent).withComponent("storm", fluxComponent).withMaxTimeMS(-1).withMillisecondsBetweenAttempts(2000).withNumRetries(10).withCustomShutdownOrder(new String[] { "storm", "kafka", "zk", "mr" }).build();    runner.start();    fluxComponent.submitTopology();    sendPcapEntriesCallback.send(kafkaComponent, pcapEntries);    runner.process(new Processor<Void>() {        @Override        public ReadinessState process(ComponentRunner runner) {            int numFiles = numFiles(inputDir, mr.getConfiguration());            int expectedNumFiles = pcapEntries.size() / 2;            if (numFiles == expectedNumFiles) {                return ReadinessState.READY;            } else {                return ReadinessState.NOT_READY;            }        }        @Override        public ProcessorResult<Void> getResult() {            return null;        }    });}
0
public ReadinessState process(ComponentRunner runner)
{    int numFiles = numFiles(inputDir, mr.getConfiguration());    int expectedNumFiles = pcapEntries.size() / 2;    if (numFiles == expectedNumFiles) {        return ReadinessState.READY;    } else {        return ReadinessState.NOT_READY;    }}
0
public ProcessorResult<Void> getResult()
{    return null;}
0
public void setup() throws IOException
{    configuration = new FixedPcapConfig(PcapCli.PREFIX_STRATEGY);    Configuration hadoopConf = new Configuration();    PcapOptions.JOB_NAME.put(configuration, "jobName");    PcapOptions.HADOOP_CONF.put(configuration, hadoopConf);    PcapOptions.FILESYSTEM.put(configuration, FileSystem.get(hadoopConf));    PcapOptions.BASE_PATH.put(configuration, new Path(inputDir.getAbsolutePath()));    PcapOptions.BASE_INTERIM_RESULT_PATH.put(configuration, new Path(interimResultDir.getAbsolutePath()));    PcapOptions.NUM_REDUCERS.put(configuration, 10);    PcapOptions.NUM_RECORDS_PER_FILE.put(configuration, 1);    PcapOptions.FINAL_OUTPUT_PATH.put(configuration, new Path(outputDir.getAbsolutePath()));    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(configuration, 4);}
0
public void filters_pcaps_by_start_end_ns_with_fixed_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(4, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(5, pcapEntries));    PcapOptions.FIELDS.put(configuration, new HashMap());    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals("Expected 2 records returned.", 2, resultPages.getSize());    Assert.assertEquals("Expected 1 record in first file.", 1, PcapHelper.toPacketInfo(Iterables.get(bytes, 0)).size());    Assert.assertEquals("Expected 1 record in second file.", 1, PcapHelper.toPacketInfo(Iterables.get(bytes, 1)).size());}
0
public void filters_pcaps_by_start_end_ns_with_empty_query_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(4, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(5, pcapEntries));    PcapOptions.FIELDS.put(configuration, "");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals("Expected 2 records returned.", 2, resultPages.getSize());    Assert.assertEquals("Expected 1 record in first file.", 1, PcapHelper.toPacketInfo(Iterables.get(bytes, 0)).size());    Assert.assertEquals("Expected 1 record in second file.", 1, PcapHelper.toPacketInfo(Iterables.get(bytes, 1)).size());}
0
public void date_range_filters_out_all_results() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.FIELDS.put(configuration, new HashMap<>());    PcapOptions.START_TIME_NS.put(configuration, 0);    PcapOptions.END_TIME_NS.put(configuration, 1);    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Assert.assertEquals(100.0, results.getStatus().getPercentComplete(), 0.0);    Assert.assertEquals("No results in specified date range.", results.getStatus().getDescription());    Assert.assertEquals(results.get().getSize(), 0);}
0
public void ip_address_filters_out_all_results_with_fixed_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(1, pcapEntries));    PcapOptions.FIELDS.put(configuration, new HashMap<String, String>() {        {            put(Constants.Fields.DST_ADDR.getName(), "207.28.210.1");        }    });    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Assert.assertEquals(results.get().getSize(), 0);}
0
public void ip_address_filters_out_all_results_with_query_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(1, pcapEntries));    PcapOptions.FIELDS.put(configuration, "ip_dst_addr == '207.28.210.1'");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Assert.assertEquals(results.get().getSize(), 0);}
0
public void protocol_filters_out_all_results_with_fixed_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(1, pcapEntries));    PcapOptions.FIELDS.put(configuration, new HashMap<String, String>() {        {            put(Constants.Fields.PROTOCOL.getName(), "foo");        }    });    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Assert.assertEquals(results.get().getSize(), 0);}
0
public void protocol_filters_out_all_results_with_query_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(1, pcapEntries));    PcapOptions.FIELDS.put(configuration, "protocol == 'foo'");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Assert.assertEquals(results.get().getSize(), 0);}
0
public void fixed_filter_returns_all_results_for_full_date_range() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, new HashMap<>());    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(pcapEntries.size(), resultPages.getSize());}
0
public void query_filter_returns_all_results_for_full_date_range() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(pcapEntries.size(), resultPages.getSize());}
0
public void filters_results_by_dst_port_with_fixed_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new FixedPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, new HashMap<String, String>() {        {            put(Constants.Fields.DST_PORT.getName(), "22");        }    });    PcapOptions.NUM_RECORDS_PER_FILE.put(configuration, 1);    PcapJob<Map<String, String>> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertTrue(resultPages.getSize() > 0);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && prt.toString().equals("22");        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
0
public boolean apply(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && prt.toString().equals("22");}
0
public void filters_results_by_dst_port_with_query_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "ip_dst_port == 22");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && prt.toString().equals("22");        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
0
public boolean apply(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && prt.toString().equals("22");}
0
public void filters_results_by_dst_port_range_with_query_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "ip_dst_port > 20 and ip_dst_port < 55792");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(results.get(), path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && ((Long) prt > 20 && (Long) prt < 55792);        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
0
public boolean apply(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && ((Long) prt > 20 && (Long) prt < 55792);}
0
public void filters_results_by_dst_port_greater_than_value_with_query_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapOptions.FIELDS.put(configuration, "ip_dst_port > 55790");    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Pageable<Path> resultPages = results.get();    Iterable<byte[]> bytes = Iterables.transform(resultPages, path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(Iterables.size(filterPcaps(pcapEntries, new Predicate<JSONObject>() {        @Override        public boolean apply(@Nullable JSONObject input) {            Object prt = input.get(Constants.Fields.DST_PORT.getName());            return prt != null && (Long) prt > 55790;        }    }, withHeaders)), resultPages.getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(resultPages.getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
0
public boolean apply(@Nullable JSONObject input)
{    Object prt = input.get(Constants.Fields.DST_PORT.getName());    return prt != null && (Long) prt > 55790;}
0
public void filters_results_by_BYTEARRAY_MATCHER_with_query_filter() throws Exception
{    PcapOptions.FILTER_IMPL.put(configuration, new QueryPcapFilter.Configurator());    PcapOptions.FIELDS.put(configuration, "BYTEARRAY_MATCHER('2f56abd814bc56420489ca38e7faf8cec3d4', packet)");    PcapOptions.START_TIME_NS.put(configuration, getTimestamp(0, pcapEntries));    PcapOptions.END_TIME_NS.put(configuration, getTimestamp(pcapEntries.size() - 1, pcapEntries) + 1);    PcapJob<String> job = new PcapJob<>();    Statusable<Path> results = job.submit(PcapFinalizerStrategies.CLI, configuration);    Assert.assertEquals(Statusable.JobType.MAP_REDUCE, results.getJobType());    waitForJob(results);    Assert.assertEquals(JobStatus.State.SUCCEEDED, results.getStatus().getState());    Iterable<byte[]> bytes = Iterables.transform(results.get(), path -> {        try {            return HDFSUtils.readBytes(path);        } catch (IOException e) {            throw new IllegalStateException(e);        }    });    assertInOrder(bytes);    Assert.assertEquals(1, results.get().getSize());    ByteArrayOutputStream baos = new ByteArrayOutputStream();    PcapMerger.merge(baos, HDFSUtils.readBytes(results.get().getPage(0)));    Assert.assertTrue(baos.toByteArray().length > 0);}
0
private void waitForJob(Statusable statusable) throws Exception
{    for (int t = 0; t < MAX_RETRIES; ++t, Thread.sleep(SLEEP_MS)) {        if (!statusable.getStatus().getState().equals(JobStatus.State.RUNNING)) {            if (statusable.isDone()) {                return;            }        }    }    throw new Exception("Job did not complete within " + (MAX_RETRIES * SLEEP_MS) + " seconds");}
0
private static Iterable<Map.Entry<byte[], byte[]>> readPcaps(Path pcapFile, boolean withHeaders) throws IOException
{    SequenceFile.Reader reader = new SequenceFile.Reader(new Configuration(), SequenceFile.Reader.file(pcapFile));    List<Map.Entry<byte[], byte[]>> ret = new ArrayList<>();    IntWritable key = new IntWritable();    BytesWritable value = new BytesWritable();    while (reader.next(key, value)) {        byte[] pcapWithHeader = value.copyBytes();                                                long calculatedTs = PcapHelper.getTimestamp(pcapWithHeader);        {            List<PacketInfo> info = PcapHelper.toPacketInfo(pcapWithHeader);            for (PacketInfo pi : info) {                Assert.assertEquals(calculatedTs, pi.getPacketTimeInNanos());                                    }        }        if (withHeaders) {            ret.add(new AbstractMap.SimpleImmutableEntry<>(Bytes.toBytes(calculatedTs), pcapWithHeader));        } else {            byte[] pcapRaw = new byte[pcapWithHeader.length - PcapHelper.GLOBAL_HEADER_SIZE - PcapHelper.PACKET_HEADER_SIZE];            System.arraycopy(pcapWithHeader, PcapHelper.GLOBAL_HEADER_SIZE + PcapHelper.PACKET_HEADER_SIZE, pcapRaw, 0, pcapRaw.length);            ret.add(new AbstractMap.SimpleImmutableEntry<>(Bytes.toBytes(calculatedTs), pcapRaw));        }    }    return Iterables.limit(ret, 2 * (ret.size() / 2));}
0
public static void assertInOrder(Iterable<byte[]> packets)
{    long previous = 0;    for (byte[] packet : packets) {        for (JSONObject json : TO_JSONS.apply(packet)) {            Long current = Long.parseLong(json.get("ts_micro").toString());            Assert.assertNotNull(current);            Assert.assertTrue(Long.compareUnsigned(current, previous) >= 0);            previous = current;        }    }}
0
public Iterable<JSONObject> apply(@Nullable byte[] input)
{    try {        return PcapHelper.toJSON(PcapHelper.toPacketInfo(input));    } catch (IOException e) {        throw new RuntimeException(e.getMessage(), e);    }}
0
private Iterable<JSONObject> filterPcaps(Iterable<Map.Entry<byte[], byte[]>> pcaps, Predicate<JSONObject> predicate, boolean withHeaders)
{    Function<Map.Entry<byte[], byte[]>, byte[]> pcapTransform = null;    if (!withHeaders) {        final Endianness endianness = Endianness.getNativeEndianness();        pcapTransform = kv -> PcapHelper.addGlobalHeader(PcapHelper.addPacketHeader(Bytes.toLong(kv.getKey()), kv.getValue(), endianness), endianness);    } else {        pcapTransform = kv -> kv.getValue();    }    return Iterables.filter(Iterables.concat(Iterables.transform(Iterables.transform(pcaps, pcapTransform), TO_JSONS)), predicate);}
0
public void setup() throws IOException
{    MockitoAnnotations.initMocks(this);    execDir = System.getProperty("user.dir");    prefixStrategy = clock -> "random_prefix";}
0
public void runs_fixed_pcap_filter_job_with_default_argument_list() throws Exception
{    String[] args = { "fixed", "-start_time", "500", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-packet_filter", "`casey`" };    HashMap<String, String> query = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");            put(Constants.Fields.DST_ADDR.getName(), "192.168.1.2");            put(Constants.Fields.SRC_PORT.getName(), "8081");            put(Constants.Fields.DST_PORT.getName(), "8082");            put(Constants.Fields.PROTOCOL.getName(), "6");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "false");            put(PcapHelper.PacketFields.PACKET_FILTER.getName(), "`casey`");        }    };    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, BASE_INPUT_PATH_DEFAULT);    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, BASE_INTERIM_RESULT_PATH_DEFAULT);    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);    PcapOptions.START_TIME_MS.put(config, 500L);    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
0
private Matcher<Map<K, V>> mapContaining(Map<K, V> map)
{    return new TypeSafeMatcher<Map<K, V>>() {        @Override        protected boolean matchesSafely(Map<K, V> item) {            for (K key : map.keySet()) {                if (key.equals(PcapOptions.HADOOP_CONF.getKey())) {                    Configuration itemConfiguration = (Configuration) item.get(PcapOptions.HADOOP_CONF.getKey());                    Map<String, Object> mapConfiguration = (Map<String, Object>) map.get(PcapOptions.HADOOP_CONF.getKey());                    for (String setting : mapConfiguration.keySet()) {                        if (!mapConfiguration.get(setting).equals(itemConfiguration.get(setting, ""))) {                            return false;                        }                    }                } else {                    V itemValue = item.get(key);                    V mapValue = map.get(key);                    if (itemValue != null ? !itemValue.equals(mapValue) : mapValue != null) {                        return false;                    }                }            }            return true;        }        @Override        public void describeTo(Description description) {            description.appendText("Should contain items: ");            for (Entry<K, V> entry : map.entrySet()) {                StringBuilder sb = new StringBuilder();                sb.append("key=");                sb.append(entry.getKey());                sb.append(",value=");                sb.append(entry.getValue());                description.appendText(sb.toString());            }        }    };}
0
protected boolean matchesSafely(Map<K, V> item)
{    for (K key : map.keySet()) {        if (key.equals(PcapOptions.HADOOP_CONF.getKey())) {            Configuration itemConfiguration = (Configuration) item.get(PcapOptions.HADOOP_CONF.getKey());            Map<String, Object> mapConfiguration = (Map<String, Object>) map.get(PcapOptions.HADOOP_CONF.getKey());            for (String setting : mapConfiguration.keySet()) {                if (!mapConfiguration.get(setting).equals(itemConfiguration.get(setting, ""))) {                    return false;                }            }        } else {            V itemValue = item.get(key);            V mapValue = map.get(key);            if (itemValue != null ? !itemValue.equals(mapValue) : mapValue != null) {                return false;            }        }    }    return true;}
0
public void describeTo(Description description)
{    description.appendText("Should contain items: ");    for (Entry<K, V> entry : map.entrySet()) {        StringBuilder sb = new StringBuilder();        sb.append("key=");        sb.append(entry.getKey());        sb.append(",value=");        sb.append(entry.getValue());        description.appendText(sb.toString());    }}
0
public void runs_fixed_pcap_filter_job_with_full_argument_list_and_default_dateformat() throws Exception
{    String[] args = { "fixed", "-start_time", "500", "-end_time", "1000", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-include_reverse", "-num_reducers", "10", "-records_per_file", "1000", "-finalizer_threads", "10" };    Map<String, String> query = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");            put(Constants.Fields.DST_ADDR.getName(), "192.168.1.2");            put(Constants.Fields.SRC_PORT.getName(), "8081");            put(Constants.Fields.DST_PORT.getName(), "8082");            put(Constants.Fields.PROTOCOL.getName(), "6");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "true");        }    };    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, "/base/path");    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, "/base/output/path");    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);    PcapOptions.START_TIME_MS.put(config, 500L);    PcapOptions.END_TIME_MS.put(config, 1000L);    PcapOptions.NUM_RECORDS_PER_FILE.put(config, 1000);    PcapOptions.PRINT_JOB_STATUS.put(config, true);    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "10");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
0
public void runs_fixed_pcap_filter_job_with_full_argument_list() throws Exception
{    String[] args = { "fixed", "-start_time", "2016-06-13-18:35.00", "-end_time", "2016-06-15-18:35.00", "-date_format", "yyyy-MM-dd-HH:mm.ss", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-include_reverse", "-num_reducers", "10", "-records_per_file", "1000", "-yq", "pcap", "-finalizer_threads", "10" };    Map<String, String> query = new HashMap<String, String>() {        {            put(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");            put(Constants.Fields.DST_ADDR.getName(), "192.168.1.2");            put(Constants.Fields.SRC_PORT.getName(), "8081");            put(Constants.Fields.DST_PORT.getName(), "8082");            put(Constants.Fields.PROTOCOL.getName(), "6");            put(Constants.Fields.INCLUDES_REVERSE_TRAFFIC.getName(), "true");        }    };    long startAsNanos = asNanos("2016-06-13-18:35.00", "yyyy-MM-dd-HH:mm.ss");    long endAsNanos = asNanos("2016-06-15-18:35.00", "yyyy-MM-dd-HH:mm.ss");    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, "/base/path");    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, "/base/output/path");    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);        PcapOptions.START_TIME_MS.put(config, startAsNanos / 1000000L);        PcapOptions.END_TIME_MS.put(config, endAsNanos / 1000000L);    PcapOptions.NUM_RECORDS_PER_FILE.put(config, 1000);    PcapOptions.PRINT_JOB_STATUS.put(config, true);    PcapOptions.HADOOP_CONF.put(config, new HashMap<String, Object>() {        {            put(MRJobConfig.QUEUE_NAME, "pcap");        }    });    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "10");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
0
private long asNanos(String inDate, String format) throws ParseException
{    SimpleDateFormat sdf = new SimpleDateFormat(format);    Date date = sdf.parse(inDate);    return TimestampConverters.MILLISECONDS.toNanoseconds(date.getTime());}
0
private byte[] asBytes(String val)
{    return val.getBytes(StandardCharsets.UTF_8);}
0
public void runs_query_pcap_filter_job_with_default_argument_list() throws Exception
{    String[] args = { "query", "-start_time", "500", "-query", "some query string" };    String query = "some query string";    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, BASE_INPUT_PATH_DEFAULT);    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, BASE_INTERIM_RESULT_PATH_DEFAULT);    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);    PcapOptions.START_TIME_MS.put(config, 500L);    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "1");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
0
public void runs_query_pcap_filter_job_with_full_argument_list() throws Exception
{    String[] args = { "query", "-start_time", "500", "-end_time", "1000", "-num_reducers", "10", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-query", "some query string", "-records_per_file", "1000", "-finalizer_threads", "10" };    String query = "some query string";    FixedPcapConfig config = new FixedPcapConfig(prefixStrategy);    PcapOptions.BASE_PATH.put(config, "/base/path");    PcapOptions.BASE_INTERIM_RESULT_PATH.put(config, "/base/output/path");    PcapOptions.FIELDS.put(config, query);    PcapOptions.NUM_REDUCERS.put(config, 10);        PcapOptions.START_TIME_MS.put(config, 500L);        PcapOptions.END_TIME_MS.put(config, 1000L);    PcapOptions.NUM_RECORDS_PER_FILE.put(config, 1000);    PcapOptions.PRINT_JOB_STATUS.put(config, true);    PcapOptions.FINALIZER_THREADPOOL_SIZE.put(config, "10");    when(jobRunner.submit(isA(Finalizer.class), argThat(mapContaining(config)))).thenReturn(jobRunner);    PcapCli cli = new PcapCli(jobRunner, prefixStrategy);    assertThat("Expect no errors on run", cli.run(args), equalTo(0));    verify(jobRunner).get();}
0
public void invalid_fixed_filter_arg_prints_help() throws Exception
{    String[] args = { "fixed", "-start_time", "500", "-end_time", "1000", "-num_reducers", "10", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-query", "THIS IS AN ERROR" };    assertCliError(args, "Fixed", "Unrecognized option: -query");}
0
public void assertCliError(String[] args, String type, String optMsg) throws UnsupportedEncodingException
{    PrintStream originalOutStream = System.out;    PrintStream originalErrOutStream = System.err;    try {        ByteArrayOutputStream bos = new ByteArrayOutputStream();        PrintStream outStream = new PrintStream(new BufferedOutputStream(bos), false, StandardCharsets.UTF_8.name());        System.setOut(outStream);        ByteArrayOutputStream ebos = new ByteArrayOutputStream();        PrintStream errOutStream = new PrintStream(new BufferedOutputStream(ebos), false, StandardCharsets.UTF_8.name());        System.setErr(errOutStream);        PcapCli cli = new PcapCli(jobRunner, clock -> "random_prefix");        assertThat("Expect errors on run", cli.run(args), equalTo(-1));        assertThat("Expect missing required option error: " + ebos.toString(), ebos.toString().contains(optMsg), equalTo(true));        assertThat("Expect usage to be printed: " + bos.toString(), bos.toString().contains("usage: " + type + " filter options"), equalTo(true));    } finally {        System.setOut(originalOutStream);        System.setErr(originalErrOutStream);    }}
0
public void invalid_query_filter_arg_prints_help() throws Exception
{    String[] args = { "query", "-start_time", "500", "-end_time", "1000", "-num_reducers", "10", "-base_path", "/base/path", "-base_output_path", "/base/output/path", "-ip_src_addr", "THIS IS AN ERROR" };    assertCliError(args, "Query", "");}
0
public void missing_start_time_arg_prints_error_and_help() throws Exception
{    String[] args = { "fixed", "-ip_src_addr", "192.168.1.1", "-ip_dst_addr", "192.168.1.2", "-ip_src_port", "8081", "-ip_dst_port", "8082", "-protocol", "6", "-num_reducers", "10" };    assertCliError(args, "Fixed", "Missing required option: st");}
0
public void empty_or_null_key_throws_illegal_argument_exception()
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("Expected a key but none provided");    FromKeyDeserializer deserializer = new FromKeyDeserializer(TimestampConverters.NANOSECONDS);    deserializer.deserializeKeyValue(null, null);}
0
public static SolrClient create(Map<String, Object> globalConfig)
{    if (solrClient == null) {        synchronized (SolrClientFactory.class) {            if (solrClient == null) {                solrClient = new CloudSolrClient.Builder().withZkHost(getZkHosts(globalConfig)).build();            }        }    }    return solrClient;}
0
public static void close()
{    synchronized (SolrClientFactory.class) {        if (solrClient != null) {            try {                solrClient.close();            } catch (IOException e) {                            } finally {                solrClient = null;            }        }    }}
1
protected static List<String> getZkHosts(Map<String, Object> globalConfig)
{    return Splitter.on(',').trimResults().splitToList((String) globalConfig.getOrDefault(SOLR_ZOOKEEPER, ""));}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    Map<String, FieldType> indexColumnMetadata = new HashMap<>();    Map<String, String> previousIndices = new HashMap<>();    Set<String> fieldBlackList = Sets.newHashSet(SolrDao.ROOT_FIELD, SolrDao.VERSION_FIELD);    for (String index : indices) {        try {            getIndexFields(index).forEach(field -> {                String name = (String) field.get("name");                if (!fieldBlackList.contains(name)) {                    FieldType type = toFieldType((String) field.get("type"));                    if (!indexColumnMetadata.containsKey(name)) {                        indexColumnMetadata.put(name, type);                                                previousIndices.put(name, index);                    } else {                        FieldType previousType = indexColumnMetadata.get(name);                        if (!type.equals(previousType)) {                            String previousIndexName = previousIndices.get(name);                                                        indexColumnMetadata.put(name, FieldType.OTHER);                                                        fieldBlackList.add(name);                        }                    }                }            });        } catch (SolrServerException e) {            throw new IOException(e);        } catch (SolrException e) {                        if (e.code() != 400) {                throw new IOException(e);            }        }    }    return indexColumnMetadata;}
1
protected List<Map<String, Object>> getIndexFields(String index) throws IOException, SolrServerException
{    List<Map<String, Object>> indexFields = new ArrayList<>();        LukeRequest lukeRequest = new LukeRequest();    LukeResponse lukeResponse = lukeRequest.process(client, index);    for (Entry<String, LukeResponse.FieldInfo> field : lukeResponse.getFieldInfo().entrySet()) {        Map<String, Object> fieldData = new HashMap<>();        fieldData.put("name", field.getValue().getName());        fieldData.put("type", field.getValue().getType());        indexFields.add(fieldData);    }        SchemaRepresentation schemaRepresentation = new SchemaRequest().process(client, index).getSchemaRepresentation();    indexFields.addAll(schemaRepresentation.getFields());    return indexFields;}
0
private FieldType toFieldType(String type)
{    return solrTypeMap.getOrDefault(type, FieldType.OTHER);}
0
public void init(AccessConfig config)
{    if (config.getKerberosEnabled()) {        enableKerberos();    }    if (this.client == null) {        this.accessConfig = config;        this.client = SolrClientFactory.create(config.getGlobalConfigSupplier().get());        this.solrSearchDao = new SolrSearchDao(this.client, this.accessConfig);        this.solrRetrieveLatestDao = new SolrRetrieveLatestDao(this.client, this.accessConfig);        this.solrUpdateDao = new SolrUpdateDao(this.client, this.solrRetrieveLatestDao, this.accessConfig);        this.solrColumnMetadataDao = new SolrColumnMetadataDao(this.client);    }}
0
public Optional<String> getIndex(String sensorName, Optional<String> index)
{    if (index.isPresent()) {        return index;    } else {        String realIndex = accessConfig.getIndexSupplier().apply(sensorName);        return Optional.ofNullable(realIndex);    }}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    return this.solrSearchDao.search(searchRequest);}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    return this.solrSearchDao.group(groupRequest);}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    return this.solrRetrieveLatestDao.getLatest(guid, sensorType);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    return this.solrRetrieveLatestDao.getAllLatest(getRequests);}
0
public Document update(Document update, Optional<String> index) throws IOException
{    return this.solrUpdateDao.update(update, index);}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) throws IOException
{    return this.solrUpdateDao.batchUpdate(updates);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    return this.solrUpdateDao.addCommentToAlert(request);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    return this.solrUpdateDao.removeCommentFromAlert(request);}
0
public Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    return solrUpdateDao.patch(retrieveLatestDao, request, timestamp);}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    return this.solrColumnMetadataDao.getColumnMetadata(indices);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return this.solrUpdateDao.addCommentToAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return this.solrUpdateDao.removeCommentFromAlert(request, latest);}
0
 void enableKerberos()
{    HttpClientUtil.addConfigurer(new Krb5HttpClientConfigurer());}
0
public SolrSearchDao getSolrSearchDao()
{    return solrSearchDao;}
0
public SolrUpdateDao getSolrUpdateDao()
{    return solrUpdateDao;}
0
public void init(IndexDao indexDao, Optional<String> threatSort)
{    if (indexDao instanceof MultiIndexDao) {        this.indexDao = indexDao;        MultiIndexDao multiIndexDao = (MultiIndexDao) indexDao;        for (IndexDao childDao : multiIndexDao.getIndices()) {            if (childDao instanceof SolrDao) {                this.solrDao = (SolrDao) childDao;            }        }    } else if (indexDao instanceof SolrDao) {        this.indexDao = indexDao;        this.solrDao = (SolrDao) indexDao;    } else {        throw new IllegalArgumentException("Need a SolrDao when using SolrMetaAlertDao");    }    Supplier<Map<String, Object>> globalConfigSupplier = () -> new HashMap<>();    if (metaAlertSearchDao != null && metaAlertSearchDao.solrSearchDao != null && metaAlertSearchDao.solrSearchDao.getAccessConfig() != null) {        globalConfigSupplier = metaAlertSearchDao.solrSearchDao.getAccessConfig().getGlobalConfigSupplier();    }    MetaAlertConfig config = new MetaAlertConfig(metaAlertsCollection, this.threatSort, globalConfigSupplier) {        @Override        protected String getDefaultThreatTriageField() {            return MetaAlertConstants.THREAT_FIELD_DEFAULT.replace(':', '.');        }        @Override        protected String getDefaultSourceTypeField() {            return Constants.SENSOR_TYPE;        }    };    SolrClient solrClient = SolrClientFactory.create(globalConfigSupplier.get());    this.metaAlertSearchDao = new SolrMetaAlertSearchDao(solrClient, solrDao.getSolrSearchDao(), config);    this.metaAlertRetrieveLatestDao = new SolrMetaAlertRetrieveLatestDao(solrClient, solrDao);    this.metaAlertUpdateDao = new SolrMetaAlertUpdateDao(solrClient, solrDao, metaAlertSearchDao, metaAlertRetrieveLatestDao, config);    if (threatSort.isPresent()) {        this.threatSort = threatSort.get();    }}
0
protected String getDefaultThreatTriageField()
{    return MetaAlertConstants.THREAT_FIELD_DEFAULT.replace(':', '.');}
0
protected String getDefaultSourceTypeField()
{    return Constants.SENSOR_TYPE;}
0
public void init(AccessConfig config)
{}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices) throws IOException
{    return indexDao.getColumnMetadata(indices);}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    return metaAlertRetrieveLatestDao.getLatest(guid, sensorType);}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    return metaAlertRetrieveLatestDao.getAllLatest(getRequests);}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    return metaAlertSearchDao.search(searchRequest);}
0
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    return metaAlertSearchDao.group(groupRequest);}
0
public Document update(Document update, Optional<String> index) throws IOException
{    return metaAlertUpdateDao.update(update, index);}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates)
{    return metaAlertUpdateDao.batchUpdate(updates);}
0
public Document patch(RetrieveLatestDao retrieveLatestDao, PatchRequest request, Optional<Long> timestamp) throws OriginalNotFoundException, IOException
{    return metaAlertUpdateDao.patch(retrieveLatestDao, request, timestamp);}
0
public SearchResponse getAllMetaAlertsForAlert(String guid) throws InvalidSearchException
{    return metaAlertSearchDao.getAllMetaAlertsForAlert(guid);}
0
public Document createMetaAlert(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    return metaAlertUpdateDao.createMetaAlert(request);}
0
public Document addAlertsToMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.addAlertsToMetaAlert(metaAlertGuid, alertRequests);}
0
public Document removeAlertsFromMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException
{    return metaAlertUpdateDao.removeAlertsFromMetaAlert(metaAlertGuid, alertRequests);}
0
public Document updateMetaAlertStatus(String metaAlertGuid, MetaAlertStatus status) throws IOException
{    return metaAlertUpdateDao.updateMetaAlertStatus(metaAlertGuid, status);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    return solrDao.addCommentToAlert(request);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    return solrDao.removeCommentFromAlert(request);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return solrDao.addCommentToAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return solrDao.removeCommentFromAlert(request, latest);}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    if (MetaAlertConstants.METAALERT_TYPE.equals(sensorType)) {                        String guidClause = Constants.GUID + ":" + guid;        SolrQuery query = new SolrQuery();        query.setQuery(guidClause).setFields("*", "[child parentFilter=" + guidClause + " limit=999]");        try {            QueryResponse response = solrClient.query(METAALERTS_COLLECTION, query);                        if (response.getResults().size() == 1) {                SolrDocument result = response.getResults().get(0);                return SolrUtilities.toDocument(result);            } else {                return null;            }        } catch (SolrServerException e) {            throw new IOException("Unable to retrieve metaalert", e);        }    } else {        return solrDao.getLatest(guid, sensorType);    }}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    return solrDao.getAllLatest(getRequests);}
0
public SearchResponse getAllMetaAlertsForAlert(String guid) throws InvalidSearchException
{    if (guid == null || guid.trim().isEmpty()) {        throw new InvalidSearchException("Guid cannot be empty");    }                String activeClause = MetaAlertConstants.STATUS_FIELD + ":" + MetaAlertStatus.ACTIVE.getStatusString();    String guidClause = Constants.GUID + ":" + guid;    String fullClause = "{!parent which=" + activeClause + "}" + guidClause;    String metaalertTypeClause = config.getSourceTypeField() + ":" + MetaAlertConstants.METAALERT_TYPE;    SolrQuery solrQuery = new SolrQuery().setQuery(fullClause).setFields("*", "[child parentFilter=" + metaalertTypeClause + " limit=999]").addSort(Constants.GUID,     SolrQuery.ORDER.asc);        List<SearchResult> allResults = new ArrayList<>();    try {        String cursorMark = CursorMarkParams.CURSOR_MARK_START;        boolean done = false;        while (!done) {            solrQuery.set(CursorMarkParams.CURSOR_MARK_PARAM, cursorMark);            QueryResponse rsp = solrClient.query(METAALERTS_COLLECTION, solrQuery);            String nextCursorMark = rsp.getNextCursorMark();            rsp.getResults().stream().map(solrDocument -> SolrUtilities.getSearchResult(solrDocument, null, solrSearchDao.getAccessConfig().getIndexSupplier())).forEachOrdered(allResults::add);            if (cursorMark.equals(nextCursorMark)) {                done = true;            }            cursorMark = nextCursorMark;        }    } catch (IOException | SolrServerException e) {        throw new InvalidSearchException("Unable to complete search", e);    }    SearchResponse searchResponse = new SearchResponse();    searchResponse.setResults(allResults);    searchResponse.setTotal(allResults.size());    return searchResponse;}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{                String activeStatusClause = MetaAlertConstants.STATUS_FIELD + ":" + MetaAlertStatus.ACTIVE.getStatusString();    String metaalertTypeClause = config.getSourceTypeField() + ":" + MetaAlertConstants.METAALERT_TYPE;                    String parentChildQuery = "(+" + activeStatusClause + " +" + "{!parent which=" + metaalertTypeClause + " v='" + searchRequest.getQuery() + "'})";                    String fullQuery = "(" + searchRequest.getQuery() + " AND -" + MetaAlertConstants.METAALERT_FIELD + ":[* TO *]" + " AND " + "-" + metaalertTypeClause + ")" + " OR " + parentChildQuery;        searchRequest.setQuery(fullQuery);        List<String> fields = searchRequest.getFields();    String fieldList = "*";    if (fields != null) {        fieldList = StringUtils.join(fields, ",");    }        SearchResponse results = solrSearchDao.search(searchRequest, fieldList);            if (fieldList.contains("*") || fieldList.contains(config.getSourceTypeField())) {        List<String> metaalertGuids = new ArrayList<>();        for (SearchResult result : results.getResults()) {            if (result.getSource().get(config.getSourceTypeField()).equals(MetaAlertConstants.METAALERT_TYPE)) {                                metaalertGuids.add(result.getId());            }        }                        if (metaalertGuids.size() > 0) {            Map<String, String> params = new HashMap<>();            params.put("fl", fieldList + ",[child parentFilter=" + metaalertTypeClause + " limit=999]");            SolrParams solrParams = new MapSolrParams(params);            try {                SolrDocumentList solrDocumentList = solrClient.getById(METAALERTS_COLLECTION, metaalertGuids, solrParams);                Map<String, Document> guidToDocuments = new HashMap<>();                for (SolrDocument doc : solrDocumentList) {                    Document document = SolrUtilities.toDocument(doc);                    guidToDocuments.put(document.getGuid(), document);                }                                for (SearchResult result : results.getResults()) {                    Document fullDoc = guidToDocuments.get(result.getId());                    if (fullDoc != null) {                        result.setSource(fullDoc.getDocument());                    }                }            } catch (SolrServerException | IOException e) {                throw new InvalidSearchException("Error when retrieving child alerts for metaalerts", e);            }        }    }    return results;}
1
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{        String sourceType = ClientUtils.escapeQueryChars(config.getSourceTypeField());    String baseQuery = groupRequest.getQuery();    String adjustedQuery = baseQuery + " -" + MetaAlertConstants.METAALERT_FIELD + ":[* TO *]" + " -" + sourceType + ":" + MetaAlertConstants.METAALERT_TYPE;        groupRequest.setQuery(adjustedQuery);    return solrSearchDao.group(groupRequest);}
1
public Document createMetaAlert(MetaAlertCreateRequest request) throws InvalidCreateException, IOException
{    List<GetRequest> alertRequests = request.getAlerts();    if (request.getAlerts().isEmpty()) {        throw new InvalidCreateException("MetaAlertCreateRequest must contain alerts");    }    if (request.getGroups().isEmpty()) {        throw new InvalidCreateException("MetaAlertCreateRequest must contain UI groups");    }        Iterable<Document> alerts = getRetrieveLatestDao().getAllLatest(alertRequests);    Document metaAlert = buildCreateDocument(alerts, request.getGroups(), MetaAlertConstants.ALERT_FIELD);    MetaScores.calculateMetaScores(metaAlert, getConfig().getThreatTriageField(), getConfig().getThreatSort());        metaAlert.getDocument().put(getConfig().getSourceTypeField(), MetaAlertConstants.METAALERT_TYPE);        Map<Document, Optional<String>> updates = new HashMap<>();    updates.put(metaAlert, Optional.of(METAALERTS_COLLECTION));    try {                        Map<String, Optional<String>> guidToIndices = alertRequests.stream().collect(Collectors.toMap(GetRequest::getGuid, GetRequest::getIndex));        Map<String, String> guidToSensorTypes = alertRequests.stream().collect(Collectors.toMap(GetRequest::getGuid, GetRequest::getSensorType));        for (Document alert : alerts) {            if (addMetaAlertToAlert(metaAlert.getGuid(), alert)) {                                Optional<String> index = guidToIndices.get(alert.getGuid());                if (!index.isPresent()) {                    index = Optional.ofNullable(guidToSensorTypes.get(alert.getGuid()));                    if (!index.isPresent()) {                        throw new IllegalArgumentException("Could not find index for " + alert.getGuid());                    }                }                updates.put(alert, index);            }        }                update(updates);        solrClient.commit(METAALERTS_COLLECTION);        return metaAlert;    } catch (IOException | SolrServerException e) {        throw new InvalidCreateException("Unable to create meta alert", e);    }}
0
public Document update(Document update, Optional<String> collection) throws IOException
{    if (MetaAlertConstants.METAALERT_TYPE.equals(update.getSensorType())) {                throw new UnsupportedOperationException("Meta alerts cannot be directly updated");    }        Map<Document, Optional<String>> updates = new HashMap<>();    updates.put(update, collection);            SearchResponse searchResponse;    try {        searchResponse = metaAlertSearchDao.getAllMetaAlertsForAlert(update.getGuid());    } catch (InvalidSearchException e) {        throw new IOException("Unable to retrieve metaalerts for alert", e);    }    ArrayList<Document> metaAlerts = new ArrayList<>();    for (SearchResult searchResult : searchResponse.getResults()) {        Document doc = new Document(searchResult.getSource(), searchResult.getId(), MetaAlertConstants.METAALERT_TYPE, 0L);        metaAlerts.add(doc);    }    for (Document metaAlert : metaAlerts) {        if (replaceAlertInMetaAlert(metaAlert, update)) {            updates.put(metaAlert, Optional.of(METAALERTS_COLLECTION));        }    }        getUpdateDao().batchUpdate(updates);    try {        solrClient.commit(METAALERTS_COLLECTION);        if (collection.isPresent()) {            solrClient.commit(collection.get());        }    } catch (SolrServerException e) {        throw new IOException("Unable to update document", e);    }    return update;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    return getUpdateDao().addCommentToAlert(request);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    return getUpdateDao().removeCommentFromAlert(request);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return getUpdateDao().addCommentToAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    return getUpdateDao().removeCommentFromAlert(request, latest);}
0
protected boolean replaceAlertInMetaAlert(Document metaAlert, Document alert)
{    boolean metaAlertUpdated = removeAlertsFromMetaAlert(metaAlert, Collections.singleton(alert.getGuid()));    if (metaAlertUpdated) {        addAlertsToMetaAlert(metaAlert, Collections.singleton(alert));    }    return metaAlertUpdated;}
0
public Document addAlertsToMetaAlert(String metaAlertGuid, List<GetRequest> alertRequests) throws IOException, IllegalStateException
{    Document metaAlert = getRetrieveLatestDao().getLatest(metaAlertGuid, MetaAlertConstants.METAALERT_TYPE);    if (MetaAlertStatus.ACTIVE.getStatusString().equals(metaAlert.getDocument().get(MetaAlertConstants.STATUS_FIELD))) {        Iterable<Document> alerts = getRetrieveLatestDao().getAllLatest(alertRequests);        Map<Document, Optional<String>> updates = buildAddAlertToMetaAlertUpdates(metaAlert, alerts);        update(updates);    } else {        throw new IllegalStateException("Adding alerts to an INACTIVE meta alert is not allowed");    }    try {        solrClient.commit(METAALERTS_COLLECTION);    } catch (SolrServerException e) {        throw new IOException("Unable to commit alerts to metaalert: " + metaAlertGuid, e);    }    return metaAlert;}
0
public Document getLatest(String guid, String sensorType) throws IOException
{    try {        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), sensorType, Optional.empty());        if (!index.isPresent()) {                        return null;        }        SolrDocument solrDocument = client.getById(index.get(), guid);        if (solrDocument == null) {                        return null;        }        return SolrUtilities.toDocument(solrDocument);    } catch (SolrServerException e) {        throw new IOException(e);    }}
1
public Iterable<Document> getAllLatest(List<GetRequest> getRequests) throws IOException
{    Map<String, Collection<String>> collectionIdMap = new HashMap<>();    for (GetRequest getRequest : getRequests) {        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), getRequest.getSensorType(), getRequest.getIndex());        if (index.isPresent()) {            Collection<String> ids = collectionIdMap.getOrDefault(index.get(), new HashSet<>());            ids.add(getRequest.getGuid());            collectionIdMap.put(index.get(), ids);        } else {                    }    }    try {        List<Document> documents = new ArrayList<>();        for (String collection : collectionIdMap.keySet()) {            SolrDocumentList solrDocumentList = client.getById(collectionIdMap.get(collection), new SolrQuery().set("collection", collection));            documents.addAll(solrDocumentList.stream().map(SolrUtilities::toDocument).collect(Collectors.toList()));        }        return documents;    } catch (SolrServerException e) {        throw new IOException(e);    }}
1
protected AccessConfig getAccessConfig()
{    return accessConfig;}
0
public SearchResponse search(SearchRequest searchRequest) throws InvalidSearchException
{    return search(searchRequest, null);}
0
public SearchResponse search(SearchRequest searchRequest, String fieldList) throws InvalidSearchException
{    validateSearchRequest(searchRequest);    try {        SolrQuery query = buildSearchRequest(searchRequest, fieldList);        QueryResponse response = client.query(query);        logQueryDebugDetail(query, response);        return buildSearchResponse(searchRequest, response);    } catch (SolrException | IOException | SolrServerException e) {        String msg = e.getMessage();                throw new InvalidSearchException(msg, e);    }}
1
private void validateSearchRequest(SearchRequest searchRequest) throws InvalidSearchException
{    if (searchRequest.getQuery() == null) {        throw new InvalidSearchException("Search query is invalid: null");    }    if (client == null) {        throw new InvalidSearchException("Uninitialized Dao!  You must call init() prior to use.");    }    if (searchRequest.getSize() > accessConfig.getMaxSearchResults()) {        throw new InvalidSearchException("Search result size must be less than " + accessConfig.getMaxSearchResults());    }}
0
private void logQueryDebugDetail(SolrQuery query, QueryResponse response)
{    if (LOG.isDebugEnabled()) {        final String ls = System.lineSeparator();            }}
1
public GroupResponse group(GroupRequest groupRequest) throws InvalidSearchException
{    try {        validateGroupRequest(groupRequest);        String groupNames = groupRequest.getGroups().stream().map(Group::getField).collect(Collectors.joining(","));        SolrQuery query = new SolrQuery().setStart(0).setRows(0).setQuery(groupRequest.getQuery()).setShowDebugInfo(        LOG.isDebugEnabled());        query.set("collection", getCollections(groupRequest.getIndices()));        Optional<String> scoreField = groupRequest.getScoreField();        if (scoreField.isPresent()) {            query.set("stats", true);            query.set("stats.field", String.format("{!tag=piv1 sum=true}%s", scoreField.get()));        }        query.set("facet", true);        query.set("facet.pivot", String.format("{!stats=piv1}%s", groupNames));        QueryResponse response = client.query(query);        logQueryDebugDetail(query, response);        return buildGroupResponse(groupRequest, response);    } catch (IOException | SolrServerException e) {        String msg = e.getMessage();                throw new InvalidSearchException(msg, e);    }}
1
private void validateGroupRequest(GroupRequest groupRequest) throws InvalidSearchException
{    if (groupRequest.getGroups() == null || groupRequest.getGroups().size() == 0) {        throw new InvalidSearchException("At least 1 group must be provided.");    }}
0
protected SolrQuery buildSearchRequest(SearchRequest searchRequest, String fieldList) throws IOException, SolrServerException
{    SolrQuery query = new SolrQuery().setStart(searchRequest.getFrom()).setRows(searchRequest.getSize()).setQuery(searchRequest.getQuery()).setShowDebugInfo(    LOG.isDebugEnabled());        for (SortField sortField : searchRequest.getSort()) {        query.addSort(sortField.getField(), getSolrSortOrder(sortField.getSortOrder()));    }        List<String> fields = searchRequest.getFields();    if (fieldList == null) {        fieldList = "*";        if (fields != null) {            fieldList = StringUtils.join(fields, ",");        }    }    query.set("fl", fieldList);        List<String> facetFields = searchRequest.getFacetFields();    if (facetFields != null) {        facetFields.forEach(query::addFacetField);    }    query.set("collection", getCollections(searchRequest.getIndices()));    return query;}
0
private String getCollections(List<String> indices) throws IOException, SolrServerException
{    List<String> existingCollections = CollectionAdminRequest.listCollections(client);    return indices.stream().filter(existingCollections::contains).collect(Collectors.joining(","));}
0
private SolrQuery.ORDER getSolrSortOrder(SortOrder sortOrder)
{    return sortOrder == SortOrder.DESC ? ORDER.desc : ORDER.asc;}
0
protected Map<String, Map<String, Long>> getFacetCounts(List<String> fields, QueryResponse solrResponse)
{    Map<String, Map<String, Long>> fieldCounts = new HashMap<>();    for (String field : fields) {        Map<String, Long> valueCounts = new HashMap<>();        FacetField facetField = solrResponse.getFacetField(field);        for (Count facetCount : facetField.getValues()) {            valueCounts.put(facetCount.getName(), facetCount.getCount());        }        fieldCounts.put(field, valueCounts);    }    return fieldCounts;}
0
protected GroupResponse buildGroupResponse(GroupRequest groupRequest, QueryResponse response)
{    String groupNames = groupRequest.getGroups().stream().map(Group::getField).collect(Collectors.joining(","));    List<PivotField> pivotFields = response.getFacetPivot().get(groupNames);    GroupResponse groupResponse = new GroupResponse();    groupResponse.setGroupedBy(groupRequest.getGroups().get(0).getField());    groupResponse.setGroupResults(getGroupResults(groupRequest, 0, pivotFields));    return groupResponse;}
0
protected List<GroupResult> getGroupResults(GroupRequest groupRequest, int index, List<PivotField> pivotFields)
{    List<Group> groups = groupRequest.getGroups();    List<GroupResult> searchResultGroups = new ArrayList<>();    final GroupOrder groupOrder = groups.get(index).getOrder();    pivotFields.sort((o1, o2) -> {        String s1 = groupOrder.getGroupOrderType() == GroupOrderType.TERM ? o1.getValue().toString() : Integer.toString(o1.getCount());        String s2 = groupOrder.getGroupOrderType() == GroupOrderType.TERM ? o2.getValue().toString() : Integer.toString(o2.getCount());        if (groupOrder.getSortOrder() == SortOrder.ASC) {            return s1.compareTo(s2);        } else {            return s2.compareTo(s1);        }    });    for (PivotField pivotField : pivotFields) {        GroupResult groupResult = new GroupResult();        groupResult.setKey(pivotField.getValue().toString());        groupResult.setTotal(pivotField.getCount());        Optional<String> scoreField = groupRequest.getScoreField();        if (scoreField.isPresent()) {            groupResult.setScore((Double) pivotField.getFieldStatsInfo().get(scoreField.get()).getSum());        }        if (index < groups.size() - 1) {            groupResult.setGroupedBy(groups.get(index + 1).getField());            groupResult.setGroupResults(getGroupResults(groupRequest, index + 1, pivotField.getPivot()));        }        searchResultGroups.add(groupResult);    }    return searchResultGroups;}
0
public Document update(Document update, Optional<String> rawIndex) throws IOException
{    Document newVersion = update;        Object commentsObj = update.getDocument().get(COMMENTS_FIELD);    if (commentsObj instanceof List && ((List<Object>) commentsObj).size() > 0 && ((List<Object>) commentsObj).get(0) instanceof Map) {        newVersion = new Document(update);        convertCommentsToRaw(newVersion.getDocument());    }    try {        SolrInputDocument solrInputDocument = SolrUtilities.toSolrInputDocument(newVersion);        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), newVersion.getSensorType(), rawIndex);        if (index.isPresent()) {            this.client.add(index.get(), solrInputDocument);            this.client.commit(index.get());        } else {            throw new IllegalStateException("Index must be specified or inferred.");        }    } catch (SolrServerException e) {        throw new IOException(e);    }    return newVersion;}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) throws IOException
{        Map<String, Collection<SolrInputDocument>> solrCollectionUpdates = new HashMap<>();    Set<String> collectionsUpdated = new HashSet<>();    for (Entry<Document, Optional<String>> entry : updates.entrySet()) {        SolrInputDocument solrInputDocument = SolrUtilities.toSolrInputDocument(entry.getKey());        Optional<String> index = SolrUtilities.getIndex(config.getIndexSupplier(), entry.getKey().getSensorType(), entry.getValue());        if (index.isPresent()) {            Collection<SolrInputDocument> solrInputDocuments = solrCollectionUpdates.getOrDefault(index.get(), new ArrayList<>());            solrInputDocuments.add(solrInputDocument);            solrCollectionUpdates.put(index.get(), solrInputDocuments);            collectionsUpdated.add(index.get());        } else {            String lookupIndex = config.getIndexSupplier().apply(entry.getKey().getSensorType());            Collection<SolrInputDocument> solrInputDocuments = solrCollectionUpdates.getOrDefault(lookupIndex, new ArrayList<>());            solrInputDocuments.add(solrInputDocument);            solrCollectionUpdates.put(lookupIndex, solrInputDocuments);            collectionsUpdated.add(lookupIndex);        }    }    try {        for (Entry<String, Collection<SolrInputDocument>> entry : solrCollectionUpdates.entrySet()) {            this.client.add(entry.getKey(), entry.getValue());        }        for (String collection : collectionsUpdated) {            this.client.commit(collection);        }    } catch (SolrServerException e) {        throw new IOException(e);    }    return updates;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = retrieveLatestDao.getLatest(request.getGuid(), request.getSensorType());    return addCommentToAlert(request, latest);}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to add comment. Document with guid %s cannot be found.", request.getGuid()));    }    @SuppressWarnings("unchecked")    List<Map<String, Object>> comments = (List<Map<String, Object>>) latest.getDocument().getOrDefault(COMMENTS_FIELD, new ArrayList<>());    List<Map<String, Object>> originalComments = new ArrayList<>(comments);        List<String> commentStrs = new ArrayList<>();    for (Map<String, Object> comment : originalComments) {        commentStrs.add(new AlertComment(comment).asJson());    }    commentStrs.add(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()).asJson());    Document newVersion = new Document(latest);    newVersion.getDocument().put(COMMENTS_FIELD, commentStrs);    return update(newVersion, Optional.empty());}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request) throws IOException
{    Document latest = retrieveLatestDao.getLatest(request.getGuid(), request.getSensorType());    return removeCommentFromAlert(request, latest);}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) throws IOException
{    if (latest == null || latest.getDocument() == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s cannot be found.", request.getGuid()));    }    @SuppressWarnings("unchecked")    List<Map<String, Object>> commentMap = (List<Map<String, Object>>) latest.getDocument().get(COMMENTS_FIELD);        if (commentMap == null) {        throw new IOException(String.format("Unable to remove comment. Document with guid %s has no comments.", request.getGuid()));    }    List<Map<String, Object>> originalComments = new ArrayList<>(commentMap);    List<AlertComment> comments = new ArrayList<>();    for (Map<String, Object> commentStr : originalComments) {        comments.add(new AlertComment(commentStr));    }    comments.remove(new AlertComment(request.getComment(), request.getUsername(), request.getTimestamp()));    List<String> commentsAsJson = comments.stream().map(AlertComment::asJson).collect(Collectors.toList());    Document newVersion = new Document(latest);    newVersion.getDocument().put(COMMENTS_FIELD, commentsAsJson);    return update(newVersion, Optional.empty());}
0
public void convertCommentsToRaw(Map<String, Object> source)
{    @SuppressWarnings("unchecked")    List<Map<String, Object>> comments = (List<Map<String, Object>>) source.get(COMMENTS_FIELD);    if (comments == null || comments.isEmpty()) {        return;    }    List<String> asJson = new ArrayList<>();    for (Map<String, Object> comment : comments) {        asJson.add((new AlertComment(comment)).asJson());    }    source.put(COMMENTS_FIELD, asJson);}
0
public static SearchResult getSearchResult(SolrDocument solrDocument, List<String> fields, Function<String, String> indexSupplier)
{    SearchResult searchResult = new SearchResult();    searchResult.setId((String) solrDocument.getFieldValue(Constants.GUID));    searchResult.setIndex(indexSupplier.apply((String) solrDocument.getFieldValue(Constants.SENSOR_TYPE)));    Map<String, Object> docSource = toDocument(solrDocument).getDocument();    final Map<String, Object> source = new HashMap<>();    if (fields != null) {        fields.forEach(field -> source.put(field, docSource.get(field)));    } else {        source.putAll(docSource);    }    searchResult.setSource(source);    return searchResult;}
0
public static Document toDocument(SolrDocument solrDocument)
{    Map<String, Object> document = new HashMap<>();    solrDocument.getFieldNames().stream().filter(name -> !name.equals(SolrDao.VERSION_FIELD)).forEach(name -> document.put(name, solrDocument.getFieldValue(name)));    reformatComments(solrDocument, document);    insertChildAlerts(solrDocument, document);    return new Document(document, (String) solrDocument.getFieldValue(Constants.GUID), (String) solrDocument.getFieldValue(Constants.SENSOR_TYPE), (Long) solrDocument.getFieldValue(Constants.Fields.TIMESTAMP.getName()));}
0
protected static void reformatComments(SolrDocument solrDocument, Map<String, Object> document)
{        @SuppressWarnings("unchecked")    List<String> commentStrs = (List<String>) solrDocument.get(COMMENTS_FIELD);    if (commentStrs != null) {        try {            List<AlertComment> comments = new ArrayList<>();            for (String commentStr : commentStrs) {                comments.add(new AlertComment(commentStr));            }            document.put(COMMENTS_FIELD, comments.stream().map(AlertComment::asMap).collect(Collectors.toList()));        } catch (ParseException e) {            throw new IllegalStateException("Unable to parse comment", e);        }    }}
0
protected static void insertChildAlerts(SolrDocument solrDocument, Map<String, Object> document)
{        if (solrDocument.hasChildDocuments() && solrDocument.getFieldValue(Constants.SENSOR_TYPE).equals(MetaAlertConstants.METAALERT_TYPE)) {        List<Map<String, Object>> childDocuments = new ArrayList<>();        for (SolrDocument childDoc : solrDocument.getChildDocuments()) {            Map<String, Object> childDocMap = new HashMap<>();            childDoc.getFieldNames().stream().filter(name -> !name.equals(SolrDao.VERSION_FIELD)).forEach(name -> childDocMap.put(name, childDoc.getFieldValue(name)));            childDocuments.add(childDocMap);        }        document.put(MetaAlertConstants.ALERT_FIELD, childDocuments);    }}
0
public static SolrInputDocument toSolrInputDocument(Document document)
{    SolrInputDocument solrInputDocument = new SolrInputDocument();    for (Map.Entry<String, Object> field : document.getDocument().entrySet()) {        if (field.getKey().equals(MetaAlertConstants.ALERT_FIELD)) {                        List<Map<String, Object>> alerts = (List<Map<String, Object>>) field.getValue();            for (Map<String, Object> alert : alerts) {                SolrInputDocument childDocument = new SolrInputDocument();                for (Map.Entry<String, Object> alertField : alert.entrySet()) {                    childDocument.addField(alertField.getKey(), alertField.getValue());                }                solrInputDocument.addChildDocument(childDocument);            }        } else {            solrInputDocument.addField(field.getKey(), field.getValue());        }    }    return solrInputDocument;}
0
public static Optional<String> getIndex(Function<String, String> indexSupplier, String sensorName, Optional<String> index)
{    if (index.isPresent()) {        return index;    } else {        String realIndex = indexSupplier.apply(sensorName);        return Optional.ofNullable(realIndex);    }}
0
public String getName()
{    return name;}
0
public FieldType sortMissingLast()
{    this.sortMissingLast = true;    return this;}
0
public FieldType docValues()
{    this.docValues = true;    return this;}
0
public FieldType multiValued()
{    this.multiValued = true;    return this;}
0
public FieldType indexed()
{    this.indexed = true;    return this;}
0
public FieldType stored()
{    this.stored = true;    return this;}
0
public String toString()
{    return String.format("<fieldType name=\"%s\" " + "stored=\"%s\" " + "indexed=\"%s\" " + "multiValued=\"%s\" " + "class=\"%s\" " + "sortMissingLast=\"%s\" " + "docValues=\"%s\"" + "/>", name, stored + "", indexed + "", multiValued + "", solrClass + "", sortMissingLast + "", docValues + "");}
0
public String getTypeDeclaration()
{    return solrType.toString();}
0
public static SolrFields byElasticsearchType(String type)
{    for (SolrFields f : values()) {        if (f.elasticsearchTypes.contains(type)) {            return f;        }    }    return null;}
0
public static void printTypes(PrintWriter pw)
{    for (SolrFields f : values()) {        pw.println(TAB + f.getTypeDeclaration());    }}
0
public static String normalizeField(String fieldName)
{    return fieldName.replace(':', '.');}
0
public static void processProperties(PrintWriter pw, Map<String, Object> properties)
{    for (Map.Entry<String, Object> property : properties.entrySet()) {        String fieldName = normalizeField(property.getKey());        System.out.println("Processing property: " + fieldName);        if (fieldName.equals("guid")) {            pw.println(TAB + "<field name=\"guid\" type=\"" + SolrFields.STRING.solrType.getName() + "\" indexed=\"true\" stored=\"true\" required=\"true\" multiValued=\"false\" />");        } else {            String type = (String) ((Map<String, Object>) property.getValue()).get("type");            SolrFields solrField = SolrFields.byElasticsearchType(type);            if (solrField == null) {                System.out.println("Skipping " + fieldName + " because I can't find solr type for " + type);                continue;            }            pw.println(TAB + String.format("<field name=\"%s\" type=\"%s\" indexed=\"true\" stored=\"true\" />", fieldName, solrField.solrType.getName()));        }    }}
0
public static void processDynamicMappings(PrintWriter pw, List<Map<String, Object>> properties)
{    for (Map<String, Object> dynamicProperty : properties) {        for (Map.Entry<String, Object> dynamicFieldDef : dynamicProperty.entrySet()) {            System.out.println("Processing dynamic property: " + dynamicFieldDef.getKey());            Map<String, Object> def = (Map<String, Object>) dynamicFieldDef.getValue();            String match = (String) def.get("match");            if (match == null) {                match = (String) def.get("path_match");            }            match = normalizeField(match);            String type = (String) ((Map<String, Object>) def.get("mapping")).get("type");            SolrFields solrField = SolrFields.byElasticsearchType(type);            if (solrField == null) {                System.out.println("Skipping " + match + " because I can't find solr type for " + type);                continue;            }            if (solrField == null) {                throw new IllegalStateException("Unable to find associated solr type for " + type + " with dynamic property " + solrField);            }            pw.println(TAB + String.format("<dynamicField name=\"%s\" type=\"%s\" multiValued=\"false\" docValues=\"true\"/>", match, solrField.solrType.getName()));        }    }}
0
public static void translate(PrintWriter pw, Map<String, Object> template)
{    pw.println(PREAMBLE);    System.out.println("Processing " + template.getOrDefault(TEMPLATE_KEY, "unknown template"));    Map<String, Object> mappings = (Map<String, Object>) template.getOrDefault("mappings", new HashMap<>());    if (mappings.size() != 1) {        System.err.println("Unable to process mappings. We expect exactly 1 mapping, there are " + mappings.size() + " mappings specified");    }    String docName = Iterables.getFirst(mappings.keySet(), null);    pw.println(String.format(SCHEMA_FORMAT, docName));    pw.println(TAB + VERSION_FIELD);    pw.println(TAB + ROOT_FIELD);    for (Map.Entry<String, Object> docTypeToMapping : mappings.entrySet()) {        System.out.println("Processing " + docTypeToMapping.getKey() + " doc type");        Map<String, Object> actualMappings = (Map<String, Object>) docTypeToMapping.getValue();        Map<String, Object> properties = (Map<String, Object>) actualMappings.getOrDefault(PROPERTIES_KEY, new HashMap<>());        processProperties(pw, properties);        List<Map<String, Object>> dynamicMappings = (List<Map<String, Object>>) actualMappings.getOrDefault(DYNAMIC_TEMPLATES_KEY, new ArrayList<>());        processDynamicMappings(pw, dynamicMappings);        pw.println(TAB + DYNAMIC_FIELD_CATCHALL);        pw.println(TAB + UNIQUE_KEY);        SolrFields.printTypes(pw);    }    pw.println("</schema>");    pw.flush();}
0
public static void main(String... argv) throws IOException
{    String templateFile = argv[0];    String schemaFile = argv[1];    Map<String, Object> template = JSONUtils.INSTANCE.load(new File(templateFile), JSONUtils.MAP_SUPPLIER);    try (PrintWriter pw = new PrintWriter(new File(schemaFile), StandardCharsets.UTF_8.name())) {        translate(pw, template);    }}
0
public static SolrParams toSolrProps(Map<String, Object> config)
{    if (config == null || config.isEmpty()) {        return null;    }    ModifiableSolrParams ret = new ModifiableSolrParams();    for (Map.Entry<String, Object> kv : config.entrySet()) {        Object v = kv.getValue();        if (v instanceof Boolean) {            ret.set(kv.getKey(), (Boolean) v);        } else if (v instanceof Integer) {            ret.set(kv.getKey(), (Integer) v);        } else if (v instanceof Iterable) {            Iterable vals = (Iterable) v;            String[] strVals = new String[Iterables.size(vals)];            int i = 0;            for (Object o : (Iterable) v) {                strVals[i++] = o.toString();            }        }    }    return ret;}
0
public void createCollection(String name, int numShards, int replicationFactor) throws IOException, SolrServerException
{    if (!listCollections().contains(name)) {        request(getCreateCollectionsRequest(name, numShards, replicationFactor));    }}
0
public QueryRequest getCreateCollectionsRequest(String name, int numShards, int replicationFactor)
{    ModifiableSolrParams params = new ModifiableSolrParams();    params.set(SolrConstants.REQUEST_ACTION, CollectionParams.CollectionAction.CREATE.name());    params.set(SolrConstants.REQUEST_NAME, name);    params.set(SolrConstants.REQUEST_NUM_SHARDS, numShards);    params.set(SolrConstants.REQUEST_REPLICATION_FACTOR, replicationFactor);    params.set(SolrConstants.REQUEST_COLLECTION_CONFIG_NAME, name);    QueryRequest request = new QueryRequest(params);    request.setPath(SolrConstants.REQUEST_COLLECTIONS_PATH);    return request;}
0
public List<String> listCollections() throws IOException, SolrServerException
{    NamedList<Object> response = request(getListCollectionsRequest(), null);    return (List<String>) response.get(SolrConstants.RESPONSE_COLLECTIONS);}
0
public QueryRequest getListCollectionsRequest()
{    ModifiableSolrParams params = new ModifiableSolrParams();    params.set(SolrConstants.REQUEST_ACTION, CollectionParams.CollectionAction.LIST.name());    QueryRequest request = new QueryRequest(params);    request.setPath(SolrConstants.REQUEST_COLLECTIONS_PATH);    return request;}
0
public Optional<T> coerceOrDefault(Map<String, Object> globalConfig, Class<T> clazz)
{    Object val = globalConfig.get(name);    if (val != null) {        T ret = null;        try {            ret = ConversionUtils.convert(val, clazz);        } catch (ClassCastException cce) {            ret = null;        }        if (ret == null) {                                    if (defaultValue.isPresent()) {                return Optional.ofNullable(ConversionUtils.convert(defaultValue.get(), clazz));            } else {                return Optional.empty();            }        } else {            return Optional.ofNullable(ret);        }    } else {        if (defaultValue.isPresent()) {            return Optional.ofNullable(ConversionUtils.convert(defaultValue.get(), clazz));        } else {            return Optional.empty();        }    }}
1
public Supplier<IllegalArgumentException> errorOut(Map<String, Object> globalConfig)
{    String message = "Unable to retrieve " + name + " from global config, value associated is " + globalConfig.get(name);    return () -> new IllegalArgumentException(message);}
0
public T coerceOrDefaultOrExcept(Map<String, Object> globalConfig, Class<T> clazz)
{    return this.coerceOrDefault(globalConfig, clazz).orElseThrow(this.errorOut(globalConfig));}
0
public SolrWriter withMetronSolrClient(MetronSolrClient solr)
{    this.solr = solr;    return this;}
0
public void initializeFromGlobalConfig(Map<String, Object> globalConfiguration)
{    zookeeperUrl = SolrProperties.ZOOKEEPER_QUORUM.coerceOrDefaultOrExcept(globalConfiguration, String.class);    defaultCollection = SolrProperties.DEFAULT_COLLECTION.coerceOrDefaultOrExcept(globalConfiguration, String.class);    solrHttpConfig = SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(globalConfiguration, Map.class);    shouldCommit = SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);    softCommit = SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);    waitSearcher = SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);    waitFlush = SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(globalConfiguration, Boolean.class);}
0
public void init(Map stormConf, WriterConfiguration configurations) throws IOException, SolrServerException
{    Map<String, Object> globalConfiguration = configurations.getGlobalConfig();    initializeFromGlobalConfig(globalConfiguration);                            if (solr == null) {        if (isKerberosEnabled(stormConf)) {            HttpClientUtil.addConfigurer(new Krb5HttpClientConfigurer());        }        solr = new MetronSolrClient(zookeeperUrl, solrHttpConfig);    }    solr.setDefaultCollection(defaultCollection);}
1
public Collection<SolrInputDocument> toDocs(Iterable<BulkMessage<JSONObject>> messages)
{    Collection<SolrInputDocument> ret = new ArrayList<>();    for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        SolrInputDocument document = new SolrInputDocument();        JSONObject message = bulkWriterMessage.getMessage();        for (Object key : message.keySet()) {            Object value = message.get(key);            if (value instanceof Iterable) {                for (Object v : (Iterable) value) {                    document.addField("" + key, v);                }            } else {                document.addField("" + key, value);            }        }        if (!document.containsKey(Constants.GUID)) {            document.addField(Constants.GUID, UUID.randomUUID().toString());        }        ret.add(document);    }    return ret;}
0
protected String getCollection(String sourceType, WriterConfiguration configurations)
{    String collection = configurations.getIndex(sourceType);    if (StringUtils.isEmpty(collection)) {        return solr.getDefaultCollection();    }    return collection;}
0
public BulkWriterResponse write(String sourceType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    String collection = getCollection(sourceType, configurations);    BulkWriterResponse bulkResponse = new BulkWriterResponse();    Collection<SolrInputDocument> docs = toDocs(messages);    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    try {        Optional<SolrException> exceptionOptional = fromUpdateResponse(solr.add(collection, docs));                if (exceptionOptional.isPresent()) {            bulkResponse.addAllErrors(exceptionOptional.get(), ids);        } else {            if (shouldCommit) {                exceptionOptional = fromUpdateResponse(solr.commit(collection, waitFlush, waitSearcher, softCommit));                if (exceptionOptional.isPresent()) {                    bulkResponse.addAllErrors(exceptionOptional.get(), ids);                }            }            if (!exceptionOptional.isPresent()) {                bulkResponse.addAllSuccesses(ids);            }        }    } catch (HttpSolrClient.RemoteSolrException sse) {        bulkResponse.addAllErrors(sse, ids);    }    return bulkResponse;}
0
protected Optional<SolrException> fromUpdateResponse(UpdateResponse response)
{    if (response != null && response.getStatus() > 0) {        String message = "Solr Update response: " + Joiner.on(",").join(response.getResponse());        return Optional.of(new SolrException(SolrException.ErrorCode.BAD_REQUEST, message));    }    return Optional.empty();}
0
public String getName()
{    return SOLR_WRITER_NAME;}
0
public void close() throws Exception
{    if (solr != null) {        solr.close();    }}
0
private boolean isKerberosEnabled(Map stormConfig)
{    if (stormConfig == null) {        return false;    }    String value = (String) stormConfig.get(JAVA_SECURITY_CONFIG_PROPERTY);    return value != null && !value.isEmpty();}
0
public static Configurations getSampleConfigs() throws IOException
{    Configurations configurations = new Configurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH));    return configurations;}
0
public static ParserConfigurations getSampleParserConfigs() throws IOException
{    ParserConfigurations configurations = new ParserConfigurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile(TestConstants.SAMPLE_CONFIG_PATH));    Map<String, byte[]> sensorParserConfigs = ConfigurationsUtils.readSensorParserConfigsFromFile(TestConstants.PARSER_CONFIGS_PATH);    for (String sensorType : sensorParserConfigs.keySet()) {        configurations.updateSensorParserConfig(sensorType, sensorParserConfigs.get(sensorType));    }    return configurations;}
0
public static EnrichmentConfigurations getSampleEnrichmentConfigs() throws IOException
{    EnrichmentConfigurations configurations = new EnrichmentConfigurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile(TestConstants.SAMPLE_CONFIG_PATH));    Map<String, byte[]> sensorEnrichmentConfigs = ConfigurationsUtils.readSensorEnrichmentConfigsFromFile(TestConstants.SAMPLE_CONFIG_PATH);    for (String sensorType : sensorEnrichmentConfigs.keySet()) {        configurations.updateSensorEnrichmentConfig(sensorType, sensorEnrichmentConfigs.get(sensorType));    }    return configurations;}
0
public static IndexingConfigurations getSampleIndexingConfigs() throws IOException
{    IndexingConfigurations configurations = new IndexingConfigurations();    configurations.updateGlobalConfig(ConfigurationsUtils.readGlobalConfigFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH));    Map<String, byte[]> sensorIndexingConfigs = ConfigurationsUtils.readSensorIndexingConfigsFromFile("../" + TestConstants.SAMPLE_CONFIG_PATH);    for (String sensorType : sensorIndexingConfigs.keySet()) {        configurations.updateSensorIndexingConfig(sensorType, sensorIndexingConfigs.get(sensorType));    }    return configurations;}
0
public void testGetZkHostsSingle()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "   zookeeper:2181   ");        }    };    List<String> actual = SolrClientFactory.getZkHosts(globalConfig);    List<String> expected = new ArrayList<>();    expected.add("zookeeper:2181");    assertEquals(expected, actual);}
0
public void testGetZkHostsMultiple()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "   zookeeper:2181    ,   zookeeper2:2181    ");        }    };    List<String> actual = SolrClientFactory.getZkHosts(globalConfig);    List<String> expected = new ArrayList<>();    expected.add("zookeeper:2181");    expected.add("zookeeper2:2181");    assertEquals(expected, actual);}
0
public void setUp() throws Exception
{    solrColumnMetadataDao = new SolrColumnMetadataDao(null);}
0
public void getColumnMetadataShouldProperlyReturnColumnMetadata() throws Exception
{    List<Map<String, Object>> broFields = new ArrayList<>();    broFields.add(new HashMap<String, Object>() {        {            put("name", "string");            put("type", "string");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "int");            put("type", "pint");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "float");            put("type", "pfloat");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "double");            put("type", "pdouble");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "boolean");            put("type", "boolean");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "broField");            put("type", "string");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "conflict");            put("type", "string");        }    });    List<Map<String, Object>> snortFields = new ArrayList<>();    snortFields.add(new HashMap<String, Object>() {        {            put("name", "long");            put("type", "plong");        }    });    snortFields.add(new HashMap<String, Object>() {        {            put("name", "snortField");            put("type", "plong");        }    });    snortFields.add(new HashMap<String, Object>() {        {            put("name", "unknown");            put("type", "unknown");        }    });    broFields.add(new HashMap<String, Object>() {        {            put("name", "conflict");            put("type", "plong");        }    });    solrColumnMetadataDao = spy(new SolrColumnMetadataDao(null));    doReturn(broFields).when(solrColumnMetadataDao).getIndexFields("bro");    doReturn(snortFields).when(solrColumnMetadataDao).getIndexFields("snort");    Map<String, FieldType> columnMetadata = solrColumnMetadataDao.getColumnMetadata(Arrays.asList("bro", "snort"));    assertEquals(FieldType.BOOLEAN, columnMetadata.get("boolean"));    assertEquals(FieldType.TEXT, columnMetadata.get("string"));    assertEquals(FieldType.TEXT, columnMetadata.get("broField"));    assertEquals(FieldType.DOUBLE, columnMetadata.get("double"));    assertEquals(FieldType.LONG, columnMetadata.get("long"));    assertEquals(FieldType.FLOAT, columnMetadata.get("float"));    assertEquals(FieldType.INTEGER, columnMetadata.get("int"));    assertEquals(FieldType.LONG, columnMetadata.get("snortField"));    assertEquals(FieldType.OTHER, columnMetadata.get("conflict"));    assertEquals(FieldType.OTHER, columnMetadata.get("unknown"));}
0
public void getColumnMetadataShouldThrowSolrException() throws Exception
{    exception.expect(IOException.class);    exception.expectMessage("solr exception");    solrColumnMetadataDao = spy(new SolrColumnMetadataDao(null));    doThrow(new SolrServerException("solr exception")).when(solrColumnMetadataDao).getIndexFields("bro");    solrColumnMetadataDao.getColumnMetadata(Arrays.asList("bro", "snort"));}
0
public void getColumnMetadataShouldHandle400Exception() throws Exception
{    solrColumnMetadataDao = spy(new SolrColumnMetadataDao(null));    SolrException solrException = new SolrException(SolrException.ErrorCode.BAD_REQUEST, "solr exception");    doThrow(solrException).when(solrColumnMetadataDao).getIndexFields("bro");    Map<String, FieldType> columnMetadata = solrColumnMetadataDao.getColumnMetadata(Collections.singletonList("bro"));    assertNotNull(columnMetadata);}
0
public void setUp()
{    client = mock(SolrClient.class);    solrSearchDao = mock(SolrSearchDao.class);    solrUpdateDao = mock(SolrUpdateDao.class);    solrRetrieveLatestDao = mock(SolrRetrieveLatestDao.class);    solrColumnMetadataDao = mock(SolrColumnMetadataDao.class);    mockStatic(SolrClientFactory.class);}
0
public void initShouldEnableKerberos()
{    AccessConfig accessConfig = new AccessConfig();    solrDao = spy(new SolrDao(client, accessConfig, solrSearchDao, solrUpdateDao, solrRetrieveLatestDao, solrColumnMetadataDao));    doNothing().when(solrDao).enableKerberos();    solrDao.init(accessConfig);    verify(solrDao, times(0)).enableKerberos();    accessConfig.setKerberosEnabled(true);    solrDao.init(accessConfig);    verify(solrDao).enableKerberos();}
0
public void initShouldCreateDaos() throws Exception
{    AccessConfig accessConfig = new AccessConfig();    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "zookeeper:2181");        }    });    solrDao = spy(new SolrDao());    when(SolrClientFactory.create(accessConfig.getGlobalConfigSupplier().get())).thenReturn(client);    whenNew(SolrSearchDao.class).withArguments(client, accessConfig).thenReturn(solrSearchDao);    whenNew(SolrRetrieveLatestDao.class).withArguments(client, accessConfig).thenReturn(solrRetrieveLatestDao);    whenNew(SolrUpdateDao.class).withArguments(client, solrRetrieveLatestDao, accessConfig).thenReturn(solrUpdateDao);    whenNew(SolrColumnMetadataDao.class).withArguments(client).thenReturn(solrColumnMetadataDao);    solrDao.init(accessConfig);    SearchRequest searchRequest = mock(SearchRequest.class);    solrDao.search(searchRequest);    verify(solrSearchDao).search(searchRequest);    GroupRequest groupRequest = mock(GroupRequest.class);    solrDao.group(groupRequest);    verify(solrSearchDao).group(groupRequest);    solrDao.getLatest("guid", "collection");    verify(solrRetrieveLatestDao).getLatest("guid", "collection");    GetRequest getRequest1 = mock(GetRequest.class);    GetRequest getRequest2 = mock(GetRequest.class);    solrDao.getAllLatest(Arrays.asList(getRequest1, getRequest2));    verify(solrRetrieveLatestDao).getAllLatest(Arrays.asList(getRequest1, getRequest2));    Document document = mock(Document.class);    solrDao.update(document, Optional.of("bro"));    verify(solrUpdateDao).update(document, Optional.of("bro"));    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(document, Optional.of("bro"));        }    };    solrDao.batchUpdate(updates);    verify(solrUpdateDao).batchUpdate(updates);    solrDao.getColumnMetadata(Arrays.asList("bro", "snort"));    verify(solrColumnMetadataDao).getColumnMetadata(Arrays.asList("bro", "snort"));}
0
public static void setupBefore()
{    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "zookeeper:2181");        }    });}
0
public void setUp()
{    client = mock(SolrClient.class);    mockStatic(SolrClientFactory.class);    when(SolrClientFactory.create(accessConfig.getGlobalConfigSupplier().get())).thenReturn(client);}
0
public void testInvalidInit()
{    IndexDao dao = new IndexDao() {        @Override        public SearchResponse search(SearchRequest searchRequest) {            return null;        }        @Override        public GroupResponse group(GroupRequest groupRequest) {            return null;        }        @Override        public void init(AccessConfig config) {        }        @Override        public Document getLatest(String guid, String sensorType) {            return null;        }        @Override        public Iterable<Document> getAllLatest(List<GetRequest> getRequests) {            return null;        }        @Override        public Document update(Document update, Optional<String> index) {            return null;        }        @Override        public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates) {            return null;        }        @Override        public Document addCommentToAlert(CommentAddRemoveRequest request) {            return null;        }        @Override        public Document removeCommentFromAlert(CommentAddRemoveRequest request) {            return null;        }        @Override        public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest) {            return null;        }        @Override        public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest) {            return null;        }        @Override        public Document patch(RetrieveLatestDao dao, PatchRequest request, Optional<Long> timestamp) {            return null;        }        @Override        public Map<String, FieldType> getColumnMetadata(List<String> indices) {            return null;        }    };    SolrMetaAlertDao metaAlertDao = new SolrMetaAlertDao();    metaAlertDao.init(dao);}
0
public SearchResponse search(SearchRequest searchRequest)
{    return null;}
0
public GroupResponse group(GroupRequest groupRequest)
{    return null;}
0
public void init(AccessConfig config)
{}
0
public Document getLatest(String guid, String sensorType)
{    return null;}
0
public Iterable<Document> getAllLatest(List<GetRequest> getRequests)
{    return null;}
0
public Document update(Document update, Optional<String> index)
{    return null;}
0
public Map<Document, Optional<String>> batchUpdate(Map<Document, Optional<String>> updates)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request)
{    return null;}
0
public Document addCommentToAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Document removeCommentFromAlert(CommentAddRemoveRequest request, Document latest)
{    return null;}
0
public Document patch(RetrieveLatestDao dao, PatchRequest request, Optional<Long> timestamp)
{    return null;}
0
public Map<String, FieldType> getColumnMetadata(List<String> indices)
{    return null;}
0
public void testInitInvalidDao()
{    HBaseDao dao = new HBaseDao();    SolrMetaAlertDao solrDao = new SolrMetaAlertDao();    solrDao.init(dao, Optional.empty());}
0
public void testCreateMetaAlertEmptyGuids() throws InvalidCreateException, IOException
{    SolrDao solrDao = new SolrDao();    solrDao.init(accessConfig);    SolrMetaAlertDao emaDao = new SolrMetaAlertDao();    emaDao.init(solrDao);    MetaAlertCreateRequest createRequest = new MetaAlertCreateRequest();    emaDao.createMetaAlert(createRequest);}
0
public void testCreateMetaAlertEmptyGroups() throws InvalidCreateException, IOException
{    SolrDao solrDao = new SolrDao();    solrDao.init(accessConfig);    MultiIndexDao miDao = new MultiIndexDao(solrDao);    SolrMetaAlertDao emaDao = new SolrMetaAlertDao();    emaDao.init(miDao);    MetaAlertCreateRequest createRequest = new MetaAlertCreateRequest();    createRequest.setAlerts(Collections.singletonList(new GetRequest("don't", "care")));    emaDao.createMetaAlert(createRequest);}
0
public void setUp() throws Exception
{    client = mock(SolrClient.class);    accessConfig = mock(AccessConfig.class);    when(accessConfig.getIndexSupplier()).thenReturn(sensorType -> sensorType);    solrSearchDao = new SolrSearchDao(client, accessConfig);    solrRetrieveLatestDao = new SolrRetrieveLatestDao(client, accessConfig);    mockStatic(CollectionAdminRequest.class);    when(CollectionAdminRequest.listCollections(client)).thenReturn(Arrays.asList("bro", "snort"));}
0
public void searchShouldProperlyReturnSearchResponse() throws Exception
{    SearchRequest searchRequest = mock(SearchRequest.class);    SearchResponse searchResponse = mock(SearchResponse.class);    SolrQuery solrQuery = mock(SolrQuery.class);    QueryResponse queryResponse = mock(QueryResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(searchRequest.getQuery()).thenReturn("query");    doReturn(solrQuery).when(solrSearchDao).buildSearchRequest(searchRequest, "*");    when(client.query(solrQuery)).thenReturn(queryResponse);    doReturn(searchResponse).when(solrSearchDao).buildSearchResponse(searchRequest, queryResponse);    assertEquals(searchResponse, solrSearchDao.search(searchRequest, "*"));    verify(solrSearchDao).buildSearchRequest(searchRequest, "*");    verify(client).query(solrQuery);    verify(solrSearchDao).buildSearchResponse(searchRequest, queryResponse);    verifyNoMoreInteractions(client);}
0
public void searchShouldThrowInvalidSearchExceptionOnEmptyQuery() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("Search query is invalid: null");    solrSearchDao.search(new SearchRequest());}
0
public void searchShouldThrowInvalidSearchExceptionOnEmptyClient() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("Uninitialized Dao!  You must call init() prior to use.");    SearchRequest searchRequest = new SearchRequest();    searchRequest.setQuery("query");    new SolrSearchDao(null, accessConfig).search(searchRequest);}
0
public void searchShouldThrowInvalidSearchExceptionOnNullGroup() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("At least 1 group must be provided.");    GroupRequest groupRequest = mock(GroupRequest.class);    GroupResponse groupResponse = mock(GroupResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(groupRequest.getQuery()).thenReturn("query");    when(groupRequest.getGroups()).thenReturn(null);    when(groupRequest.getScoreField()).thenReturn(Optional.of("scoreField"));    when(groupRequest.getIndices()).thenReturn(Arrays.asList("bro", "snort"));    assertEquals(groupResponse, solrSearchDao.group(groupRequest));    verifyNoMoreInteractions(client);}
0
public void searchShouldThrowInvalidSearchExceptionOnEmptyGroup() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("At least 1 group must be provided.");    GroupRequest groupRequest = mock(GroupRequest.class);    GroupResponse groupResponse = mock(GroupResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(groupRequest.getQuery()).thenReturn("query");    when(groupRequest.getGroups()).thenReturn(Collections.EMPTY_LIST);    when(groupRequest.getScoreField()).thenReturn(Optional.of("scoreField"));    when(groupRequest.getIndices()).thenReturn(Arrays.asList("bro", "snort"));    assertEquals(groupResponse, solrSearchDao.group(groupRequest));    verifyNoMoreInteractions(client);}
0
public void searchShouldThrowSearchResultSizeException() throws Exception
{    exception.expect(InvalidSearchException.class);    exception.expectMessage("Search result size must be less than 100");    when(accessConfig.getMaxSearchResults()).thenReturn(100);    SearchRequest searchRequest = new SearchRequest();    searchRequest.setQuery("query");    searchRequest.setSize(200);    solrSearchDao.search(searchRequest);}
0
public void groupShouldProperlyReturnGroupResponse() throws Exception
{    GroupRequest groupRequest = mock(GroupRequest.class);    QueryResponse queryResponse = mock(QueryResponse.class);    GroupResponse groupResponse = mock(GroupResponse.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    Group group1 = new Group();    group1.setField("field1");    Group group2 = new Group();    group2.setField("field2");    when(groupRequest.getQuery()).thenReturn("query");    when(groupRequest.getGroups()).thenReturn(Arrays.asList(group1, group2));    when(groupRequest.getScoreField()).thenReturn(Optional.of("scoreField"));    when(groupRequest.getIndices()).thenReturn(Arrays.asList("bro", "snort"));    when(client.query(any())).thenReturn(queryResponse);    doReturn(groupResponse).when(solrSearchDao).buildGroupResponse(groupRequest, queryResponse);    SolrQuery expectedSolrQuery = new SolrQuery().setStart(0).setRows(0).setQuery("query");    expectedSolrQuery.set("collection", "bro,snort");    expectedSolrQuery.set("stats", true);    expectedSolrQuery.set("stats.field", "{!tag=piv1 sum=true}scoreField");    expectedSolrQuery.set("facet", true);    expectedSolrQuery.set("facet.pivot", "{!stats=piv1}field1,field2");    assertEquals(groupResponse, solrSearchDao.group(groupRequest));    verify(client).query(argThat(new SolrQueryMatcher(expectedSolrQuery)));    verify(solrSearchDao).buildGroupResponse(groupRequest, queryResponse);    verifyNoMoreInteractions(client);}
0
public void getLatestShouldProperlyReturnDocument() throws Exception
{    SolrDocument solrDocument = createSolrDocument("bro", 123456789L);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    when(client.getById("collection", "guid")).thenReturn(solrDocument);    Document document = SolrUtilities.toDocument(solrDocument);    assertEquals(document, solrRetrieveLatestDao.getLatest("guid", "collection"));    verify(client).getById("collection", "guid");    verifyNoMoreInteractions(client);}
0
public void getAllLatestShouldProperlyReturnDocuments() throws Exception
{    GetRequest broRequest1 = new GetRequest("bro-1", "bro");    GetRequest broRequest2 = new GetRequest("bro-2", "bro");    GetRequest snortRequest1 = new GetRequest("snort-1", "snort");    GetRequest snortRequest2 = new GetRequest("snort-2", "snort");    SolrDocument broSolrDoc1 = createSolrDocument("bro", 12345L);    SolrDocument broSolrDoc2 = createSolrDocument("bro", 34567L);    SolrDocument snortSolrDoc1 = createSolrDocument("snort", 12345L);    SolrDocument snortSolrDoc2 = createSolrDocument("snort", 67890L);    Document broDoc1 = SolrUtilities.toDocument(broSolrDoc1);    Document broDoc2 = SolrUtilities.toDocument(broSolrDoc2);    Document snortDoc1 = SolrUtilities.toDocument(snortSolrDoc1);    Document snortDoc2 = SolrUtilities.toDocument(snortSolrDoc2);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    SolrDocumentList broList = new SolrDocumentList();    broList.add(broSolrDoc1);    broList.add(broSolrDoc2);    SolrDocumentList snortList = new SolrDocumentList();    snortList.add(snortSolrDoc1);    snortList.add(snortSolrDoc2);    when(client.getById((Collection<String>) argThat(hasItems("bro-1", "bro-2")), argThat(new ModifiableSolrParamsMatcher(new ModifiableSolrParams().set("collection", "bro"))))).thenReturn(broList);    when(client.getById((Collection<String>) argThat(hasItems("snort-1", "snort-2")), argThat(new ModifiableSolrParamsMatcher(new ModifiableSolrParams().set("collection", "snort"))))).thenReturn(snortList);    assertEquals(Arrays.asList(broDoc1, broDoc2, snortDoc1, snortDoc2), solrRetrieveLatestDao.getAllLatest(Arrays.asList(broRequest1, broRequest2, snortRequest1, snortRequest2)));}
0
public void buildSearchRequestShouldReturnSolrQuery() throws Exception
{    SearchRequest searchRequest = new SearchRequest();    searchRequest.setIndices(Arrays.asList("bro", "snort"));    searchRequest.setSize(5);    searchRequest.setFrom(10);    searchRequest.setQuery("query");    SortField sortField = new SortField();    sortField.setField("sortField");    sortField.setSortOrder("ASC");    searchRequest.setSort(Collections.singletonList(sortField));    searchRequest.setFields(Arrays.asList("field1", "field2"));    searchRequest.setFacetFields(Arrays.asList("facetField1", "facetField2"));    SolrQuery exceptedSolrQuery = new SolrQuery().setStart(10).setRows(5).setQuery("query").addSort("sortField", SolrQuery.ORDER.asc).addField("field1").addField("field2").addFacetField("facetField1", "facetField2");    exceptedSolrQuery.set("collection", "bro,snort");    SolrQuery solrQuery = solrSearchDao.buildSearchRequest(searchRequest, "field1,field2");    assertThat(solrQuery, new SolrQueryMatcher(exceptedSolrQuery));}
0
public void buildSearchResponseShouldReturnSearchResponse()
{    SearchRequest searchRequest = new SearchRequest();    searchRequest.setFields(Collections.singletonList("id"));    searchRequest.setFacetFields(Collections.singletonList("facetField"));    QueryResponse queryResponse = mock(QueryResponse.class);    SolrDocument solrDocument1 = new SolrDocument();    solrDocument1.setField(Constants.GUID, "id1");    solrDocument1.setField("id", "id1");    SolrDocument solrDocument2 = new SolrDocument();    solrDocument2.setField(Constants.GUID, "id2");    solrDocument2.setField("id", "id2");    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    SolrDocumentList solrDocumentList = new SolrDocumentList();    solrDocumentList.add(solrDocument1);    solrDocumentList.add(solrDocument2);    solrDocumentList.setNumFound(100);    when(queryResponse.getResults()).thenReturn(solrDocumentList);    SearchResult searchResult1 = new SearchResult();    searchResult1.setId("id1");    HashMap<String, Object> source1 = new HashMap<>();    source1.put("id", "id1");    searchResult1.setSource(source1);    SearchResult searchResult2 = new SearchResult();    searchResult2.setId("id2");    HashMap<String, Object> source2 = new HashMap<>();    source2.put("id", "id2");    searchResult2.setSource(source2);    Map<String, Map<String, Long>> facetCounts = new HashMap<String, Map<String, Long>>() {        {            put("id", new HashMap<String, Long>() {                {                    put("id1", 1L);                    put("id2", 1L);                }            });        }    };    doReturn(facetCounts).when(solrSearchDao).getFacetCounts(Collections.singletonList("facetField"), queryResponse);    SearchResponse expectedSearchResponse = new SearchResponse();    SearchResult expectedSearchResult1 = new SearchResult();    expectedSearchResult1.setId("id1");    expectedSearchResult1.setSource(source1);    SearchResult expectedSearchResult2 = new SearchResult();    expectedSearchResult2.setId("id2");    expectedSearchResult2.setSource(source2);    expectedSearchResponse.setResults(Arrays.asList(expectedSearchResult1, expectedSearchResult2));    expectedSearchResponse.setTotal(100);    expectedSearchResponse.setFacetCounts(facetCounts);    assertEquals(expectedSearchResponse, solrSearchDao.buildSearchResponse(searchRequest, queryResponse));}
0
public void getSearchResultShouldProperlyReturnResults()
{    SolrDocument solrDocument = mock(SolrDocument.class);    when(solrDocument.getFieldValue(Constants.GUID)).thenReturn("guid");    when(solrDocument.getFieldValue(Constants.SENSOR_TYPE)).thenReturn("sensorType");    when(solrDocument.getFieldValue("field1")).thenReturn("value1");    when(solrDocument.getFieldValue("field2")).thenReturn("value2");    when(solrDocument.getFieldNames()).thenReturn(Arrays.asList("field1", "field2"));    SearchResult expectedSearchResult = new SearchResult();    expectedSearchResult.setId("guid");    expectedSearchResult.setIndex("sensorType");    expectedSearchResult.setSource(new HashMap<String, Object>() {        {            put("field1", "value1");        }    });    assertEquals(expectedSearchResult, SolrUtilities.getSearchResult(solrDocument, Collections.singletonList("field1"), solrSearchDao.getAccessConfig().getIndexSupplier()));    SearchResult expectedSearchResultAllFields = new SearchResult();    expectedSearchResultAllFields.setId("guid");    expectedSearchResultAllFields.setIndex("sensorType");    expectedSearchResultAllFields.setSource(new HashMap<String, Object>() {        {            put("field1", "value1");            put("field2", "value2");        }    });    assertEquals(expectedSearchResultAllFields, SolrUtilities.getSearchResult(solrDocument, null, solrSearchDao.getAccessConfig().getIndexSupplier()));}
0
public void getFacetCountsShouldProperlyReturnFacetCounts()
{    QueryResponse queryResponse = mock(QueryResponse.class);    FacetField facetField1 = new FacetField("field1");    facetField1.add("value1", 1);    facetField1.add("value2", 2);    FacetField facetField2 = new FacetField("field2");    facetField2.add("value3", 3);    facetField2.add("value4", 4);    when(queryResponse.getFacetField("field1")).thenReturn(facetField1);    when(queryResponse.getFacetField("field2")).thenReturn(facetField2);    Map<String, Map<String, Long>> expectedFacetCounts = new HashMap<String, Map<String, Long>>() {        {            put("field1", new HashMap<String, Long>() {                {                    put("value1", 1L);                    put("value2", 2L);                }            });            put("field2", new HashMap<String, Long>() {                {                    put("value3", 3L);                    put("value4", 4L);                }            });        }    };    assertEquals(expectedFacetCounts, solrSearchDao.getFacetCounts(Arrays.asList("field1", "field2"), queryResponse));}
0
public void buildGroupResponseShouldProperlyReturnGroupReponse()
{    GroupRequest groupRequest = mock(GroupRequest.class);    QueryResponse queryResponse = mock(QueryResponse.class);    NamedList namedList = mock(NamedList.class);    List pivotFields = mock(List.class);    List groupResults = mock(List.class);    solrSearchDao = spy(new SolrSearchDao(client, accessConfig));    Group group1 = new Group();    group1.setField("field1");    Group group2 = new Group();    group2.setField("field2");    when(groupRequest.getGroups()).thenReturn(Arrays.asList(group1, group2));    when(queryResponse.getFacetPivot()).thenReturn(namedList);    when(namedList.get("field1,field2")).thenReturn(pivotFields);    doReturn(groupResults).when(solrSearchDao).getGroupResults(groupRequest, 0, pivotFields);    GroupResponse groupResponse = solrSearchDao.buildGroupResponse(groupRequest, queryResponse);    assertEquals("field1", groupResponse.getGroupedBy());    verify(namedList).get("field1,field2");    verify(solrSearchDao).getGroupResults(groupRequest, 0, pivotFields);}
0
public void getGroupResultsShouldProperlyReturnGroupResults()
{    GroupRequest groupRequest = new GroupRequest();    Group group1 = new Group();    group1.setField("field1");    GroupOrder groupOrder1 = new GroupOrder();    groupOrder1.setSortOrder("ASC");    groupOrder1.setGroupOrderType("TERM");    group1.setOrder(groupOrder1);    Group group2 = new Group();    group2.setField("field2");    GroupOrder groupOrder2 = new GroupOrder();    groupOrder2.setSortOrder("DESC");    groupOrder2.setGroupOrderType("COUNT");    group2.setOrder(groupOrder2);    groupRequest.setGroups(Arrays.asList(group1, group2));    groupRequest.setScoreField("score");    PivotField level1Pivot1 = mock(PivotField.class);    PivotField level1Pivot2 = mock(PivotField.class);    PivotField level2Pivot1 = mock(PivotField.class);    PivotField level2Pivot2 = mock(PivotField.class);    FieldStatsInfo level1Pivot1FieldStatsInfo = mock(FieldStatsInfo.class);    FieldStatsInfo level1Pivot2FieldStatsInfo = mock(FieldStatsInfo.class);    FieldStatsInfo level2Pivot1FieldStatsInfo = mock(FieldStatsInfo.class);    FieldStatsInfo level2Pivot2FieldStatsInfo = mock(FieldStatsInfo.class);    List<PivotField> level1Pivots = Arrays.asList(level1Pivot1, level1Pivot2);    List<PivotField> level2Pivots = Arrays.asList(level2Pivot1, level2Pivot2);    when(level1Pivot1.getValue()).thenReturn("field1value1");    when(level1Pivot1.getCount()).thenReturn(1);    when(level1Pivot1FieldStatsInfo.getSum()).thenReturn(1.0);    when(level1Pivot1.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level1Pivot1FieldStatsInfo);        }    });    when(level1Pivot2.getValue()).thenReturn("field1value2");    when(level1Pivot2.getCount()).thenReturn(2);    when(level1Pivot2FieldStatsInfo.getSum()).thenReturn(2.0);    when(level1Pivot2.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level1Pivot2FieldStatsInfo);        }    });    when(level2Pivot1.getValue()).thenReturn("field2value1");    when(level2Pivot1.getCount()).thenReturn(3);    when(level2Pivot1FieldStatsInfo.getSum()).thenReturn(3.0);    when(level2Pivot1.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level2Pivot1FieldStatsInfo);        }    });    when(level2Pivot2.getValue()).thenReturn("field2value2");    when(level2Pivot2.getCount()).thenReturn(4);    when(level2Pivot2FieldStatsInfo.getSum()).thenReturn(4.0);    when(level2Pivot2.getFieldStatsInfo()).thenReturn(new HashMap<String, FieldStatsInfo>() {        {            put("score", level2Pivot2FieldStatsInfo);        }    });    when(level1Pivot1.getPivot()).thenReturn(level2Pivots);    List<GroupResult> level1GroupResults = solrSearchDao.getGroupResults(groupRequest, 0, level1Pivots);    assertEquals("field1value1", level1GroupResults.get(0).getKey());    assertEquals(1, level1GroupResults.get(0).getTotal());    assertEquals(1.0, level1GroupResults.get(0).getScore(), 0.00001);    assertEquals("field2", level1GroupResults.get(0).getGroupedBy());    assertEquals("field1value2", level1GroupResults.get(1).getKey());    assertEquals(2, level1GroupResults.get(1).getTotal());    assertEquals(2.0, level1GroupResults.get(1).getScore(), 0.00001);    assertEquals("field2", level1GroupResults.get(1).getGroupedBy());    assertEquals(0, level1GroupResults.get(1).getGroupResults().size());    List<GroupResult> level2GroupResults = level1GroupResults.get(0).getGroupResults();    assertEquals("field2value2", level2GroupResults.get(0).getKey());    assertEquals(4, level2GroupResults.get(0).getTotal());    assertEquals(4.0, level2GroupResults.get(0).getScore(), 0.00001);    assertNull(level2GroupResults.get(0).getGroupedBy());    assertNull(level2GroupResults.get(0).getGroupResults());    assertEquals("field2value1", level2GroupResults.get(1).getKey());    assertEquals(3, level2GroupResults.get(1).getTotal());    assertEquals(3.0, level2GroupResults.get(1).getScore(), 0.00001);    assertNull(level2GroupResults.get(1).getGroupedBy());    assertNull(level2GroupResults.get(1).getGroupResults());}
0
private SolrDocument createSolrDocument(String sensorType, Long timestamp)
{    SolrDocument solrDocument = new SolrDocument();    solrDocument.addField(SolrDao.VERSION_FIELD, 1.0);    solrDocument.addField(Constants.GUID, UUID.randomUUID().toString());    solrDocument.addField(Constants.SENSOR_TYPE, sensorType);    solrDocument.addField(Constants.Fields.TIMESTAMP.getName(), timestamp);    solrDocument.addField(Constants.Fields.SRC_ADDR.getName(), "192.168.1.1");    return solrDocument;}
0
public static void setupBefore()
{    accessConfig.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, "zookeeper:2181");        }    });    IndexingConfigurations indexingConfigs = mock(IndexingConfigurations.class);    ConfigurationsCache cache = mock(ConfigurationsCache.class);    Map<String, Object> broIndexingConfig = new HashMap<String, Object>() {        {            put("solr", new HashMap<String, Object>() {                {                }            });        }    };    when(indexingConfigs.getSensorIndexingConfig("bro")).thenReturn(broIndexingConfig);    when(cache.get(IndexingConfigurations.class)).thenReturn(indexingConfigs);    accessConfig.setIndexSupplier(IndexingCacheUtil.getIndexLookupFunction(cache, "solr"));}
0
public void setUp() throws Exception
{    client = mock(SolrClient.class);    solrRetrieveLatestDao = new SolrRetrieveLatestDao(client, accessConfig);    solrUpdateDao = new SolrUpdateDao(client, solrRetrieveLatestDao, accessConfig);}
0
public void updateShouldProperlyUpdateDocumentImplicitIndex() throws Exception
{    Document document = new Document(new HashMap<String, Object>() {        {            put("field", "value");        }    }, "guid", "bro", 0L);    SolrInputDocument solrInputDocument = new SolrInputDocument();    solrInputDocument.addField("field", "value");    solrUpdateDao.update(document, Optional.empty());    verify(client).add(eq("bro"), argThat(new SolrInputDocumentMatcher(solrInputDocument)));}
0
public void updateShouldProperlyUpdateDocumentExplicitIndex() throws Exception
{    Document document = new Document(new HashMap<String, Object>() {        {            put("field", "value");        }    }, "guid", "bro", 0L);    SolrInputDocument solrInputDocument = new SolrInputDocument();    solrInputDocument.addField("field", "value");    solrUpdateDao.update(document, Optional.of("bro"));    verify(client).add(eq("bro"), argThat(new SolrInputDocumentMatcher(solrInputDocument)));}
0
public void batchUpdateShouldProperlyUpdateDocuments() throws Exception
{    Document broDocument1 = new Document(new HashMap<String, Object>() {        {            put("broField1", "value");            put("guid", "broGuid1");        }    }, "broGuid1", "bro", 0L);    Document broDocument2 = new Document(new HashMap<String, Object>() {        {            put("broField2", "value");            put("guid", "broGuid2");        }    }, "broGuid2", "bro", 0L);    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(broDocument1, Optional.of("bro"));            put(broDocument2, Optional.of("bro"));        }    };    SolrInputDocument broSolrInputDocument1 = new SolrInputDocument();    broSolrInputDocument1.addField("broField1", "value");    broSolrInputDocument1.addField("guid", "broGuid1");    SolrInputDocument broSolrInputDocument2 = new SolrInputDocument();    broSolrInputDocument2.addField("broField2", "value");    broSolrInputDocument2.addField("guid", "broGuid2");    solrUpdateDao.batchUpdate(updates);    verify(client).add(eq("bro"), argThat(new SolrInputDocumentListMatcher(Arrays.asList(broSolrInputDocument1, broSolrInputDocument2))));}
0
public void batchUpdateShouldProperlyUpdateDocumentsWithoutIndex() throws Exception
{    Document snortDocument1 = new Document(new HashMap<String, Object>() {        {            put("snortField1", "value");            put("guid", "snortGuid1");        }    }, "snortGuid1", "snort", 0L);    Document snortDocument2 = new Document(new HashMap<String, Object>() {        {            put("snortField2", "value");            put("guid", "snortGuid2");        }    }, "snortGuid2", "snort", 0L);    Map<Document, Optional<String>> updates = new HashMap<Document, Optional<String>>() {        {            put(snortDocument1, Optional.empty());            put(snortDocument2, Optional.empty());        }    };    SolrInputDocument snortSolrInputDocument1 = new SolrInputDocument();    snortSolrInputDocument1.addField("snortField1", "value");    snortSolrInputDocument1.addField("guid", "snortGuid1");    SolrInputDocument snortSolrInputDocument2 = new SolrInputDocument();    snortSolrInputDocument2.addField("snortField2", "value");    snortSolrInputDocument2.addField("guid", "snortGuid2");    solrUpdateDao.batchUpdate(updates);    verify(client).add(eq("snort"), argThat(new SolrInputDocumentListMatcher(Arrays.asList(snortSolrInputDocument1, snortSolrInputDocument2))));}
0
public void testConvertCommentsToRaw()
{    List<Map<String, Object>> commentList = new ArrayList<>();    Map<String, Object> comments = new HashMap<>();    comments.put("comment", "test comment");    comments.put("username", "test username");    comments.put("timestamp", 1526424323279L);    commentList.add(comments);    Map<String, Object> document = new HashMap<>();    document.put("testField", "testValue");    document.put(COMMENTS_FIELD, commentList);    solrUpdateDao.convertCommentsToRaw(document);    @SuppressWarnings("unchecked")    List<String> actualComments = (List<String>) document.get(COMMENTS_FIELD);    String expectedComment = "{\"comment\":\"test comment\",\"username\":\"test username\",\"timestamp\":1526424323279}";    assertEquals(expectedComment, actualComments.get(0));    assertEquals(1, actualComments.size());    assertEquals("testValue", document.get("testField"));}
0
public void getPatchedDocument() throws IOException, OriginalNotFoundException
{        Map<String, Object> latestDoc = new HashMap<>();    latestDoc.put(Constants.GUID, "guid");    List<Map<String, Object>> comments = new ArrayList<>();    comments.add(new AlertComment("comment", "user", 0L).asMap());    comments.add(new AlertComment("comment_2", "user_2", 0L).asMap());    latestDoc.put(COMMENTS_FIELD, comments);    Document latest = new Document(latestDoc, "guid", "bro", 0L);    SolrRetrieveLatestDao retrieveLatestDao = spy(new SolrRetrieveLatestDao(null, accessConfig));    doReturn(latest).when(retrieveLatestDao).getLatest("guid", "bro");        PatchRequest request = new PatchRequest();    request.setIndex("bro");    request.setSensorType("bro");    request.setGuid("guid");    List<Map<String, Object>> patchList = new ArrayList<>();    Map<String, Object> patch = new HashMap<>();    patch.put("op", "add");    patch.put("path", "/project");    patch.put("value", "metron");    patchList.add(patch);    request.setPatch(patchList);    Document actual = solrUpdateDao.getPatchedDocument(retrieveLatestDao, request, Optional.of(0L));        latest.getDocument().put("project", "metron");    assertEquals(actual, latest);}
0
public UpdateDao getUpdateDao()
{    return solrUpdateDao;}
0
public void toDocumentShouldProperlyReturnDocument() throws Exception
{    long expectedTimestamp = System.currentTimeMillis();    SolrDocument solrDocument = new SolrDocument();    solrDocument.addField(SolrDao.VERSION_FIELD, 1.0);    solrDocument.addField(Constants.GUID, "guid");    solrDocument.addField(Constants.SENSOR_TYPE, "bro");    solrDocument.addField(Constants.Fields.TIMESTAMP.getName(), expectedTimestamp);    solrDocument.addField("field", "value");    Document expectedDocument = new Document(new HashMap<String, Object>() {        {            put("field", "value");            put(Constants.GUID, "guid");            put(Constants.SENSOR_TYPE, "bro");            put(Constants.Fields.TIMESTAMP.getName(), expectedTimestamp);        }    }, "guid", "bro", expectedTimestamp);    Document actualDocument = SolrUtilities.toDocument(solrDocument);    assertEquals(expectedDocument, actualDocument);}
0
public Builder withPort(int port)
{    this.port = port;    return this;}
0
public Builder withSolrXmlPath(String solrXmlPath)
{    this.solrXmlPath = solrXmlPath;    return this;}
0
public Builder addInitialCollection(String name, String configPath)
{    initialCollections.put(name, configPath);    return this;}
0
public Builder withPostStartCallback(Function<SolrComponent, Void> f)
{    postStartCallback = f;    return this;}
0
public SolrComponent build()
{    return new SolrComponent(port, solrXmlPath, initialCollections, postStartCallback);}
0
public void start() throws UnableToStartException
{    try {        File baseDir = Files.createTempDirectory("solrcomponent").toFile();        baseDir.deleteOnExit();        miniSolrCloudCluster = new MiniSolrCloudCluster(1, baseDir.toPath(), JettyConfig.builder().setPort(port).build());        for (String name : collections.keySet()) {            String configPath = collections.get(name);            miniSolrCloudCluster.uploadConfigSet(new File(configPath).toPath(), name);            CollectionAdminRequest.createCollection(name, 1, 1).process(miniSolrCloudCluster.getSolrClient());        }        if (postStartCallback != null) {            postStartCallback.apply(this);        }    } catch (Exception e) {        throw new UnableToStartException(e.getMessage(), e);    }}
0
public void stop()
{    try {        miniSolrCloudCluster.deleteAllCollections();        miniSolrCloudCluster.shutdown();    } catch (Exception e) {        }}
0
public void reset()
{    try {        miniSolrCloudCluster.deleteAllCollections();    } catch (Exception e) {        }}
0
public MetronSolrClient getSolrClient()
{    return new MetronSolrClient(getZookeeperUrl());}
0
public MiniSolrCloudCluster getMiniSolrCloudCluster()
{    return this.miniSolrCloudCluster;}
0
public String getZookeeperUrl()
{    return miniSolrCloudCluster.getZkServer().getZkAddress();}
0
public void addCollection(String name, String configPath) throws InterruptedException, IOException, KeeperException, SolrServerException
{    miniSolrCloudCluster.uploadConfigSet(new File(configPath).toPath(), name);    CollectionAdminRequest.createCollection(name, 1, 1).process(miniSolrCloudCluster.getSolrClient());}
0
public boolean hasCollection(String collection)
{    MetronSolrClient solr = getSolrClient();    boolean collectionFound = false;    try {        collectionFound = solr.listCollections().contains(collection);    } catch (Exception e) {        e.printStackTrace();    }    return collectionFound;}
0
public List<Map<String, Object>> getAllIndexedDocs(String collection)
{    List<Map<String, Object>> docs = new ArrayList<>();    CloudSolrClient solr = miniSolrCloudCluster.getSolrClient();    solr.setDefaultCollection(collection);    SolrQuery parameters = new SolrQuery();        if (collection.equals("metaalert")) {        parameters.setQuery("source.type:metaalert").setFields("*", "[child parentFilter=source.type:metaalert limit=999]");    } else {        parameters.set("q", "*:*");    }    try {        solr.commit();        QueryResponse response = solr.query(parameters);        for (SolrDocument solrDocument : response.getResults()) {                        docs.add(SolrUtilities.toDocument(solrDocument).getDocument());        }    } catch (SolrServerException | IOException e) {        e.printStackTrace();    }    return docs;}
0
public void addDocs(String collection, List<Map<String, Object>> docs) throws IOException, SolrServerException
{    CloudSolrClient solr = miniSolrCloudCluster.getSolrClient();    solr.setDefaultCollection(collection);    Collection<SolrInputDocument> solrInputDocuments = docs.stream().map(doc -> {        SolrInputDocument solrInputDocument = new SolrInputDocument();        for (Entry<String, Object> entry : doc.entrySet()) {                        if (entry.getValue() instanceof List && !entry.getKey().equals(MetaAlertConstants.METAALERT_FIELD)) {                for (Object entryItem : (List) entry.getValue()) {                    if (entryItem instanceof Map) {                        @SuppressWarnings("unchecked")                        Map<String, Object> childDoc = (Map<String, Object>) entryItem;                        SolrInputDocument childInputDoc = new SolrInputDocument();                        for (Entry<String, Object> childEntry : childDoc.entrySet()) {                            childInputDoc.addField(childEntry.getKey(), childEntry.getValue());                        }                        solrInputDocument.addChildDocument(childInputDoc);                    }                }            } else {                solrInputDocument.addField(entry.getKey(), entry.getValue());            }        }        return solrInputDocument;    }).collect(Collectors.toList());    checkUpdateResponse(solr.add(collection, solrInputDocuments));        checkUpdateResponse(solr.commit(true, true));}
0
protected void checkUpdateResponse(UpdateResponse result) throws IOException
{    if (result.getStatus() != 0) {        throw new IOException("Response error received while adding documents: " + result);    }}
0
public static Iterable<String> getData(String sensor) throws IOException
{    return Iterables.filter(Files.readLines(new File("src/test/resources/example_data/" + sensor), Charset.defaultCharset()), s -> !s.startsWith("#") && s.length() > 0);}
0
public static Map<String, Object> getGlobalConfig(String sensorType, SolrComponent component)
{    Map<String, Object> globalConfig = new HashMap<>();    globalConfig.put(SOLR_ZOOKEEPER, component.getZookeeperUrl());    return globalConfig;}
0
public static SolrComponent createSolrComponent(String sensor) throws Exception
{    return new SolrComponent.Builder().build();}
0
public void testError() throws Exception
{    test("error");}
0
public void testBro() throws Exception
{    test("bro");}
0
public void testSnort() throws Exception
{    test("snort");}
0
public void testYaf() throws Exception
{    test("yaf");}
0
public String getGuid(Map<String, Object> m)
{    if (m.containsKey("guid")) {        return (String) m.get("guid");    } else {        return (String) m.get("original_string");    }}
0
public void test(String sensorType) throws Exception
{    SolrComponent component = null;    try {        component = createSolrComponent(sensorType);        component.start();        component.addCollection(String.format("%s", sensorType), String.format("src/main/config/schema/%s", sensorType));        Map<String, Object> globalConfig = getGlobalConfig(sensorType, component);        List<BulkMessage<JSONObject>> messages = new ArrayList<>();        Map<String, Map<String, Object>> index = new HashMap<>();        int i = 0;        for (String message : getData(sensorType)) {            if (message.trim().length() > 0) {                Map<String, Object> m = JSONUtils.INSTANCE.load(message.trim(), JSONUtils.MAP_SUPPLIER);                String guid = getGuid(m);                index.put(guid, m);                messages.add(new BulkMessage<>(String.format("message%d", ++i), new JSONObject(m)));            }        }        Assert.assertTrue(messages.size() > 0);        SolrWriter solrWriter = new SolrWriter();        WriterConfiguration writerConfig = new WriterConfiguration() {            @Override            public int getBatchSize(String sensorName) {                return messages.size();            }            @Override            public int getBatchTimeout(String sensorName) {                return 0;            }            @Override            public List<Integer> getAllConfiguredTimeouts() {                return new ArrayList<>();            }            @Override            public String getIndex(String sensorName) {                return sensorType;            }            @Override            public boolean isEnabled(String sensorName) {                return true;            }            @Override            public Map<String, Object> getSensorConfig(String sensorName) {                return new HashMap<String, Object>() {                    {                        put("index", sensorType);                        put("batchSize", messages.size());                        put("enabled", true);                    }                };            }            @Override            public Map<String, Object> getGlobalConfig() {                return globalConfig;            }            @Override            public boolean isDefault(String sensorName) {                return false;            }            @Override            public String getFieldNameConverter(String sensorName) {                return null;            }        };        solrWriter.init(null, writerConfig);        BulkWriterResponse response = solrWriter.write(sensorType, writerConfig, messages);        Assert.assertTrue(response.getErrors().isEmpty());        for (Map<String, Object> m : component.getAllIndexedDocs(sensorType)) {            Map<String, Object> expected = index.get(getGuid(m));            for (Map.Entry<String, Object> field : expected.entrySet()) {                if (field.getValue() instanceof Collection && ((Collection) field.getValue()).size() == 0) {                    continue;                }                if (m.get(field.getKey()) instanceof Number) {                    Number n1 = ConversionUtils.convert(field.getValue(), Double.class);                    Number n2 = (Number) m.get(field.getKey());                    boolean isSame = Math.abs(n1.doubleValue() - n2.doubleValue()) < 1e-3;                    if (!isSame) {                        String s1 = "" + n1.doubleValue();                        String s2 = "" + n2.doubleValue();                        isSame = s1.startsWith(s2) || s2.startsWith(s1);                    }                    Assert.assertTrue("Unable to validate " + field.getKey() + ": " + n1 + " != " + n2, isSame);                } else {                    Assert.assertEquals("Unable to find " + field.getKey(), "" + field.getValue(), "" + m.get(field.getKey()));                }            }        }    } finally {        if (component != null) {            component.stop();        }    }}
0
public int getBatchSize(String sensorName)
{    return messages.size();}
0
public int getBatchTimeout(String sensorName)
{    return 0;}
0
public List<Integer> getAllConfiguredTimeouts()
{    return new ArrayList<>();}
0
public String getIndex(String sensorName)
{    return sensorType;}
0
public boolean isEnabled(String sensorName)
{    return true;}
0
public Map<String, Object> getSensorConfig(String sensorName)
{    return new HashMap<String, Object>() {        {            put("index", sensorType);            put("batchSize", messages.size());            put("enabled", true);        }    };}
0
public Map<String, Object> getGlobalConfig()
{    return globalConfig;}
0
public boolean isDefault(String sensorName)
{    return false;}
0
public String getFieldNameConverter(String sensorName)
{    return null;}
0
public static void setupBefore() throws Exception
{        MAX_RETRIES = 1;        solr = new SolrComponent.Builder().build();    solr.start();    AccessConfig accessConfig = new AccessConfig();    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put("solr.clustername", "metron");            put("solr.port", "9300");            put("solr.ip", "localhost");            put("solr.date.format", DATE_FORMAT);            put(SOLR_ZOOKEEPER, solr.getZookeeperUrl());        }    };    accessConfig.setMaxSearchResults(1000);    accessConfig.setGlobalConfigSupplier(() -> globalConfig);    accessConfig.setMaxSearchGroups(100);        accessConfig.setIndexSupplier(s -> s);    solrDao = new SolrDao();    solrDao.init(accessConfig);    MetaAlertConfig config = new MetaAlertConfig(METAALERTS_COLLECTION, THREAT_SORT_DEFAULT, () -> ImmutableMap.of(Constants.SENSOR_TYPE_FIELD_PROPERTY, Constants.SENSOR_TYPE, Constants.THREAT_SCORE_FIELD_PROPERTY, THREAT_FIELD_DEFAULT)) {        @Override        protected String getDefaultThreatTriageField() {            return THREAT_FIELD_DEFAULT.replace(':', '.');        }        @Override        protected String getDefaultSourceTypeField() {            return Constants.SENSOR_TYPE;        }    };    SolrClient solrClient = SolrClientFactory.create(globalConfig);    SolrMetaAlertSearchDao searchDao = new SolrMetaAlertSearchDao(solrClient, solrDao.getSolrSearchDao(), config);    SolrMetaAlertRetrieveLatestDao retrieveLatestDao = new SolrMetaAlertRetrieveLatestDao(solrClient, solrDao);    SolrMetaAlertUpdateDao updateDao = new SolrMetaAlertUpdateDao(solrClient, solrDao, searchDao, retrieveLatestDao, config);    metaDao = new SolrMetaAlertDao(solrDao, searchDao, updateDao, retrieveLatestDao);}
0
protected String getDefaultThreatTriageField()
{    return THREAT_FIELD_DEFAULT.replace(':', '.');}
0
protected String getDefaultSourceTypeField()
{    return Constants.SENSOR_TYPE;}
0
public void setup() throws IOException, InterruptedException, SolrServerException, KeeperException
{    solr.addCollection(METAALERTS_COLLECTION, "./src/main/config/schema//metaalert");    solr.addCollection(SENSOR_NAME, "./src/test/resources/config/test/conf");}
0
public static void teardown()
{    SolrClientFactory.close();    if (solr != null) {        solr.stop();    }}
0
public void reset()
{    solr.reset();}
0
public void shouldSearchByNestedAlert() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(4);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(0).put("ip_src_addr", "192.168.1.1");    alerts.get(0).put("ip_src_port", 8010);    alerts.get(1).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(1).put("ip_src_addr", "192.168.1.2");    alerts.get(1).put("ip_src_port", 8009);    alerts.get(2).put("ip_src_addr", "192.168.1.3");    alerts.get(2).put("ip_src_port", 8008);    alerts.get(3).put("ip_src_addr", "192.168.1.4");    alerts.get(3).put("ip_src_port", 8007);    addRecords(alerts, getTestIndexName(), SENSOR_NAME);        setupTypings();        Map<String, Object> activeMetaAlert = buildMetaAlert("meta_active", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0), alerts.get(1))));    Map<String, Object> inactiveMetaAlert = buildMetaAlert("meta_inactive", MetaAlertStatus.INACTIVE, Optional.of(Arrays.asList(alerts.get(2), alerts.get(3))));        addRecords(Arrays.asList(activeMetaAlert, inactiveMetaAlert), METAALERTS_COLLECTION, METAALERT_TYPE);        findCreatedDocs(Arrays.asList(new GetRequest("message_0", SENSOR_NAME), new GetRequest("message_1", SENSOR_NAME), new GetRequest("message_2", SENSOR_NAME), new GetRequest("message_3", SENSOR_NAME), new GetRequest("meta_active", METAALERT_TYPE), new GetRequest("meta_inactive", METAALERT_TYPE)));    SearchResponse searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.1 AND ip_src_port:8010");            setIndices(Collections.singletonList(METAALERT_TYPE));            setFrom(0);            setSize(5);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        List<Map<String, Object>> actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertEquals(2, actualAlerts.size());    Assert.assertEquals("meta_active", searchResponse.getResults().get(0).getSource().get("guid"));            searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.1 AND ip_src_port:8010");            setIndices(queryIndices);            setFrom(0);            setSize(5);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertEquals(2, actualAlerts.size());    Assert.assertEquals("meta_active", searchResponse.getResults().get(0).getSource().get("guid"));            searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.3 AND ip_src_port:8008");            setIndices(queryIndices);            setFrom(0);            setSize(1);            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertNull(actualAlerts);    Assert.assertEquals("message_2", searchResponse.getResults().get(0).getSource().get("guid"));}
0
public void shouldNotRetrieveFullChildrenWithoutSourceType() throws Exception
{        List<Map<String, Object>> alerts = buildAlerts(1);    alerts.get(0).put(METAALERT_FIELD, Collections.singletonList("meta_active"));    alerts.get(0).put("ip_src_addr", "192.168.1.1");    alerts.get(0).put("ip_src_port", 8010);    addRecords(alerts, getTestIndexName(), SENSOR_NAME);        setupTypings();        Map<String, Object> activeMetaAlert = buildMetaAlert("meta_active", MetaAlertStatus.ACTIVE, Optional.of(Arrays.asList(alerts.get(0))));        addRecords(Collections.singletonList(activeMetaAlert), METAALERTS_COLLECTION, METAALERT_TYPE);        findCreatedDocs(Collections.singletonList(new GetRequest("meta_active", METAALERT_TYPE)));    SearchResponse searchResponse = metaDao.search(new SearchRequest() {        {            setQuery("ip_src_addr:192.168.1.1 AND ip_src_port:8010");            setIndices(Collections.singletonList(METAALERT_TYPE));            setFrom(0);            setSize(5);            setFields(Collections.singletonList(Constants.GUID));            setSort(Collections.singletonList(new SortField() {                {                    setField(Constants.GUID);                }            }));        }    });        Assert.assertEquals(1, searchResponse.getTotal());        List<Map<String, Object>> actualAlerts = (List<Map<String, Object>>) searchResponse.getResults().get(0).getSource().get(MetaAlertConstants.ALERT_FIELD);    Assert.assertNull(actualAlerts);    Assert.assertEquals("meta_active", searchResponse.getResults().get(0).getSource().get("guid"));}
0
protected long getMatchingAlertCount(String fieldName, Object fieldValue) throws InterruptedException
{    long cnt = 0;    for (int t = 0; t < MAX_RETRIES && cnt == 0; ++t, Thread.sleep(SLEEP_MS)) {        List<Map<String, Object>> docs = solr.getAllIndexedDocs(getTestIndexName());        cnt = docs.stream().filter(d -> {            Object newfield = d.get(fieldName);            return newfield != null && newfield.equals(fieldValue);        }).count();    }    return cnt;}
0
protected long getMatchingMetaAlertCount(String fieldName, String fieldValue) throws InterruptedException
{    long cnt = 0;    for (int t = 0; t < MAX_RETRIES && cnt == 0; ++t, Thread.sleep(SLEEP_MS)) {        List<Map<String, Object>> docs = solr.getAllIndexedDocs(METAALERTS_COLLECTION);        cnt = docs.stream().filter(d -> {            @SuppressWarnings("unchecked")            List<Map<String, Object>> alerts = (List<Map<String, Object>>) d.get(ALERT_FIELD);            for (Map<String, Object> alert : alerts) {                Object newField = alert.get(fieldName);                if (newField != null && newField.equals(fieldValue)) {                    return true;                }            }            return false;        }).count();    }    return cnt;}
0
protected void addRecords(List<Map<String, Object>> inputData, String index, String docType) throws IOException
{        try {        solr.addDocs(index, inputData);    } catch (SolrServerException e) {        throw new IOException("Unable to load Solr Docs", e);    }}
0
protected void setupTypings()
{}
0
protected String getTestIndexName()
{    return COLLECTION;}
0
protected String getMetaAlertIndex()
{    return METAALERTS_COLLECTION;}
0
protected String getSourceTypeField()
{    return Constants.SENSOR_TYPE;}
0
protected void commit() throws IOException
{    try {        List<String> collections = solr.getSolrClient().listCollections();        for (String collection : collections) {            solr.getSolrClient().commit(collection);        }    } catch (SolrServerException e) {        throw new IOException("Unable to commit", e);    }}
0
protected void setEmptiedMetaAlertField(Map<String, Object> docMap)
{    docMap.remove(METAALERT_FIELD);}
0
protected boolean isFiniteDoubleOnly()
{    return false;}
0
protected boolean isEmptyMetaAlertList()
{    return false;}
0
public static void setupBeforeClass() throws Exception
{    solrComponent = new SolrComponent.Builder().build();    solrComponent.start();}
0
public void setup() throws Exception
{    solrComponent.addCollection(TEST_COLLECTION, "./src/test/resources/config/test/conf");    solrComponent.addCollection(BRO_SENSOR, "./src/main/config/schema/bro");    AccessConfig accessConfig = new AccessConfig();    Map<String, Object> globalConfig = new HashMap<>();    globalConfig.put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());    accessConfig.setGlobalConfigSupplier(() -> globalConfig);        accessConfig.setIndexSupplier(s -> s.equals(TEST_SENSOR) ? TEST_COLLECTION : s);    dao = new SolrDao();    dao.init(accessConfig);    addData(BRO_SENSOR, BRO_SENSOR, expectedTimestamp);    addData(TEST_COLLECTION, TEST_SENSOR, expectedTimestamp);}
0
public void reset()
{    solrComponent.reset();}
0
public static void teardown()
{    SolrClientFactory.close();    solrComponent.stop();}
0
public void testGetLatest() throws IOException
{    Document actual = dao.getLatest("message_1_bro", BRO_SENSOR);    assertEquals(buildExpectedDocument(BRO_SENSOR, 1), actual);}
0
public void testGetMissing() throws IOException
{    Document actual = dao.getLatest("message_1_bro", TEST_SENSOR);    assertNull(actual);}
0
public void testGetBrokenMapping() throws IOException
{    AccessConfig accessConfig = new AccessConfig();    Map<String, Object> globalConfig = new HashMap<>();    globalConfig.put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());    accessConfig.setGlobalConfigSupplier(() -> globalConfig);        accessConfig.setIndexSupplier(s -> null);    dao = new SolrDao();    dao.init(accessConfig);    Document actual = dao.getLatest("message_1_bro", TEST_SENSOR);    assertNull(actual);}
0
public void testGetLatestCollectionSensorDiffer() throws IOException
{    Document actual = dao.getLatest("message_1_test_sensor", TEST_SENSOR);    assertEquals(buildExpectedDocument(TEST_SENSOR, 1), actual);}
0
public void testGetAllLatest() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    requests.add(buildGetRequest(BRO_SENSOR, 1));    requests.add(buildGetRequest(BRO_SENSOR, 2));    Iterable<Document> actual = dao.getAllLatest(requests);    Document expected1 = buildExpectedDocument(BRO_SENSOR, 1);    assertTrue(Iterables.contains(actual, expected1));    Document expected2 = buildExpectedDocument(BRO_SENSOR, 2);    assertTrue(Iterables.contains(actual, expected2));    assertEquals(2, Iterables.size(actual));}
0
public void testGetAllLatestCollectionExplicitIndex() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    GetRequest getRequestOne = buildGetRequest(TEST_SENSOR, 1);            getRequestOne.setIndex(BRO_SENSOR);    requests.add(getRequestOne);    Iterable<Document> actual = dao.getAllLatest(requests);        assertEquals(0, Iterables.size(actual));}
0
public void testGetAllLatestCollectionSensorMixed() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    requests.add(buildGetRequest(TEST_SENSOR, 1));    requests.add(buildGetRequest(BRO_SENSOR, 2));    Iterable<Document> actual = dao.getAllLatest(requests);    assertTrue(Iterables.contains(actual, buildExpectedDocument(TEST_SENSOR, 1)));    assertTrue(Iterables.contains(actual, buildExpectedDocument(BRO_SENSOR, 2)));    assertEquals(2, Iterables.size(actual));}
0
public void testGetAllLatestCollectionOneMissing() throws IOException
{    List<GetRequest> requests = new ArrayList<>();    requests.add(buildGetRequest(TEST_SENSOR, 1));    GetRequest brokenRequest = new GetRequest();    brokenRequest.setGuid(buildGuid(BRO_SENSOR, 2));    brokenRequest.setSensorType(TEST_SENSOR);    requests.add(brokenRequest);    Iterable<Document> actual = dao.getAllLatest(requests);    assertTrue(Iterables.contains(actual, buildExpectedDocument(TEST_SENSOR, 1)));    assertEquals(1, Iterables.size(actual));}
0
protected Document buildExpectedDocument(String sensor, int i)
{    Map<String, Object> expectedMapOne = new HashMap<>();    expectedMapOne.put("source.type", sensor);    expectedMapOne.put(Constants.Fields.TIMESTAMP.getName(), expectedTimestamp);    expectedMapOne.put(Constants.GUID, buildGuid(sensor, i));    return new Document(expectedMapOne, buildGuid(sensor, i), sensor, expectedTimestamp);}
0
protected GetRequest buildGetRequest(String sensor, int i)
{    GetRequest requestOne = new GetRequest();    requestOne.setGuid(buildGuid(sensor, i));    requestOne.setSensorType(sensor);    return requestOne;}
0
protected static void addData(String collection, String sensorName, Long timestamp) throws IOException, SolrServerException
{    List<Map<String, Object>> inputData = new ArrayList<>();    for (int i = 0; i < 3; ++i) {        final String name = buildGuid(sensorName, i);        HashMap<String, Object> inputMap = new HashMap<>();        inputMap.put("source.type", sensorName);        inputMap.put(Constants.GUID, name);        inputMap.put(Constants.Fields.TIMESTAMP.getName(), timestamp);        inputData.add(inputMap);    }    solrComponent.addDocs(collection, inputData);}
0
protected static String buildGuid(String sensorName, int i)
{    return "message_" + i + "_" + sensorName;}
0
public static void setupClass() throws Exception
{    indexComponent = startIndex();    dao = createDao();        broData = SearchIntegrationTest.broData.replace("source:type", "source.type");    snortData = SearchIntegrationTest.snortData.replace("source:type", "source.type");    solrComponent.addCollection("bro", "./src/main/config/schema/bro");    solrComponent.addCollection("snort", "./src/main/config/schema/snort");    loadTestData();}
0
public static void teardown()
{    SolrClientFactory.close();    if (solrComponent != null) {        solrComponent.stop();    }}
0
public IndexDao getIndexDao()
{    return dao;}
0
protected static IndexDao createDao()
{    AccessConfig config = new AccessConfig();    config.setMaxSearchResults(100);    config.setMaxSearchGroups(100);    config.setGlobalConfigSupplier(() -> new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());        }    });    config.setIndexSupplier(sensorType -> sensorType);    IndexDao dao = new SolrDao();    dao.init(config);    return dao;}
0
protected static InMemoryComponent startIndex() throws Exception
{    solrComponent = new SolrComponent.Builder().build();    solrComponent.start();    return solrComponent;}
0
protected static void loadTestData() throws ParseException, IOException, SolrServerException
{    JSONArray broArray = (JSONArray) new JSONParser().parse(broData);    solrComponent.addDocs("bro", broArray);    JSONArray snortArray = (JSONArray) new JSONParser().parse(snortData);    solrComponent.addDocs("snort", snortArray);}
0
public void returns_column_metadata_for_specified_indices() throws Exception
{        {        Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Collections.singletonList("bro"));                Assert.assertEquals(263, fieldTypes.size());                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("guid"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("source.type"));        Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));        Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("username"));                Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("score"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("location_point"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("timestamp"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("method"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("ttl"));                Assert.assertEquals(null, fieldTypes.get("dgmlen"));                Assert.assertEquals(null, fieldTypes.get("fake.field"));    }        {        Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Collections.singletonList("snort"));        Assert.assertEquals(33, fieldTypes.size());                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("guid"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("source.type"));        Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));        Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));                Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("dgmlen"));                Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("score"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("location_point"));                Assert.assertEquals(FieldType.OTHER, fieldTypes.get("timestamp"));                Assert.assertEquals(FieldType.TEXT, fieldTypes.get("sig_generator"));                Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ttl"));                Assert.assertEquals(null, fieldTypes.get("username"));                Assert.assertEquals(null, fieldTypes.get("fake.field"));    }}
0
public void returns_column_data_for_multiple_indices() throws Exception
{    Map<String, FieldType> fieldTypes = dao.getColumnMetadata(Arrays.asList("bro", "snort"));            Assert.assertEquals(FieldType.TEXT, fieldTypes.get("guid"));    Assert.assertEquals(FieldType.TEXT, fieldTypes.get("source.type"));    Assert.assertEquals(FieldType.IP, fieldTypes.get("ip_src_addr"));    Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("ip_src_port"));    Assert.assertEquals(FieldType.BOOLEAN, fieldTypes.get("is_alert"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("username"));        Assert.assertEquals(FieldType.INTEGER, fieldTypes.get("dgmlen"));        Assert.assertEquals(FieldType.FLOAT, fieldTypes.get("score"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("location_point"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("timestamp"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("method"));        Assert.assertEquals(FieldType.TEXT, fieldTypes.get("sig_generator"));        Assert.assertEquals(FieldType.OTHER, fieldTypes.get("ttl"));        Assert.assertEquals(null, fieldTypes.get("fake.field"));}
0
public void different_type_filter_query() throws Exception
{    thrown.expect(InvalidSearchException.class);    SearchRequest request = JSONUtils.INSTANCE.load(differentTypeFilterQuery, SearchRequest.class);    SearchResponse response = dao.search(request);}
0
protected String getSourceTypeField()
{    return Constants.SENSOR_TYPE;}
0
protected String getIndexName(String sensorType)
{    return sensorType;}
0
public static void setupBeforeClass() throws Exception
{    solrComponent = new SolrComponent.Builder().build();    solrComponent.start();}
0
public void setup() throws Exception
{    solrComponent.addCollection(SENSOR_NAME, "./src/test/resources/config/test/conf");    solrComponent.addCollection("error", "./src/main/config/schema/error");    Map<String, Object> globalConfig = createGlobalConfig();    globalConfig.put(HBaseDao.HBASE_TABLE, TABLE_NAME);    globalConfig.put(HBaseDao.HBASE_CF, CF);    CuratorFramework client = ConfigurationsUtils.getClient(solrComponent.getZookeeperUrl());    client.start();    ZKConfigurationsCache cache = new ZKConfigurationsCache(client);    cache.start();    AccessConfig accessConfig = new AccessConfig();    accessConfig.setGlobalConfigSupplier(() -> globalConfig);    accessConfig.setIndexSupplier(s -> s);    accessConfig.setIndexSupplier(IndexingCacheUtil.getIndexLookupFunction(cache, "solr"));    SolrDao dao = new SolrDao();    dao.init(accessConfig);    setDao(dao);}
0
public void reset()
{    solrComponent.reset();}
0
public static void teardown()
{    SolrClientFactory.close();    solrComponent.stop();}
0
protected String getIndexName()
{    return SENSOR_NAME;}
0
private static Map<String, Object> createGlobalConfig()
{    return new HashMap<String, Object>() {        {            put(SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());        }    };}
0
protected void addTestData(String indexName, String sensorType, List<Map<String, Object>> docs) throws Exception
{    solrComponent.addDocs(indexName, docs);}
0
protected List<Map<String, Object>> getIndexedTestData(String indexName, String sensorType)
{    return solrComponent.getAllIndexedDocs(indexName);}
0
public void suppress_expanded_fields() throws Exception
{    Map<String, Object> fields = new HashMap<>();    fields.put("guid", "bro_1");    fields.put("source.type", SENSOR_NAME);    fields.put("ip_src_port", 8010);    fields.put("long_field", 10000);    fields.put("latitude", 48.5839);    fields.put("score", 10.0);    fields.put("is_alert", true);    fields.put("field.location_point", "48.5839,7.7455");    Document document = new Document(fields, "bro_1", SENSOR_NAME, 0L);    getDao().update(document, Optional.of(SENSOR_NAME));    Document indexedDocument = getDao().getLatest("bro_1", SENSOR_NAME);        assertEquals(8, indexedDocument.getDocument().size());}
0
public void testHugeErrorFields() throws Exception
{    String hugeString = StringUtils.repeat("test ", 1_000_000);    String hugeStringTwo = hugeString + "-2";    Map<String, Object> documentMap = new HashMap<>();    documentMap.put("guid", "error_guid");        documentMap.put("raw_message", hugeString);    documentMap.put("raw_message_1", hugeStringTwo);    Document errorDoc = new Document(documentMap, "error", "error", 0L);    getDao().update(errorDoc, Optional.of("error"));        Document latest = getDao().getLatest("error_guid", "error");    @SuppressWarnings("unchecked")    String actual = (String) latest.getDocument().get("raw_message");    assertEquals(actual, hugeString);    String actualTwo = (String) latest.getDocument().get("raw_message_1");    assertEquals(actualTwo, hugeStringTwo);        documentMap.put("error_hash", hugeString);    errorDoc = new Document(documentMap, "error", "error", 0L);    exception.expect(SolrException.class);    exception.expectMessage("Document contains at least one immense term in field=\"error_hash\"");    getDao().update(errorDoc, Optional.of("error"));}
0
public boolean matches(Object o)
{    ModifiableSolrParams modifiableSolrParams = (ModifiableSolrParams) o;    for (String name : expectedModifiableSolrParams.getParameterNames()) {        String expectedValue = expectedModifiableSolrParams.get(name);        String value = modifiableSolrParams.get(name);        if (expectedValue == null) {            if (value != null) {                return false;            }        } else {            if (!expectedValue.equals(value)) {                return false;            }        }    }    return true;}
0
public void describeTo(Description description)
{    description.appendValue(expectedModifiableSolrParams);}
0
public boolean matches(Object o)
{    List<SolrInputDocument> solrInputDocuments = (List<SolrInputDocument>) o;    for (int i = 0; i < solrInputDocuments.size(); i++) {        SolrInputDocument solrInputDocument = solrInputDocuments.get(i);        for (int j = 0; j < expectedSolrInputDocuments.size(); j++) {            SolrInputDocument expectedSolrInputDocument = expectedSolrInputDocuments.get(j);            if (solrInputDocument.get("guid").equals(expectedSolrInputDocument.get("guid"))) {                for (String field : solrInputDocument.getFieldNames()) {                    Object expectedValue = expectedSolrInputDocument.getField(field).getValue();                    Object value = solrInputDocument.getField(field).getValue();                    boolean matches = expectedValue != null ? expectedValue.equals(value) : value == null;                    if (!matches) {                        return false;                    }                }            }        }    }    return true;}
0
public void describeTo(Description description)
{    description.appendValue(expectedSolrInputDocuments);}
0
public boolean matches(Object o)
{    SolrInputDocument solrInputDocument = (SolrInputDocument) o;    for (String field : solrInputDocument.getFieldNames()) {        Object expectedValue = expectedSolrInputDocument.getField(field).getValue();        Object value = solrInputDocument.getField(field).getValue();        boolean matches = expectedValue != null ? expectedValue.equals(value) : value == null;        if (!matches) {            return false;        }    }    return true;}
0
public void describeTo(Description description)
{    description.appendValue(expectedSolrInputDocument);}
0
public boolean matches(Object o)
{    SolrQuery solrQuery = (SolrQuery) o;    return Objects.equals(solrQuery.getStart(), expectedSolrQuery.getStart()) && Objects.equals(solrQuery.getRows(), expectedSolrQuery.getRows()) && Objects.equals(solrQuery.getQuery(), expectedSolrQuery.getQuery()) && Objects.equals(solrQuery.getSorts(), expectedSolrQuery.getSorts()) && Objects.equals(solrQuery.getFields(), expectedSolrQuery.getFields()) && Arrays.equals(solrQuery.getFacetFields(), expectedSolrQuery.getFacetFields()) && Objects.equals(solrQuery.get("collection"), expectedSolrQuery.get("collection")) && Objects.equals(solrQuery.get("stats"), expectedSolrQuery.get("stats")) && Objects.equals(solrQuery.get("stats.field"), expectedSolrQuery.get("stats.field")) && Objects.equals(solrQuery.get("facet"), expectedSolrQuery.get("facet")) && Objects.equals(solrQuery.get("facet.pivot"), expectedSolrQuery.get("facet.pivot"));}
0
public void describeTo(Description description)
{    description.appendValue(expectedSolrQuery);}
0
public boolean matches(Object o)
{    QueryRequest queryRequest = (QueryRequest) o;    return name.equals(queryRequest.getParams().get("action"));}
0
public void describeTo(Description description)
{    description.appendText(name);}
0
public void testClient() throws Exception
{    final String collection = "metron";    String zookeeperUrl = "zookeeperUrl";    MetronSolrClient metronSolrClient = Mockito.spy(new MetronSolrClient(zookeeperUrl));    Mockito.doReturn(new NamedList<Object>() {        {            add("collections", new ArrayList<String>() {                {                    add(collection);                }            });        }    }).when(metronSolrClient).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    metronSolrClient.createCollection(collection, 1, 1);    verify(metronSolrClient, times(1)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    verify(metronSolrClient, times(0)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.CREATE.name())), (String) isNull());    metronSolrClient = Mockito.spy(new MetronSolrClient(zookeeperUrl));    Mockito.doReturn(new NamedList<Object>() {        {            add("collections", new ArrayList<String>());        }    }).when(metronSolrClient).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    Mockito.doReturn(new NamedList<>()).when(metronSolrClient).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.CREATE.name())), (String) isNull());    metronSolrClient.createCollection(collection, 1, 1);    verify(metronSolrClient, times(1)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.LIST.name())), (String) isNull());    verify(metronSolrClient, times(1)).request(argThat(new CollectionRequestMatcher(CollectionParams.CollectionAction.CREATE.name())), (String) isNull());}
0
public boolean matches(Object o)
{    QueryRequest queryRequest = (QueryRequest) o;    return name.equals(queryRequest.getParams().get("action"));}
0
public void describeTo(Description description)
{    description.appendText(name);}
0
public boolean matches(Object o)
{    List<SolrInputDocument> docs = (List<SolrInputDocument>) o;    int size = docs.size();    if (size != expectedDocs.size()) {        return false;    }    for (int i = 0; i < size; ++i) {        SolrInputDocument doc = docs.get(i);        Map<String, Object> expectedDoc = expectedDocs.get(i);        for (Map.Entry<String, Object> expectedKv : expectedDoc.entrySet()) {            if (!expectedKv.getValue().equals(doc.get(expectedKv.getKey()).getValue())) {                return false;            }        }    }    return true;}
0
public void describeTo(Description description)
{    description.appendText(expectedDocs.toString());}
0
public void testWriter() throws Exception
{    IndexingConfigurations configurations = SampleUtil.getSampleIndexingConfigs();    JSONObject message1 = new JSONObject();    message1.put(Constants.GUID, "guid-1");    message1.put(Constants.SENSOR_TYPE, "test");    message1.put("intField", 100);    message1.put("doubleField", 100.0);    JSONObject message2 = new JSONObject();    message2.put(Constants.GUID, "guid-2");    message2.put(Constants.SENSOR_TYPE, "test");    message2.put("intField", 200);    message2.put("doubleField", 200.0);    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    messages.add(new BulkMessage<>("message1", message1));    messages.add(new BulkMessage<>("message2", message2));    String collection = "metron";    MetronSolrClient solr = Mockito.mock(MetronSolrClient.class);    SolrWriter writer = new SolrWriter().withMetronSolrClient(solr);    writer.init(null, new IndexingWriterConfiguration("solr", configurations));    verify(solr, times(1)).setDefaultCollection(collection);    collection = "metron2";    Map<String, Object> globalConfig = configurations.getGlobalConfig();    globalConfig.put("solr.collection", collection);    configurations.updateGlobalConfig(globalConfig);    writer = new SolrWriter().withMetronSolrClient(solr);    writer.init(null, new IndexingWriterConfiguration("solr", configurations));    verify(solr, times(1)).setDefaultCollection(collection);    writer.write("test", new IndexingWriterConfiguration("solr", configurations), messages);    verify(solr, times(1)).add(eq("yaf"), argThat(new SolrInputDocumentMatcher(ImmutableList.of(message1, message2))));    verify(solr, times(1)).commit("yaf", (boolean) SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.defaultValue.get(), (boolean) SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.defaultValue.get(), (boolean) SolrWriter.SolrProperties.COMMIT_SOFT.defaultValue.get());}
0
public void configTest_zookeeperQuorumSpecified() throws Exception
{    String expected = "test";    Assert.assertEquals(expected, SolrWriter.SolrProperties.ZOOKEEPER_QUORUM.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.ZOOKEEPER_QUORUM.name, expected), String.class));}
0
public void configTest_zookeeperQuorumUnpecified() throws Exception
{    SolrWriter.SolrProperties.ZOOKEEPER_QUORUM.coerceOrDefaultOrExcept(new HashMap<>(), String.class);}
0
public void configTest_commitPerBatchSpecified() throws Exception
{    Object expected = false;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_PER_BATCH.name, false), Boolean.class));}
0
public void configTest_commitPerBatchUnpecified() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_PER_BATCH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_PER_BATCH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_PER_BATCH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_PER_BATCH.name, new DummyClass()), Boolean.class));}
0
public void configTest_commitSoftSpecified() throws Exception
{    Object expected = true;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_SOFT.name, expected), Boolean.class));}
0
public void configTest_commitSoftUnpecified() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_SOFT.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_SOFT.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_SOFT.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_SOFT.name, new DummyClass()), Boolean.class));}
0
public void configTest_commitWaitFlushSpecified() throws Exception
{    Object expected = false;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.name, expected), Boolean.class));}
0
public void configTest_commitWaitFlushUnspecified() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_FLUSH.name, new DummyClass()), Boolean.class));}
0
public void configTest_commitWaitSearcherSpecified() throws Exception
{    Object expected = false;    Assert.assertEquals(expected, SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.name, expected), Boolean.class));}
0
public void configTest_commitWaitSearcherUnspecified() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(new HashMap<>(), Boolean.class));    Assert.assertEquals(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.defaultValue.get(), SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.COMMIT_WAIT_SEARCHER.name, new DummyClass()), Boolean.class));}
0
public void configTest_defaultCollectionSpecified() throws Exception
{    Object expected = "mycollection";    Assert.assertEquals(expected, SolrWriter.SolrProperties.DEFAULT_COLLECTION.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.DEFAULT_COLLECTION.name, expected), String.class));}
0
public void configTest_defaultCollectionUnspecified() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.DEFAULT_COLLECTION.defaultValue.get(), SolrWriter.SolrProperties.DEFAULT_COLLECTION.coerceOrDefaultOrExcept(new HashMap<>(), String.class));}
0
public void configTest_httpConfigSpecified() throws Exception
{    Object expected = new HashMap<String, Object>() {        {            put("name", "metron");        }    };    Assert.assertEquals(expected, SolrWriter.SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.HTTP_CONFIG.name, expected), Map.class));}
0
public void configTest_httpConfigUnspecified() throws Exception
{    Assert.assertEquals(SolrWriter.SolrProperties.HTTP_CONFIG.defaultValue.get(), SolrWriter.SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(new HashMap<>(), Map.class));    Assert.assertEquals(SolrWriter.SolrProperties.HTTP_CONFIG.defaultValue.get(), SolrWriter.SolrProperties.HTTP_CONFIG.coerceOrDefaultOrExcept(ImmutableMap.of(SolrWriter.SolrProperties.HTTP_CONFIG.name, new DummyClass()), Map.class));}
0
public FieldNameConverter getFieldNameConverter()
{    return fieldNameConverter;}
0
public InMemoryComponent getSearchComponent(final Properties topologyProperties) throws Exception
{    SolrComponent solrComponent = new SolrComponent.Builder().addInitialCollection(collection, "../metron-solr-common/src/main/config/schema/yaf").withPostStartCallback(new Function<SolrComponent, Void>() {        @Nullable        @Override        public Void apply(@Nullable SolrComponent solrComponent) {            topologyProperties.setProperty("solr.zk", solrComponent.getZookeeperUrl());            try {                String testZookeeperUrl = topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY);                Configurations configurations = SampleUtil.getSampleConfigs();                Map<String, Object> globalConfig = configurations.getGlobalConfig();                globalConfig.put(SolrConstants.SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());                ConfigurationsUtils.writeGlobalConfigToZookeeper(JSONUtils.INSTANCE.toJSONPretty(globalConfig), testZookeeperUrl);            } catch (Exception e) {                e.printStackTrace();            }            return null;        }    }).build();    return solrComponent;}
0
public Void apply(@Nullable SolrComponent solrComponent)
{    topologyProperties.setProperty("solr.zk", solrComponent.getZookeeperUrl());    try {        String testZookeeperUrl = topologyProperties.getProperty(ZKServerComponent.ZOOKEEPER_PROPERTY);        Configurations configurations = SampleUtil.getSampleConfigs();        Map<String, Object> globalConfig = configurations.getGlobalConfig();        globalConfig.put(SolrConstants.SOLR_ZOOKEEPER, solrComponent.getZookeeperUrl());        ConfigurationsUtils.writeGlobalConfigToZookeeper(JSONUtils.INSTANCE.toJSONPretty(globalConfig), testZookeeperUrl);    } catch (Exception e) {        e.printStackTrace();    }    return null;}
0
public Processor<List<Map<String, Object>>> getProcessor(final List<byte[]> inputMessages)
{    return new Processor<List<Map<String, Object>>>() {        List<Map<String, Object>> docs = null;        List<byte[]> errors = null;        @Override        public ReadinessState process(ComponentRunner runner) {            SolrComponent solrComponent = runner.getComponent("search", SolrComponent.class);            KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);            if (solrComponent.hasCollection(collection)) {                docs = solrComponent.getAllIndexedDocs(collection);                if (docs.size() < inputMessages.size()) {                    errors = kafkaComponent.readMessages(ERROR_TOPIC);                    if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {                        return ReadinessState.READY;                    }                    return ReadinessState.NOT_READY;                } else {                    return ReadinessState.READY;                }            } else {                return ReadinessState.NOT_READY;            }        }        @Override        public ProcessorResult<List<Map<String, Object>>> getResult() {            ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();            return builder.withResult(docs).withProcessErrors(errors).build();        }    };}
0
public ReadinessState process(ComponentRunner runner)
{    SolrComponent solrComponent = runner.getComponent("search", SolrComponent.class);    KafkaComponent kafkaComponent = runner.getComponent("kafka", KafkaComponent.class);    if (solrComponent.hasCollection(collection)) {        docs = solrComponent.getAllIndexedDocs(collection);        if (docs.size() < inputMessages.size()) {            errors = kafkaComponent.readMessages(ERROR_TOPIC);            if (errors.size() > 0 && errors.size() + docs.size() == inputMessages.size()) {                return ReadinessState.READY;            }            return ReadinessState.NOT_READY;        } else {            return ReadinessState.READY;        }    } else {        return ReadinessState.NOT_READY;    }}
0
public ProcessorResult<List<Map<String, Object>>> getResult()
{    ProcessorResult.Builder<List<Map<String, Object>>> builder = new ProcessorResult.Builder();    return builder.withResult(docs).withProcessErrors(errors).build();}
0
public void setAdditionalProperties(Properties topologyProperties)
{    topologyProperties.setProperty("ra_indexing_writer_class_name", "org.apache.metron.solr.writer.SolrWriter");    topologyProperties.setProperty("ra_indexing_kafka_start", "UNCOMMITTED_EARLIEST");    topologyProperties.setProperty("ra_indexing_workers", "1");    topologyProperties.setProperty("ra_indexing_acker_executors", "0");    topologyProperties.setProperty("ra_indexing_topology_max_spout_pending", "");    topologyProperties.setProperty("ra_indexing_kafka_spout_parallelism", "1");    topologyProperties.setProperty("ra_indexing_writer_parallelism", "1");}
0
public String cleanField(String field)
{    return field.replaceFirst("_[dfils]$", "");}
0
public String getTemplatePath()
{    return "./src/main/config/solr.properties.j2";}
0
public String getFluxPath()
{    return "../../metron-indexing/metron-indexing-storm/src/main/flux/indexing/random_access/remote.yaml";}
0
public String getFieldName()
{    return fieldName;}
0
public static List<FieldsConfiguration> toList(String... configs)
{    List<FieldsConfiguration> ret = new ArrayList<>();    for (String config : configs) {        ret.add(FieldsConfiguration.valueOf(config.toUpperCase()));    }    return ret;}
0
public static List<FieldsConfiguration> toList(List<String> configs)
{    List<FieldsConfiguration> ret = new ArrayList<>();    for (String config : configs) {        ret.add(FieldsConfiguration.valueOf(config.toUpperCase()));    }    return ret;}
0
public static Fields getFields(Iterable<FieldsConfiguration> configs)
{    List<String> fields = new ArrayList<>();    for (FieldsConfiguration config : configs) {        fields.add(config.fieldName);    }    return new Fields(fields);}
0
public List<Object> apply(ConsumerRecord<K, V> consumerRecord)
{    Values ret = new Values();    for (FieldsConfiguration config : configurations) {        ret.add(config.recordExtractor.apply(consumerRecord));    }    return ret;}
0
public Fields getFieldsFor(String s)
{    return fields;}
0
public List<String> streams()
{    return DEFAULT_STREAM;}
0
private static Subscription toSubscription(String topicOrSubscription)
{    if (StringUtils.isEmpty(topicOrSubscription)) {        throw new IllegalArgumentException("Topic name is invalid (empty or null): " + topicOrSubscription);    }    int length = topicOrSubscription.length();    if (topicOrSubscription.charAt(0) == '/' && topicOrSubscription.charAt(length - 1) == '/') {                String substr = topicOrSubscription.substring(1, length - 1);        return new PatternSubscription(Pattern.compile(substr));    } else {        return new NamedSubscription(topicOrSubscription);    }}
0
private static Class<Deserializer<T>> createDeserializer(Optional<String> deserializerClass, String defaultDeserializerClass)
{    try {        return (Class<Deserializer<T>>) Class.forName(deserializerClass.orElse(defaultDeserializerClass));    } catch (Exception e) {        throw new IllegalStateException("Unable to create a deserializer: " + deserializerClass.orElse(defaultDeserializerClass) + ": " + e.getMessage(), e);    }}
0
private static String getBootstrapServers(String zkQuorum, Map<String, Object> kafkaProps)
{    String brokers = (String) kafkaProps.get(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG);    if (brokers == null) {        try {            return Joiner.on(",").join(KafkaUtils.INSTANCE.getBrokersFromZookeeper(zkQuorum));        } catch (Exception e) {            throw new IllegalStateException("Unable to find the bootstrap servers: " + e.getMessage(), e);        }    }    return brokers;}
0
public static StormKafkaSpout<K, V> create(String topic, String zkQuorum, List<String> fieldsConfiguration, Map<String, Object> kafkaProps)
{    Map<String, Object> spoutConfig = SpoutConfiguration.separate(kafkaProps);    SimpleStormKafkaBuilder<K, V> builder = new SimpleStormKafkaBuilder<>(kafkaProps, topic, zkQuorum, fieldsConfiguration);    SpoutConfiguration.configure(builder, spoutConfig);    return new StormKafkaSpout<>(builder);}
0
public static Map<String, Object> separate(Map<String, Object> config)
{    Map<String, Object> ret = new HashMap<>();    for (SpoutConfiguration spoutConfig : SpoutConfiguration.values()) {        if (config.containsKey(spoutConfig.key)) {            Object val = config.get(spoutConfig.key);            config.remove(spoutConfig.key);            ret.put(spoutConfig.key, val);        }    }    return ret;}
0
public static KafkaSpoutConfig.Builder configure(KafkaSpoutConfig.Builder<K, V> builder, Map<String, Object> config)
{    for (SpoutConfiguration spoutConfig : SpoutConfiguration.values()) {        if (config.containsKey(spoutConfig.key)) {            Container container = new Container(config, builder, config.get(spoutConfig.key));            spoutConfig.consumer.accept(container);        }    }    return builder;}
0
public static List<String> allOptions()
{    List<String> ret = new ArrayList<>();    for (SpoutConfiguration spoutConfig : SpoutConfiguration.values()) {        ret.add(spoutConfig.key);    }    ret.add(ConsumerConfig.GROUP_ID_CONFIG);    ret.add(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG);    ret.add(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG);    return ret;}
0
public void deactivate()
{    try {        super.deactivate();    } catch (WakeupException we) {                    } finally {        isShutdown.set(true);    }}
1
public void close()
{    try {        if (!isShutdown.get()) {            super.close();            isShutdown.set(true);        }    } catch (WakeupException we) {                    } catch (IllegalStateException ise) {        if (ise.getMessage().contains("This consumer has already been closed")) {                    } else {            throw ise;        }    }}
1
public static int getPartition(Object messageIdObj)
{    KafkaSpoutMessageId messageId = (KafkaSpoutMessageId) messageIdObj;    return messageId.getTopicPartition().partition();}
0
public List<Integer> emit(String streamId, List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.PARTITION, getPartition(messageId)).with(EmitContext.Type.STREAM_ID, streamId));    return _delegate.emit(streamId, t, messageId);}
0
public List<Integer> emit(List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.PARTITION, getPartition(messageId)));    return _delegate.emit(t, messageId);}
0
public List<Integer> emit(List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext());    return _delegate.emit(t);}
0
public List<Integer> emit(String streamId, List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.STREAM_ID, streamId));    return _delegate.emit(streamId, t);}
0
public void emitDirect(int taskId, String streamId, List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.STREAM_ID, streamId).with(EmitContext.Type.PARTITION, getPartition(messageId)).with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, streamId, t, messageId);}
0
public void emitDirect(int taskId, List<Object> tuple, Object messageId)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.PARTITION, getPartition(messageId)).with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, t, messageId);}
0
public void emitDirect(int taskId, String streamId, List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.STREAM_ID, streamId).with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, streamId, t);}
0
public void emitDirect(int taskId, List<Object> tuple)
{    List<Object> t = _callback.apply(tuple, _context.cloneContext().with(EmitContext.Type.TASK_ID, taskId));    _delegate.emitDirect(taskId, t);}
0
public void initialize(TopologyContext context)
{    _callback = createCallback(callbackClazz);    _context = new EmitContext().with(EmitContext.Type.SPOUT_CONFIG, _spoutConfig).with(EmitContext.Type.UUID, context.getStormId());    _callback.initialize(_context);}
0
private static Class<? extends Callback> toCallbackClass(String callbackClass)
{    try {        return (Class<? extends Callback>) Callback.class.forName(callbackClass);    } catch (ClassNotFoundException e) {        throw new RuntimeException(callbackClass + " not found", e);    }}
0
protected Callback createCallback(Class<? extends Callback> callbackClass)
{    try {        return callbackClass.getConstructor().newInstance();    } catch (InstantiationException | NoSuchMethodException | InvocationTargetException e) {        throw new RuntimeException("Unable to instantiate callback", e);    } catch (IllegalAccessException e) {        throw new RuntimeException("Illegal access", e);    }}
0
public void open(Map conf, final TopologyContext context, final SpoutOutputCollector collector)
{    if (_callback == null) {        initialize(context);    }    super.open(conf, context, new CallbackCollector(_callback, collector, _context.cloneContext().with(EmitContext.Type.OPEN_CONFIG, conf).with(EmitContext.Type.TOPOLOGY_CONTEXT, context)));}
0
public void close()
{    super.close();    if (_callback != null) {        try {            _callback.close();        } catch (Exception e) {            throw new IllegalStateException("Unable to close callback", e);        }    }}
0
public Class<?> clazz()
{    return clazz;}
0
public EmitContext with(Type t, T o)
{    _context.put(t, t.clazz().cast(o));    return this;}
0
public void add(Type t, T o)
{    with(t, o);}
0
public T get(Type t)
{    Object o = _context.get(t);    if (o == null) {        return null;    } else {        return (T) o;    }}
0
public EmitContext cloneContext()
{    try {        return (EmitContext) this.clone();    } catch (CloneNotSupportedException e) {        throw new RuntimeException("Unable to clone emit context.", e);    }}
0
protected Object clone() throws CloneNotSupportedException
{    EmitContext context = new EmitContext(_context.clone());    return context;}
0
public void testSeparation()
{    Map<String, Object> config = new HashMap<String, Object>() {        {            put(SpoutConfiguration.FIRST_POLL_OFFSET_STRATEGY.key, "UNCOMMITTED_EARLIEST");            put(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key, "1000");            put("group.id", "foobar");        }    };    Map<String, Object> spoutConfig = SpoutConfiguration.separate(config);    Assert.assertTrue(spoutConfig.containsKey(SpoutConfiguration.FIRST_POLL_OFFSET_STRATEGY.key));    Assert.assertEquals(spoutConfig.get(SpoutConfiguration.FIRST_POLL_OFFSET_STRATEGY.key), "UNCOMMITTED_EARLIEST");    Assert.assertTrue(spoutConfig.containsKey(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key));    Assert.assertEquals(spoutConfig.get(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key), "1000");    Assert.assertEquals(2, spoutConfig.size());    Assert.assertEquals(1, config.size());    Assert.assertEquals(config.get("group.id"), "foobar");}
0
public void testBuilderCreation()
{    Map<String, Object> config = new HashMap<String, Object>() {        {            put(SpoutConfiguration.OFFSET_COMMIT_PERIOD_MS.key, "1000");            put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "foo:1234");            put("group.id", "foobar");        }    };    Map<String, Object> spoutConfig = SpoutConfiguration.separate(config);    KafkaSpoutConfig.Builder<Object, Object> builder = new SimpleStormKafkaBuilder(config, "topic", null);    SpoutConfiguration.configure(builder, spoutConfig);    KafkaSpoutConfig c = builder.build();    Assert.assertEquals(1000, c.getOffsetsCommitPeriodMs());}
0
public long period()
{    return this.period;}
0
public long delay()
{    return this.delay;}
0
public TimeUnit getTimeUnit()
{    return this.timeUnit;}
0
public boolean isExpiredResetOnTrue()
{    boolean expired = System.nanoTime() - this.start >= this.periodNanos;    if (expired) {        this.start = System.nanoTime();    }    return expired;}
0
public int compare(RetrySchedule entry1, RetrySchedule entry2)
{    int result = Long.valueOf(entry1.nextRetryTimeNanos()).compareTo(entry2.nextRetryTimeNanos());    if (result == 0) {                        result = entry1.hashCode() - entry2.hashCode();    }    return result;}
0
public void setNextRetryTimeNanos()
{    nextRetryTimeNanos = nextTime(msgId);    }
1
public boolean retry(long currentTimeNanos)
{    return nextRetryTimeNanos <= currentTimeNanos;}
0
public String toString()
{    return "RetrySchedule{" + "msgId=" + msgId + ", nextRetryTimeNanos=" + nextRetryTimeNanos + '}';}
0
public KafkaSpoutMessageId msgId()
{    return msgId;}
0
public long nextRetryTimeNanos()
{    return nextRetryTimeNanos;}
0
public static TimeInterval seconds(long length)
{    return new TimeInterval(length, TimeUnit.SECONDS);}
0
public static TimeInterval milliSeconds(long length)
{    return new TimeInterval(length, TimeUnit.MILLISECONDS);}
0
public static TimeInterval microSeconds(long length)
{    return new TimeInterval(length, TimeUnit.MICROSECONDS);}
0
public long lengthNanos()
{    return lengthNanos;}
0
public TimeUnit timeUnit()
{    return timeUnit;}
0
public String toString()
{    return "TimeInterval{" + "length=" + length + ", timeUnit=" + timeUnit + '}';}
0
public Map<TopicPartition, Long> earliestRetriableOffsets()
{    final Map<TopicPartition, Long> tpToEarliestRetriableOffset = new HashMap<>();    final long currentTimeNanos = System.nanoTime();    for (RetrySchedule retrySchedule : retrySchedules) {        if (retrySchedule.retry(currentTimeNanos)) {            final KafkaSpoutMessageId msgId = retrySchedule.msgId;            final TopicPartition tpForMessage = new TopicPartition(msgId.topic(), msgId.partition());            final Long currentLowestOffset = tpToEarliestRetriableOffset.get(tpForMessage);            if (currentLowestOffset != null) {                tpToEarliestRetriableOffset.put(tpForMessage, Math.min(currentLowestOffset, msgId.offset()));            } else {                tpToEarliestRetriableOffset.put(tpForMessage, msgId.offset());            }        } else {                        break;        }    }        return tpToEarliestRetriableOffset;}
1
public boolean isReady(KafkaSpoutMessageId msgId)
{    boolean retry = false;    if (isScheduled(msgId)) {        final long currentTimeNanos = System.nanoTime();        for (RetrySchedule retrySchedule : retrySchedules) {            if (retrySchedule.retry(currentTimeNanos)) {                if (retrySchedule.msgId.equals(msgId)) {                    retry = true;                                                            break;                }            } else {                                                break;            }        }    }    return retry;}
1
public boolean isScheduled(KafkaSpoutMessageId msgId)
{    return toRetryMsgs.contains(msgId);}
0
public boolean remove(KafkaSpoutMessageId msgId)
{    boolean removed = false;    if (isScheduled(msgId)) {        toRetryMsgs.remove(msgId);        for (Iterator<RetrySchedule> iterator = retrySchedules.iterator(); iterator.hasNext(); ) {            final RetrySchedule retrySchedule = iterator.next();            if (retrySchedule.msgId().equals(msgId)) {                iterator.remove();                removed = true;                                break;            }        }    }        LOG.trace("Current state {}", retrySchedules);    return removed;}
1
public boolean retainAll(Collection<TopicPartition> topicPartitions)
{    boolean result = false;    for (Iterator<RetrySchedule> rsIterator = retrySchedules.iterator(); rsIterator.hasNext(); ) {        final RetrySchedule retrySchedule = rsIterator.next();        final KafkaSpoutMessageId msgId = retrySchedule.msgId;        final TopicPartition tpRetry = new TopicPartition(msgId.topic(), msgId.partition());        if (!topicPartitions.contains(tpRetry)) {            rsIterator.remove();            toRetryMsgs.remove(msgId);                        LOG.trace("Current state {}", retrySchedules);            result = true;        }    }    return result;}
1
public boolean schedule(KafkaSpoutMessageId msgId)
{    if (msgId.numFails() > maxRetries) {                return false;    } else {                remove(msgId);        final RetrySchedule retrySchedule = new RetrySchedule(msgId, nextTime(msgId));        retrySchedules.add(retrySchedule);        toRetryMsgs.add(msgId);                LOG.trace("Current state {}", retrySchedules);        return true;    }}
1
public int readyMessageCount()
{    int count = 0;    final long currentTimeNanos = System.nanoTime();    for (RetrySchedule retrySchedule : retrySchedules) {        if (retrySchedule.retry(currentTimeNanos)) {            ++count;        } else {                        break;        }    }    return count;}
0
public KafkaSpoutMessageId getMessageId(ConsumerRecord<?, ?> record)
{    KafkaSpoutMessageId msgId = new KafkaSpoutMessageId(record);    if (isScheduled(msgId)) {        for (KafkaSpoutMessageId originalMsgId : toRetryMsgs) {            if (originalMsgId.equals(msgId)) {                return originalMsgId;            }        }    }    return msgId;}
0
private long nextTime(KafkaSpoutMessageId msgId)
{    Validate.isTrue(msgId.numFails() > 0, "nextTime assumes the message has failed at least once");    final long currentTimeNanos = System.nanoTime();    final long nextTimeNanos =     msgId.numFails() == 1 ? currentTimeNanos + initialDelay.lengthNanos : currentTimeNanos + delayPeriod.lengthNanos * (long) (Math.pow(2, msgId.numFails() - 1));    return Math.min(nextTimeNanos, currentTimeNanos + maxDelay.lengthNanos);}
0
public String toString()
{    return toStringImpl();}
0
private String toStringImpl()
{        return "KafkaSpoutRetryExponentialBackoff{" + "delay=" + initialDelay + ", ratio=" + delayPeriod + ", maxRetries=" + maxRetries + ", maxRetryDelay=" + maxDelay + '}';}
0
public void testReset() throws InterruptedException
{    Timer t = new Timer(0, 2, TimeUnit.SECONDS);    Thread.sleep(1000);    Assert.assertFalse(t.isExpiredResetOnTrue());    Thread.sleep(1000);    Assert.assertTrue(t.isExpiredResetOnTrue());}
0
public void initMocks()
{    MockitoAnnotations.initMocks(this);}
0
public boolean matches(Object o)
{    Fields fields = (Fields) o;    return expectedFields.equals(fields.toList());}
0
public void describeTo(Description description)
{    description.appendText(String.format("[%s]", Joiner.on(",").join(expectedFields)));}
0
public void removeTimingFields(JSONObject message)
{    ImmutableSet keys = ImmutableSet.copyOf(message.keySet());    for (Object key : keys) {        if (key.toString().endsWith(".ts")) {            message.remove(key);        }    }}
0
public void parseBaseMessages() throws ParseException
{    JSONParser parser = new JSONParser();    sampleMessage = (JSONObject) parser.parse(sampleMessageString);    geoMessage = (JSONObject) parser.parse(geoMessageString);    hostMessage = (JSONObject) parser.parse(hostMessageString);    hbaseEnrichmentMessage = (JSONObject) parser.parse(hbaseEnrichmentMessageString);    streamIds.add("geo");    streamIds.add("stellar");    streamIds.add("host");    streamIds.add("hbaseEnrichment");    joinStreamIds.add("geo:");    joinStreamIds.add("stellar:");    joinStreamIds.add("stellar:numeric");    joinStreamIds.add("stellar:dst_enrichment");    joinStreamIds.add("stellar:src_enrichment");    joinStreamIds.add("stellar:error_test");    joinStreamIds.add("host:");    joinStreamIds.add("hbaseEnrichment:");    joinStreamIds.add("message:");}
0
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)
{}
0
public void execute(Tuple input)
{    System.out.println("---------[RECEIVED] " + input);}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{}
0
public byte[] convert(String s)
{    return _underlying.convert(s);}
0
public byte[] convert(String s)
{    int len = s.length();    byte[] data = new byte[len / 2];    for (int i = 0; i < len; i += 2) {        data[i / 2] = (byte) ((Character.digit(s.charAt(i), 16) << 4) + Character.digit(s.charAt(i + 1), 16));    }    return data;}
0
public boolean matches(Object o)
{    Values values = (Values) o;    JSONObject actual = (JSONObject) values.get(0);    actual.remove("timestamp");    expected.remove("timestamp");    actual.remove("stack");    expected.remove("stack");    actual.remove("guid");    expected.remove("guid");    return actual.equals(expected);}
0
public List<String> readFromFile(String filename) throws IOException
{    System.out.println("Reading stream from " + filename);    List<String> lines = new LinkedList<String>();    InputStream stream = null;    if (new File(filename).exists()) {        stream = new FileInputStream(filename);    } else {        stream = Thread.currentThread().getContextClassLoader().getResourceAsStream(filename);    }    DataInputStream in = new DataInputStream(stream);    BufferedReader br = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8));    String strLine;    while ((strLine = br.readLine()) != null) {                lines.add(strLine);    }    return lines;}
0
public GenericInternalTestSpout withFilename(String filename)
{    if (filename != null && filename.length() > 0 && filename.charAt(0) == '$') {        filename = Iterables.getLast(Splitter.on("}").split(filename));    }    _filename = filename;    return this;}
0
public GenericInternalTestSpout withMillisecondDelay(Integer delay)
{    _delay = delay;    return this;}
0
public GenericInternalTestSpout withRepeating(Boolean repeating)
{    _repeating = repeating;    return this;}
0
public GenericInternalTestSpout withBinaryConverter(String converter)
{    if (converter == null) {        _converter = BinaryConverters.DEFAULT;    } else {        _converter = BinaryConverters.valueOf(converter);    }    return this;}
0
public void open(Map conf, TopologyContext context, SpoutOutputCollector collector)
{    _collector = collector;    try {        Reader = new FileReader();        jsons = Reader.readFromFile(_filename);    } catch (Throwable e) {        System.out.println("Could not read sample JSONs");        e.printStackTrace();    }}
0
public void nextTuple()
{    Utils.sleep(_delay);    if (cnt < jsons.size()) {        byte[] value;        if (_converter != null) {            value = _converter.convert(jsons.get(cnt));        } else {            value = jsons.get(cnt).getBytes(StandardCharsets.UTF_8);        }        _collector.emit(new Values(value));    }    cnt++;    if (_repeating && cnt == jsons.size() - 1)        cnt = 0;}
0
public void ack(Object id)
{}
0
public void fail(Object id)
{}
0
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    declarer.declare(new Fields("message"));}
0
public String getDirectoryName()
{    return directoryName;}
0
public KafkaLoader withDelay(int delay)
{    this.delay = delay;    return this;}
0
public KafkaLoader withIterations(int iterations)
{    this.iterations = iterations;    return this;}
0
public void start()
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", brokerUrl);    producerConfig.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");    producerConfig.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");    kafkaProducer = new KafkaProducer<>(producerConfig);    try {        while (iterations == -1 || iterations-- > 0) {            BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(samplePath), StandardCharsets.UTF_8));            String line;            while ((line = reader.readLine()) != null) {                kafkaProducer.send(new ProducerRecord<String, String>(topic, line));                Thread.sleep(delay);            }            reader.close();        }    } catch (Exception e) {        e.printStackTrace();    }}
0
public void stop()
{    kafkaProducer.close();}
0
public static void main(String[] args)
{    KafkaLoader kafkaLoader = new KafkaLoader(args[0], args[1], args[2]);    if (args.length > 3)        kafkaLoader.withDelay(Integer.parseInt(args[3]));    if (args.length > 4)        kafkaLoader.withIterations(Integer.parseInt(args[4]));    kafkaLoader.start();    kafkaLoader.stop();}
0
public static String getSampleDataPath(String pathPrefix, String sensorType, TestDataType testDataType) throws FileNotFoundException
{    File sensorSampleDataPath = new File(pathPrefix + "/" + TestConstants.SAMPLE_DATA_PATH, sensorType);    if (sensorSampleDataPath.exists() && sensorSampleDataPath.isDirectory()) {        File sampleDataPath = new File(sensorSampleDataPath, testDataType.getDirectoryName());        if (sampleDataPath.exists() && sampleDataPath.isDirectory()) {            File[] children = sampleDataPath.listFiles();            if (children != null && children.length > 0) {                return children[0].getAbsolutePath();            }        }    }    throw new FileNotFoundException("Could not find data in " + TestConstants.SAMPLE_DATA_PATH + sensorType + "/" + testDataType.getDirectoryName());}
0
public static String getSampleDataPath(String sensorType, TestDataType testDataType) throws FileNotFoundException
{    return getSampleDataPath("", sensorType, testDataType);}
0
public static String findDir(String name)
{    return findDir(new File("."), name);}
0
public static String findDir(File startDir, String name)
{    Stack<File> s = new Stack<File>();    s.push(startDir);    while (!s.empty()) {        File parent = s.pop();        if (parent.getName().equalsIgnoreCase(name)) {            return parent.getAbsolutePath();        } else {            File[] children = parent.listFiles();            if (children != null) {                for (File child : children) {                    s.push(child);                }            }        }    }    return null;}
0
public static void assertSetEqual(String type, Set<T> expectedPcapIds, Set<T> found)
{    boolean mismatch = false;    for (T f : found) {        if (!expectedPcapIds.contains(f)) {            mismatch = true;            System.out.println("Found " + type + " that I did not expect: " + f);        }    }    for (T expectedId : expectedPcapIds) {        if (!found.contains(expectedId)) {            mismatch = true;            System.out.println("Expected " + type + " that I did not index: " + expectedId);        }    }    Assert.assertFalse(mismatch);}
0
public static void verboseLogging()
{    verboseLogging("%d [%p|%c|%C{1}] %m%n", Level.ALL);}
0
public static void verboseLogging(String pattern, Level level)
{        ConsoleAppender console = new ConsoleAppender();        console.setLayout(new PatternLayout(pattern));    console.setThreshold(level);    console.activateOptions();        Logger.getRootLogger().addAppender(console);}
0
public static void setLog4jLevel(Class clazz, Level level)
{    Logger logger = Logger.getLogger(clazz);    logger.setLevel(level);}
0
public static void setLog4jLevel(Level level)
{    Logger logger = Logger.getRootLogger();    logger.setLevel(level);}
0
public static Level getLog4jLevel()
{    Logger rootLogger = Logger.getRootLogger();    return rootLogger.getLevel();}
0
public static Level getLog4jLevel(Class clazz)
{    Logger logger = Logger.getLogger(clazz);    return logger.getLevel();}
0
public static void setJavaLoggingLevel(Class clazz, java.util.logging.Level level)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger(clazz.getName());    logger.setLevel(level);}
0
public static java.util.logging.Level getJavaLoggingLevel(Class clazz)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger(clazz.getName());    return logger.getLevel();}
0
public static void setJavaLoggingLevel(java.util.logging.Level level)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger("");    logger.setLevel(level);}
0
public static java.util.logging.Level getJavaLoggingLevel()
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger("");    return logger.getLevel();}
0
public static File createTempDir(File dir) throws IOException
{    return createTempDir(dir, true);}
0
public static File createTempDir(File dir, boolean cleanup) throws IOException
{    if (!dir.mkdirs() && !dir.exists()) {        throw new IOException(String.format("Failed to create directory structure '%s'", dir.toString()));    }    if (cleanup) {        addCleanupHook(dir.toPath());    }    return dir;}
0
public static File createTempDir(String prefix) throws IOException
{    return createTempDir(prefix, true);}
0
public static File createTempDir(String prefix, boolean cleanup) throws IOException
{    Path tmpDir = Files.createTempDirectory(prefix);    addCleanupHook(tmpDir);    return tmpDir.toFile();}
0
public static void addCleanupHook(final Path dir)
{    Runtime.getRuntime().addShutdownHook(new Thread() {        @Override        public void run() {            try {                cleanDir(dir);            } catch (IOException e) {                System.out.println(format("Warning: Unable to clean folder '%s'", dir.toString()));            }        }    });}
0
public void run()
{    try {        cleanDir(dir);    } catch (IOException e) {        System.out.println(format("Warning: Unable to clean folder '%s'", dir.toString()));    }}
0
public static void cleanDir(Path dir) throws IOException
{    Files.walkFileTree(dir, new SimpleFileVisitor<Path>() {        @Override        public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {            if (exc == null) {                return FileVisitResult.CONTINUE;            } else {                throw exc;            }        }    });    Files.delete(dir);}
0
public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
0
public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
0
public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException
{    if (exc == null) {        return FileVisitResult.CONTINUE;    } else {        throw exc;    }}
0
public static File write(File file, String contents) throws IOException
{    com.google.common.io.Files.createParentDirs(file);    com.google.common.io.Files.write(contents, file, StandardCharsets.UTF_8);    return file;}
0
public static void assertJsonEqual(String expected, String actual) throws IOException
{    ObjectMapper mapper = new ObjectMapper();    Map m1 = mapper.readValue(expected, Map.class);    Map m2 = mapper.readValue(actual, Map.class);    for (Object k : m1.keySet()) {        Object v1 = m1.get(k);        Object v2 = m2.get(k);        if (v2 == null) {            Assert.fail("Unable to find key: " + k + " in output");        }        if (k.equals("timestamp") || k.equals("guid")) {                        Assert.assertEquals(v1.toString().length(), v2.toString().length());        } else if (!v2.equals(v1)) {            boolean goodDeepDown = false;                        if (((String) k).equals("original_string")) {                try {                    mapper.readValue((String) v1, Map.class);                    assertJsonEqual((String) v1, (String) v2);                    goodDeepDown = true;                } catch (Exception e) {                                }            }            if (!goodDeepDown) {                Assert.assertEquals("value mismatch for " + k, v1, v2);            }        }    }    Assert.assertEquals(m1.size(), m2.size());}
0
public boolean shouldFlush(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    boolean shouldFlush = false;    int batchSize = messages.size();    int configuredBatchSize = configurations.getBatchSize(sensorType);        if (batchSize >= configuredBatchSize) {                shouldFlush = true;    }    return shouldFlush;}
1
public void onFlush(String sensorType, BulkWriterResponse response)
{}
0
public boolean shouldFlush(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    boolean shouldFlush = false;    long currentTimeMillis = clock.currentTimeMillis();    if (!timeouts.containsKey(sensorType)) {                                long batchTimeoutMs = getBatchTimeout(sensorType, configurations);                timeouts.put(sensorType, currentTimeMillis + batchTimeoutMs);    }    if (timeouts.get(sensorType) <= currentTimeMillis) {                shouldFlush = true;    }    return shouldFlush;}
1
public void onFlush(String sensorType, BulkWriterResponse response)
{    timeouts.remove(sensorType);}
0
protected long getBatchTimeout(String sensorType, WriterConfiguration configurations)
{    int batchTimeoutSecs = configurations.getBatchTimeout(sensorType);    if (batchTimeoutSecs <= 0 || batchTimeoutSecs > maxBatchTimeout) {                batchTimeoutSecs = maxBatchTimeout;    }    return TimeUnit.SECONDS.toMillis(batchTimeoutSecs);}
1
public void write(String sensorType, BulkMessage<MESSAGE_T> bulkWriterMessage, BulkMessageWriter<MESSAGE_T> bulkMessageWriter, WriterConfiguration configurations)
{    List<BulkMessage<MESSAGE_T>> messages = sensorMessageCache.getOrDefault(sensorType, new ArrayList<>());    sensorMessageCache.put(sensorType, messages);        if (!configurations.isEnabled(sensorType)) {                flush(sensorType, bulkMessageWriter, configurations, messages);                BulkWriterResponse response = new BulkWriterResponse();        response.addSuccess(bulkWriterMessage.getId());        onFlush(sensorType, response);    } else {        messages.add(bulkWriterMessage);        applyShouldFlush(sensorType, bulkMessageWriter, configurations, sensorMessageCache.get(sensorType));    }}
0
public void flushAll(BulkMessageWriter<MESSAGE_T> bulkMessageWriter, WriterConfiguration configurations)
{        for (String sensorType : new HashSet<>(sensorMessageCache.keySet())) {        applyShouldFlush(sensorType, bulkMessageWriter, configurations, sensorMessageCache.get(sensorType));    }}
0
public void addFlushPolicy(FlushPolicy flushPolicy)
{    this.flushPolicies.add(flushPolicy);}
0
private void applyShouldFlush(String sensorType, BulkMessageWriter<MESSAGE_T> bulkMessageWriter, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    if (messages.size() > 0) {                for (FlushPolicy<MESSAGE_T> flushPolicy : flushPolicies) {            if (flushPolicy.shouldFlush(sensorType, configurations, messages)) {                flush(sensorType, bulkMessageWriter, configurations, messages);                break;            }        }    }}
0
private void onFlush(String sensorType, BulkWriterResponse response)
{    sensorMessageCache.remove(sensorType);    for (FlushPolicy flushPolicy : flushPolicies) {        flushPolicy.onFlush(sensorType, response);    }}
0
public String getKey()
{    return key;}
0
public Object get(Map<String, Object> config)
{    Object o = config.get(key);    if (o == null) {            }    return o;}
1
public T getAndConvert(Map<String, Object> config, Class<T> clazz)
{    Object o = get(config);    if (o != null) {        return ConversionUtils.convert(o, clazz);    }        return null;}
1
public String transform(final JSONObject message)
{    String transformedMessage = keys.stream().map(x -> {        Object o = message.get(x);        return o == null ? "" : o.toString();    }).collect(Collectors.joining(delim));        return transformedMessage;}
1
public void configure(String sensorName, WriterConfiguration configuration)
{    validateEnrichmentType(sensorName, configuration);    validateKeyColumns(sensorName, configuration);    String hbaseProviderImpl = Configurations.HBASE_PROVIDER.getAndConvert(configuration.getSensorConfig(sensorName), String.class);    if (hbaseProviderImpl != null) {        provider = ReflectionUtils.createInstance(hbaseProviderImpl);    }    if (converter == null) {        converter = new EnrichmentConverter();    }    }
1
private void validateEnrichmentType(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> sensorConfig = configuration.getSensorConfig(sensorName);    Object enrichmentTypeObj = Configurations.ENRICHMENT_TYPE.get(sensorConfig);    if (enrichmentTypeObj == null) {        throw new IllegalArgumentException(String.format("%s must be provided", Configurations.ENRICHMENT_TYPE.getKey()));    }    if (!(enrichmentTypeObj instanceof String)) {        throw new IllegalArgumentException(String.format("%s must be a string", Configurations.ENRICHMENT_TYPE.getKey()));    }    String enrichmentType = enrichmentTypeObj.toString();    if (enrichmentType.trim().isEmpty()) {        throw new IllegalArgumentException(String.format("%s must not be an empty string", Configurations.ENRICHMENT_TYPE.getKey()));    }}
0
private void validateKeyColumns(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> sensorConfig = configuration.getSensorConfig(sensorName);    Object keyColumnsObj = Configurations.KEY_COLUMNS.get(sensorConfig);    try {        List<String> keyColumns = getColumns(keyColumnsObj, true);        if (keyColumns == null || keyColumns.isEmpty()) {            throw new IllegalArgumentException(String.format("%s must be provided", Configurations.KEY_COLUMNS.getKey()));        }    } catch (RuntimeException ex) {        throw new IllegalArgumentException(ex.getMessage(), ex);    }}
0
private String getClassName(Object object)
{    return object == null ? "" : object.getClass().getName();}
0
public void init(Map stormConf, WriterConfiguration configuration) throws Exception
{    if (converter == null) {        converter = new EnrichmentConverter();    }}
0
protected synchronized TableProvider getProvider()
{    if (provider == null) {        provider = new HTableProvider();    }    return provider;}
0
public Table getTable(String tableName, String cf) throws IOException
{    synchronized (this) {        boolean isInitial = this.tableName == null || this.cf == null;        boolean isValid = tableName != null && cf != null;        if (isInitial || (isValid && (!this.tableName.equals(tableName) || !this.cf.equals(cf)))) {            Configuration conf = HBaseConfiguration.create();                        if (table != null) {                table.close();            }                        table = getProvider().getTable(conf, tableName);            this.tableName = tableName;            this.cf = cf;        }        return table;    }}
1
public Table getTable(Map<String, Object> config) throws IOException
{    return getTable(Configurations.HBASE_TABLE.getAndConvert(config, String.class), Configurations.HBASE_CF.getAndConvert(config, String.class));}
0
private List<String> getColumns(Object keyColumnsObj, boolean allowNull)
{    Object o = keyColumnsObj;    if (allowNull && keyColumnsObj == null) {                return Collections.emptyList();    }    if (o instanceof String) {                return ImmutableList.of(o.toString());    } else if (o instanceof List) {        List<String> keyCols = new ArrayList<>();        for (Object key : (List) o) {            if (key == null) {                throw new IllegalArgumentException("Column name must not be null");            }            String columnName = key.toString();            if (columnName.trim().isEmpty()) {                throw new IllegalArgumentException("Column name must not be empty");            }            keyCols.add(columnName);        }                return keyCols;    } else {        throw new RuntimeException("Unable to get columns: " + o);    }}
1
private KeyTransformer getTransformer(Map<String, Object> config)
{    Object o = Configurations.KEY_COLUMNS.get(config);    KeyTransformer transformer = null;    if (keyTransformer != null && keyTransformer.getKey() == o) {        transformer = keyTransformer.getValue();                return transformer;    } else {        List<String> keys = getColumns(o, false);        Object delimObj = Configurations.KEY_DELIM.get(config);        String delim = (delimObj == null || !(delimObj instanceof String)) ? null : delimObj.toString();        KeyTransformer newtransformer = new KeyTransformer(keys, delim);        keyTransformer = new AbstractMap.SimpleEntry<>(o, newtransformer);                return newtransformer;    }}
1
private EnrichmentValue getValue(JSONObject message, Set<String> keyColumns, Set<String> valueColumns)
{    Map<String, Object> metadata = new HashMap<>();    if (valueColumns == null || valueColumns.isEmpty()) {        for (Object kv : message.entrySet()) {            Map.Entry<Object, Object> entry = (Map.Entry<Object, Object>) kv;            if (!keyColumns.contains(entry.getKey())) {                addMetadataEntry(metadata, entry);            }        }        return new EnrichmentValue(metadata);    } else {        for (Object kv : message.entrySet()) {            Map.Entry<Object, Object> entry = (Map.Entry<Object, Object>) kv;            if (valueColumns.contains(entry.getKey())) {                addMetadataEntry(metadata, entry);            }        }        return new EnrichmentValue(metadata);    }}
0
private void addMetadataEntry(Map<String, Object> metadata, Map.Entry<Object, Object> entry)
{    String key = entry.getKey().toString();    Object value = entry.getValue();        metadata.put(key, value);}
1
private EnrichmentKey getKey(JSONObject message, KeyTransformer transformer, String enrichmentType)
{    if (enrichmentType != null) {        return new EnrichmentKey(enrichmentType, transformer.transform(message));    } else {        return null;    }}
0
public BulkWriterResponse write(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    Map<String, Object> sensorConfig = configurations.getSensorConfig(sensorType);    Table table = getTable(sensorConfig);    KeyTransformer transformer = getTransformer(sensorConfig);    Object enrichmentTypeObj = Configurations.ENRICHMENT_TYPE.get(sensorConfig);    String enrichmentType = enrichmentTypeObj == null ? null : enrichmentTypeObj.toString();    Set<String> valueColumns = new HashSet<>(getColumns(Configurations.VALUE_COLUMNS.get(sensorConfig), true));    List<Put> puts = new ArrayList<>();    for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        EnrichmentKey key = getKey(bulkWriterMessage.getMessage(), transformer, enrichmentType);        EnrichmentValue value = getValue(bulkWriterMessage.getMessage(), transformer.keySet, valueColumns);        if (key == null || value == null) {            continue;        }        Put put = converter.toPut(this.cf, key, value);        if (put != null) {                        puts.add(put);        }    }    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    BulkWriterResponse response = new BulkWriterResponse();    try {        table.put(puts);    } catch (Exception e) {        response.addAllErrors(e, ids);        return response;    }        response.addAllSuccesses(ids);    return response;}
1
public String getName()
{    return "hbaseEnrichment";}
0
public void close() throws Exception
{    synchronized (this) {        if (table != null) {            table.close();        }    }}
0
public Object get(Optional<String> configPrefix, Map<String, Object> config)
{    return config.get(StringUtils.join(".", configPrefix, Optional.of(key)));}
0
public T getAndConvert(Optional<String> configPrefix, Map<String, Object> config, Class<T> clazz)
{    Object o = get(configPrefix, config);    if (o != null) {        return ConversionUtils.convert(o, clazz);    }    return null;}
0
public KafkaWriter withBrokerUrl(String brokerUrl)
{    this.brokerUrl = brokerUrl;    return this;}
0
public KafkaWriter withZkQuorum(String zkQuorum)
{    this.zkQuorum = zkQuorum;    return this;}
0
public KafkaWriter withKeySerializer(String keySerializer)
{    this.keySerializer = keySerializer;    return this;}
0
public KafkaWriter withValueSerializer(String valueSerializer)
{    this.valueSerializer = valueSerializer;    return this;}
0
public KafkaWriter withRequiredAcks(Integer requiredAcks)
{    this.requiredAcks = requiredAcks;    return this;}
0
public KafkaWriter withTopic(String topic)
{    this.kafkaTopic = topic;    return this;}
0
public KafkaWriter withTopicField(String topicField)
{    this.kafkaTopicField = topicField;    return this;}
0
public KafkaWriter withConfigPrefix(String prefix)
{    this.configPrefix = prefix;    return this;}
0
public KafkaWriter withProducerConfigs(Map<String, Object> extraConfigs)
{    if (producerConfigs == null) {        this.producerConfigs = extraConfigs;    } else if (extraConfigs != null) {        producerConfigs.putAll(extraConfigs);    }    return this;}
0
public Optional<String> getConfigPrefix()
{    return Optional.ofNullable(configPrefix);}
0
protected void setKafkaProducer(KafkaProducer kafkaProducer)
{    this.kafkaProducer = kafkaProducer;}
0
public void configure(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> configMap = configuration.getSensorConfig(sensorName);    String brokerUrl = Configurations.BROKER.getAndConvert(getConfigPrefix(), configMap, String.class);    if (brokerUrl != null) {        this.brokerUrl = brokerUrl;    }    String zkQuorum = Configurations.ZK_QUORUM.getAndConvert(getConfigPrefix(), configMap, String.class);    if (zkQuorum != null) {        withZkQuorum(zkQuorum);    }    String keySerializer = Configurations.KEY_SERIALIZER.getAndConvert(getConfigPrefix(), configMap, String.class);    if (keySerializer != null) {        withKeySerializer(keySerializer);    }    String valueSerializer = Configurations.VALUE_SERIALIZER.getAndConvert(getConfigPrefix(), configMap, String.class);    if (valueSerializer != null) {        withValueSerializer(keySerializer);    }    Integer requiredAcks = Configurations.REQUIRED_ACKS.getAndConvert(getConfigPrefix(), configMap, Integer.class);    if (requiredAcks != null) {        withRequiredAcks(requiredAcks);    }    String topic = Configurations.TOPIC.getAndConvert(getConfigPrefix(), configMap, String.class);    if (topic != null) {        withTopic(topic);    }    String topicField = Configurations.TOPIC_FIELD.getAndConvert(getConfigPrefix(), configMap, String.class);    if (topicField != null) {        withTopicField(topicField);    }    Map<String, Object> producerConfigs = (Map) Configurations.PRODUCER_CONFIGS.get(getConfigPrefix(), configMap);    if (producerConfigs != null) {        withProducerConfigs(producerConfigs);    }}
0
public void init(Map stormConf, WriterConfiguration config) throws Exception
{    if (this.zkQuorum != null && this.brokerUrl == null) {        try {            this.brokerUrl = Joiner.on(",").join(KafkaUtils.INSTANCE.getBrokersFromZookeeper(this.zkQuorum));        } catch (Exception e) {            throw new IllegalStateException("Cannot read kafka brokers from zookeeper and you didn't specify them, giving up!", e);        }    }    this.kafkaProducer = new KafkaProducer<>(createProducerConfigs());}
0
public Map<String, Object> createProducerConfigs()
{    Map<String, Object> producerConfig = new HashMap<>();    producerConfig.put("bootstrap.servers", brokerUrl);    producerConfig.put("key.serializer", keySerializer);    producerConfig.put("value.serializer", valueSerializer);    producerConfig.put("request.required.acks", requiredAcks);    producerConfig.put(ProducerConfig.BATCH_SIZE_CONFIG, DEFAULT_BATCH_SIZE);    producerConfig.putAll(producerConfigs == null ? new HashMap<>() : producerConfigs);    producerConfig = KafkaUtils.INSTANCE.normalizeProtocol(producerConfig);    return producerConfig;}
0
public Optional<String> getKafkaTopic(JSONObject message)
{    String t = null;    if (kafkaTopicField != null) {        t = (String) message.get(kafkaTopicField);            } else {        t = kafkaTopic;            }    return Optional.ofNullable(t);}
1
public BulkWriterResponse write(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages)
{    BulkWriterResponse writerResponse = new BulkWriterResponse();    List<Map.Entry<MessageId, Future>> results = new ArrayList<>();    for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        MessageId messageId = bulkWriterMessage.getId();        JSONObject message = bulkWriterMessage.getMessage();        String jsonMessage;        try {            jsonMessage = message.toJSONString();        } catch (Throwable t) {            writerResponse.addError(t, messageId);            continue;        }        Optional<String> topic = getKafkaTopic(message);        if (topic.isPresent()) {            Future future = kafkaProducer.send(new ProducerRecord<String, String>(topic.get(), jsonMessage));                        results.add(new AbstractMap.SimpleEntry<>(messageId, future));        } else {                    }    }    Collection<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toList());    try {                kafkaProducer.flush();    } catch (InterruptException e) {        writerResponse.addAllErrors(e, ids);        return writerResponse;    }    for (Map.Entry<MessageId, Future> kv : results) {        try {            kv.getValue().get();            writerResponse.addSuccess(kv.getKey());        } catch (Exception e) {            writerResponse.addError(e, kv.getKey());        }    }    return writerResponse;}
1
public String getName()
{    return "kafka";}
0
public void close() throws Exception
{    kafkaProducer.close();}
0
public int getMin()
{    return min;}
0
public int getMax()
{    return max;}
0
public Void apply(Void aVoid)
{    int sleepMs = ThreadLocalRandom.current().nextInt(min, max + 1);    try {        Thread.sleep(sleepMs);    } catch (InterruptedException e) {    }    return null;}
0
public int getLatency()
{    return latency;}
0
public Void apply(Void aVoid)
{    if (latency > 0) {        try {            Thread.sleep(latency);        } catch (InterruptedException e) {        }    }    return null;}
0
public NoopWriter withLatency(String sleepConfig)
{    sleepFunction = getSleepFunction(sleepConfig);    return this;}
0
private Function<Void, Void> getSleepFunction(String sleepConfig)
{    String usageMessage = "Unexpected: " + sleepConfig + " Expected value: integer for a fixed sleep duration in milliseconds (e.g. 10) " + "or a range of latencies separated by a comma (e.g. \"10, 20\") to sleep a random amount in that range.";    try {        if (sleepConfig.contains(",")) {                        Iterable<String> it = Splitter.on(',').split(sleepConfig);            Integer min = ConversionUtils.convert(Iterables.getFirst(it, "").trim(), Integer.class);            Integer max = ConversionUtils.convert(Iterables.getLast(it, "").trim(), Integer.class);            if (min != null && max != null) {                return new RandomLatency(min, max);            }        } else {                        Integer latency = ConversionUtils.convert(sleepConfig.trim(), Integer.class);            if (latency != null) {                return new FixedLatency(latency);            }        }    } catch (Throwable t) {        throw new IllegalArgumentException(usageMessage, t);    }    throw new IllegalArgumentException(usageMessage);}
0
public void configure(String sensorName, WriterConfiguration configuration)
{    Map<String, Object> config = configuration.getSensorConfig(sensorName);    if (config != null) {        Object noopLatency = config.get("noopLatency");        if (noopLatency != null) {            sleepFunction = getSleepFunction(noopLatency.toString());        }    }}
0
public void init(Map stormConf, WriterConfiguration config) throws Exception
{}
0
public BulkWriterResponse write(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    if (sleepFunction != null) {        sleepFunction.apply(null);    }    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    BulkWriterResponse response = new BulkWriterResponse();    response.addAllSuccesses(ids);    return response;}
0
public String getName()
{    return "noop";}
0
public void close() throws Exception
{}
0
public void init(Map stormConf, WriterConfiguration config) throws Exception
{    messageWriter.init();}
0
public BulkWriterResponse write(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages) throws Exception
{    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());    BulkWriterResponse response = new BulkWriterResponse();    if (messages.size() > 1) {        response.addAllErrors(new IllegalStateException("WriterToBulkWriter expects a batch of exactly 1"), ids);        return response;    }    try {        messageWriter.write(sensorType, configurations, Iterables.getFirst(messages, null));    } catch (Exception e) {        response.addAllErrors(e, ids);        return response;    }    response.addAllSuccesses(ids);    return response;}
0
public String getName()
{    return messageWriter.getName();}
0
public void close() throws Exception
{    messageWriter.close();}
0
public void setup()
{    when(configurations.getBatchSize(sensorType)).thenReturn(2);}
0
public void shouldFlushWhenBatchSizeReached()
{    BatchSizePolicy<JSONObject> batchSizePolicy = new BatchSizePolicy<>();    messages.add(new BulkMessage<>("message1", new JSONObject()));    messages.add(new BulkMessage<>("message2", new JSONObject()));    assertTrue(batchSizePolicy.shouldFlush(sensorType, configurations, messages));}
0
public void shouldNotFlushWhenBatchSizeNotReached()
{    BatchSizePolicy<JSONObject> batchSizePolicy = new BatchSizePolicy<>();    messages.add(new BulkMessage<>("message1", new JSONObject()));    assertFalse(batchSizePolicy.shouldFlush(sensorType, configurations, messages));}
0
public void shouldFlushWhenBatchSizeExceeded()
{    BatchSizePolicy<JSONObject> batchSizePolicy = new BatchSizePolicy<>();    messages.add(new BulkMessage<>("message1", new JSONObject()));    messages.add(new BulkMessage<>("message2", new JSONObject()));    messages.add(new BulkMessage<>("message3", new JSONObject()));    assertTrue(batchSizePolicy.shouldFlush(sensorType, configurations, messages));}
0
public void shouldFlushSensorsOnTimeouts()
{    Clock clock = mock(Clock.class);    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy<>(maxBatchTimeout, clock);    when(configurations.getBatchTimeout(sensor1)).thenReturn(1);    when(configurations.getBatchTimeout(sensor2)).thenReturn(2);        when(clock.currentTimeMillis()).thenReturn(0L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    assertFalse(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(999L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    assertFalse(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(1000L);    assertTrue(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    assertFalse(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(2000L);    assertTrue(batchTimeoutPolicy.shouldFlush(sensor2, configurations, messages));}
0
public void shouldResetTimeouts()
{    Clock clock = mock(Clock.class);    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy(maxBatchTimeout, clock);    when(configurations.getBatchTimeout(sensor1)).thenReturn(1);        when(clock.currentTimeMillis()).thenReturn(0L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));    batchTimeoutPolicy.onFlush(sensor1, new BulkWriterResponse());        when(clock.currentTimeMillis()).thenReturn(1000L);    assertFalse(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));        when(clock.currentTimeMillis()).thenReturn(2000L);    assertTrue(batchTimeoutPolicy.shouldFlush(sensor1, configurations, messages));}
0
public void getBatchTimeoutShouldReturnConfiguredTimeout()
{    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy(maxBatchTimeout);    when(configurations.getBatchTimeout(sensor1)).thenReturn(5);    assertEquals(5000L, batchTimeoutPolicy.getBatchTimeout(sensor1, configurations));}
0
public void getBatchTimeoutShouldReturnMaxBatchTimeout()
{    BatchTimeoutPolicy batchTimeoutPolicy = new BatchTimeoutPolicy(maxBatchTimeout);    when(configurations.getBatchTimeout(sensor1)).thenReturn(0);    assertEquals(maxBatchTimeout * 1000, batchTimeoutPolicy.getBatchTimeout(sensor1, configurations));}
0
public void setup()
{    MockitoAnnotations.initMocks(this);    message1.put("value", "message1");    message2.put("value", "message2");    messageIds = Arrays.asList(messageId1, messageId2);    messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>(messageId1, message1));            add(new BulkMessage<>(messageId2, message2));        }    };    when(configurations.isEnabled(any())).thenReturn(true);}
0
public void writeShouldProperlyAckTuplesInBatch() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    BulkWriterResponse response = new BulkWriterResponse();    response.addAllSuccesses(messageIds);    when(bulkMessageWriter.write(sensorType, configurations, messages)).thenReturn(response);    bulkWriterComponent.write(sensorType, messages.get(0), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    reset(flushPolicy);    when(flushPolicy.shouldFlush(sensorType, configurations, messages)).thenReturn(true);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    BulkWriterResponse expectedResponse = new BulkWriterResponse();    expectedResponse.addAllSuccesses(messageIds);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, Arrays.asList(new BulkMessage<>(messageId1, message1), new BulkMessage<>(messageId2, message2)));    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedResponse);    verifyNoMoreInteractions(bulkMessageWriter, flushPolicy);}
0
public void writeShouldFlushPreviousMessagesWhenDisabled() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    BulkMessage<JSONObject> beforeDisabledMessage = messages.get(0);    BulkMessage<JSONObject> afterDisabledMessage = messages.get(1);    BulkWriterResponse beforeDisabledResponse = new BulkWriterResponse();    beforeDisabledResponse.addSuccess(beforeDisabledMessage.getId());    BulkWriterResponse afterDisabledResponse = new BulkWriterResponse();    afterDisabledResponse.addSuccess(afterDisabledMessage.getId());    when(bulkMessageWriter.write(sensorType, configurations, Collections.singletonList(messages.get(0)))).thenReturn(beforeDisabledResponse);    bulkWriterComponent.write(sensorType, beforeDisabledMessage, bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    when(configurations.isEnabled(sensorType)).thenReturn(false);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, Collections.singletonList(messages.get(0)));    verify(flushPolicy, times(1)).onFlush(sensorType, beforeDisabledResponse);    verify(flushPolicy, times(1)).onFlush(sensorType, afterDisabledResponse);    verifyNoMoreInteractions(bulkMessageWriter, flushPolicy);}
0
public void writeShouldProperlyHandleWriterErrors() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    Throwable e = new Exception("test exception");    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(e, messageIds);    when(bulkMessageWriter.write(sensorType, configurations, messages)).thenReturn(response);    bulkWriterComponent.write(sensorType, messages.get(0), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    reset(flushPolicy);    when(flushPolicy.shouldFlush(sensorType, configurations, messages)).thenReturn(true);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    BulkWriterResponse expectedErrorResponse = new BulkWriterResponse();    expectedErrorResponse.addAllErrors(e, messageIds);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, messages);    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedErrorResponse);    verifyNoMoreInteractions(bulkMessageWriter, flushPolicy);}
0
public void writeShouldProperlyHandleWriterException() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    Throwable e = new Exception("test exception");    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(e, messageIds);    when(bulkMessageWriter.write(sensorType, configurations, messages)).thenThrow(e);    bulkWriterComponent.write(sensorType, messages.get(0), bulkMessageWriter, configurations);    verify(bulkMessageWriter, times(0)).write(eq(sensorType), eq(configurations), any());    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages.subList(0, 1));    verify(flushPolicy, times(0)).onFlush(any(), any());    reset(flushPolicy);    when(flushPolicy.shouldFlush(sensorType, configurations, messages)).thenReturn(true);    bulkWriterComponent.write(sensorType, messages.get(1), bulkMessageWriter, configurations);    BulkWriterResponse expectedErrorResponse = new BulkWriterResponse();    expectedErrorResponse.addAllErrors(e, messageIds);    verify(bulkMessageWriter, times(1)).write(sensorType, configurations, messages);    verify(flushPolicy, times(1)).shouldFlush(sensorType, configurations, messages);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedErrorResponse);    verifyNoMoreInteractions(flushPolicy);}
0
public void flushShouldAckMissingTuples() throws Exception
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    BulkMessageWriter<JSONObject> bulkMessageWriter = mock(BulkMessageWriter.class);    MessageId successId = new MessageId("successId");    MessageId errorId = new MessageId("errorId");    MessageId missingId = new MessageId("missingId");    JSONObject successMessage = new JSONObject();    successMessage.put("name", "success");    JSONObject errorMessage = new JSONObject();    errorMessage.put("name", "error");    JSONObject missingMessage = new JSONObject();    missingMessage.put("name", "missing");    List<BulkMessage<JSONObject>> allMessages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>(successId, successMessage));            add(new BulkMessage<>(errorId, errorMessage));            add(new BulkMessage<>(missingId, missingMessage));        }    };    BulkWriterResponse bulkWriterResponse = new BulkWriterResponse();    bulkWriterResponse.addSuccess(successId);    Throwable throwable = mock(Throwable.class);    bulkWriterResponse.addError(throwable, errorId);    when(bulkMessageWriter.write(sensorType, configurations, allMessages)).thenReturn(bulkWriterResponse);    bulkWriterComponent.flush(sensorType, bulkMessageWriter, configurations, allMessages);    BulkWriterResponse expectedResponse = new BulkWriterResponse();    expectedResponse.addSuccess(successId);    expectedResponse.addError(throwable, errorId);    expectedResponse.addSuccess(missingId);    verify(flushPolicy, times(1)).onFlush(sensorType, expectedResponse);    verifyNoMoreInteractions(flushPolicy);}
0
public void flushAllShouldFlushAllSensors()
{    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(Collections.singletonList(flushPolicy));    bulkWriterComponent.write("sensor1", messages.get(0), bulkMessageWriter, configurations);    bulkWriterComponent.write("sensor2", messages.get(1), bulkMessageWriter, configurations);    reset(flushPolicy);    bulkWriterComponent.flushAll(bulkMessageWriter, configurations);    verify(flushPolicy, times(1)).shouldFlush("sensor1", configurations, messages.subList(0, 1));    verify(flushPolicy, times(1)).shouldFlush("sensor2", configurations, messages.subList(1, 2));    verifyNoMoreInteractions(flushPolicy);}
0
public void setupMockTable()
{    MockHBaseTableProvider.addToCache(TABLE_NAME, TABLE_CF);}
0
public void testBatchOneNormalPath() throws Exception
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>(BASE_WRITER_CONFIG) {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");        }    });    writer.configure(sensorType, configuration);    writer.write(SENSOR_TYPE, configuration, new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("messageId", new JSONObject(ImmutableMap.of("ip", "localhost", "user", "cstella", "foo", "bar"))));        }    });    List<LookupKV<EnrichmentKey, EnrichmentValue>> values = getValues();    Assert.assertEquals(1, values.size());    Assert.assertEquals("localhost", values.get(0).getKey().indicator);    Assert.assertEquals("cstella", values.get(0).getValue().getMetadata().get("user"));    Assert.assertEquals("bar", values.get(0).getValue().getMetadata().get("foo"));    Assert.assertEquals(2, values.get(0).getValue().getMetadata().size());}
0
public void testFilteredKey() throws Exception
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>(BASE_WRITER_CONFIG) {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.VALUE_COLUMNS.getKey(), "user");        }    });    writer.configure(sensorType, configuration);    writer.write(SENSOR_TYPE, configuration, new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("messageId", new JSONObject(ImmutableMap.of("ip", "localhost", "user", "cstella", "foo", "bar"))));        }    });    List<LookupKV<EnrichmentKey, EnrichmentValue>> values = getValues();    Assert.assertEquals(1, values.size());    Assert.assertEquals("localhost", values.get(0).getKey().indicator);    Assert.assertEquals("cstella", values.get(0).getValue().getMetadata().get("user"));    Assert.assertNull(values.get(0).getValue().getMetadata().get("foo"));    Assert.assertEquals(1, values.get(0).getValue().getMetadata().size());}
0
public void testFilteredKeys() throws Exception
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>(BASE_WRITER_CONFIG) {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.VALUE_COLUMNS.getKey(), ImmutableList.of("user", "ip"));        }    });    writer.configure(sensorType, configuration);    writer.write(SENSOR_TYPE, configuration, new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("messageId", new JSONObject(ImmutableMap.of("ip", "localhost", "user", "cstella", "foo", "bar"))));        }    });    List<LookupKV<EnrichmentKey, EnrichmentValue>> values = getValues();    Assert.assertEquals(1, values.size());    Assert.assertEquals("localhost", values.get(0).getKey().indicator);    Assert.assertEquals("cstella", values.get(0).getValue().getMetadata().get("user"));    Assert.assertEquals("localhost", values.get(0).getValue().getMetadata().get("ip"));    Assert.assertNull(values.get(0).getValue().getMetadata().get("foo"));    Assert.assertEquals(2, values.get(0).getValue().getMetadata().size());}
0
public void testConfigValidation_missing_enrichment_type()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must be provided", SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey()), ex.getMessage());        throw ex;    }}
0
public void testConfigValidation_enrichment_type_is_not_a_string()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), 10);        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must be a string", SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey()), ex.getMessage());        throw ex;    }}
0
public void testConfigValidation_enrichment_type_is_empty()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), "ip");            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), "  ");        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must not be an empty string", SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey()), ex.getMessage());        throw ex;    }}
0
public void testConfigValidation_missing_key_columns()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), ENRICHMENT_TYPE);        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals(String.format("%s must be provided", SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey()), ex.getMessage());        throw ex;    }}
0
public void testConfigValidation_key_columns_contain_an_empty_value()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), ENRICHMENT_TYPE);            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), Arrays.asList("ip", "  "));        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals("Column name must not be empty", ex.getMessage());        throw ex;    }}
0
public void testConfigValidation_key_columns_contain_a_null_value()
{    final String sensorType = "dummy";    SimpleHbaseEnrichmentWriter writer = new SimpleHbaseEnrichmentWriter();    WriterConfiguration configuration = createConfig(1, new HashMap<String, Object>() {        {            put(SimpleHbaseEnrichmentWriter.Configurations.ENRICHMENT_TYPE.getKey(), ENRICHMENT_TYPE);            put(SimpleHbaseEnrichmentWriter.Configurations.KEY_COLUMNS.getKey(), Arrays.asList("ip", null));        }    });    try {        writer.configure(sensorType, configuration);    } catch (IllegalArgumentException ex) {        Assert.assertEquals("Column name must not be null", ex.getMessage());        throw ex;    }}
0
public static List<LookupKV<EnrichmentKey, EnrichmentValue>> getValues() throws IOException
{    MockHTable table = (MockHTable) MockHBaseTableProvider.getFromCache(TABLE_NAME);    Assert.assertNotNull(table);    List<LookupKV<EnrichmentKey, EnrichmentValue>> ret = new ArrayList<>();    EnrichmentConverter converter = new EnrichmentConverter();    for (Result r : table.getScanner(Bytes.toBytes(TABLE_CF))) {        ret.add(converter.fromResult(r, TABLE_CF));    }    return ret;}
0
public static WriterConfiguration createConfig(final int batchSize, final Map<String, Object> sensorConfig)
{    return new WriterConfiguration() {        @Override        public int getBatchSize(String sensorName) {            return batchSize;        }        @Override        public int getBatchTimeout(String sensorName) {                        return 0;        }        @Override        public List<Integer> getAllConfiguredTimeouts() {                        return new ArrayList<>();        }        @Override        public String getIndex(String sensorName) {            return SENSOR_TYPE;        }        @Override        public boolean isEnabled(String sensorName) {            return true;        }        @Override        public Map<String, Object> getSensorConfig(String sensorName) {            return sensorConfig;        }        @Override        public Map<String, Object> getGlobalConfig() {            return null;        }        @Override        public boolean isDefault(String sensorName) {            return false;        }        @Override        public String getFieldNameConverter(String sensorName) {            return null;        }    };}
0
public int getBatchSize(String sensorName)
{    return batchSize;}
0
public int getBatchTimeout(String sensorName)
{        return 0;}
0
public List<Integer> getAllConfiguredTimeouts()
{        return new ArrayList<>();}
0
public String getIndex(String sensorName)
{    return SENSOR_TYPE;}
0
public boolean isEnabled(String sensorName)
{    return true;}
0
public Map<String, Object> getSensorConfig(String sensorName)
{    return sensorConfig;}
0
public Map<String, Object> getGlobalConfig()
{    return null;}
0
public boolean isDefault(String sensorName)
{    return false;}
0
public String getFieldNameConverter(String sensorName)
{    return null;}
0
public WriterConfiguration createConfiguration(final Map<String, Object> parserConfig)
{    ParserConfigurations configurations = new ParserConfigurations();    configurations.updateSensorParserConfig(SENSOR_TYPE, new SensorParserConfig() {        {            setParserConfig(parserConfig);        }    });    return new ParserWriterConfiguration(configurations);}
0
public void setup()
{    MockitoAnnotations.initMocks(this);}
0
public void testHappyPathGlobalConfig() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.topic", SENSOR_TYPE);            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    Map<String, Object> producerConfigs = writer.createProducerConfigs();    assertEquals(producerConfigs.get("bootstrap.servers"), "localhost:6667");    assertEquals(producerConfigs.get("key.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("value.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("request.required.acks"), 1);    assertEquals(producerConfigs.get("key1"), 1);    assertEquals(producerConfigs.get("key2"), "value2");}
0
public void testHappyPathGlobalConfigWithPrefix() throws Exception
{    KafkaWriter writer = new KafkaWriter();    writer.withConfigPrefix("prefix");    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("prefix.kafka.brokerUrl", "localhost:6667");            put("prefix.kafka.topic", SENSOR_TYPE);            put("prefix.kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    Map<String, Object> producerConfigs = writer.createProducerConfigs();    assertEquals(producerConfigs.get("bootstrap.servers"), "localhost:6667");    assertEquals(producerConfigs.get("key.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("value.serializer"), "org.apache.kafka.common.serialization.StringSerializer");    assertEquals(producerConfigs.get("request.required.acks"), 1);    assertEquals(producerConfigs.get("key1"), 1);    assertEquals(producerConfigs.get("key2"), "value2");}
0
public void testTopicField_bothTopicAndFieldSpecified() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.topic", SENSOR_TYPE);            put("kafka.topicField", "kafka_topic");            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    assertEquals("metron", writer.getKafkaTopic(new JSONObject() {        {            put("kafka_topic", "metron");        }    }).get());    Assert.assertFalse(writer.getKafkaTopic(new JSONObject()).isPresent());}
0
public void testTopicField_onlyFieldSpecified() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.topicField", "kafka_topic");            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    assertEquals("metron", writer.getKafkaTopic(new JSONObject() {        {            put("kafka_topic", "metron");        }    }).get());    Assert.assertFalse(writer.getKafkaTopic(new JSONObject()).isPresent());}
0
public void testTopicField_neitherSpecified() throws Exception
{    KafkaWriter writer = new KafkaWriter();    WriterConfiguration configuration = createConfiguration(new HashMap<String, Object>() {        {            put("kafka.brokerUrl", "localhost:6667");            put("kafka.producerConfigs", ImmutableMap.of("key1", 1, "key2", "value2"));        }    });    writer.configure(SENSOR_TYPE, configuration);    assertEquals(Constants.ENRICHMENT_TOPIC, writer.getKafkaTopic(new JSONObject() {        {            put("kafka_topic", "metron");        }    }).get());    Assert.assertTrue(writer.getKafkaTopic(new JSONObject()).isPresent());}
0
public void testWriterShouldReturnResponse() throws Exception
{    KafkaWriter writer = spy(new KafkaWriter());    writer.setKafkaProducer(kafkaProducer);    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    JSONObject successMessage = new JSONObject();    successMessage.put("value", "success");    JSONObject errorMessage = new JSONObject();    errorMessage.put("value", "error");    JSONObject droppedMessage = new JSONObject();    droppedMessage.put("value", "dropped");    messages.add(new BulkMessage<>("successId", successMessage));    messages.add(new BulkMessage<>("errorId", errorMessage));    messages.add(new BulkMessage<>("droppedId", droppedMessage));    doReturn(Optional.of("successTopic")).when(writer).getKafkaTopic(successMessage);    doReturn(Optional.of("errorTopic")).when(writer).getKafkaTopic(errorMessage);    doReturn(Optional.empty()).when(writer).getKafkaTopic(droppedMessage);    Future successFuture = mock(Future.class);    Future errorFuture = mock(Future.class);    ExecutionException throwable = new ExecutionException(new Exception("kafka error"));    when(kafkaProducer.send(new ProducerRecord<String, String>("errorTopic", "{\"value\":\"error\"}"))).thenReturn(errorFuture);    when(kafkaProducer.send(new ProducerRecord<String, String>("successTopic", "{\"value\":\"success\"}"))).thenReturn(successFuture);    when(errorFuture.get()).thenThrow(throwable);    BulkWriterResponse response = new BulkWriterResponse();    response.addSuccess(new MessageId("successId"));    response.addError(throwable, new MessageId("errorId"));    assertEquals(response, writer.write(SENSOR_TYPE, createConfiguration(new HashMap<>()), messages));    verify(kafkaProducer, times(1)).flush();    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("successTopic", "{\"value\":\"success\"}"));    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("errorTopic", "{\"value\":\"error\"}"));    verifyNoMoreInteractions(kafkaProducer);}
0
public void testWriteShouldReturnErrorsOnFailedFlush() throws Exception
{    KafkaWriter writer = spy(new KafkaWriter());    writer.setKafkaProducer(kafkaProducer);    List<BulkMessage<JSONObject>> messages = new ArrayList<>();    JSONObject message1 = new JSONObject();    message1.put("value", "message1");    JSONObject message2 = new JSONObject();    message2.put("value", "message2");    messages.add(new BulkMessage<>("messageId1", message1));    messages.add(new BulkMessage<>("messageId2", message2));    doReturn(Optional.of("topic1")).when(writer).getKafkaTopic(message1);    doReturn(Optional.of("topic2")).when(writer).getKafkaTopic(message2);    Future future1 = mock(Future.class);    Future future2 = mock(Future.class);    when(kafkaProducer.send(new ProducerRecord<String, String>("topic1", "{\"value\":\"message1\"}"))).thenReturn(future1);    when(kafkaProducer.send(new ProducerRecord<String, String>("topic2", "{\"value\":\"message2\"}"))).thenReturn(future2);    InterruptException throwable = new InterruptException("kafka flush exception");    doThrow(throwable).when(kafkaProducer).flush();    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(throwable, Arrays.asList(new MessageId("messageId1"), new MessageId("messageId2")));    assertEquals(response, writer.write(SENSOR_TYPE, createConfiguration(new HashMap<>()), messages));    verify(kafkaProducer, times(1)).flush();    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("topic1", "{\"value\":\"message1\"}"));    verify(kafkaProducer, times(1)).send(new ProducerRecord<String, String>("topic2", "{\"value\":\"message2\"}"));    verifyNoMoreInteractions(kafkaProducer);}
0
public void testFixedLatencyConfig()
{    NoopWriter writer = new NoopWriter().withLatency("10");    Assert.assertTrue(writer.sleepFunction instanceof NoopWriter.FixedLatency);    NoopWriter.FixedLatency sleepFunction = (NoopWriter.FixedLatency) writer.sleepFunction;    Assert.assertEquals(10, sleepFunction.getLatency());}
0
private void ensureRandomLatencyConfig(String latencyConfig, int min, int max)
{    NoopWriter writer = new NoopWriter().withLatency(latencyConfig);    Assert.assertTrue(writer.sleepFunction instanceof NoopWriter.RandomLatency);    NoopWriter.RandomLatency sleepFunction = (NoopWriter.RandomLatency) writer.sleepFunction;    Assert.assertEquals(min, sleepFunction.getMin());    Assert.assertEquals(max, sleepFunction.getMax());}
0
public void testRandomLatencyConfig()
{    ensureRandomLatencyConfig("10,20", 10, 20);    ensureRandomLatencyConfig("10, 20", 10, 20);    ensureRandomLatencyConfig("10 ,20", 10, 20);    ensureRandomLatencyConfig("10 , 20", 10, 20);}
0
protected Map<Tuple, Collection<MessageId>> getTupleMessageMap()
{    return tupleMessageMap;}
0
protected Map<Tuple, Set<Throwable>> getTupleErrorMap()
{    return tupleErrorMap;}
0
public boolean shouldFlush(String sensorType, WriterConfiguration configurations, List<BulkMessage<MESSAGE_T>> messages)
{    return false;}
0
public void onFlush(String sensorType, BulkWriterResponse response)
{            Collection<Tuple> tuplesToAck = new ArrayList<>();    tupleMessageMap = tupleMessageMap.entrySet().stream().map(entry -> {        Tuple tuple = entry.getKey();        Collection<MessageId> ids = new ArrayList<>(entry.getValue());                ids.removeAll(response.getSuccesses());                response.getErrors().forEach((throwable, failedIds) -> {            if (ids.removeAll(failedIds)) {                                Set<Throwable> errorList = tupleErrorMap.getOrDefault(tuple, new HashSet<>());                tupleErrorMap.put(tuple, errorList);                errorList.add(throwable);                handleError(sensorType, throwable, tuple);            }        });        return new AbstractMap.SimpleEntry<>(tuple, ids);    }).filter(entry -> {                if (entry.getValue().isEmpty()) {            tuplesToAck.add(entry.getKey());                        return false;        }        return true;    }).collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));        tuplesToAck.forEach(tuple -> {        collector.ack(tuple);    });        Collection<Tuple> failedTuples = tuplesToAck.stream().filter(tuple -> tupleErrorMap.containsKey(tuple)).collect(Collectors.toList());        Set<Throwable> errorsToReport = new HashSet<>();    failedTuples.forEach(tuple -> {                errorsToReport.addAll(tupleErrorMap.remove(tuple));    });    errorsToReport.forEach(throwable -> {                collector.reportError(throwable);    });}
1
public void addTupleMessageIds(Tuple tuple, Collection<String> messageIds)
{        tupleMessageMap.put(tuple, messageIds.stream().map(MessageId::new).collect(Collectors.toSet()));}
1
private void handleError(String sensorType, Throwable e, Tuple tuple)
{    MetronError error = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e).addRawMessage(messageGetStrategy.get(tuple));    collector.emit(Constants.ERROR_STREAM, new Values(error.getJSONObject()));}
0
private synchronized void init()
{    if (initialized)        return;    readGlobalTimeoutConfigs();    calcMaxBatchTimeoutAllowed();    readMinBatchTimeoutRequested();    calcRecommendedTickInterval();    initialized = true;}
0
private Map readStormConfigWithoutCLI()
{    Map ret = Utils.readDefaultConfig();    String confFile = System.getProperty("storm.conf.file");    Map storm;    if (confFile == null || confFile.equals("")) {        storm = Utils.findAndReadConfigFile("storm.yaml", false);    } else {        storm = Utils.findAndReadConfigFile(confFile, true);    }    ret.putAll(storm);    return ret;}
0
private void readGlobalTimeoutConfigs()
{    Map stormConf = readStormConfigWithoutCLI();    Map cliConf = Utils.readCommandLineOpts();        baseMessageTimeoutSecs = (Integer) stormConf.getOrDefault(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, 0);    cliMessageTimeoutSecs = (Integer) cliConf.getOrDefault(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, 0);        Object scratch;    scratch = stormConf.getOrDefault(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 0);    baseTickTupleFreqSecs = (scratch == null) ? 0 : (Integer) scratch;    scratch = cliConf.getOrDefault(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, 0);    cliTickTupleFreqSecs = (scratch == null) ? 0 : (Integer) scratch;}
0
private void calcMaxBatchTimeoutAllowed()
{        effectiveMessageTimeoutSecs = (cliMessageTimeoutSecs == 0 ? baseMessageTimeoutSecs : cliMessageTimeoutSecs);    if (effectiveMessageTimeoutSecs == 0) {                maxBatchTimeoutAllowedSecs = Integer.MAX_VALUE;    } else {                                        maxBatchTimeoutAllowedSecs = effectiveMessageTimeoutSecs / 2 / batchTimeoutDivisor - 1;        if (maxBatchTimeoutAllowedSecs <= 0) {                        maxBatchTimeoutAllowedSecs = 1;        }    }}
1
public int getMaxBatchTimeout()
{    if (!initialized) {        this.init();    }    return maxBatchTimeoutAllowedSecs;}
0
private void readMinBatchTimeoutRequested()
{            List<Integer> configuredTimeouts = listAllConfiguredTimeouts.get();        int minval = Integer.MAX_VALUE;    for (int k : configuredTimeouts) {        if (k < minval && k > 0)            minval = k;    }    minBatchTimeoutRequestedSecs = minval;}
0
private void calcRecommendedTickInterval()
{    recommendedTickIntervalSecs = Integer.min(minBatchTimeoutRequestedSecs, maxBatchTimeoutAllowedSecs);}
0
public int getRecommendedTickInterval()
{    if (!initialized) {        this.init();    }        if (cliTickTupleFreqSecs > 0 && cliTickTupleFreqSecs > recommendedTickIntervalSecs) {            }    if (cliTickTupleFreqSecs > 0 && cliTickTupleFreqSecs < recommendedTickIntervalSecs) {            }    return recommendedTickIntervalSecs;}
1
public BulkMessageWriterBolt<CONFIG_T> withBulkMessageWriter(BulkMessageWriter<JSONObject> bulkMessageWriter)
{    this.bulkMessageWriter = bulkMessageWriter;    return this;}
0
public BulkMessageWriterBolt<CONFIG_T> withMessageWriter(MessageWriter<JSONObject> messageWriter)
{    this.bulkMessageWriter = new WriterToBulkWriter<>(messageWriter);    return this;}
0
public BulkMessageWriterBolt<CONFIG_T> withMessageGetter(String messageGetStrategyType)
{    this.messageGetStrategyType = messageGetStrategyType;    return this;}
0
public BulkMessageWriterBolt<CONFIG_T> withMessageGetterField(String messageGetField)
{    this.messageGetField = messageGetField;    return this;}
0
public BulkMessageWriterBolt<CONFIG_T> withBatchTimeoutDivisor(int batchTimeoutDivisor)
{    if (batchTimeoutDivisor <= 0) {        throw new IllegalArgumentException(String.format("batchTimeoutDivisor must be positive. Value provided was %s", batchTimeoutDivisor));    }    this.batchTimeoutDivisor = batchTimeoutDivisor;    return this;}
0
protected void setMaxBatchTimeout(int maxBatchTimeout)
{    this.maxBatchTimeout = maxBatchTimeout;}
0
public int getMaxBatchTimeout()
{    return maxBatchTimeout;}
0
public BulkWriterComponent<JSONObject> getWriterComponent()
{    return writerComponent;}
0
public void setWriterComponent(BulkWriterComponent<JSONObject> component)
{    writerComponent = component;}
0
public Map<String, Object> getComponentConfiguration()
{                Function<WriterConfiguration, WriterConfiguration> configurationXform;    if (bulkMessageWriter instanceof WriterToBulkWriter) {        configurationXform = WriterToBulkWriter.TRANSFORMATION;    } else {        configurationXform = x -> x;    }    WriterConfiguration writerconf = configurationXform.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations()));    BatchTimeoutHelper timeoutHelper = new BatchTimeoutHelper(writerconf::getAllConfiguredTimeouts, batchTimeoutDivisor);    this.requestedTickFreqSecs = timeoutHelper.getRecommendedTickInterval();        this.maxBatchTimeout = timeoutHelper.getMaxBatchTimeout();    Map<String, Object> conf = super.getComponentConfiguration();    if (conf == null) {        conf = new HashMap<String, Object>();    }    conf.put(Config.TOPOLOGY_TICK_TUPLE_FREQ_SECS, requestedTickFreqSecs);        return conf;}
1
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector)
{    this.collector = collector;    super.prepare(stormConf, context, collector);    if (messageGetField != null) {        messageGetStrategy = MessageGetters.valueOf(messageGetStrategyType).get(messageGetField);    } else {        messageGetStrategy = MessageGetters.valueOf(messageGetStrategyType).get();    }    if (bulkMessageWriter instanceof WriterToBulkWriter) {        configurationTransformation = WriterToBulkWriter.TRANSFORMATION;    } else {        configurationTransformation = x -> x;    }    ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);    try {        WriterConfiguration writerconf = configurationTransformation.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations()));        if (maxBatchTimeout == 0) {                                    BatchTimeoutHelper timeoutHelper = new BatchTimeoutHelper(writerconf::getAllConfiguredTimeouts, batchTimeoutDivisor);            maxBatchTimeout = timeoutHelper.getMaxBatchTimeout();        }        BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(maxBatchTimeout);        bulkWriterComponent.addFlushPolicy(ackTuplesPolicy);        setWriterComponent(bulkWriterComponent);        bulkMessageWriter.init(stormConf, writerconf);        if (bulkMessageWriter instanceof HdfsWriter) {            ((HdfsWriter) bulkMessageWriter).initFileNameFormat(context);        }    } catch (Exception e) {        throw new RuntimeException(e);    }}
0
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector, Clock clock)
{    prepare(stormConf, context, collector);    BulkWriterComponent<JSONObject> bulkWriterComponent = new BulkWriterComponent<>(maxBatchTimeout, clock);    bulkWriterComponent.addFlushPolicy(ackTuplesPolicy);    setWriterComponent(bulkWriterComponent);}
0
public void execute(Tuple tuple)
{    if (isTick(tuple)) {        try {            if (!(bulkMessageWriter instanceof WriterToBulkWriter)) {                                                getWriterComponent().flushAll(bulkMessageWriter, configurationTransformation.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations())));            }        } catch (Exception e) {            throw new RuntimeException("This should have been caught in the writerComponent.  If you see this, file a JIRA", e);        } finally {            collector.ack(tuple);        }        return;    }    try {        JSONObject message = getMessage(tuple);        if (message == null) {            handleMissingMessage(tuple);            return;        }        String sensorType = MessageUtils.getSensorType(message);        if (sensorType == null) {            handleMissingSensorType(tuple, message);            return;        }        LOG.trace("Writing enrichment message: {}", message);        WriterConfiguration writerConfiguration = configurationTransformation.apply(getConfigurationStrategy().createWriterConfig(bulkMessageWriter, getConfigurations()));        if (writerConfiguration.isDefault(sensorType)) {                        collector.reportError(new Exception("WARNING: Default and (likely) unoptimized writer config used for " + bulkMessageWriter.getName() + " writer and sensor " + sensorType));        }        String messagesId = MessageUtils.getGuid(message);        ackTuplesPolicy.addTupleMessageIds(tuple, Collections.singleton(messagesId));        getWriterComponent().write(sensorType, new BulkMessage<>(messagesId, message), bulkMessageWriter, writerConfiguration);    } catch (Exception e) {        throw new RuntimeException("This should have been caught in the writerComponent.  If you see this, file a JIRA", e);    }}
1
private JSONObject getMessage(Tuple tuple)
{    JSONObject message = null;    try {        message = (JSONObject) messageGetStrategy.get(tuple);    } catch (Throwable e) {            }    return message;}
1
public void declareOutputFields(OutputFieldsDeclarer declarer)
{    declarer.declareStream(Constants.ERROR_STREAM, new Fields("message"));}
0
public SyncPolicy create(String sensor, WriterConfiguration config)
{    try {                                                                        syncPolicy.reset();        byte[] serializedForm = SerDeUtils.toBytes(syncPolicy);        return SerDeUtils.fromBytes(serializedForm, SyncPolicy.class);    } catch (Exception e) {        throw new IllegalStateException(e.getMessage(), e);    }}
0
public HdfsWriter withFileNameFormat(FileNameFormat fileNameFormat)
{    this.fileNameFormat = fileNameFormat;    return this;}
0
public HdfsWriter withSyncPolicy(SyncPolicy syncPolicy)
{    this.syncPolicy = syncPolicy;    return this;}
0
public HdfsWriter withRotationPolicy(FileRotationPolicy rotationPolicy)
{    this.rotationPolicy = rotationPolicy;    return this;}
0
public HdfsWriter addRotationAction(RotationAction action)
{    this.rotationActions.add(action);    return this;}
0
public HdfsWriter withMaxOpenFiles(int maxOpenFiles)
{    this.maxOpenFiles = maxOpenFiles;    return this;}
0
public void init(Map stormConfig, WriterConfiguration configurations)
{    this.stormConfig = stormConfig;    this.stellarProcessor = new StellarProcessor();    if (syncPolicy != null) {                        syncPolicyCreator = new ClonedSyncPolicyCreator(syncPolicy);    } else {                        syncPolicyCreator = (source, config) -> new CountSyncPolicy(config == null ? 1 : config.getBatchSize(source));    }}
1
public void initFileNameFormat(TopologyContext topologyContext)
{    this.fileNameFormat.prepare(stormConfig, topologyContext);}
0
public BulkWriterResponse write(String sensorType, WriterConfiguration configurations, List<BulkMessage<JSONObject>> messages) throws Exception
{    BulkWriterResponse response = new BulkWriterResponse();    Set<MessageId> ids = messages.stream().map(BulkMessage::getId).collect(Collectors.toSet());        for (BulkMessage<JSONObject> bulkWriterMessage : messages) {        JSONObject message = bulkWriterMessage.getMessage();        String path = getHdfsPathExtension(sensorType, (String) configurations.getSensorConfig(sensorType).getOrDefault(IndexingConfigurations.OUTPUT_PATH_FUNCTION_CONF, ""), message);        try {            LOG.trace("Writing message {} to path: {}", () -> message.toJSONString(), () -> path);            SourceHandler handler = getSourceHandler(sensorType, path, configurations);            handler.handle(message, sensorType, configurations, syncPolicyCreator);        } catch (Exception e) {                        response.addAllErrors(e, ids);        }    }    response.addAllSuccesses(ids);    return response;}
1
public String getName()
{    return "hdfs";}
0
public void close()
{    for (SourceHandler handler : sourceHandlerMap.values()) {                handler.close();    }        sourceHandlerMap.clear();}
1
 synchronized SourceHandler getSourceHandler(String sourceType, String stellarResult, WriterConfiguration config) throws IOException
{    SourceHandlerKey key = new SourceHandlerKey(sourceType, stellarResult);    SourceHandler ret = sourceHandlerMap.get(key);    if (ret == null) {        if (sourceHandlerMap.size() >= maxOpenFiles) {            String errorMsg = "Too many HDFS files open! Maximum number of open files is: " + maxOpenFiles + ". Current number of open files is: " + sourceHandlerMap.size();                        throw new IllegalStateException(errorMsg);        }        ret = new SourceHandler(rotationActions, rotationPolicy, syncPolicyCreator.create(sourceType, config), new PathExtensionFileNameFormat(key.getStellarResult(), fileNameFormat), new SourceHandlerCallback(sourceHandlerMap, key));                sourceHandlerMap.put(key, ret);    }    return ret;}
1
public void prepare(Map map, TopologyContext topologyContext)
{    this.delegate.prepare(map, topologyContext);}
0
public String getName(long rotation, long l1)
{    return delegate.getName(rotation, l1);}
0
public String getPath()
{    return delegate.getPath() + "/" + pathExtension;}
0
public SourceAwareMoveAction toDestination(String destDir)
{    destination = destDir;    return this;}
0
private static String getSource(Path filePath)
{    return filePath.getParent().getName();}
0
public void execute(FileSystem fileSystem, Path filePath) throws IOException
{    Path destPath = new Path(new Path(destination, getSource(filePath)), filePath.getName());        boolean success = fileSystem.rename(filePath, destPath);}
1
protected void handle(JSONObject message, String sensor, WriterConfiguration config, SyncPolicyCreator syncPolicyCreator) throws IOException
{    byte[] bytes = (message.toJSONString() + "\n").getBytes(StandardCharsets.UTF_8);    synchronized (this.writeLock) {        try {            out.write(bytes);        } catch (IOException writeException) {                                    if (writeException.getMessage().contains("Stream Closed")) {                                rotateOutputFile();                                out.write(bytes);            } else {                throw writeException;            }        }        this.offset += bytes.length;        if (this.syncPolicy.mark(null, this.offset)) {                        if (this.out instanceof HdfsDataOutputStream) {                ((HdfsDataOutputStream) this.out).hsync(EnumSet.of(HdfsDataOutputStream.SyncFlag.UPDATE_LENGTH));            } else {                this.out.hsync();            }                                                this.syncPolicy = syncPolicyCreator.create(sensor, config);        }    }    if (this.rotationPolicy.mark(null, this.offset)) {                        rotateOutputFile();        this.offset = 0;        this.rotationPolicy.reset();    }}
1
private void initialize() throws IOException
{        this.fs = FileSystem.get(new Configuration());    this.currentFile = createOutputFile();        if (this.rotationPolicy instanceof TimedRotationPolicy) {        long interval = ((TimedRotationPolicy) this.rotationPolicy).getInterval();        this.rotationTimer = new Timer(true);        TimerTask task = new TimerTask() {            @Override            public void run() {                try {                                        rotateOutputFile();                } catch (IOException e) {                                    }            }        };        this.rotationTimer.scheduleAtFixedRate(task, interval, interval);    }}
1
public void run()
{    try {                rotateOutputFile();    } catch (IOException e) {            }}
1
protected void rotateOutputFile() throws IOException
{        long start = System.currentTimeMillis();    synchronized (this.writeLock) {        closeOutputFile();                cleanupCallback();                for (RotationAction action : this.rotationActions) {            action.execute(this.fs, this.currentFile);        }    }    long time = System.currentTimeMillis() - start;    }
1
private Path createOutputFile() throws IOException
{                Path path = new Path(this.fileNameFormat.getPath(), this.fileNameFormat.getName(0, System.currentTimeMillis()));        if (fs.getScheme().equals("file")) {                fs.mkdirs(path.getParent());        this.out = new FSDataOutputStream(new FileOutputStream(path.toString()), null);    } else {        this.out = this.fs.create(path);    }    return path;}
1
protected void closeOutputFile() throws IOException
{    this.out.close();}
0
private void cleanupCallback()
{    this.cleanupCallback.removeKey();}
0
public void close()
{    try {        closeOutputFile();        if (rotationTimer != null) {            rotationTimer.cancel();        }        } catch (IOException e) {        throw new RuntimeException("Unable to close output file.", e);    }}
0
public String toString()
{    return "SourceHandler{" + "rotationActions=" + rotationActions + ", rotationPolicy=" + rotationPolicy + ", syncPolicy=" + syncPolicy + ", fileNameFormat=" + fileNameFormat + ", offset=" + offset + ", out=" + out + ", writeLock=" + writeLock + ", rotationTimer=" + rotationTimer + ", fs=" + fs + ", currentFile=" + currentFile + '}';}
0
public void removeKey()
{    SourceHandler removed = sourceHandlerMap.remove(key);    if (removed != null) {        removed.close();    }    }
1
public String getSourceType()
{    return sourceType;}
0
public String getStellarResult()
{    return stellarResult;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    SourceHandlerKey that = (SourceHandlerKey) o;    if (sourceType != null ? !sourceType.equals(that.sourceType) : that.sourceType != null) {        return false;    }    return stellarResult != null ? stellarResult.equals(that.stellarResult) : that.stellarResult == null;}
0
public int hashCode()
{    int result = sourceType != null ? sourceType.hashCode() : 0;    result = 31 * result + (stellarResult != null ? stellarResult.hashCode() : 0);    return result;}
0
public String toString()
{    return "SourceHandlerKey{" + "sourceType='" + sourceType + '\'' + ", stellarResult='" + stellarResult + '\'' + '}';}
0
public void setup()
{    MockitoAnnotations.initMocks(this);    ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);}
0
public void shouldProperlyHandleSuccessAndErrors() throws Exception
{    String messageId1 = "messageId1";    String messageId2 = "messageId2";    String messageId3 = "messageId3";    JSONObject message1 = new JSONObject();    JSONObject message2 = new JSONObject();    JSONObject message3 = new JSONObject();    message1.put("value", "message1");    message2.put("value", "message2");    message3.put("value", "message3");    Tuple tuple3 = mock(Tuple.class);    Throwable e = new Exception("test exception");    MetronError expectedError1 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e).withRawMessages(Collections.singletonList(message1));    MetronError expectedError2 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e).withRawMessages(Collections.singletonList(message2));    BulkWriterResponse response = new BulkWriterResponse();    response.addAllErrors(e, Arrays.asList(new MessageId(messageId1), new MessageId(messageId2)));    response.addSuccess(new MessageId(messageId3));    when(messageGetStrategy.get(tuple1)).thenReturn(message1);    when(messageGetStrategy.get(tuple2)).thenReturn(message2);    ackTuplesPolicy.addTupleMessageIds(tuple1, Collections.singleton(messageId1));    ackTuplesPolicy.addTupleMessageIds(tuple2, Collections.singleton(messageId2));    ackTuplesPolicy.addTupleMessageIds(tuple3, Collections.singleton(messageId3));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    Assert.assertEquals(0, ackTuplesPolicy.getTupleErrorMap().size());    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError1.getJSONObject()))));    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError2.getJSONObject()))));    verify(collector, times(1)).ack(tuple1);    verify(collector, times(1)).ack(tuple2);    verify(collector, times(1)).ack(tuple3);    verify(collector, times(1)).reportError(e);    verifyNoMoreInteractions(collector);}
0
public void shouldOnlyReportErrorsOncePerBatch()
{    AckTuplesPolicy ackTuplesPolicy = new AckTuplesPolicy(collector, messageGetStrategy);    JSONObject rawMessage1 = new JSONObject();    JSONObject rawMessage2 = new JSONObject();    rawMessage1.put("value", "rawMessage1");    rawMessage2.put("value", "rawMessage2");    String messageId1 = "messageId1";    String messageId2 = "messageId2";    String messageId3 = "messageId3";    JSONObject message1 = new JSONObject();    JSONObject message2 = new JSONObject();    JSONObject message3 = new JSONObject();    message1.put("value", "message1");    message2.put("value", "message2");    message3.put("value", "message3");    Throwable e1 = new Exception("test exception 1");    Throwable e2 = new Exception("test exception 2");    MetronError expectedError1 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e1).withRawMessages(Collections.singletonList(rawMessage1));    MetronError expectedError2 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e2).withRawMessages(Collections.singletonList(rawMessage1));    MetronError expectedError3 = new MetronError().withSensorType(Collections.singleton(sensorType)).withErrorType(Constants.ErrorType.INDEXING_ERROR).withThrowable(e1).withRawMessages(Collections.singletonList(rawMessage2));    when(messageGetStrategy.get(tuple1)).thenReturn(rawMessage1);    when(messageGetStrategy.get(tuple2)).thenReturn(rawMessage2);    ackTuplesPolicy.addTupleMessageIds(tuple1, Arrays.asList(messageId1, messageId2));    ackTuplesPolicy.addTupleMessageIds(tuple2, Collections.singletonList(messageId3));    BulkWriterResponse response = new BulkWriterResponse();    response.addError(e1, new MessageId(messageId1));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(2, ackTuplesPolicy.getTupleMessageMap().size());    Assert.assertEquals(1, ackTuplesPolicy.getTupleErrorMap().size());    verify(collector, times(0)).ack(any());    verify(collector, times(0)).reportError(any());    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError1.getJSONObject()))));    response = new BulkWriterResponse();    response.addError(e2, new MessageId(messageId2));    response.addError(e1, new MessageId(messageId3));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    Assert.assertEquals(0, ackTuplesPolicy.getTupleErrorMap().size());    verify(collector, times(1)).ack(tuple1);    verify(collector, times(1)).ack(tuple2);    verify(collector, times(1)).reportError(e1);    verify(collector, times(1)).reportError(e2);    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError2.getJSONObject()))));    verify(collector, times(1)).emit(eq(Constants.ERROR_STREAM), new Values(argThat(new MetronErrorJSONMatcher(expectedError3.getJSONObject()))));    verifyNoMoreInteractions(collector);}
0
public void shouldProperlyAckTuples()
{    ackTuplesPolicy.addTupleMessageIds(tuple1, Collections.singletonList("message1"));    ackTuplesPolicy.addTupleMessageIds(tuple2, Collections.singletonList("message2"));    BulkWriterResponse response = new BulkWriterResponse();    response.addSuccess(new MessageId("message1"));    response.addSuccess(new MessageId("message2"));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    verify(collector, times(1)).ack(tuple1);    verify(collector, times(1)).ack(tuple2);    verifyNoMoreInteractions(collector);}
0
public void shouldOnlyAckTupleAfterHandlingAllMessages()
{    ackTuplesPolicy.addTupleMessageIds(tuple1, Arrays.asList("message1", "message2", "message3"));    BulkWriterResponse response = new BulkWriterResponse();    response.addSuccess(new MessageId("message1"));    response.addSuccess(new MessageId("message2"));    ackTuplesPolicy.onFlush(sensorType, response);    verify(collector, times(0)).ack(any());    response = new BulkWriterResponse();    response.addSuccess(new MessageId("message3"));    ackTuplesPolicy.onFlush(sensorType, response);    Assert.assertEquals(0, ackTuplesPolicy.getTupleMessageMap().size());    verify(collector, times(1)).ack(tuple1);    verifyNoMoreInteractions(collector);}
0
public void testGetMaxBatchTimeout() throws Exception
{            assertEquals(30, Utils.readStormConfig().getOrDefault(Config.TOPOLOGY_MESSAGE_TIMEOUT_SECS, 0));    BatchTimeoutHelper bth;    bth = new BatchTimeoutHelper(defaultConfigList, 1);    assertEquals(14, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 2);    assertEquals(6, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 3);    assertEquals(4, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 4);    assertEquals(2, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 6);    assertEquals(1, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(defaultConfigList, 20);    assertEquals(1, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(disabledConfigList, 2);    assertEquals(6, bth.getMaxBatchTimeout());    bth = new BatchTimeoutHelper(smallTimeoutsList, 2);    assertEquals(6, bth.getMaxBatchTimeout());}
0
public void testGetRecommendedTickInterval() throws Exception
{        BatchTimeoutHelper bth;    bth = new BatchTimeoutHelper(defaultConfigList, 2);    assertEquals(6, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(disabledConfigList, 2);    assertEquals(6, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(largeTimeoutsList, 2);    assertEquals(6, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(smallTimeoutsList, 2);    assertEquals(2, bth.getRecommendedTickInterval());    bth = new BatchTimeoutHelper(illegalTimeoutsList, 2);    assertEquals(2, bth.getRecommendedTickInterval());}
0
public List<Integer> get()
{    return list;}
0
public void parseMessages() throws ParseException
{    JSONParser parser = new JSONParser();    fullMessageList = new ArrayList<>();    sampleMessage = (JSONObject) parser.parse(sampleMessageString);    sampleMessage.put(Constants.GUID, "message1");    sampleMessage.put("field", "value1");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message2");    sampleMessage.put("field", "value2");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message3");    sampleMessage.put("field", "value3");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message4");    sampleMessage.put("field", "value4");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    sampleMessage.put(Constants.GUID, "message5");    sampleMessage.put("field", "value5");    fullMessageList.add(((JSONObject) sampleMessage.clone()));    MockitoAnnotations.initMocks(this);    messageIdList = new ArrayList<>();    tupleList = new ArrayList<>();    messageList = new ArrayList<>();    bulkMessageWriterBolt = spy(new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING").withBulkMessageWriter(bulkMessageWriter).withMessageGetter(MessageGetters.JSON_FROM_FIELD.name()).withMessageGetterField("message"));    for (int i = 0; i < 5; i++) {        String messageId = String.format("message%s", i + 1);        messageIdList.add(new MessageId(messageId));        JSONObject message = fullMessageList.get(i);        Tuple tuple = mock(Tuple.class);        when(tuple.getValueByField("message")).thenReturn(message);        tupleList.add(tuple);        messageList.add(new BulkMessage<>(messageId, message));    }}
0
public void testSourceTypeMissing() throws Exception
{        BulkMessageWriterBolt<IndexingConfigurations> bulkMessageWriterBolt = new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING").withBulkMessageWriter(bulkMessageWriter).withMessageGetter(MessageGetters.JSON_FROM_FIELD.name()).withMessageGetterField("message");    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));        bulkMessageWriterBolt.declareOutputFields(declarer);    Map stormConf = new HashMap();    bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector);        JSONObject message = (JSONObject) new JSONParser().parse(sampleMessageString);    message.remove("source.type");    when(tuple.getValueByField("message")).thenReturn(message);        bulkMessageWriterBolt.execute(tuple);    verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), any());    verify(outputCollector, times(1)).ack(tuple);    verify(outputCollector, times(1)).reportError(any(Throwable.class));    Mockito.verifyNoMoreInteractions(outputCollector);}
0
public void testFlushOnBatchSize() throws Exception
{    Map stormConf = new HashMap();    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));    {        doThrow(new Exception()).when(bulkMessageWriter).init(eq(stormConf), any(WriterConfiguration.class));        try {            bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector);            fail("A runtime exception should be thrown when bulkMessageWriter.init throws an exception");        } catch (RuntimeException e) {        }        reset(bulkMessageWriter);    }    {        when(bulkMessageWriter.getName()).thenReturn("hdfs");        bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector);        verify(bulkMessageWriter, times(1)).init(eq(stormConf), any(WriterConfiguration.class));    }    {        for (int i = 0; i < 4; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));            verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), anyList());        }        BulkWriterResponse response = new BulkWriterResponse();        response.addAllSuccesses(messageIdList);        when(bulkMessageWriter.write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList))).thenReturn(response);        bulkMessageWriterBolt.execute(tupleList.get(4));        verify(bulkMessageWriter, times(1)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));        reset(outputCollector);    }    {        doThrow(new Exception()).when(bulkMessageWriter).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), anyList());        UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.FATAL);        for (int i = 0; i < 5; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));        }        UnitTestHelper.setLog4jLevel(BulkWriterComponent.class, Level.ERROR);        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));        verify(outputCollector, times(5)).emit(eq(Constants.ERROR_STREAM), any(Values.class));        verify(outputCollector, times(1)).reportError(any(Throwable.class));    }    Mockito.verifyNoMoreInteractions(outputCollector);}
0
public void testFlushOnBatchTimeout() throws Exception
{    FakeClock clock = new FakeClock();    bulkMessageWriterBolt = bulkMessageWriterBolt.withBatchTimeoutDivisor(3);    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));    {        bulkMessageWriterBolt.declareOutputFields(declarer);        verify(declarer, times(1)).declareStream(eq("error"), argThat(new FieldsMatcher("message")));    }    {        Map stormConf = new HashMap();        when(bulkMessageWriter.getName()).thenReturn("elasticsearch");        bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector, clock);        verify(bulkMessageWriter, times(1)).init(eq(stormConf), any(WriterConfiguration.class));    }    {        int batchTimeout = bulkMessageWriterBolt.getMaxBatchTimeout();        assertEquals(4, batchTimeout);        for (int i = 0; i < 4; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));            verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), any(List.class));        }        clock.elapseSeconds(5);        BulkWriterResponse response = new BulkWriterResponse();        response.addAllSuccesses(messageIdList);        when(bulkMessageWriter.write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList))).thenReturn(response);        bulkMessageWriterBolt.execute(tupleList.get(4));        verify(bulkMessageWriter, times(1)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));    }    Mockito.verifyNoMoreInteractions(outputCollector);}
0
public void testFlushOnTickTuple() throws Exception
{    FakeClock clock = new FakeClock();    bulkMessageWriterBolt.setCuratorFramework(client);    bulkMessageWriterBolt.setZKCache(cache);    bulkMessageWriterBolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));    {        bulkMessageWriterBolt.declareOutputFields(declarer);        verify(declarer, times(1)).declareStream(eq("error"), argThat(new FieldsMatcher("message")));    }    {        Map stormConf = new HashMap();        when(bulkMessageWriter.getName()).thenReturn("elasticsearch");        bulkMessageWriterBolt.prepare(stormConf, topologyContext, outputCollector, clock);        verify(bulkMessageWriter, times(1)).init(eq(stormConf), any(WriterConfiguration.class));    }    {        int batchTimeout = bulkMessageWriterBolt.getMaxBatchTimeout();        assertEquals(14, batchTimeout);        for (int i = 0; i < 5; i++) {            bulkMessageWriterBolt.execute(tupleList.get(i));            verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), any());        }        Tuple tickTuple = mock(Tuple.class);        when(tickTuple.getValueByField("message")).thenReturn(null);                when(tickTuple.getSourceComponent()).thenReturn("__system");                when(tickTuple.getSourceStreamId()).thenReturn("__tick");        BulkWriterResponse response = new BulkWriterResponse();        response.addAllSuccesses(messageIdList);        when(bulkMessageWriter.write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList))).thenReturn(response);        clock.advanceToSeconds(2);        bulkMessageWriterBolt.execute(tickTuple);        verify(bulkMessageWriter, times(0)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));                verify(outputCollector, times(1)).ack(tickTuple);        clock.advanceToSeconds(9);        bulkMessageWriterBolt.execute(tickTuple);        verify(bulkMessageWriter, times(1)).write(eq(BaseEnrichmentBoltTest.sensorType), any(WriterConfiguration.class), eq(messageList));        assertEquals(5, tupleList.size());        tupleList.forEach(tuple -> verify(outputCollector, times(1)).ack(tuple));        verify(outputCollector, times(2)).ack(tickTuple);    }    Mockito.verifyNoMoreInteractions(outputCollector);}
0
public void testMessageInvalid() throws Exception
{    FakeClock clock = new FakeClock();        BulkMessageWriterBolt<IndexingConfigurations> bolt = new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING").withBulkMessageWriter(bulkMessageWriter).withMessageGetter(MessageGetters.JSON_FROM_POSITION.name()).withMessageGetterField("message");    bolt.setCuratorFramework(client);    bolt.setZKCache(cache);    bolt.getConfigurations().updateSensorIndexingConfig(BaseEnrichmentBoltTest.sensorType, new FileInputStream("../" + BaseEnrichmentBoltTest.sampleSensorIndexingConfigPath));        bolt.declareOutputFields(declarer);    Map stormConf = new HashMap();    bolt.prepare(stormConf, topologyContext, outputCollector, clock);        byte[] invalidJSON = "this is not valid JSON".getBytes(StandardCharsets.UTF_8);    when(tuple.getBinary(0)).thenReturn(invalidJSON);    bolt.execute(tuple);        verify(outputCollector, times(1)).emit(eq(Constants.ERROR_STREAM), any());    verify(outputCollector, times(1)).ack(tuple);    verify(outputCollector, times(1)).reportError(any(Throwable.class));    Mockito.verifyNoMoreInteractions(outputCollector);}
0
public void testDeclareOutputFields()
{    BulkMessageWriterBolt<IndexingConfigurations> bulkMessageWriterBolt = new BulkMessageWriterBolt<IndexingConfigurations>("zookeeperUrl", "INDEXING");    bulkMessageWriterBolt.declareOutputFields(declarer);    verify(declarer, times(1)).declareStream(eq("error"), argThat(new FieldsMatcher("message")));}
0
public void testClonedPolicy()
{    CountSyncPolicy basePolicy = new CountSyncPolicy(5);    ClonedSyncPolicyCreator creator = new ClonedSyncPolicyCreator(basePolicy);        SyncPolicy clonedPolicy = creator.create("blah", null);    for (int i = 0; i < 4; ++i) {        Assert.assertFalse(clonedPolicy.mark(null, i));    }    Assert.assertTrue(clonedPolicy.mark(null, 5));        clonedPolicy = creator.create("blah", null);    Assert.assertFalse(clonedPolicy.mark(null, 0));}
0
public static void beforeAll() throws Exception
{            Thread.interrupted();}
0
public void setup() throws IOException
{        folder = tempFolder.newFolder();    testFormat = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");}
0
public void testGetHdfsPathNull()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, null, message);    writer.close();    Assert.assertEquals(SENSOR_NAME, result);}
0
public void testGetHdfsPathEmptyString()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "", message);    writer.close();    Assert.assertEquals(SENSOR_NAME, result);}
0
public void testGetHdfsPathConstant()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "'new'", message);    writer.close();    Assert.assertEquals("new", result);}
0
public void testGetHdfsPathDirectVariable()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "test.key", message);    writer.close();    Assert.assertEquals("test.value", result);}
0
public void testGetHdfsPathFormatConstant()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('/test/folder/')", message);    writer.close();    Assert.assertEquals("/test/folder/", result);}
0
public void testGetHdfsPathFormatVariable()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key.2", "test.value.2");    message.put("test.key.3", "test.value.3");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s/%s/%s', test.key, test.key.2, test.key.3)", message);    writer.close();    Assert.assertEquals("test.value/test.value.2/test.value.3", result);}
0
public void testSetsCorrectHdfsFilename()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    String filename = writer.fileNameFormat.getName(1, 1);    Assert.assertEquals("prefix-Xcom-7-1-1.json", filename);    writer.close();}
0
public void testGetHdfsPathMultipleFunctions()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key.2", "test.value.2");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s', test.key)", message);    Assert.assertEquals("test.value", result);    result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s/%s', test.key, test.key.2)", message);    Assert.assertEquals("test.value/test.value.2", result);    result = writer.getHdfsPathExtension(SENSOR_NAME, "FORMAT('%s', test.key)", message);    writer.close();    Assert.assertEquals("test.value", result);}
0
public void testGetHdfsPathStringReturned()
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    Object result = writer.getHdfsPathExtension(SENSOR_NAME, "TO_UPPER(FORMAT(MAP_GET('key', {'key': 'AbC%s'}), test.key))", message);    writer.close();    Assert.assertEquals("ABCTEST.VALUE", result);}
0
public void testGetHdfsPathNonString()
{    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, new IndexingConfigurations());    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    writer.getHdfsPathExtension(SENSOR_NAME, "{'key':'value'}", message);    writer.close();}
0
public void testGetSourceHandlerOpenFilesMax() throws IOException
{    int maxFiles = 2;    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat).withMaxOpenFiles(maxFiles);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    for (int i = 0; i < maxFiles; i++) {        writer.getSourceHandler(SENSOR_NAME, Integer.toString(i), null);    }    writer.close();}
0
public void testGetSourceHandlerOpenFilesOverMax() throws IOException
{    int maxFiles = 2;    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat).withMaxOpenFiles(maxFiles);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    for (int i = 0; i < maxFiles + 1; i++) {        writer.getSourceHandler(SENSOR_NAME, Integer.toString(i), null);    }    writer.close();}
0
public void testWriteNoOutputFunction() throws Exception
{    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    IndexingConfigurations indexingConfig = new IndexingConfigurations();    WriterConfiguration config = new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key2", "test.value2");    JSONObject message2 = new JSONObject();    message2.put("test.key", "test.value3");    message2.put("test.key2", "test.value2");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));            add(new BulkMessage("message2", message2));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    expected.add(message2.toJSONString());    Collections.sort(expected);        File outputFolder = new File(folder.getAbsolutePath() + "/" + SENSOR_NAME);    Assert.assertTrue(outputFolder.exists() && outputFolder.isDirectory());    Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected, lines);    }}
0
public void testWriteSingleFile() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());        JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key2", "test.value2");    JSONObject message2 = new JSONObject();    message2.put("test.key", "test.value");    message2.put("test.key3", "test.value2");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage<>("message1", message));            add(new BulkMessage<>("message2", message2));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    expected.add(message2.toJSONString());    Collections.sort(expected);    File outputFolder = new File(folder.getAbsolutePath() + "/test-test.value/test.value/");    Assert.assertTrue(outputFolder.exists() && outputFolder.isDirectory());    Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected, lines);    }}
0
public void testWriteMultipleFiles() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());        JSONObject message = new JSONObject();    message.put("test.key", "test.value");    message.put("test.key2", "test.value2");    JSONObject message2 = new JSONObject();    message2.put("test.key", "test.value2");    message2.put("test.key3", "test.value3");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));            add(new BulkMessage("message2", message2));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected1 = new ArrayList<>();    expected1.add(message.toJSONString());    Collections.sort(expected1);    File outputFolder1 = new File(folder.getAbsolutePath() + "/test-test.value/test.value/");    Assert.assertTrue(outputFolder1.exists() && outputFolder1.isDirectory());    Assert.assertEquals(1, outputFolder1.listFiles().length);    for (File file : outputFolder1.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected1, lines);    }    ArrayList<String> expected2 = new ArrayList<>();    expected2.add(message2.toJSONString());    Collections.sort(expected2);    File outputFolder2 = new File(folder.getAbsolutePath() + "/test-test.value2/test.value2/");    Assert.assertTrue(outputFolder2.exists() && outputFolder2.isDirectory());    Assert.assertEquals(1, outputFolder2.listFiles().length);    for (File file : outputFolder2.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected2, lines);    }}
0
public void testWriteSingleFileWithNull() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    FileNameFormat format = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    HdfsWriter writer = new HdfsWriter().withFileNameFormat(format);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());        JSONObject message = new JSONObject();    message.put("test.key2", "test.value2");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));        }    };    writer.write(SENSOR_NAME, config, messages);    writer.close();    ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    Collections.sort(expected);    File outputFolder = new File(folder.getAbsolutePath() + "/test-null/null/");    Assert.assertTrue(outputFolder.exists() && outputFolder.isDirectory());    Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());        Collections.sort(lines);        Assert.assertEquals(expected, lines);    }}
0
public void testSingleFileIfNoStreamClosed() throws Exception
{    String function = "FORMAT('test-%s/%s', test.key, test.key)";    WriterConfiguration config = buildWriterConfiguration(function);    HdfsWriter writer = new HdfsWriter().withFileNameFormat(testFormat);    writer.init(new HashMap<String, String>(), config);    writer.initFileNameFormat(createTopologyContext());    JSONObject message = new JSONObject();    message.put("test.key", "test.value");    List<BulkMessage<JSONObject>> messages = new ArrayList<BulkMessage<JSONObject>>() {        {            add(new BulkMessage("message1", message));        }    };    CountSyncPolicy basePolicy = new CountSyncPolicy(5);    ClonedSyncPolicyCreator creator = new ClonedSyncPolicyCreator(basePolicy);    writer.write(SENSOR_NAME, config, messages);    writer.write(SENSOR_NAME, config, messages);    writer.close();    File outputFolder = new File(folder.getAbsolutePath() + "/test-test.value/test.value/");        ArrayList<String> expected = new ArrayList<>();    expected.add(message.toJSONString());    expected.add(message.toJSONString());        Assert.assertEquals(1, outputFolder.listFiles().length);    for (File file : outputFolder.listFiles()) {        List<String> lines = Files.readAllLines(file.toPath());                Assert.assertEquals(2, lines.size());        Assert.assertEquals(expected, lines);    }}
0
protected WriterConfiguration buildWriterConfiguration(String function)
{    IndexingConfigurations indexingConfig = new IndexingConfigurations();    Map<String, Object> sensorIndexingConfig = new HashMap<>();    Map<String, Object> writerIndexingConfig = new HashMap<>();    writerIndexingConfig.put(IndexingConfigurations.OUTPUT_PATH_FUNCTION_CONF, function);    sensorIndexingConfig.put(WRITER_NAME, writerIndexingConfig);    indexingConfig.updateSensorIndexingConfig(SENSOR_NAME, sensorIndexingConfig);    return new IndexingWriterConfiguration(WRITER_NAME, indexingConfig);}
0
private TopologyContext createTopologyContext()
{    Map<Integer, String> taskToComponent = new HashMap<Integer, String>();    taskToComponent.put(7, "Xcom");    return new TopologyContext(null, null, taskToComponent, null, null, null, null, null, 7, 6703, null, null, null, null, null, null);}
0
public void testGetPath()
{    FileNameFormat delegate = new DefaultFileNameFormat().withExtension(EXTENSION).withPath(PATH);    FileNameFormat sourceFormat = new PathExtensionFileNameFormat(PATH_EXTENSION, delegate);    String actual = sourceFormat.getPath();    String expected = PATH + "/" + PATH_EXTENSION;    Assert.assertEquals(expected, actual);}
0
public void testGetPathEmptyPathExtension()
{    FileNameFormat delegate = new DefaultFileNameFormat().withExtension(EXTENSION).withPath(PATH);    FileNameFormat sourceFormat = new PathExtensionFileNameFormat("", delegate);    String actual = sourceFormat.getPath();    Assert.assertEquals(PATH + "/", actual);}
0
public void setup() throws IOException
{        folder = tempFolder.newFolder();    testFormat = new DefaultFileNameFormat().withPath(folder.toString()).withExtension(".json").withPrefix("prefix-");    rotActions = new ArrayList<>();    rotActions.add(rotAction1);    rotActions.add(rotAction2);}
0
public void testRotateOutputFile() throws IOException
{    SourceHandler handler = new SourceHandler(rotActions,     new FileSizeRotationPolicy(10000, Units.MB), new CountSyncPolicy(1), testFormat, callback);    handler.rotateOutputFile();        verify(rotAction1).execute(any(), any());    verify(rotAction2).execute(any(), any());    verify(callback).removeKey();}
0
public Builder with(Callback callback, TreeCacheEvent.Type... types)
{    return with(ImmutableList.of(callback), types);}
0
public Builder with(Iterable<? extends Callback> callback, TreeCacheEvent.Type... types)
{    for (TreeCacheEvent.Type t : types) {        List<Callback> cbs = callbacks.get(t);        if (cbs == null) {            cbs = new ArrayList<>();        }        Iterables.addAll(cbs, callback);        callbacks.put(t, cbs);    }    return this;}
0
public SimpleEventListener build()
{    return new SimpleEventListener(callbacks);}
0
public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception
{    String path = null;    byte[] data = null;    if (event != null && event.getData() != null) {        path = event.getData().getPath();        data = event.getData().getData();    }        List<Callback> callback = callbacks.get(event.getType());    if (callback != null) {        for (Callback cb : callback) {            cb.apply(client, path, data);        }    }}
1
public Builder withClient(CuratorFramework client)
{    this.client = Optional.ofNullable(client);    ownClient = false;    return this;}
0
public Builder withClient(String zookeeperUrl)
{    this.client = Optional.ofNullable(createClient(zookeeperUrl, Optional.empty()));    ownClient = true;    return this;}
0
public Builder withClient(String zookeeperUrl, RetryPolicy retryPolicy)
{    this.client = Optional.ofNullable(createClient(zookeeperUrl, Optional.ofNullable(retryPolicy)));    ownClient = true;    return this;}
0
public Builder withListener(TreeCacheListener listener)
{    this.listener.add(listener);    return this;}
0
public Builder withRoot(String zkRoot)
{    this.zkRoot = zkRoot;    return this;}
0
public ZKCache build()
{    if (!client.isPresent()) {        throw new IllegalArgumentException("Zookeeper client must be specified.");    }    if (listener.isEmpty()) {            }    if (zkRoot == null) {        throw new IllegalArgumentException("Zookeeper root must not be null.");    }    return new ZKCache(client.get(), listener, zkRoot, ownClient);}
1
public CuratorFramework getClient()
{    return client;}
0
public void start() throws Exception
{    if (cache == null) {        if (ownClient) {            client.start();        }        TreeCache.Builder builder = TreeCache.newBuilder(client, zkRoot);        builder.setCacheData(true);        cache = builder.build();        for (TreeCacheListener l : listeners) {            cache.getListenable().addListener(l);        }        cache.start();    }}
0
public void close()
{    cache.close();    if (ownClient) {        client.close();    }}
0
public static CuratorFramework createClient(String zookeeperUrl, Optional<RetryPolicy> retryPolicy)
{    return CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy.orElse(new ExponentialBackoffRetry(DEFAULT_CLIENT_SLEEP_MS, DEFAULT_MAX_RETRIES)));}
0
public Object apply(List<Object> list, Context context) throws ParseException
{    return System.currentTimeMillis();}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
 static Cache<String, StellarCompiler.Expression> createCache(int cacheSize, int expiryTime, TimeUnit expiryUnit)
{    CacheLoader<String, StellarCompiler.Expression> loader = key -> compile(key);    return Caffeine.newBuilder().maximumSize(cacheSize).expireAfterAccess(expiryTime, expiryUnit).build(loader);}
0
public Set<String> variablesUsed(final String rule)
{    if (rule == null || isEmpty(rule.trim())) {        return null;    }    StellarCompiler.Expression expression = null;    try {        expression = expressionCache.get(rule, r -> compile(r));    } catch (Throwable e) {        throw new ParseException("Unable to parse: " + rule + " due to: " + e.getMessage(), e);    }    return expression.variablesUsed;}
0
public T parse(final String rule, final VariableResolver variableResolver, final FunctionResolver functionResolver, final Context context)
{    StellarCompiler.Expression expression = null;    if (rule == null || isEmpty(rule.trim())) {        return null;    }    if (context.getActivityType() == null) {        context.setActivityType(ActivityType.PARSE_ACTIVITY);    }    try {        expression = expressionCache.get(rule, r -> compile(r));    } catch (Throwable e) {        throw createException(rule, variableResolver, e);    }    try {        return clazz.cast(expression.apply(new StellarCompiler.ExpressionState(context, functionResolver, variableResolver)));    } catch (Throwable e) {        throw createException(rule, variableResolver, e);    } finally {                context.setActivityType(null);    }}
0
private ParseException createException(String rule, VariableResolver resolver, Throwable t)
{    String message = "Unable to parse: " + rule + " due to: " + t.getMessage();    Set<String> variablesUsed = variablesUsed(rule);    if (variablesUsed.isEmpty()) {        return new ParseException(message, t);    }    List<Map.Entry<String, Object>> messagesUsed = new ArrayList<>(variablesUsed.size());    for (String v : variablesUsed) {        Optional<Object> resolved = Optional.ofNullable(resolver.resolve(v));        messagesUsed.add(new AbstractMap.SimpleEntry<>(v, resolved.orElse("missing")));    }    return new ParseException(message + " with relevant variables " + Joiner.on(",").join(messagesUsed), t);}
0
public static StellarCompiler.Expression compile(final String rule)
{    if (rule == null || isEmpty(rule.trim())) {        return null;    }    ANTLRInputStream input = new ANTLRInputStream(rule);    StellarLexer lexer = new StellarLexer(input);    lexer.removeErrorListeners();    lexer.addErrorListener(new ErrorListener());    TokenStream tokens = new CommonTokenStream(lexer);    StellarParser parser = new StellarParser(tokens);    StellarCompiler treeBuilder = new StellarCompiler(ArithmeticEvaluator.INSTANCE, NumberLiteralEvaluator.INSTANCE, ComparisonExpressionWithOperatorEvaluator.INSTANCE);    parser.addParseListener(treeBuilder);    parser.removeErrorListeners();    parser.addErrorListener(new ErrorListener());    parser.transformation();    return treeBuilder.getExpression();}
0
public boolean validate(final String rule) throws ParseException
{    return validate(rule, true, Context.EMPTY_CONTEXT());}
0
public boolean validate(final String rule, final Context context) throws ParseException
{    return validate(rule, true, context);}
0
public boolean validate(final String rule, final boolean throwException, final Context context) throws ParseException
{    if (rule == null || isEmpty(rule.trim())) {        return true;    }            context.setActivityType(ActivityType.VALIDATION_ACTIVITY);    try {        parse(rule, DefaultVariableResolver.NULL_RESOLVER(), StellarFunctions.FUNCTION_RESOLVER(), context);    } catch (Throwable t) {        if (throwException) {            throw new ParseException("Unable to parse " + rule + ": " + t.getMessage(), t);        } else {            return false;        }    }    return true;}
0
public static DescriptiveStatistics run(StellarStatement statement, int warmupRounds, int benchmarkRounds)
{    run(warmupRounds, statement, ts -> {    });    final DescriptiveStatistics stats = new DescriptiveStatistics();    run(benchmarkRounds, statement, ts -> {        stats.addValue(ts);    });    return stats;}
0
private static void run(int numTimes, StellarStatement statement, Consumer<Long> func)
{    StellarProcessor processor = new StellarProcessor();    for (int i = 0; i < numTimes; ++i) {        long start = System.nanoTime();        processor.parse(statement.expression, statement.variableResolver, statement.functionResolver, statement.context);        func.accept((System.nanoTime() - start) / 1000);    }}
0
public static String describe(DescriptiveStatistics stats, Double[] percentiles)
{    StringBuilder sb = new StringBuilder();    sb.append(String.format("round: mean of %dms [+-%d], measured %d rounds;\n", (long) stats.getMean(), (long) stats.getStandardDeviation(), stats.getN()));    sb.append("\tMin - " + (long) stats.getMin() + "\n");    for (double pctile : percentiles) {        sb.append("\t" + pctile + " - " + stats.getPercentile(pctile) + "\n");    }    sb.append("\tMax - " + (long) stats.getMax());    return sb.toString();}
0
public boolean has(CommandLine cli)
{    return cli.hasOption(shortCode);}
0
public String get(CommandLine cli)
{    return cli.getOptionValue(shortCode);}
0
public static CommandLine parse(CommandLineParser parser, String[] args)
{    try {        CommandLine cli = parser.parse(getOptions(), args);        if (HELP.has(cli)) {            printHelp();            System.exit(0);        }        return cli;    } catch (org.apache.commons.cli.ParseException e) {        System.err.println("Unable to parse args: " + Joiner.on(' ').join(args));        e.printStackTrace(System.err);        printHelp();        System.exit(-1);        return null;    }}
0
public static EnumMap<BenchmarkOptions, Optional<Object>> createConfig(CommandLine cli)
{    EnumMap<BenchmarkOptions, Optional<Object>> ret = new EnumMap<>(BenchmarkOptions.class);    for (BenchmarkOptions option : values()) {        ret.put(option, option.handler.getValue(option, cli));    }    return ret;}
0
public static void printHelp()
{    HelpFormatter formatter = new HelpFormatter();    formatter.printHelp("StellarBenchmark", getOptions());}
0
public static Options getOptions()
{    Options ret = new Options();    for (BenchmarkOptions o : BenchmarkOptions.values()) {        ret.addOption(o.option);    }    return ret;}
0
public Option apply(@Nullable String s)
{    return new Option(s, "help", false, "Generate Help screen");}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "warmup", true, "Number of times for warmup per expression. Default: " + DEFAULT_WARMUP);    o.setArgName("NUM");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "percentiles", true, "Percentiles to calculate per run. Default: " + Joiner.on(",").join(Arrays.asList(DEFAULT_PERCENTILES)));    o.setArgName("NUM");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "num_times", true, "Number of times to run per expression (after warmup). Default: " + DEFAULT_NUM_TIMES);    o.setArgName("NUM");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "expressions", true, "Stellar expressions");    o.setArgName("FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "variables", true, "File containing a JSON Map of variables to use");    o.setArgName("FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public Option apply(@Nullable String s)
{    Option o = new Option(s, "output", true, "File to write output.");    o.setArgName("FILE");    o.setRequired(false);    return o;}
0
public Optional<Object> getValue(BenchmarkOptions option, CommandLine cli)
{    return Optional.ofNullable(option.get(cli).trim());}
0
public static void main(String... argv) throws IOException
{    CommandLine cli = BenchmarkOptions.parse(new PosixParser(), argv);    if (!BenchmarkOptions.EXPRESSIONS.has(cli)) {        throw new IllegalStateException("You must at least specify an expressions file.");    }    File expressionsFile = new File(BenchmarkOptions.EXPRESSIONS.get(cli));    Optional<File> variablesFile = Optional.ofNullable(!BenchmarkOptions.VARIABLES.has(cli) ? null : new File(BenchmarkOptions.VARIABLES.get(cli)));    Optional<File> output = Optional.ofNullable(!BenchmarkOptions.OUTPUT.has(cli) ? null : new File(BenchmarkOptions.OUTPUT.get(cli)));    List<String> lines = Files.readLines(expressionsFile, Charset.defaultCharset());    Map<String, Object> variables = new HashMap<>();    if (variablesFile.isPresent()) {        variables = JSONUtils.INSTANCE.load(new FileInputStream(variablesFile.get()), JSONUtils.MAP_SUPPLIER);    }    int numTimes = DEFAULT_NUM_TIMES;    if (BenchmarkOptions.NUM_TIMES.has(cli)) {        numTimes = Integer.parseInt(BenchmarkOptions.NUM_TIMES.get(cli));    }    int warmup = DEFAULT_WARMUP;    if (BenchmarkOptions.WARMUP.has(cli)) {        warmup = Integer.parseInt(BenchmarkOptions.WARMUP.get(cli));    }    Double[] percentiles = DEFAULT_PERCENTILES;    if (BenchmarkOptions.PERCENTILES.has(cli)) {        List<Double> percentileList = new ArrayList<>();        for (String token : Splitter.on(",").split(BenchmarkOptions.PERCENTILES.get(cli))) {            if (token.trim().isEmpty()) {                continue;            }            Double d = Double.parseDouble(token.trim());            percentileList.add(d);        }        percentiles = (Double[]) percentileList.toArray();    }    PrintWriter out = new PrintWriter(new BufferedWriter(new OutputStreamWriter(System.out, StandardCharsets.UTF_8)));    if (output.isPresent()) {        out = new PrintWriter(output.get(), StandardCharsets.UTF_8.name());    }    for (String statement : lines) {        if (statement.trim().startsWith("#") || statement.trim().isEmpty()) {            continue;        }        Microbenchmark.StellarStatement s = new Microbenchmark.StellarStatement();        s.context = Context.EMPTY_CONTEXT();        s.expression = statement;        s.functionResolver = StellarFunctions.FUNCTION_RESOLVER();        s.variableResolver = new MapVariableResolver(variables);        DescriptiveStatistics stats = Microbenchmark.run(s, warmup, numTimes);        out.println("Expression: " + statement);        out.println(Microbenchmark.describe(stats, percentiles));    }    if (argv.length > 2) {        out.close();    }}
0
public String getExpression()
{    return expression;}
0
public Map<String, Object> getInput()
{    return input;}
0
public boolean equals(Object o)
{    if (this == o) {        return true;    }    if (o == null || getClass() != o.getClass()) {        return false;    }    Key key = (Key) o;    return new EqualsBuilder().append(expression, key.expression).append(input, key.input).isEquals();}
0
public int hashCode()
{    return new HashCodeBuilder(17, 37).append(expression).append(input).toHashCode();}
0
public String toString()
{    return new ToStringBuilder(this).append("expression", expression).append("input", input).toString();}
0
public Object parse(String expression, VariableResolver variableResolver, FunctionResolver functionResolver, Context context)
{    Optional<Object> cacheOpt = context.getCapability(Context.Capabilities.CACHE, false);    if (cacheOpt.isPresent()) {                Cache<Key, Object> cache = (Cache<Key, Object>) cacheOpt.get();        Key k = toKey(expression, variableResolver);        return cache.get(k, x -> parseUncached(x.expression, variableResolver, functionResolver, context));    } else {                return parseUncached(expression, variableResolver, functionResolver, context);    }}
1
private static T getParam(Map<String, Object> config, String key, T defaultVal, Class<T> clazz)
{    Object o = config.get(key);    if (o == null) {        return defaultVal;    }    T ret = ConversionUtils.convert(o, clazz);    return ret == null ? defaultVal : ret;}
0
public static CuratorFramework getClient(String zookeeperUrl)
{    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);    return CuratorFrameworkFactory.newClient(zookeeperUrl, retryPolicy);}
0
public static void writeGlobalConfigToZookeeper(Map<String, Object> globalConfig, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeGlobalConfigToZookeeper(globalConfig, client);    }}
0
public static void writeGlobalConfigToZookeeper(Map<String, Object> globalConfig, CuratorFramework client) throws Exception
{    writeGlobalConfigToZookeeper(JSONUtils.INSTANCE.toJSON(globalConfig), client);}
0
public static void writeGlobalConfigToZookeeper(byte[] globalConfig, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeGlobalConfigToZookeeper(globalConfig, client);    }}
0
public static void writeGlobalConfigToZookeeper(byte[] globalConfig, CuratorFramework client) throws Exception
{    GLOBAL.deserialize(new String(globalConfig, StandardCharsets.UTF_8));    writeToZookeeper(GLOBAL.getZookeeperRoot(), globalConfig, client);}
0
public static void writeConfigToZookeeper(String name, Map<String, Object> config, String zookeeperUrl) throws Exception
{    writeConfigToZookeeper(name, JSONUtils.INSTANCE.toJSON(config), zookeeperUrl);}
0
public static void writeConfigToZookeeper(String name, byte[] config, String zookeeperUrl) throws Exception
{    try (CuratorFramework client = getClient(zookeeperUrl)) {        client.start();        writeToZookeeper(Constants.ZOOKEEPER_TOPOLOGY_ROOT + "/" + name, config, client);    }}
0
public static void writeToZookeeper(String path, byte[] configData, CuratorFramework client) throws Exception
{    try {        client.setData().forPath(path, configData);    } catch (KeeperException.NoNodeException e) {        client.create().creatingParentsIfNeeded().forPath(path, configData);    }}
0
public static byte[] readGlobalConfigBytesFromZookeeper(CuratorFramework client) throws Exception
{    return readFromZookeeper(GLOBAL.getZookeeperRoot(), client);}
0
public static byte[] readConfigBytesFromZookeeper(String name, CuratorFramework client) throws Exception
{    return readFromZookeeper(Constants.ZOOKEEPER_TOPOLOGY_ROOT + "/" + name, client);}
0
public static byte[] readFromZookeeper(String path, CuratorFramework client) throws Exception
{    if (client != null && client.getData() != null && path != null) {        return client.getData().forPath(path);    }    return new byte[] {};}
0
public static void setupStellarStatically(CuratorFramework client) throws Exception
{    byte[] ret = null;    try {        ret = readGlobalConfigBytesFromZookeeper(client);    } catch (KeeperException.NoNodeException nne) {        }    if (ret == null || ret.length == 0) {        setupStellarStatically(client, Optional.empty());    } else {        setupStellarStatically(client, Optional.of(new String(ret, StandardCharsets.UTF_8)));    }}
0
public static void setupStellarStatically(CuratorFramework client, Optional<String> globalConfig)
{    /*      In order to validate stellar functions, the function resolver must be initialized.  Otherwise,      those utilities that require validation cannot validate the stellar expressions necessarily.    */    Context.Builder builder = new Context.Builder().with(Context.Capabilities.ZOOKEEPER_CLIENT, () -> client);    if (globalConfig.isPresent()) {        builder = builder.with(Context.Capabilities.GLOBAL_CONFIG, () -> GLOBAL.deserialize(globalConfig.get())).with(Context.Capabilities.STELLAR_CONFIG, () -> GLOBAL.deserialize(globalConfig.get()));    } else {        builder = builder.with(Context.Capabilities.STELLAR_CONFIG, () -> new HashMap<>());    }    Context stellarContext = builder.build();    StellarFunctions.FUNCTION_RESOLVER().initialize(stellarContext);}
0
public static byte[] readGlobalConfigFromFile(String rootPath) throws IOException
{    byte[] globalConfig = new byte[0];    File configPath = new File(rootPath, GLOBAL.getName() + ".json");    if (configPath.exists()) {        globalConfig = Files.readAllBytes(configPath.toPath());    }    return globalConfig;}
0
public static void visitConfigs(CuratorFramework client, final ConfigurationVisitor callback) throws Exception
{    visitConfigs(client, (type, name, data) -> {        setupStellarStatically(client, Optional.ofNullable(data));        callback.visit(type, name, data);    }, GLOBAL);}
0
public static void visitConfigs(CuratorFramework client, ConfigurationVisitor callback, ConfigurationType configType) throws Exception
{    if (client.checkExists().forPath(configType.getZookeeperRoot()) != null) {        if (configType.equals(GLOBAL)) {            byte[] globalConfigData = client.getData().forPath(configType.getZookeeperRoot());            callback.visit(configType, "global", new String(globalConfigData, StandardCharsets.UTF_8));        }    }}
0
public static void dumpConfigs(PrintStream out, CuratorFramework client) throws Exception
{    ConfigurationsUtils.visitConfigs(client, (type, name, data) -> {        type.deserialize(data);        out.println(type + " Config: " + name + "\n" + data);    });}
0
public String getName()
{    return name;}
0
public String getDirectory()
{    return directory;}
0
public Object deserialize(String s)
{    return deserializer.apply(s);}
0
public Object apply(String s)
{    return deserialize(s);}
0
public String getZookeeperRoot()
{    return zookeeperRoot;}
0
public String getName()
{    return name;}
0
public static Fields fromString(String fieldName)
{    return nameToField.get(fieldName);}
0
public String getName()
{    return name;}
0
public String getType()
{    return type;}
0
public Map<String, Object> getState()
{    return ImmutableMap.copyOf(state);}
0
public void assign(String variable, String expression, Map<String, Object> transientState)
{    Object result = execute(expression, transientState);    if (result == null || variable == null) {        return;    }    state.put(variable, result);}
0
public void assign(String variable, Object value)
{    if (value == null || variable == null) {        return;    }    state.put(variable, value);}
0
public T execute(String expression, Map<String, Object> state, Class<T> clazz)
{    Object resultObject = execute(expression, state);        T result = ConversionUtils.convert(resultObject, clazz);    if (result == null) {        throw new IllegalArgumentException(String.format("Unexpected type: expected=%s, actual=%s, expression=%s", clazz.getSimpleName(), ClassUtils.getShortClassName(resultObject, "null"), expression));    }    return result;}
0
public void clearState()
{    this.state = new HashMap<>();}
0
public void setContext(Context context)
{    this.context = context;}
0
public void setFunctionResolver(FunctionResolver functionResolver)
{    this.functionResolver = functionResolver;}
0
private Object execute(String expression, Map<String, Object> transientState)
{    VariableResolver variableResolver = new MapVariableResolver(state, transientState);    StellarProcessor processor = new StellarProcessor();    return processor.parse(expression, variableResolver, functionResolver, context);}
0
public boolean is(String possible)
{    return is.test(possible);}
0
public String decode(String encoded)
{    return decode(encoded, false);}
0
public String decode(String encoded, boolean verify)
{    if (verify) {        if (is.test(encoded)) {            return decode.apply(encoded);        } else {            return encoded;        }    }    return decode.apply(encoded);}
0
public String encode(String toEncode)
{    return encode.apply(toEncode);}
0
public Token<? extends Number> evaluate(BiFunction<Number, Number, Token<? extends Number>> function, Pair<Token<? extends Number>, Token<? extends Number>> p)
{    if (p == null || p.getKey() == null || p.getValue() == null) {        throw new IllegalArgumentException();    }    final Number l = p.getKey().getValue();    final Number r = p.getValue().getValue();    return function.apply(l == null ? 0 : l, r == null ? 0 : r);}
0
public static BiFunction<Number, Number, Token<? extends Number>> addition(final FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() + r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() + r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() + r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() + r.intValue(), Integer.class, context);        }    };}
0
public static BiFunction<Number, Number, Token<? extends Number>> multiplication(final FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() * r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() * r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() * r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() * r.intValue(), Integer.class, context);        }    };}
0
public static BiFunction<Number, Number, Token<? extends Number>> subtraction(final FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() - r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() - r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() - r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() - r.intValue(), Integer.class, context);        }    };}
0
public static BiFunction<Number, Number, Token<? extends Number>> division(FrameContext.Context context)
{    return (Number l, Number r) -> {        if (l instanceof Double || r instanceof Double) {            return new Token<>(l.doubleValue() / r.doubleValue(), Double.class, context);        } else if (l instanceof Float || r instanceof Float) {            return new Token<>(l.floatValue() / r.floatValue(), Float.class, context);        } else if (l instanceof Long || r instanceof Long) {            return new Token<>(l.longValue() / r.longValue(), Long.class, context);        } else {            return new Token<>(l.intValue() / r.intValue(), Integer.class, context);        }    };}
0
public ComparisonExpressionEvaluator evaluator()
{    return evaluator;}
0
public Token<Boolean> evaluate(final Token<?> left, final Token<?> right, final StellarParser.ComparisonOpContext op, FrameContext.Context context)
{    if (op.EQ() != null) {        return new Token<>(Strategy.EQUALITY_OPERATORS.evaluator().evaluate(left, right, op), Boolean.class, context);    } else if (op.NEQ() != null) {        return new Token<>(!Strategy.EQUALITY_OPERATORS.evaluator().evaluate(left, right, op), Boolean.class, context);    } else if (op.LT() != null || op.GT() != null || op.LTE() != null || op.GTE() != null) {        return new Token<>(Strategy.COMPARISON_OPERATORS.evaluator().evaluate(left, right, op), Boolean.class, context);    }    throw new ParseException("Unsupported operations. The following expression is invalid: " + left.getValue() + op.getText() + right.getValue());}
0
public boolean evaluate(final Token<?> left, final Token<?> right, final StellarParser.ComparisonOpContext op)
{    if (left.getValue() == null || right.getValue() == null) {        return false;    } else if (left.getValue() instanceof Number && right.getValue() instanceof Number) {        return compareNumbers((Number) left.getValue(), (Number) right.getValue(), op);    } else if (left.getValue().getClass() == right.getValue().getClass() && left.getValue() instanceof Comparable && right.getValue() instanceof Comparable) {        return compare((Comparable<?>) left.getValue(), (Comparable<?>) right.getValue(), op);    }    throw new ParseException("Unsupported operations. The following expression is invalid: " + left.getValue() + op + right.getValue());}
0
private boolean compare(final T l, final T r, final StellarParser.ComparisonOpContext op)
{    int compareTo = l.compareTo(r);    if (op.LT() != null) {        return compareTo < 0;    } else if (op.LTE() != null) {        return compareTo <= 0;    } else if (op.GT() != null) {        return compareTo > 0;    } else if (op.GTE() != null) {        return compareTo >= 0;    }    throw new ParseException("Unsupported operator: " + op);}
0
private boolean compareNumbers(final Number l, final Number r, final StellarParser.ComparisonOpContext op)
{    if (op.LT() != null) {        return lessThan(l, r);    } else if (op.LTE() != null) {        return lessThanEqual(l, r);    } else if (op.GT() != null) {        return greaterThan(l, r);    } else if (op.GTE() != null) {        return greaterThanEqual(l, r);    }    throw new ParseException("Unsupported operator: " + op);}
0
private boolean lessThan(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() < r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() < r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() < r.longValue();    } else {        return l.intValue() < r.intValue();    }}
0
private boolean lessThanEqual(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() <= r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() <= r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() <= r.longValue();    } else {        return l.intValue() <= r.intValue();    }}
0
private boolean greaterThan(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() > r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() > r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() > r.longValue();    } else {        return l.intValue() > r.intValue();    }}
0
private boolean greaterThanEqual(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() >= r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() >= r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() >= r.longValue();    } else {        return l.intValue() >= r.intValue();    }}
0
public Token<Double> evaluate(StellarParser.DoubleLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    return new Token<>(Double.parseDouble(context.getText()), Double.class, contextVariety);}
0
public boolean evaluate(final Token<?> left, final Token<?> right, final StellarParser.ComparisonOpContext op)
{    if (left.getValue() == null || right.getValue() == null) {        return left.getValue() == right.getValue();    } else if (left.getValue() instanceof Number && right.getValue() instanceof Number) {        return eq((Number) left.getValue(), (Number) right.getValue());    } else {        return left.getValue().equals(right.getValue());    }}
0
private boolean eq(final Number l, final Number r)
{    if (l instanceof Double || r instanceof Double) {        return l.doubleValue() == r.doubleValue();    } else if (l instanceof Float || r instanceof Float) {        return l.floatValue() == r.floatValue();    } else if (l instanceof Long || r instanceof Long) {        return l.longValue() == r.longValue();    } else {        return l.intValue() == r.intValue();    }}
0
public Token<Float> evaluate(StellarParser.FloatLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    return new Token<>(Float.parseFloat(context.getText()), Float.class, contextVariety);}
0
public Token<Integer> evaluate(StellarParser.IntLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    return new Token<>(Integer.parseInt(context.getText()), Integer.class, contextVariety);}
0
public Token<Long> evaluate(StellarParser.LongLiteralContext context, FrameContext.Context contextVariety)
{    if (context == null) {        throw new IllegalArgumentException("Cannot evaluate a context that is null.");    }    String value = context.getText();    if (value.endsWith("l") || value.endsWith("L")) {                value = value.substring(0, value.length() - 1);        return new Token<>(Long.parseLong(value), Long.class, contextVariety);    } else {                throw new ParseException("Invalid format for long. Failed trying to parse a long with the following value: " + value);    }}
0
 Token<? extends Number> evaluate(StellarParser.Arithmetic_operandsContext context, Map<Class<? extends StellarParser.Arithmetic_operandsContext>, NumberEvaluator> instanceMap, FrameContext.Context contextVariety)
{    NumberEvaluator evaluator = instanceMap.get(context.getClass());    if (evaluator == null) {        throw new ParseException("Does not support evaluation for type " + context.getClass());    }    return evaluator.evaluate(context, contextVariety);}
0
public Token<? extends Number> evaluate(StellarParser.Arithmetic_operandsContext context, FrameContext.Context contextVariety)
{    return evaluate(context, Strategy.strategyMap, contextVariety);}
0
public FrameContext getVariety()
{    return variety;}
0
public String toString()
{    return "Context{" + "variety=" + variety + '}';}
0
public Context create()
{    return new Context(this);}
0
public void enterTransformation(StellarParser.TransformationContext ctx)
{}
0
public void exitTransformation(StellarParser.TransformationContext ctx)
{}
0
public void enterConditionalExpr(StellarParser.ConditionalExprContext ctx)
{}
0
public void exitConditionalExpr(StellarParser.ConditionalExprContext ctx)
{}
0
public void enterTransformationExpr(StellarParser.TransformationExprContext ctx)
{}
0
public void exitTransformationExpr(StellarParser.TransformationExprContext ctx)
{}
0
public void enterArithExpression(StellarParser.ArithExpressionContext ctx)
{}
0
public void exitArithExpression(StellarParser.ArithExpressionContext ctx)
{}
0
public void enterTransformationEntity(StellarParser.TransformationEntityContext ctx)
{}
0
public void exitTransformationEntity(StellarParser.TransformationEntityContext ctx)
{}
0
public void enterComparisonExpression(StellarParser.ComparisonExpressionContext ctx)
{}
0
public void exitComparisonExpression(StellarParser.ComparisonExpressionContext ctx)
{}
0
public void enterLogicalExpression(StellarParser.LogicalExpressionContext ctx)
{}
0
public void exitLogicalExpression(StellarParser.LogicalExpressionContext ctx)
{}
0
public void enterInExpression(StellarParser.InExpressionContext ctx)
{}
0
public void exitInExpression(StellarParser.InExpressionContext ctx)
{}
0
public void enterMatchExpr(StellarParser.MatchExprContext ctx)
{}
0
public void exitMatchExpr(StellarParser.MatchExprContext ctx)
{}
0
public void enterIf_expr(StellarParser.If_exprContext ctx)
{}
0
public void exitIf_expr(StellarParser.If_exprContext ctx)
{}
0
public void enterThen_expr(StellarParser.Then_exprContext ctx)
{}
0
public void exitThen_expr(StellarParser.Then_exprContext ctx)
{}
0
public void enterElse_expr(StellarParser.Else_exprContext ctx)
{}
0
public void exitElse_expr(StellarParser.Else_exprContext ctx)
{}
0
public void enterTernaryFuncWithoutIf(StellarParser.TernaryFuncWithoutIfContext ctx)
{}
0
public void exitTernaryFuncWithoutIf(StellarParser.TernaryFuncWithoutIfContext ctx)
{}
0
public void enterTernaryFuncWithIf(StellarParser.TernaryFuncWithIfContext ctx)
{}
0
public void exitTernaryFuncWithIf(StellarParser.TernaryFuncWithIfContext ctx)
{}
0
public void enterLogicalExpressionAnd(StellarParser.LogicalExpressionAndContext ctx)
{}
0
public void exitLogicalExpressionAnd(StellarParser.LogicalExpressionAndContext ctx)
{}
0
public void enterLogicalExpressionOr(StellarParser.LogicalExpressionOrContext ctx)
{}
0
public void exitLogicalExpressionOr(StellarParser.LogicalExpressionOrContext ctx)
{}
0
public void enterBoleanExpression(StellarParser.BoleanExpressionContext ctx)
{}
0
public void exitBoleanExpression(StellarParser.BoleanExpressionContext ctx)
{}
0
public void enterB_expr(StellarParser.B_exprContext ctx)
{}
0
public void exitB_expr(StellarParser.B_exprContext ctx)
{}
0
public void enterInExpressionStatement(StellarParser.InExpressionStatementContext ctx)
{}
0
public void exitInExpressionStatement(StellarParser.InExpressionStatementContext ctx)
{}
0
public void enterNInExpressionStatement(StellarParser.NInExpressionStatementContext ctx)
{}
0
public void exitNInExpressionStatement(StellarParser.NInExpressionStatementContext ctx)
{}
0
public void enterNotFunc(StellarParser.NotFuncContext ctx)
{}
0
public void exitNotFunc(StellarParser.NotFuncContext ctx)
{}
0
public void enterComparisonExpressionParens(StellarParser.ComparisonExpressionParensContext ctx)
{}
0
public void exitComparisonExpressionParens(StellarParser.ComparisonExpressionParensContext ctx)
{}
0
public void enterComparisonExpressionWithOperator(StellarParser.ComparisonExpressionWithOperatorContext ctx)
{}
0
public void exitComparisonExpressionWithOperator(StellarParser.ComparisonExpressionWithOperatorContext ctx)
{}
0
public void enterOperand(StellarParser.OperandContext ctx)
{}
0
public void exitOperand(StellarParser.OperandContext ctx)
{}
0
public void enterTransformation_entity(StellarParser.Transformation_entityContext ctx)
{}
0
public void exitTransformation_entity(StellarParser.Transformation_entityContext ctx)
{}
0
public void enterComparisonOp(StellarParser.ComparisonOpContext ctx)
{}
0
public void exitComparisonOp(StellarParser.ComparisonOpContext ctx)
{}
0
public void enterFunc_args(StellarParser.Func_argsContext ctx)
{}
0
public void exitFunc_args(StellarParser.Func_argsContext ctx)
{}
0
public void enterOp_list(StellarParser.Op_listContext ctx)
{}
0
public void exitOp_list(StellarParser.Op_listContext ctx)
{}
0
public void enterList_entity(StellarParser.List_entityContext ctx)
{}
0
public void exitList_entity(StellarParser.List_entityContext ctx)
{}
0
public void enterKv_list(StellarParser.Kv_listContext ctx)
{}
0
public void exitKv_list(StellarParser.Kv_listContext ctx)
{}
0
public void enterMap_entity(StellarParser.Map_entityContext ctx)
{}
0
public void exitMap_entity(StellarParser.Map_entityContext ctx)
{}
0
public void enterArithExpr_solo(StellarParser.ArithExpr_soloContext ctx)
{}
0
public void exitArithExpr_solo(StellarParser.ArithExpr_soloContext ctx)
{}
0
public void enterArithExpr_minus(StellarParser.ArithExpr_minusContext ctx)
{}
0
public void exitArithExpr_minus(StellarParser.ArithExpr_minusContext ctx)
{}
0
public void enterArithExpr_plus(StellarParser.ArithExpr_plusContext ctx)
{}
0
public void exitArithExpr_plus(StellarParser.ArithExpr_plusContext ctx)
{}
0
public void enterArithExpr_div(StellarParser.ArithExpr_divContext ctx)
{}
0
public void exitArithExpr_div(StellarParser.ArithExpr_divContext ctx)
{}
0
public void enterArithExpr_mul_solo(StellarParser.ArithExpr_mul_soloContext ctx)
{}
0
public void exitArithExpr_mul_solo(StellarParser.ArithExpr_mul_soloContext ctx)
{}
0
public void enterArithExpr_mul(StellarParser.ArithExpr_mulContext ctx)
{}
0
public void exitArithExpr_mul(StellarParser.ArithExpr_mulContext ctx)
{}
0
public void enterTransformationFunc(StellarParser.TransformationFuncContext ctx)
{}
0
public void exitTransformationFunc(StellarParser.TransformationFuncContext ctx)
{}
0
public void enterNumericFunctions(StellarParser.NumericFunctionsContext ctx)
{}
0
public void exitNumericFunctions(StellarParser.NumericFunctionsContext ctx)
{}
0
public void enterDoubleLiteral(StellarParser.DoubleLiteralContext ctx)
{}
0
public void exitDoubleLiteral(StellarParser.DoubleLiteralContext ctx)
{}
0
public void enterIntLiteral(StellarParser.IntLiteralContext ctx)
{}
0
public void exitIntLiteral(StellarParser.IntLiteralContext ctx)
{}
0
public void enterLongLiteral(StellarParser.LongLiteralContext ctx)
{}
0
public void exitLongLiteral(StellarParser.LongLiteralContext ctx)
{}
0
public void enterFloatLiteral(StellarParser.FloatLiteralContext ctx)
{}
0
public void exitFloatLiteral(StellarParser.FloatLiteralContext ctx)
{}
0
public void enterVariable(StellarParser.VariableContext ctx)
{}
0
public void exitVariable(StellarParser.VariableContext ctx)
{}
0
public void enterNaNArith(StellarParser.NaNArithContext ctx)
{}
0
public void exitNaNArith(StellarParser.NaNArithContext ctx)
{}
0
public void enterParenArith(StellarParser.ParenArithContext ctx)
{}
0
public void exitParenArith(StellarParser.ParenArithContext ctx)
{}
0
public void enterCondExpr(StellarParser.CondExprContext ctx)
{}
0
public void exitCondExpr(StellarParser.CondExprContext ctx)
{}
0
public void enterLogicalConst(StellarParser.LogicalConstContext ctx)
{}
0
public void exitLogicalConst(StellarParser.LogicalConstContext ctx)
{}
0
public void enterLambdaWithArgsExpr(StellarParser.LambdaWithArgsExprContext ctx)
{}
0
public void exitLambdaWithArgsExpr(StellarParser.LambdaWithArgsExprContext ctx)
{}
0
public void enterLambdaWithoutArgsExpr(StellarParser.LambdaWithoutArgsExprContext ctx)
{}
0
public void exitLambdaWithoutArgsExpr(StellarParser.LambdaWithoutArgsExprContext ctx)
{}
0
public void enterArithmeticOperands(StellarParser.ArithmeticOperandsContext ctx)
{}
0
public void exitArithmeticOperands(StellarParser.ArithmeticOperandsContext ctx)
{}
0
public void enterStringLiteral(StellarParser.StringLiteralContext ctx)
{}
0
public void exitStringLiteral(StellarParser.StringLiteralContext ctx)
{}
0
public void enterList(StellarParser.ListContext ctx)
{}
0
public void exitList(StellarParser.ListContext ctx)
{}
0
public void enterMapConst(StellarParser.MapConstContext ctx)
{}
0
public void exitMapConst(StellarParser.MapConstContext ctx)
{}
0
public void enterNullConst(StellarParser.NullConstContext ctx)
{}
0
public void exitNullConst(StellarParser.NullConstContext ctx)
{}
0
public void enterExistsFunc(StellarParser.ExistsFuncContext ctx)
{}
0
public void exitExistsFunc(StellarParser.ExistsFuncContext ctx)
{}
0
public void enterCondExpr_paren(StellarParser.CondExpr_parenContext ctx)
{}
0
public void exitCondExpr_paren(StellarParser.CondExpr_parenContext ctx)
{}
0
public void enterFunc(StellarParser.FuncContext ctx)
{}
0
public void exitFunc(StellarParser.FuncContext ctx)
{}
0
public void enterDefault(StellarParser.DefaultContext ctx)
{}
0
public void exitDefault(StellarParser.DefaultContext ctx)
{}
0
public void enterLambda_without_args(StellarParser.Lambda_without_argsContext ctx)
{}
0
public void exitLambda_without_args(StellarParser.Lambda_without_argsContext ctx)
{}
0
public void enterLambda_with_args(StellarParser.Lambda_with_argsContext ctx)
{}
0
public void exitLambda_with_args(StellarParser.Lambda_with_argsContext ctx)
{}
0
public void enterLambda_variables(StellarParser.Lambda_variablesContext ctx)
{}
0
public void exitLambda_variables(StellarParser.Lambda_variablesContext ctx)
{}
0
public void enterSingle_lambda_variable(StellarParser.Single_lambda_variableContext ctx)
{}
0
public void exitSingle_lambda_variable(StellarParser.Single_lambda_variableContext ctx)
{}
0
public void enterLambda_variable(StellarParser.Lambda_variableContext ctx)
{}
0
public void exitLambda_variable(StellarParser.Lambda_variableContext ctx)
{}
0
public void enterMatchClauses(StellarParser.MatchClausesContext ctx)
{}
0
public void exitMatchClauses(StellarParser.MatchClausesContext ctx)
{}
0
public void enterMatch_clauses(StellarParser.Match_clausesContext ctx)
{}
0
public void exitMatch_clauses(StellarParser.Match_clausesContext ctx)
{}
0
public void enterMatch_clause(StellarParser.Match_clauseContext ctx)
{}
0
public void exitMatch_clause(StellarParser.Match_clauseContext ctx)
{}
0
public void enterMatchClauseAction(StellarParser.MatchClauseActionContext ctx)
{}
0
public void exitMatchClauseAction(StellarParser.MatchClauseActionContext ctx)
{}
0
public void enterMatchClauseCheckExpr(StellarParser.MatchClauseCheckExprContext ctx)
{}
0
public void exitMatchClauseCheckExpr(StellarParser.MatchClauseCheckExprContext ctx)
{}
0
public void enterEveryRule(ParserRuleContext ctx)
{}
0
public void exitEveryRule(ParserRuleContext ctx)
{}
0
public void visitTerminal(TerminalNode node)
{}
0
public void visitErrorNode(ErrorNode node)
{}
0
public String[] getTokenNames()
{    return tokenNames;}
0
public Vocabulary getVocabulary()
{    return VOCABULARY;}
0
public String getGrammarFileName()
{    return "Stellar.g4";}
0
public String[] getRuleNames()
{    return ruleNames;}
0
public String getSerializedATN()
{    return _serializedATN;}
0
public String[] getModeNames()
{    return modeNames;}
0
public ATN getATN()
{    return _ATN;}
0
public String[] getTokenNames()
{    return tokenNames;}
0
public Vocabulary getVocabulary()
{    return VOCABULARY;}
0
public String getGrammarFileName()
{    return "Stellar.g4";}
0
public String[] getRuleNames()
{    return ruleNames;}
0
public String getSerializedATN()
{    return _serializedATN;}
0
public ATN getATN()
{    return _ATN;}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public TerminalNode EOF()
{    return getToken(StellarParser.EOF, 0);}
0
public int getRuleIndex()
{    return RULE_transformation;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformation(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformation(this);}
0
public final TransformationContext transformation() throws RecognitionException
{    TransformationContext _localctx = new TransformationContext(_ctx, getState());    enterRule(_localctx, 0, RULE_transformation);    try {        enterOuterAlt(_localctx, 1);        {            setState(66);            transformation_expr();            setState(67);            match(EOF);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_transformation_expr;}
0
public void copyFrom(Transformation_exprContext ctx)
{    super.copyFrom(ctx);}
0
public Comparison_exprContext comparison_expr()
{    return getRuleContext(Comparison_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonExpression(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonExpression(this);}
0
public Logical_exprContext logical_expr()
{    return getRuleContext(Logical_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLogicalExpression(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLogicalExpression(this);}
0
public Transformation_entityContext transformation_entity()
{    return getRuleContext(Transformation_entityContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformationEntity(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformationEntity(this);}
0
public In_exprContext in_expr()
{    return getRuleContext(In_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterInExpression(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitInExpression(this);}
0
public Arithmetic_exprContext arithmetic_expr()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpression(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpression(this);}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformationExpr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformationExpr(this);}
0
public Conditional_exprContext conditional_expr()
{    return getRuleContext(Conditional_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterConditionalExpr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitConditionalExpr(this);}
0
public Match_exprContext match_expr()
{    return getRuleContext(Match_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMatchExpr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMatchExpr(this);}
0
public final Transformation_exprContext transformation_expr() throws RecognitionException
{    Transformation_exprContext _localctx = new Transformation_exprContext(_ctx, getState());    enterRule(_localctx, 2, RULE_transformation_expr);    try {        setState(80);        switch(getInterpreter().adaptivePredict(_input, 0, _ctx)) {            case 1:                _localctx = new ConditionalExprContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(69);                    conditional_expr();                }                break;            case 2:                _localctx = new TransformationExprContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(70);                    match(LPAREN);                    setState(71);                    transformation_expr();                    setState(72);                    match(RPAREN);                }                break;            case 3:                _localctx = new ArithExpressionContext(_localctx);                enterOuterAlt(_localctx, 3);                {                    setState(74);                    arithmetic_expr(0);                }                break;            case 4:                _localctx = new TransformationEntityContext(_localctx);                enterOuterAlt(_localctx, 4);                {                    setState(75);                    transformation_entity();                }                break;            case 5:                _localctx = new ComparisonExpressionContext(_localctx);                enterOuterAlt(_localctx, 5);                {                    setState(76);                    comparison_expr(0);                }                break;            case 6:                _localctx = new LogicalExpressionContext(_localctx);                enterOuterAlt(_localctx, 6);                {                    setState(77);                    logical_expr();                }                break;            case 7:                _localctx = new InExpressionContext(_localctx);                enterOuterAlt(_localctx, 7);                {                    setState(78);                    in_expr();                }                break;            case 8:                _localctx = new MatchExprContext(_localctx);                enterOuterAlt(_localctx, 8);                {                    setState(79);                    match_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Logical_exprContext logical_expr()
{    return getRuleContext(Logical_exprContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_if_expr;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterIf_expr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitIf_expr(this);}
0
public final If_exprContext if_expr() throws RecognitionException
{    If_exprContext _localctx = new If_exprContext(_ctx, getState());    enterRule(_localctx, 4, RULE_if_expr);    try {        enterOuterAlt(_localctx, 1);        {            setState(82);            logical_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_then_expr;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterThen_expr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitThen_expr(this);}
0
public final Then_exprContext then_expr() throws RecognitionException
{    Then_exprContext _localctx = new Then_exprContext(_ctx, getState());    enterRule(_localctx, 6, RULE_then_expr);    try {        enterOuterAlt(_localctx, 1);        {            setState(84);            transformation_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_else_expr;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterElse_expr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitElse_expr(this);}
0
public final Else_exprContext else_expr() throws RecognitionException
{    Else_exprContext _localctx = new Else_exprContext(_ctx, getState());    enterRule(_localctx, 8, RULE_else_expr);    try {        enterOuterAlt(_localctx, 1);        {            setState(86);            transformation_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_conditional_expr;}
0
public void copyFrom(Conditional_exprContext ctx)
{    super.copyFrom(ctx);}
0
public If_exprContext if_expr()
{    return getRuleContext(If_exprContext.class, 0);}
0
public TerminalNode QUESTION()
{    return getToken(StellarParser.QUESTION, 0);}
0
public Then_exprContext then_expr()
{    return getRuleContext(Then_exprContext.class, 0);}
0
public TerminalNode COLON()
{    return getToken(StellarParser.COLON, 0);}
0
public Else_exprContext else_expr()
{    return getRuleContext(Else_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTernaryFuncWithoutIf(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTernaryFuncWithoutIf(this);}
0
public TerminalNode IF()
{    return getToken(StellarParser.IF, 0);}
0
public If_exprContext if_expr()
{    return getRuleContext(If_exprContext.class, 0);}
0
public TerminalNode THEN()
{    return getToken(StellarParser.THEN, 0);}
0
public Then_exprContext then_expr()
{    return getRuleContext(Then_exprContext.class, 0);}
0
public TerminalNode ELSE()
{    return getToken(StellarParser.ELSE, 0);}
0
public Else_exprContext else_expr()
{    return getRuleContext(Else_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTernaryFuncWithIf(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTernaryFuncWithIf(this);}
0
public final Conditional_exprContext conditional_expr() throws RecognitionException
{    Conditional_exprContext _localctx = new Conditional_exprContext(_ctx, getState());    enterRule(_localctx, 10, RULE_conditional_expr);    try {        setState(101);        switch(_input.LA(1)) {            case NOT:            case TRUE:            case FALSE:            case NULL:            case NAN:            case LBRACE:            case LBRACKET:            case LPAREN:            case EXISTS:            case INT_LITERAL:            case DOUBLE_LITERAL:            case FLOAT_LITERAL:            case LONG_LITERAL:            case IDENTIFIER:            case STRING_LITERAL:                _localctx = new TernaryFuncWithoutIfContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(88);                    if_expr();                    setState(89);                    match(QUESTION);                    setState(90);                    then_expr();                    setState(91);                    match(COLON);                    setState(92);                    else_expr();                }                break;            case IF:                _localctx = new TernaryFuncWithIfContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(94);                    match(IF);                    setState(95);                    if_expr();                    setState(96);                    match(THEN);                    setState(97);                    then_expr();                    setState(98);                    match(ELSE);                    setState(99);                    else_expr();                }                break;            default:                throw new NoViableAltException(this);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_logical_expr;}
0
public void copyFrom(Logical_exprContext ctx)
{    super.copyFrom(ctx);}
0
public B_exprContext b_expr()
{    return getRuleContext(B_exprContext.class, 0);}
0
public TerminalNode AND()
{    return getToken(StellarParser.AND, 0);}
0
public Logical_exprContext logical_expr()
{    return getRuleContext(Logical_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLogicalExpressionAnd(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLogicalExpressionAnd(this);}
0
public B_exprContext b_expr()
{    return getRuleContext(B_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterBoleanExpression(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitBoleanExpression(this);}
0
public B_exprContext b_expr()
{    return getRuleContext(B_exprContext.class, 0);}
0
public TerminalNode OR()
{    return getToken(StellarParser.OR, 0);}
0
public Logical_exprContext logical_expr()
{    return getRuleContext(Logical_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLogicalExpressionOr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLogicalExpressionOr(this);}
0
public final Logical_exprContext logical_expr() throws RecognitionException
{    Logical_exprContext _localctx = new Logical_exprContext(_ctx, getState());    enterRule(_localctx, 12, RULE_logical_expr);    try {        setState(112);        switch(getInterpreter().adaptivePredict(_input, 2, _ctx)) {            case 1:                _localctx = new LogicalExpressionAndContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(103);                    b_expr();                    setState(104);                    match(AND);                    setState(105);                    logical_expr();                }                break;            case 2:                _localctx = new LogicalExpressionOrContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(107);                    b_expr();                    setState(108);                    match(OR);                    setState(109);                    logical_expr();                }                break;            case 3:                _localctx = new BoleanExpressionContext(_localctx);                enterOuterAlt(_localctx, 3);                {                    setState(111);                    b_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Comparison_exprContext comparison_expr()
{    return getRuleContext(Comparison_exprContext.class, 0);}
0
public In_exprContext in_expr()
{    return getRuleContext(In_exprContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_b_expr;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterB_expr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitB_expr(this);}
0
public final B_exprContext b_expr() throws RecognitionException
{    B_exprContext _localctx = new B_exprContext(_ctx, getState());    enterRule(_localctx, 14, RULE_b_expr);    try {        setState(116);        switch(getInterpreter().adaptivePredict(_input, 3, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(114);                    comparison_expr(0);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(115);                    in_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_in_expr;}
0
public void copyFrom(In_exprContext ctx)
{    super.copyFrom(ctx);}
0
public Identifier_operandContext identifier_operand()
{    return getRuleContext(Identifier_operandContext.class, 0);}
0
public TerminalNode NIN()
{    return getToken(StellarParser.NIN, 0);}
0
public B_exprContext b_expr()
{    return getRuleContext(B_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterNInExpressionStatement(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitNInExpressionStatement(this);}
0
public Identifier_operandContext identifier_operand()
{    return getRuleContext(Identifier_operandContext.class, 0);}
0
public TerminalNode IN()
{    return getToken(StellarParser.IN, 0);}
0
public B_exprContext b_expr()
{    return getRuleContext(B_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterInExpressionStatement(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitInExpressionStatement(this);}
0
public final In_exprContext in_expr() throws RecognitionException
{    In_exprContext _localctx = new In_exprContext(_ctx, getState());    enterRule(_localctx, 16, RULE_in_expr);    try {        setState(126);        switch(getInterpreter().adaptivePredict(_input, 4, _ctx)) {            case 1:                _localctx = new InExpressionStatementContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(118);                    identifier_operand();                    setState(119);                    match(IN);                    setState(120);                    b_expr();                }                break;            case 2:                _localctx = new NInExpressionStatementContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(122);                    identifier_operand();                    setState(123);                    match(NIN);                    setState(124);                    b_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_comparison_expr;}
0
public void copyFrom(Comparison_exprContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode NOT()
{    return getToken(StellarParser.NOT, 0);}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Logical_exprContext logical_expr()
{    return getRuleContext(Logical_exprContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterNotFunc(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitNotFunc(this);}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Logical_exprContext logical_expr()
{    return getRuleContext(Logical_exprContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonExpressionParens(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonExpressionParens(this);}
0
public List<Comparison_exprContext> comparison_expr()
{    return getRuleContexts(Comparison_exprContext.class);}
0
public Comparison_exprContext comparison_expr(int i)
{    return getRuleContext(Comparison_exprContext.class, i);}
0
public Comp_operatorContext comp_operator()
{    return getRuleContext(Comp_operatorContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonExpressionWithOperator(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonExpressionWithOperator(this);}
0
public Identifier_operandContext identifier_operand()
{    return getRuleContext(Identifier_operandContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterOperand(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitOperand(this);}
0
public final Comparison_exprContext comparison_expr() throws RecognitionException
{    return comparison_expr(0);}
0
private Comparison_exprContext comparison_expr(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Comparison_exprContext _localctx = new Comparison_exprContext(_ctx, _parentState);    Comparison_exprContext _prevctx = _localctx;    int _startState = 18;    enterRecursionRule(_localctx, 18, RULE_comparison_expr, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            setState(139);            switch(getInterpreter().adaptivePredict(_input, 5, _ctx)) {                case 1:                    {                        _localctx = new NotFuncContext(_localctx);                        _ctx = _localctx;                        _prevctx = _localctx;                        setState(129);                        match(NOT);                        setState(130);                        match(LPAREN);                        setState(131);                        logical_expr();                        setState(132);                        match(RPAREN);                    }                    break;                case 2:                    {                        _localctx = new ComparisonExpressionParensContext(_localctx);                        _ctx = _localctx;                        _prevctx = _localctx;                        setState(134);                        match(LPAREN);                        setState(135);                        logical_expr();                        setState(136);                        match(RPAREN);                    }                    break;                case 3:                    {                        _localctx = new OperandContext(_localctx);                        _ctx = _localctx;                        _prevctx = _localctx;                        setState(138);                        identifier_operand();                    }                    break;            }            _ctx.stop = _input.LT(-1);            setState(147);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 6, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        {                            _localctx = new ComparisonExpressionWithOperatorContext(new Comparison_exprContext(_parentctx, _parentState));                            pushNewRecursionContext(_localctx, _startState, RULE_comparison_expr);                            setState(141);                            if (!(precpred(_ctx, 4)))                                throw new FailedPredicateException(this, "precpred(_ctx, 4)");                            setState(142);                            comp_operator();                            setState(143);                            comparison_expr(5);                        }                    }                }                setState(149);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 6, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
0
public Identifier_operandContext identifier_operand()
{    return getRuleContext(Identifier_operandContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_transformation_entity;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformation_entity(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformation_entity(this);}
0
public final Transformation_entityContext transformation_entity() throws RecognitionException
{    Transformation_entityContext _localctx = new Transformation_entityContext(_ctx, getState());    enterRule(_localctx, 20, RULE_transformation_entity);    try {        enterOuterAlt(_localctx, 1);        {            setState(150);            identifier_operand();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_comp_operator;}
0
public void copyFrom(Comp_operatorContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode EQ()
{    return getToken(StellarParser.EQ, 0);}
0
public TerminalNode NEQ()
{    return getToken(StellarParser.NEQ, 0);}
0
public TerminalNode LT()
{    return getToken(StellarParser.LT, 0);}
0
public TerminalNode LTE()
{    return getToken(StellarParser.LTE, 0);}
0
public TerminalNode GT()
{    return getToken(StellarParser.GT, 0);}
0
public TerminalNode GTE()
{    return getToken(StellarParser.GTE, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterComparisonOp(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitComparisonOp(this);}
0
public final Comp_operatorContext comp_operator() throws RecognitionException
{    Comp_operatorContext _localctx = new Comp_operatorContext(_ctx, getState());    enterRule(_localctx, 22, RULE_comp_operator);    int _la;    try {        _localctx = new ComparisonOpContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(152);            _la = _input.LA(1);            if (!((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << EQ) | (1L << NEQ) | (1L << LT) | (1L << LTE) | (1L << GT) | (1L << GTE))) != 0))) {                _errHandler.recoverInline(this);            } else {                consume();            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Op_listContext op_list()
{    return getRuleContext(Op_listContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public int getRuleIndex()
{    return RULE_func_args;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterFunc_args(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitFunc_args(this);}
0
public final Func_argsContext func_args() throws RecognitionException
{    Func_argsContext _localctx = new Func_argsContext(_ctx, getState());    enterRule(_localctx, 24, RULE_func_args);    try {        setState(160);        switch(getInterpreter().adaptivePredict(_input, 7, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(154);                    match(LPAREN);                    setState(155);                    op_list(0);                    setState(156);                    match(RPAREN);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(158);                    match(LPAREN);                    setState(159);                    match(RPAREN);                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Identifier_operandContext identifier_operand()
{    return getRuleContext(Identifier_operandContext.class, 0);}
0
public Conditional_exprContext conditional_expr()
{    return getRuleContext(Conditional_exprContext.class, 0);}
0
public Comparison_exprContext comparison_expr()
{    return getRuleContext(Comparison_exprContext.class, 0);}
0
public Op_listContext op_list()
{    return getRuleContext(Op_listContext.class, 0);}
0
public TerminalNode COMMA()
{    return getToken(StellarParser.COMMA, 0);}
0
public int getRuleIndex()
{    return RULE_op_list;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterOp_list(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitOp_list(this);}
0
public final Op_listContext op_list() throws RecognitionException
{    return op_list(0);}
0
private Op_listContext op_list(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Op_listContext _localctx = new Op_listContext(_ctx, _parentState);    Op_listContext _prevctx = _localctx;    int _startState = 26;    enterRecursionRule(_localctx, 26, RULE_op_list, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            setState(166);            switch(getInterpreter().adaptivePredict(_input, 8, _ctx)) {                case 1:                    {                        setState(163);                        identifier_operand();                    }                    break;                case 2:                    {                        setState(164);                        conditional_expr();                    }                    break;                case 3:                    {                        setState(165);                        comparison_expr(0);                    }                    break;            }            _ctx.stop = _input.LT(-1);            setState(179);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 10, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        setState(177);                        switch(getInterpreter().adaptivePredict(_input, 9, _ctx)) {                            case 1:                                {                                    _localctx = new Op_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_op_list);                                    setState(168);                                    if (!(precpred(_ctx, 5)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 5)");                                    setState(169);                                    match(COMMA);                                    setState(170);                                    identifier_operand();                                }                                break;                            case 2:                                {                                    _localctx = new Op_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_op_list);                                    setState(171);                                    if (!(precpred(_ctx, 3)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 3)");                                    setState(172);                                    match(COMMA);                                    setState(173);                                    conditional_expr();                                }                                break;                            case 3:                                {                                    _localctx = new Op_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_op_list);                                    setState(174);                                    if (!(precpred(_ctx, 1)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 1)");                                    setState(175);                                    match(COMMA);                                    setState(176);                                    comparison_expr(0);                                }                                break;                        }                    }                }                setState(181);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 10, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
0
public TerminalNode LBRACKET()
{    return getToken(StellarParser.LBRACKET, 0);}
0
public TerminalNode RBRACKET()
{    return getToken(StellarParser.RBRACKET, 0);}
0
public Op_listContext op_list()
{    return getRuleContext(Op_listContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_list_entity;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterList_entity(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitList_entity(this);}
0
public final List_entityContext list_entity() throws RecognitionException
{    List_entityContext _localctx = new List_entityContext(_ctx, getState());    enterRule(_localctx, 28, RULE_list_entity);    try {        setState(188);        switch(getInterpreter().adaptivePredict(_input, 11, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(182);                    match(LBRACKET);                    setState(183);                    match(RBRACKET);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(184);                    match(LBRACKET);                    setState(185);                    op_list(0);                    setState(186);                    match(RBRACKET);                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Identifier_operandContext identifier_operand()
{    return getRuleContext(Identifier_operandContext.class, 0);}
0
public TerminalNode COLON()
{    return getToken(StellarParser.COLON, 0);}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public Comparison_exprContext comparison_expr()
{    return getRuleContext(Comparison_exprContext.class, 0);}
0
public Kv_listContext kv_list()
{    return getRuleContext(Kv_listContext.class, 0);}
0
public TerminalNode COMMA()
{    return getToken(StellarParser.COMMA, 0);}
0
public int getRuleIndex()
{    return RULE_kv_list;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterKv_list(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitKv_list(this);}
0
public final Kv_listContext kv_list() throws RecognitionException
{    return kv_list(0);}
0
private Kv_listContext kv_list(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Kv_listContext _localctx = new Kv_listContext(_ctx, _parentState);    Kv_listContext _prevctx = _localctx;    int _startState = 30;    enterRecursionRule(_localctx, 30, RULE_kv_list, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            setState(199);            switch(getInterpreter().adaptivePredict(_input, 12, _ctx)) {                case 1:                    {                        setState(191);                        identifier_operand();                        setState(192);                        match(COLON);                        setState(193);                        transformation_expr();                    }                    break;                case 2:                    {                        setState(195);                        comparison_expr(0);                        setState(196);                        match(COLON);                        setState(197);                        transformation_expr();                    }                    break;            }            _ctx.stop = _input.LT(-1);            setState(215);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 14, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        setState(213);                        switch(getInterpreter().adaptivePredict(_input, 13, _ctx)) {                            case 1:                                {                                    _localctx = new Kv_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_kv_list);                                    setState(201);                                    if (!(precpred(_ctx, 2)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 2)");                                    setState(202);                                    match(COMMA);                                    setState(203);                                    identifier_operand();                                    setState(204);                                    match(COLON);                                    setState(205);                                    transformation_expr();                                }                                break;                            case 2:                                {                                    _localctx = new Kv_listContext(_parentctx, _parentState);                                    pushNewRecursionContext(_localctx, _startState, RULE_kv_list);                                    setState(207);                                    if (!(precpred(_ctx, 1)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 1)");                                    setState(208);                                    match(COMMA);                                    setState(209);                                    comparison_expr(0);                                    setState(210);                                    match(COLON);                                    setState(211);                                    transformation_expr();                                }                                break;                        }                    }                }                setState(217);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 14, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
0
public TerminalNode LBRACE()
{    return getToken(StellarParser.LBRACE, 0);}
0
public Kv_listContext kv_list()
{    return getRuleContext(Kv_listContext.class, 0);}
0
public TerminalNode RBRACE()
{    return getToken(StellarParser.RBRACE, 0);}
0
public int getRuleIndex()
{    return RULE_map_entity;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMap_entity(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMap_entity(this);}
0
public final Map_entityContext map_entity() throws RecognitionException
{    Map_entityContext _localctx = new Map_entityContext(_ctx, getState());    enterRule(_localctx, 32, RULE_map_entity);    try {        setState(224);        switch(getInterpreter().adaptivePredict(_input, 15, _ctx)) {            case 1:                enterOuterAlt(_localctx, 1);                {                    setState(218);                    match(LBRACE);                    setState(219);                    kv_list(0);                    setState(220);                    match(RBRACE);                }                break;            case 2:                enterOuterAlt(_localctx, 2);                {                    setState(222);                    match(LBRACE);                    setState(223);                    match(RBRACE);                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_arithmetic_expr;}
0
public void copyFrom(Arithmetic_exprContext ctx)
{    super.copyFrom(ctx);}
0
public Arithmetic_expr_mulContext arithmetic_expr_mul()
{    return getRuleContext(Arithmetic_expr_mulContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_solo(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_solo(this);}
0
public Arithmetic_exprContext arithmetic_expr()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
0
public TerminalNode MINUS()
{    return getToken(StellarParser.MINUS, 0);}
0
public Arithmetic_expr_mulContext arithmetic_expr_mul()
{    return getRuleContext(Arithmetic_expr_mulContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_minus(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_minus(this);}
0
public Arithmetic_exprContext arithmetic_expr()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
0
public TerminalNode PLUS()
{    return getToken(StellarParser.PLUS, 0);}
0
public Arithmetic_expr_mulContext arithmetic_expr_mul()
{    return getRuleContext(Arithmetic_expr_mulContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_plus(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_plus(this);}
0
public final Arithmetic_exprContext arithmetic_expr() throws RecognitionException
{    return arithmetic_expr(0);}
0
private Arithmetic_exprContext arithmetic_expr(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Arithmetic_exprContext _localctx = new Arithmetic_exprContext(_ctx, _parentState);    Arithmetic_exprContext _prevctx = _localctx;    int _startState = 34;    enterRecursionRule(_localctx, 34, RULE_arithmetic_expr, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            {                _localctx = new ArithExpr_soloContext(_localctx);                _ctx = _localctx;                _prevctx = _localctx;                setState(227);                arithmetic_expr_mul(0);            }            _ctx.stop = _input.LT(-1);            setState(237);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 17, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        setState(235);                        switch(getInterpreter().adaptivePredict(_input, 16, _ctx)) {                            case 1:                                {                                    _localctx = new ArithExpr_plusContext(new Arithmetic_exprContext(_parentctx, _parentState));                                    pushNewRecursionContext(_localctx, _startState, RULE_arithmetic_expr);                                    setState(229);                                    if (!(precpred(_ctx, 2)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 2)");                                    setState(230);                                    match(PLUS);                                    setState(231);                                    arithmetic_expr_mul(0);                                }                                break;                            case 2:                                {                                    _localctx = new ArithExpr_minusContext(new Arithmetic_exprContext(_parentctx, _parentState));                                    pushNewRecursionContext(_localctx, _startState, RULE_arithmetic_expr);                                    setState(232);                                    if (!(precpred(_ctx, 1)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 1)");                                    setState(233);                                    match(MINUS);                                    setState(234);                                    arithmetic_expr_mul(0);                                }                                break;                        }                    }                }                setState(239);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 17, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_arithmetic_expr_mul;}
0
public void copyFrom(Arithmetic_expr_mulContext ctx)
{    super.copyFrom(ctx);}
0
public List<Arithmetic_expr_mulContext> arithmetic_expr_mul()
{    return getRuleContexts(Arithmetic_expr_mulContext.class);}
0
public Arithmetic_expr_mulContext arithmetic_expr_mul(int i)
{    return getRuleContext(Arithmetic_expr_mulContext.class, i);}
0
public TerminalNode DIV()
{    return getToken(StellarParser.DIV, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_div(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_div(this);}
0
public Arithmetic_operandsContext arithmetic_operands()
{    return getRuleContext(Arithmetic_operandsContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_mul_solo(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_mul_solo(this);}
0
public List<Arithmetic_expr_mulContext> arithmetic_expr_mul()
{    return getRuleContexts(Arithmetic_expr_mulContext.class);}
0
public Arithmetic_expr_mulContext arithmetic_expr_mul(int i)
{    return getRuleContext(Arithmetic_expr_mulContext.class, i);}
0
public TerminalNode MUL()
{    return getToken(StellarParser.MUL, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithExpr_mul(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithExpr_mul(this);}
0
public final Arithmetic_expr_mulContext arithmetic_expr_mul() throws RecognitionException
{    return arithmetic_expr_mul(0);}
0
private Arithmetic_expr_mulContext arithmetic_expr_mul(int _p) throws RecognitionException
{    ParserRuleContext _parentctx = _ctx;    int _parentState = getState();    Arithmetic_expr_mulContext _localctx = new Arithmetic_expr_mulContext(_ctx, _parentState);    Arithmetic_expr_mulContext _prevctx = _localctx;    int _startState = 36;    enterRecursionRule(_localctx, 36, RULE_arithmetic_expr_mul, _p);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            {                _localctx = new ArithExpr_mul_soloContext(_localctx);                _ctx = _localctx;                _prevctx = _localctx;                setState(241);                arithmetic_operands();            }            _ctx.stop = _input.LT(-1);            setState(251);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 19, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    if (_parseListeners != null)                        triggerExitRuleEvent();                    _prevctx = _localctx;                    {                        setState(249);                        switch(getInterpreter().adaptivePredict(_input, 18, _ctx)) {                            case 1:                                {                                    _localctx = new ArithExpr_mulContext(new Arithmetic_expr_mulContext(_parentctx, _parentState));                                    pushNewRecursionContext(_localctx, _startState, RULE_arithmetic_expr_mul);                                    setState(243);                                    if (!(precpred(_ctx, 2)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 2)");                                    setState(244);                                    match(MUL);                                    setState(245);                                    arithmetic_expr_mul(3);                                }                                break;                            case 2:                                {                                    _localctx = new ArithExpr_divContext(new Arithmetic_expr_mulContext(_parentctx, _parentState));                                    pushNewRecursionContext(_localctx, _startState, RULE_arithmetic_expr_mul);                                    setState(246);                                    if (!(precpred(_ctx, 1)))                                        throw new FailedPredicateException(this, "precpred(_ctx, 1)");                                    setState(247);                                    match(DIV);                                    setState(248);                                    arithmetic_expr_mul(2);                                }                                break;                        }                    }                }                setState(253);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 19, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        unrollRecursionContexts(_parentctx);    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_functions;}
0
public void copyFrom(FunctionsContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode IDENTIFIER()
{    return getToken(StellarParser.IDENTIFIER, 0);}
0
public Func_argsContext func_args()
{    return getRuleContext(Func_argsContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterTransformationFunc(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitTransformationFunc(this);}
0
public final FunctionsContext functions() throws RecognitionException
{    FunctionsContext _localctx = new FunctionsContext(_ctx, getState());    enterRule(_localctx, 38, RULE_functions);    try {        _localctx = new TransformationFuncContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(254);            match(IDENTIFIER);            setState(255);            func_args();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_arithmetic_operands;}
0
public void copyFrom(Arithmetic_operandsContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode IDENTIFIER()
{    return getToken(StellarParser.IDENTIFIER, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterVariable(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitVariable(this);}
0
public FunctionsContext functions()
{    return getRuleContext(FunctionsContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterNumericFunctions(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitNumericFunctions(this);}
0
public TerminalNode LONG_LITERAL()
{    return getToken(StellarParser.LONG_LITERAL, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLongLiteral(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLongLiteral(this);}
0
public TerminalNode FLOAT_LITERAL()
{    return getToken(StellarParser.FLOAT_LITERAL, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterFloatLiteral(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitFloatLiteral(this);}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Conditional_exprContext conditional_expr()
{    return getRuleContext(Conditional_exprContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterCondExpr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitCondExpr(this);}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Arithmetic_exprContext arithmetic_expr()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterParenArith(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitParenArith(this);}
0
public TerminalNode INT_LITERAL()
{    return getToken(StellarParser.INT_LITERAL, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterIntLiteral(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitIntLiteral(this);}
0
public TerminalNode NAN()
{    return getToken(StellarParser.NAN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterNaNArith(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitNaNArith(this);}
0
public TerminalNode DOUBLE_LITERAL()
{    return getToken(StellarParser.DOUBLE_LITERAL, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterDoubleLiteral(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitDoubleLiteral(this);}
0
public final Arithmetic_operandsContext arithmetic_operands() throws RecognitionException
{    Arithmetic_operandsContext _localctx = new Arithmetic_operandsContext(_ctx, getState());    enterRule(_localctx, 40, RULE_arithmetic_operands);    try {        setState(272);        switch(getInterpreter().adaptivePredict(_input, 20, _ctx)) {            case 1:                _localctx = new NumericFunctionsContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(257);                    functions();                }                break;            case 2:                _localctx = new DoubleLiteralContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(258);                    match(DOUBLE_LITERAL);                }                break;            case 3:                _localctx = new IntLiteralContext(_localctx);                enterOuterAlt(_localctx, 3);                {                    setState(259);                    match(INT_LITERAL);                }                break;            case 4:                _localctx = new LongLiteralContext(_localctx);                enterOuterAlt(_localctx, 4);                {                    setState(260);                    match(LONG_LITERAL);                }                break;            case 5:                _localctx = new FloatLiteralContext(_localctx);                enterOuterAlt(_localctx, 5);                {                    setState(261);                    match(FLOAT_LITERAL);                }                break;            case 6:                _localctx = new VariableContext(_localctx);                enterOuterAlt(_localctx, 6);                {                    setState(262);                    match(IDENTIFIER);                }                break;            case 7:                _localctx = new NaNArithContext(_localctx);                enterOuterAlt(_localctx, 7);                {                    setState(263);                    match(NAN);                }                break;            case 8:                _localctx = new ParenArithContext(_localctx);                enterOuterAlt(_localctx, 8);                {                    setState(264);                    match(LPAREN);                    setState(265);                    arithmetic_expr(0);                    setState(266);                    match(RPAREN);                }                break;            case 9:                _localctx = new CondExprContext(_localctx);                enterOuterAlt(_localctx, 9);                {                    setState(268);                    match(LPAREN);                    setState(269);                    conditional_expr();                    setState(270);                    match(RPAREN);                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_identifier_operand;}
0
public void copyFrom(Identifier_operandContext ctx)
{    super.copyFrom(ctx);}
0
public Arithmetic_exprContext arithmetic_expr()
{    return getRuleContext(Arithmetic_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterArithmeticOperands(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitArithmeticOperands(this);}
0
public Lambda_with_argsContext lambda_with_args()
{    return getRuleContext(Lambda_with_argsContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLambdaWithArgsExpr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLambdaWithArgsExpr(this);}
0
public TerminalNode STRING_LITERAL()
{    return getToken(StellarParser.STRING_LITERAL, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterStringLiteral(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitStringLiteral(this);}
0
public FunctionsContext functions()
{    return getRuleContext(FunctionsContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterFunc(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitFunc(this);}
0
public Lambda_without_argsContext lambda_without_args()
{    return getRuleContext(Lambda_without_argsContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLambdaWithoutArgsExpr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLambdaWithoutArgsExpr(this);}
0
public List_entityContext list_entity()
{    return getRuleContext(List_entityContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterList(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitList(this);}
0
public Map_entityContext map_entity()
{    return getRuleContext(Map_entityContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMapConst(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMapConst(this);}
0
public TerminalNode TRUE()
{    return getToken(StellarParser.TRUE, 0);}
0
public TerminalNode FALSE()
{    return getToken(StellarParser.FALSE, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLogicalConst(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLogicalConst(this);}
0
public TerminalNode NULL()
{    return getToken(StellarParser.NULL, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterNullConst(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitNullConst(this);}
0
public TerminalNode EXISTS()
{    return getToken(StellarParser.EXISTS, 0);}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public TerminalNode IDENTIFIER()
{    return getToken(StellarParser.IDENTIFIER, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterExistsFunc(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitExistsFunc(this);}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Conditional_exprContext conditional_expr()
{    return getRuleContext(Conditional_exprContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterCondExpr_paren(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitCondExpr_paren(this);}
0
public final Identifier_operandContext identifier_operand() throws RecognitionException
{    Identifier_operandContext _localctx = new Identifier_operandContext(_ctx, getState());    enterRule(_localctx, 42, RULE_identifier_operand);    int _la;    try {        setState(291);        switch(getInterpreter().adaptivePredict(_input, 21, _ctx)) {            case 1:                _localctx = new LogicalConstContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(274);                    _la = _input.LA(1);                    if (!(_la == TRUE || _la == FALSE)) {                        _errHandler.recoverInline(this);                    } else {                        consume();                    }                }                break;            case 2:                _localctx = new LambdaWithArgsExprContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(275);                    lambda_with_args();                }                break;            case 3:                _localctx = new LambdaWithoutArgsExprContext(_localctx);                enterOuterAlt(_localctx, 3);                {                    setState(276);                    lambda_without_args();                }                break;            case 4:                _localctx = new ArithmeticOperandsContext(_localctx);                enterOuterAlt(_localctx, 4);                {                    setState(277);                    arithmetic_expr(0);                }                break;            case 5:                _localctx = new StringLiteralContext(_localctx);                enterOuterAlt(_localctx, 5);                {                    setState(278);                    match(STRING_LITERAL);                }                break;            case 6:                _localctx = new ListContext(_localctx);                enterOuterAlt(_localctx, 6);                {                    setState(279);                    list_entity();                }                break;            case 7:                _localctx = new MapConstContext(_localctx);                enterOuterAlt(_localctx, 7);                {                    setState(280);                    map_entity();                }                break;            case 8:                _localctx = new NullConstContext(_localctx);                enterOuterAlt(_localctx, 8);                {                    setState(281);                    match(NULL);                }                break;            case 9:                _localctx = new ExistsFuncContext(_localctx);                enterOuterAlt(_localctx, 9);                {                    setState(282);                    match(EXISTS);                    setState(283);                    match(LPAREN);                    setState(284);                    match(IDENTIFIER);                    setState(285);                    match(RPAREN);                }                break;            case 10:                _localctx = new CondExpr_parenContext(_localctx);                enterOuterAlt(_localctx, 10);                {                    setState(286);                    match(LPAREN);                    setState(287);                    conditional_expr();                    setState(288);                    match(RPAREN);                }                break;            case 11:                _localctx = new FuncContext(_localctx);                enterOuterAlt(_localctx, 11);                {                    setState(290);                    functions();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_default_operand;}
0
public void copyFrom(Default_operandContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode DEFAULT()
{    return getToken(StellarParser.DEFAULT, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterDefault(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitDefault(this);}
0
public final Default_operandContext default_operand() throws RecognitionException
{    Default_operandContext _localctx = new Default_operandContext(_ctx, getState());    enterRule(_localctx, 44, RULE_default_operand);    try {        _localctx = new DefaultContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(293);            match(DEFAULT);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public TerminalNode LAMBDA_OP()
{    return getToken(StellarParser.LAMBDA_OP, 0);}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_lambda_without_args;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLambda_without_args(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLambda_without_args(this);}
0
public final Lambda_without_argsContext lambda_without_args() throws RecognitionException
{    Lambda_without_argsContext _localctx = new Lambda_without_argsContext(_ctx, getState());    enterRule(_localctx, 46, RULE_lambda_without_args);    try {        enterOuterAlt(_localctx, 1);        {            setState(295);            match(LPAREN);            setState(296);            match(RPAREN);            setState(297);            match(LAMBDA_OP);            setState(298);            transformation_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode LPAREN()
{    return getToken(StellarParser.LPAREN, 0);}
0
public Lambda_variablesContext lambda_variables()
{    return getRuleContext(Lambda_variablesContext.class, 0);}
0
public TerminalNode RPAREN()
{    return getToken(StellarParser.RPAREN, 0);}
0
public TerminalNode LAMBDA_OP()
{    return getToken(StellarParser.LAMBDA_OP, 0);}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public Single_lambda_variableContext single_lambda_variable()
{    return getRuleContext(Single_lambda_variableContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_lambda_with_args;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLambda_with_args(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLambda_with_args(this);}
0
public final Lambda_with_argsContext lambda_with_args() throws RecognitionException
{    Lambda_with_argsContext _localctx = new Lambda_with_argsContext(_ctx, getState());    enterRule(_localctx, 48, RULE_lambda_with_args);    try {        setState(310);        switch(_input.LA(1)) {            case LPAREN:                enterOuterAlt(_localctx, 1);                {                    setState(300);                    match(LPAREN);                    setState(301);                    lambda_variables();                    setState(302);                    match(RPAREN);                    setState(303);                    match(LAMBDA_OP);                    setState(304);                    transformation_expr();                }                break;            case IDENTIFIER:                enterOuterAlt(_localctx, 2);                {                    setState(306);                    single_lambda_variable();                    setState(307);                    match(LAMBDA_OP);                    setState(308);                    transformation_expr();                }                break;            default:                throw new NoViableAltException(this);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public List<Lambda_variableContext> lambda_variable()
{    return getRuleContexts(Lambda_variableContext.class);}
0
public Lambda_variableContext lambda_variable(int i)
{    return getRuleContext(Lambda_variableContext.class, i);}
0
public List<TerminalNode> COMMA()
{    return getTokens(StellarParser.COMMA);}
0
public TerminalNode COMMA(int i)
{    return getToken(StellarParser.COMMA, i);}
0
public int getRuleIndex()
{    return RULE_lambda_variables;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLambda_variables(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLambda_variables(this);}
0
public final Lambda_variablesContext lambda_variables() throws RecognitionException
{    Lambda_variablesContext _localctx = new Lambda_variablesContext(_ctx, getState());    enterRule(_localctx, 50, RULE_lambda_variables);    int _la;    try {        enterOuterAlt(_localctx, 1);        {            setState(312);            lambda_variable();            setState(317);            _errHandler.sync(this);            _la = _input.LA(1);            while (_la == COMMA) {                {                    {                        setState(313);                        match(COMMA);                        setState(314);                        lambda_variable();                    }                }                setState(319);                _errHandler.sync(this);                _la = _input.LA(1);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Lambda_variableContext lambda_variable()
{    return getRuleContext(Lambda_variableContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_single_lambda_variable;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterSingle_lambda_variable(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitSingle_lambda_variable(this);}
0
public final Single_lambda_variableContext single_lambda_variable() throws RecognitionException
{    Single_lambda_variableContext _localctx = new Single_lambda_variableContext(_ctx, getState());    enterRule(_localctx, 52, RULE_single_lambda_variable);    try {        enterOuterAlt(_localctx, 1);        {            setState(320);            lambda_variable();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public TerminalNode IDENTIFIER()
{    return getToken(StellarParser.IDENTIFIER, 0);}
0
public int getRuleIndex()
{    return RULE_lambda_variable;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterLambda_variable(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitLambda_variable(this);}
0
public final Lambda_variableContext lambda_variable() throws RecognitionException
{    Lambda_variableContext _localctx = new Lambda_variableContext(_ctx, getState());    enterRule(_localctx, 54, RULE_lambda_variable);    try {        enterOuterAlt(_localctx, 1);        {            setState(322);            match(IDENTIFIER);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_match_expr;}
0
public void copyFrom(Match_exprContext ctx)
{    super.copyFrom(ctx);}
0
public TerminalNode MATCH()
{    return getToken(StellarParser.MATCH, 0);}
0
public TerminalNode LBRACE()
{    return getToken(StellarParser.LBRACE, 0);}
0
public Match_clausesContext match_clauses()
{    return getRuleContext(Match_clausesContext.class, 0);}
0
public TerminalNode COMMA()
{    return getToken(StellarParser.COMMA, 0);}
0
public TerminalNode DEFAULT()
{    return getToken(StellarParser.DEFAULT, 0);}
0
public TerminalNode MATCH_ACTION()
{    return getToken(StellarParser.MATCH_ACTION, 0);}
0
public Match_clause_actionContext match_clause_action()
{    return getRuleContext(Match_clause_actionContext.class, 0);}
0
public TerminalNode RBRACE()
{    return getToken(StellarParser.RBRACE, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMatchClauses(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMatchClauses(this);}
0
public final Match_exprContext match_expr() throws RecognitionException
{    Match_exprContext _localctx = new Match_exprContext(_ctx, getState());    enterRule(_localctx, 56, RULE_match_expr);    try {        _localctx = new MatchClausesContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(324);            match(MATCH);            setState(325);            match(LBRACE);            setState(326);            match_clauses();            setState(327);            match(COMMA);            setState(328);            match(DEFAULT);            setState(329);            match(MATCH_ACTION);            setState(330);            match_clause_action();            setState(331);            match(RBRACE);        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public List<Match_clauseContext> match_clause()
{    return getRuleContexts(Match_clauseContext.class);}
0
public Match_clauseContext match_clause(int i)
{    return getRuleContext(Match_clauseContext.class, i);}
0
public List<TerminalNode> COMMA()
{    return getTokens(StellarParser.COMMA);}
0
public TerminalNode COMMA(int i)
{    return getToken(StellarParser.COMMA, i);}
0
public int getRuleIndex()
{    return RULE_match_clauses;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMatch_clauses(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMatch_clauses(this);}
0
public final Match_clausesContext match_clauses() throws RecognitionException
{    Match_clausesContext _localctx = new Match_clausesContext(_ctx, getState());    enterRule(_localctx, 58, RULE_match_clauses);    try {        int _alt;        enterOuterAlt(_localctx, 1);        {            setState(333);            match_clause();            setState(338);            _errHandler.sync(this);            _alt = getInterpreter().adaptivePredict(_input, 24, _ctx);            while (_alt != 2 && _alt != org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER) {                if (_alt == 1) {                    {                        {                            setState(334);                            match(COMMA);                            setState(335);                            match_clause();                        }                    }                }                setState(340);                _errHandler.sync(this);                _alt = getInterpreter().adaptivePredict(_input, 24, _ctx);            }        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public Match_clause_checkContext match_clause_check()
{    return getRuleContext(Match_clause_checkContext.class, 0);}
0
public TerminalNode MATCH_ACTION()
{    return getToken(StellarParser.MATCH_ACTION, 0);}
0
public Match_clause_actionContext match_clause_action()
{    return getRuleContext(Match_clause_actionContext.class, 0);}
0
public int getRuleIndex()
{    return RULE_match_clause;}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMatch_clause(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMatch_clause(this);}
0
public final Match_clauseContext match_clause() throws RecognitionException
{    Match_clauseContext _localctx = new Match_clauseContext(_ctx, getState());    enterRule(_localctx, 60, RULE_match_clause);    try {        enterOuterAlt(_localctx, 1);        {            setState(341);            match_clause_check();            setState(342);            match(MATCH_ACTION);            setState(343);            match_clause_action();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_match_clause_action;}
0
public void copyFrom(Match_clause_actionContext ctx)
{    super.copyFrom(ctx);}
0
public Transformation_exprContext transformation_expr()
{    return getRuleContext(Transformation_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMatchClauseAction(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMatchClauseAction(this);}
0
public final Match_clause_actionContext match_clause_action() throws RecognitionException
{    Match_clause_actionContext _localctx = new Match_clause_actionContext(_ctx, getState());    enterRule(_localctx, 62, RULE_match_clause_action);    try {        _localctx = new MatchClauseActionContext(_localctx);        enterOuterAlt(_localctx, 1);        {            setState(345);            transformation_expr();        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public int getRuleIndex()
{    return RULE_match_clause_check;}
0
public void copyFrom(Match_clause_checkContext ctx)
{    super.copyFrom(ctx);}
0
public Logical_exprContext logical_expr()
{    return getRuleContext(Logical_exprContext.class, 0);}
0
public Conditional_exprContext conditional_expr()
{    return getRuleContext(Conditional_exprContext.class, 0);}
0
public void enterRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).enterMatchClauseCheckExpr(this);}
0
public void exitRule(ParseTreeListener listener)
{    if (listener instanceof StellarListener)        ((StellarListener) listener).exitMatchClauseCheckExpr(this);}
0
public final Match_clause_checkContext match_clause_check() throws RecognitionException
{    Match_clause_checkContext _localctx = new Match_clause_checkContext(_ctx, getState());    enterRule(_localctx, 64, RULE_match_clause_check);    try {        setState(349);        switch(getInterpreter().adaptivePredict(_input, 25, _ctx)) {            case 1:                _localctx = new MatchClauseCheckExprContext(_localctx);                enterOuterAlt(_localctx, 1);                {                    setState(347);                    logical_expr();                }                break;            case 2:                _localctx = new MatchClauseCheckExprContext(_localctx);                enterOuterAlt(_localctx, 2);                {                    setState(348);                    conditional_expr();                }                break;        }    } catch (RecognitionException re) {        _localctx.exception = re;        _errHandler.reportError(this, re);        _errHandler.recover(this, re);    } finally {        exitRule();    }    return _localctx;}
0
public boolean sempred(RuleContext _localctx, int ruleIndex, int predIndex)
{    switch(ruleIndex) {        case 9:            return comparison_expr_sempred((Comparison_exprContext) _localctx, predIndex);        case 13:            return op_list_sempred((Op_listContext) _localctx, predIndex);        case 15:            return kv_list_sempred((Kv_listContext) _localctx, predIndex);        case 17:            return arithmetic_expr_sempred((Arithmetic_exprContext) _localctx, predIndex);        case 18:            return arithmetic_expr_mul_sempred((Arithmetic_expr_mulContext) _localctx, predIndex);    }    return true;}
0
private boolean comparison_expr_sempred(Comparison_exprContext _localctx, int predIndex)
{    switch(predIndex) {        case 0:            return precpred(_ctx, 4);    }    return true;}
0
private boolean op_list_sempred(Op_listContext _localctx, int predIndex)
{    switch(predIndex) {        case 1:            return precpred(_ctx, 5);        case 2:            return precpred(_ctx, 3);        case 3:            return precpred(_ctx, 1);    }    return true;}
0
private boolean kv_list_sempred(Kv_listContext _localctx, int predIndex)
{    switch(predIndex) {        case 4:            return precpred(_ctx, 2);        case 5:            return precpred(_ctx, 1);    }    return true;}
0
private boolean arithmetic_expr_sempred(Arithmetic_exprContext _localctx, int predIndex)
{    switch(predIndex) {        case 6:            return precpred(_ctx, 2);        case 7:            return precpred(_ctx, 1);    }    return true;}
0
private boolean arithmetic_expr_mul_sempred(Arithmetic_expr_mulContext _localctx, int predIndex)
{    switch(predIndex) {        case 8:            return precpred(_ctx, 2);        case 9:            return precpred(_ctx, 1);    }    return true;}
0
public Deque<Token<?>> getTokenDeque()
{    Deque<Token<?>> ret = new ArrayDeque<>(super.getTokenDeque().size());    for (Token<?> token : super.getTokenDeque()) {        ret.add(token);    }    return ret;}
0
public Object apply(List<Object> variableArgs)
{    Map<String, Object> lambdaVariables = new HashMap<>();    int i = 0;    for (; i < Math.min(variables.size(), variableArgs.size()); ++i) {        lambdaVariables.put(variables.get(i), variableArgs.get(i));    }    for (; i < variables.size(); ++i) {        lambdaVariables.put(variables.get(i), null);    }    VariableResolver variableResolver = new DefaultVariableResolver(variable -> lambdaVariables.getOrDefault(variable, state.variableResolver.resolve(variable)), variable -> true);    StellarCompiler.ExpressionState localState = new StellarCompiler.ExpressionState(state.context, state.functionResolver, variableResolver);    return apply(localState);}
0
public void pause()
{    paused.set(true);}
0
public void unpause() throws IOException
{    paused.set(false);}
0
public int read() throws IOException
{    if (paused.get()) {        try {            Thread.sleep(1000);        } catch (InterruptedException e) {            e.printStackTrace();        }        return 0;    }    return in.read();}
0
public int read(byte[] b) throws IOException
{    if (paused.get()) {        try {            Thread.sleep(1000);        } catch (InterruptedException e) {            e.printStackTrace();        }        return 0;    }    int ret = in.read(b);    return ret;}
0
public int read(byte[] b, int off, int len) throws IOException
{    if (paused.get()) {        try {            Thread.sleep(1000);        } catch (InterruptedException e) {            e.printStackTrace();        }        return 0;    }    int ret = in.read(b, off, len);    return ret;}
0
public long skip(long n) throws IOException
{    return in.skip(n);}
0
public int available() throws IOException
{    return in.available();}
0
public void close() throws IOException
{    in.close();}
0
public synchronized void mark(int readlimit)
{    in.mark(readlimit);}
0
public synchronized void reset() throws IOException
{    in.reset();}
0
public boolean markSupported()
{    return in.markSupported();}
0
public static void main(String[] args) throws Exception
{    StellarShell shell = new StellarShell(args);    shell.run();}
0
private Options defineCommandLineOptions()
{    Options options = new Options();    options.addOption("z", "zookeeper", true, "Zookeeper URL fragment in the form [HOSTNAME|IPADDRESS]:PORT");    options.addOption("v", "variables", true, "File containing a JSON Map of variables");    options.addOption("irc", "inputrc", true, "File containing the inputrc if not the default ~/.inputrc");    options.addOption("na", "no_ansi", false, "Make the input prompt not use ANSI colors.");    options.addOption("h", "help", false, "Print help");    options.addOption("p", "properties", true, "File containing Stellar properties");    Option log4j = new Option("l", "log4j", true, "The log4j properties file to load");    log4j.setArgName("FILE");    log4j.setRequired(false);    options.addOption(log4j);    return options;}
0
private static void loadVariables(CommandLine commandLine, StellarShellExecutor executor) throws IOException
{    if (commandLine.hasOption("v")) {                String variablePath = commandLine.getOptionValue("v");        Map<String, Object> variables = JSONUtils.INSTANCE.load(new File(variablePath), JSONUtils.MAP_SUPPLIER);                for (Map.Entry<String, Object> kv : variables.entrySet()) {            String variable = kv.getKey();            Object value = kv.getValue();                        executor.assign(variable, value, Optional.empty());        }    }}
0
private StellarShellExecutor createExecutor(CommandLine commandLine, Console console, Properties properties, StellarAutoCompleter autoCompleter) throws Exception
{        Optional<String> zookeeperUrl = Optional.empty();    if (commandLine.hasOption("z")) {        zookeeperUrl = Optional.of(commandLine.getOptionValue("z"));    }    StellarShellExecutor executor = new DefaultStellarShellExecutor(properties, zookeeperUrl);        executor.getContext().addCapability(CONSOLE, () -> console);        executor.getContext().addCapability(SHELL_VARIABLES, () -> executor.getState());        executor.addSpecialListener((special) -> autoCompleter.addCandidateFunction(special.getCommand()));    executor.addFunctionListener((function) -> autoCompleter.addCandidateFunction(function.getName()));    executor.addVariableListener((name, val) -> autoCompleter.addCandidateVariable(name));    executor.init();    return executor;}
0
private Console createConsole(CommandLine commandLine)
{        boolean useAnsi = !commandLine.hasOption("na");    SettingsBuilder settings = new SettingsBuilder().enableAlias(true).enableMan(true).ansi(useAnsi).parseOperators(false).inputStream(PausableInput.INSTANCE);    if (commandLine.hasOption("irc")) {        settings = settings.inputrc(new File(commandLine.getOptionValue("irc")));    }    return new Console(settings.create());}
0
private Properties getStellarProperties(CommandLine commandLine) throws IOException
{    Properties properties = new Properties();    if (commandLine.hasOption("p")) {                try (InputStream in = new FileInputStream(commandLine.getOptionValue("p"))) {            if (in != null) {                properties.load(in);            }        }    } else {                try (InputStream in = getClass().getClassLoader().getResourceAsStream(STELLAR_PROPERTIES_FILENAME)) {            if (in != null) {                properties.load(in);            }        }    }    return properties;}
0
public void run()
{        writeLine(WELCOME);        executor.getContext().getCapability(GLOBAL_CONFIG, false).ifPresent(conf -> writeLine(conf.toString()));    console.start();}
0
private void handleQuit()
{    try {        console.stop();        StellarFunctions.close();    } catch (Throwable e) {        e.printStackTrace();    }}
0
private void writeLine(String out)
{    console.getShell().out().println(out);}
0
public int execute(ConsoleOperation output) throws InterruptedException
{        String expression = StringUtils.trimToEmpty(output.getBuffer());    if (StringUtils.isNotBlank(expression)) {                StellarResult result = executor.execute(expression);        if (result.isSuccess()) {                        result.getValue().ifPresent(v -> writeLine(v.toString()));        } else if (result.isError()) {                        result.getException().ifPresent(e -> writeLine(ERROR_PROMPT + e.getMessage()));            result.getException().ifPresent(e -> e.printStackTrace());        } else if (result.isTerminate()) {                        handleQuit();        } else {                        throw new IllegalStateException("An execution result is neither a success nor a failure. Please file a bug report.");        }    }    return 0;}
0
public void complete(CompleteOperation completeOperation)
{    String buffer = completeOperation.getBuffer();    final String lastToken = getLastToken(buffer);    Iterable<String> candidates = autoCompleter.autoComplete(buffer);        if (candidates != null && !Iterables.isEmpty(candidates)) {        for (String candidate : candidates) {            String completion = stripOff(buffer, lastToken) + candidate;            completeOperation.addCompletionCandidate(completion);        }    }}
0
private static String getLastToken(String buffer)
{    String lastToken = Iterables.getLast(Splitter.on(" ").split(buffer), null);    return lastToken.trim();}
0
private static String stripOff(String baseString, String lastBit)
{    int index = baseString.lastIndexOf(lastBit);    if (index < 0) {        return baseString;    }    return baseString.substring(0, index);}
0
public StellarShellExecutor getExecutor()
{    return executor;}
0
public Console getConsole()
{    return console;}
0
public static void validateOptions(CommandLine commandLine) throws IllegalArgumentException
{    if (commandLine.hasOption('z')) {        validateZookeeperOption(commandLine.getOptionValue('z'));    }        if (commandLine.hasOption('v')) {        validateFileOption("v", commandLine.getOptionValue('v'));    }    if (commandLine.hasOption("irc")) {        validateFileOption("irc", commandLine.getOptionValue("irc"));    }    if (commandLine.hasOption('p')) {        validateFileOption("p", commandLine.getOptionValue('p'));    }}
0
private static void validateZookeeperOption(String zMulti) throws IllegalArgumentException
{    for (String z : Splitter.on(",").split(zMulti)) {        Matcher matcher = validPortPattern.matcher(z);        boolean hasPort = z.contains(":");        if (hasPort && !matcher.matches()) {            throw new IllegalArgumentException(String.format("Zookeeper option must have valid port: %s", z));        }        if (hasPort && matcher.groupCount() != 2) {            throw new IllegalArgumentException(String.format("Zookeeper Option must be in the form of [HOST|IP]:PORT  %s", z));        }        String name = hasPort ? matcher.group(1) : z;        Integer port = hasPort ? Integer.parseInt(matcher.group(2)) : null;        if (!hostnameValidator.test(name) && !inetAddressValidator.isValid(name)) {            throw new IllegalArgumentException(String.format("Zookeeper Option %s is not a valid host name or ip address  %s", name, z));        }        if (hasPort && (port == 0 || port > 65535)) {            throw new IllegalArgumentException(String.format("Zookeeper Option %s port is not valid", z));        }    }}
0
private static void validateFileOption(String option, String fileName) throws IllegalArgumentException
{    File file = new File(fileName);    if (!file.exists()) {        throw new IllegalArgumentException(String.format("%s: File %s doesn't exist", option, fileName));    }    if (!file.canRead()) {        throw new IllegalArgumentException(String.format("%s: File %s is not readable", option, fileName));    }}
0
public String transform(OperationType type, String key)
{    return transform.transform(type, key);}
0
public Iterable<String> autoComplete(String buffer)
{    Iterable<String> candidates = IterableUtils.emptyIterable();    final String lastToken = getLastToken(buffer);    if (StringUtils.isNotEmpty(lastToken)) {        if (isDoc(lastToken)) {            candidates = autoCompleteDoc(lastToken.substring(1));        } else if (isMagic(lastToken)) {            candidates = autoCompleteMagic(lastToken);        } else {            candidates = autoCompleteNormal(lastToken);        }    }    return candidates;}
0
private boolean isMagic(String expression)
{    return StringUtils.startsWith(expression, "%");}
0
private boolean isDoc(String expression)
{    return StringUtils.startsWith(expression, "?");}
0
private Iterable<String> autoCompleteNormal(String buffer)
{    return autoComplete(buffer, OperationType.NORMAL);}
0
private Iterable<String> autoCompleteDoc(String buffer)
{    return autoComplete(buffer, OperationType.DOC);}
0
private Iterable<String> autoCompleteMagic(String buffer)
{    return autoComplete(buffer, OperationType.MAGIC);}
0
private Iterable<String> autoComplete(String buffer, final OperationType opType)
{    indexLock.readLock().lock();    try {        SortedMap<String, AutoCompleteType> ret = autocompleteIndex.prefixMap(buffer);        if (ret.isEmpty()) {            return new ArrayList<>();        }        return Iterables.transform(ret.entrySet(), kv -> kv.getValue().transform(opType, kv.getKey()));    } finally {        indexLock.readLock().unlock();    }}
0
public void addCandidateFunction(String name)
{    add(name, AutoCompleteType.FUNCTION);}
0
public void addCandidateVariable(String name)
{    add(name, AutoCompleteType.VARIABLE);}
0
private void add(String name, AutoCompleteType type)
{    if (StringUtils.isNotBlank(name)) {                indexLock.writeLock().lock();        try {            this.autocompleteIndex.put(name, type);        } finally {            indexLock.writeLock().unlock();        }    }}
0
private PatriciaTrie<AutoCompleteType> initializeIndex()
{    Map<String, AutoCompleteType> index = new HashMap<>();    index.put("==", AutoCompleteType.TOKEN);    index.put(">=", AutoCompleteType.TOKEN);    index.put("<=", AutoCompleteType.TOKEN);    return new PatriciaTrie<>(index);}
0
private static String getLastToken(String buffer)
{    String lastToken = Iterables.getLast(Splitter.on(" ").split(buffer), null);    return lastToken.trim();}
0
public static List<SpecialCommand> defaultSpecials()
{    return Arrays.asList(new AssignmentCommand(), new DocCommand(), new QuitCommand(), new Comment(), new MagicListFunctions(), new MagicListVariables(), new MagicDefineGlobal(), new MagicUndefineGlobal(), new MagicListGlobals());}
0
public void init()
{    StellarFunctions.initialize(this.context);        for (SpecialCommand command : specials) {        notifySpecialListeners(command);    }        for (StellarFunctionInfo fn : functionResolver.getFunctionInfo()) {        notifyFunctionListeners(fn);    }}
0
public void addFunctionListener(FunctionDefinedListener listener)
{    this.functionListeners.add(listener);}
0
private void notifyFunctionListeners(StellarFunctionInfo functionInfo)
{    for (FunctionDefinedListener listener : functionListeners) {        listener.whenFunctionDefined(functionInfo);    }}
0
public void addVariableListener(VariableDefinedListener listener)
{    this.variableListeners.add(listener);}
0
private void notifyVariableListeners(String variableName, VariableResult result)
{    for (VariableDefinedListener listener : variableListeners) {        listener.whenVariableDefined(variableName, result);    }}
0
public void addSpecialListener(SpecialDefinedListener listener)
{    this.specialListeners.add(listener);}
0
private void notifySpecialListeners(SpecialCommand specialCommand)
{    for (SpecialDefinedListener listener : specialListeners) {        listener.whenSpecialDefined(specialCommand);    }}
0
public StellarResult execute(String expression)
{        expression = StringUtils.trimToEmpty(expression);    if (StringUtils.isBlank(expression)) {        return noop();    }        for (SpecialCommand command : specials) {        if (command.getMatcher().apply(expression)) {            return command.execute(expression, this);        }    }        return executeStellar(expression);}
0
public Map<String, Object> getGlobalConfig()
{    Map<String, Object> globals;    Optional<Object> capability = getContext().getCapability(GLOBAL_CONFIG, false);    if (capability.isPresent()) {        globals = (Map<String, Object>) capability.get();    } else {        throw new IllegalStateException("'GLOBAL_CONFIG' is missing");    }    return globals;}
0
public void assign(String variableName, Object value, Optional<String> expression)
{        VariableResult varResult = VariableResult.withExpression(value, expression);    this.variables.put(variableName, varResult);        notifyVariableListeners(variableName, varResult);}
0
public FunctionResolver getFunctionResolver()
{    return functionResolver;}
0
public Map<String, VariableResult> getState()
{    return UnmodifiableMap.decorate(variables);}
0
public Map<String, Object> getVariables()
{    return Maps.transformValues(variables, (v) -> v.getResult());}
0
public Context getContext()
{    return context;}
0
private Map<String, Object> fetchGlobalConfig(CuratorFramework zkClient) throws Exception
{    byte[] raw = readGlobalConfigBytesFromZookeeper(zkClient);    return JSONUtils.INSTANCE.load(new ByteArrayInputStream(raw), JSONUtils.MAP_SUPPLIER);}
0
private Map<String, Object> getStellarConfig(Map<String, Object> globalConfig, Properties props)
{    Map<String, Object> stellarConfig = new HashMap<>();    stellarConfig.putAll(globalConfig);    if (props != null) {        for (Map.Entry<Object, Object> kv : props.entrySet()) {            stellarConfig.put(kv.getKey().toString(), kv.getValue());        }    }    return stellarConfig;}
0
private StellarResult executeStellar(String expression)
{    StellarResult result;    try {                VariableResolver variableResolver = new MapVariableResolver(getVariables());        Object exprResult = new StellarProcessor().parse(expression, variableResolver, functionResolver, context);        result = success(exprResult);    } catch (Throwable t) {        result = error(t);    }    return result;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> StellarAssignment.isAssignment(input);}
0
public String getCommand()
{    return ASSIGNMENT_OP;}
0
public StellarResult execute(String input, StellarShellExecutor executor)
{    assert StellarAssignment.isAssignment(input);        StellarAssignment assignment = StellarAssignment.from(input);    String varName = assignment.getVariable();    String varExpr = assignment.getStatement();        StellarResult result = executor.execute(varExpr);    if (result.isSuccess()) {        Object value = null;        if (result.getValue().isPresent()) {            value = result.getValue().get();        } else if (result.isValueNull()) {            value = null;        }                executor.assign(varName, value, Optional.of(varExpr));        return result;    } else {        return result;    }}
0
public String getCommand()
{    return "#";}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> startsWith(trimToEmpty(input), COMMENT_PREFIX);}
0
public StellarResult execute(String expression, StellarShellExecutor executor)
{    return noop();}
0
public String getCommand()
{    return DOC_PREFIX;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> StringUtils.startsWith(input, DOC_PREFIX);}
0
public StellarResult execute(String command, StellarShellExecutor executor)
{    StellarResult result;        String functionName = StringUtils.substring(command, 1);        Spliterator<StellarFunctionInfo> fnIterator = executor.getFunctionResolver().getFunctionInfo().spliterator();    Optional<StellarFunctionInfo> functionInfo = StreamSupport.stream(fnIterator, false).filter(info -> StringUtils.equals(functionName, info.getName())).findFirst();    if (functionInfo.isPresent()) {        result = success(docFormat(functionInfo.get()));    } else {        result = error(String.format("No docs available for function '%s'", functionName));    }    return result;}
0
private String docFormat(StellarFunctionInfo info)
{    StringBuffer docString = new StringBuffer();        docString.append(info.getName() + "\n");        docString.append(String.format("Description: %-60s\n\n", info.getDescription()));        if (info.getParams().length > 0) {        docString.append("Arguments:\n");        for (String param : info.getParams()) {            docString.append(String.format("\t%-60s\n", param));        }        docString.append("\n");    }        docString.append(String.format("Returns: %-60s\n", info.getReturns()));    return docString.toString();}
0
public String getCommand()
{    return MAGIC_DEFINE;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> startsWith(trimToEmpty(input), MAGIC_DEFINE);}
0
public StellarResult execute(String command, StellarShellExecutor executor)
{        String assignExpr = StringUtils.trimToEmpty(command.substring(MAGIC_DEFINE.length()));    if (StringUtils.length(assignExpr) < 1) {        return error(MAGIC_DEFINE + " missing assignment expression");    }        if (!StellarAssignment.isAssignment(assignExpr)) {        return error(MAGIC_DEFINE + " expected assignment expression");    }        StellarAssignment expr = StellarAssignment.from(assignExpr);    StellarResult result = executor.execute(expr.getStatement());        if (!result.isSuccess()) {        return error(MAGIC_DEFINE + " expression execution failed");    }        if (!result.getValue().isPresent()) {        return error(MAGIC_DEFINE + " expression produced no result");    }        Object value = result.getValue().get();    executor.getGlobalConfig().put(expr.getVariable(), value);    return success(value);}
0
public String getCommand()
{    return MAGIC_FUNCTIONS;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> startsWith(trimToEmpty(input), MAGIC_FUNCTIONS);}
0
public StellarResult execute(String command, StellarShellExecutor executor)
{        String startsWith = StringUtils.trimToEmpty(command.substring(MAGIC_FUNCTIONS.length()));    Predicate<String> nameFilter = (name -> true);    if (StringUtils.isNotBlank(startsWith)) {        nameFilter = (name -> name.contains(startsWith));    }        String functions = StreamSupport.stream(executor.getFunctionResolver().getFunctionInfo().spliterator(), false).map(info -> String.format("%s", info.getName())).filter(nameFilter).sorted().collect(Collectors.joining(", "));    return StellarResult.success(functions);}
0
public String getCommand()
{    return MAGIC_GLOBALS;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> startsWith(trimToEmpty(input), MAGIC_GLOBALS);}
0
public StellarResult execute(String command, StellarShellExecutor executor)
{    Map<String, Object> globals = executor.getGlobalConfig();    return StellarResult.success(globals.toString());}
0
public String getCommand()
{    return MAGIC_VARS;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> startsWith(trimToEmpty(input), MAGIC_VARS);}
0
public StellarResult execute(String command, StellarShellExecutor executor)
{        String vars = executor.getState().entrySet().stream().map(e -> format(e)).collect(Collectors.joining(", "));    return success(vars);}
0
private String format(Map.Entry<String, VariableResult> var)
{        String out = String.format("%s = %s", var.getKey(), var.getValue().getResult());        if (var.getValue().getExpression().isPresent()) {        out += String.format(" via `%s`", var.getValue().getExpression().get());    }    return out;}
0
public String getCommand()
{    return MAGIC_UNDEFINE;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> startsWith(trimToEmpty(input), MAGIC_UNDEFINE);}
0
public StellarResult execute(String command, StellarShellExecutor executor)
{    StellarResult result;    String variable = StringUtils.trimToEmpty(command.substring(MAGIC_UNDEFINE.length()));    if (StringUtils.isNotBlank(variable)) {                Map<String, Object> globals = executor.getGlobalConfig();        globals.remove(variable);        result = noop();    } else {        result = error(String.format("%s expected name of global, got '%s'", MAGIC_UNDEFINE, variable));    }    return result;}
0
public String getCommand()
{    return QUIT_COMMAND;}
0
public Function<String, Boolean> getMatcher()
{    return (input) -> QUIT_COMMAND.equals(input);}
0
public StellarResult execute(String command, StellarShellExecutor executor)
{    return terminate();}
0
public static StellarResult success(Object value)
{    return new StellarResult(Status.SUCCESS, value);}
0
public static StellarResult error(Throwable exception)
{    return new StellarResult(Status.ERROR, exception);}
0
public static StellarResult error(String errorMessage)
{    return new StellarResult(Status.ERROR, new IllegalArgumentException(errorMessage));}
0
public static StellarResult noop()
{    return new StellarResult(Status.SUCCESS, "");}
0
public static StellarResult terminate()
{    return new StellarResult(Status.TERMINATE, "");}
0
public boolean isSuccess()
{    return status == Status.SUCCESS;}
0
public boolean isError()
{    return status == Status.ERROR;}
0
public boolean isTerminate()
{    return status == Status.TERMINATE;}
0
public boolean isValueNull()
{    return isValueNull;}
0
public Status getStatus()
{    return status;}
0
public Optional<Object> getValue()
{    return value;}
0
public Optional<Throwable> getException()
{    return exception;}
0
public String toString()
{    return "StellarResult{" + "status=" + status + ", value=" + value + ", exception=" + exception + ", isValueNull=" + isValueNull + '}';}
0
public static VariableResult withExpression(Object value, String expression)
{    return new VariableResult(Optional.of(expression), value);}
0
public static VariableResult withExpression(Object value, Optional<String> expression)
{    return new VariableResult(expression, value);}
0
public static VariableResult withValue(Object value)
{    return new VariableResult(Optional.empty(), value);}
0
public Optional<String> getExpression()
{    return expression;}
0
public Object getResult()
{    return result;}
0
public String toString()
{    String ret = "" + result;    if (getExpression().isPresent()) {        ret += " via " + expression.get();    }    return ret;}
0
public String getVariable()
{    return variable;}
0
public String getStatement()
{    return statement;}
0
public static boolean isAssignment(String statement)
{    return statement != null &&     statement.contains(":=") &&     !statement.trim().startsWith("%");}
0
public static StellarAssignment from(String statement)
{    if (statement == null || statement.length() == 0) {        return new StellarAssignment(null, null);    }    char prev = statement.charAt(0);    char curr;    String variable = "" + prev;    String s = null;    boolean isAssignment = false;    for (int i = 1; i < statement.length(); ++i, prev = curr) {        curr = statement.charAt(i);        if (prev == ':' && curr == '=') {            isAssignment = true;            variable = variable.substring(0, variable.length() - 1);            s = "";            continue;        }        if (!isAssignment) {            variable += curr;        } else {            s += curr;        }    }    if (!isAssignment) {        s = variable;        variable = null;    }    if (s != null) {        s = s.trim();    }    if (variable != null) {        variable = variable.trim();    }    return new StellarAssignment(variable, s);}
0
public String getKey()
{    return variable;}
0
public Object getValue()
{    return statement;}
0
public String setValue(Object value)
{    throw new UnsupportedOperationException("Assignments are immutable.");}
0
public void clear()
{    tokenDeque.clear();    variablesUsed.clear();    multiArgumentState.clear();}
0
public Deque<Token<?>> getTokenDeque()
{    return tokenDeque;}
0
private boolean isConditionalContext(Class<?> tokenValueType)
{    return tokenValueType != null && (tokenValueType == BooleanArg.class || tokenValueType == IfExpr.class || tokenValueType == MatchClauseCheckExpr.class);}
0
private boolean isEmptyList(Token<?> token, Object value)
{    if (value != null && isConditionalContext(token.getUnderlyingType())) {        if (value instanceof Iterable) {            return Iterables.isEmpty((Iterable) value);        } else if (value instanceof Map) {            return ((Map) value).isEmpty();        } else {            return false;        }    } else {        return false;    }}
0
private boolean isBoolean(Token<?> token, Object value)
{    if (token == null || token.getValue() == null) {        return false;    }    return value == null && isConditionalContext(token.getValue().getClass());}
0
public Object apply(ExpressionState state)
{    Deque<Token<?>> instanceDeque = new ArrayDeque<>();    {        int skipElseCount = 0;        boolean skipMatchClauses = false;        Token<?> token = null;        for (Iterator<Token<?>> it = getTokenDeque().descendingIterator(); it.hasNext(); ) {            token = it.next();                        if (skipElseCount > 0 && token.getUnderlyingType() == ElseExpr.class) {                while (it.hasNext()) {                    token = it.next();                    if (token.getUnderlyingType() == EndConditional.class) {                        break;                    }                }                                skipElseCount--;            }            if (skipMatchClauses && (token.getUnderlyingType() == MatchClauseEnd.class || token.getUnderlyingType() == MatchClauseCheckExpr.class)) {                while (it.hasNext()) {                    token = it.next();                    if (token.getUnderlyingType() == MatchClausesEnd.class) {                        break;                    }                }                skipMatchClauses = false;            }            /*          curr is the current value on the stack.  This is the non-deferred actual evaluation for this expression          and with the current context.           */            Token<?> curr = instanceDeque.peek();            boolean isFalsey = curr != null && (isBoolean(token, curr.getValue()) || isEmptyList(token, curr.getValue()));            if (isFalsey) {                                                                                curr = new Token<>(false, Boolean.class, curr.getMultiArgContext());                instanceDeque.removeFirst();                instanceDeque.addFirst(curr);            }            if (curr != null && curr.getValue() != null && curr.getValue() instanceof Boolean && ShortCircuitOp.class.isAssignableFrom(token.getUnderlyingType())) {                                if (token.getUnderlyingType() == BooleanArg.class) {                    if (token.getMultiArgContext() != null && token.getMultiArgContext().getVariety() == FrameContext.BOOLEAN_OR && (Boolean) (curr.getValue())) {                                                FrameContext.Context context = curr.getMultiArgContext();                        shortCircuit(it, context);                    } else if (token.getMultiArgContext() != null && token.getMultiArgContext().getVariety() == FrameContext.BOOLEAN_AND && !(Boolean) (curr.getValue())) {                                                FrameContext.Context context = curr.getMultiArgContext();                        shortCircuit(it, context);                    }                } else if (token.getUnderlyingType() == IfExpr.class) {                                        instanceDeque.pop();                    if ((Boolean) curr.getValue()) {                                                skipElseCount++;                    } else {                                                                        int innerIfCount = 0;                        while (it.hasNext()) {                            Token<?> t = it.next();                            if (t.getUnderlyingType() == IfExpr.class) {                                innerIfCount++;                            } else if (t.getUnderlyingType() == ElseExpr.class) {                                if (innerIfCount == 0) {                                    break;                                } else {                                    innerIfCount--;                                }                            }                        }                    }                } else if (token.getUnderlyingType() == MatchClauseCheckExpr.class) {                    instanceDeque.pop();                    if ((Boolean) curr.getValue()) {                                                skipMatchClauses = true;                    } else {                        while (it.hasNext()) {                            Token<?> t = it.next();                            if (t.getUnderlyingType() == MatchClauseEnd.class) {                                break;                            }                        }                    }                }            }            if (token.getUnderlyingType() == DeferredFunction.class) {                DeferredFunction func = (DeferredFunction) token.getValue();                func.apply(instanceDeque, state);            } else if (token.getUnderlyingType() != ShortCircuitFrame.class && !ShortCircuitOp.class.isAssignableFrom(token.getUnderlyingType())) {                instanceDeque.push(token);            }        }    }    if (instanceDeque.isEmpty()) {        throw new ParseException("Invalid predicate: Empty stack.");    }    Token<?> token = instanceDeque.pop();    if (instanceDeque.isEmpty()) {        return token.getValue();    }    if (instanceDeque.isEmpty()) {        throw new ParseException("Invalid parse, stack not empty: " + Joiner.on(',').join(instanceDeque));    } else {        throw new ParseException("Invalid parse, found " + token);    }}
0
public void shortCircuit(Iterator<Token<?>> it, FrameContext.Context context)
{    while (it.hasNext()) {        Token<?> token = it.next();        if (token.getUnderlyingType() == ShortCircuitFrame.class && token.getMultiArgContext() == context) {            break;        }    }}
0
public void enterTransformation(StellarParser.TransformationContext ctx)
{    expression.clear();}
0
private boolean handleIn(final Token<?> left, final Token<?> right)
{    Object key = right.getValue();    if (left.getValue() != null) {        if (left.getValue() instanceof String && key instanceof String) {            return ((String) left.getValue()).contains(key.toString());        } else if (left.getValue() instanceof Collection) {            return ((Collection) left.getValue()).contains(key);        } else if (left.getValue() instanceof Map) {            return ((Map) left.getValue()).containsKey(key);        } else {            if (key == null) {                return key == left.getValue();            } else {                return key.equals(left.getValue());            }        }    } else {        return false;    }}
0
public void exitNullConst(StellarParser.NullConstContext ctx)
{    expression.tokenDeque.push(new Token<>(null, Object.class, getArgContext()));}
0
public void exitNaNArith(StellarParser.NaNArithContext ctx)
{    expression.tokenDeque.push(new Token<>(Double.NaN, Double.class, getArgContext()));}
0
public void exitArithExpr_plus(StellarParser.ArithExpr_plusContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Pair<Token<? extends Number>, Token<? extends Number>> p = getArithExpressionPair(tokenDeque);        tokenDeque.push(arithmeticEvaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(context), p));    }, DeferredFunction.class, context));}
0
public void exitArithExpr_minus(StellarParser.ArithExpr_minusContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Pair<Token<? extends Number>, Token<? extends Number>> p = getArithExpressionPair(tokenDeque);        tokenDeque.push(arithmeticEvaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.subtraction(context), p));    }, DeferredFunction.class, context));}
0
public void exitArithExpr_div(StellarParser.ArithExpr_divContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Pair<Token<? extends Number>, Token<? extends Number>> p = getArithExpressionPair(tokenDeque);        tokenDeque.push(arithmeticEvaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(context), p));    }, DeferredFunction.class, context));}
0
public void exitArithExpr_mul(StellarParser.ArithExpr_mulContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Pair<Token<? extends Number>, Token<? extends Number>> p = getArithExpressionPair(tokenDeque);        tokenDeque.push(arithmeticEvaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.multiplication(context), p));    }, DeferredFunction.class, context));}
0
private Pair<Token<? extends Number>, Token<? extends Number>> getArithExpressionPair(Deque<Token<?>> tokenDeque)
{    Token<? extends Number> right = (Token<? extends Number>) popDeque(tokenDeque);    Token<? extends Number> left = (Token<? extends Number>) popDeque(tokenDeque);    return Pair.of(left, right);}
0
public void exitIf_expr(StellarParser.If_exprContext ctx)
{    expression.tokenDeque.push(new Token<>(new IfExpr(), IfExpr.class, getArgContext()));}
0
public void enterThen_expr(StellarParser.Then_exprContext ctx)
{    expression.tokenDeque.push(new Token<>(new ThenExpr(), ThenExpr.class, getArgContext()));}
0
public void enterElse_expr(StellarParser.Else_exprContext ctx)
{    expression.tokenDeque.push(new Token<>(new ElseExpr(), ElseExpr.class, getArgContext()));}
0
public void exitElse_expr(StellarParser.Else_exprContext ctx)
{    expression.tokenDeque.push(new Token<>(new EndConditional(), EndConditional.class, getArgContext()));}
0
public void exitInExpressionStatement(StellarParser.InExpressionStatementContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Token<?> left = popDeque(tokenDeque);        Token<?> right = popDeque(tokenDeque);        tokenDeque.push(new Token<>(handleIn(left, right), Boolean.class, context));    }, DeferredFunction.class, context));}
0
public void exitNInExpressionStatement(StellarParser.NInExpressionStatementContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Token<?> left = popDeque(tokenDeque);        Token<?> right = popDeque(tokenDeque);        tokenDeque.push(new Token<>(!handleIn(left, right), Boolean.class, context));    }, DeferredFunction.class, context));}
0
public void exitNotFunc(StellarParser.NotFuncContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Token<Boolean> arg = (Token<Boolean>) popDeque(tokenDeque);        Boolean v = Optional.ofNullable(ConversionUtils.convert(arg.getValue(), Boolean.class)).orElse(false);        tokenDeque.push(new Token<>(!v, Boolean.class, context));    }, DeferredFunction.class, context));}
0
public void exitVariable(StellarParser.VariableContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        String varName = ctx.getText();        if (state.context.getActivityType().equals(ActivityType.PARSE_ACTIVITY) && !state.variableResolver.exists(varName)) {                        throw new ParseException(String.format("variable: %s is not defined", varName));        }        Object resolved = state.variableResolver.resolve(varName);        tokenDeque.push(new Token<>(resolved, Object.class, context));    }, DeferredFunction.class, context));    expression.variablesUsed.add(ctx.getText());}
0
public void exitStringLiteral(StellarParser.StringLiteralContext ctx)
{    String rawToken = ctx.getText();    String literal = StringEscapeUtils.UNESCAPE_JSON.translate(rawToken);    expression.tokenDeque.push(new Token<>(literal.substring(1, literal.length() - 1), String.class, getArgContext()));}
0
public void exitIntLiteral(StellarParser.IntLiteralContext ctx)
{    expression.tokenDeque.push(numberLiteralEvaluator.evaluate(ctx, getArgContext()));}
0
public void exitDoubleLiteral(StellarParser.DoubleLiteralContext ctx)
{    expression.tokenDeque.push(numberLiteralEvaluator.evaluate(ctx, getArgContext()));}
0
public void exitFloatLiteral(StellarParser.FloatLiteralContext ctx)
{    expression.tokenDeque.push(numberLiteralEvaluator.evaluate(ctx, getArgContext()));}
0
public void exitLongLiteral(StellarParser.LongLiteralContext ctx)
{    expression.tokenDeque.push(numberLiteralEvaluator.evaluate(ctx, getArgContext()));}
0
public void enterB_expr(StellarParser.B_exprContext ctx)
{        if (ctx.getParent() instanceof StellarParser.LogicalExpressionOrContext) {        expression.multiArgumentState.push(FrameContext.BOOLEAN_OR.create());    } else if (ctx.getParent() instanceof StellarParser.LogicalExpressionAndContext) {        expression.multiArgumentState.push(FrameContext.BOOLEAN_AND.create());    }}
0
public void exitB_expr(StellarParser.B_exprContext ctx)
{    if (ctx.getParent() instanceof StellarParser.LogicalExpressionOrContext || ctx.getParent() instanceof StellarParser.LogicalExpressionAndContext) {                expression.tokenDeque.push(new Token<>(new BooleanArg(), BooleanArg.class, getArgContext()));    }}
0
public void exitLogicalExpressionAnd(StellarParser.LogicalExpressionAndContext ctx)
{    final FrameContext.Context context = getArgContext();    popArgContext();    final FrameContext.Context parentContext = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Token<?> left = popDeque(tokenDeque);        Token<?> right = popDeque(tokenDeque);        tokenDeque.push(new Token<>(booleanOp(left, right, (l, r) -> l && r, "&&"), Boolean.class, parentContext));    }, DeferredFunction.class, context));    expression.tokenDeque.push(new Token<>(new ShortCircuitFrame(), ShortCircuitFrame.class, context));}
0
public void exitLogicalExpressionOr(StellarParser.LogicalExpressionOrContext ctx)
{    final FrameContext.Context context = getArgContext();    popArgContext();    final FrameContext.Context parentContext = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Token<?> left = popDeque(tokenDeque);        Token<?> right = popDeque(tokenDeque);        tokenDeque.push(new Token<>(booleanOp(left, right, (l, r) -> l || r, "||"), Boolean.class, parentContext));    }, DeferredFunction.class, context));    expression.tokenDeque.push(new Token<>(new ShortCircuitFrame(), ShortCircuitFrame.class, context));}
0
public void exitLogicalConst(StellarParser.LogicalConstContext ctx)
{    Boolean b;    switch(ctx.getText().toUpperCase()) {        case "TRUE":            b = true;            break;        case "FALSE":            b = false;            break;        default:            throw new ParseException("Unable to process " + ctx.getText() + " as a boolean constant");    }    expression.tokenDeque.push(new Token<>(b, Boolean.class, getArgContext()));}
0
private boolean booleanOp(final Token<?> left, final Token<?> right, final BooleanOp op, final String opName)
{    Boolean l = Optional.ofNullable(ConversionUtils.convert(left.getValue(), Boolean.class)).orElse(false);    Boolean r = Optional.ofNullable(ConversionUtils.convert(right.getValue(), Boolean.class)).orElse(false);    return op.op(l, r);}
0
public void enterSingle_lambda_variable(StellarParser.Single_lambda_variableContext ctx)
{    enterLambdaVariables();}
0
public void exitSingle_lambda_variable(StellarParser.Single_lambda_variableContext ctx)
{    exitLambdaVariables();}
0
public void enterLambda_variables(StellarParser.Lambda_variablesContext ctx)
{    enterLambdaVariables();}
0
public void exitLambda_variables(StellarParser.Lambda_variablesContext ctx)
{    exitLambdaVariables();}
0
public void exitLambda_variable(StellarParser.Lambda_variableContext ctx)
{    expression.tokenDeque.push(new Token<>(ctx.getText(), String.class, getArgContext()));}
0
private void enterLambdaVariables()
{    expression.tokenDeque.push(LAMBDA_VARIABLES);}
0
private void exitLambdaVariables()
{    Token<?> t = expression.tokenDeque.pop();    LinkedList<String> variables = new LinkedList<>();    for (; !expression.tokenDeque.isEmpty() && t != LAMBDA_VARIABLES; t = expression.tokenDeque.pop()) {        variables.addFirst(t.getValue().toString());    }    expression.tokenDeque.push(new Token<>(variables, List.class, getArgContext()));}
0
private void enterLambda()
{    expression.tokenDeque.push(EXPRESSION_REFERENCE);}
0
private void exitLambda(boolean hasArgs)
{    final FrameContext.Context context = getArgContext();    Token<?> t = expression.tokenDeque.pop();    final Deque<Token<?>> instanceDeque = new ArrayDeque<>();    for (; !expression.tokenDeque.isEmpty() && t != EXPRESSION_REFERENCE; t = expression.tokenDeque.pop()) {        instanceDeque.addLast(t);    }    final List<String> variables = hasArgs ? (List<String>) instanceDeque.removeLast().getValue() : new ArrayList<>();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        LambdaExpression expr = new LambdaExpression(variables, instanceDeque, state);        tokenDeque.push(new Token<>(expr, Object.class, context));    }, DeferredFunction.class, context));}
0
public void enterLambda_with_args(StellarParser.Lambda_with_argsContext ctx)
{    enterLambda();}
0
public void exitLambda_with_args(StellarParser.Lambda_with_argsContext ctx)
{    exitLambda(true);}
0
public void enterLambda_without_args(StellarParser.Lambda_without_argsContext ctx)
{    enterLambda();}
0
public void exitLambda_without_args(StellarParser.Lambda_without_argsContext ctx)
{    exitLambda(false);}
0
public void exitTransformationFunc(StellarParser.TransformationFuncContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {                String functionName = ctx.getChild(0).getText();        StellarFunction function = resolveFunction(state.functionResolver, functionName);        initializeFunction(state.context, function, functionName);                List<Object> args = getFunctionArguments(popDeque(tokenDeque));        Object result = function.apply(args, state.context);        tokenDeque.push(new Token<>(result, Object.class, context));    }, DeferredFunction.class, context));}
0
private List<Object> getFunctionArguments(final Token<?> token)
{    if (token.getUnderlyingType().equals(List.class)) {        return (List<Object>) token.getValue();    } else {        throw new ParseException("Unable to process in clause because " + token.getValue() + " is not a set");    }}
0
private StellarFunction resolveFunction(FunctionResolver functionResolver, String funcName)
{    try {        return functionResolver.apply(funcName);    } catch (Exception e) {        String valid = Joiner.on(',').join(functionResolver.getFunctions());        String error = format("Unable to resolve function named '%s'.  Valid functions are %s", funcName, valid);        throw new ParseException(error, e);    }}
0
private void initializeFunction(Context context, StellarFunction function, String functionName)
{    try {        if (!function.isInitialized()) {            function.initialize(context);        }    } catch (Throwable t) {        String error = format("Unable to initialize function '%s'", functionName);        throw new ParseException(error, t);    }}
0
public void exitExistsFunc(StellarParser.ExistsFuncContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        String variable = ctx.getChild(2).getText();        boolean exists = state.variableResolver.resolve(variable) != null;        tokenDeque.push(new Token<>(exists, Boolean.class, context));    }, DeferredFunction.class, context));    String variable = ctx.getChild(2).getText();    expression.variablesUsed.add(variable);}
0
public void enterFunc_args(StellarParser.Func_argsContext ctx)
{    expression.tokenDeque.push(new Token<>(new FunctionMarker(), FunctionMarker.class, getArgContext()));}
0
public void exitFunc_args(StellarParser.Func_argsContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        LinkedList<Object> args = new LinkedList<>();        while (true) {            Token<?> token = popDeque(tokenDeque);            if (token.getUnderlyingType().equals(FunctionMarker.class)) {                break;            } else {                args.addFirst(token.getValue());            }        }        tokenDeque.push(new Token<>(args, List.class, context));    }, DeferredFunction.class, context));}
0
public void enterMap_entity(StellarParser.Map_entityContext ctx)
{    expression.tokenDeque.push(new Token<>(new FunctionMarker(), FunctionMarker.class, getArgContext()));}
0
public void exitMap_entity(StellarParser.Map_entityContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        HashMap<Object, Object> args = new HashMap<>();        Object value = null;        for (int i = 0; true; i++) {            Token<?> token = popDeque(tokenDeque);            if (token.getUnderlyingType().equals(FunctionMarker.class)) {                break;            } else {                if (i % 2 == 0) {                    value = token.getValue();                } else {                    args.put(token.getValue(), value);                }            }        }        tokenDeque.push(new Token<>(args, Map.class, context));    }, DeferredFunction.class, context));}
0
public void exitList_entity(StellarParser.List_entityContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        LinkedList<Object> args = new LinkedList<>();        while (true) {            Token<?> token = popDeque(tokenDeque);            if (token.getUnderlyingType().equals(FunctionMarker.class)) {                break;            } else {                args.addFirst(token.getValue());            }        }        tokenDeque.push(new Token<>(args, List.class, context));    }, DeferredFunction.class, context));}
0
public void exitDefault(StellarParser.DefaultContext ctx)
{    expression.tokenDeque.push(new Token<>(true, Boolean.class, getArgContext()));}
0
public void exitMatchClauseCheckExpr(StellarParser.MatchClauseCheckExprContext ctx)
{    final FrameContext.Context context = getArgContext();        if (ctx.getStart() == ctx.getStop()) {        expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {            if (tokenDeque.size() == 1 && (tokenDeque.peek().getValue() == null || tokenDeque.peek().getUnderlyingType() == Boolean.class)) {                tokenDeque.pop();                tokenDeque.add(new Token<>(false, Boolean.class, getArgContext()));            }        }, DeferredFunction.class, context));    }    expression.tokenDeque.push(new Token<>(new MatchClauseCheckExpr(), MatchClauseCheckExpr.class, getArgContext()));}
0
public void exitMatchClauseAction(StellarParser.MatchClauseActionContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        Token<?> token = popDeque(tokenDeque);        Object value = token.getValue();        if (value != null && LambdaExpression.class.isAssignableFrom(value.getClass())) {            LambdaExpression expr = (LambdaExpression) value;                                                                        Object result = expr.apply(new ArrayList<>());            tokenDeque.push(new Token<>(result, Object.class, context));        } else {            tokenDeque.push(new Token<>(value, Object.class, context));        }    }, DeferredFunction.class, context));}
0
public void exitMatch_clause(StellarParser.Match_clauseContext ctx)
{    expression.tokenDeque.push(new Token<>(new MatchClauseEnd(), MatchClauseEnd.class, getArgContext()));}
0
public void exitMatchClauses(StellarParser.MatchClausesContext ctx)
{    expression.tokenDeque.push(new Token<>(new MatchClausesEnd(), MatchClausesEnd.class, getArgContext()));}
0
public void exitComparisonExpressionWithOperator(StellarParser.ComparisonExpressionWithOperatorContext ctx)
{    final FrameContext.Context context = getArgContext();    expression.tokenDeque.push(new Token<>((tokenDeque, state) -> {        StellarParser.Comp_operatorContext op = ctx.comp_operator();        Token<?> right = popDeque(tokenDeque);        Token<?> left = popDeque(tokenDeque);        tokenDeque.push(comparisonExpressionWithOperatorEvaluator.evaluate(left, right, (StellarParser.ComparisonOpContext) op, context));    }, DeferredFunction.class, context));}
0
public void enterList_entity(StellarParser.List_entityContext ctx)
{    expression.tokenDeque.push(new Token<>(new FunctionMarker(), FunctionMarker.class, getArgContext()));}
0
private void popArgContext()
{    if (!expression.multiArgumentState.isEmpty()) {        expression.multiArgumentState.pop();    }}
0
private FrameContext.Context getArgContext()
{    return expression.multiArgumentState.isEmpty() ? null : expression.multiArgumentState.peek();}
0
private Token<?> popDeque(Deque<Token<?>> tokenDeque)
{    if (tokenDeque.isEmpty()) {        throw new ParseException("Unable to pop an empty stack");    }    return tokenDeque.pop();}
0
public Expression getExpression()
{    return expression;}
0
public Boolean parse(String rule, VariableResolver variableResolver, FunctionResolver functionResolver, Context context)
{    if (rule == null || isEmpty(rule.trim())) {        return true;    }    try {        return super.parse(rule, variableResolver, functionResolver, context);    } catch (ClassCastException e) {                throw new IllegalArgumentException(String.format("The rule '%s' does not return a boolean value.", rule), e);    } catch (Exception e) {        if (e.getCause() != null && e.getCause() instanceof ClassCastException) {            throw new IllegalArgumentException(String.format("The rule '%s' does not return a boolean value.", rule), e.getCause());        }        throw e;    }}
0
public long currentTimeMillis()
{    return System.currentTimeMillis();}
0
public String currentTimeFormatted(String stdDateFormat)
{    SimpleDateFormat format = new SimpleDateFormat(stdDateFormat);    format.setTimeZone(TimeZone.getTimeZone(UTC));    return format.format(new Date(currentTimeMillis()));}
0
public String get(String variable)
{    return System.getenv().get(variable);}
0
public void funnel(T obj, PrimitiveSink primitiveSink)
{    primitiveSink.putBytes(serializer.apply(obj));}
0
public boolean equals(Object obj)
{    return this.getClass().equals(obj.getClass());}
0
public int hashCode()
{    return super.hashCode() * 31;}
0
public byte[] apply(T t)
{    return SerDeUtils.toBytes(t);}
0
public boolean mightContain(T key)
{    return filter.mightContain(key);}
0
public void add(T key)
{    filter.put(key);}
0
public void merge(BloomFilter<T> filter2)
{    filter.putAll(filter2.filter);}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    BloomFilter<?> that = (BloomFilter<?>) o;    return filter != null ? filter.equals(that.filter) : that.filter == null;}
0
public int hashCode()
{    return filter != null ? filter.hashCode() : 0;}
0
public Optional<Object> getValue(OPT_T option, CommandLine cli)
{    return Optional.empty();}
0
public int size()
{    int size = 0;    for (Map m : variableMappings) {        size += m.size();    }    return size;}
0
public boolean isEmpty()
{    boolean isEmpty = true;    for (Map m : variableMappings) {        isEmpty &= m.isEmpty();    }    return isEmpty;}
0
public boolean containsKey(Object key)
{    for (Map m : variableMappings) {        if (m.containsKey(key)) {            return true;        }    }    return false;}
0
public boolean containsValue(Object value)
{    for (Map m : variableMappings) {        if (m.containsValue(value)) {            return true;        }    }    return false;}
0
public Object get(Object key)
{    Object ret = null;    for (Map m : variableMappings) {        ret = m.get(key);        if (ret != null) {            break;        }    }    return ret;}
0
public Object put(String key, Object value)
{    throw new UnsupportedOperationException("Merged map is immutable.");}
0
public Object remove(Object key)
{    throw new UnsupportedOperationException("Merged map is immutable.");}
0
public void putAll(Map<? extends String, ?> m)
{    throw new UnsupportedOperationException("Merged map is immutable.");}
0
public void clear()
{    throw new UnsupportedOperationException("Merged map is immutable.");}
0
public Set<String> keySet()
{    Set<String> ret = null;    for (Map m : variableMappings) {        if (ret == null) {            ret = m.keySet();        } else {            ret = Sets.union(ret, m.keySet());        }    }    return ret;}
0
public Collection<Object> values()
{    Collection<Object> ret = new ArrayList<>(size());    for (Map m : variableMappings) {        ret.addAll(m.values());    }    return ret;}
0
public Set<Entry<String, Object>> entrySet()
{    Set<Entry<String, Object>> ret = null;    for (Map m : variableMappings) {        if (ret == null) {            ret = m.entrySet();        } else {            ret = Sets.union(ret, m.entrySet());        }    }    return ret;}
0
public String toString()
{    Iterable<Iterable<Map.Entry<Object, Object>>> transformed = Iterables.transform(variableMappings, x -> x.entrySet());    Iterable<Map.Entry<Object, Object>> it = Iterables.filter(Iterables.concat(transformed), x -> x.getValue() != null);    return "{" + Joiner.on(", ").join(it) + "}";}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ConcatMap concatMap = (ConcatMap) o;    return variableMappings != null ? variableMappings.equals(concatMap.variableMappings) : concatMap.variableMappings == null;}
0
public int hashCode()
{    return variableMappings != null ? variableMappings.hashCode() : 0;}
0
public void write(Kryo kryo, Output output)
{    int numVariableMappings = variableMappings.isEmpty() ? 0 : variableMappings.size();    output.writeShort(numVariableMappings);    for (Map m : variableMappings) {        byte[] b = m == null ? new byte[] {} : SerDeUtils.toBytes(m);        output.writeInt(b.length);        if (b.length > 0) {            output.writeBytes(b);        }    }}
0
public void read(Kryo kryo, Input input)
{    int numVariableMappings = input.readShort();    variableMappings = new ArrayList<>(numVariableMappings);    for (int i = 0; i < numVariableMappings; ++i) {        int size = input.readInt();        if (size > 0) {            byte[] bytes = input.readBytes(size);            Map m = SerDeUtils.fromBytes(bytes, Map.class);            variableMappings.add(m);        }    }}
0
protected ConvertUtilsBean initialValue()
{    ConvertUtilsBean ret = BeanUtilsBean2.getInstance().getConvertUtils();    ret.deregister();    ret.register(false, true, 1);    return ret;}
0
public static T convert(Object o, Class<T> clazz)
{    if (o == null) {        return null;    }    return clazz.cast(UTILS_BEAN.get().convert(o, clazz));}
0
public static List<U> convertList(List<T> from, Class<U> clazz)
{    return Lists.transform(from, s -> convert(s, clazz));}
0
public static Map<K, V2> convertMap(Map<K, V1> from, Class<V2> clazz)
{    return Maps.transformValues(from, s -> convert(s, clazz));}
0
public String getKey()
{    return key;}
0
public String getHash(final Object toHash) throws EncoderException, NoSuchAlgorithmException
{    final MessageDigest messageDigest = MessageDigest.getInstance(algorithm);    if (toHash == null) {        return StringUtils.repeat("00", messageDigest.getDigestLength());    } else if (toHash instanceof String) {        return getHash(messageDigest, toHash.toString().getBytes(charset));    } else if (toHash instanceof Serializable) {        final byte[] serialized = SerializationUtils.serialize((Serializable) toHash);        return getHash(messageDigest, serialized);    }    return null;}
0
private String getHash(final MessageDigest messageDigest, final byte[] toHash) throws EncoderException
{    messageDigest.update(toHash);    final byte[] encode = encoder.encode(messageDigest.digest());    return new String(encode, charset);}
0
public void configure(Optional<Map<String, Object>> config)
{    if (config.isPresent() && !config.get().isEmpty()) {        charset = Config.CHARSET.get(config.get(), o -> {            String charset = ConversionUtils.convert(o, String.class);            if (charset != null) {                Charset set = Charset.forName(charset);                return set;            }            return null;        }).orElse(charset);    }}
0
public static final Set<String> supportedHashes()
{    return new HashSet<>(Security.getAlgorithms("MessageDigest"));}
0
 Optional<T> get(Map<String, Object> config, Function<Object, T> converter)
{    Object o = config.get(getKey());    return o == null ? Optional.empty() : Optional.ofNullable(converter.apply(o));}
0
public static Hasher getHasher(String algorithm, Optional<Map<String, Object>> config)
{    Hasher h = null;    for (HashStrategy factory : HashStrategy.values()) {        if (factory.getSupportedHashes().contains(algorithm.toUpperCase())) {            h = factory.hasherCreator.apply(algorithm);            break;        }    }    if (h == null) {        throw new IllegalArgumentException("Unsupported hash function: " + algorithm + ".  Supported algorithms are " + Joiner.on(",").join(ALL_SUPPORTED_HASHES));    }    h.configure(config);    return h;}
0
public Set<String> getSupportedHashes()
{    return supportedHashes;}
0
public String apply(byte[] data, boolean force)
{    try {        creator.update(data);        return creator.getHash(force).getEncoded();    } finally {        creator.reset();    }}
0
public static int distance(String hash1, String hash2, Optional<Boolean> includeLength)
{    if (hash1 == null || hash2 == null) {        return -1;    }    if (hash1.equals(hash2)) {        return 0;    }    Tlsh t1 = Tlsh.fromTlshStr(hash1);    Tlsh t2 = Tlsh.fromTlshStr(hash2);    return t1.totalDiff(t2, includeLength.orElse(false));}
0
public TLSH getTLSH(BucketOption bo, ChecksumOption co)
{    return cache.computeIfAbsent(new AbstractMap.SimpleEntry<>(bo, co), kv -> new TLSH(kv.getKey(), kv.getValue()));}
0
public String getKey()
{    return key;}
0
public Object getHash(Object o) throws EncoderException, NoSuchAlgorithmException
{    TLSH tlsh = TLSHCache.INSTANCE.get().getTLSH(bucketOption, checksumOption);    byte[] data = null;    if (o instanceof String) {        data = ((String) o).getBytes(StandardCharsets.UTF_8);    } else if (o instanceof byte[]) {        data = (byte[]) o;    } else {        data = SerDeUtils.toBytes(o);    }    try {        String hash = tlsh.apply(data, force);        if (hashes != null && hashes.size() > 0) {            Map<String, Object> ret = new HashMap<>();            ret.put(TLSH_KEY, hash);            ret.putAll(bin(hash));            return ret;        } else {            return hash;        }    } catch (Exception e) {        return null;    }}
0
public Map<String, String> bin(String hash) throws DecoderException
{    Random r = new Random(0);    byte[] h = Hex.decodeHex(hash.substring(2 * checksumOption.getChecksumLength()).toCharArray());    BitSet vector = BitSet.valueOf(h);    int n = vector.length();    Map<String, String> ret = new HashMap<>();    boolean singleHash = hashes.size() == 1;    for (int numHashes : hashes) {        BitSet projection = new BitSet();        for (int i = 0; i < numHashes; ++i) {            int index = r.nextInt(n);            projection.set(i, vector.get(index));        }        String outputHash = numHashes + Hex.encodeHexString(projection.toByteArray());        if (singleHash) {            ret.put(TLSH_BIN_KEY, outputHash);        } else {            ret.put(TLSH_BIN_KEY + "_" + numHashes, outputHash);        }    }    return ret;}
0
public void configure(Optional<Map<String, Object>> config)
{    if (config.isPresent() && !config.get().isEmpty()) {        bucketOption = Config.BUCKET_SIZE.get(config.get(), o -> {            Integer bucketSize = ConversionUtils.convert(o, Integer.class);            switch(bucketSize) {                case 128:                    return BucketOption.BUCKETS_128;                case 256:                    return BucketOption.BUCKETS_256;                default:                    return null;            }        }).orElse(bucketOption);        checksumOption = Config.CHECKSUM.get(config.get(), o -> {            Integer checksumBytes = ConversionUtils.convert(o, Integer.class);            switch(checksumBytes) {                case 1:                    return ChecksumOption.CHECKSUM_1B;                case 3:                    return ChecksumOption.CHECKSUM_3B;                default:                    return null;            }        }).orElse(checksumOption);        force = Config.FORCE.get(config.get(), o -> ConversionUtils.convert(o, Boolean.class)).orElse(force);        hashes = Config.HASHES.get(config.get(), o -> {            List<Integer> ret = new ArrayList<>();            if (o instanceof List) {                List<? extends Object> vals = (List<? extends Object>) o;                for (Object oVal : vals) {                    ret.add(ConversionUtils.convert(oVal, Integer.class));                }            } else {                ret.add(ConversionUtils.convert(o, Integer.class));            }            return ret;        }).orElse(hashes);    }}
0
public static final Set<String> supportedHashes()
{    return new HashSet<String>() {        {            add("TLSH");        }    };}
0
public TypeReference<T> get()
{    return new TypeReference<T>() {        @Override        public Type getType() {            return type;        }    };}
0
public Type getType()
{    return type;}
0
public T load(InputStream is, ReferenceSupplier<T> ref) throws IOException
{    return _mapper.get().readValue(is, (TypeReference<T>) ref.get());}
0
public T load(String is, ReferenceSupplier<T> ref) throws IOException
{    return _mapper.get().readValue(is, (TypeReference<T>) ref.get());}
0
public T load(File f, ReferenceSupplier<T> ref) throws IOException
{    try (InputStream is = new BufferedInputStream(new FileInputStream(f))) {        return _mapper.get().readValue(is, (TypeReference<T>) ref.get());    }}
0
public T load(InputStream is, Class<T> clazz) throws IOException
{    return _mapper.get().readValue(is, clazz);}
0
public T load(File f, Class<T> clazz) throws IOException
{    try (InputStream is = new BufferedInputStream(new FileInputStream(f))) {        return _mapper.get().readValue(is, clazz);    }}
0
public T load(String is, Class<T> clazz) throws IOException
{    return _mapper.get().readValue(is, clazz);}
0
public String toJSON(Object o, boolean pretty) throws JsonProcessingException
{    if (pretty) {        return _mapper.get().writerWithDefaultPrettyPrinter().writeValueAsString(o);    } else {        return _mapper.get().writeValueAsString(o);    }}
0
public byte[] toJSON(Object config) throws JsonProcessingException
{    return _mapper.get().writeValueAsBytes(config);}
0
public JSONObject toJSONObject(Object o) throws JsonProcessingException, ParseException
{    return toJSONObject(toJSON(o, false));}
0
public JSONObject toJSONObject(String json) throws ParseException
{    return (JSONObject) _parser.get().parse(json);}
0
public int getMaxArgs()
{    return maxArgs;}
0
public int getMinArgs()
{    return minArgs;}
0
public Function<Number[], Number> getOperation()
{    return operation;}
0
public Number apply(Number[] numbers)
{    return f.apply(numbers[0].doubleValue());}
0
public Number apply(Number[] numbers)
{    return f.apply(numbers[0].doubleValue(), numbers[1].doubleValue());}
0
public Number apply(Number[] in)
{    return op.getOperation().apply(in);}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    if (args.size() < _func.getMinArgs()) {        return Double.NaN;    }    Number[] nums = new Number[_func.getMaxArgs()];    for (int i = 0; i < _func.getMaxArgs(); ++i) {        nums[i] = (Number) args.get(i);        if (nums[i] == null) {            return Double.NaN;        }    }    Object ret = _func.getOperation().apply(nums);    return ret;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Pattern getPattern(String patternString)
{    Pattern pattern = _cache.get().get(patternString);    if (pattern == null) {        pattern = Pattern.compile(patternString);        _cache.get().put(patternString, pattern);    }    return pattern;}
0
protected Kryo initialValue()
{    Kryo ret = new Kryo();    ret.setReferences(true);    ret.setInstantiatorStrategy(new DefaultInstantiatorStrategy(new StdInstantiatorStrategy()));    ret.register(Arrays.asList("").getClass(), new ArraysAsListSerializer());    ret.register(Collections.EMPTY_LIST.getClass(), new CollectionsEmptyListSerializer());    ret.register(Collections.EMPTY_MAP.getClass(), new CollectionsEmptyMapSerializer());    ret.register(Collections.EMPTY_SET.getClass(), new CollectionsEmptySetSerializer());    ret.register(Collections.singletonList("").getClass(), new CollectionsSingletonListSerializer());    ret.register(Collections.singleton("").getClass(), new CollectionsSingletonSetSerializer());    ret.register(Collections.singletonMap("", "").getClass(), new CollectionsSingletonMapSerializer());    ret.register(GregorianCalendar.class, new GregorianCalendarSerializer());    ret.register(InvocationHandler.class, new JdkProxySerializer());    UnmodifiableCollectionsSerializer.registerSerializers(ret);    SynchronizedCollectionsSerializer.registerSerializers(ret);            ret.register(CGLibProxySerializer.CGLibProxyMarker.class, new CGLibProxySerializer());        ret.register(LocalDate.class, new JodaLocalDateSerializer());    ret.register(LocalDateTime.class, new JodaLocalDateTimeSerializer());        ImmutableListSerializer.registerSerializers(ret);    ImmutableSetSerializer.registerSerializers(ret);    ImmutableMapSerializer.registerSerializers(ret);    ImmutableMultimapSerializer.registerSerializers(ret);    return ret;}
0
public void setFallbackInstantiatorStrategy(final InstantiatorStrategy fallbackStrategy)
{    this.fallbackStrategy = fallbackStrategy;}
0
public InstantiatorStrategy getFallbackInstantiatorStrategy()
{    return fallbackStrategy;}
0
public ObjectInstantiator newInstantiatorOf(final Class type)
{    if (!Util.isAndroid) {                Class enclosingType = type.getEnclosingClass();        boolean isNonStaticMemberClass = enclosingType != null && type.isMemberClass() && !Modifier.isStatic(type.getModifiers());        if (!isNonStaticMemberClass) {            try {                final ConstructorAccess access = ConstructorAccess.get(type);                return new ObjectInstantiator() {                    @Override                    public Object newInstance() {                        try {                            return access.newInstance();                        } catch (Exception ex) {                            throw new KryoException("Error constructing instance of class: " + className(type), ex);                        }                    }                };            } catch (Exception ignored) {            }        }    }        try {        Constructor ctor;        try {            ctor = type.getConstructor((Class[]) null);        } catch (Exception ex) {            ctor = type.getDeclaredConstructor((Class[]) null);            ctor.setAccessible(true);        }        final Constructor constructor = ctor;        return new ObjectInstantiator() {            @Override            public Object newInstance() {                try {                    return constructor.newInstance();                } catch (Exception ex) {                    throw new KryoException("Error constructing instance of class: " + className(type), ex);                }            }        };    } catch (Exception ignored) {    }    if (fallbackStrategy == null) {        if (type.isMemberClass() && !Modifier.isStatic(type.getModifiers()))            throw new KryoException("Class cannot be created (non-static member class): " + className(type));        else            throw new KryoException("Class cannot be created (missing no-arg constructor): " + className(type));    }        return fallbackStrategy.newInstantiatorOf(type);}
0
public Object newInstance()
{    try {        return access.newInstance();    } catch (Exception ex) {        throw new KryoException("Error constructing instance of class: " + className(type), ex);    }}
0
public Object newInstance()
{    try {        return constructor.newInstance();    } catch (Exception ex) {        throw new KryoException("Error constructing instance of class: " + className(type), ex);    }}
0
public byte[] apply(Object o)
{    return toBytes(o);}
0
public T apply(byte[] bytes)
{    return fromBytes(bytes, clazz);}
0
public static byte[] toBytes(Object value)
{    try {        ByteArrayOutputStream bos = new ByteArrayOutputStream();        Output output = new Output(bos);        kryo.get().writeClassAndObject(output, value);        output.flush();        bos.flush();        return bos.toByteArray();    } catch (Throwable t) {                throw new IllegalStateException("Unable to serialize " + value + " because " + t.getMessage(), t);    }}
1
public static T fromBytes(byte[] value, Class<T> clazz)
{    try {        Input input = new Input(new ByteArrayInputStream(value));        return clazz.cast(kryo.get().readClassAndObject(input));    } catch (Throwable t) {                throw t;    }}
1
public static Object run(String expression, VariableResolver varResolver, Context context)
{    validate(expression, context);    Object result = execute(expression, varResolver, context);    ensureKryoSerializable(result, expression);    ensureJavaSerializable(result, expression);    return result;}
0
public static Object run(String expression, Map<String, Object> variables, Context context)
{    VariableResolver varResolver = new DefaultVariableResolver(x -> {        if (x.equals(MapVariableResolver.ALL_FIELDS)) {            return variables;        }        return variables.get(x);    }, x -> x.equals(MapVariableResolver.ALL_FIELDS) || variables.containsKey(x));    return run(expression, varResolver, context);}
0
private static Object execute(String expression, VariableResolver variableResolver, Context context)
{    StellarProcessor processor = new StellarProcessor();    Object result = processor.parse(expression, variableResolver, StellarFunctions.FUNCTION_RESOLVER(), context);    return result;}
0
private static void ensureKryoSerializable(Object value, String expression)
{    String msg = String.format("Expression result is not Kryo serializable. It is highly recommended for all " + "functions to return a result that is Kryo serializable to allow for their broadest possible use. " + "expr=%s, value=%s", expression, value);    byte[] raw = SerDeUtils.toBytes(value);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    Assert.assertEquals(msg, value, actual);}
0
private static void ensureJavaSerializable(Object value, String expression)
{    String msg = String.format("Expression result is not Java serializable. It is highly recommended for all " + "functions to return a result that is Java serializable to allow for their broadest possible use. " + "expr=%s, value=%s", expression, value);    try {                ByteArrayOutputStream bytes = new ByteArrayOutputStream();        ObjectOutputStream out = new ObjectOutputStream(bytes);        out.writeObject(value);                byte[] raw = bytes.toByteArray();        assertTrue(raw.length > 0);                ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(raw));        Object actual = in.readObject();                assertEquals(msg, value, actual);    } catch (IOException | ClassNotFoundException e) {        String error = String.format("Expression result is not Java serializable. It is highly recommended for all " + "functions to return a result that is Java serializable to allow for their broadest possible use. " + "expr=%s, value=%s, error=%s", expression, value, ExceptionUtils.getRootCauseMessage(e));        fail(error);    }}
0
public static Object run(String expression, Map<String, Object> variables)
{    return run(expression, variables, Context.EMPTY_CONTEXT());}
0
public static Object run(String expression, VariableResolver variables)
{    return run(expression, variables, Context.EMPTY_CONTEXT());}
0
public static Object run(String expression, Context context)
{    return run(expression, Collections.emptyMap(), context);}
0
public static void validate(String expression, Context context)
{    StellarProcessor processor = new StellarProcessor();    Assert.assertTrue("Invalid expression; expr=" + expression, processor.validate(expression, context));}
0
public static void validate(String rule)
{    validate(rule, Context.EMPTY_CONTEXT());}
0
public static boolean runPredicate(String rule, Map resolver)
{    return runPredicate(rule, resolver, Context.EMPTY_CONTEXT());}
0
public static boolean runPredicate(String rule, Map resolver, Context context)
{    return runPredicate(rule, new MapVariableResolver(resolver), context);}
0
public static boolean runPredicate(String rule, VariableResolver resolver)
{    return runPredicate(rule, resolver, Context.EMPTY_CONTEXT());}
0
public static boolean runPredicate(String rule, VariableResolver resolver, Context context)
{    StellarPredicateProcessor processor = new StellarPredicateProcessor();    Assert.assertTrue(rule + " not valid.", processor.validate(rule));    return processor.parse(rule, resolver, StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public static void runWithArguments(String function, Object argument, Object expected)
{    runWithArguments(function, ImmutableList.of(argument), expected);}
0
public static void runWithArguments(String function, List<Object> arguments, Object expected)
{    Supplier<Stream<Map.Entry<String, Object>>> kvStream = () -> StreamSupport.stream(new XRange(arguments.size()), false).map(i -> new AbstractMap.SimpleImmutableEntry<>("var" + i, arguments.get(i)));    String args = kvStream.get().map(kv -> kv.getKey()).collect(Collectors.joining(","));    Map<String, Object> variables = kvStream.get().collect(Collectors.toMap(kv -> kv.getKey(), kv -> kv.getValue()));    String stellarStatement = function + "(" + args + ")";    String reason = stellarStatement + " != " + expected + " with variables: " + variables;    if (expected instanceof Double) {        Assert.assertEquals(reason, (Double) expected, (Double) run(stellarStatement, variables), 1e-6);    } else {        Assert.assertEquals(reason, expected, run(stellarStatement, variables));    }}
0
public boolean tryAdvance(IntConsumer action)
{    boolean isDone = i >= end;    if (isDone) {        return false;    } else {        action.accept(i);        i++;        return true;    }}
0
public boolean tryAdvance(Consumer<? super Integer> action)
{    boolean isDone = i >= end;    if (isDone) {        return false;    } else {        action.accept(i);        i++;        return true;    }}
0
public static FileSystemManager generateVfs() throws FileSystemException
{    DefaultFileSystemManager vfs = new DefaultFileSystemManager();    vfs.addProvider("res", new org.apache.commons.vfs2.provider.res.ResourceFileProvider());    vfs.addProvider("zip", new org.apache.commons.vfs2.provider.zip.ZipFileProvider());    vfs.addProvider("gz", new org.apache.commons.vfs2.provider.gzip.GzipFileProvider());    vfs.addProvider("ram", new org.apache.commons.vfs2.provider.ram.RamFileProvider());    vfs.addProvider("file", new org.apache.commons.vfs2.provider.local.DefaultLocalFileProvider());    vfs.addProvider("jar", new org.apache.commons.vfs2.provider.jar.JarFileProvider());    vfs.addProvider("http", new org.apache.commons.vfs2.provider.http.HttpFileProvider());    vfs.addProvider("https", new org.apache.commons.vfs2.provider.https.HttpsFileProvider());    vfs.addProvider("ftp", new org.apache.commons.vfs2.provider.ftp.FtpFileProvider());    vfs.addProvider("ftps", new org.apache.commons.vfs2.provider.ftps.FtpsFileProvider());    vfs.addProvider("war", new org.apache.commons.vfs2.provider.jar.JarFileProvider());    vfs.addProvider("par", new org.apache.commons.vfs2.provider.jar.JarFileProvider());    vfs.addProvider("ear", new org.apache.commons.vfs2.provider.jar.JarFileProvider());    vfs.addProvider("sar", new org.apache.commons.vfs2.provider.jar.JarFileProvider());    vfs.addProvider("ejb3", new org.apache.commons.vfs2.provider.jar.JarFileProvider());    vfs.addProvider("tmp", new org.apache.commons.vfs2.provider.temp.TemporaryFileProvider());    vfs.addProvider("tar", new org.apache.commons.vfs2.provider.tar.TarFileProvider());    vfs.addProvider("tbz2", new org.apache.commons.vfs2.provider.tar.TarFileProvider());    vfs.addProvider("tgz", new org.apache.commons.vfs2.provider.tar.TarFileProvider());    vfs.addProvider("bz2", new org.apache.commons.vfs2.provider.bzip2.Bzip2FileProvider());    vfs.addProvider("hdfs", new HdfsFileProvider());    vfs.addExtensionMap("jar", "jar");    vfs.addExtensionMap("zip", "zip");    vfs.addExtensionMap("gz", "gz");    vfs.addExtensionMap("tar", "tar");    vfs.addExtensionMap("tbz2", "tar");    vfs.addExtensionMap("tgz", "tar");    vfs.addExtensionMap("bz2", "bz2");    vfs.addMimeTypeMap("application/x-tar", "tar");    vfs.addMimeTypeMap("application/x-gzip", "gz");    vfs.addMimeTypeMap("application/zip", "zip");    vfs.setFileContentInfoFactory(new FileContentInfoFilenameFactory());    vfs.setFilesCache(new SoftRefFilesCache());    vfs.setReplicator(new UniqueFileReplicator(new File(System.getProperty("java.io.tmpdir"))));    vfs.setCacheStrategy(CacheStrategy.ON_RESOLVE);    vfs.init();    return vfs;}
0
public static Optional<ClassLoader> configureClassloader(String paths) throws FileSystemException
{        if (paths.trim().isEmpty()) {                return Optional.empty();    }    FileSystemManager vfs = generateVfs();    FileObject[] objects = resolve(vfs, paths);    if (objects == null || objects.length == 0) {                return Optional.empty();    }        return Optional.of(new VFSClassLoader(objects, vfs, vfs.getClass().getClassLoader()));}
1
 static FileObject[] resolve(FileSystemManager vfs, String uris) throws FileSystemException
{    if (uris == null) {        return new FileObject[0];    }    ArrayList<FileObject> classpath = new ArrayList<>();    for (String path : uris.split(",")) {        path = path.trim();        if (path.equals("")) {            continue;        }        FileObject fo = vfs.resolveFile(path);        switch(fo.getType()) {            case FILE:            case FOLDER:                classpath.add(fo);                break;            case IMAGINARY:                                String pattern = fo.getName().getBaseName();                if (fo.getParent() != null && fo.getParent().getType() == FileType.FOLDER) {                    FileObject[] children = fo.getParent().getChildren();                    for (FileObject child : children) {                        if (child.getType() == FileType.FILE && child.getName().getBaseName().matches(pattern)) {                            classpath.add(child);                        }                    }                } else {                                    }                break;            default:                                break;        }    }    return classpath.toArray(new FileObject[classpath.size()]);}
1
public Object apply(List<Object> args, Context context) throws ParseException
{    return apply(args);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Builder with(String s, Capability capability)
{    capabilityMap.put(s, capability);    return this;}
0
public Builder with(Enum<?> s, Capability capability)
{    capabilityMap.put(s.toString(), capability);    return this;}
0
public Builder withAll(Map<String, Object> externalConfig)
{    for (Map.Entry<String, Object> entry : externalConfig.entrySet()) {        capabilityMap.put(entry.getKey(), () -> entry.getValue());    }    return this;}
0
public Context build()
{    return new Context(capabilityMap);}
0
public static Context EMPTY_CONTEXT()
{    return new Context(new HashMap<>()) {    };}
0
public Optional<Object> getCapability(Enum<?> capability)
{    return getCapability(capability, true);}
0
public Optional<Object> getCapability(Enum<?> capability, boolean errorIfNotThere)
{    return getCapability(capability.toString(), errorIfNotThere);}
0
public Optional<Object> getCapability(String capability)
{    return getCapability(capability, true);}
0
public Optional<Object> getCapability(String capability, boolean errorIfNotThere)
{    Capability c = capabilities.get(capability);    if (c == null && errorIfNotThere) {        throw new IllegalStateException("Unable to find capability " + capability + "; it may not be available in your context.");    } else if (c == null) {        return Optional.empty();    }    return Optional.ofNullable(c.get());}
0
public void addCapability(String s, Capability capability)
{    this.capabilities.put(s, capability);}
0
public void addCapability(Enum<?> s, Capability capability)
{    this.capabilities.put(s.toString(), capability);}
0
public ActivityType getActivityType()
{    return _activityType.get();}
0
public void setActivityType(ActivityType activityType)
{    _activityType.set(activityType);}
0
public Object resolve(String variable)
{    return resolveFunc.apply(variable);}
0
public boolean exists(String variable)
{    return existsFunc.apply(variable);}
0
public static DefaultVariableResolver NULL_RESOLVER()
{    return new DefaultVariableResolver(x -> null, x -> false);}
0
public void syntaxError(Recognizer<?, ?> recognizer, Object offendingSymbol, int line, int charPositionInLine, String msg, RecognitionException e)
{    throw new ParseException("Syntax error @ " + line + ":" + charPositionInLine + " " + msg, e);}
0
public void reportAmbiguity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, boolean exact, BitSet ambigAlts, ATNConfigSet configs)
{}
0
public void reportAttemptingFullContext(Parser recognizer, DFA dfa, int startIndex, int stopIndex, BitSet conflictingAlts, ATNConfigSet configs)
{}
0
public void reportContextSensitivity(Parser recognizer, DFA dfa, int startIndex, int stopIndex, int prediction, ATNConfigSet configs)
{}
0
public Object apply(List<Object> strings)
{    return strings.get(0) == null ? null : ConversionUtils.convert(strings.get(0), clazz);}
0
public Object apply(List<Object> args)
{    BloomFilter<Object> filter = (BloomFilter) args.get(0);    for (int i = 1; i < args.size(); ++i) {        Object arg = args.get(i);        if (arg != null) {            filter.add(args.get(i));        }    }    return filter;}
0
public Object apply(List<Object> args)
{    if (args.size() == 0) {        return false;    }    BloomFilter<Object> filter = (BloomFilter) args.get(0);    if (args.size() > 1) {        Object arg = args.get(1);        if (arg == null) {            return false;        }        return filter.mightContain(arg);    }    return false;}
0
public Object apply(List<Object> args)
{    int expectedInsertions = 100000;    float falsePositiveRate = 0.01f;    if (args.size() > 1) {        expectedInsertions = ConversionUtils.convert(args.get(0), Integer.class);    }    if (args.size() > 2) {        falsePositiveRate = ConversionUtils.convert(args.get(1), Float.class);    }    return new BloomFilter<>(SerDeUtils.SERIALIZER, expectedInsertions, falsePositiveRate);}
0
public Object apply(List<Object> args)
{    if (args.size() > 0) {        Object firstArg = args.get(0);        if (firstArg instanceof List) {            BloomFilter ret = null;            for (Object bf : (List) firstArg) {                if (bf instanceof BloomFilter) {                    if (ret == null) {                        ret = (BloomFilter) bf;                    } else {                        ret.merge((BloomFilter) bf);                    }                }            }            return ret;        } else {            return null;        }    }    return null;}
0
public Object apply(List<Object> list)
{    if (null == list || list.size() == 0) {        return true;    }    Object o = list.get(0);    if (o instanceof Collection) {        return ((Collection) o).isEmpty();    } else if (o instanceof String) {        String val = (String) list.get(0);        return val == null || val.isEmpty() ? true : false;    } else if (o instanceof Map) {        return (((Map) o).isEmpty());    } else {        return o == null;    }}
0
public Object apply(List<Object> list)
{    if (list.size() == 0) {        return null;    }    Object o = list.get(0);    if (list.size() == 1) {        return o;    }    if (o instanceof List) {        List l = (List) o;        Object arg = list.get(1);        l.add(arg);        return l;    } else {        return o;    }}
0
public Object apply(List<Object> list)
{    if (list.size() == 0) {        return 0;    }    Object o = list.get(0);    if (o instanceof Collection) {        return ((Collection) o).size();    } else if (o instanceof Map) {        return ((Map) o).size();    } else if (o instanceof String) {        String val = (String) list.get(0);        return val == null || val.isEmpty() ? 0 : val.length();    } else {        return 0;    }}
0
public SimpleDateFormat toDateFormat()
{    return createFormat(format, timezone);}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    TimezonedFormat that = (TimezonedFormat) o;    if (format != null ? !format.equals(that.format) : that.format != null)        return false;    return timezone != null ? timezone.equals(that.timezone) : that.timezone == null;}
0
public int hashCode()
{    int result = format != null ? format.hashCode() : 0;    result = 31 * result + (timezone != null ? timezone.hashCode() : 0);    return result;}
0
public ThreadLocal<SimpleDateFormat> load(final TimezonedFormat format) throws Exception
{    return new ThreadLocal<SimpleDateFormat>() {        @Override        public SimpleDateFormat initialValue() {            return format.toDateFormat();        }    };}
0
public SimpleDateFormat initialValue()
{    return format.toDateFormat();}
0
public static SimpleDateFormat createFormat(String format, Optional<String> timezone)
{    SimpleDateFormat sdf = new SimpleDateFormat(format);    if (timezone.isPresent()) {        sdf.setTimeZone(TimeZone.getTimeZone(timezone.get()));    }    return sdf;}
0
public static long getEpochTime(String date, String format, Optional<String> timezone) throws ExecutionException, ParseException
{    TimezonedFormat fmt;    if (timezone.isPresent()) {        fmt = new TimezonedFormat(format, timezone.get());    } else {        fmt = new TimezonedFormat(format);    }    SimpleDateFormat sdf = formatCache.get(fmt).get();    return sdf.parse(date).getTime();}
0
public static String getDateFormat(String format, Optional<Long> epochTime, Optional<String> timezone)
{    Long time = epochTime.orElseGet(System::currentTimeMillis);    TimezonedFormat fmt = timezone.map(s -> new TimezonedFormat(format, s)).orElseGet(() -> new TimezonedFormat(format));    SimpleDateFormat sdf = formatCache.get(fmt).get();    return sdf.format(new Date(time));}
0
public Object apply(List<Object> objects)
{    Object dateObj = objects.get(0);    Object formatObj = objects.get(1);    Object tzObj = null;    if (objects.size() >= 3) {        tzObj = objects.get(2);    }    if (dateObj != null && formatObj != null) {        try {            Optional<String> tz = (tzObj == null) ? Optional.empty() : Optional.of(tzObj.toString());            return getEpochTime(dateObj.toString(), formatObj.toString(), tz);        } catch (ExecutionException | ParseException e) {            return null;        }    }    return null;}
0
public Object apply(List<Object> objects)
{    int size = objects.size();    Optional<Object> formatObj = Optional.ofNullable(objects.get(0));    Optional<Long> epochObj = Optional.empty();    Optional<String> tzObj = Optional.empty();    if (size > 1) {        if (size == 2) {            if (objects.get(1) == null) {                return null;            }            epochObj = objects.get(1) instanceof Long ? Optional.of((Long) objects.get(1)) : Optional.empty();            tzObj = objects.get(1) instanceof String ? Optional.of((String) objects.get(1)) : Optional.empty();        } else {            epochObj = Optional.ofNullable((Long) objects.get(1));            tzObj = Optional.ofNullable((String) objects.get(2));        }    }    if (formatObj.isPresent()) {        return getDateFormat(formatObj.get().toString(), epochObj, tzObj);    } else {        return null;    }}
0
private static T getOrDefault(List<Object> args, int position, Class<T> clazz, T defaultValue)
{    T result = defaultValue;    if (args.size() > position) {        result = ConversionUtils.convert(args.get(position), clazz);    }    return result;}
0
public Object apply(List<Object> args)
{        Long epochMillis = getOrDefault(args, 0, Long.class, System.currentTimeMillis());    if (epochMillis == null) {                return null;    }        Calendar calendar = Calendar.getInstance();    calendar.setTimeInMillis(epochMillis);    return calendar.get(Calendar.DAY_OF_WEEK);}
0
public Object apply(List<Object> args)
{        Long epochMillis = getOrDefault(args, 0, Long.class, System.currentTimeMillis());    if (epochMillis == null) {                return null;    }        Calendar calendar = Calendar.getInstance();    calendar.setTimeInMillis(epochMillis);    return calendar.get(Calendar.DAY_OF_MONTH);}
0
public Object apply(List<Object> args)
{        Long epochMillis = getOrDefault(args, 0, Long.class, System.currentTimeMillis());    if (epochMillis == null) {                return null;    }        Calendar calendar = Calendar.getInstance();    calendar.setTimeInMillis(epochMillis);    return calendar.get(Calendar.WEEK_OF_MONTH);}
0
public Object apply(List<Object> args)
{        Long epochMillis = getOrDefault(args, 0, Long.class, System.currentTimeMillis());    if (epochMillis == null) {                return null;    }        Calendar calendar = Calendar.getInstance();    calendar.setTimeInMillis(epochMillis);    return calendar.get(Calendar.WEEK_OF_YEAR);}
0
public Object apply(List<Object> args)
{        Long epochMillis = getOrDefault(args, 0, Long.class, System.currentTimeMillis());    if (epochMillis == null) {                return null;    }        Calendar calendar = Calendar.getInstance();    calendar.setTimeInMillis(epochMillis);    return calendar.get(Calendar.MONTH);}
0
public Object apply(List<Object> args)
{        Long epochMillis = getOrDefault(args, 0, Long.class, System.currentTimeMillis());    if (epochMillis == null) {                return null;    }        Calendar calendar = Calendar.getInstance();    calendar.setTimeInMillis(epochMillis);    return calendar.get(Calendar.YEAR);}
0
public Object apply(List<Object> args)
{        Long epochMillis = getOrDefault(args, 0, Long.class, System.currentTimeMillis());    if (epochMillis == null) {                return null;    }        Calendar calendar = Calendar.getInstance();    calendar.setTimeInMillis(epochMillis);    return calendar.get(Calendar.DAY_OF_YEAR);}
0
public Object apply(List<Object> list)
{    return Encodings.SUPPORTED_LIST;}
0
public Object apply(List<Object> list)
{    if (list.size() < 2) {        throw new IllegalStateException("IS_ENCODING expects two args: [string, encoding] where encoding is one from " + "the supported list");    }    String str = (String) list.get(0);    String encoding = (String) list.get(1);    if (StringUtils.isEmpty(str) || StringUtils.isEmpty(encoding)) {        return false;    }    Encodings enc = null;    try {        enc = Encodings.valueOf(encoding.toUpperCase());    } catch (IllegalArgumentException iae) {        throw new IllegalStateException(String.format("Encoding %s not supported", encoding), iae);    }    return enc.is(str);}
0
public Object apply(List<Object> list)
{    if (list.size() != 2 && list.size() != 3) {        throw new IllegalStateException("DECODE expects two or three args: [string, encoding] or " + "[string, encoding, verify] where encoding is one from " + "the supported list");    }    Boolean verify = false;    String str = (String) list.get(0);    String encoding = (String) list.get(1);    if (list.size() == 3) {        verify = (Boolean) list.get(2);    }    if (StringUtils.isEmpty(str) || StringUtils.isEmpty(encoding)) {        return null;    }    Encodings enc = null;    try {        enc = Encodings.valueOf(encoding.toUpperCase());    } catch (IllegalArgumentException iae) {        throw new IllegalStateException(String.format("Encoding %s not supported", encoding), iae);    }    return enc.decode(str, verify);}
0
public Object apply(List<Object> list)
{    if (list.size() != 2 && list.size() != 3) {        throw new IllegalStateException("ENCODE expects two or three args: [string, encoding] where encoding is one from " + "the supported list");    }    String str = (String) list.get(0);    String encoding = (String) list.get(1);    if (StringUtils.isEmpty(str) || StringUtils.isEmpty(encoding)) {        return null;    }    Encodings enc = null;    try {        enc = Encodings.valueOf(encoding.toUpperCase());    } catch (IllegalArgumentException iae) {        throw new IllegalStateException(String.format("Encoding %s not supported", encoding), iae);    }    return enc.encode(str);}
0
public Object apply(List<Object> args)
{    Iterable<? extends Object> input = getIterable(args.get(0));    LambdaExpression expression = (LambdaExpression) args.get(1);    if (input == null || expression == null) {        return input;    }    List<Object> ret = new ArrayList<>();    for (Object o : input) {        ret.add(expression.apply(listOf(o)));    }    return ret;}
0
public Object apply(List<Object> args)
{    Iterable<? extends Object> input = getIterable(args.get(0));    LambdaExpression expression = (LambdaExpression) args.get(1);    if (input == null || expression == null) {        return input;    }    List<Object> ret = new ArrayList<>();    for (Object o : input) {        Object result = expression.apply(listOf(o));        if (result != null && result instanceof Boolean && (Boolean) result) {            ret.add(o);        }    }    return ret;}
0
public Object apply(List<Object> args)
{    Iterable<? extends Object> input = getIterable(args.get(0));    if (input == null || args.size() < 3) {        return null;    }    LambdaExpression expression = (LambdaExpression) args.get(1);    Object runningResult = args.get(2);    if (expression == null || runningResult == null) {        return null;    }    for (Object rhs : input) {        runningResult = expression.apply(listOf(runningResult, rhs));    }    return runningResult;}
0
private static Iterable<? extends Object> getIterable(Object o)
{    if (o == null) {        return null;    }    if (o instanceof String) {        return Lists.charactersOf((String) o);    } else if (o instanceof Iterable) {        return (Iterable<Object>) o;    } else {        throw new IllegalArgumentException(o.getClass() + " is not an iterable, and therefore cannot be used.");    }}
0
public Object apply(List<Object> args)
{    if (args == null || args.size() == 0) {        return new ArrayList<>();    }    return zip(args, true);}
0
public Object apply(List<Object> args)
{    if (args == null || args.size() == 0) {        return new ArrayList<>();    }    return zip(args, false);}
0
private static List<List<Object>> zip(List<Object> args, boolean jagged)
{    List<List<Object>> lists = new ArrayList<>();    Integer resultSize = null;    for (Object o : args) {        if (o instanceof List) {            List<Object> l = (List<Object>) o;            if (resultSize == null) {                resultSize = l.size();            } else if (jagged) {                resultSize = Math.max(l.size(), resultSize);            } else {                resultSize = Math.min(l.size(), resultSize);            }            lists.add(l);        }    }    if (resultSize == null) {        return new ArrayList<>();    }    return IntStream.range(0, resultSize).mapToObj(i -> {        List<Object> o = new ArrayList<>();        for (List<Object> list : lists) {            o.add(i < list.size() ? list.get(i) : null);        }        return o;    }).collect(Collectors.toList());}
0
private static List<Object> listOf(Object... vals)
{    List<Object> ret = new ArrayList<>(vals.length);    for (int i = 0; i < vals.length; ++i) {        ret.add(vals[i]);    }    return ret;}
0
public List<String> apply(final List<Object> args)
{    if (args == null || args.size() != 0) {        throw new IllegalArgumentException("Invalid call. This function does not expect any arguments.");    }    List<String> ret = new ArrayList<>();    ret.addAll(HashStrategy.ALL_SUPPORTED_HASHES);    return ret;}
0
public Object apply(final List<Object> args)
{    if (args == null || args.size() < 2) {        throw new IllegalArgumentException("Invalid number of arguments: " + (args == null ? 0 : args.size()));    }    final Object toHash = args.get(0);    final Object hashType = args.get(1);    if (hashType == null) {        return null;    }    Map<String, Object> config = null;    if (args.size() > 2) {        Object configObj = args.get(2);        if (configObj instanceof Map && configObj != null) {            config = (Map<String, Object>) configObj;        }    }    try {        return HashStrategy.getHasher(hashType.toString(), Optional.ofNullable(config)).getHash(toHash);    } catch (final EncoderException e) {        return null;    } catch (final NoSuchAlgorithmException e) {        throw new IllegalArgumentException("Invalid hash type: " + hashType.toString());    }}
0
public Integer apply(final List<Object> args)
{    if (args == null || args.size() < 2) {        throw new IllegalArgumentException("Invalid call. This function requires at least 2 arguments: the two TLSH hashes.");    }    Object h1Obj = args.get(0);    Object h2Obj = args.get(1);    if (h1Obj != null && !(h1Obj instanceof String)) {        throw new IllegalArgumentException(h1Obj + " must be strings");    }    if (h2Obj != null && !(h2Obj instanceof String)) {        throw new IllegalArgumentException(h2Obj + " must be strings");    }    Optional<Boolean> includeLength = Optional.empty();    if (args.size() > 2) {        Object includeLengthArg = args.get(2);        if (includeLengthArg != null) {            includeLength = Optional.ofNullable(ConversionUtils.convert(includeLengthArg, Boolean.class));        }    }    return TLSH.distance(h1Obj == null ? null : h1Obj.toString(), h2Obj == null ? null : h2Obj.toString(), includeLength);}
0
public Object apply(List<Object> list)
{    if (list.size() < 2) {        return false;    }    Object key = list.get(0);    Object mapObj = list.get(1);    if (key != null && mapObj != null && mapObj instanceof Map) {        return ((Map) mapObj).containsKey(key);    }    return false;}
0
public Object apply(List<Object> objects)
{    Object keyObj = objects.get(0);    Object mapObj = objects.get(1);    Object defaultObj = null;    if (objects.size() >= 3) {        defaultObj = objects.get(2);    }    if (keyObj == null || mapObj == null) {        return defaultObj;    }    Map<Object, Object> map = (Map) mapObj;    Object ret = map.get(keyObj);    if (ret == null && defaultObj != null) {        return defaultObj;    }    return ret;}
0
public Object apply(List<Object> objects)
{    if (objects.size() < 3) {        throw new IllegalArgumentException("Must pass a key, value, and map");    } else {        Object keyObj = objects.get(0);        Object valueObj = objects.get(1);        Object mapObj = objects.get(2);        if (mapObj == null) {            mapObj = new HashMap<>();        }        Map<Object, Object> map = (Map) mapObj;        map.put(keyObj, valueObj);        return map;    }}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashMap<Object, Object> ret = new LinkedHashMap<>();    Object o = list.get(0);    if (o != null) {        if (!(o instanceof Iterable)) {            throw new IllegalArgumentException("Expected an Iterable, but " + o + " is of type " + o.getClass());        }        Iterable<? extends Map> maps = (Iterable<? extends Map>) o;        if (Iterables.size(maps) == 1) {            return Iterables.getFirst(maps, null);        }        for (Map m : maps) {            if (m != null) {                ret.putAll(m);            }        }    }    return ret;}
0
public Object apply(List<Object> args)
{    if (args == null || args.size() != 1) {        throw new IllegalStateException("IS_NAN expects one: [number] ");    }    Object obj = args.get(0);    if (obj instanceof Number) {        return Double.isNaN(((Number) obj).doubleValue());    } else {        throw new ParseException("IS_NAN() expects a number argument");    }}
0
public Object apply(List<Object> list)
{    if (list.size() < 2) {        throw new IllegalStateException("IN_SUBNET expects at least two args: [ip, cidr1, cidr2, ...]" + " where cidr is the subnet mask in cidr form");    }    String ip = (String) list.get(0);    if (ip == null) {        return false;    }    boolean inSubnet = false;    for (int i = 1; i < list.size() && !inSubnet; ++i) {        String cidr = (String) list.get(i);        if (cidr == null) {            continue;        }        inSubnet |= new SubnetUtils(cidr).getInfo().isInRange(ip);    }    return inSubnet;}
0
public Object apply(List<Object> objects)
{    if (objects.isEmpty()) {        return null;    }    Object dnObj = objects.get(0);    InternetDomainName idn = toDomainName(dnObj);    if (idn != null) {        String dn = dnObj.toString();        String tld = extractTld(idn, dn);        if (!StringUtils.isEmpty(dn)) {            String suffix = safeSubstring(dn, 0, dn.length() - tld.length());            String hostnameWithoutTLD = safeSubstring(suffix, 0, suffix.length() - 1);            if (hostnameWithoutTLD == null) {                return dn;            }            String hostnameWithoutSubsAndTLD = Iterables.getLast(Splitter.on(".").split(hostnameWithoutTLD), null);            if (hostnameWithoutSubsAndTLD == null) {                return null;            }            return hostnameWithoutSubsAndTLD + "." + tld;        }    }    return null;}
0
public Object apply(List<Object> objects)
{    Object dnObj = objects.get(0);    InternetDomainName idn = toDomainName(dnObj);    if (idn != null) {        String dn = dnObj.toString();        String tld = extractTld(idn, dn);        String suffix = safeSubstring(dn, 0, dn.length() - tld.length());        if (StringUtils.isEmpty(suffix)) {            return suffix;        } else {            return suffix.substring(0, suffix.length() - 1);        }    }    return null;}
0
public Object apply(List<Object> objects)
{    Object dnObj = objects.get(0);    InternetDomainName idn = toDomainName(dnObj);    return extractTld(idn, dnObj + "");}
0
public Object apply(List<Object> objects)
{    URL url = toUrl(objects.get(0));    if (url == null) {        return null;    }    int port = url.getPort();    return port >= 0 ? port : url.getDefaultPort();}
0
public Object apply(List<Object> objects)
{    URL url = toUrl(objects.get(0));    return url == null ? null : url.getPath();}
0
public Object apply(List<Object> objects)
{    URL url = toUrl(objects.get(0));    return url == null ? null : url.getHost();}
0
public Object apply(List<Object> objects)
{    URL url = toUrl(objects.get(0));    return url == null ? null : url.getProtocol();}
0
private static String extractTld(InternetDomainName idn, String dn)
{    if (idn != null && idn.hasPublicSuffix()) {        String ret = idn.publicSuffix().toString();        if (ret.startsWith("InternetDomainName")) {            return Joiner.on(".").join(idn.publicSuffix().parts());        } else {            return ret;        }    } else if (dn != null) {        StringBuffer tld = new StringBuffer("");        for (int idx = dn.length() - 1; idx >= 0; idx--) {            char c = dn.charAt(idx);            if (c == '.') {                break;            } else {                tld.append(dn.charAt(idx));            }        }        return tld.reverse().toString();    } else {        return null;    }}
0
private static String safeSubstring(String val, int start, int end)
{    if (!StringUtils.isEmpty(val)) {        return val.substring(start, end);    }    return null;}
0
private static InternetDomainName toDomainName(Object dnObj)
{    if (dnObj != null) {        if (dnObj instanceof String) {            String dn = dnObj.toString();            try {                return InternetDomainName.from(dn);            } catch (IllegalArgumentException iae) {                return null;            }        } else {            throw new IllegalArgumentException(dnObj + " is not a string and therefore also not a domain.");        }    }    return null;}
0
private static URL toUrl(Object urlObj)
{    if (urlObj == null) {        return null;    }    if (urlObj instanceof String) {        String url = urlObj.toString();        try {            return new URL(url);        } catch (MalformedURLException e) {            return null;        }    } else {        throw new IllegalArgumentException(urlObj + " is not a string and therefore also not a URL.");    }}
0
public Object apply(List<Object> args)
{    if (args.size() < 1 || args.get(0) == null) {        throw new IllegalStateException("MAX function requires at least one argument");    }    Object firstArg = args.get(0);    if (firstArg instanceof Ordinal) {        Ordinal stats = convert(firstArg, Ordinal.class);        return stats.getMax();    } else if (firstArg instanceof Iterable) {        Iterable<Comparable> list = (Iterable<Comparable>) args.get(0);        return orderList(list, (ret, val) -> ret.compareTo(val) < 0, "MAX");    } else {        throw new IllegalStateException("MAX function expects either 'a StatisticsProvider object' or 'Stellar list of values'");    }}
0
public Object apply(List<Object> args)
{    if (args.size() < 1 || args.get(0) == null) {        throw new IllegalStateException("MIN function requires at least one argument");    }    Object firstArg = args.get(0);    if (firstArg instanceof Ordinal) {        Ordinal stats = convert(firstArg, Ordinal.class);        return stats.getMin();    } else if (firstArg instanceof Iterable) {        Iterable<Comparable> list = (Iterable<Comparable>) args.get(0);        return orderList(list, (ret, val) -> ret.compareTo(val) > 0, "MIN");    } else {        throw new IllegalStateException("MIN function expects either 'a StatisticsProvider object' or 'Stellar list of values' ");    }}
0
private static Comparable orderList(Iterable<Comparable> list, BiFunction<Comparable, Comparable, Boolean> eval, String funcName)
{    if (Iterables.isEmpty(list)) {        return null;    }    Object o = Iterables.getFirst(list, null);    Comparable ret = null;    for (Object valueVal : list) {        if (valueVal == null) {            continue;        }        Comparable value = null;        if (!(valueVal instanceof Comparable)) {            throw new IllegalStateException("Noncomparable object type " + valueVal.getClass().getName() + " submitted to " + funcName);        } else {            value = (Comparable) valueVal;        }        try {            Comparable convertedRet = ConversionUtils.convert(ret, value.getClass());            if (convertedRet == null && ret != null) {                throw new IllegalStateException("Incomparable objects were submitted to " + funcName + ": " + ret.getClass() + " is incomparable to " + value.getClass());            }            if (ret == null || eval.apply(convertedRet, value)) {                ret = value;            }        } catch (ClassCastException cce) {            throw new IllegalStateException("Incomparable objects were submitted to " + funcName + ": " + cce.getMessage(), cce);        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 2) {        throw new IllegalStateException("REGEXP_MATCH expects two args: [string, pattern] where pattern is a regexp pattern or a list of regexp patterns");    }    Object patternObject = list.get(1);    String str = (String) list.get(0);    if (str == null || patternObject == null) {        return false;    }    if (patternObject instanceof String) {        return PatternCache.INSTANCE.getPattern((String) patternObject).matcher(str).matches();    } else if (patternObject instanceof Iterable) {        boolean matches = false;        for (Object thisPatternObject : (Iterable) patternObject) {            if (thisPatternObject == null) {                continue;            }            if (PatternCache.INSTANCE.getPattern(thisPatternObject.toString()).matcher(str).matches()) {                matches = true;                break;            }        }        return matches;    }    return false;}
0
public Object apply(List<Object> list)
{    if (list.size() != 3) {        throw new IllegalStateException("REGEXP_GROUP_VAL expects three args: [string, pattern, int]" + "" + "where pattern is a regexp pattern");    }    String stringPattern = (String) list.get(1);    String str = (String) list.get(0);    Integer groupNumber = ConversionUtils.convert(list.get(2), Integer.class);    if (groupNumber == null) {                return null;    }    if (groupNumber == 0) {                return str;    }    if (str == null || stringPattern == null) {        return null;    }    Pattern pattern = PatternCache.INSTANCE.getPattern(stringPattern);    Matcher matcher = pattern.matcher(str);    if (!matcher.matches()) {        return null;    }    int groupCount = matcher.groupCount();    if (groupCount == 0 || groupCount < groupNumber) {        return null;    }    return matcher.group(groupNumber);}
0
public Object apply(List<Object> list)
{    if (list.size() != 3) {        throw new IllegalStateException("REGEXP_REPLACE expects three args: [string, pattern, value]" + " where pattern is a regexp pattern");    }    String str = (String) list.get(0);    String stringPattern = (String) list.get(1);    String value = (String) list.get(2);    if (StringUtils.isEmpty(str)) {        return null;    }    if (StringUtils.isEmpty(stringPattern) || StringUtils.isEmpty(value)) {        return str;    }    Pattern pattern = PatternCache.INSTANCE.getPattern(stringPattern);    Matcher matcher = pattern.matcher(str);    return matcher.replaceAll(value);}
0
public Iterable<StellarFunctionInfo> getFunctionInfo()
{    return functions.get().values();}
0
public Iterable<String> getFunctions()
{    return functions.get().keySet();}
0
public void initialize(Context context)
{    this.context = context;}
0
public void close() throws IOException
{    if (!closed) {                Map<String, Throwable> errors = new HashMap<>();        for (StellarFunctionInfo info : getFunctionInfo()) {            try {                info.getFunction().close();            } catch (Throwable t) {                errors.put(info.getName(), t);            }        }        if (!errors.isEmpty()) {            StringBuilder sb = new StringBuilder();            sb.append("Unable to close Stellar functions:");            for (Map.Entry<String, Throwable> e : errors.entrySet()) {                Throwable throwable = e.getValue();                String eText = String.format("Exception - Function: %s; Message: %s; Cause: %s", e.getKey(), throwable.getMessage(), throwable.getCause());                sb.append(System.lineSeparator());                sb.append(eText);            }            closed = true;            throw new IOException(sb.toString());        }        closed = true;    } else {            }}
1
public StellarFunction apply(String functionName)
{    StellarFunctionInfo info = functions.get().get(functionName);    if (info == null) {        throw new IllegalStateException(format("Unknown function: `%s`", functionName));    }    return info.getFunction();}
0
public static StellarFunctionInfo resolveFunction(Class<? extends StellarFunction> clazz)
{    StellarFunctionInfo info = null;        if (clazz.isAnnotationPresent(Stellar.class)) {        Stellar annotation = clazz.getAnnotation(Stellar.class);        String fullyQualifiedName = getNameFromAnnotation(annotation);        StellarFunction function = createFunction(clazz);        if (fullyQualifiedName != null && function != null) {            info = new StellarFunctionInfo(annotation.description(), fullyQualifiedName, annotation.params(), annotation.returns(), function);        }    }    return info;}
0
public static String getNameFromAnnotation(Stellar annotation)
{        String name = annotation.name();    if (name == null || name.trim().length() == 0) {        return null;    } else {        name = name.trim();    }        String namespace = annotation.namespace();    if (namespace == null || namespace.length() == 0) {        namespace = null;    } else {        namespace = namespace.trim();    }    return Joiner.on("_").skipNulls().join(Arrays.asList(namespace, name));}
0
public static StellarFunction createFunction(Class<? extends StellarFunction> clazz)
{    try {        return clazz.getConstructor().newInstance();    } catch (Exception e) {                return null;    }}
1
public String param()
{    return param;}
0
public Object get(Map<String, Object> config)
{    return config.getOrDefault(param, defaultValue);}
0
public T get(Map<String, Object> config, Class<T> clazz)
{    return ConversionUtils.convert(get(config), clazz);}
0
public void classLoaders(ClassLoader... classloaders)
{    classLoaders.clear();    Arrays.stream(classloaders).forEach(c -> classLoaders.add(c));}
0
public void include(String... toInclude)
{    for (String incl : toInclude) {        includes.add(incl);    }}
0
public void exclude(String... toExclude)
{    for (String excl : toExclude) {        excludes.add(excl);    }}
0
protected Iterable<Class<?>> getStellarClasses(ClassLoader cl)
{    return ClassIndex.getAnnotated(Stellar.class, cl);}
0
protected boolean includeClass(Class<?> c, FilterBuilder filterBuilder)
{    boolean isAssignable = StellarFunction.class.isAssignableFrom(c);    boolean isFiltered = filterBuilder.apply(c.getCanonicalName());    return isAssignable && isFiltered;}
0
public Set<Class<? extends StellarFunction>> resolvables()
{    ClassLoader[] cls = null;    if (this.classLoaders.size() == 0) {                cls = new ClassLoader[] { getClass().getClassLoader() };    } else {        List<ClassLoader> classLoaderList = new ArrayList<>();        for (int i = 0; i < this.classLoaders.size(); ++i) {            ClassLoader cl = this.classLoaders.get(i);            if (null != cl) {                                classLoaderList.add(cl);            } else {                            }        }        cls = classLoaderList.toArray(new ClassLoader[0]);    }    FilterBuilder filterBuilder = new FilterBuilder();    excludes.forEach(excl -> {        if (excl != null) {            filterBuilder.exclude(excl);        }    });    includes.forEach(incl -> {        if (incl != null) {            filterBuilder.include(incl);        }    });    Set<String> classes = new HashSet<>();    Set<Class<? extends StellarFunction>> ret = new HashSet<>();    for (ClassLoader cl : cls) {        for (Class<?> c : getStellarClasses(cl)) {            try {                                if (includeClass(c, filterBuilder)) {                    String className = c.getName();                    if (!classes.contains(className)) {                                                ret.add((Class<? extends StellarFunction>) c);                        classes.add(className);                    }                }            } catch (Error le) {                                try {                                    } catch (Error ie) {                                                        }            }        }    }    return ret;}
1
 void close() throws IOException
{}
0
public Set<Class<? extends StellarFunction>> resolvables()
{    return classesToResolve;}
0
public SimpleFunctionResolver withClass(Class<? extends StellarFunction> clazz)
{    this.classesToResolve.add(clazz);    return this;}
0
public static FunctionResolver getInstance()
{    return INSTANCE;}
0
public String getBasicAuthUser()
{    return (String) get(BASIC_AUTH_USER);}
0
public String getBasicAuthPasswordPath()
{    return (String) get(BASIC_AUTH_PASSWORD_PATH);}
0
public String getProxyHost()
{    return (String) get(PROXY_HOST);}
0
public Integer getProxyPort()
{    return (Integer) get(PROXY_PORT);}
0
public String getProxyBasicAuthUser()
{    return (String) get(PROXY_BASIC_AUTH_USER);}
0
public String getProxyBasicAuthPasswordPath()
{    return (String) get(PROXY_BASIC_AUTH_PASSWORD_PATH);}
0
public Integer getTimeout()
{    return (Integer) get(TIMEOUT);}
0
public Integer getConnectTimeout()
{    return (Integer) get(CONNECT_TIMEOUT);}
0
public Integer getConnectionRequestTimeout()
{    return (Integer) get(CONNECTION_REQUEST_TIMEOUT);}
0
public Integer getSocketTimeout()
{    return (Integer) get(SOCKET_TIMEOUT);}
0
public List<Integer> getResponseCodesAllowed()
{    return (List<Integer>) get(RESPONSE_CODES_ALLOWED);}
0
public Object getEmptyContentOverride()
{    return get(EMPTY_CONTENT_OVERRIDE);}
0
public Object getErrorValueOverride()
{    return get(ERROR_VALUE_OVERRIDE);}
0
public Integer getPoolingMaxTotal()
{    return (Integer) get(POOLING_MAX_TOTAL);}
0
public Integer getPoolingDefaultMaxPerRoute()
{    return (Integer) get(POOLING_DEFAULT_MAX_PER_RUOTE);}
0
public Boolean verifyContentLength()
{    return (Boolean) get(VERIFY_CONTENT_LENGTH);}
0
public Boolean enforceJson()
{    return (Boolean) get(ENFORCE_JSON);}
0
private static synchronized void initializeHttpClient(Context context)
{    if (closeableHttpClient == null) {        closeableHttpClient = getHttpClient(context);    }}
0
private static synchronized void closeHttpClient() throws IOException
{    if (closeableHttpClient != null) {        closeableHttpClient.close();        closeableHttpClient = null;    }}
0
private static synchronized void initializeExecutorService()
{    if (scheduledExecutorService == null) {        scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();    }}
0
private static synchronized void closeExecutorService()
{    if (scheduledExecutorService != null) {        scheduledExecutorService.shutdown();        scheduledExecutorService = null;    }}
0
public void initialize(Context context)
{    initializeExecutorService();    initializeHttpClient(context);    initialized = true;}
0
public boolean isInitialized()
{    return initialized;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String uriString = getArg(0, String.class, args);    Map<String, Object> functionRestConfig = null;    Map<String, Object> queryParameters = new HashMap<>();    if (args.size() > 1) {        functionRestConfig = getArg(1, Map.class, args);        if (args.size() == 3) {            queryParameters = getArg(2, Map.class, args);        }    }        Map<String, Object> globalRestConfig = (Map<String, Object>) getGlobalConfig(context).get(STELLAR_REST_SETTINGS);    Map<String, Object> getRestConfig = (Map<String, Object>) getGlobalConfig(context).get(STELLAR_REST_GET_SETTINGS);    RestConfig restConfig = buildRestConfig(globalRestConfig, getRestConfig, functionRestConfig);    try {        HttpGet httpGet = buildGetRequest(uriString, queryParameters);        return executeRequest(restConfig, httpGet);    } catch (URISyntaxException e) {        throw new IllegalArgumentException(e.getMessage(), e);    } catch (IOException e) {                return restConfig.getErrorValueOverride();    }}
1
public void close() throws IOException
{    closeHttpClient();    closeExecutorService();}
0
private HttpGet buildGetRequest(String uri, Map<String, Object> queryParameters) throws URISyntaxException
{    HttpGet httpGet = new HttpGet(getURI(uri, queryParameters));    httpGet.addHeader("Accept", "application/json");    return httpGet;}
0
public void initialize(Context context)
{    initializeExecutorService();    initializeHttpClient(context);    initialized = true;}
0
public boolean isInitialized()
{    return initialized;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    String uriString = getArg(0, String.class, args);    Object dataObject = getArg(1, Object.class, args);    Map<String, Object> functionRestConfig = null;    Map<String, Object> queryParameters = new HashMap<>();    if (args.size() > 2) {        functionRestConfig = getArg(2, Map.class, args);        if (args.size() == 4) {            queryParameters = getArg(3, Map.class, args);        }    }        Map<String, Object> globalRestConfig = (Map<String, Object>) getGlobalConfig(context).get(STELLAR_REST_SETTINGS);    Map<String, Object> postRestConfig = (Map<String, Object>) getGlobalConfig(context).get(STELLAR_REST_POST_SETTINGS);    RestConfig restConfig = buildRestConfig(globalRestConfig, postRestConfig, functionRestConfig);    try {        HttpPost httpPost = buildPostRequest(restConfig, uriString, dataObject, queryParameters);        return executeRequest(restConfig, httpPost);    } catch (URISyntaxException e) {        throw new IllegalArgumentException(e.getMessage(), e);    } catch (IOException e) {                return restConfig.getErrorValueOverride();    }}
1
public void close() throws IOException
{    closeHttpClient();    closeExecutorService();}
0
private HttpPost buildPostRequest(RestConfig restConfig, String uriString, Object dataObject, Map<String, Object> queryParameters) throws JsonProcessingException, URISyntaxException, UnsupportedEncodingException
{    String body = getPostData(restConfig, dataObject);    URI uri = getURI(uriString, queryParameters);    HttpPost httpPost = new HttpPost(uri);    httpPost.setEntity(new StringEntity(body));    httpPost.addHeader("Accept", "application/json");    httpPost.addHeader("Content-type", "application/json");    return httpPost;}
0
private String getPostData(RestConfig restConfig, Object arg) throws JsonProcessingException
{    String data = "";    if (arg == null) {        return data;    }    if (arg instanceof Map) {        data = JSONUtils.INSTANCE.toJSON(arg, false);    } else {        data = arg.toString();        if (restConfig.enforceJson()) {            try {                JSONUtils.INSTANCE.toJSONObject(data);            } catch (org.json.simple.parser.ParseException e) {                throw new IllegalArgumentException(String.format("POST data '%s' must be properly formatted JSON.  " + "Set the '%s' property to false to disable this check.", data, RestConfig.ENFORCE_JSON));            }        }    }    return data;}
0
public static T getArg(int index, Class<T> clazz, List<Object> args)
{    if (index >= args.size()) {        throw new IllegalArgumentException(format("Expected at least %d argument(s), found %d", index + 1, args.size()));    }    return ConversionUtils.convert(args.get(index), clazz);}
0
protected static CloseableHttpClient getHttpClient(Context context)
{    RestConfig restConfig = buildRestConfig(getGlobalConfig(context));    PoolingHttpClientConnectionManager cm = getConnectionManager(restConfig);    return HttpClients.custom().setConnectionManager(cm).build();}
0
protected static PoolingHttpClientConnectionManager getConnectionManager(RestConfig restConfig)
{    PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();    if (restConfig.containsKey(POOLING_MAX_TOTAL)) {        cm.setMaxTotal(restConfig.getPoolingMaxTotal());    }    if (restConfig.containsKey(POOLING_DEFAULT_MAX_PER_RUOTE)) {        cm.setDefaultMaxPerRoute(restConfig.getPoolingDefaultMaxPerRoute());    }    return cm;}
0
private static Map<String, Object> getGlobalConfig(Context context)
{    Optional<Object> globalCapability = context.getCapability(GLOBAL_CONFIG, false);    return globalCapability.map(o -> (Map<String, Object>) o).orElseGet(HashMap::new);}
0
protected static RestConfig buildRestConfig(Map<String, Object>... configs)
{    RestConfig restConfig = new RestConfig();        for (Map<String, Object> config : configs) {        if (config != null) {            restConfig.putAll(config);        }    }    return restConfig;}
0
private static URI getURI(String uriString, Map<String, Object> queryParameters) throws URISyntaxException
{    URIBuilder uriBuilder = new URIBuilder(uriString);    if (queryParameters != null) {        for (Map.Entry<String, Object> entry : queryParameters.entrySet()) {            uriBuilder.setParameter(entry.getKey(), (String) entry.getValue());        }    }    return uriBuilder.build();}
0
protected static Optional<HttpHost> getProxy(RestConfig restConfig)
{    Optional<HttpHost> proxy = Optional.empty();    if (restConfig.getProxyHost() != null && restConfig.getProxyPort() != null) {        proxy = Optional.of(new HttpHost(restConfig.getProxyHost(), restConfig.getProxyPort(), "http"));    }    return proxy;}
0
protected static RequestConfig getRequestConfig(RestConfig restConfig, Optional<HttpHost> proxy)
{    RequestConfig.Builder requestConfigBuilder = RequestConfig.custom();    if (restConfig.getConnectTimeout() != null) {        requestConfigBuilder.setConnectTimeout(restConfig.getConnectTimeout());    }    if (restConfig.getConnectionRequestTimeout() != null) {        requestConfigBuilder.setConnectionRequestTimeout(restConfig.getConnectionRequestTimeout());    }    if (restConfig.getSocketTimeout() != null) {        requestConfigBuilder.setSocketTimeout(restConfig.getSocketTimeout());    }    proxy.ifPresent(requestConfigBuilder::setProxy);    return requestConfigBuilder.build();}
0
protected static HttpClientContext getHttpClientContext(RestConfig restConfig, HttpHost target, Optional<HttpHost> proxy) throws IOException
{    HttpClientContext httpClientContext = HttpClientContext.create();    boolean credentialsAdded = false;    CredentialsProvider credentialsProvider = new BasicCredentialsProvider();        if (restConfig.getBasicAuthUser() != null && restConfig.getBasicAuthPasswordPath() != null) {        String password = new String(readBytes(new Path(restConfig.getBasicAuthPasswordPath())), StandardCharsets.UTF_8);        credentialsProvider.setCredentials(new AuthScope(target), new UsernamePasswordCredentials(restConfig.getBasicAuthUser(), password));        credentialsAdded = true;    }        if (proxy.isPresent() && restConfig.getProxyBasicAuthUser() != null && restConfig.getProxyBasicAuthPasswordPath() != null) {        String password = new String(readBytes(new Path(restConfig.getProxyBasicAuthPasswordPath())), StandardCharsets.UTF_8);        credentialsProvider.setCredentials(new AuthScope(proxy.get()), new UsernamePasswordCredentials(restConfig.getProxyBasicAuthUser(), password));        credentialsAdded = true;    }    if (credentialsAdded) {        httpClientContext.setCredentialsProvider(credentialsProvider);    }    return httpClientContext;}
0
private static byte[] readBytes(Path inPath) throws IOException
{    FileSystem fs = FileSystem.get(inPath.toUri(), new Configuration());    try (FSDataInputStream inputStream = fs.open(inPath)) {        return IOUtils.toByteArray(inputStream);    }}
0
protected static Optional<Object> parseResponse(RestConfig restConfig, HttpUriRequest httpUriRequest, HttpEntity httpEntity) throws IOException
{    Optional<Object> parsedResponse = Optional.empty();    if (httpEntity != null) {        int actualContentLength = 0;        String json = EntityUtils.toString(httpEntity);        if (json != null && !json.isEmpty()) {            actualContentLength = json.length();            parsedResponse = Optional.of(JSONUtils.INSTANCE.load(json, JSONUtils.MAP_SUPPLIER));        }        if (restConfig.verifyContentLength() && actualContentLength != httpEntity.getContentLength()) {            throw new IOException(String.format("Stellar REST request to %s returned incorrect or missing content length. " + "Content length in the response was %d but the actual body content length was %d.", httpUriRequest.getURI().toString(), httpEntity.getContentLength(), actualContentLength));        }    }    return parsedResponse;}
0
protected static void setCloseableHttpClient(CloseableHttpClient httpClient)
{    closeableHttpClient = httpClient;}
0
protected static void setScheduledExecutorService(ScheduledExecutorService executorService)
{    scheduledExecutorService = executorService;}
0
public Object apply(List<Object> list)
{    LinkedHashSet<Object> ret = new LinkedHashSet<>();    if (list.size() == 1) {        Object o = list.get(0);        if (o != null) {            if (o instanceof Iterable) {                Iterables.addAll(ret, (Iterable) o);            } else {                throw new IllegalArgumentException("Expected an Iterable, but " + o + " is of type " + o.getClass());            }        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashSet<Object> ret = (LinkedHashSet<Object>) list.get(0);    if (ret == null) {        ret = new LinkedHashSet<>();    }    for (int i = 1; i < list.size(); ++i) {        Object o = list.get(i);        if (o != null) {            ret.add(o);        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashSet<Object> ret = (LinkedHashSet<Object>) list.get(0);    if (ret == null) {        ret = new LinkedHashSet<>();    }    for (int i = 1; i < list.size(); ++i) {        Object o = list.get(i);        if (o != null) {            ret.remove(o);        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashSet<Object> ret = new LinkedHashSet<>();    Object o = list.get(0);    if (o != null) {        if (!(o instanceof Iterable)) {            throw new IllegalArgumentException("Expected an Iterable, but " + o + " is of type " + o.getClass());        }        Iterable<? extends Iterable> sets = (Iterable<? extends Iterable>) o;        for (Iterable s : sets) {            if (s != null) {                Iterables.addAll(ret, s);            }        }    }    return ret;}
0
public Object apply(List<Object> list)
{    LinkedHashMap<Object, Integer> ret = new LinkedHashMap<>();    if (list.size() >= 1) {        Object o = list.get(0);        if (o != null) {            if (!(o instanceof Iterable)) {                throw new IllegalArgumentException("Expected an Iterable, but " + o + " is of type " + o.getClass());            }            for (Object obj : (Iterable) o) {                ret.merge(obj, 1, (k, one) -> k + one);            }        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashMap<Object, Integer> ret = (LinkedHashMap<Object, Integer>) list.get(0);    if (ret == null) {        ret = new LinkedHashMap<>();    }    for (int i = 1; i < list.size(); ++i) {        Object o = list.get(i);        if (o != null) {            ret.merge(o, 1, (k, one) -> k + one);        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashMap<Object, Integer> ret = (LinkedHashMap<Object, Integer>) list.get(0);    if (ret == null) {        ret = new LinkedHashMap<>();    }    for (int i = 1; i < list.size(); ++i) {        Object o = list.get(i);        if (o != null) {            Integer cnt = ret.get(o);            if (cnt == null) {                continue;            }            if (cnt == 1) {                ret.remove(o);            } else {                ret.put(o, cnt - 1);            }        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashMap<Object, Integer> ret = new LinkedHashMap<>();    Iterable<Map<Object, Integer>> maps = (Iterable<Map<Object, Integer>>) list.get(0);    for (Map<Object, Integer> s : maps) {        if (s != null) {            for (Map.Entry<Object, Integer> kv : s.entrySet()) {                ret.merge(kv.getKey(), kv.getValue(), (k, cnt) -> k + cnt);            }        }    }    return ret;}
0
public Object apply(List<Object> list)
{    if (list.size() < 1) {        return null;    }    LinkedHashSet<Object> ret = new LinkedHashSet<>();    if (list.size() == 1) {        Map<Object, Integer> multiset = (Map<Object, Integer>) list.get(0);        if (multiset != null) {            ret.addAll(multiset.keySet());        }    }    return ret;}
0
private static Map<String, VariableResult> getVariables(Context context)
{    return (Map<String, VariableResult>) context.getCapability(Context.Capabilities.SHELL_VARIABLES).get();}
0
public Object apply(List<Object> args)
{    if (args.size() < 1) {        return null;    }    Map<Object, Object> map = (Map<Object, Object>) args.get(0);    if (map == null) {        map = new HashMap<>();    }    String[] headers = { "KEY", "VALUE" };    String[][] data = new String[map.size()][2];    int i = 0;    for (Map.Entry<Object, Object> kv : map.entrySet()) {        data[i++] = new String[] { kv.getKey().toString(), kv.getValue().toString() };    }    return FlipTable.of(headers, data);}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    Map<String, VariableResult> variables = getVariables(context);    String[] headers = { "VARIABLE", "VALUE", "EXPRESSION" };    String[][] data = new String[variables.size()][3];    int wordWrap = -1;    if (args.size() > 0) {        wordWrap = ConversionUtils.convert(args.get(0), Integer.class);    }    int i = 0;    for (Map.Entry<String, VariableResult> kv : variables.entrySet()) {        VariableResult result = kv.getValue();        data[i++] = new String[] { toWrappedString(kv.getKey(), wordWrap), toWrappedString(result.getResult(), wordWrap), toWrappedString(result.getExpression().get(), wordWrap) };    }    return FlipTable.of(headers, data);}
0
private static String toWrappedString(Object o, int wrap)
{    String s = "" + o;    if (wrap <= 0) {        return s;    }    return WordUtils.wrap(s, wrap);}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    Map<String, VariableResult> variables = getVariables(context);    LinkedHashMap<String, String> ret = new LinkedHashMap<>();    for (Object arg : args) {        if (arg == null) {            continue;        }        String variable = (String) arg;        VariableResult result = variables.get(variable);        if (result != null && result.getExpression().isPresent()) {            ret.put(variable, result.getExpression().orElseGet(() -> ""));        }    }    return ret;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    Map<String, VariableResult> variables = getVariables(context);    if (args.size() == 0) {        return null;    }    String variable = (String) args.get(0);    if (variable == null) {        return null;    }    VariableResult result = variables.get(variable);    if (result != null && result.getExpression().isPresent()) {        return result.getExpression().get();    }    return null;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
private String getEditor()
{            String editor = System.getProperty("EDITOR");    if (org.apache.commons.lang3.StringUtils.isEmpty(editor)) {        editor = System.getenv().get("EDITOR");    }    if (org.apache.commons.lang3.StringUtils.isEmpty(editor)) {        editor = System.getenv("VISUAL");    }    if (org.apache.commons.lang3.StringUtils.isEmpty(editor)) {        editor = "/bin/vi";    }    return editor;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    File outFile = null;    String editor = getEditor();    try {        outFile = File.createTempFile("stellar_shell", "out");        if (args.size() > 0) {            String arg = (String) args.get(0);            try (PrintWriter pw = new PrintWriter(outFile, StandardCharsets.UTF_8.name())) {                IOUtils.write(arg, pw);            }        }    } catch (IOException e) {        String message = "Unable to create temp file: " + e.getMessage();                throw new IllegalStateException(message, e);    }    Optional<Object> console = context.getCapability(CONSOLE, false);    try {        PausableInput.INSTANCE.pause();                ProcessBuilder processBuilder = new ProcessBuilder(editor, outFile.getAbsolutePath());        processBuilder.redirectInput(ProcessBuilder.Redirect.INHERIT);        processBuilder.redirectOutput(ProcessBuilder.Redirect.INHERIT);        processBuilder.redirectError(ProcessBuilder.Redirect.INHERIT);        try {            Process p = processBuilder.start();                        p.waitFor();            try (BufferedReader br = Files.newBufferedReader(outFile.toPath(), StandardCharsets.UTF_8)) {                return IOUtils.toString(br).trim();            }        } catch (Exception e) {            String message = "Unable to read output: " + e.getMessage();                        return null;        }    } finally {        try {            PausableInput.INSTANCE.unpause();            if (console.isPresent()) {                ((Console) console.get()).pushToInputStream("\b\n");            }        } catch (IOException e) {                    }        if (outFile.exists()) {            outFile.delete();        }    }}
1
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> list)
{    if (list.size() < 2) {        throw new IllegalStateException("ENDS_WITH expects two args: [string, suffix] where suffix is the string fragment that the string should end with");    }    String prefix = (String) list.get(1);    String str = (String) list.get(0);    if (str == null || prefix == null) {        return false;    }    return str.endsWith(prefix);}
0
public Object apply(List<Object> list)
{    if (list.size() < 2) {        throw new IllegalStateException("STARTS_WITH expects two args: [string, prefix] where prefix is the string fragment that the string should start with");    }    String prefix = (String) list.get(1);    String str = (String) list.get(0);    if (str == null || prefix == null) {        return false;    }    return str.startsWith(prefix);}
0
public Object apply(List<Object> strings)
{    return strings.get(0) == null ? null : strings.get(0).toString().toLowerCase();}
0
public Object apply(List<Object> strings)
{    return strings.get(0) == null ? null : strings.get(0).toString().toUpperCase();}
0
public Object apply(List<Object> strings)
{    return strings.get(0) == null ? null : strings.get(0).toString();}
0
public Object apply(List<Object> strings)
{    return strings.get(0) == null ? null : strings.get(0).toString().trim();}
0
public Object apply(List<Object> args)
{    Iterable<Object> arg1 = (Iterable<Object>) args.get(0);    String delim = (String) args.get(1);    return Joiner.on(delim).join(Iterables.filter(arg1, x -> x != null));}
0
public Object apply(List<Object> args)
{    List ret = new ArrayList();    Object o1 = args.get(0);    if (o1 != null) {        String arg1 = o1.toString();        String delim = (String) args.get(1);        Iterables.addAll(ret, Splitter.on(delim).split(arg1));    }    return ret;}
0
public Object apply(List<Object> args)
{    List<Object> arg1 = (List<Object>) args.get(0);    return Iterables.getLast(arg1, null);}
0
public Object apply(List<Object> args)
{    List<Object> arg1 = (List<Object>) args.get(0);    return Iterables.getFirst(arg1, null);}
0
public Object apply(List<Object> args)
{    List<Object> arg1 = (List<Object>) args.get(0);    int offset = (Integer) args.get(1);    if (offset < arg1.size()) {        return Iterables.get(arg1, offset);    }    return null;}
0
public Object apply(List<Object> args)
{    if (args.size() < 3) {        throw new IllegalStateException("FILL_LEFT expects three args: [string,char,length] where char is the fill character string and length is the required length of the result");    }    return fill(FillDirection.LEFT, args.get(0), args.get(1), args.get(2));}
0
public Object apply(List<Object> args)
{    if (args.size() < 3) {        throw new IllegalStateException("FILL_RIGHT expects three args: [string,char,length] where char is the fill character string and length is the required length of the result");    }    return fill(FillDirection.RIGHT, args.get(0), args.get(1), args.get(2));}
0
private static Object fill(FillDirection direction, Object inputObject, Object fillObject, Object requiredLengthObject) throws ParseException
{    if (inputObject == null) {        return null;    }    String input = inputObject.toString();    if (requiredLengthObject == null || fillObject == null) {        throw new IllegalStateException("Required Length and Fill String are both required");    }    String fill = fillObject.toString();    if (org.apache.commons.lang.StringUtils.isEmpty(fill)) {        throw new IllegalStateException("The fill cannot be an empty string");    }    fill = fill.substring(0, 1);    Integer requiredLength = ConversionUtils.convert(requiredLengthObject, Integer.class);    if (requiredLength == null) {        throw new IllegalStateException("Required Length  not a valid Integer: " + requiredLengthObject.toString());    }    if (direction == FillDirection.LEFT) {        return org.apache.commons.lang.StringUtils.leftPad(input, requiredLength, fill);    }    return org.apache.commons.lang.StringUtils.rightPad(input, requiredLength, fill);}
0
public Object apply(List<Object> strings)
{    /*      Shannon entropy is defined as follows:      \Eta(X) = - \sum(p(x_i)*log_2(p(x_i)), i=0, n-1) where x_i are distinct characters in the string.       */    Map<Character, Integer> frequency = new HashMap<>();    if (strings.size() != 1) {        throw new IllegalArgumentException("STRING_ENTROPY expects exactly one argument which is a string.");    }    String input = ConversionUtils.convert(strings.get(0), String.class);    if (StringUtils.isEmpty(input)) {        return 0.0;    }    for (int i = 0; i < input.length(); ++i) {        char c = input.charAt(i);        frequency.put(c, frequency.getOrDefault(c, 0) + 1);    }    double ret = 0.0;    double log2 = Math.log(2);    for (Integer f : frequency.values()) {        double p = f.doubleValue() / input.length();        ret -= p * Math.log(p) / log2;    }    return ret;}
0
public Object apply(List<Object> args)
{    if (args.size() == 0) {        throw new IllegalArgumentException("[FORMAT] missing argument: format string");    }    String format = ConversionUtils.convert(args.get(0), String.class);    Object[] formatArgs = args.subList(1, args.size()).toArray();    return String.format(format, formatArgs);}
0
public Object apply(List<Object> strings)
{    if (strings == null || strings.size() < 2) {        throw new IllegalArgumentException("SUBSTRING requires (at least) 2 arguments: the input and the start position (inclusive)");    }    Object varObj = strings.get(0);    if (varObj != null && !(varObj instanceof String)) {        throw new IllegalArgumentException("SUBSTRING input must be a String");    }    String var = varObj == null ? null : (String) varObj;    Object startObj = strings.get(1);    if (startObj != null && !(startObj instanceof Number)) {        throw new IllegalArgumentException("SUBSTRING start must be an Number");    }    Integer start = startObj == null ? null : ((Number) startObj).intValue();    Integer end = null;    if (strings.size() > 2) {        Object endObj = strings.get(2);        if (endObj != null && !(endObj instanceof Number)) {            throw new IllegalArgumentException("SUBSTRING end must be an Number");        }        end = endObj == null ? null : ((Number) endObj).intValue();    }    if (var == null || start == null) {        return null;    } else if (var.length() == 0) {        return var;    } else {        if (end == null) {            return var.substring(start);        } else {            return var.substring(start, end);        }    }}
0
public Object apply(List<Object> strings)
{    if (strings == null || strings.size() == 0) {        throw new IllegalArgumentException("[CHOMP] missing argument: string to be chopped");    }    String var = strings.get(0) == null ? null : (String) strings.get(0);    if (var == null) {        return null;    } else if (var.length() == 0) {        return var;    } else {        return StringUtils.chomp(var);    }}
0
public Object apply(List<Object> strings)
{    if (strings == null || strings.size() == 0) {        throw new IllegalArgumentException("[CHOP] missing argument: string to be chopped");    }    String var = strings.get(0) == null ? null : (String) strings.get(0);    if (var == null) {        return null;    } else if (var.length() == 0) {        return var;    } else {        return StringUtils.chop(var);    }}
0
public Object apply(List<Object> strings)
{    String prefixed;    switch(strings.size()) {        case 2:            prefixed = StringUtils.prependIfMissing((String) strings.get(0), (String) strings.get(1));            break;        case 3:            prefixed = StringUtils.prependIfMissing((String) strings.get(0), (String) strings.get(1), (String) strings.get(2));            break;        default:            throw new IllegalArgumentException("[PREPEND_IF_MISSING] incorrect arguments: " + strings.toString() + "\nUsage: PREPEND_IF_MISSING <String> <prefix> [<prefix>...]");    }    return prefixed;}
0
public Object apply(List<Object> strings)
{    String suffixed;    switch(strings.size()) {        case 2:            suffixed = StringUtils.appendIfMissing((String) strings.get(0), (String) strings.get(1));            break;        case 3:            suffixed = StringUtils.appendIfMissing((String) strings.get(0), (String) strings.get(1), (String) strings.get(2));            break;        default:            throw new IllegalArgumentException("[APPEND_IF_MISSING] incorrect arguments. Usage: APPEND_IF_MISSING <String> <prefix> [<prefix>...]");    }    return suffixed;}
0
public Object apply(List<Object> strings)
{    if (strings.size() != 2) {        throw new IllegalArgumentException("[COUNT_MATCHES] incorrect arguments. Usage: COUNT_MATCHES <String> <substring>");    }    int matchcount;    matchcount = StringUtils.countMatches((String) strings.get(0), (String) strings.get(1));    return matchcount;}
0
public Object apply(List<Object> strings)
{    if (strings == null || strings.size() == 0) {        throw new IllegalArgumentException("[TO_JSON_OBJECT] incorrect arguments. Usage: TO_JSON_OBJECT <String>");    }    String var = (strings.get(0) == null) ? null : (String) strings.get(0);    if (var == null) {        return null;    } else if (var.length() == 0) {        return var;    } else {        if (!(strings.get(0) instanceof String)) {            throw new ParseException("Valid JSON string not supplied");        }                try {            return JSONUtils.INSTANCE.load((String) strings.get(0), Object.class);        } catch (JsonProcessingException ex) {            throw new ParseException("Valid JSON string not supplied", ex);        } catch (IOException e) {            e.printStackTrace();        }    }    return new ParseException("Unable to parse JSON string");}
0
public Object apply(List<Object> strings)
{    if (strings == null || strings.size() == 0) {        throw new IllegalArgumentException("[TO_JSON_MAP] incorrect arguments. Usage: TO_JSON_MAP <JSON String>");    }    String var = (strings.get(0) == null) ? null : (String) strings.get(0);    if (var == null) {        return null;    } else if (var.length() == 0) {        return var;    } else {        if (!(strings.get(0) instanceof String)) {            throw new ParseException("Valid JSON string not supplied");        }                String in = (String) strings.get(0);        try {            return (Map) JSONUtils.INSTANCE.load(in, JSONUtils.MAP_SUPPLIER);        } catch (JsonProcessingException ex) {            throw new ParseException(String.format("%s is not a valid JSON string", in), ex);        } catch (IOException ex) {            throw new ParseException(String.format("%s is not a valid JSON string", in), ex);        } catch (ClassCastException ex) {            throw new ParseException(String.format("%s is not a valid JSON string, expected a map", in), ex);        }    }}
0
public Object apply(List<Object> strings)
{    if (strings == null || strings.size() == 0) {        throw new IllegalArgumentException("[TO_JSON_LIST] incorrect arguments. Usage: TO_JSON_LIST <JSON String>");    }    String var = (strings.get(0) == null) ? null : (String) strings.get(0);    if (var == null) {        return null;    } else if (var.length() == 0) {        return var;    } else {        if (!(strings.get(0) instanceof String)) {            throw new ParseException("Valid JSON string not supplied");        }                String in = (String) strings.get(0);        try {            return (List) JSONUtils.INSTANCE.load(in, JSONUtils.LIST_SUPPLIER);        } catch (JsonProcessingException ex) {            throw new ParseException(String.format("%s is not a valid JSON string", in), ex);        } catch (IOException ex) {            throw new ParseException(String.format("%s is not a valid JSON string", in), ex);        } catch (ClassCastException ex) {            throw new ParseException(String.format("%s is not a valid JSON string, expected a list", in), ex);        }    }}
0
public Object apply(List<Object> args)
{    return extractTypeChecked(args, 0, String.class, x -> env.get((String) x.get(0)));}
0
public static Object extractTypeChecked(List<Object> args, int i, Class clazz, Function<List<Object>, Object> extractFunc)
{    if (args.size() < i + 1) {        return null;    } else if (clazz.isInstance(args.get(i))) {        return extractFunc.apply(args);    } else {        return null;    }}
0
public Object apply(List<Object> args)
{    return extractTypeChecked(args, 0, String.class, x -> System.getProperty((String) args.get(0)));}
0
public Object apply(List<Object> list)
{    return tagsList;}
0
public Object apply(List<Object> list)
{    if (list.size() < 3) {        throw new IllegalStateException("FUZZY_SCORE expects three args: [string, string, string]");    }    Object oterm = list.get(0);    Object oquery = list.get(1);    Object olang = list.get(2);        if (!(oterm instanceof String) || !(oquery instanceof String) || !(olang instanceof String)) {        return 0;    }    String term = (String) oterm;    String query = (String) oquery;    String lang = (String) olang;    if (!tagsList.contains(lang)) {        throw new ParseException("FUZZY_SCORE requires a valid IETF BCP47 language code see FUZZY_LANGS and https://tools.ietf.org/html/bcp47");    }    if (StringUtils.isEmpty(term) || StringUtils.isEmpty(query)) {        return 0;    }    Locale locale = Locale.forLanguageTag(lang);    FuzzyScore score = new FuzzyScore(locale);    return score.fuzzyScore(term, query);}
0
public static String toSyntaxTree(ParseTree tree)
{    return new AST(tree).toString();}
0
private Object getPayload(ParseTree tree)
{    if (tree.getChildCount() == 0) {        return tree.getPayload();    } else {        String ruleName = tree.getClass().getSimpleName().replace("Context", "");        return Character.toLowerCase(ruleName.charAt(0)) + ruleName.substring(1);    }}
0
private static void walk(ParseTree tree, AST ast)
{    if (tree.getChildCount() == 0) {        new AST(ast, tree);    } else if (tree.getChildCount() == 1) {        walk(tree.getChild(0), ast);    } else if (tree.getChildCount() > 1) {        for (int i = 0; i < tree.getChildCount(); i++) {            AST temp = new AST(ast, tree.getChild(i));            if (!(temp.payload instanceof Token)) {                walk(tree.getChild(i), temp);            }        }    }}
0
public String toString()
{    StringBuilder builder = new StringBuilder();    AST ast = this;    List<AST> firstStack = new ArrayList<>();    firstStack.add(ast);    List<List<AST>> childListStack = new ArrayList<>();    childListStack.add(firstStack);    while (!childListStack.isEmpty()) {        List<AST> childStack = childListStack.get(childListStack.size() - 1);        if (childStack.isEmpty()) {            childListStack.remove(childListStack.size() - 1);        } else {            ast = childStack.remove(0);            String caption;            if (ast.payload instanceof Token) {                Token token = (Token) ast.payload;                caption = String.format("TOKEN[type: %s, text: %s]", token.getType(), token.getText().replace("\n", "\\n"));            } else {                caption = String.valueOf(ast.payload);            }            String indent = "";            for (int i = 0; i < childListStack.size() - 1; i++) {                indent += (childListStack.get(i).size() > 0) ? "|  " : "   ";            }            builder.append(indent).append(childStack.isEmpty() ? "'- " : "|- ").append(caption).append("\n");            if (ast.children.size() > 0) {                List<AST> children = new ArrayList<>();                for (int i = 0; i < ast.children.size(); i++) {                    children.add(ast.children.get(i));                }                childListStack.add(children);            }        }    }    return builder.toString();}
0
public void add(Map... ms)
{    if (ms != null) {        for (Map m : ms) {            if (m != null) {                this.variableMappings.add(m);            }        }    }}
0
public Object resolve(String variable)
{    if (variable != null && variable.equals(VariableResolver.ALL_FIELDS)) {        return new ConcatMap(variableMappings);    }    for (Map variableMapping : variableMappings) {        Object o = variableMapping.get(variable);        if (o != null) {            return o;        }    }    return null;}
0
public boolean exists(String variable)
{    return true;}
0
public Object apply(List<Object> objects)
{    return pred.test(objects);}
0
 void close() throws IOException
{}
0
public String getReturns()
{    return returns;}
0
public String getDescription()
{    return description;}
0
public String getName()
{    return name;}
0
public String[] getParams()
{    return params;}
0
public StellarFunction getFunction()
{    return function;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    StellarFunctionInfo that = (StellarFunctionInfo) o;    if (name != null ? !name.equals(that.name) : that.name != null)        return false;    if (description != null ? !description.equals(that.description) : that.description != null)        return false;    if (returns != null ? !returns.equals(that.returns) : that.returns != null)        return false;        if (!Arrays.equals(params, that.params))        return false;    return function != null ? function.equals(that.function) : that.function == null;}
0
public int hashCode()
{    int result = name != null ? name.hashCode() : 0;    result = 31 * result + (description != null ? description.hashCode() : 0);    result = 31 * result + (returns != null ? returns.hashCode() : 0);    result = 31 * result + Arrays.hashCode(params);    result = 31 * result + (function != null ? function.hashCode() : 0);    return result;}
0
public String toString()
{    return "StellarFunctionInfo{" + "name='" + name + '\'' + ", description='" + description + '\'' + ", returns='" + returns + '\'' + ", params=" + Arrays.toString(params) + ", function=" + function + '}';}
0
public static FunctionResolver FUNCTION_RESOLVER()
{    return SingletonFunctionResolver.getInstance();}
0
public static void initialize(Context context)
{    SingletonFunctionResolver.getInstance().initialize(context);}
0
public static void close() throws IOException
{    SingletonFunctionResolver.getInstance().close();}
0
public FrameContext.Context getMultiArgContext()
{    return multiArgContext;}
0
public T getValue()
{    return value;}
0
public Class<T> getUnderlyingType()
{    return underlyingType;}
0
public String toString()
{    return "" + value;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    Token<?> token = (Token<?>) o;    if (getValue() != null ? !getValue().equals(token.getValue()) : token.getValue() != null)        return false;    return getUnderlyingType() != null ? getUnderlyingType().equals(token.getUnderlyingType()) : token.getUnderlyingType() == null;}
0
public int hashCode()
{    int result = getValue() != null ? getValue().hashCode() : 0;    result = 31 * result + (getUnderlyingType() != null ? getUnderlyingType().hashCode() : 0);    return result;}
0
public void setUp() throws Exception
{    processor = new BaseStellarProcessor<>(Object.class);}
0
public void validateShouldProperlyThrowExceptionOnInvalidStellarExpression() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage("Unable to parse ': ");    processor.validate("'", true, Context.EMPTY_CONTEXT());}
0
public void validateShouldProperlyThrowExceptionByDefaultOnInvalidStellarExpression() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage("Unable to parse ': ");    processor.validate("'", Context.EMPTY_CONTEXT());}
0
public void validateShouldProperlyThrowExceptionByDefaultOnInvalidStellarExpression2() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage("Unable to parse ': ");    processor.validate("'");}
0
public void validateMethodShouldFailOnUnknownFunctions() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage(" Unable to resolve function named 'UNKNOWN_FUNCTION'.");    assertTrue(processor.validate("1 < UNKNOWN_FUNCTION(3)", Context.EMPTY_CONTEXT()));}
0
public void validateMethodShouldNotFailOnUnknownvariables() throws Exception
{    assertTrue(processor.validate("unknown_variable\n\n"));    assertTrue(processor.validate("unknown_variable > 2", Context.EMPTY_CONTEXT()));}
0
public void makeSureBasicLexerErrorsAreCaughtDuringValidation() throws Exception
{    assertFalse(processor.validate("true ", false, Context.EMPTY_CONTEXT()));    assertFalse(processor.validate(" (1 + 2)", false, Context.EMPTY_CONTEXT()));}
0
public void setup() throws Exception
{        Map<String, Object> cacheConfig = ImmutableMap.of(CachingStellarProcessor.MAX_CACHE_SIZE_PARAM, 2, CachingStellarProcessor.MAX_TIME_RETAIN_PARAM, 10, CachingStellarProcessor.RECORD_STATS, true);    cache = CachingStellarProcessor.createCache(cacheConfig);    contextWithCache = new Context.Builder().with(Context.Capabilities.CACHE, () -> cache).build();        processor = new CachingStellarProcessor();}
0
public void testWithCache()
{    Object result = execute("TO_UPPER(name)", contextWithCache);    assertEquals("BLAH", result);    assertEquals(1, cache.stats().requestCount());    assertEquals(1, cache.stats().missCount());    assertEquals(0, cache.stats().hitCount());    result = execute("TO_UPPER(name)", contextWithCache);    assertEquals("BLAH", result);    assertEquals(2, cache.stats().requestCount());    assertEquals(1, cache.stats().missCount());    assertEquals(1, cache.stats().hitCount());    result = execute("TO_UPPER(name)", contextWithCache);    assertEquals("BLAH", result);    assertEquals(3, cache.stats().requestCount());    assertEquals(1, cache.stats().missCount());    assertEquals(2, cache.stats().hitCount());}
0
public void testNoCache() throws Exception
{        Context contextNoCache = Context.EMPTY_CONTEXT();    assertEquals("BLAH", execute("TO_UPPER(name)", contextNoCache));    assertEquals("BLAH", execute("TO_UPPER(name)", contextNoCache));}
0
public void testInvalidMaxCacheSize()
{    Map<String, Object> cacheConfig = ImmutableMap.of(CachingStellarProcessor.MAX_CACHE_SIZE_PARAM, -1, CachingStellarProcessor.MAX_TIME_RETAIN_PARAM, 10);    cache = CachingStellarProcessor.createCache(cacheConfig);    assertNull(cache);}
0
public void testMissingMaxCacheSize()
{    Map<String, Object> cacheConfig = ImmutableMap.of(CachingStellarProcessor.MAX_TIME_RETAIN_PARAM, 10);    cache = CachingStellarProcessor.createCache(cacheConfig);    assertNull(cache);}
0
public void testInvalidMaxTimeRetain()
{    Map<String, Object> cacheConfig = ImmutableMap.of(CachingStellarProcessor.MAX_CACHE_SIZE_PARAM, 10, CachingStellarProcessor.MAX_TIME_RETAIN_PARAM, -2);    cache = CachingStellarProcessor.createCache(cacheConfig);    assertNull(cache);}
0
public void testMissingMaxTimeRetain()
{    Map<String, Object> cacheConfig = ImmutableMap.of(CachingStellarProcessor.MAX_CACHE_SIZE_PARAM, 10);    cache = CachingStellarProcessor.createCache(cacheConfig);    assertNull(cache);}
0
public void testUnrelatedVariableChange()
{        Object result = execute("TO_UPPER(name)", contextWithCache);    assertEquals("BLAH", result);    assertEquals(1, cache.stats().requestCount());    assertEquals(1, cache.stats().missCount());    assertEquals(0, cache.stats().hitCount());        fields.put("unrelated_var_1", "true");    fields.put("unrelated_var_2", 22);        result = execute("TO_UPPER(name)", contextWithCache);    assertEquals("BLAH", result);    assertEquals(2, cache.stats().requestCount());    assertEquals(1, cache.stats().missCount());    assertEquals(1, cache.stats().hitCount());}
0
private Object execute(String expression, Context context)
{    Object result = processor.parse(expression, new MapVariableResolver(fields), StellarFunctions.FUNCTION_RESOLVER(), context);    return result;}
0
public void setup() throws ParseException
{        JSONParser parser = new JSONParser();    message = (JSONObject) parser.parse(input);        executor = new DefaultStellarStatefulExecutor();    executor.setContext(Context.EMPTY_CONTEXT());    ClasspathFunctionResolver resolver = new ClasspathFunctionResolver();    executor.setFunctionResolver(resolver);}
0
public void testAssign()
{    executor.assign("foo", "2", message);        Object var = executor.getState().get("foo");    assertThat(var, instanceOf(Integer.class));    assertThat(var, equalTo(2));}
0
public void testAssignWithVariableResolution()
{    executor.assign("foo", "ip_src_addr", message);        Object var = executor.getState().get("foo");    assertThat(var, instanceOf(String.class));    assertThat(var, equalTo("10.0.0.1"));}
0
public void testState()
{    executor.assign("two", "2", message);    executor.assign("four", "4", message);    executor.assign("sum", "two + four", message);        Object var = executor.getState().get("sum");    assertEquals(6, var);}
0
public void testClearState()
{    executor.assign("two", "2", message);    executor.clearState();        assertThat(executor.getState().containsKey("two"), equalTo(false));}
0
public void testExecuteTransformation()
{    String actual = executor.execute("TO_UPPER('lowercase')", message, String.class);    assertThat(actual, equalTo("LOWERCASE"));}
0
public void testExecutePredicate()
{    boolean actual = executor.execute("IS_INTEGER(2)", message, Boolean.class);    assertThat(actual, equalTo(true));}
0
public void testExecuteWithWrongType()
{    executor.execute("2 + 2", message, Boolean.class);}
0
public void testExecuteWithTypeConversion()
{    executor.execute("2", message, Double.class);    executor.execute("2", message, Float.class);    executor.execute("2", message, Short.class);    executor.execute("2", message, Long.class);}
0
public void testSerializable() throws Exception
{        ByteArrayOutputStream bytes = new ByteArrayOutputStream();    new ObjectOutputStream(bytes).writeObject(executor);        new ObjectInputStream(new ByteArrayInputStream(bytes.toByteArray())).readObject();}
0
public void is() throws Exception
{        Assert.assertTrue(Encodings.BASE32.is(BASE32_FIXTURE));    Assert.assertFalse(Encodings.BASE32.is(STRING_FIXTURE));        Assert.assertTrue(Encodings.BASE32HEX.is(BASE32HEX_FIXTURE));    Assert.assertFalse(Encodings.BASE32HEX.is(STRING_FIXTURE));        Assert.assertTrue(Encodings.BASE64.is(BASE64_FIXTURE));    Assert.assertFalse(Encodings.BASE64.is(STRING_FIXTURE + "\0"));        Assert.assertTrue(Encodings.BINARY.is(BINARY_FIXTURE));    Assert.assertFalse(Encodings.BINARY.is(STRING_FIXTURE));        Assert.assertTrue(Encodings.HEX.is(HEX_FIXTURE));    Assert.assertFalse(Encodings.HEX.is("AAA"));}
0
public void decode() throws Exception
{    Assert.assertEquals(STRING_FIXTURE, Encodings.BASE32.decode(BASE32_FIXTURE));    Assert.assertEquals(STRING_FIXTURE, Encodings.BASE32HEX.decode(BASE32HEX_FIXTURE));    Assert.assertEquals(STRING_FIXTURE, Encodings.BASE64.decode(BASE64_FIXTURE));    Assert.assertEquals(STRING_FIXTURE, Encodings.BINARY.decode(BINARY_FIXTURE));    Assert.assertEquals(STRING_FIXTURE, Encodings.HEX.decode(HEX_FIXTURE));        Assert.assertNotEquals(STRING_FIXTURE, Encodings.BASE32.decode(STRING_FIXTURE));    Assert.assertNotEquals(STRING_FIXTURE, Encodings.BASE32HEX.decode(STRING_FIXTURE));    Assert.assertNotEquals(STRING_FIXTURE, Encodings.BASE64.decode(STRING_FIXTURE));            Assert.assertEquals(STRING_FIXTURE, Encodings.BINARY.decode(STRING_FIXTURE));    Assert.assertEquals(STRING_FIXTURE, Encodings.HEX.decode(STRING_FIXTURE));}
0
public void decodeWithVerify() throws Exception
{    Assert.assertEquals(STRING_FIXTURE, Encodings.BASE32.decode(BASE32_FIXTURE, true));    Assert.assertEquals(STRING_FIXTURE, Encodings.BASE32HEX.decode(BASE32HEX_FIXTURE, true));    Assert.assertEquals(STRING_FIXTURE, Encodings.BASE64.decode(BASE64_FIXTURE, true));    Assert.assertEquals(STRING_FIXTURE, Encodings.BINARY.decode(BINARY_FIXTURE, true));    Assert.assertEquals(STRING_FIXTURE, Encodings.HEX.decode(HEX_FIXTURE, true));        Assert.assertEquals(STRING_FIXTURE, Encodings.BASE32.decode(STRING_FIXTURE, true));    Assert.assertEquals(STRING_FIXTURE, Encodings.BASE32HEX.decode(STRING_FIXTURE, true));        Assert.assertNotEquals(STRING_FIXTURE, Encodings.BASE64.decode(STRING_FIXTURE, true));        Assert.assertEquals(STRING_FIXTURE + "\0", Encodings.BASE64.decode(STRING_FIXTURE + "\0", true));    Assert.assertEquals(STRING_FIXTURE, Encodings.BINARY.decode(STRING_FIXTURE, true));    Assert.assertEquals(STRING_FIXTURE, Encodings.HEX.decode(STRING_FIXTURE, true));}
0
public void testEncode() throws Exception
{    Assert.assertEquals(BASE32_FIXTURE, Encodings.BASE32.encode(STRING_FIXTURE));    Assert.assertEquals(BASE32HEX_FIXTURE, Encodings.BASE32HEX.encode(STRING_FIXTURE));    Assert.assertEquals(BASE64_FIXTURE, Encodings.BASE64.encode(STRING_FIXTURE));    Assert.assertEquals(BINARY_FIXTURE, Encodings.BINARY.encode(STRING_FIXTURE));    Assert.assertEquals(HEX_FIXTURE, Encodings.HEX.encode(STRING_FIXTURE));}
0
public void evaluateDoubleShouldReturnDoubleAdd() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Double> r = mock(Token.class);    when(r.getValue()).thenReturn(2D);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), p);    assertTrue(evaluated.getValue() instanceof Double);    assertEquals(3.0D, evaluated.getValue());}
0
public void evaluateIntegerShouldReturnIntegerAdd() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), p);    assertTrue(evaluated.getValue() instanceof Integer);    assertEquals(3, evaluated.getValue());}
0
public void evaluateFloatsShouldReturnFloatAdd() throws Exception
{    Token<Float> l = mock(Token.class);    when(l.getValue()).thenReturn(1F);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), p);    assertTrue(evaluated.getValue() instanceof Float);    assertEquals(3F, evaluated.getValue());}
0
public void evaluateLongsShouldReturnLongAdd() throws Exception
{    Token<Long> l = mock(Token.class);    when(l.getValue()).thenReturn(1L);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), p);    assertTrue(evaluated.getValue() instanceof Long);    assertEquals(3L, evaluated.getValue());}
0
public void evaluateIntegerShouldReturnDoubleMul() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Double> r = mock(Token.class);    when(r.getValue()).thenReturn(2D);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.multiplication(null), p);    assertTrue(evaluated.getValue() instanceof Double);    assertEquals(2.0D, evaluated.getValue());}
0
public void evaluateIntegerShouldReturnIntegerMul() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.multiplication(null), p);    assertTrue(evaluated.getValue() instanceof Integer);    assertEquals(2, evaluated.getValue());}
0
public void evaluateFloatsShouldReturnFloatMul() throws Exception
{    Token<Float> l = mock(Token.class);    when(l.getValue()).thenReturn(1F);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.multiplication(null), p);    assertTrue(evaluated.getValue() instanceof Float);    assertEquals(2F, evaluated.getValue());}
0
public void evaluateLongsShouldReturnLongMul() throws Exception
{    Token<Long> l = mock(Token.class);    when(l.getValue()).thenReturn(1L);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.multiplication(null), p);    assertTrue(evaluated.getValue() instanceof Long);    assertEquals(2L, evaluated.getValue());}
0
public void evaluateDoubleShouldReturnDoubleSub() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Double> r = mock(Token.class);    when(r.getValue()).thenReturn(2D);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.subtraction(null), p);    assertTrue(evaluated.getValue() instanceof Double);    assertEquals(-1.0D, evaluated.getValue());}
0
public void evaluateIntegerShouldReturnIntegerSub() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.subtraction(null), p);    assertTrue(evaluated.getValue() instanceof Integer);    assertEquals(-1, evaluated.getValue());}
0
public void evaluateFloatsShouldReturnFloatSub() throws Exception
{    Token<Float> l = mock(Token.class);    when(l.getValue()).thenReturn(1F);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.subtraction(null), p);    assertTrue(evaluated.getValue() instanceof Float);    assertEquals(-1F, evaluated.getValue());}
0
public void evaluateLongsShouldReturnLongSub() throws Exception
{    Token<Long> l = mock(Token.class);    when(l.getValue()).thenReturn(1L);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.subtraction(null), p);    assertTrue(evaluated.getValue() instanceof Long);    assertEquals(-1L, evaluated.getValue());}
0
public void evaluateDoubleShouldReturnDoubleDiv() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Double> r = mock(Token.class);    when(r.getValue()).thenReturn(2D);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), p);    assertTrue(evaluated.getValue() instanceof Double);    assertEquals(1 / 2D, evaluated.getValue());}
0
public void evaluateIntegerShouldReturnIntegerDiv() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), p);    assertTrue(evaluated.getValue() instanceof Integer);    assertEquals(1 / 2, evaluated.getValue());}
0
public void evaluateFloatsShouldReturnFloatDiv() throws Exception
{    Token<Float> l = mock(Token.class);    when(l.getValue()).thenReturn(1F);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), p);    assertTrue(evaluated.getValue() instanceof Float);    assertEquals(0.5F, evaluated.getValue());}
0
public void evaluateLongsShouldReturnLongDiv() throws Exception
{    Token<Long> l = mock(Token.class);    when(l.getValue()).thenReturn(1L);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), p);    assertTrue(evaluated.getValue() instanceof Long);    assertEquals(0L, evaluated.getValue());}
0
public void evaluateShouldThroughIllegalArgumentExceptionWhenInputIsNull() throws Exception
{    evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), null);}
0
public void evaluateShouldThroughIllegalArgumentExceptionWhenInputsKeyIsNull() throws Exception
{    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(null, mock(Token.class));    evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), p);}
0
public void evaluateShouldThroughIllegalArgumentExceptionWhenInputsValueIsNull() throws Exception
{    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(mock(Token.class), null);    evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), p);}
0
public void evaluateShouldConvertShortsToIntegersType() throws Exception
{    Token<Short> l = mock(Token.class);    when(l.getValue()).thenReturn((short) 2);    Token<Short> r = mock(Token.class);    when(r.getValue()).thenReturn((short) 3);    Token<? extends Number> evaluated0 = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), Pair.of(l, r));    Token<? extends Number> evaluated1 = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.subtraction(null), Pair.of(l, r));    Token<? extends Number> evaluated2 = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.multiplication(null), Pair.of(l, r));    Token<? extends Number> evaluated3 = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), Pair.of(l, r));    assertTrue(evaluated0.getValue() instanceof Integer);    assertEquals(5, evaluated0.getValue());    assertTrue(evaluated1.getValue() instanceof Integer);    assertEquals(-1, evaluated1.getValue());    assertTrue(evaluated2.getValue() instanceof Integer);    assertEquals(6, evaluated2.getValue());    assertTrue(evaluated3.getValue() instanceof Integer);    assertEquals(0, evaluated3.getValue());}
0
public void evaluateIntegerShouldReturnIntegerWhenLeftsValueIsNull() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(null);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(2);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), p);    assertTrue(evaluated.getValue() instanceof Integer);    assertEquals(2, evaluated.getValue());}
0
public void evaluateIntegerShouldReturnIntegerWhenRightsValueIsNull() throws Exception
{    Token<Integer> l = mock(Token.class);    when(l.getValue()).thenReturn(1);    Token<Integer> r = mock(Token.class);    when(r.getValue()).thenReturn(null);    Pair<Token<? extends Number>, Token<? extends Number>> p = Pair.of(l, r);    Token<? extends Number> evaluated = evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), p);    assertTrue(evaluated.getValue() instanceof Integer);    assertEquals(1, evaluated.getValue());}
0
public void verifyExpectedReturnTypes() throws Exception
{    Token<Integer> integer = mock(Token.class);    when(integer.getValue()).thenReturn(1);    Token<Long> lng = mock(Token.class);    when(lng.getValue()).thenReturn(1L);    Token<Double> dbl = mock(Token.class);    when(dbl.getValue()).thenReturn(1.0D);    Token<Float> flt = mock(Token.class);    when(flt.getValue()).thenReturn(1.0F);    Map<Pair<Token<? extends Number>, Token<? extends Number>>, Class<? extends Number>> expectedReturnTypeMappings = new HashMap<Pair<Token<? extends Number>, Token<? extends Number>>, Class<? extends Number>>() {        {            put(Pair.of(flt, lng), Float.class);            put(Pair.of(flt, dbl), Double.class);            put(Pair.of(flt, flt), Float.class);            put(Pair.of(flt, integer), Float.class);            put(Pair.of(lng, lng), Long.class);            put(Pair.of(lng, dbl), Double.class);            put(Pair.of(lng, flt), Float.class);            put(Pair.of(lng, integer), Long.class);            put(Pair.of(dbl, lng), Double.class);            put(Pair.of(dbl, dbl), Double.class);            put(Pair.of(dbl, flt), Double.class);            put(Pair.of(dbl, integer), Double.class);            put(Pair.of(integer, lng), Long.class);            put(Pair.of(integer, dbl), Double.class);            put(Pair.of(integer, flt), Float.class);            put(Pair.of(integer, integer), Integer.class);        }    };    expectedReturnTypeMappings.forEach((pair, expectedClass) -> {        assertTrue(evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.addition(null), pair).getValue().getClass() == expectedClass);        assertTrue(evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.division(null), pair).getValue().getClass() == expectedClass);        assertTrue(evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.subtraction(null), pair).getValue().getClass() == expectedClass);        assertTrue(evaluator.evaluate(ArithmeticEvaluator.ArithmeticEvaluatorFunctions.multiplication(null), pair).getValue().getClass() == expectedClass);    });}
0
public void evaluateEqShouldProperlyCallEqualityOperatorsEvaluator() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(1D);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    Token<Boolean> evaluated = evaluator.evaluate(left, right, op, null);    assertTrue(evaluated.getValue());}
0
public void evaluateNotEqShouldProperlyCallEqualityOperatorsEvaluator() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(1D);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.NEQ()).thenReturn(mock(TerminalNode.class));    Token<Boolean> evaluated = evaluator.evaluate(left, right, op, null);    assertFalse(evaluated.getValue());}
0
public void evaluateLessThanEqShouldProperlyCallEqualityOperatorsEvaluator() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(0D);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.LTE()).thenReturn(mock(TerminalNode.class));    Token<Boolean> evaluated = evaluator.evaluate(left, right, op, null);    assertTrue(evaluated.getValue());}
0
public void unexpectedOperatorShouldThrowException() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage("Unsupported operations. The following expression is invalid: ");    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(0D);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    evaluator.evaluate(left, right, op, null);}
0
public void nonExpectedOperatorShouldThrowException() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage("Unsupported operations. The following expression is invalid: ");    Token<String> left = mock(Token.class);    when(left.getValue()).thenReturn("adsf");    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.LTE()).thenReturn(mock(TerminalNode.class));    evaluator.evaluate(left, right, op, null);}
0
public void setUp() throws Exception
{    evaluator = new ComparisonOperatorsEvaluator();}
0
public void nonSupportedOperatorThrowsExceptionNonNumbericComparable() throws Exception
{    Token<String> left = mock(Token.class);    when(left.getValue()).thenReturn("b");    Token<String> right = mock(Token.class);    when(right.getValue()).thenReturn("a");    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    exception.expect(ParseException.class);    exception.expectMessage("Unsupported operator: " + op);    evaluator.evaluate(left, right, op);}
0
public void nonSupportedOperatorThrowsExceptionNumbericComparison() throws Exception
{    Token<Long> left = mock(Token.class);    when(left.getValue()).thenReturn(1L);    Token<Long> right = mock(Token.class);    when(right.getValue()).thenReturn(0L);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    exception.expect(ParseException.class);    exception.expectMessage("Unsupported operator: " + op);    evaluator.evaluate(left, right, op);}
0
public void leftIsNullThenThrowException() throws Exception
{    Token<Long> left = mock(Token.class);    Token<Long> right = mock(Token.class);    when(right.getValue()).thenReturn(1L);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.LT()).thenReturn(mock(TerminalNode.class));    assertFalse(evaluator.evaluate(left, right, op));}
0
public void rightIsNullThenReturnFalse() throws Exception
{    Token<Long> left = mock(Token.class);    when(left.getValue()).thenReturn(1L);    Token<Long> right = mock(Token.class);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.LT()).thenReturn(mock(TerminalNode.class));    assertFalse(evaluator.evaluate(left, right, op));}
0
public void rightAndLeftIsNullThenReturnFalse() throws Exception
{    Token<Long> left = mock(Token.class);    Token<Long> right = mock(Token.class);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.LT()).thenReturn(mock(TerminalNode.class));    assertFalse(evaluator.evaluate(left, right, op));}
0
public void throwParseExceptionWhenTryingToCompareNonComparable() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage("Unsupported operations. The following expression is invalid: ");    Token<Serializable> left = mock(Token.class);    when(left.getValue()).thenReturn(mock(Serializable.class));    Token<Serializable> right = mock(Token.class);    when(right.getValue()).thenReturn(mock(Serializable.class));    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.LT()).thenReturn(mock(TerminalNode.class));    evaluator.evaluate(left, right, op);}
0
public void makeSureAllOperatorsProperlyWorkForLongs() throws Exception
{    Token<Long> left = mock(Token.class);    when(left.getValue()).thenReturn(0L);    Token<Long> right = mock(Token.class);    when(right.getValue()).thenReturn(1L);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsProperlyWorkForDoubles() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(0D);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsProperlyWorkForFloats() throws Exception
{    Token<Float> left = mock(Token.class);    when(left.getValue()).thenReturn(0F);    Token<Float> right = mock(Token.class);    when(right.getValue()).thenReturn(1F);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsProperlyWorkForInts() throws Exception
{    Token<Integer> left = mock(Token.class);    when(left.getValue()).thenReturn(0);    Token<Integer> right = mock(Token.class);    when(right.getValue()).thenReturn(1);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsWorkForMixedTypesDoublesLong() throws Exception
{    Token<Long> left = mock(Token.class);    when(left.getValue()).thenReturn(1L);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1.0000001D);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertTrue(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertFalse(evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsWorkForMixedTypesDoublesFloat() throws Exception
{    final double leftValue = 1.0000001D;    final float rightValue = 1.0000001F;    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(leftValue);    Token<Float> right = mock(Token.class);    when(right.getValue()).thenReturn(rightValue);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue < rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue <= rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue > rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue >= rightValue, evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsWorkForMixedTypesFloatIntegers() throws Exception
{    final int leftValue = 1;    final float rightValue = 1.0000001F;    Token<Integer> left = mock(Token.class);    when(left.getValue()).thenReturn(leftValue);    Token<Float> right = mock(Token.class);    when(right.getValue()).thenReturn(rightValue);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue < rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue <= rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue > rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue >= rightValue, evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsWorkForMixedTypesFloatIntegers2() throws Exception
{    final int leftValue = 1;    final float rightValue = 1.00000001F;    Token<Integer> left = mock(Token.class);    when(left.getValue()).thenReturn(leftValue);    Token<Float> right = mock(Token.class);    when(right.getValue()).thenReturn(rightValue);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue < rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue <= rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue > rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue >= rightValue, evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsWorkForMixedTypesLongIntegers() throws Exception
{    final int leftValue = 1;    final long rightValue = 3L;    Token<Integer> left = mock(Token.class);    when(left.getValue()).thenReturn(leftValue);    Token<Long> right = mock(Token.class);    when(right.getValue()).thenReturn(rightValue);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue < rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue <= rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue > rightValue, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue >= rightValue, evaluator.evaluate(left, right, op));    }}
0
public void makeSureAllOperatorsWorkForNonIntegerComparableTypes() throws Exception
{    final String leftValue = "a";    final String rightValue = "b";    Token<String> left = mock(Token.class);    when(left.getValue()).thenReturn(leftValue);    Token<String> right = mock(Token.class);    when(right.getValue()).thenReturn(rightValue);    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue.compareTo(rightValue) < 0, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.LTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue.compareTo(rightValue) <= 0, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GT()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue.compareTo(rightValue) > 0, evaluator.evaluate(left, right, op));    }    {        StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);        when(op.GTE()).thenReturn(mock(TerminalNode.class));        assertEquals(leftValue.compareTo(rightValue) >= 0, evaluator.evaluate(left, right, op));    }}
0
public void setUp() throws Exception
{    evaluator = new DoubleLiteralEvaluator();    context = mock(StellarParser.DoubleLiteralContext.class);}
0
public void verifyHappyPathEvaluation() throws Exception
{    when(context.getText()).thenReturn("100D");    Token<? extends Number> evaluated = evaluator.evaluate(context, null);    assertEquals(new Token<>(100D, Double.class, null), evaluated);    verify(context).getText();    verifyNoMoreInteractions(context);}
0
public void verifyNumberFormationExceptionWithEmptyString() throws Exception
{    exception.expect(NumberFormatException.class);    when(context.getText()).thenReturn("");    evaluator.evaluate(context, null);}
0
public void throwIllegalArgumentExceptionWhenContextIsNull() throws Exception
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("Cannot evaluate a context that is null.");    evaluator.evaluate(null, null);}
0
public void setUp() throws Exception
{    evaluator = new EqualityOperatorsEvaluator();}
0
public void leftAndRightNullShouldBeTrue() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(null);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(null);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    boolean evaluated = evaluator.evaluate(left, right, op);    assertTrue(evaluated);}
0
public void leftNullAndRightNotShouldBeFalse() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(null);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    boolean evaluated = evaluator.evaluate(left, right, op);    assertFalse(evaluated);}
0
public void leftNotNullAndRightNullShouldBeFalse() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(1D);    Token<Long> right = mock(Token.class);    when(right.getValue()).thenReturn(null);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    boolean evaluated = evaluator.evaluate(left, right, op);    assertFalse(evaluated);}
0
public void eqTestForTwoLongs() throws Exception
{    Token<Long> left = mock(Token.class);    when(left.getValue()).thenReturn(1L);    Token<Long> right = mock(Token.class);    when(right.getValue()).thenReturn(1L);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    assertTrue(evaluator.evaluate(left, right, op));}
0
public void eqTestForTwoDoubles() throws Exception
{    Token<Double> left = mock(Token.class);    when(left.getValue()).thenReturn(1D);    Token<Double> right = mock(Token.class);    when(right.getValue()).thenReturn(1D);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    assertTrue(evaluator.evaluate(left, right, op));}
0
public void eqTestForTwoFloats() throws Exception
{    Token<Float> left = mock(Token.class);    when(left.getValue()).thenReturn(1F);    Token<Float> right = mock(Token.class);    when(right.getValue()).thenReturn(1F);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    assertTrue(evaluator.evaluate(left, right, op));}
0
public void eqTestForTwoIntegers() throws Exception
{    Token<Integer> left = mock(Token.class);    when(left.getValue()).thenReturn(1);    Token<Integer> right = mock(Token.class);    when(right.getValue()).thenReturn(1);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    assertTrue(evaluator.evaluate(left, right, op));}
0
public void eqTestForTwoStrings() throws Exception
{    Token<String> left = mock(Token.class);    when(left.getValue()).thenReturn("1");    Token<String> right = mock(Token.class);    when(right.getValue()).thenReturn("1");    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    assertTrue(evaluator.evaluate(left, right, op));}
0
public void eqTestForUnlikeTypes() throws Exception
{    Token<String> left = mock(Token.class);    when(left.getValue()).thenReturn("1");    Token<Long> right = mock(Token.class);    when(right.getValue()).thenReturn(1L);    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    assertFalse(evaluator.evaluate(left, right, op));}
0
public void eqTestForUnlikeTypesLongString() throws Exception
{    Token<Long> left = mock(Token.class);    when(left.getValue()).thenReturn(1L);    Token<String> right = mock(Token.class);    when(right.getValue()).thenReturn("1");    StellarParser.ComparisonOpContext op = mock(StellarParser.ComparisonOpContext.class);    when(op.EQ()).thenReturn(mock(TerminalNode.class));    assertFalse(evaluator.evaluate(left, right, op));}
0
public void setUp() throws Exception
{    evaluator = new FloatLiteralEvaluator();    context = mock(StellarParser.FloatLiteralContext.class);}
0
public void verifyHappyPathEvaluation() throws Exception
{    when(context.getText()).thenReturn("100f");    Token<? extends Number> evaluated = evaluator.evaluate(context, null);    assertEquals(new Token<>(100f, Float.class, null), evaluated);    verify(context).getText();    verifyNoMoreInteractions(context);}
0
public void verifyNumberFormationExceptionWithEmptyString() throws Exception
{    exception.expect(NumberFormatException.class);    when(context.getText()).thenReturn("");    evaluator.evaluate(context, null);}
0
public void throwIllegalArgumentExceptionWhenContextIsNull() throws Exception
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("Cannot evaluate a context that is null.");    evaluator.evaluate(null, null);}
0
public void setUp() throws Exception
{    evaluator = new IntLiteralEvaluator();    context = mock(StellarParser.IntLiteralContext.class);}
0
public void verifyHappyPathEvaluation() throws Exception
{    when(context.getText()).thenReturn("100");    Token<? extends Number> evaluated = evaluator.evaluate(context, null);    assertEquals(new Token<>(100, Integer.class, null), evaluated);    verify(context).getText();    verifyNoMoreInteractions(context);}
0
public void verifyNumberFormationExceptionWithEmptyString() throws Exception
{    exception.expect(NumberFormatException.class);    when(context.getText()).thenReturn("");    evaluator.evaluate(context, null);}
0
public void throwIllegalArgumentExceptionWhenContextIsNull() throws Exception
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("Cannot evaluate a context that is null.");    evaluator.evaluate(null, null);}
0
public void setUp() throws Exception
{    evaluator = new LongLiteralEvaluator();    context = mock(StellarParser.LongLiteralContext.class);}
0
public void verifyHappyPathEvaluation() throws Exception
{    when(context.getText()).thenReturn("100L");    Token<? extends Number> evaluated = evaluator.evaluate(context, null);    assertEquals(new Token<>(100L, Long.class, null), evaluated);    verify(context).getText();    verifyNoMoreInteractions(context);}
0
public void verifyNumberFormationExceptionWithEmptyString() throws Exception
{    exception.expect(ParseException.class);    exception.expectMessage("Invalid format for long. Failed trying to parse a long with the following value: ");    when(context.getText()).thenReturn("");    evaluator.evaluate(context, null);}
0
public void throwIllegalArgumentExceptionWhenContextIsNull() throws Exception
{    exception.expect(IllegalArgumentException.class);    exception.expectMessage("Cannot evaluate a context that is null.");    evaluator.evaluate(null, null);}
0
public void setUp() throws Exception
{    intLiteralContextNumberEvaluator = mock(IntLiteralEvaluator.class);    doubleLiteralContextNumberEvaluator = mock(DoubleLiteralEvaluator.class);    floatLiteralContextNumberEvaluator = mock(FloatLiteralEvaluator.class);    longLiteralContextNumberEvaluator = mock(LongLiteralEvaluator.class);    instanceMap = new HashMap<Class<? extends StellarParser.Arithmetic_operandsContext>, NumberEvaluator>() {        {            put(mock(StellarParser.IntLiteralContext.class).getClass(), intLiteralContextNumberEvaluator);            put(mock(StellarParser.DoubleLiteralContext.class).getClass(), doubleLiteralContextNumberEvaluator);            put(mock(StellarParser.FloatLiteralContext.class).getClass(), floatLiteralContextNumberEvaluator);            put(mock(StellarParser.LongLiteralContext.class).getClass(), longLiteralContextNumberEvaluator);        }    };}
0
public void verifyIntLiteralContextIsProperlyEvaluated() throws Exception
{    StellarParser.IntLiteralContext context = mock(StellarParser.IntLiteralContext.class);    NumberLiteralEvaluator.INSTANCE.evaluate(context, instanceMap, null);    verify(intLiteralContextNumberEvaluator).evaluate(context, null);    verifyZeroInteractions(doubleLiteralContextNumberEvaluator, floatLiteralContextNumberEvaluator, longLiteralContextNumberEvaluator);}
0
public void verifyDoubleLiteralContextIsProperlyEvaluated() throws Exception
{    StellarParser.DoubleLiteralContext context = mock(StellarParser.DoubleLiteralContext.class);    NumberLiteralEvaluator.INSTANCE.evaluate(context, instanceMap, null);    verify(doubleLiteralContextNumberEvaluator).evaluate(context, null);    verifyZeroInteractions(intLiteralContextNumberEvaluator, floatLiteralContextNumberEvaluator, longLiteralContextNumberEvaluator);}
0
public void verifyFloatLiteralContextIsProperlyEvaluated() throws Exception
{    StellarParser.FloatLiteralContext context = mock(StellarParser.FloatLiteralContext.class);    NumberLiteralEvaluator.INSTANCE.evaluate(context, instanceMap, null);    verify(floatLiteralContextNumberEvaluator).evaluate(context, null);    verifyZeroInteractions(doubleLiteralContextNumberEvaluator, intLiteralContextNumberEvaluator, longLiteralContextNumberEvaluator);}
0
public void verifyLongLiteralContextIsProperlyEvaluated() throws Exception
{    StellarParser.LongLiteralContext context = mock(StellarParser.LongLiteralContext.class);    NumberLiteralEvaluator.INSTANCE.evaluate(context, instanceMap, null);    verify(longLiteralContextNumberEvaluator).evaluate(context, null);    verifyZeroInteractions(doubleLiteralContextNumberEvaluator, floatLiteralContextNumberEvaluator, intLiteralContextNumberEvaluator);}
0
public void verifyExceptionThrownForUnsupportedContextType() throws Exception
{    StellarParser.VariableContext context = mock(StellarParser.VariableContext.class);    exception.expect(ParseException.class);    exception.expectMessage("Does not support evaluation for type " + context.getClass());    NumberLiteralEvaluator.INSTANCE.evaluate(context, instanceMap, null);    verifyZeroInteractions(longLiteralContextNumberEvaluator, doubleLiteralContextNumberEvaluator, floatLiteralContextNumberEvaluator, intLiteralContextNumberEvaluator);}
0
public void inSubnetTest_positive()
{    runWithArguments("IN_SUBNET", ImmutableList.of("192.168.0.1", "192.168.0.0/24"), true);}
0
public void inSubnetTest_negative()
{    runWithArguments("IN_SUBNET", ImmutableList.of("192.168.1.1", "192.168.0.0/24"), false);}
0
public void inSubnetTest_multiple()
{    runWithArguments("IN_SUBNET", ImmutableList.of("192.168.1.1", "192.168.0.0/24", "192.168.1.0/24"), true);}
0
public void removeSubdomainsTest()
{    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "www.google.co.uk", "google.co.uk");    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "www.google.com", "google.com");    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "com", "com");}
0
public void removeSubdomainsTest_tld_square()
{    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "com.com", "com.com");    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "net.net", "net.net");    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "co.uk.co.uk", "uk.co.uk");    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "www.subdomain.com.com", "com.com");}
0
public void removeSubdomainsTest_unknowntld()
{    runWithArguments("DOMAIN_REMOVE_SUBDOMAINS", "www.subdomain.google.gmail", "google.gmail");}
0
public void toTldTest()
{    runWithArguments("DOMAIN_TO_TLD", "www.google.co.uk", "co.uk");    runWithArguments("DOMAIN_TO_TLD", "www.google.com", "com");    runWithArguments("DOMAIN_TO_TLD", "com", "com");}
0
public void toTldTest_tld_square()
{    runWithArguments("DOMAIN_TO_TLD", "com.com", "com");    runWithArguments("DOMAIN_TO_TLD", "net.net", "net");    runWithArguments("DOMAIN_TO_TLD", "co.uk.co.uk", "co.uk");    runWithArguments("DOMAIN_TO_TLD", "www.subdomain.com.com", "com");}
0
public void toTldTest_unknowntld()
{    runWithArguments("DOMAIN_TO_TLD", "www.subdomain.google.gmail", "gmail");}
0
public void removeTldTest()
{    runWithArguments("DOMAIN_REMOVE_TLD", "google.com", "google");    runWithArguments("DOMAIN_REMOVE_TLD", "www.google.co.uk", "www.google");    runWithArguments("DOMAIN_REMOVE_TLD", "www.google.com", "www.google");    runWithArguments("DOMAIN_REMOVE_TLD", "com", "");}
0
public void removeTldTest_tld_square()
{    runWithArguments("DOMAIN_REMOVE_TLD", "com.com", "com");    runWithArguments("DOMAIN_REMOVE_TLD", "net.net", "net");    runWithArguments("DOMAIN_REMOVE_TLD", "co.uk.co.uk", "co.uk");    runWithArguments("DOMAIN_REMOVE_TLD", "www.subdomain.com.com", "www.subdomain.com");}
0
public void removeTldTest_unknowntld()
{    runWithArguments("DOMAIN_REMOVE_TLD", "www.subdomain.google.gmail", "www.subdomain.google");}
0
public void urlToPortTest()
{    runWithArguments("URL_TO_PORT", "http://www.google.com/foo/bar", 80);    runWithArguments("URL_TO_PORT", "https://www.google.com/foo/bar", 443);    runWithArguments("URL_TO_PORT", "http://www.google.com:7979/foo/bar", 7979);}
0
public void urlToPortTest_unknowntld()
{    runWithArguments("URL_TO_PORT", "http://www.google.gmail/foo/bar", 80);}
0
public void urlToHostTest()
{    runWithArguments("URL_TO_HOST", "http://www.google.com/foo/bar", "www.google.com");    runWithArguments("URL_TO_HOST", "https://www.google.com/foo/bar", "www.google.com");    runWithArguments("URL_TO_HOST", "http://www.google.com:7979/foo/bar", "www.google.com");    runWithArguments("URL_TO_HOST", "http://localhost:8080/a", "localhost");}
0
public void urlToHostTest_unknowntld()
{    runWithArguments("URL_TO_HOST", "http://www.google.gmail/foo/bar", "www.google.gmail");}
0
public void urlToProtocolTest()
{    runWithArguments("URL_TO_PROTOCOL", "http://www.google.com/foo/bar", "http");    runWithArguments("URL_TO_PROTOCOL", "https://www.google.com/foo/bar", "https");}
0
public void urlToProtocolTest_unknowntld()
{    runWithArguments("URL_TO_PROTOCOL", "http://www.google.gmail/foo/bar", "http");}
0
public void urlToPathTest()
{    runWithArguments("URL_TO_PATH", "http://www.google.com/foo/bar", "/foo/bar");    runWithArguments("URL_TO_PATH", "https://www.google.com/foo/bar", "/foo/bar");}
0
public void urlToPathTest_unknowntld()
{    runWithArguments("URL_TO_PATH", "http://www.google.gmail/foo/bar", "/foo/bar");}
0
public void validateOptions() throws Exception
{    String[] validZHostArg = new String[] { "-z", "localhost:8888" };    String[] validZHostArgNoPort = new String[] { "-z", "localhost" };    String[] validZIPArgNoPort = new String[] { "-z", "10.10.10.3" };    String[] validZHostArgList = new String[] { "-z", "localhost:8888,localhost:2181,localhost" };    String[] validZIPArg = new String[] { "-z", "10.10.10.3:9999" };    String[] invalidZNameArg = new String[] { "-z", "!!!@!!@!:8882" };    String[] invalidZIPArg = new String[] { "-z", "11111.22222.10.3:3332" };    String[] invalidZMissingNameArg = new String[] { "-z", ":8882" };    String[] invalidZZeroPortArg = new String[] { "-z", "youtube.com:0" };    String[] invalidZHugePortArg = new String[] { "-z", "youtube.com:75565" };    String existingFileName = "./target/existsFile";    String nonExistentFile = "./target/doesNotExist";    String[] validVFileArg = new String[] { "-v", existingFileName };    String[] validIrcFileArg = new String[] { "-irc", existingFileName };    String[] validPFileArg = new String[] { "-p", existingFileName };    String[] invalidVFileArg = new String[] { "-v", nonExistentFile };    String[] invalidIrcFileArg = new String[] { "-irc", nonExistentFile };    String[] invalidPFileArg = new String[] { "-p", nonExistentFile };    File existingFile = new File(existingFileName);    if (!existingFile.exists()) {        existingFile.createNewFile();    }    Options options = new Options();    options.addOption("z", "zookeeper", true, "Zookeeper URL");    options.addOption("v", "variables", true, "File containing a JSON Map of variables");    options.addOption("irc", "inputrc", true, "File containing the inputrc if not the default ~/.inputrc");    options.addOption("na", "no_ansi", false, "Make the input prompt not use ANSI colors.");    options.addOption("h", "help", false, "Print help");    options.addOption("p", "properties", true, "File containing Stellar properties");    CommandLineParser parser = new PosixParser();        CommandLine commandLine = parser.parse(options, validZHostArg);    StellarShellOptionsValidator.validateOptions(commandLine);    commandLine = parser.parse(options, validZIPArg);    StellarShellOptionsValidator.validateOptions(commandLine);    commandLine = parser.parse(options, validVFileArg);    StellarShellOptionsValidator.validateOptions(commandLine);    commandLine = parser.parse(options, validIrcFileArg);    StellarShellOptionsValidator.validateOptions(commandLine);    commandLine = parser.parse(options, validPFileArg);    StellarShellOptionsValidator.validateOptions(commandLine);    commandLine = parser.parse(options, validZHostArgNoPort);    StellarShellOptionsValidator.validateOptions(commandLine);    commandLine = parser.parse(options, validZHostArgList);    StellarShellOptionsValidator.validateOptions(commandLine);    commandLine = parser.parse(options, validZIPArgNoPort);    StellarShellOptionsValidator.validateOptions(commandLine);        boolean thrown = false;    try {        commandLine = parser.parse(options, invalidZNameArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for providing invalid host name ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidZIPArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for providing invalid ip address ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidZMissingNameArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for only providing port ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidZZeroPortArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for 0 port ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidZHugePortArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for port out of range ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidVFileArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for passing non-existant file to -v ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidVFileArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for passing non-existant file to -v ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidIrcFileArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for passing non-existant file to -irc ", thrown);    thrown = false;    try {        commandLine = parser.parse(options, invalidPFileArg);        StellarShellOptionsValidator.validateOptions(commandLine);    } catch (IllegalArgumentException e) {        thrown = true;    }    Assert.assertTrue("Did not catch failure for passing non-existant file to -p ", thrown);    thrown = false;}
0
public void setup() throws Exception
{    out = new ByteArrayOutputStream();    err = new ByteArrayOutputStream();        System.setOut(new PrintStream(out, false, StandardCharsets.UTF_8.name()));    System.setErr(new PrintStream(err, false, StandardCharsets.UTF_8.name()));    String[] args = new String[0];    stellarShell = new StellarShell(args);}
0
public void cleanUp()
{    System.setOut(null);    System.setErr(null);}
0
private String stdout()
{    return out.toString().replace(System.lineSeparator(), "");}
0
private String stdoutWithNewlines()
{    return out.toString();}
0
private String stderr()
{    return err.toString().replace(System.lineSeparator(), "");}
0
private ConsoleOperation createOp(String buffer)
{    return new ConsoleOperation(ControlOperator.APPEND_OUT, buffer);}
0
public void testExecuteStellar() throws Exception
{    stellarShell.execute(createOp("2 + 2"));    assertEquals("4", stdout());}
0
public void testBackslashInStrings() throws Exception
{    stellarShell.execute(createOp("SPLIT('foo\\\\bar', '\\\\')"));    assertEquals("[foo, bar]", stdout());}
0
public void testExecuteWithStellarList() throws Exception
{    stellarShell.execute(createOp("[1,2,3,4,5]"));    assertEquals("[1, 2, 3, 4, 5]", stdout());}
0
public void testExecuteWithStellarMap() throws Exception
{    stellarShell.execute(createOp("{ 'foo':2, 'key':'val' }"));    assertEquals("{foo=2, key=val}", stdout());}
0
public void testExecuteBadStellar() throws Exception
{    stellarShell.execute(createOp("2 + "));    final String expected = "[!] Unable to parse: 2 + ";    assertTrue(stdout().startsWith(expected));}
0
public void testExecuteNoop() throws Exception
{    stellarShell.execute(createOp("x"));    assertEquals("", stdout());}
0
public void testQuit() throws Exception
{    stellarShell.execute(createOp("quit"));        assertFalse(stellarShell.getConsole().isRunning());}
0
public void testStart() throws Exception
{    StellarShell.main(new String[0]);        assertTrue(stdoutWithNewlines().contains(StellarShell.WELCOME));}
0
public void testAutoComplete() throws Exception
{        final String buffer = "TO_";        int cursor = buffer.length();        AeshContext context = new DefaultAeshContext();    CompleteOperation op = new CompleteOperation(context, buffer, cursor);    stellarShell.complete(op);        List<String> candidates = op.getFormattedCompletionCandidates();    assertTrue(candidates.size() > 0);        for (String candidate : candidates) {        String completion = buffer + candidate;                assertEquals("(", completion.substring(completion.length() - 1));                String function = completion.substring(0, completion.length() - 1);        Iterable<String> allFunctions = stellarShell.getExecutor().getFunctionResolver().getFunctions();        String definedFunction = Iterables.find(allFunctions, (fn) -> fn.equals(function));        assertEquals(function, definedFunction);    }}
0
public void setup()
{    completer = new DefaultStellarAutoCompleter();}
0
public void testAutoCompleteFunction()
{        completer.addCandidateFunction("FREUD");    completer.addCandidateFunction("FRIEND");    completer.addCandidateFunction("FOE");        Iterable<String> result = completer.autoComplete("FR");        List<String> completes = Lists.newArrayList(result);    assertEquals(2, completes.size());        assertThat(completes, hasItem("FREUD("));    assertThat(completes, hasItem("FRIEND("));}
0
public void testNoCandidateFunctions()
{        completer.addCandidateFunction("FREUD");    completer.addCandidateFunction("FRIEND");    completer.addCandidateFunction("FOE");        Iterable<String> result = completer.autoComplete("G");        List<String> completes = Lists.newArrayList(result);    assertEquals(0, completes.size());}
0
public void testAutoCompleteVariable()
{        completer.addCandidateVariable("very");    completer.addCandidateVariable("vast");    completer.addCandidateVariable("vat");        Iterable<String> result = completer.autoComplete("va");        List<String> completes = Lists.newArrayList(result);    assertEquals(2, completes.size());    assertThat(completes, hasItem("vast"));    assertThat(completes, hasItem("vat"));}
0
public void testNoCandidateVariable()
{        completer.addCandidateVariable("very");    completer.addCandidateVariable("vast");    completer.addCandidateVariable("vat");        Iterable<String> result = completer.autoComplete("x");        List<String> completes = Lists.newArrayList(result);    assertEquals(0, completes.size());}
0
public void testAutoCompleteDocString()
{        completer.addCandidateFunction("FREUD");    completer.addCandidateFunction("FRIEND");    completer.addCandidateFunction("FOE");        Iterable<String> result = completer.autoComplete("?FR");        List<String> completes = Lists.newArrayList(result);    assertEquals(2, completes.size());        assertThat(completes, hasItem("?FREUD"));    assertThat(completes, hasItem("?FRIEND"));}
0
public void testNoCandidateDocStrings()
{        completer.addCandidateFunction("FREUD");    completer.addCandidateFunction("FRIEND");    completer.addCandidateFunction("FOE");        Iterable<String> result = completer.autoComplete("?G");        List<String> completes = Lists.newArrayList(result);    assertEquals(0, completes.size());}
0
public void testAutoCompleteMagic()
{        completer.addCandidateFunction("%vars");    completer.addCandidateFunction("%vast");    completer.addCandidateFunction("%verbotten");        Iterable<String> result = completer.autoComplete("%va");        List<String> completes = Lists.newArrayList(result);    assertEquals(2, completes.size());        assertThat(completes, hasItem("%vars"));    assertThat(completes, hasItem("%vast"));}
0
public void testNoCandidateMagic()
{        completer.addCandidateFunction("%vars");    completer.addCandidateFunction("%vast");    completer.addCandidateFunction("%verbotten");        Iterable<String> result = completer.autoComplete("%xy");        List<String> completes = Lists.newArrayList(result);    assertEquals(0, completes.size());}
0
public void setup() throws Exception
{    Properties props = new Properties();    executor = new DefaultStellarShellExecutor(props, Optional.empty());    executor.init();}
0
public void testAssignment()
{        {        StellarResult result = executor.execute("x := 2 + 2");        assertTrue(result.isSuccess());        assertTrue(result.getValue().isPresent());        assertEquals(4, result.getValue().get());        assertEquals(4, executor.getVariables().get("x"));    }        {        StellarResult result = executor.execute("y := x + 2");        assertTrue(result.isSuccess());        assertTrue(result.getValue().isPresent());        assertEquals(6, result.getValue().get());        assertEquals(6, executor.getVariables().get("y"));    }        {        StellarResult result = executor.execute("z := x + y");        assertTrue(result.isSuccess());        assertTrue(result.getValue().isPresent());        assertEquals(10, result.getValue().get());        assertEquals(10, executor.getVariables().get("z"));    }}
0
public void testAssignmentOfLists()
{    List<Integer> expected = Arrays.asList(1, 2, 3, 4, 5);        StellarResult result = executor.execute("x := [1,2,3,4,5]");        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(expected, result.getValue().get());        List<Integer> variable = (List<Integer>) executor.getVariables().get("x");    assertEquals(expected, variable);}
0
public void testAssignmentOfMaps()
{    Map<String, Integer> expected = ImmutableMap.<String, Integer>builder().put("a", 10).put("b", 20).build();        StellarResult result = executor.execute("x := {'a':10, 'b':20}");        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(expected, result.getValue().get());        Map<String, Integer> variable = (Map<String, Integer>) executor.getVariables().get("x");    assertEquals(expected, variable);}
0
public void testAssignmentWithOddWhitespace()
{    StellarResult result = executor.execute("   x   :=    2 +      2      ");    assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(4, result.getValue().get());    assertEquals(4, executor.getVariables().get("x"));}
0
public void testBadAssignment()
{    StellarResult result = executor.execute("x := 2 + ");    assertTrue(result.isError());    assertTrue(result.getException().isPresent());}
0
public void testExpression()
{    StellarResult result = executor.execute("2 + 2");    assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(4, result.getValue().get());}
0
public void testExpressionWithOddWhitespace()
{    StellarResult result = executor.execute("    2    +    2");    assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(4, result.getValue().get());}
0
public void testBadExpression()
{    StellarResult result = executor.execute("2 + ");    assertTrue(result.isError());    assertTrue(result.getException().isPresent());}
0
public void testMagicCommand()
{        executor.execute("x := 2 + 2");        StellarResult result = executor.execute("%vars");    assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertNotNull(result.getValue().get());}
0
public void testDefineGlobal()
{        executor.execute("%define x := 2");    assertFalse(executor.getVariables().containsKey("x"));        assertEquals(2, executor.getGlobalConfig().get("x"));}
0
public void testBadMagicCommand()
{    StellarResult result = executor.execute("%invalid");    assertTrue(result.isError());    assertTrue(result.getException().isPresent());}
0
public void testDocCommand()
{        StellarResult result = executor.execute("?TO_STRING");    assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertNotNull(result.getValue().get());}
0
public void testBadDocCommand()
{    StellarResult result = executor.execute("?INVALID");    assertTrue(result.isError());    assertTrue(result.getException().isPresent());}
0
public void testQuit()
{    StellarResult result = executor.execute("quit");    assertTrue(result.isTerminate());}
0
public void testAssign()
{    {                executor.assign("x", 10, Optional.empty());    }    {        StellarResult result = executor.execute("x + 2");        assertTrue(result.isSuccess());        assertTrue(result.getValue().isPresent());        assertEquals(12, result.getValue().get());    }}
0
public void testNotifyVariableListeners()
{    notified = false;    executor.addVariableListener((var, value) -> {        assertEquals("x", var);        assertEquals(4, value.getResult());        notified = true;    });    executor.execute("x := 2 + 2");    assertTrue(notified);}
0
public void testNotifySpecialListeners() throws Exception
{        notified = false;    Properties props = new Properties();    DefaultStellarShellExecutor executor = new DefaultStellarShellExecutor(props, Optional.empty());        notified = false;    executor.addSpecialListener((magic) -> {        assertNotNull(magic);        assertNotNull(magic.getCommand());        notified = true;    });        executor.init();    assertTrue(notified);}
0
public void testNotifyFunctionListeners() throws Exception
{        notified = false;    Properties props = new Properties();    DefaultStellarShellExecutor executor = new DefaultStellarShellExecutor(props, Optional.empty());        notified = false;    executor.addFunctionListener((fn) -> {        assertNotNull(fn);        assertNotNull(fn.getName());        assertNotNull(fn.getFunction());        notified = true;    });        executor.init();    assertTrue(notified);}
0
public void testEmptyInput()
{    StellarResult result = executor.execute("");    assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals("", result.getValue().get());}
0
public void testComment()
{    StellarResult result = executor.execute("# this is a comment");    assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals("", result.getValue().get());}
0
public void testEmptyGlobalsWithNoZookeeper()
{    assertNotNull(executor.getGlobalConfig());    assertEquals(0, executor.getGlobalConfig().size());}
0
public void setup() throws Exception
{    command = new AssignmentCommand();        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(props, Optional.empty());    executor.init();}
0
public void testGetCommand()
{    assertEquals(":=", command.getCommand());}
0
public void testShouldMatch()
{    List<String> inputs = Arrays.asList("x := 2 + 2", "   x      :=      2     +  2   ", "  x    :=    2", " x := ");    for (String in : inputs) {        assertTrue("failed: " + in, command.getMatcher().apply(in));    }}
0
public void testShouldNotMatch()
{    List<String> inputs = Arrays.asList("2+2", " %define x := 2", "x");    for (String in : inputs) {        assertFalse("failed: " + in, command.getMatcher().apply(in));    }}
0
public void testAssignment()
{    StellarResult result = command.execute("x := 2 + 2", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(4, result.getValue().get());        assertEquals(4, executor.getState().get("x").getResult());}
0
public void testAssignments()
{        assertTrue(command.execute("x := 2 + 2", executor).isSuccess());    assertTrue(command.execute("y := 2 + x", executor).isSuccess());    assertTrue(command.execute("z := x + y", executor).isSuccess());        assertEquals(4, executor.getState().get("x").getResult());    assertEquals(6, executor.getState().get("y").getResult());    assertEquals(10, executor.getState().get("z").getResult());}
0
public void testReassignment()
{        assertTrue(command.execute("x := 2 + 2", executor).isSuccess());    assertTrue(command.execute("x := 5 + 5", executor).isSuccess());        assertEquals(10, executor.getState().get("x").getResult());}
0
public void testAssignmentOfEmptyVar()
{        StellarResult result = command.execute("x := z", executor);        assertTrue(result.isSuccess());    assertTrue(result.isValueNull());    assertFalse(result.getValue().isPresent());        assertNull(executor.getState().get("x").getResult());}
0
public void testBadAssignmentExpr()
{    StellarResult result = command.execute("x := 2 + ", executor);        assertTrue(result.isError());    assertTrue(result.getException().isPresent());        assertFalse(executor.getState().containsKey("x"));}
0
public void testErrorMessageWhenAssignmentFails()
{    String stmt = "0/0";    StellarResult result = command.execute("x := " + stmt, executor);        assertTrue(result.isError());    assertTrue(result.getException().isPresent());    assertEquals(ParseException.class, result.getException().get().getClass());    assertTrue(result.getException().get().getMessage().contains(stmt));}
0
public void testAssignNull()
{    StellarResult result = command.execute("x := NULL", executor);        assertTrue(result.isSuccess());    assertTrue(result.isValueNull());        assertNull(executor.getState().get("x").getResult());}
0
public void testNoAssignmentExpr()
{    StellarResult result = command.execute("x := ", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        assertEquals("", executor.getState().get("x").getResult());}
0
public void testAssignmentWithVar()
{        executor.assign("x", 10, Optional.empty());        StellarResult result = command.execute("y := x + 2", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(12, result.getValue().get());        assertEquals(10, executor.getState().get("x").getResult());    assertEquals(12, executor.getState().get("y").getResult());}
0
public void testAssignmentWithOddWhitespace()
{    StellarResult result = command.execute("        x   :=    2 +      2", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals(4, result.getValue().get());        assertEquals(4, executor.getState().get("x").getResult());}
0
public void setup() throws Exception
{        magic = new Comment();        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(props, Optional.empty());    executor.init();}
0
public void testGetCommand()
{    assertEquals("#", magic.getCommand());}
0
public void testShouldMatch()
{    List<String> inputs = Arrays.asList("#comment", "   #   comment   ", "      #comment");    for (String in : inputs) {        assertTrue("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testShouldNotMatch()
{    List<String> inputs = Arrays.asList("foo", "  define ", "bar");    for (String in : inputs) {        assertFalse("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testComment()
{    StellarResult result = magic.execute("#  this is a comment ", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    assertEquals("", result.getValue().get());}
0
public void setup() throws Exception
{        command = new DocCommand();        SimpleFunctionResolver functionResolver = new SimpleFunctionResolver().withClass(StringFunctions.ToString.class).withClass(StringFunctions.ToLower.class).withClass(StringFunctions.ToUpper.class);        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(functionResolver, props, Optional.empty());    executor.init();}
0
public void testWithFunction()
{    StellarResult result = command.execute("?TO_STRING", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        assertTrue(result.getValue().toString().length() > 0);}
0
public void testFunctionNotDefined()
{    StellarResult result = command.execute("?INVALID", executor);        assertTrue(result.isError());    assertTrue(result.getException().isPresent());}
0
public void testNoFunction()
{    StellarResult result = command.execute("?", executor);        assertTrue(result.isError());    assertTrue(result.getException().isPresent());}
0
public void setup() throws Exception
{        magic = new MagicDefineGlobal();        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(props, Optional.empty());    executor.init();}
0
public void testGetCommand()
{    assertEquals("%define", magic.getCommand());}
0
public void testShouldMatch()
{    List<String> inputs = Arrays.asList("%define", "   %define   ", "%define x := 2", "    %define   x := 2 ");    for (String in : inputs) {        assertTrue("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testShouldNotMatch()
{    List<String> inputs = Arrays.asList("foo", "  define ", "bar");    for (String in : inputs) {        assertFalse("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testDefine()
{    final int expected = 4;    {        StellarResult result = magic.execute("%define global := 2 + 2", executor);                assertTrue(result.isSuccess());        assertTrue(result.getValue().isPresent());        assertEquals(expected, result.getValue().get());                assertTrue(executor.getGlobalConfig().containsKey("global"));        assertEquals(expected, executor.getGlobalConfig().get("global"));    }        {                StellarResult result = executor.execute("%globals");                assertTrue(result.isSuccess());        assertTrue(result.getValue().isPresent());        String out = ConversionUtils.convert(result.getValue().get(), String.class);        assertEquals("{global=4}", out);    }}
0
public void testNotAssignmentExpression()
{    StellarResult result = magic.execute("%define 2 + 2", executor);        assertTrue(result.isError());    assertFalse(result.getValue().isPresent());    assertTrue(result.getException().isPresent());        assertEquals(0, executor.getGlobalConfig().size());}
0
public void testMissingExpression()
{    StellarResult result = magic.execute("%define", executor);        assertTrue(result.isError());    assertFalse(result.getValue().isPresent());    assertTrue(result.getException().isPresent());        assertEquals(0, executor.getGlobalConfig().size());}
0
public void setup() throws Exception
{        magic = new MagicListFunctions();        SimpleFunctionResolver functionResolver = new SimpleFunctionResolver().withClass(StringFunctions.ToString.class).withClass(StringFunctions.ToLower.class).withClass(StringFunctions.ToUpper.class);        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(functionResolver, props, Optional.empty());    executor.init();}
0
public void testGetCommand()
{    assertEquals("%functions", magic.getCommand());}
0
public void testShouldMatch()
{    List<String> inputs = Arrays.asList("%functions", "   %functions   ", "%functions FOO", "    %functions    FOO ");    for (String in : inputs) {        assertTrue("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testShouldNotMatch()
{    List<String> inputs = Arrays.asList("foo", "  functions ", "bar", "%define");    for (String in : inputs) {        assertFalse("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testFunctions()
{    StellarResult result = magic.execute("%functions", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        String value = ConversionUtils.convert(result.getValue().get(), String.class);    String[] functions = value.split(", ");    assertEquals(3, functions.length);}
0
public void testFunctionsWithMatch()
{    StellarResult result = magic.execute("%functions UPPER", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        String value = ConversionUtils.convert(result.getValue().get(), String.class);    String[] functions = value.split(", ");    assertEquals(1, functions.length);    assertEquals("TO_UPPER", functions[0]);}
0
public void testFunctionsWithNoMatch()
{    StellarResult result = magic.execute("%functions NOMATCH", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        String value = ConversionUtils.convert(result.getValue().get(), String.class);    String[] functions = value.trim().split(", ");    assertEquals(1, functions.length);    assertEquals("", functions[0]);}
0
public void setup() throws Exception
{        magic = new MagicListGlobals();        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(props, Optional.empty());    executor.init();}
0
public void testGetCommand()
{    assertEquals("%globals", magic.getCommand());}
0
public void testShouldMatch()
{    List<String> inputs = Arrays.asList("%globals", "   %globals   ", "%globals   FOO", "    %globals    FOO ");    for (String in : inputs) {        assertTrue("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testShouldNotMatch()
{    List<String> inputs = Arrays.asList("foo", "  globals ", "bar", "%define");    for (String in : inputs) {        assertFalse("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void test()
{        executor.getGlobalConfig().put("x", 2);        StellarResult result = executor.execute("%globals");        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    String out = ConversionUtils.convert(result.getValue().get(), String.class);    assertEquals("{x=2}", out);}
0
public void testWithNoGlobals()
{        StellarResult result = executor.execute("%globals");        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());    String out = ConversionUtils.convert(result.getValue().get(), String.class);    assertEquals("{}", out);}
0
public void setup() throws Exception
{        magic = new MagicListVariables();        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(props, Optional.empty());    executor.init();}
0
public void testGetCommand()
{    assertEquals("%vars", magic.getCommand());}
0
public void testShouldMatch()
{    List<String> inputs = Arrays.asList("%vars", "   %vars   ", "%vars   FOO", "    %vars    FOO ");    for (String in : inputs) {        assertTrue("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testShouldNotMatch()
{    List<String> inputs = Arrays.asList("foo", "  vars ", "bar", "%define");    for (String in : inputs) {        assertFalse("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void test()
{        executor.execute("x := 2 + 2");    StellarResult result = executor.execute("%vars");        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        String vars = ConversionUtils.convert(result.getValue().get(), String.class);    assertEquals("x = 4 via `2 + 2`", vars);}
0
public void testWithNoVars()
{        StellarResult result = executor.execute("%vars");        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        String vars = ConversionUtils.convert(result.getValue().get(), String.class);    assertEquals("", vars);}
0
public void setup() throws Exception
{        magic = new MagicUndefineGlobal();        Properties props = new Properties();    executor = new DefaultStellarShellExecutor(props, Optional.empty());    executor.init();}
0
public void testGetCommand()
{    assertEquals("%undefine", magic.getCommand());}
0
public void testShouldMatch()
{    List<String> inputs = Arrays.asList("%undefine", "   %undefine   ", "%undefine   FOO", "    %undefine    FOO ");    for (String in : inputs) {        assertTrue("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testShouldNotMatch()
{    List<String> inputs = Arrays.asList("foo", "  undefine ", "bar", "%define");    for (String in : inputs) {        assertFalse("failed: " + in, magic.getMatcher().apply(in));    }}
0
public void testUndefine()
{        executor.getGlobalConfig().put("global", 22);    assertEquals(1, executor.getGlobalConfig().size());        StellarResult result = magic.execute("%undefine global", executor);        assertTrue(result.isSuccess());    assertTrue(result.getValue().isPresent());        assertEquals(0, executor.getGlobalConfig().size());}
0
public void testWithNoVariable()
{        executor.getGlobalConfig().put("global", 22);    assertEquals(1, executor.getGlobalConfig().size());        StellarResult result = magic.execute("%undefine", executor);        assertTrue(result.isError());    assertTrue(result.getException().isPresent());        assertEquals(1, executor.getGlobalConfig().size());}
0
public void testSuccess()
{    final int expected = 2;        StellarResult result = StellarResult.success(expected);    assertNotNull(result);        assertTrue(result.getValue().isPresent());    assertEquals(expected, result.getValue().get());        assertFalse(result.getException().isPresent());        assertEquals(StellarResult.Status.SUCCESS, result.getStatus());    assertTrue(result.isSuccess());    assertFalse(result.isError());    assertFalse(result.isTerminate());}
0
public void testError()
{    final String expected = "my error message";        StellarResult result = StellarResult.error(expected);    assertNotNull(result);        assertFalse(result.getValue().isPresent());        assertTrue(result.getException().isPresent());    assertEquals(expected, result.getException().get().getMessage());        assertEquals(StellarResult.Status.ERROR, result.getStatus());    assertFalse(result.isSuccess());    assertTrue(result.isError());    assertFalse(result.isTerminate());}
0
public void testTerminate()
{        StellarResult result = StellarResult.terminate();    assertNotNull(result);        assertTrue(result.getValue().isPresent());        assertFalse(result.getException().isPresent());        assertEquals(StellarResult.Status.TERMINATE, result.getStatus());    assertFalse(result.isSuccess());    assertFalse(result.isError());    assertTrue(result.isTerminate());}
0
public void testNoop()
{        StellarResult result = StellarResult.noop();    assertNotNull(result);        assertTrue(result.getValue().isPresent());        assertFalse(result.getException().isPresent());        assertEquals(StellarResult.Status.SUCCESS, result.getStatus());    assertTrue(result.isSuccess());    assertFalse(result.isError());    assertFalse(result.isTerminate());}
0
public void testSuccessWithNull()
{    final Object expected = null;        StellarResult result = StellarResult.success(expected);    assertNotNull(result);        assertTrue(result.isValueNull());        assertFalse(result.getException().isPresent());        assertEquals(StellarResult.Status.SUCCESS, result.getStatus());    assertTrue(result.isSuccess());    assertFalse(result.isError());    assertFalse(result.isTerminate());}
0
public void testNonSuccessWithNull()
{    assertFalse(StellarResult.error(new Exception()).isValueNull());    assertFalse(StellarResult.error("error msg").isValueNull());    assertFalse(StellarResult.noop().isValueNull());    assertFalse(StellarResult.terminate().isValueNull());}
0
public void addingLongsShouldYieldLong() throws Exception
{    final long timestamp = 1452013350000L;    String query = "TO_EPOCH_TIMESTAMP('2016-01-05 17:02:30', 'yyyy-MM-dd HH:mm:ss', 'UTC') + 2";    assertEquals(timestamp + 2, run(query, new HashMap<>()));}
0
public void addingIntegersShouldYieldAnInteger() throws Exception
{    String query = "1 + 2";    assertEquals(3, run(query, new HashMap<>()));}
0
public void addingDoublesShouldYieldADouble() throws Exception
{    String query = "1.0 + 2.0";    assertEquals(3.0, run(query, new HashMap<>()));}
0
public void addingDoubleAndIntegerWhereSubjectIsDoubleShouldYieldADouble() throws Exception
{    String query = "2.1 + 1";    assertEquals(3.1, run(query, new HashMap<>()));}
0
public void addingDoubleAndIntegerWhereSubjectIsIntegerShouldYieldADouble() throws Exception
{    String query = "1 + 2.1";    assertEquals(3.1, run(query, new HashMap<>()));}
0
public void testArithmetic()
{    assertEquals(3, run("1 + 2", new HashMap<>()));    assertEquals(3.2, run("1.2 + 2", new HashMap<>()));    assertEquals(1.2e-3 + 2, run("1.2e-3 + 2", new HashMap<>()));    assertEquals(1.2f + 3.7, run("1.2f + 3.7", new HashMap<>()));    assertEquals(12L * (1.2f + 7), run("12L*(1.2f + 7)", new HashMap<>()));    assertEquals(12.2f * (1.2f + 7L), run("TO_FLOAT(12.2) * (1.2f + 7L)", new HashMap<>()));}
0
public void testNumericOperations()
{    {        String query = "TO_INTEGER(1 + 2*2 + 3 - 4 - 0.5)";        assertEquals(3, (Integer) run(query, new HashMap<>()), 1e-6);    }    {        String query = "1 + 2*2 + 3 - 4 - 0.5";        assertEquals(3.5, (Double) run(query, new HashMap<>()), 1e-6);    }    {        String query = "2*one*(1 + 2*2 + 3 - 4)";        assertEquals(8, run(query, ImmutableMap.of("one", 1)));    }    {        String query = "2*(1 + 2 + 3 - 4)";        assertEquals(4, (Integer) run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.000001)), 1e-6);    }    {        String query = "1 + 2 + 3 - 4 - 2";        assertEquals(0, (Integer) run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.000001)), 1e-6);    }    {        String query = "1 + 2 + 3 + 4";        assertEquals(10, (Integer) run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.000001)), 1e-6);    }    {        String query = "(one + 2)*3";        assertEquals(9, (Integer) run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.000001)), 1e-6);    }    {        String query = "TO_INTEGER((one + 2)*3.5)";        assertEquals(10, (Integer) run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.000001)), 1e-6);    }    {        String query = "1 + 2*3";        assertEquals(7, (Integer) run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.000001)), 1e-6);    }    {        String query = "TO_LONG(foo)";        Assert.assertNull(run(query, ImmutableMap.of("foo", "not a number")));    }    {        String query = "TO_LONG(foo)";        assertEquals(232321L, run(query, ImmutableMap.of("foo", "00232321")));    }    {        String query = "TO_LONG(foo)";        assertEquals(Long.MAX_VALUE, run(query, ImmutableMap.of("foo", Long.toString(Long.MAX_VALUE))));    }}
0
public void verifyExpectedReturnTypes() throws Exception
{    Token<Integer> integer = mock(Token.class);    when(integer.getValue()).thenReturn(1);    Token<Long> lng = mock(Token.class);    when(lng.getValue()).thenReturn(1L);    Token<Double> dbl = mock(Token.class);    when(dbl.getValue()).thenReturn(1.0D);    Token<Float> flt = mock(Token.class);    when(flt.getValue()).thenReturn(1.0F);    Map<Pair<String, String>, Class<? extends Number>> expectedReturnTypeMappings = new HashMap<Pair<String, String>, Class<? extends Number>>() {        {            put(Pair.of("TO_FLOAT(3.0)", "TO_LONG(1)"), Float.class);            put(Pair.of("TO_FLOAT(3)", "3.0"), Double.class);            put(Pair.of("TO_FLOAT(3)", "TO_FLOAT(3)"), Float.class);            put(Pair.of("TO_FLOAT(3)", "3"), Float.class);            put(Pair.of("TO_LONG(1)", "TO_LONG(1)"), Long.class);            put(Pair.of("TO_LONG(1)", "3.0"), Double.class);            put(Pair.of("TO_LONG(1)", "TO_FLOAT(3)"), Float.class);            put(Pair.of("TO_LONG(1)", "3"), Long.class);            put(Pair.of("3.0", "TO_LONG(1)"), Double.class);            put(Pair.of("3.0", "3.0"), Double.class);            put(Pair.of("3.0", "TO_FLOAT(3)"), Double.class);            put(Pair.of("3.0", "3"), Double.class);            put(Pair.of("3", "TO_LONG(1)"), Long.class);            put(Pair.of("3", "3.0"), Double.class);            put(Pair.of("3", "TO_FLOAT(3)"), Float.class);            put(Pair.of("3", "3"), Integer.class);        }    };    expectedReturnTypeMappings.forEach((pair, expectedClass) -> {        assertTrue(run(pair.getLeft() + " * " + pair.getRight(), ImmutableMap.of()).getClass() == expectedClass);        assertTrue(run(pair.getLeft() + " + " + pair.getRight(), ImmutableMap.of()).getClass() == expectedClass);        assertTrue(run(pair.getLeft() + " - " + pair.getRight(), ImmutableMap.of()).getClass() == expectedClass);        assertTrue(run(pair.getLeft() + " / " + pair.getRight(), ImmutableMap.of()).getClass() == expectedClass);    });}
0
public void happyPathFloatArithmetic() throws Exception
{    Object run = run(".0f * 1", ImmutableMap.of());    assertEquals(.0f * 1, run);    assertEquals(Float.class, run.getClass());    Object run1 = run("0.f / 1F", ImmutableMap.of());    assertEquals(0.f / 1F, run1);    assertEquals(Float.class, run1.getClass());    Object run2 = run(".0F + 1.0f", ImmutableMap.of());    assertEquals(.0F + 1.0f, run2);    assertEquals(Float.class, run2.getClass());    Object run3 = run("0.0f - 0.1f", ImmutableMap.of());    assertEquals(0.0f - 0.1f, run3);    assertEquals(Float.class, run2.getClass());}
0
public void happyPathLongArithmetic() throws Exception
{    assertEquals(0L * 1L, run("0L * 1L", ImmutableMap.of()));    assertEquals(0l / 1L, run("0l / 1L", ImmutableMap.of()));    assertEquals(1L - 1l, run("1L - 1l", ImmutableMap.of()));    assertEquals(2147483648L + 1L, run("2147483648L + 1L", ImmutableMap.of()));}
0
public void checkInterestingCases() throws Exception
{    assertEquals((((((1L) + .5d)))) * 6.f, run("(((((1L) + .5d)))) * 6.f", ImmutableMap.of()));    assertEquals((((((1L) + .5d)))) * 6.f / 0.f, run("(((((1L) + .5d)))) * 6.f / 0.f", ImmutableMap.of()));    assertEquals(Double.class, run("(((((1L) + .5d)))) * 6.f / 0.f", ImmutableMap.of()).getClass());}
0
public void makeSureStellarProperlyEvaluatesLiteralsToExpectedTypes() throws Exception
{    {        assertEquals(Float.class, run("6.f", ImmutableMap.of()).getClass());        assertEquals(Float.class, run(".0f", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("6.0F", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("6f", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("6e-6f", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("6e+6f", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("6e6f", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("TO_FLOAT(1231)", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("TO_FLOAT(12.31)", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("TO_FLOAT(12.31f)", ImmutableMap.of()).getClass());        assertEquals(Float.class, run("TO_FLOAT(12L)", ImmutableMap.of()).getClass());    }    {        assertEquals(Double.class, run("6.d", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("6.D", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("6.0d", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("6D", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("6e5D", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("6e-5D", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("6e+5D", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("TO_DOUBLE(1231)", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("TO_DOUBLE(12.31)", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("TO_DOUBLE(12.31f)", ImmutableMap.of()).getClass());        assertEquals(Double.class, run("TO_DOUBLE(12L)", ImmutableMap.of()).getClass());    }    {        assertEquals(Integer.class, run("6", ImmutableMap.of()).getClass());        assertEquals(Integer.class, run("60000000", ImmutableMap.of()).getClass());        assertEquals(Integer.class, run("-0", ImmutableMap.of()).getClass());        assertEquals(Integer.class, run("-60000000", ImmutableMap.of()).getClass());        assertEquals(Integer.class, run("TO_INTEGER(1231)", ImmutableMap.of()).getClass());        assertEquals(Integer.class, run("TO_INTEGER(12.31)", ImmutableMap.of()).getClass());        assertEquals(Integer.class, run("TO_INTEGER(12.31f)", ImmutableMap.of()).getClass());        assertEquals(Integer.class, run("TO_INTEGER(12L)", ImmutableMap.of()).getClass());    }    {        assertEquals(Long.class, run("12345678910l", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("0l", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("-0l", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("-60000000L", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("-60000000L", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("TO_LONG(1231)", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("TO_LONG(12.31)", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("TO_LONG(12.31f)", ImmutableMap.of()).getClass());        assertEquals(Long.class, run("TO_LONG(12L)", ImmutableMap.of()).getClass());    }}
0
public void parseExceptionMultipleLeadingZerosOnInteger() throws Exception
{    exception.expect(ParseException.class);    run("000000", ImmutableMap.of());}
0
public void parseExceptionMultipleLeadingZerosOnLong() throws Exception
{    exception.expect(ParseException.class);    run("000000l", ImmutableMap.of());}
0
public void parseExceptionMultipleLeadingZerosOnDouble() throws Exception
{    exception.expect(ParseException.class);    run("000000d", ImmutableMap.of());}
0
public void parseExceptionMultipleLeadingZerosOnFloat() throws Exception
{    exception.expect(ParseException.class);    run("000000f", ImmutableMap.of());}
0
public void parseExceptionMultipleLeadingNegativeSignsFloat() throws Exception
{    exception.expect(ParseException.class);    run("--000000f", ImmutableMap.of());}
0
public void parseExceptionMultipleLeadingNegativeSignsDouble() throws Exception
{    exception.expect(ParseException.class);    run("--000000D", ImmutableMap.of());}
0
public void parseExceptionMultipleLeadingNegativeSignsLong() throws Exception
{    exception.expect(ParseException.class);    run("--000000L", ImmutableMap.of());}
0
public void unableToDivideByZeroWithIntegers() throws Exception
{    run("0/0", ImmutableMap.of());}
0
public void unableToDivideByZeroWithLongs() throws Exception
{    run("0L/0L", ImmutableMap.of());}
0
public void ableToDivideByZero() throws Exception
{    assertEquals(0F / 0F, run("0F/0F", ImmutableMap.of()));    assertEquals(0D / 0D, run("0D/0D", ImmutableMap.of()));    assertEquals(0D / 0F, run("0D/0F", ImmutableMap.of()));    assertEquals(0F / 0D, run("0F/0D", ImmutableMap.of()));    assertEquals(0F / 0, run("0F/0", ImmutableMap.of()));    assertEquals(0D / 0, run("0D/0", ImmutableMap.of()));    assertEquals(0 / 0D, run("0/0D", ImmutableMap.of()));    assertEquals(0 / 0F, run("0/0F", ImmutableMap.of()));}
0
public void testAssignment()
{    for (String statement : ImmutableList.of("foo := bar + grok", "foo   := bar + grok", "foo := bar + grok   ")) {        StellarAssignment assignment = StellarAssignment.from(statement);        Assert.assertEquals("foo", assignment.getKey());        Assert.assertEquals("foo", assignment.getVariable());        Assert.assertEquals("bar + grok", assignment.getStatement());        Assert.assertEquals("bar + grok", assignment.getValue());    }}
0
public void testNonAssignment()
{    for (String statement : ImmutableList.of("bar + grok", "  bar + grok", "bar + grok   ")) {        StellarAssignment assignment = StellarAssignment.from(statement);        Assert.assertNull(assignment.getKey());        Assert.assertNull(assignment.getVariable());        Assert.assertEquals("bar + grok", assignment.getStatement());        Assert.assertEquals("bar + grok", assignment.getValue());    }}
0
public void testImmutability()
{    StellarAssignment assignment = StellarAssignment.from("foo := bar");    assignment.setValue("myval");}
0
public void checkLessThanComparisonOperators() throws Exception
{    assertEquals(1 < 2, run("1 < 2", ImmutableMap.of()));    assertEquals(1f < 2, run("1f < 2", ImmutableMap.of()));    assertEquals(1f < 2d, run("1f < 2d", ImmutableMap.of()));    assertEquals(1f < 2e-4d, run("1f < 2e-4d", ImmutableMap.of()));    assertEquals(1L < 2e-4d, run("1L < 2e-4d", ImmutableMap.of()));    assertEquals(1 < 2e-4d, run("1 < 2e-4d", ImmutableMap.of()));    assertEquals(1 < 2L, run("1 < 2L", ImmutableMap.of()));    assertEquals(1.0f < 2.0f, run("1.0f < 2.0f", ImmutableMap.of()));    assertEquals(1L < 3.0f, run("1L < 3.0f", ImmutableMap.of()));    assertEquals(1 < 3.0f, run("1 < 3.0f", ImmutableMap.of()));    assertEquals(1.0 < 3.0f, run("1.0 < 3.0f", ImmutableMap.of()));    boolean thrown = false;    try {        run("foo < 3.0f", ImmutableMap.of());    } catch (ParseException pe) {        thrown = true;    }    assertTrue(thrown);    thrown = false;    try {        run("foo < foo", ImmutableMap.of());    } catch (ParseException pe) {        thrown = true;    }    assertTrue(thrown);    assertEquals(1L < 3.0f ? true : false, run("if 1L < 3.0f then true else false", ImmutableMap.of()));}
0
public void checkComparisonOperationsWithFunctions() throws Exception
{    assertEquals(1f >= 2, run("TO_FLOAT(1) >= 2", ImmutableMap.of()));    assertEquals(1f <= 2, run("TO_FLOAT(1) <= TO_FLOAT(2)", ImmutableMap.of()));    assertEquals(1f == 2, run("TO_FLOAT(1) == TO_LONG(2)", ImmutableMap.of()));    assertEquals(12.31f == 10.2f, run("TO_FLOAT(12.31) < 10.2f", ImmutableMap.of()));}
0
public void testSimpleOps() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("empty", "");            put("spaced", "metron is great");            put("foo.bar", "casey");        }    };    assertTrue(runPredicate("'casey' == foo.bar", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("'casey' == foo", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("'casey' != foo", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("'stella' == 'stella'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("'stella' == foo", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("foo== foo", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("empty== ''", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("spaced == 'metron is great'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate(null, new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate(" ", (new DefaultVariableResolver(variableMap::get, variableMap::containsKey))));}
0
public void compareNumberAndStringWithSameValueShouldBeFalse() throws Exception
{    Map<String, String> variableMap = new HashMap<>();    assertFalse(runPredicate("1 == '1'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("'1' == 1", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void comparingNullShouldNotCauseNullPointer() throws Exception
{    Map<String, String> variableMap = new HashMap<>();    assertFalse(runPredicate("null == '1'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("\"1\" == null", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("null == null", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void makeSureSingleQuotesAndDoubleQuotesAreEqual() throws Exception
{    Map<String, String> variableMap = new HashMap<>();    assertTrue(runPredicate("\"1\" == '1'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("'1' == \"1\"", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("'1' == \"1\"", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void makeSureSingleQuoteStringsAreEvaluatedAsStrings() throws Exception
{    Map<String, String> variableMap = new HashMap<>();    assertFalse(runPredicate("55 == '7'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("97 == 'a'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void testNumericComparisonFunctions() throws Exception
{    final Map<String, Object> variableMap = new HashMap<String, Object>() {        {            put("foo", "casey");            put("bar", "bar.casey.grok");            put("ip", "192.168.0.1");            put("num", 7);            put("num2", 8.5);            put("num3", 7);            put("num4", "8.5");            put("empty", "");            put("spaced", "metron is great");        }    };    assertTrue(runPredicate("num == 7", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("num < num2", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("num < TO_DOUBLE(num2)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("num < TO_DOUBLE(num4)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("num < 100", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("num == num3", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("num == num2", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("num == num2 || true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("num > num2", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("num == 7 && num > 2", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void positiveAndNegativeZeroAreEqual() throws Exception
{    final Map<String, Object> variableMap = new HashMap<String, Object>() {        {            put("num", -0);        }    };    Arrays.asList("!=", "==").forEach(op -> {        assertEquals("==".equals(op), runPredicate("num " + op + " 0", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("==".equals(op), runPredicate("0 " + op + " -0", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("==".equals(op), runPredicate("0 " + op + " -0d", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("==".equals(op), runPredicate("-0 " + op + " 0", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("==".equals(op), runPredicate("-0F " + op + " 0D", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("==".equals(op), runPredicate("-0.F " + op + " 0", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("==".equals(op), runPredicate("-0.F " + op + " 0F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("==".equals(op), runPredicate("-0.D " + op + " 0D", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    });}
0
public void naNIsNotEqualToNaN() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    Arrays.asList("!=", "==").forEach(op -> {        assertEquals("!=".equals(op), runPredicate("(0f/0f) " + op + " (0f/0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(-0f/0f) " + op + " (0f/0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(-0f/-0f) " + op + " (0f/0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(-0f/-0f) " + op + " (-0f/0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(-0f/-0f) " + op + " (-0f/-0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(0f/-0f) " + op + " (0f/0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(0f/-0f) " + op + " (-0f/0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(0f/-0f) " + op + " (-0f/-0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(0f/0f) " + op + " (-0f/0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(0f/0d) " + op + " (-0f/-0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(0d/-0f) " + op + " (0f/-0f)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(-0f/0f) " + op + " (0f/-0d)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(-0d/-0d) " + op + " (0d/-0d)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals("!=".equals(op), runPredicate("(0d/0d) " + op + " (0d/0d)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    });}
0
public void booleanComparisonTests() throws Exception
{    final Map<String, Object> variableMap = new HashMap<String, Object>() {        {            put("t", true);            put("f", false);        }    };    assertTrue(runPredicate("t != f", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("f != t", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("true != false", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("true != true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("false != true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("false != false", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("t == f", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("f == t", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("true == false", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("true == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("false == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("false == false", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("null == false", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("null == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("true == NULL", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("false == NULL", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void nullComparisonTests() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    assertFalse(runPredicate("null == false", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("null == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("true == NULL", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("false == NULL", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("1 == NULL", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("'null' == NULL", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("'' == NULL", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertFalse(runPredicate("null == ''", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    assertTrue(runPredicate("NULL == null", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void precisionEqualityTests() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    assertEquals(0.1 + 0.2 == 0.3, runPredicate("0.1 + 0.2 == 0.3", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void differentTypesShouldThrowErrorWhenUsingLT() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    runPredicate("1 < '1'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey));}
0
public void differentTypesShouldThrowErrorWhenUsingLTE() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    runPredicate("'1' <= 1", new DefaultVariableResolver(variableMap::get, variableMap::containsKey));}
0
public void differentTypesShouldThrowErrorWhenUsingGT() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    runPredicate("1 > '1'", new DefaultVariableResolver(variableMap::get, variableMap::containsKey));}
0
public void differentTypesShouldThrowErrorWhenUsingGTE() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    runPredicate("'1' >= 1", new DefaultVariableResolver(variableMap::get, variableMap::containsKey));}
0
public void differentTypesShouldThrowErrorWhenUsingComparisons() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    final Integer[] result = { 0 };    Stream.of("<", "<=", ">", ">=").forEach(op -> {        assertFalse(runPredicate("'1' " + op + " null", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    });}
0
public void makeSurePrecisionIsProperlyHandled() throws Exception
{    final Map<String, Object> variableMap = new HashMap<>();    {        assertEquals(1 == 1.00000001, runPredicate("1 == 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 < 1.00000001, runPredicate("1 < 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 <= 1.00000001, runPredicate("1 <= 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 > 1.00000001, runPredicate("1 > 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 >= 1.00000001, runPredicate("1 >= 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    }    {        assertEquals(1 == 1.00000001F, runPredicate("1 == 1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 < 1.00000001F, runPredicate("1 < 1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 <= 1.00000001F, runPredicate("1 <= 1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 > 1.00000001F, runPredicate("1 > 1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1 >= 1.00000001F, runPredicate("1 >= 1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    }    {        assertEquals(1.00000001F == 1.00000001, runPredicate("1.00000001F == 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1.00000001F < 1.00000001, runPredicate("1.00000001F < 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1.00000001F <= 1.00000001, runPredicate("1.00000001F <= 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1.00000001F > 1.00000001, runPredicate("1.00000001F > 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(1.00000001F >= 1.00000001, runPredicate("1.00000001F >= 1.00000001", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    }    {        assertEquals(-1L == -1.00000001F, runPredicate("-1L == -1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(-1L < -1.00000001F, runPredicate("-1L < -1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(-1L <= -1.00000001F, runPredicate("-1L <= -1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(-1L > -1.00000001F, runPredicate("-1L > -1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));        assertEquals(-1L >= -1.00000001F, runPredicate("-1L >= -1.00000001F", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    }}
0
public void setUp() throws Exception
{    variableResolver = mock(VariableResolver.class);    functionResolver = mock(FunctionResolver.class);    context = mock(Context.class);    tokenStack = new ArrayDeque<>();    arithmeticEvaluator = mock(ArithmeticEvaluator.class);    numberLiteralEvaluator = mock(NumberLiteralEvaluator.class);    comparisonExpressionWithOperatorEvaluator = mock(ComparisonExpressionWithOperatorEvaluator.class);    expression = new StellarCompiler.Expression(tokenStack);    compiler = new StellarCompiler(expression, arithmeticEvaluator, numberLiteralEvaluator, comparisonExpressionWithOperatorEvaluator);}
0
public void exitIntLiteralShouldProperlyParseStringsAsIntegers() throws Exception
{    StellarParser.IntLiteralContext ctx = mock(StellarParser.IntLiteralContext.class);    Token result = mock(Token.class);    when(ctx.getText()).thenReturn("1000");    when(numberLiteralEvaluator.evaluate(ctx, null)).thenReturn(result);    compiler.exitIntLiteral(ctx);    verify(numberLiteralEvaluator).evaluate(ctx, null);    Assert.assertEquals(1, tokenStack.size());    Assert.assertEquals(tokenStack.getFirst(), result);    verifyZeroInteractions(variableResolver);    verifyZeroInteractions(functionResolver);    verifyZeroInteractions(context);    verifyZeroInteractions(arithmeticEvaluator);    verifyZeroInteractions(comparisonExpressionWithOperatorEvaluator);}
0
public void exitDoubleLiteralShouldProperlyParseStringsAsDoubles() throws Exception
{    StellarParser.DoubleLiteralContext ctx = mock(StellarParser.DoubleLiteralContext.class);    Token result = mock(Token.class);    when(numberLiteralEvaluator.evaluate(ctx, null)).thenReturn(result);    when(ctx.getText()).thenReturn("1000D");    compiler.exitDoubleLiteral(ctx);    verify(numberLiteralEvaluator).evaluate(ctx, null);    Assert.assertEquals(1, tokenStack.size());    Assert.assertEquals(tokenStack.getFirst(), result);    verifyZeroInteractions(variableResolver);    verifyZeroInteractions(functionResolver);    verifyZeroInteractions(context);    verifyZeroInteractions(arithmeticEvaluator);    verifyZeroInteractions(comparisonExpressionWithOperatorEvaluator);}
0
public void exitFloatLiteralShouldProperlyParseStringsAsFloats() throws Exception
{    StellarParser.FloatLiteralContext ctx = mock(StellarParser.FloatLiteralContext.class);    when(ctx.getText()).thenReturn("1000f");    Token result = mock(Token.class);    when(numberLiteralEvaluator.evaluate(ctx, null)).thenReturn(result);    compiler.exitFloatLiteral(ctx);    verify(numberLiteralEvaluator).evaluate(ctx, null);    Assert.assertEquals(1, tokenStack.size());    Assert.assertEquals(tokenStack.getFirst(), result);    verifyZeroInteractions(variableResolver);    verifyZeroInteractions(functionResolver);    verifyZeroInteractions(context);    verifyZeroInteractions(arithmeticEvaluator);    verifyZeroInteractions(comparisonExpressionWithOperatorEvaluator);}
0
public void exitLongLiteralShouldProperlyParseStringsAsLongs() throws Exception
{    StellarParser.LongLiteralContext ctx = mock(StellarParser.LongLiteralContext.class);    when(ctx.getText()).thenReturn("1000l");    Token result = mock(Token.class);    when(numberLiteralEvaluator.evaluate(ctx, null)).thenReturn(result);    compiler.exitLongLiteral(ctx);    verify(numberLiteralEvaluator).evaluate(ctx, null);    Assert.assertEquals(1, tokenStack.size());    Assert.assertEquals(tokenStack.getFirst(), result);    verifyZeroInteractions(variableResolver);    verifyZeroInteractions(functionResolver);    verifyZeroInteractions(context);    verifyZeroInteractions(arithmeticEvaluator);    verifyZeroInteractions(comparisonExpressionWithOperatorEvaluator);}
0
public void properlyCompareTwoNumbers() throws Exception
{    StellarParser.ComparisonExpressionWithOperatorContext ctx = mock(StellarParser.ComparisonExpressionWithOperatorContext.class);    StellarParser.ComparisonOpContext mockOp = mock(StellarParser.ComparisonOpContext.class);    when(ctx.comp_operator()).thenReturn(mockOp);    Token result = mock(Token.class);    when(comparisonExpressionWithOperatorEvaluator.evaluate(any(Token.class), any(Token.class), any(StellarParser.ComparisonOpContext.class), any())).thenReturn(result);    compiler.exitComparisonExpressionWithOperator(ctx);    Assert.assertEquals(1, tokenStack.size());    StellarCompiler.DeferredFunction func = (StellarCompiler.DeferredFunction) tokenStack.pop().getValue();    tokenStack.push(new Token<>(1000, Integer.class, null));    tokenStack.push(new Token<>(1500f, Float.class, null));    func.apply(tokenStack, new StellarCompiler.ExpressionState(context, functionResolver, variableResolver));    Assert.assertEquals(1, tokenStack.size());    Assert.assertEquals(tokenStack.getFirst(), result);    verify(comparisonExpressionWithOperatorEvaluator).evaluate(any(Token.class), any(Token.class), eq(mockOp), any());    verifyZeroInteractions(numberLiteralEvaluator);    verifyZeroInteractions(variableResolver);    verifyZeroInteractions(functionResolver);    verifyZeroInteractions(context);    verifyZeroInteractions(arithmeticEvaluator);}
0
public void testValidation() throws Exception
{    StellarPredicateProcessor processor = new StellarPredicateProcessor();    try {        processor.validate("enrichedField1 == 'enrichedValue1");        fail("Invalid rule found to be valid - unclosed single quotes.");    } catch (ParseException e) {    }}
0
public void returns_system_time() throws Exception
{    Clock clock = new Clock();    long t1 = clock.currentTimeMillis();    Thread.sleep(50);    long t2 = clock.currentTimeMillis();    Thread.sleep(50);    long t3 = clock.currentTimeMillis();    assertThat("t3 should be greater", t3 > t2, equalTo(true));    assertThat("t2 should be greater", t2 > t1, equalTo(true));}
0
public void formats_system_time_given_passed_format() throws Exception
{    Clock clock = Mockito.spy(Clock.class);    SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMddHHmmssSSSZ");    sdf.setTimeZone(TimeZone.getTimeZone("UTC"));    Date date = sdf.parse("20160615183527162+0000");    Mockito.when(clock.currentTimeMillis()).thenReturn(date.getTime());    assertThat("time not right", clock.currentTimeFormatted("yyyyMMddHHmmssSSSZ"), equalTo("20160615183527162+0000"));}
0
public void testMerge()
{    BloomFilter bloomString = (BloomFilter) run("BLOOM_ADD(BLOOM_INIT(), string)", variables);    BloomFilter bloomDouble = (BloomFilter) run("BLOOM_ADD(BLOOM_INIT(), double)", variables);    BloomFilter bloomInteger = (BloomFilter) run("BLOOM_ADD(BLOOM_INIT(), integer)", variables);    BloomFilter bloomMap = (BloomFilter) run("BLOOM_ADD(BLOOM_INIT(), map)", variables);    BloomFilter merged = (BloomFilter) run("BLOOM_MERGE([stringFilter, doubleFilter, integerFilter, mapFilter])", ImmutableMap.of("stringFilter", bloomString, "doubleFilter", bloomDouble, "integerFilter", bloomInteger, "mapFilter", bloomMap));    Assert.assertNotNull(merged);    for (Object val : variables.values()) {        Assert.assertTrue(merged.mightContain(val));    }}
0
public void testAdd()
{    BloomFilter result = (BloomFilter) run("BLOOM_ADD(BLOOM_INIT(), string, double, integer, map)", variables);    for (Object val : variables.values()) {        Assert.assertTrue(result.mightContain(val));    }    Assert.assertTrue(result.mightContain(ImmutableMap.of("key1", "value1", "key2", "value2")));}
0
public void testExists()
{    {        Boolean result = (Boolean) run("BLOOM_EXISTS(BLOOM_ADD(BLOOM_INIT(), string, double, integer, map), 'casey')", variables);        Assert.assertTrue(result);    }    {        Boolean result = (Boolean) run("BLOOM_EXISTS(BLOOM_ADD(BLOOM_INIT(), string, double, integer, map), double)", variables);        Assert.assertTrue(result);    }    {        Boolean result = (Boolean) run("BLOOM_EXISTS(BLOOM_ADD(BLOOM_INIT(), string, double, integer, map), integer)", variables);        Assert.assertTrue(result);    }    {        Boolean result = (Boolean) run("BLOOM_EXISTS(BLOOM_ADD(BLOOM_INIT(), string, double, integer, map), map)", variables);        Assert.assertTrue(result);    }    {        Boolean result = (Boolean) run("BLOOM_EXISTS(BLOOM_ADD(BLOOM_INIT(), string, double, integer, map), 'samantha')", variables);        Assert.assertFalse(result);    }    {        boolean thrown = false;        try {            run("BLOOM_EXISTS(BLOOM_ADD(BLOOM_INIT(), string, double, integer, map), sam)", variables);        } catch (ParseException pe) {            thrown = true;        }        Assert.assertTrue(thrown);    }}
0
public void testToString() throws Exception
{    Map<String, Object> v1 = new HashMap<>();    v1.put("k1", "v1");    Map<String, Object> v2 = new HashMap<>();    v2.put("k2", "v2");    v2.put("k3", null);    Map<String, Object> union = new HashMap<String, Object>() {        {            putAll(v1);            put("k2", "v2");        }    };    ConcatMap c = create(v1, v2);    Assert.assertEquals(c.toString(), union.toString());}
0
private ConcatMap create(Map... ms)
{    List<Map> l = new ArrayList<>();    for (Map m : ms) {        l.add(m);    }    return new ConcatMap(l);}
0
private void assertKryoserializable(ConcatMap c)
{    byte[] serialized = SerDeUtils.toBytes(c);    ConcatMap deserialized = SerDeUtils.fromBytes(serialized, ConcatMap.class);    Assert.assertEquals(deserialized, c);}
0
public void testKryoSerialization()
{    Map<String, Object> v1 = new HashMap<>();    v1.put("k1", "v1");    Map<String, Object> v2 = new HashMap<>();    v2.put("k2", "v2");    v2.put("k3", null);    {                ConcatMap c = create(v1, v2);        assertKryoserializable(c);    }    {                ConcatMap c = create(v1);        assertKryoserializable(c);    }    {                ConcatMap c = create();        assertKryoserializable(c);    }}
0
public void testIntegerConversions()
{    Object o = 1;    Assert.assertEquals(Integer.valueOf(1), ConversionUtils.convert(o, Integer.class));    Assert.assertEquals(Integer.valueOf(1), ConversionUtils.convert("1", Integer.class));    Assert.assertNull(ConversionUtils.convert("foo", Integer.class));}
0
public void getHashAsHexOfNullValueReturnsPadded00() throws Exception
{    assertEquals(StringUtils.repeat("00", 16), new DefaultHasher("md5", encoder).getHash(null));    assertEquals(StringUtils.repeat("00", 32), new DefaultHasher("sha-256", encoder).getHash(null));}
0
public void nonSerializableShouldReturnNull() throws Exception
{    assertNull(new DefaultHasher("md5", encoder, charset).getHash(new Object()));}
0
public void hashingStringWithEmptyString() throws Exception
{    assertEquals("d41d8cd98f00b204e9800998ecf8427e", new DefaultHasher("md5", encoder).getHash(""));}
0
public void hashingSerializableObject() throws Exception
{    final Collection<String> serializable = Collections.emptyList();    assertEquals("ef5e8c8d27af3a953b4674065c99a52a", new DefaultHasher("md5", encoder, charset).getHash(serializable));}
0
public static void setUp() throws Exception
{    tmpDir = UnitTestHelper.createTempDir(new File("target/jsonutilstest"));    configFile = UnitTestHelper.write(new File(tmpDir, "config.json"), config);}
0
public void loads_file_with_typeref() throws Exception
{    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("a", "hello");            put("b", "world");        }    };    Map<String, Object> actual = JSONUtils.INSTANCE.load(configFile, JSONUtils.MAP_SUPPLIER);    Assert.assertThat("config not equal", actual, equalTo(expected));}
0
public void loads_file_with_map_class() throws Exception
{    Map<String, Object> expected = new HashMap<String, Object>() {        {            put("a", "hello");            put("b", "world");        }    };    Map<String, Object> actual = JSONUtils.INSTANCE.load(configFile, Map.class);    Assert.assertThat("config not equal", actual, equalTo(expected));}
0
public void loads_file_with_custom_class() throws Exception
{    TestConfig expected = new TestConfig().setA("hello").setB("world");    TestConfig actual = JSONUtils.INSTANCE.load(configFile, TestConfig.class);    Assert.assertThat("a not equal", actual.getA(), equalTo(expected.getA()));    Assert.assertThat("b not equal", actual.getB(), equalTo(expected.getB()));}
0
public String getA()
{    return a;}
0
public TestConfig setA(String a)
{    this.a = a;    return this;}
0
public String getB()
{    return b;}
0
public TestConfig setB(String b)
{    this.b = b;    return this;}
0
public void testInteger()
{    final int expected = 2;    byte[] raw = SerDeUtils.toBytes(expected);    int actual = SerDeUtils.fromBytes(raw, Integer.class);    assertEquals(expected, actual);}
0
public void testDouble()
{    final double expected = 2.0;    byte[] raw = SerDeUtils.toBytes(expected);    {        double actual = SerDeUtils.fromBytes(raw, Double.class);        assertEquals(expected, actual, 0.01);    }    {        double actual = (double) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual, 0.01);    }}
0
public void testShort()
{    final short expected = 2;    byte[] raw = SerDeUtils.toBytes(expected);    {        short actual = SerDeUtils.fromBytes(raw, Short.class);        assertEquals(expected, actual);    }    {        short actual = (short) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual);    }}
0
public void testLong()
{    final long expected = 2L;    byte[] raw = SerDeUtils.toBytes(expected);    {        long actual = SerDeUtils.fromBytes(raw, Long.class);        assertEquals(expected, actual);    }    {        long actual = (Long) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual);    }}
0
public void testFloat()
{    final Float expected = 2.2F;    byte[] raw = SerDeUtils.toBytes(expected);    {        float actual = SerDeUtils.fromBytes(raw, Float.class);        assertEquals(expected, actual, 0.01);    }    {        float actual = (float) SerDeUtils.fromBytes(raw, Object.class);        assertEquals(expected, actual, 0.01);    }}
0
public void testMap()
{    final Map<String, Object> expected = new HashMap<>();    expected.put("foo", "bar");    expected.put("bar", 1.0);    ;    byte[] raw = SerDeUtils.toBytes(expected);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    assertEquals(expected, actual);}
0
public void testList()
{    final List<String> expected = new ArrayList<String>();    expected.add("foo");    expected.add("bar");    byte[] raw = SerDeUtils.toBytes(expected);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    assertEquals(expected, actual);}
0
public void testBloomFilter()
{    final BloomFilter<Object> expected = new BloomFilter<>(new BloomFilter.DefaultSerializer<>(), 10000, 0.01);    expected.add("foo");    expected.add("bar");    byte[] raw = SerDeUtils.toBytes(expected);    BloomFilter<Object> actual = (BloomFilter) SerDeUtils.fromBytes(raw, Object.class);    Assert.assertTrue(actual.mightContain("foo"));    Assert.assertFalse(actual.mightContain("timothy"));    assertEquals(expected, actual);}
0
public List<String> getList()
{    return list;}
0
public void setList(List<String> list)
{    this.list = list;}
0
public String getString()
{    return string;}
0
public void setString(String string)
{    this.string = string;}
0
public Double getD()
{    return d;}
0
public void setD(Double d)
{    this.d = d;}
0
public Map<String, String> getMap()
{    return map;}
0
public void setMap(Map<String, String> map)
{    this.map = map;}
0
public boolean equals(Object o)
{    if (this == o)        return true;    if (o == null || getClass() != o.getClass())        return false;    ArbitraryPojo that = (ArbitraryPojo) o;    if (getList() != null ? !getList().equals(that.getList()) : that.getList() != null)        return false;    if (getString() != null ? !getString().equals(that.getString()) : that.getString() != null)        return false;    if (getD() != null ? !getD().equals(that.getD()) : that.getD() != null)        return false;    if (getMap() != null ? !getMap().equals(that.getMap()) : that.getMap() != null)        return false;    return immutableList != null ? immutableList.equals(that.immutableList) : that.immutableList == null;}
0
public int hashCode()
{    int result = getList() != null ? getList().hashCode() : 0;    result = 31 * result + (getString() != null ? getString().hashCode() : 0);    result = 31 * result + (getD() != null ? getD().hashCode() : 0);    result = 31 * result + (getMap() != null ? getMap().hashCode() : 0);    result = 31 * result + (immutableList != null ? immutableList.hashCode() : 0);    return result;}
0
public void testArbitraryPojo()
{    final ArbitraryPojo expected = new ArbitraryPojo();    byte[] raw = SerDeUtils.toBytes(expected);    Object actual = SerDeUtils.fromBytes(raw, Object.class);    assertEquals(expected, actual);}
0
public static String findDir(String name)
{    return findDir(new File("."), name);}
0
public static String findDir(File startDir, String name)
{    Stack<File> s = new Stack<File>();    s.push(startDir);    while (!s.empty()) {        File parent = s.pop();        if (parent.getName().equalsIgnoreCase(name)) {            return parent.getAbsolutePath();        } else {            File[] children = parent.listFiles();            if (children != null) {                for (File child : children) {                    s.push(child);                }            }        }    }    return null;}
0
public static void assertSetEqual(String type, Set<T> expectedPcapIds, Set<T> found)
{    boolean mismatch = false;    for (T f : found) {        if (!expectedPcapIds.contains(f)) {            mismatch = true;            System.out.println("Found " + type + " that I did not expect: " + f);        }    }    for (T expectedId : expectedPcapIds) {        if (!found.contains(expectedId)) {            mismatch = true;            System.out.println("Expected " + type + " that I did not index: " + expectedId);        }    }    Assert.assertFalse(mismatch);}
0
public static void verboseLogging()
{    verboseLogging("%d [%p|%c|%C{1}] %m%n", Level.ALL);}
0
public static void verboseLogging(String pattern, Level level)
{        ConsoleAppender console = new ConsoleAppender();        console.setLayout(new PatternLayout(pattern));    console.setThreshold(level);    console.activateOptions();        Logger.getRootLogger().addAppender(console);}
0
public static void setLog4jLevel(Class clazz, Level level)
{    Logger logger = Logger.getLogger(clazz);    logger.setLevel(level);}
0
public static Level getLog4jLevel(Class clazz)
{    Logger logger = Logger.getLogger(clazz);    return logger.getLevel();}
0
public static void setJavaLoggingLevel(Class clazz, java.util.logging.Level level)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger(clazz.getName());    logger.setLevel(level);}
0
public static java.util.logging.Level getJavaLoggingLevel(Class clazz)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger(clazz.getName());    return logger.getLevel();}
0
public static void setJavaLoggingLevel(java.util.logging.Level level)
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger("");    logger.setLevel(level);}
0
public static java.util.logging.Level getJavaLoggingLevel()
{    java.util.logging.Logger logger = java.util.logging.Logger.getLogger("");    return logger.getLevel();}
0
public static File createTempDir(File dir) throws IOException
{    return createTempDir(dir, true);}
0
public static File createTempDir(File dir, boolean cleanup) throws IOException
{    if (!dir.mkdirs() && !dir.exists()) {        throw new IOException(String.format("Failed to create directory structure '%s'", dir.toString()));    }    if (cleanup) {        addCleanupHook(dir.toPath());    }    return dir;}
0
public static File createTempDir(String prefix) throws IOException
{    return createTempDir(prefix, true);}
0
public static File createTempDir(String prefix, boolean cleanup) throws IOException
{    Path tmpDir = Files.createTempDirectory(prefix);    addCleanupHook(tmpDir);    return tmpDir.toFile();}
0
public static void addCleanupHook(final Path dir)
{    Runtime.getRuntime().addShutdownHook(new Thread() {        @Override        public void run() {            try {                cleanDir(dir);            } catch (IOException e) {                System.out.println(format("Warning: Unable to clean folder '%s'", dir.toString()));            }        }    });}
0
public void run()
{    try {        cleanDir(dir);    } catch (IOException e) {        System.out.println(format("Warning: Unable to clean folder '%s'", dir.toString()));    }}
0
public static void cleanDir(Path dir) throws IOException
{    Files.walkFileTree(dir, new SimpleFileVisitor<Path>() {        @Override        public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException {            Files.delete(file);            return FileVisitResult.CONTINUE;        }        @Override        public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException {            if (exc == null) {                return FileVisitResult.CONTINUE;            } else {                throw exc;            }        }    });    Files.delete(dir);}
0
public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
0
public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException
{    Files.delete(file);    return FileVisitResult.CONTINUE;}
0
public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException
{    if (exc == null) {        return FileVisitResult.CONTINUE;    } else {        throw exc;    }}
0
public static File write(File file, String contents) throws IOException
{    com.google.common.io.Files.createParentDirs(file);    com.google.common.io.Files.write(contents, file, StandardCharsets.UTF_8);    return file;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    throw new IllegalStateException(Joiner.on(" ").join(args));}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    return true;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return true;}
0
public void ensureDocumentation()
{    ClassLoader classLoader = getClass().getClassLoader();    int numFound = 0;    for (Class<?> clazz : new ClasspathFunctionResolver().resolvables()) {        if (clazz.isAnnotationPresent(Stellar.class)) {            numFound++;            Stellar annotation = clazz.getAnnotation(Stellar.class);            Assert.assertFalse("Must specify a name for " + clazz.getName(), StringUtils.isEmpty(annotation.name()));            Assert.assertFalse("Must specify a description annotation for " + clazz.getName(), StringUtils.isEmpty(annotation.description()));            Assert.assertFalse("Must specify a returns annotation for " + clazz.getName(), StringUtils.isEmpty(annotation.returns()));        }    }    Assert.assertTrue(numFound > 0);}
0
public void testEscapedLiterals()
{    Assert.assertEquals("'bar'", run("\"'bar'\"", new HashMap<>()));    Assert.assertEquals("'BAR'", run("TO_UPPER('\\'bar\\'')", new HashMap<>()));    Assert.assertEquals("\"bar\"", run("\"\\\"bar\\\"\"", new HashMap<>()));    Assert.assertEquals("\"bar\"", run("'\"bar\"'", new HashMap<>()));    Assert.assertEquals("\"BAR\"", run("TO_UPPER(\"\\\"bar\\\"\")", new HashMap<>()));    Assert.assertEquals("bar \\ foo", run("'bar \\\\ foo'", new HashMap<>()));    Assert.assertEquals("bar \\\\ foo", run("'bar \\\\\\\\ foo'", new HashMap<>()));    Assert.assertEquals("bar\nfoo", run("'bar\\nfoo'", new HashMap<>()));    Assert.assertEquals("bar\n\nfoo", run("'bar\\n\\nfoo'", new HashMap<>()));    Assert.assertEquals("bar\tfoo", run("'bar\\tfoo'", new HashMap<>()));    Assert.assertEquals("bar\t\tfoo", run("'bar\\t\\tfoo'", new HashMap<>()));    Assert.assertEquals("bar\rfoo", run("'bar\\rfoo'", new HashMap<>()));    Assert.assertEquals("'bar'", run("'\\'bar\\''", new HashMap<>()));}
0
public void testVariableResolution()
{    {        String query = "bar:variable";        Assert.assertEquals("bar", run(query, ImmutableMap.of("bar:variable", "bar")));        Assert.assertEquals("grok", run(query, ImmutableMap.of("bar:variable", "grok")));    }    {        String query = "JOIN(['foo', bar:variable], '')";        Assert.assertEquals("foobar", run(query, ImmutableMap.of("bar:variable", "bar")));        Assert.assertEquals("foogrok", run(query, ImmutableMap.of("bar:variable", "grok")));    }    {        String query = "MAP_GET('bar', { 'foo' : 1, 'bar' : bar:variable})";        Assert.assertEquals("bar", run(query, ImmutableMap.of("bar:variable", "bar")));        Assert.assertEquals("grok", run(query, ImmutableMap.of("bar:variable", "grok")));    }}
0
public void testMissingVariablesWithParse()
{    String query = "someVar";    run(query, new HashMap<>());}
0
public void testValidateDoesNotThrow()
{    String query = "someVar";    validate(query);}
0
public void testContextActivityTypeReset()
{    String query = "someVar";    Context context = Context.EMPTY_CONTEXT();    validate(query, context);    Assert.assertNull(context.getActivityType());    run(query, ImmutableMap.of("someVar", "someValue"), context);    Assert.assertNull(context.getActivityType());}
0
public void testIfThenElseBug1()
{    String query = "50 + (true == true ? 10 : 20)";    Assert.assertEquals(60, run(query, new HashMap<>()));}
0
public void testIfThenElseBug2()
{    String query = "50 + (true == false ? 10 : 20)";    Assert.assertEquals(70, run(query, new HashMap<>()));}
0
public void testIfThenElseBug3()
{    String query = "50 * (true == false ? 2 : 10) + 20";    Assert.assertEquals(520, run(query, new HashMap<>()));}
0
public void testIfThenElseBug4()
{    String query = "TO_INTEGER(true == true ? 10.0 : 20.0 )";    Assert.assertEquals(10, run(query, new HashMap<>()));}
0
public void testVariablesUsed()
{    StellarProcessor processor = new StellarProcessor();    {        Assert.assertEquals(new HashSet<>(), processor.variablesUsed("if 1 < 2 then 'one' else 'two'"));    }    {        Assert.assertEquals(ImmutableSet.of("one"), processor.variablesUsed("if 1 < 2 then one else 'two'"));    }    {        Assert.assertEquals(ImmutableSet.of("one", "two"), processor.variablesUsed("if 1 < 2 then one else two"));    }    {        Assert.assertEquals(ImmutableSet.of("bar"), processor.variablesUsed("MAP_GET('foo', { 'foo' : bar})"));    }}
0
public void testConditionalsAsMapKeys()
{    {        String query = "{ ( RET_TRUE() && y < 50 ) : 'info', y >= 50 : 'warn'}";        Map<Boolean, String> ret = (Map) run(query, ImmutableMap.of("y", 50));        Assert.assertEquals(ret.size(), 2);        Assert.assertEquals("warn", ret.get(true));        Assert.assertEquals("info", ret.get(false));    }}
0
public void testConditionalsAsFunctionArgs()
{    {        String query = "RET_TRUE(y < 10)";        Assert.assertTrue((boolean) run(query, ImmutableMap.of("y", 50)));    }}
0
public void testFunctionEmptyArgs()
{    {        String query = "STARTS_WITH(casey, 'case') or MAP_EXISTS()";        Assert.assertTrue((Boolean) run(query, ImmutableMap.of("casey", "casey")));    }    {        String query = "true or MAP_EXISTS()";        Assert.assertTrue((Boolean) run(query, new HashMap<>()));    }    {        String query = "MAP_EXISTS() or true";        Assert.assertTrue((Boolean) run(query, new HashMap<>()));    }}
0
public void testNull()
{    {        String query = "if 1 < 2 then NULL else true";        Assert.assertNull(run(query, new HashMap<>()));    }    {        String query = "1 < 2 ? NULL : true";        Assert.assertNull(run(query, new HashMap<>()));    }    {        String query = "null == null ? true : false";        Assert.assertTrue((Boolean) run(query, new HashMap<>()));    }}
0
public void testNaN()
{            {        String query = "NaN == NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "5.0 == NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NULL == NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "'metron' == NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }        {        String query = "NaN != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "5 != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "'metron' != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }        {        String query = "NaN > 5";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN < 5";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN >= 5";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN <= 5";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN > NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN < NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN >= NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN <= NaN";        Assert.assertFalse(runPredicate(query, new HashMap<>()));    }        {        String query = "(5 + NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "5 + NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }    {        String query = "(5 - NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "5 - NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }    {        String query = "(5 / NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "5 / NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }    {        String query = "(5 * NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "5 * NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }    {        String query = "(NaN + NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN + NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }    {        String query = "(NaN - NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN - NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }    {        String query = "(NaN * NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN * NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }    {        String query = "(NaN / NaN) != NaN";        Assert.assertTrue(runPredicate(query, new HashMap<>()));    }    {        String query = "NaN / NaN";        Assert.assertTrue(run(query, new HashMap<>()).toString().equals("NaN"));    }}
0
public void testMapConstant()
{    {        String query = "MAP_GET('bar', { 'foo' : 1, 'bar' : 'bar'})";        Assert.assertEquals("bar", run(query, new HashMap<>()));    }    {        String query = "MAP_GET('blah', {  'blah' : 1 < 2 })";        Assert.assertEquals(true, run(query, new HashMap<>()));    }    {        String query = "MAP_GET('blah', {  'blah' : not(STARTS_WITH(casey, 'case')) })";        Assert.assertEquals(false, run(query, ImmutableMap.of("casey", "casey")));    }    {        String query = "MAP_GET('blah', {  'blah' : one })";        Assert.assertEquals(1, run(query, ImmutableMap.of("one", 1)));    }    {        String query = "MAP_GET('blah', {  'blah' : null })";        Assert.assertNull(run(query, new HashMap<>()));    }    {        String query = "MAP_GET('BLAH', {  TO_UPPER('blah') : null })";        Assert.assertNull(run(query, new HashMap<>()));    }    {        String query = "MAP_GET('BLAH', {  TO_UPPER('blah') : 1 < 2 })";        Assert.assertEquals(true, run(query, new HashMap<>()));    }}
0
public void testIfThenElse()
{    {        String query = "if STARTS_WITH(casey, 'case') then 'one' else 'two'";        Assert.assertEquals("one", run(query, ImmutableMap.of("casey", "casey")));    }    {        String query = "if 1 < 2 then 'one' else 'two'";        Assert.assertEquals("one", run(query, new HashMap<>()));    }    {        String query = "if 1 + 1 < 2 then 'one' else 'two'";        Assert.assertEquals("two", run(query, new HashMap<>()));    }    {        String query = "if 1 + 1 <= 2 AND 1 + 2 in [3] then 'one' else 'two'";        Assert.assertEquals("one", run(query, new HashMap<>()));    }    {        String query = "if 1 + 1 <= 2 AND (1 + 2 in [3]) then 'one' else 'two'";        Assert.assertEquals("one", run(query, new HashMap<>()));    }    {        String query = "if not(1 < 2) then 'one' else 'two'";        Assert.assertEquals("two", run(query, new HashMap<>()));    }    {        String query = "if 1 == 1.0000001 then 'one' else 'two'";        Assert.assertEquals("two", run(query, new HashMap<>()));    }    {        String query = "if one < two then 'one' else 'two'";        Assert.assertEquals("one", run(query, ImmutableMap.of("one", 1, "two", 2)));    }    {        String query = "if one == very_nearly_one then 'one' else 'two'";        Assert.assertEquals("two", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "if one == very_nearly_one OR one == very_nearly_one then 'one' else 'two'";        Assert.assertEquals("two", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "if one == very_nearly_one OR one != very_nearly_one then 'one' else 'two'";        Assert.assertEquals("one", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "if one != very_nearly_one OR one == very_nearly_one then 'one' else 'two'";        Assert.assertEquals("one", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "if 'foo' in ['foo'] OR one == very_nearly_one then 'one' else 'two'";        Assert.assertEquals("one", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "if ('foo' in ['foo']) OR one == very_nearly_one then 'one' else 'two'";        Assert.assertEquals("one", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "if not('foo' in ['foo']) OR one == very_nearly_one then 'one' else 'two'";        Assert.assertEquals("two", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "if not('foo' in ['foo'] OR one == very_nearly_one) then 'one' else 'two'";        Assert.assertEquals("two", run(query, ImmutableMap.of("one", 1, "very_nearly_one", 1.0000001)));    }    {        String query = "1 < 2 ? 'one' : 'two'";        Assert.assertEquals("one", run(query, new HashMap<>()));    }    {        String query = "1 < 2 ? TO_UPPER('one') : 'two'";        Assert.assertEquals("ONE", run(query, new HashMap<>()));    }    {        String query = "1 < 2 ? one : 'two'";        Assert.assertEquals("one", run(query, ImmutableMap.of("one", "one")));    }    {        String query = "1 < 2 ? one*3 : 'two'";        Assert.assertTrue(Math.abs(3 - (int) run(query, ImmutableMap.of("one", 1))) < 1e-6);    }    {        String query = "1 < 2 AND 1 < 2 ? one*3 : 'two'";        Assert.assertTrue(Math.abs(3 - (int) run(query, ImmutableMap.of("one", 1))) < 1e-6);    }    {        String query = "1 < 2 AND 1 > 2 ? one*3 : 'two'";        Assert.assertEquals("two", run(query, ImmutableMap.of("one", 1)));    }    {        String query = "1 > 2 AND 1 < 2 ? one*3 : 'two'";        Assert.assertEquals("two", run(query, ImmutableMap.of("one", 1)));    }    {        String query = "1 < 2 AND 'foo' in ['', 'foo'] ? one*3 : 'two'";        Assert.assertEquals(3, run(query, ImmutableMap.of("one", 1)));    }    {        String query = "1 < 2 AND ('foo' in ['', 'foo']) ? one*3 : 'two'";        Assert.assertEquals(3, run(query, ImmutableMap.of("one", 1)));    }    {        String query = "'foo' in ['', 'foo'] ? one*3 : 'two'";        Assert.assertEquals(3, run(query, ImmutableMap.of("one", 1)));    }}
0
public void testInNotIN()
{    HashMap variables = new HashMap<>();    boolean thrown = false;    try {        Object o = run("in in ['','in']", variables);    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);    thrown = false;    try {        Assert.assertEquals(true, run("'in' in ['','in']", variables));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertFalse(thrown);}
0
public void testHappyPath()
{    String query = "TO_UPPER(TRIM(foo))";    Assert.assertEquals("CASEY", run(query, ImmutableMap.of("foo", "casey ")));}
0
public void testLengthString()
{    String query = "LENGTH(foo)";    Assert.assertEquals(5, run(query, ImmutableMap.of("foo", "abcde")));}
0
public void testLengthCollection()
{    String query = "LENGTH(foo)";    Collection c = Arrays.asList(1, 2, 3, 4, 5);    Assert.assertEquals(5, run(query, ImmutableMap.of("foo", c)));}
0
public void testEmptyLengthString()
{    String query = "LENGTH(foo)";    Assert.assertEquals(0, run(query, ImmutableMap.of("foo", "")));}
0
public void testEmptyLengthCollection()
{    String query = "LENGTH(foo)";    Collection c = new ArrayList();    Assert.assertEquals(0, run(query, ImmutableMap.of("foo", c)));}
0
public void testNoVarLength()
{    String query = "LENGTH(foo)";    run(query, ImmutableMap.of());}
0
public void testJoin()
{    String query = "JOIN( [ TO_UPPER(TRIM(foo)), 'bar' ], ',')";    Assert.assertEquals("CASEY,bar", run(query, ImmutableMap.of("foo", "casey ")));    query = "JOIN( SET_INIT( [ 1, 2, 'buckle', 'my', 'shoe', 3 ] ), ',')";    Assert.assertEquals("1,2,buckle,my,shoe,3", run(query, new HashMap<>()));}
0
public void testSplit()
{    String query = "JOIN( SPLIT(foo, ':'), ',')";    Assert.assertEquals("casey,bar", run(query, ImmutableMap.of("foo", "casey:bar")));}
0
public void testMapGet()
{    String query = "MAP_GET(dc, dc2tz, 'UTC')";    Assert.assertEquals("UTC", run(query, ImmutableMap.of("dc", "nyc", "dc2tz", ImmutableMap.of("la", "PST"))));    Assert.assertEquals("EST", run(query, ImmutableMap.of("dc", "nyc", "dc2tz", ImmutableMap.of("nyc", "EST"))));}
0
public void testMapPut()
{    Map vars = ImmutableMap.of("mymap", new HashMap<String, String>());    String query = "MAP_PUT('foo','bar',mymap)";    assertThat(run(query, vars), instanceOf(Map.class));    query = "MAP_GET('foo', mymap)";    assertThat(run(query, vars), equalTo("bar"));}
0
public void testMapPutDefault()
{    Map vars = new HashMap() {        {            put("mymap", null);        }    };    String query = "MAP_PUT('foo','bar', mymap)";    Map result = (Map) run(query, vars);    assertThat(result, instanceOf(Map.class));    assertThat(result.size(), equalTo(1));    assertThat(result.get("foo"), equalTo("bar"));}
0
public void mapPutTest_wrongType() throws Exception
{    Map s = (Map) run("MAP_PUT( 'foo', 'bar', [ 'baz' ] )", new HashMap<>());}
0
public void testMapMergeEmpty()
{    Map m = (Map) StellarProcessorUtils.run("MAP_MERGE([{}, null])", new HashMap<>());    Assert.assertEquals(0, m.size());}
0
public void testMapMergeFromVariables()
{    Map vars = new HashMap() {        {            put("map1", ImmutableMap.of("a", 1, "b", 2));            put("map2", ImmutableMap.of("c", 3, "d", 4));            put("map3", ImmutableMap.of("e", 5, "f", 6));        }    };    String query = "MAP_MERGE([map1, map2, map3])";    Map result = (Map) run(query, vars);    assertThat(result, instanceOf(Map.class));    assertThat(result.size(), equalTo(6));    assertThat(result.get("a"), equalTo(1));    assertThat(result.get("b"), equalTo(2));    assertThat(result.get("c"), equalTo(3));    assertThat(result.get("d"), equalTo(4));    assertThat(result.get("e"), equalTo(5));    assertThat(result.get("f"), equalTo(6));}
0
public void testMapMergeSingleMap()
{    String query = "MAP_MERGE( [ { 'a' : '1', 'b' : '2', 'c' : '3' } ] )";    Map result = (Map) run(query, new HashMap<>());    assertThat(result, instanceOf(Map.class));    assertThat(result.size(), equalTo(3));    assertThat(result.get("a"), equalTo("1"));    assertThat(result.get("b"), equalTo("2"));    assertThat(result.get("c"), equalTo("3"));}
0
public void testMapMergeFromInlineMaps()
{    String query = "MAP_MERGE( [ { 'a' : '1', 'b' : '2' }, { 'c' : '3', 'd' : '4' }, { 'e' : '5', 'f' : '6' } ] )";    Map result = (Map) run(query, new HashMap<>());    assertThat(result, instanceOf(Map.class));    assertThat(result.size(), equalTo(6));    assertThat(result.get("a"), equalTo("1"));    assertThat(result.get("b"), equalTo("2"));    assertThat(result.get("c"), equalTo("3"));    assertThat(result.get("d"), equalTo("4"));    assertThat(result.get("e"), equalTo("5"));    assertThat(result.get("f"), equalTo("6"));}
0
public void testMapMergeWithOverlappingMapsAndMixedTypes()
{    String query = "MAP_MERGE( [ { 'a' : '1', 'b' : 2, 'c' : '3' }, { 'c' : '3b', 'd' : '4' }, { 'd' : '4b', 'e' : 5, 'f' : '6' } ] )";    Map result = (Map) run(query, new HashMap<>());    assertThat(result, instanceOf(Map.class));    assertThat(result.size(), equalTo(6));    assertThat(result.get("a"), equalTo("1"));    assertThat(result.get("b"), equalTo(2));    assertThat(result.get("c"), equalTo("3b"));    assertThat(result.get("d"), equalTo("4b"));    assertThat(result.get("e"), equalTo(5));    assertThat(result.get("f"), equalTo("6"));}
0
public void mapMergeTest_wrongType() throws Exception
{    Map s = (Map) run("MAP_MERGE( [ 'foo', 'bar' ] )", new HashMap<>());}
0
public void testTLDExtraction()
{    String query = "DOMAIN_TO_TLD(foo)";    Assert.assertEquals("co.uk", run(query, ImmutableMap.of("foo", "www.google.co.uk")));}
0
public void testTLDRemoval()
{    String query = "DOMAIN_REMOVE_TLD(foo)";    Assert.assertEquals("www.google", run(query, ImmutableMap.of("foo", "www.google.co.uk")));}
0
public void testSubdomainRemoval()
{    String query = "DOMAIN_REMOVE_SUBDOMAINS(foo)";    Assert.assertEquals("google.co.uk", run(query, ImmutableMap.of("foo", "www.google.co.uk")));    Assert.assertEquals("google.com", run(query, ImmutableMap.of("foo", "www.google.com")));}
0
public void testURLToHost()
{    String query = "URL_TO_HOST(foo)";    Assert.assertEquals("www.google.co.uk", run(query, ImmutableMap.of("foo", "http://www.google.co.uk/my/path")));}
0
public void testURLToPort()
{    String query = "URL_TO_PORT(foo)";    Assert.assertEquals(80, run(query, ImmutableMap.of("foo", "http://www.google.co.uk/my/path")));}
0
public void testURLToProtocol()
{    String query = "URL_TO_PROTOCOL(foo)";    Assert.assertEquals("http", run(query, ImmutableMap.of("foo", "http://www.google.co.uk/my/path")));}
0
public void testURLToPath()
{    String query = "URL_TO_PATH(foo)";    Assert.assertEquals("/my/path", run(query, ImmutableMap.of("foo", "http://www.google.co.uk/my/path")));}
0
public void testProtocolToName()
{    String query = "PROTOCOL_TO_NAME(protocol)";    Assert.assertEquals("TCP", run(query, ImmutableMap.of("protocol", "6")));    Assert.assertEquals("TCP", run(query, ImmutableMap.of("protocol", 6)));    Assert.assertEquals(null, run(query, ImmutableMap.of("foo", 6)));    Assert.assertEquals("chicken", run(query, ImmutableMap.of("protocol", "chicken")));}
0
public void testDateConversion()
{    long expected = 1452013350000L;    {        String query = "TO_EPOCH_TIMESTAMP(foo, 'yyyy-MM-dd HH:mm:ss', 'UTC')";        Assert.assertEquals(expected, run(query, ImmutableMap.of("foo", "2016-01-05 17:02:30")));    }    {        String query = "TO_EPOCH_TIMESTAMP(foo, 'yyyy-MM-dd HH:mm:ss')";        Long ts = (Long) run(query, ImmutableMap.of("foo", "2016-01-05 17:02:30"));                Assert.assertTrue(Math.abs(ts - expected) < 8.64e+7);    }}
0
public void testToString()
{    Assert.assertEquals("5", run("TO_STRING(foo)", ImmutableMap.of("foo", 5)));}
0
public void testToStringNull()
{    Assert.assertEquals("null", run("TO_STRING(\"null\")", ImmutableMap.of("foo", "null")));}
0
public void testToInteger()
{    Assert.assertEquals(5, run("TO_INTEGER(foo)", ImmutableMap.of("foo", "5")));    Assert.assertEquals(5, run("TO_INTEGER(foo)", ImmutableMap.of("foo", 5)));}
0
public void testToDouble()
{    Assert.assertEquals(5.1d, run("TO_DOUBLE(foo)", ImmutableMap.of("foo", 5.1d)));    Assert.assertEquals(5.1d, run("TO_DOUBLE(foo)", ImmutableMap.of("foo", "5.1")));}
0
public void testGet()
{    Map<String, Object> variables = ImmutableMap.of("foo", "www.google.co.uk");    Assert.assertEquals("www", run("GET_FIRST(SPLIT(DOMAIN_REMOVE_TLD(foo), '.'))", variables));    Assert.assertEquals("www", run("GET(SPLIT(DOMAIN_REMOVE_TLD(foo), '.'), 0)", variables));    Assert.assertEquals("google", run("GET_LAST(SPLIT(DOMAIN_REMOVE_TLD(foo), '.'))", variables));    Assert.assertEquals("google", run("GET(SPLIT(DOMAIN_REMOVE_TLD(foo), '.'), 1)", variables));}
0
public void testBooleanOps() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("empty", "");            put("spaced", "metron is great");        }    };    Assert.assertFalse(runPredicate("not('casey' == foo and true)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("not(not('casey' == foo and true))", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("('casey' == foo) && ( false != true )", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("('casey' == foo) and (FALSE == TRUE)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("'casey' == foo and FALSE", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("'casey' == foo and true", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("true", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("TRUE", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testInCollection() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("empty", "");        }    };    Assert.assertTrue(runPredicate("foo in [ 'casey', 'david' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("foo in [ ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in [ foo, 'david' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in [ 'casey', 'david' ] and 'casey' == foo", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in [ 'casey', 'david' ] and foo == 'casey'", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in [ 'casey' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("foo not in [ 'casey', 'david' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("foo not in [ 'casey', 'david' ] and 'casey' == foo", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("null in [ null, 'something' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("null not in [ null, 'something' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testInMap() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("empty", "");        }    };    Assert.assertTrue(runPredicate("'casey' in { foo : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("'casey' not in { foo : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in { foo : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("foo not in { foo : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("'foo' in { 'foo' : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("'foo' not in { 'foo' : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in { 'casey' : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("foo not in { 'casey' : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("empty in { foo : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("empty not in { foo : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("'foo' in { }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("null in { 'foo' : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("null not in { 'foo' : 5 }", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testShortCircuit_mixedBoolOps() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>();    Assert.assertTrue(runPredicate("(false && true) || true", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("(false && false) || true", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("(true || true) && false", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testInString() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("empty", "");        }    };    Assert.assertTrue(runPredicate("'case' in foo", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("'case' not in foo", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("'case' in empty", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("'case' not in empty", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("'case' in [ foo ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("'case' not in [ foo ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("null in foo", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("null not in foo", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void inNestedInStatement() throws Exception
{    final Map<String, String> variableMap = new HashMap<>();    Assert.assertTrue(runPredicate("('grok' not in 'foobar') == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("'grok' not in ('foobar' == true)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertFalse(runPredicate("'grok' in 'grokbar' == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("false in 'grokbar' == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("('foo' in 'foobar') == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertFalse(runPredicate("'foo' in ('foobar' == true)", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("'grok' not in 'grokbar' == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("false in 'grokbar' == true", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("'foo' in ['foo'] AND 'bar' in ['bar']", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("('foo' in ['foo']) AND 'bar' in ['bar']", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("'foo' in ['foo'] AND ('bar' in ['bar'])", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("('foo' in ['foo']) AND ('bar' in ['bar'])", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));    Assert.assertTrue(runPredicate("('foo' in ['foo'] AND 'bar' in ['bar'])", new DefaultVariableResolver(variableMap::get, variableMap::containsKey)));}
0
public void testExists() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("empty", "");            put("spaced", "metron is great");        }    };    Assert.assertTrue(runPredicate("exists(foo)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("exists(bar)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("exists(bar) or true", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testMapFunctions_advanced() throws Exception
{    final Map<String, Object> variableMap = new HashMap<String, Object>() {        {            put("foo", "casey");            put("bar", "bar.casey.grok");            put("ip", "192.168.0.1");            put("empty", "");            put("spaced", "metron is great");            put("myMap", ImmutableMap.of("casey", "apple"));        }    };    Assert.assertTrue(runPredicate("MAP_EXISTS(foo, myMap)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testLogicalFunctions() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("ip", "192.168.0.1");            put("ip_src_addr", "192.168.0.1");            put("ip_dst_addr", "10.0.0.1");            put("other_ip", "10.168.0.1");            put("empty", "");            put("spaced", "metron is great");        }    };    Assert.assertTrue(runPredicate("IN_SUBNET(ip, '192.168.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("IN_SUBNET(ip, '192.168.0.0/24', '11.0.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("IN_SUBNET(ip, '192.168.0.0/24', '11.0.0.0/24') in [true]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("true in IN_SUBNET(ip, '192.168.0.0/24', '11.0.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IN_SUBNET(ip_dst_addr, '192.168.0.0/24', '11.0.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IN_SUBNET(other_ip, '192.168.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    boolean thrown = false;    try {        runPredicate("IN_SUBNET(blah, '192.168.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v)));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);    Assert.assertTrue(runPredicate("true and STARTS_WITH(foo, 'ca')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("true and STARTS_WITH(TO_UPPER(foo), 'CA')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("(true and STARTS_WITH(TO_UPPER(foo), 'CA')) || true", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("true and ENDS_WITH(foo, 'sey')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("not(IN_SUBNET(ip_src_addr, '192.168.0.0/24') and IN_SUBNET(ip_dst_addr, '192.168.0.0/24'))", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("IN_SUBNET(ip_src_addr, '192.168.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("not(IN_SUBNET(ip_src_addr, '192.168.0.0/24'))", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IN_SUBNET(ip_dst_addr, '192.168.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("not(IN_SUBNET(ip_dst_addr, '192.168.0.0/24'))", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testShortCircuit_conditional() throws Exception
{    Assert.assertEquals("foo", run("if true then 'foo' else (if false then 'bar' else 'grok')", new HashMap<>()));    Assert.assertEquals("foo", run("if true_var != null && true_var then 'foo' else (if false then 'bar' else 'grok')", ImmutableMap.of("true_var", true)));    Assert.assertEquals("foo", run("if true then 'foo' else THROW('expression')", new HashMap<>()));    Assert.assertEquals("foo", run("true ? 'foo' : THROW('expression')", new HashMap<>()));    Assert.assertEquals("foo", run("if false then THROW('exception') else 'foo'", new HashMap<>()));    Assert.assertEquals("foo", run("false ? THROW('exception') : 'foo'", new HashMap<>()));    Assert.assertEquals(true, run("RET_TRUE(if true then 'foo' else THROW('expression'))", new HashMap<>()));    Assert.assertEquals("foo", run("if true or (true or THROW('if exception')) then 'foo' else THROW('expression')", new HashMap<>()));    Assert.assertEquals("foo", run("if true or (false or THROW('if exception')) then 'foo' else THROW('expression')", new HashMap<>()));    Assert.assertEquals("foo", run("if NOT(true or (false or THROW('if exception'))) then THROW('expression') else 'foo'", new HashMap<>()));    Assert.assertEquals("foo", run("if NOT('metron' in [ 'metron', 'metronicus'] ) then THROW('expression') else 'foo'", new HashMap<>()));}
0
public void testShortCircuit_nestedIf() throws Exception
{                            Assert.assertEquals("a", run("IF true THEN IF true THEN 'a' ELSE 'b' ELSE 'c'", new HashMap<>()));    Assert.assertEquals("b", run("IF true THEN IF false THEN 'a' ELSE 'b' ELSE 'c'", new HashMap<>()));    Assert.assertEquals("c", run("IF false THEN IF false THEN 'a' ELSE 'b' ELSE 'c'", new HashMap<>()));                                    Assert.assertEquals("a", run("IF true THEN IF true THEN IF true THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("b", run("IF true THEN IF true THEN IF false THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("c", run("IF true THEN IF false THEN IF true THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("c", run("IF true THEN IF false THEN IF false THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF true THEN IF true THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF true THEN IF false THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF false THEN IF true THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF false THEN IF false THEN 'a' ELSE 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));                                    Assert.assertEquals("a", run("IF true THEN IF true THEN 'a' ELSE IF true THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("a", run("IF true THEN IF true THEN 'a' ELSE IF false THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("b", run("IF true THEN IF false THEN 'a' ELSE IF true THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("c", run("IF true THEN IF false THEN 'a' ELSE IF false THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF true THEN 'a' ELSE IF true THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF true THEN 'a' ELSE IF false THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF false THEN 'a' ELSE IF true THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));    Assert.assertEquals("d", run("IF false THEN IF false THEN 'a' ELSE IF false THEN 'b' ELSE 'c' ELSE 'd'", new HashMap<>()));}
0
public void testShortCircuit_complexNested()
{                            Assert.assertEquals("less", run("IF TO_UPPER('foo') == 'FOO' THEN IF GET_FIRST(MAP(['test_true'], x -> TO_UPPER(x))) == 'TEST_TRUE' THEN match{ var1 < 10 => 'less', var1 >= 12 => 'more', default => 'default'} ELSE 'b' ELSE 'c'", Collections.singletonMap("var1", 1)));    Assert.assertEquals("default", run("IF TO_UPPER('foo') == 'FOO' THEN IF GET_FIRST(MAP(['test_true'], x -> TO_UPPER(x))) == 'TEST_TRUE' THEN match{ var1 < 10 => 'less', var1 >= 12 => 'more', default => 'default'} ELSE 'b' ELSE 'c'", Collections.singletonMap("var1", 11)));    Assert.assertEquals("more", run("IF TO_UPPER('foo') == 'FOO' THEN IF GET_FIRST(MAP(['test_true'], x -> TO_UPPER(x))) == 'TEST_TRUE' THEN match{ var1 < 10 => 'less', var1 >= 12 => 'more', default => 'default'} ELSE 'b' ELSE 'c'", Collections.singletonMap("var1", 100)));        Assert.assertEquals("c", run("IF TO_UPPER('bar') == 'FOO' THEN IF GET_FIRST(MAP(['test_true'], x -> TO_UPPER(x))) == 'TEST_TRUE' THEN match{ var1 < 10 => 'less', var1 >= 12 => 'more', default => 'default'} ELSE 'b' ELSE 'c'", Collections.singletonMap("var1", 1)));        Assert.assertEquals("b", run("IF TO_UPPER('foo') == 'FOO' THEN IF GET_FIRST(MAP(['test_false'], x -> TO_UPPER(x))) == 'TEST_TRUE' THEN match{ var1 < 10 => 'less', var1 >= 12 => 'more', default => 'default'} ELSE 'b' ELSE 'c'", Collections.singletonMap("var1", 1)));}
0
public void testShortCircuit_boolean() throws Exception
{    Assert.assertTrue(runPredicate("'metron' in ['metron', 'metronicus', 'mortron'] or (true or THROW('exception'))", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("true or (true or THROW('exception'))", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("true or (false or THROW('exception'))", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("TO_UPPER('foo') == 'FOO' or (true or THROW('exception'))", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertFalse(runPredicate("false and (true or THROW('exception'))", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("true or false or false or true", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertFalse(runPredicate("false or (false and THROW('exception'))", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("'casey' == 'casey' or THROW('exception')", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("TO_UPPER('casey') == 'CASEY' or THROW('exception')", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("NOT(TO_UPPER('casey') != 'CASEY') or THROW('exception')", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("(TO_UPPER('casey') == 'CASEY') or THROW('exception')", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertFalse(runPredicate("NOT(NOT(TO_UPPER('casey') != 'CASEY') or THROW('exception'))", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertFalse(runPredicate("NOT(NOT(TO_UPPER('casey') != 'CASEY')) and THROW('exception')", new DefaultVariableResolver(x -> null, x -> false)));    Assert.assertTrue(runPredicate("RET_TRUE('foo') or THROW('exception')", new DefaultVariableResolver(x -> null, x -> false)));    boolean thrown = false;    try {        runPredicate("NOT(foo == null or THROW('exception')) and THROW('and exception')", new DefaultVariableResolver(x -> null, x -> false));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);    thrown = false;    try {        runPredicate("(foo == null or THROW('exception') ) or THROW('and exception')", new DefaultVariableResolver(x -> null, x -> false));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);    Assert.assertTrue(runPredicate("( RET_TRUE('foo', true, false) or ( foo == null or THROW('exception') ) or THROW('and exception')) or THROW('or exception')", new DefaultVariableResolver(x -> null, x -> false)));}
0
public void non_boolean_predicate_throws_exception()
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("protocol", "http");        }    };    thrown.expect(IllegalArgumentException.class);    thrown.expectMessage("The rule 'TO_UPPER(protocol)' does not return a boolean value.");    runPredicate("TO_UPPER(protocol)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v)));}
0
public void all_fields_test()
{    final Map<String, Object> varMap1 = new HashMap<String, Object>();    varMap1.put("field1", "val1");    final Map<String, Object> varMap2 = new HashMap<String, Object>();    varMap2.put("field2", "val2");    VariableResolver resolver = new MapVariableResolver(varMap1, varMap2);    Assert.assertTrue(runPredicate("MAP_GET('field1', _) == 'val1'", resolver));    Assert.assertTrue(runPredicate("MAP_GET('field2', _) == 'val2'", resolver));    Assert.assertTrue(runPredicate("LENGTH(_) == 2", resolver));    Map<String, Object> ret = (Map<String, Object>) run("_", resolver);    Assert.assertEquals(2, ret.size());    Assert.assertEquals("val1", ret.get("field1"));    Assert.assertEquals("val2", ret.get("field2"));}
0
public void nullAsFalse()
{    checkFalsey("is_alert");}
0
private void checkFalsey(String falseyExpr)
{    VariableResolver resolver = new MapVariableResolver(new HashMap<>());    Assert.assertTrue(runPredicate(String.format(" %s || true", falseyExpr), resolver));    Assert.assertFalse(runPredicate(String.format("%s && EXCEPTION('blah')", falseyExpr), resolver));    Assert.assertTrue(runPredicate(String.format("NOT(%s)", falseyExpr), resolver));    Assert.assertFalse(runPredicate(String.format("if %s then true else false", falseyExpr), resolver));    Assert.assertFalse(runPredicate(String.format("if %s then true || %s else false", falseyExpr, falseyExpr), resolver));    Assert.assertFalse(runPredicate(String.format("if %s then true || %s else false && %s", falseyExpr, falseyExpr, falseyExpr), resolver));    Assert.assertFalse(runPredicate(String.format("if %s then true || %s else false && (%s || true)", falseyExpr, falseyExpr, falseyExpr), resolver));        Assert.assertNull(run(String.format("MAP_GET(%s, {false : 'blah'})", falseyExpr), resolver));}
0
public void emptyAsFalse()
{    checkFalsey("[]");    checkFalsey("{}");    checkFalsey("LIST_ADD([])");}
0
public void conversionFunctionsShouldProperlyConvertToSpecificType() throws Exception
{    assertEquals(1D, new ConversionFunctions.TO_DOUBLE().apply(Collections.singletonList(1)));    assertEquals(1F, new ConversionFunctions.TO_FLOAT().apply(Collections.singletonList(1.0D)));    assertEquals(1, new ConversionFunctions.TO_INTEGER().apply(Collections.singletonList(1.0D)));    assertEquals(1L, new ConversionFunctions.TO_LONG().apply(Collections.singletonList(1F)));}
0
public void conversionFunctionsShouldProperlyHandleNull() throws Exception
{    assertEquals(null, new ConversionFunctions.TO_DOUBLE().apply(Collections.singletonList(null)));    assertEquals(null, new ConversionFunctions.TO_FLOAT().apply(Collections.singletonList(null)));    assertEquals(null, new ConversionFunctions.TO_INTEGER().apply(Collections.singletonList(null)));    assertEquals(null, new ConversionFunctions.TO_LONG().apply(Collections.singletonList(null)));}
0
public void is_empty_handles_happy_path()
{    DataStructureFunctions.IsEmpty isEmpty = new DataStructureFunctions.IsEmpty();    {        boolean empty = (boolean) isEmpty.apply(ImmutableList.of("hello"));        Assert.assertThat("should be false", empty, CoreMatchers.equalTo(false));    }    {        boolean empty = (boolean) isEmpty.apply(ImmutableList.of(ImmutableList.of("hello", "world")));        Assert.assertThat("should be false", empty, CoreMatchers.equalTo(false));    }    {        boolean empty = (boolean) isEmpty.apply(ImmutableList.of(1));        Assert.assertThat("should be false", empty, CoreMatchers.equalTo(false));    }    {        boolean empty = (boolean) isEmpty.apply(ImmutableList.of(ImmutableMap.of("mykey", "myvalue")));        Assert.assertThat("should be false", empty, CoreMatchers.equalTo(false));    }}
0
public void is_empty_handles_empty_values()
{    DataStructureFunctions.IsEmpty isEmpty = new DataStructureFunctions.IsEmpty();    {        boolean empty = (boolean) isEmpty.apply(ImmutableList.of());        Assert.assertThat("should be true", empty, CoreMatchers.equalTo(true));    }    {        boolean empty = (boolean) isEmpty.apply(null);        Assert.assertThat("should be true", empty, CoreMatchers.equalTo(true));    }    {        boolean empty = (boolean) isEmpty.apply(ImmutableList.of(""));        Assert.assertThat("should be true", empty, CoreMatchers.equalTo(true));    }    {        boolean empty = (boolean) isEmpty.apply(ImmutableList.of(ImmutableMap.of()));        Assert.assertThat("should be true", empty, CoreMatchers.equalTo(true));    }}
0
public void listAdd_number()
{    for (String expr : ImmutableList.of("LIST_ADD(my_list, 1)", "LIST_ADD([], 1)", "LIST_ADD([], val)")) {        Object o = run(expr, ImmutableMap.of("my_list", new ArrayList<>(), "val", 1));        Assert.assertTrue(o instanceof List);        List<Number> result = (List<Number>) o;        Assert.assertEquals(1, result.size());        Assert.assertEquals(1, result.get(0));    }}
0
public void listAdd_mixed()
{    for (String expr : ImmutableList.of("LIST_ADD(my_list, 1)", "LIST_ADD(['foo'], 1)", "LIST_ADD(['foo'], val)")) {        ArrayList<Object> list = new ArrayList<>();        list.add("foo");        Object o = run(expr, ImmutableMap.of("my_list", list, "val", 1));        Assert.assertTrue(o instanceof List);        List<Object> result = (List<Object>) o;        Assert.assertEquals(2, result.size());        Assert.assertEquals("foo", result.get(0));        Assert.assertEquals(1, result.get(1));    }}
0
public void listAdd_number_nonempty()
{    for (String expr : ImmutableList.of("LIST_ADD(my_list, 2)", "LIST_ADD([1], 2)", "LIST_ADD([1], val)")) {        ArrayList<Integer> list = new ArrayList<>();        list.add(1);        Object o = run(expr, ImmutableMap.of("my_list", list, "val", 2));        Assert.assertTrue(o instanceof List);        List<Number> result = (List<Number>) o;        Assert.assertEquals(2, result.size());        Assert.assertEquals(1, result.get(0));        Assert.assertEquals(2, result.get(1));    }}
0
private Object run(String expr)
{    StellarProcessor processor = new StellarProcessor();    assertTrue(processor.validate(expr));    return processor.parse(expr, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), Context.EMPTY_CONTEXT());}
0
public void setup()
{    variables.put("test_datetime", AUG2016);    calendar = Calendar.getInstance();}
0
public void testDayOfWeek()
{    Object result = run("DAY_OF_WEEK(test_datetime)");    assertEquals(Calendar.THURSDAY, result);}
0
public void testDayOfWeekNow()
{    Object result = run("DAY_OF_WEEK()");    assertEquals(calendar.get(Calendar.DAY_OF_WEEK), result);}
0
public void testDayOfWeekNull()
{    Object result = run("DAY_OF_WEEK(nada)");}
0
public void testWeekOfMonth()
{    Object result = run("WEEK_OF_MONTH(test_datetime)");    assertEquals(4, result);}
0
public void testWeekOfMonthNow()
{    Object result = run("WEEK_OF_MONTH()");    assertEquals(calendar.get(Calendar.WEEK_OF_MONTH), result);}
0
public void testWeekOfMonthNull()
{    Object result = run("WEEK_OF_MONTH(nada)");}
0
public void testMonth()
{    Object result = run("MONTH(test_datetime)");    assertEquals(Calendar.AUGUST, result);}
0
public void testMonthNow()
{    Object result = run("MONTH()");    assertEquals(calendar.get(Calendar.MONTH), result);}
0
public void testMonthNull()
{    Object result = run("MONTH(nada)");}
0
public void testYear()
{    Object result = run("YEAR(test_datetime)");    assertEquals(2016, result);}
0
public void testYearNow()
{    Object result = run("YEAR()");    assertEquals(calendar.get(Calendar.YEAR), result);}
0
public void testYearNull()
{    Object result = run("YEAR(nada)");}
0
public void testDayOfMonth()
{    Object result = run("DAY_OF_MONTH(test_datetime)");    assertEquals(25, result);}
0
public void testDayOfMonthNow()
{    Object result = run("DAY_OF_MONTH()");    assertEquals(calendar.get(Calendar.DAY_OF_MONTH), result);}
0
public void testDayOfMonthNull()
{    Object result = run("DAY_OF_MONTH(nada)");}
0
public void testWeekOfYear()
{    Object result = run("WEEK_OF_YEAR(test_datetime)");    calendar.setTimeInMillis(AUG2016);    assertEquals(calendar.get(Calendar.WEEK_OF_YEAR), result);}
0
public void testWeekOfYearNow()
{    Object result = run("WEEK_OF_YEAR()");    assertEquals(calendar.get(Calendar.WEEK_OF_YEAR), result);}
0
public void testWeekOfYearNull()
{    Object result = run("WEEK_OF_YEAR(nada)");}
0
public void testDayOfYear()
{    Object result = run("DAY_OF_YEAR(test_datetime)");    assertEquals(238, result);}
0
public void testDayOfYearNow()
{    Object result = run("DAY_OF_YEAR()");    assertEquals(calendar.get(Calendar.DAY_OF_YEAR), result);}
0
public void testDayOfYearNull()
{    Object result = run("DAY_OF_YEAR(nada)");}
0
public void testDateFormat()
{    Object result = run("DATE_FORMAT('EEE MMM dd yyyy hh:mm:ss zzz', test_datetime, 'EST')");    assertEquals("Thu Aug 25 2016 08:27:10 EST", result);}
0
public void testDateFormatDefault() throws Exception
{    Object result = run("DATE_FORMAT('EEE MMM dd yyyy hh:mm:ss zzzz')");    DateTimeFormatter formatter = DateTimeFormatter.ofPattern("EEE MMM dd yyyy hh:mm:ss zzzz");    LocalDate.parse(result.toString(), formatter);}
0
public void testDateFormatNow()
{    Object result = run("DATE_FORMAT('EEE MMM dd yyyy hh:mm:ss zzz', 'GMT')");    assertTrue(result.toString().endsWith("GMT"));}
0
public void testDateFormatDefaultTimezone()
{    Object result = run("DATE_FORMAT('EEE MMM dd yyyy hh:mm:ss zzzz', test_datetime)");    boolean inDaylightSavings = ZoneId.of(TimeZone.getDefault().getID()).getRules().isDaylightSavings(Instant.ofEpochMilli(AUG2016));    assertTrue(result.toString().endsWith(TimeZone.getDefault().getDisplayName(inDaylightSavings, 1)));}
0
public void testDateFormatNull()
{    Object result = run("DATE_FORMAT('EEE MMM dd yyyy hh:mm:ss zzz', nada, 'EST')");}
0
public void testDateFormatInvalid()
{    Object result = run("DATE_FORMAT('INVALID DATE FORMAT', test_datetime, 'EST')");}
0
public void testSupportedEncodingsList() throws Exception
{    Object ret = run("GET_SUPPORTED_ENCODINGS()", new HashMap());    Assert.assertTrue(ret instanceof List);    List<String> list = (List<String>) ret;    List<String> expected = new ArrayList<>(Arrays.asList("BASE32", "BASE32HEX", "BASE64", "BINARY", "HEX"));    Assert.assertTrue(ListUtils.isEqualList(expected, list));}
0
public void testEncodingIs() throws Exception
{    Assert.assertTrue(runPredicate("IS_ENCODING(BASE32_FIXTURE,'BASE32')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IS_ENCODING(STRING_FIXTURE,'BASE32')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("IS_ENCODING(BASE32HEX_FIXTURE,'BASE32HEX')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IS_ENCODING(STRING_FIXTURE,'BASE32HEX')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("IS_ENCODING(BASE64_FIXTURE,'BASE64')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IS_ENCODING(STRING_FIXTURE_PLUS_NULL,'BASE64')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("IS_ENCODING(BINARY_FIXTURE,'BINARY')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IS_ENCODING(STRING_FIXTURE,'BINARY')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("IS_ENCODING(HEX_FIXTURE,'HEX')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("IS_ENCODING(STRING_FIXTURE,'HEX')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testDecode() throws Exception
{    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BASE32_FIXTURE,'BASE32')", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BASE32HEX_FIXTURE,'BASE32HEX')", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BASE64_FIXTURE,'BASE64')", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BINARY_FIXTURE,'BINARY')", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(HEX_FIXTURE,'HEX')", variableMap));        Assert.assertNotEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BASE32')", variableMap));    Assert.assertNotEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BASE32HEX')", variableMap));    Assert.assertNotEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BASE64')", variableMap));            Assert.assertEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BINARY')", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE, 'HEX')", variableMap));}
0
public void testDecodeWithVerify() throws Exception
{    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BASE32_FIXTURE,'BASE32',true)", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BASE32HEX_FIXTURE,'BASE32HEX',true)", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BASE64_FIXTURE,'BASE64',true)", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(BINARY_FIXTURE,'BINARY',true)", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(HEX_FIXTURE,'HEX',true)", variableMap));        Assert.assertEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BASE32',true)", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BASE32HEX',true)", variableMap));        Assert.assertNotEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BASE64',true)", variableMap));        Assert.assertEquals(STRING_FIXTURE_PLUS_NULL, run("DECODE(STRING_FIXTURE_PLUS_NULL,'BASE64',true)", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'BINARY',true)", variableMap));    Assert.assertEquals(STRING_FIXTURE, run("DECODE(STRING_FIXTURE,'HEX',true)", variableMap));}
0
public void testEncode() throws Exception
{    Assert.assertEquals(BASE32_FIXTURE, run("ENCODE(STRING_FIXTURE,'BASE32')", variableMap));    Assert.assertEquals(BASE32HEX_FIXTURE, run("ENCODE(STRING_FIXTURE,'BASE32HEX')", variableMap));    Assert.assertEquals(BASE64_FIXTURE, run("ENCODE(STRING_FIXTURE,'BASE64')", variableMap));    Assert.assertEquals(BINARY_FIXTURE, run("ENCODE(STRING_FIXTURE,'BINARY')", variableMap));    Assert.assertEquals(HEX_FIXTURE, run("ENCODE(STRING_FIXTURE,'HEX')", variableMap));}
0
public void testZipLongest_boundary()
{    for (String expr : ImmutableList.of("ZIP_LONGEST()", "ZIP_LONGEST( null, null )", "ZIP_LONGEST( [], null )", "ZIP_LONGEST( [], [] )", "ZIP_LONGEST( null, [] )")) {        List<List<Object>> o = (List<List<Object>>) run(expr, new HashMap<>());        Assert.assertEquals(0, o.size());    }}
0
public void testZip_longest()
{    Map<String, Object> variables = ImmutableMap.of("list1", ImmutableList.of(1, 2, 3), "list2", ImmutableList.of(4, 5, 6, 7));    for (String expr : ImmutableList.of("ZIP_LONGEST(list1)", "ZIP_LONGEST( [1, 2, 3])")) {        List<List<Object>> o = (List<List<Object>>) run(expr, variables);        Assert.assertEquals(3, o.size());        for (int i = 0; i < 3; ++i) {            List l = o.get(i);            Assert.assertEquals(1, l.size());            Assert.assertEquals(i + 1, l.get(0));        }    }    for (String expr : ImmutableList.of("ZIP_LONGEST(list1, list2)", "ZIP_LONGEST( [1, 2, 3], [4, 5, 6, 7] )")) {        List<List<Object>> o = (List<List<Object>>) run(expr, variables);        Assert.assertEquals(4, o.size());        for (int i = 0; i < 3; ++i) {            List l = o.get(i);            Assert.assertEquals(2, l.size());            Assert.assertEquals(i + 1, l.get(0));            Assert.assertEquals(i + 4, l.get(1));        }        {            int i = 3;            List l = o.get(i);            Assert.assertEquals(2, l.size());            Assert.assertNull(l.get(0));            Assert.assertEquals(i + 4, l.get(1));        }    }    for (String expr : ImmutableList.of("REDUCE(ZIP_LONGEST(list2, list1), (s, x) -> s + GET_FIRST(x) * GET_LAST(x), 0)", "REDUCE(ZIP_LONGEST( [1, 2, 3], [4, 5, 6, 7] ), (s, x) -> s + GET_FIRST(x) * GET_LAST(x), 0)",     "REDUCE(ZIP_LONGEST(list1, list2), (s, x) -> s + GET_FIRST(x) * GET_LAST(x), 0)",     "REDUCE(ZIP_LONGEST(list1, list2), (s, x) -> s + (GET_FIRST(x) == null?0:GET_FIRST(x)) * (GET_LAST(x) == null?0:GET_LAST(x)), 0)")) {        int o = (int) run(expr, variables);        Assert.assertEquals(1 * 4 + 2 * 5 + 3 * 6, o, 1e-7);    }}
0
public void testZip_boundary()
{    for (String expr : ImmutableList.of("ZIP()", "ZIP( null, null )", "ZIP( [], null )", "ZIP( [], [] )", "ZIP( null, [] )")) {        List<List<Object>> o = (List<List<Object>>) run(expr, new HashMap<>());        Assert.assertEquals(0, o.size());    }}
0
public void testZip()
{    Map<String, Object> variables = ImmutableMap.of("list1", ImmutableList.of(1, 2, 3), "list2", ImmutableList.of(4, 5, 6));    for (String expr : ImmutableList.of("ZIP(list1)", "ZIP( [1, 2, 3])")) {        List<List<Object>> o = (List<List<Object>>) run(expr, variables);        Assert.assertEquals(3, o.size());        for (int i = 0; i < 3; ++i) {            List l = o.get(i);            Assert.assertEquals(1, l.size());            Assert.assertEquals(i + 1, l.get(0));        }    }    for (String expr : ImmutableList.of("ZIP(list1, list2)", "ZIP( [1, 2, 3], [4, 5, 6] )", "ZIP( [1, 2, 3], [4, 5, 6, 7] )")) {        List<List<Object>> o = (List<List<Object>>) run(expr, variables);        Assert.assertEquals(3, o.size());        for (int i = 0; i < 3; ++i) {            List l = o.get(i);            Assert.assertEquals(2, l.size());            Assert.assertEquals(i + 1, l.get(0));            Assert.assertEquals(i + 4, l.get(1));        }    }    for (String expr : ImmutableList.of("REDUCE(ZIP(list1, list2), (s, x) -> s + GET_FIRST(x) * GET_LAST(x), 0)", "REDUCE(ZIP( [1, 2, 3], [4, 5, 6] ), (s, x) -> s + GET_FIRST(x) * GET_LAST(x), 0)", "REDUCE(ZIP( [1, 2, 3], [4, 5, 6, 7] ), (s, x) -> s + GET_FIRST(x) * GET_LAST(x), 0)")) {        int o = (int) run(expr, variables);        Assert.assertEquals(1 * 4 + 2 * 5 + 3 * 6, o, 1e-7);    }}
0
public void testRecursive()
{    for (String expr : ImmutableList.of("MAP(list, inner_list -> REDUCE(inner_list, (x, y) -> x + y, 0) )", "MAP(list, (inner_list) -> REDUCE(inner_list, (x, y) -> x + y, 0) )")) {        Object o = run(expr, ImmutableMap.of("list", ImmutableList.of(ImmutableList.of(1, 2, 3), ImmutableList.of(4, 5, 6))));        Assert.assertTrue(o instanceof List);        List<Number> result = (List<Number>) o;        Assert.assertEquals(2, result.size());        Assert.assertEquals(6, result.get(0));        Assert.assertEquals(15, result.get(1));    }}
0
public void testMap_null()
{    for (String expr : ImmutableList.of("MAP([ 1, 2, null], x -> if x == null then 0 else 2*x )", "MAP([ 1, 2, null], x -> x == null ? 0 : 2*x )", "MAP([ 1, foo, baz], x -> x == null ? 0 : 2*x )")) {        Map<String, Object> variableMap = new HashMap<String, Object>() {            {                put("foo", 2);                put("bar", 3);                put("baz", null);            }        };        Object o = run(expr, variableMap);        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(3, result.size());        Assert.assertEquals(2, result.get(0));        Assert.assertEquals(4, result.get(1));        Assert.assertEquals(0, result.get(2));    }}
0
public void testMap()
{    for (String expr : ImmutableList.of("MAP([ 'foo', 'bar'], (x) -> TO_UPPER(x) )", "MAP([ foo, 'bar'], (x) -> TO_UPPER(x) )", "MAP([ foo, bar], (x) -> TO_UPPER(x) )", "MAP([ foo, bar], x -> TO_UPPER(x) )", "MAP([ foo, bar], x -> true?TO_UPPER(x):THROW('error') )", "MAP([ foo, bar], x -> false?THROW('error'):TO_UPPER(x) )")) {        Object o = run(expr, ImmutableMap.of("foo", "foo", "bar", "bar"));        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(2, result.size());        Assert.assertEquals("FOO", result.get(0));        Assert.assertEquals("BAR", result.get(1));    }}
0
public void testMap_conditional()
{    for (String expr : ImmutableList.of("MAP([ 'foo', 'bar'], (item) -> item == 'foo' )", "MAP([ foo, bar], (item) -> item == 'foo' )", "MAP([ foo, bar], (item) -> item == foo )", "MAP([ foo, bar], item -> item == foo )")) {        Object o = run(expr, ImmutableMap.of("foo", "foo", "bar", "bar"));        Assert.assertTrue(o instanceof List);        List<Boolean> result = (List<Boolean>) o;        Assert.assertEquals(2, result.size());        Assert.assertEquals(true, result.get(0));        Assert.assertEquals(false, result.get(1));    }}
0
public void testFilter()
{    for (String expr : ImmutableList.of("FILTER([ 'foo', 'bar'], (item) -> item == 'foo' )", "FILTER([ 'foo', bar], (item) -> item == 'foo' )", "FILTER([ foo, bar], (item) -> item == 'foo' )", "FILTER([ foo, bar], (item) -> (item == 'foo' && true) )", "FILTER([ foo, bar], (item) -> if item == 'foo' then true else false )", "FILTER([ foo, bar], item -> if item == 'foo' then true else false )")) {        Object o = run(expr, ImmutableMap.of("foo", "foo", "bar", "bar"));        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(1, result.size());        Assert.assertEquals("foo", result.get(0));    }}
0
public void testFilter_shortcircuit()
{    for (String expr : ImmutableList.of("FILTER([ 'foo'], item -> item == 'foo' or THROW('exception') )", "FILTER([ 'foo'], (item) -> item == 'foo' or THROW('exception') )")) {        Object o = run(expr, ImmutableMap.of("foo", "foo", "bar", "bar"));        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(1, result.size());        Assert.assertEquals("foo", result.get(0));    }}
0
public void testFilter_null()
{    for (String expr : ImmutableList.of("FILTER([ 'foo', null], item -> item == null )", "FILTER([ 'foo', baz], (item) -> item == null )")) {        Map<String, Object> variableMap = new HashMap<String, Object>() {            {                put("foo", "foo");                put("bar", "bar");                put("baz", null);            }        };        Object o = run(expr, variableMap);        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(1, result.size());        Assert.assertEquals(null, result.get(0));    }}
0
public void testFilter_notnull()
{    for (String expr : ImmutableList.of("FILTER([ 'foo', null], item -> item != null )", "FILTER([ 'foo', baz], (item) -> item != null )", "FILTER([ foo, baz], (item) -> item != null )")) {        Map<String, Object> variableMap = new HashMap<String, Object>() {            {                put("foo", "foo");                put("bar", "bar");                put("baz", null);            }        };        Object o = run(expr, variableMap);        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(1, result.size());        Assert.assertEquals("foo", result.get(0));    }}
0
public void testFilter_none()
{    for (String expr : ImmutableList.of("FILTER([ foo, bar], () -> false  )", "FILTER([ 'foo', 'bar'], (item)-> false )", "FILTER([ 'foo', bar], (item ) -> false )", "FILTER([ foo, bar], (item) -> false )", "FILTER([ foo, bar], item -> false )")) {        Object o = run(expr, ImmutableMap.of("foo", "foo", "bar", "bar"));        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(0, result.size());    }}
0
public void testFilter_all()
{    for (String expr : ImmutableList.of("FILTER([ 'foo', 'bar'], (item) -> true )", "FILTER([ 'foo', bar], (item) -> true )", "FILTER([ foo, bar], (item) -> true )", "FILTER([ foo, bar], item -> true )", "FILTER([ foo, bar], ()-> true )")) {        Object o = run(expr, ImmutableMap.of("foo", "foo", "bar", "bar"));        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(2, result.size());        Assert.assertEquals("foo", result.get(0));        Assert.assertEquals("bar", result.get(1));    }}
0
public void testReduce_null()
{    for (String expr : ImmutableList.of("REDUCE([ 1, 2, 3, null], (x, y) -> if y != null then x + y else x , 0 )", "REDUCE([ foo, bar, 3, baz], (sum, y) -> if y != null then sum + y else sum, 0 )")) {        Map<String, Object> variableMap = new HashMap<String, Object>() {            {                put("foo", 1);                put("bar", 2);                put("baz", null);            }        };        Object o = run(expr, variableMap);        Assert.assertTrue(o instanceof Number);        Number result = (Number) o;        Assert.assertEquals(6, result.intValue());    }}
0
public void testReduce()
{    for (String expr : ImmutableList.of("REDUCE([ 1, 2, 3 ], (x, y) -> x + y , 0 )", "REDUCE([ foo, bar, 3 ], (x, y) -> x + y , 0 )")) {        Object o = run(expr, ImmutableMap.of("foo", 1, "bar", 2));        Assert.assertTrue(o instanceof Number);        Number result = (Number) o;        Assert.assertEquals(6, result.intValue());    }}
0
public void testReduce_on_various_list_sizes()
{    {        String expr = "REDUCE([ 1, 2, 3, 4 ], (x, y) -> x + y , 0 )";        Object o = run(expr, ImmutableMap.of());        Assert.assertTrue(o instanceof Number);        Number result = (Number) o;        Assert.assertEquals(10, result.intValue());    }    {        String expr = "REDUCE([ 1, 2 ], (x, y) -> x + y , 0 )";        Object o = run(expr, ImmutableMap.of());        Assert.assertTrue(o instanceof Number);        Number result = (Number) o;        Assert.assertEquals(3, result.intValue());    }    {        String expr = "REDUCE([ 1 ], (x, y) -> x + y , 0 )";        Object o = run(expr, ImmutableMap.of());        Assert.assertTrue(o instanceof Number);        Number result = (Number) o;        Assert.assertEquals(1, result.intValue());    }}
0
public void testReduce_NonNumeric()
{    for (String expr : ImmutableList.of("REDUCE([ 'foo', 'bar', 'grok'], (x, y) -> LIST_ADD(x, y), [] )")) {        Object o = run(expr, ImmutableMap.of("foo", 1, "bar", 2, "x", 0, "y", 0));        Assert.assertTrue(o instanceof List);        List<String> result = (List<String>) o;        Assert.assertEquals(3, result.size());        Assert.assertEquals("foo", result.get(0));        Assert.assertEquals("bar", result.get(1));        Assert.assertEquals("grok", result.get(2));    }}
0
public void testReduce_returns_null_when_less_than_3_args()
{    {        String expr = "REDUCE([ 1, 2, 3 ], (x, y) -> LIST_ADD(x, y))";        Assert.assertThat(run(expr, ImmutableMap.of()), CoreMatchers.equalTo(null));    }    {        String expr = "REDUCE([ 1, 2, 3 ])";        Assert.assertThat(run(expr, ImmutableMap.of()), CoreMatchers.equalTo(null));    }}
0
public void nullArgumentsShouldFail() throws Exception
{    listSupportedHashTypes.apply(null);}
0
public void getSupportedHashAlgorithmsCalledWithParametersShouldFail() throws Exception
{    listSupportedHashTypes.apply(Collections.singletonList("bogus"));}
0
public void listSupportedHashTypesReturnsAtMinimumTheHashingAlgorithmsThatMustBeSupported() throws Exception
{        final List<String> requiredAlgorithmsByJava = Arrays.asList("MD5", "SHA", "SHA-256");    final Collection<String> supportedHashes = listSupportedHashTypes.apply(Collections.emptyList());    requiredAlgorithmsByJava.forEach(a -> assertTrue(supportedHashes.contains(a)));}
0
public void nullArgumentListShouldThrowException() throws Exception
{    hash.apply(null);}
0
public void emptyArgumentListShouldThrowException() throws Exception
{    hash.apply(Collections.emptyList());}
0
public void singleArgumentListShouldThrowException() throws Exception
{    hash.apply(Collections.singletonList("some value."));}
0
public void argumentListWithMoreThanTwoValuesShouldThrowException3() throws Exception
{    hash.apply(Arrays.asList("1", "2", "3"));}
0
public void argumentListWithMoreThanTwoValuesShouldThrowException4() throws Exception
{    hash.apply(Arrays.asList("1", "2", "3", "4"));}
0
public void invalidAlgorithmArgumentShouldThrowException() throws Exception
{    hash.apply(Arrays.asList("value to hash", "invalidAlgorithm"));}
0
public void invalidNullAlgorithmArgumentShouldReturnNull() throws Exception
{    assertNull(hash.apply(Arrays.asList("value to hash", null)));}
0
public void nullInputForValueToHashShouldReturnHashedEncodedValueOf0x00() throws Exception
{    assertEquals(StringUtils.repeat('0', 32), hash.apply(Arrays.asList(null, "md5")));}
0
public void nullInputForValueToHashShouldReturnHashedEncodedValueOf0x00InDirectStellarCall() throws Exception
{    final String algorithm = "'md5'";    final Map<String, Object> variables = new HashMap<>();    variables.put("toHash", null);    assertEquals(StringUtils.repeat('0', 32), run("HASH(toHash, " + algorithm + ")", variables));}
0
public void allAlgorithmsForMessageDigestShouldBeAbleToHash() throws Exception
{    final String valueToHash = "My value to hash";    final Set<String> algorithms = Security.getAlgorithms("MessageDigest");    algorithms.forEach(algorithm -> {        try {            final MessageDigest expected = MessageDigest.getInstance(algorithm);            expected.update(valueToHash.getBytes(StandardCharsets.UTF_8));            assertEquals(expectedHexString(expected), hash.apply(Arrays.asList(valueToHash, algorithm)));        } catch (NoSuchAlgorithmException e) {            throw new RuntimeException(e);        }    });}
0
public void allAlgorithmsForMessageDigestShouldBeAbleToHashDirectStellarCall() throws Exception
{    final String valueToHash = "My value to hash";    final Set<String> algorithms = Security.getAlgorithms("MessageDigest");    algorithms.forEach(algorithm -> {        try {            final Object actual = run("HASH('" + valueToHash + "', '" + algorithm + "')", Collections.emptyMap());            final MessageDigest expected = MessageDigest.getInstance(algorithm);            expected.update(valueToHash.getBytes(StandardCharsets.UTF_8));            assertEquals(expectedHexString(expected), actual);        } catch (NoSuchAlgorithmException e) {            throw new RuntimeException(e);        }    });}
0
public void nonStringValueThatIsSerializableHashesSuccessfully() throws Exception
{    final String algorithm = "'md5'";    final String valueToHash = "'My value to hash'";    final Serializable input = (Serializable) Collections.singletonList(valueToHash);    final MessageDigest expected = MessageDigest.getInstance(algorithm.replace("'", ""));    expected.update(SerializationUtils.serialize(input));    final Map<String, Object> variables = new HashMap<>();    variables.put("toHash", input);    assertEquals(expectedHexString(expected), run("HASH(toHash, " + algorithm + ")", variables));}
0
public void callingHashFunctionsWithVariablesAsInputHashesSuccessfully() throws Exception
{    final String algorithm = "md5";    final String valueToHash = "'My value to hash'";    final Serializable input = (Serializable) Collections.singletonList(valueToHash);    final MessageDigest expected = MessageDigest.getInstance(algorithm);    expected.update(SerializationUtils.serialize(input));    final Map<String, Object> variables = new HashMap<>();    variables.put("toHash", input);    variables.put("hashType", algorithm);    assertEquals(expectedHexString(expected), run("HASH(toHash, hashType)", variables));}
0
public void callingHashFunctionWhereOnlyHashTypeIsAVariableHashesSuccessfully() throws Exception
{    final String algorithm = "md5";    final String valueToHash = "'My value to hash'";    final MessageDigest expected = MessageDigest.getInstance(algorithm);    expected.update(valueToHash.replace("'", "").getBytes(StandardCharsets.UTF_8));    final Map<String, Object> variables = new HashMap<>();    variables.put("hashType", algorithm);    assertEquals(expectedHexString(expected), run("HASH(" + valueToHash + ", hashType)", variables));}
0
public void aNonNullNonSerializableObjectReturnsAValueOfNull() throws Exception
{    final Map<String, Object> variables = new HashMap<>();    variables.put("toHash", new Object());    assertNull(run("HASH(toHash, 'md5')", variables));}
0
public void tlsh_happyPath() throws Exception
{    final Map<String, Object> variables = new HashMap<>();    variables.put("toHash", TLSH_DATA);    variables.put("toHashBytes", TLSH_DATA.getBytes(StandardCharsets.UTF_8));        assertEquals(TLSH_EXPECTED, run("HASH(toHash, 'tlsh')", variables));    assertEquals(TLSH_EXPECTED, run("HASH(toHash, 'TLSH')", variables));    assertEquals(TLSH_EXPECTED, run("HASH(toHashBytes, 'tlsh')", variables));}
0
public void tlsh_multiBin() throws Exception
{    final Map<String, Object> variables = new HashMap<>();    variables.put("toHash", TLSH_DATA);    Map<String, String> out = (Map<String, String>) run("HASH(toHash, 'tlsh', { 'hashes' : [ 8, 16, 32 ]} )", variables);    Assert.assertTrue(out.containsKey(TLSHHasher.TLSH_KEY));    for (int h : ImmutableList.of(8, 16, 32)) {        Assert.assertTrue(out.containsKey(TLSHHasher.TLSH_BIN_KEY + "_" + h));    }}
0
public void tlsh_multithread() throws Exception
{            Map<Map.Entry<byte[], Map<String, Object>>, String> hashes = new HashMap<>();    Random r = new Random(0);    for (int i = 0; i < 20; ++i) {        byte[] d = new byte[256];        r.nextBytes(d);        Map<String, Object> config = new HashMap<String, Object>() {            {                put(TLSHHasher.Config.BUCKET_SIZE.key, r.nextBoolean() ? 128 : 256);                put(TLSHHasher.Config.CHECKSUM.key, r.nextBoolean() ? 1 : 3);            }        };        String hash = (String) run("HASH(data, 'tlsh', config)", ImmutableMap.of("config", config, "data", d));        Assert.assertNotNull(hash);        hashes.put(new AbstractMap.SimpleEntry<>(d, config), hash);    }    ForkJoinPool forkJoinPool = new ForkJoinPool(5);    forkJoinPool.submit(() -> hashes.entrySet().parallelStream().forEach(kv -> {        Map<String, Object> config = kv.getKey().getValue();        byte[] data = kv.getKey().getKey();        String hash = (String) run("HASH(data, 'tlsh', config)", ImmutableMap.of("config", config, "data", data));        Assert.assertEquals(hash, kv.getValue());    }));}
0
public void tlsh_similarity() throws Exception
{    for (Map.Entry<String, String> kv : ImmutableMap.of("been", "ben", "document", "dokumant", "code", "cad").entrySet()) {        Map<String, Object> variables = ImmutableMap.of("toHash", TLSH_DATA, "toHashSimilar", TLSH_DATA.replace(kv.getKey(), kv.getValue()));        Map<String, Object> bin1 = (Map<String, Object>) run("HASH(toHashSimilar, 'tlsh', { 'hashes' : 4, 'bucketSize' : 128 })", variables);        Map<String, Object> bin2 = (Map<String, Object>) run("HASH(toHash, 'tlsh', { 'hashes' : [ 4 ], 'bucketSize' : 128 })", variables);        assertEquals(kv.getKey() + " != " + kv.getValue() + " because " + bin1.get("tlsh") + " != " + bin2.get("tlsh"), bin1.get("tlsh_bin"), bin2.get("tlsh_bin"));        assertNotEquals(bin1.get("tlsh"), bin2.get("tlsh"));        Map<String, Object> distVariables = ImmutableMap.of("hash1", bin1.get(TLSHHasher.TLSH_KEY), "hash2", bin2.get(TLSHHasher.TLSH_KEY));        {                        Integer diff = (Integer) run("TLSH_DIST( hash1, hash2)", distVariables);            Integer diffReflexive = (Integer) run("TLSH_DIST( hash2, hash1)", distVariables);            Assert.assertTrue("diff == " + diff, diff < 100);            Assert.assertEquals(diff, diffReflexive);        }        {                        Integer diff = (Integer) run("TLSH_DIST( hash1, hash1)", distVariables);            Assert.assertEquals((int) 0, (int) diff);        }    }}
0
public void tlshDist_invalidInput() throws Exception
{    final Map<String, Object> variables = new HashMap<>();    variables.put("hash1", 1);    variables.put("hash2", TLSH_EXPECTED);    run("TLSH_DIST( hash1, hash1)", variables);}
0
public void tlsh_insufficientComplexity() throws Exception
{    final Map<String, Object> variables = new HashMap<>();    String data = "Metron is the best";    variables.put("toHash", data);    assertNull(run("HASH(toHash, 'tlsh')", variables));}
0
public void tlsh_nullInput() throws Exception
{    final Map<String, Object> variables = new HashMap<>();    String data = null;    variables.put("toHash", data);    assertNull(run("HASH(toHash, 'tlsh')", variables));}
0
private String expectedHexString(MessageDigest expected)
{    return new String(HEX.encode(expected.digest()), StandardCharsets.UTF_8);}
0
public void testMissingVariableFalsey()
{    Assert.assertTrue(runPredicate("match{NOT(is_alert) => true, foo > 5 => false, foo > 10 => false, default => false}", new HashMap() {        {            put("foo", 100);        }    }));    Assert.assertFalse(runPredicate("match{is_alert => true, foo > 5 => false, foo > 10 => false, default => false}", new HashMap() {        {            put("foo", 100);        }    }));    Assert.assertFalse(runPredicate("match{foo > 5 => false, is_alert => true, foo > 10 => false, default => false}", new HashMap() {        {            put("foo", 100);        }    }));}
0
public void testEmptyListFalsey()
{    Assert.assertTrue(runPredicate("match{NOT([]) => true, foo > 5 => false, foo > 10 => false, default => false}", new HashMap() {        {            put("foo", 100);        }    }));    Assert.assertFalse(runPredicate("match{[] => true, foo > 5 => false, foo > 10 => false, default => false}", new HashMap() {        {            put("foo", 100);        }    }));}
0
public void testThreeTrueClausesFirstOnlyFires()
{    Assert.assertTrue(runPredicate("match{foo > 0 => true, foo > 5 => false, foo > 10 => false, default => false}", new HashMap() {        {            put("foo", 100);        }    }));}
0
public void testTwoClausesSecondFires()
{    Assert.assertTrue(runPredicate("match{foo < 0 => false, foo < 500 => true, default => false}", new HashMap() {        {            put("foo", 100);        }    }));}
0
public void testThreeClausesFirstFires()
{    List<String> list = (List<String>) run("match{ foo > 100 => ['oops'], foo > 200 => ['oh no'], foo >= 500 => MAP(['ok', 'haha'], (a) -> TO_UPPER(a)), default => ['a']}", new HashMap() {        {            put("foo", 500);        }    });    Assert.assertTrue(list.size() == 1);    Assert.assertTrue(list.contains("oops"));}
0
public void testShortCircuitWithThrows()
{    Assert.assertEquals("ok", run("match{ foo > 100 => THROW('oops'), foo > 200 => THROW('oh no'), default => 'ok' }", new HashMap() {        {            put("foo", 50);        }    }));}
0
public void testMatchLambda()
{    Assert.assertTrue(runPredicate("match { 1 >= 0 => ()-> true, default => ()->false }", new HashMap() {        {            put("foo", 0);        }    }));    Assert.assertTrue(runPredicate("match { foo == 0 => ()-> true, default => ()-> false }", new HashMap() {        {            put("foo", 0);        }    }));    Assert.assertFalse(runPredicate("match { foo == 0 => ()-> true, default => ()-> false }", new HashMap() {        {            put("foo", 1);        }    }));    Assert.assertTrue(runPredicate("match { foo == 0 => ()-> false, foo == 1 => ()-> true, default => ()-> false }", new HashMap() {        {            put("foo", 1);        }    }));    Assert.assertTrue(runPredicate("match { foo == 0 => ()-> bFalse, foo == 1 => ()-> bTrue, default => ()-> bFalse }", new HashMap() {        {            put("foo", 1);            put("bFalse", false);            put("bTrue", true);        }    }));    Assert.assertTrue(runPredicate("match { foo == 0 => ()-> bFalse, foo == 1 => ()-> bTrue, default => ()-> bFalse }", new HashMap() {        {            put("foo", 1);            put("bFalse", false);            put("bTrue", true);        }    }));}
0
public void testMatchMAPEvaluation()
{    String expr = "match{ var1 =>  MAP(['foo', 'bar'], (x) -> TO_UPPER(x)), default => null }";    Object o = run(expr, ImmutableMap.of("foo", "foo", "bar", "bar", "var1", true));    Assert.assertTrue(o instanceof List);    List<String> result = (List<String>) o;    Assert.assertEquals(2, result.size());    Assert.assertEquals("FOO", result.get(0));    Assert.assertEquals("BAR", result.get(1));}
0
public void workingMatchWithMap()
{    Assert.assertEquals(Arrays.asList("OK", "HAHA"), run("match{ foo > 100 => THROW('oops'), foo > 200 => THROW('oh no'), foo >= 50 => MAP(['ok', 'haha'], (a) -> TO_UPPER(a)), default=> 'a' }", new HashMap() {        {            put("foo", 50);        }    }));}
0
public void testMapSmall()
{    List<String> ret = (List<String>) run("match{ foo < 100 => ['oops'], default => MAP(['ok', 'haha'], (a) -> TO_UPPER(a))}", new HashMap() {        {            put("foo", 500);        }    });    Assert.assertTrue(ret.size() == 2);    Assert.assertTrue(ret.contains("OK"));    Assert.assertTrue(ret.contains("HAHA"));}
0
public void testMultiClauseMap()
{    run("match{ foo < 100 => ['oops'], foo < 200 => ['oh no'], foo >= 500 => MAP(['ok', 'haha'], (a) -> TO_UPPER(a)), default => ['a']}", new HashMap() {        {            put("foo", 500);        }    });}
0
public void testMatchRegexMatch()
{    final Map<String, String> variables = new HashMap<String, String>() {        {            put("numbers", "12345");            put("numberPattern", "\\d(\\d)(\\d).*");            put("letters", "abcde");            put("empty", "");        }    };    Assert.assertTrue(runPredicate("match{ REGEXP_MATCH(numbers,numberPattern)=> true, default => false}", new DefaultVariableResolver(variables::get, variables::containsKey)));    Assert.assertFalse(runPredicate("match{ REGEXP_MATCH(letters,numberPattern) => true, default =>false}", new DefaultVariableResolver(variables::get, variables::containsKey)));}
0
public void testMatchBareStatements()
{    Assert.assertTrue(runPredicate("match { foo == 0 => bFalse, foo == 1 => bTrue, default => false }", new HashMap() {        {            put("foo", 1);            put("bFalse", false);            put("bTrue", true);        }    }));    Assert.assertEquals("warning", run("match{ threat.triage.level < 10 => 'info', threat.triage.level < 20 => 'warning', default => 'critical' }", new HashMap() {        {            put("threat.triage.level", 15);        }    }));}
0
public void testWithFunction()
{    Assert.assertEquals("WARNING", run("match{ threat.triage.level < 10 => 'info', threat.triage.level < 20 => TO_UPPER('warning'), default => 'critical' }", new HashMap() {        {            put("threat.triage.level", 15);        }    }));}
0
public void testWithFunctionMultiArgs()
{    Assert.assertEquals("false", run("match{ threat.triage.level < 10 => 'info', threat.triage.level < 20 => TO_STRING(IS_ENCODING(other,'BASE32')), default => 'critical' }", new HashMap() {        {            put("threat.triage.level", 15);            put("other", "value");        }    }));    Assert.assertEquals(false, run("match{ threat.triage.level < 10 => 'info', threat.triage.level < 20 => IS_ENCODING(other,'BASE32'), default => 'critical' }", new HashMap() {        {            put("threat.triage.level", 15);            put("other", "value");        }    }));}
0
public void testLogical()
{    Assert.assertTrue(runPredicate("match { foo == 0  OR bar == 'yes' => ()-> true, default => ()-> false }", new HashMap() {        {            put("foo", 1);            put("bar", "yes");        }    }));    Assert.assertTrue(runPredicate("match { foo == 0  AND bar == 'yes' => ()-> true, default => ()-> false }", new HashMap() {        {            put("foo", 0);            put("bar", "yes");        }    }));}
0
public void testTernaryFuncWithoutIfCheck()
{    Assert.assertEquals("a", run("match{ foo == 5 ? true : false => 'a', default => 'ok' }", new HashMap() {        {            put("foo", 5);        }    }));}
0
public void testTernaryFuncAsMatchAction()
{    Assert.assertEquals(false, run("match{ threat.triage.level < 10 => 'info', threat.triage.level < 20 => IS_ENCODING(other,'BASE32')? true : false, default => 'critical' }", new HashMap() {        {            put("threat.triage.level", 15);            put("other", "value");        }    }));}
0
public void testVariableIFCheck()
{    Assert.assertEquals("a", run("match{ IF foo == 5 THEN true ELSE false => 'a', default => 'ok' }", new HashMap() {        {            put("foo", 5);        }    }));}
0
public void testIfThenElseAction()
{    Assert.assertEquals(2, run("match{ foo == true => IF bar THEN 1 ELSE 2, default => 0}", new HashMap() {        {            put("foo", true);            put("bar", false);        }    }));}
0
public void testVariableOnly()
{    Assert.assertEquals("a", run("match{ foo => 'a', default => null}", new HashMap() {        {            put("foo", true);        }    }));}
0
public void testVariableEqualsCheck()
{    Assert.assertEquals("a", run("match{ foo == 5 => 'a', default => 'ok' }", new HashMap() {        {            put("foo", 5);        }    }));}
0
public void testVariableOnlyCheckWithDefault()
{    Assert.assertEquals("a", run("match{ foo => 'a', default => 'b' }", new HashMap() {        {            put("foo", true);        }    }));}
0
public void testHandleVariableEqualsCheckWithDefault()
{    Assert.assertEquals("a", run("match{ foo == true => 'a', default=> 'b' }", new HashMap() {        {            put("foo", true);        }    }));}
0
public void testNullInCheckedReturnNull()
{    Assert.assertNull(run("match{ foo == null => null, foo == true => 'not that null', default => 'really not that null'}", new HashMap() {        {            put("foo", null);        }    }));}
0
public void testMatchErrorNoDefault()
{    run("match{ foo > 100 => 'greater than 100', foo > 200 => 'greater than 200' }", new HashMap() {        {            put("foo", 50);        }    });}
0
public void testNestedMatchNotSupportted()
{        Assert.assertEquals(false, run("match{  x == 0 => match{ y == 10 => false, default => true}, default => true}", new HashMap() {        {            put("x", 0);            put("y", 10);        }    }));}
0
public void testReturnList()
{    Object o = run("match{ foo > 100 => ['oops'],default => ['a']}", new HashMap() {        {            put("foo", 500);        }    });    List l = (List) o;    Assert.assertTrue(l.size() == 1);}
0
public static Object run(String rule, Map<String, Object> variables)
{    Context context = Context.EMPTY_CONTEXT();    StellarProcessor processor = new StellarProcessor();    Assert.assertTrue(rule + " not valid.", processor.validate(rule, context));    return processor.parse(rule, new DefaultVariableResolver(v -> variables.get(v), v -> variables.containsKey(v)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void testAbs()
{    assertValues("ABS", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 0d);            put(10.5d, 10.5d);            put(-10.5d, 10.5d);        }    });}
0
public void testSqrt()
{    assertValues("SQRT", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 0d);            put(25d, 5d);            put(-10.5d, Double.NaN);        }    });}
0
public void testCeiling()
{    assertValues("CEILING", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 0d);            put(10.5d, 11d);            put(-10.5d, -10d);        }    });}
0
public void testFloor()
{    assertValues("FLOOR", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 0d);            put(10.5d, 10d);            put(-10.5d, -11d);        }    });}
0
public void testSin()
{    assertValues("SIN", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 0d);            put(Math.PI / 6, 0.5);            put(Math.PI / 4, Math.sqrt(2) / 2.0);            put(Math.PI / 3, Math.sqrt(3) / 2.0);            put(Math.PI / 2, 1d);        }    });}
0
public void testCos()
{    assertValues("COS", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 1d);            put(Math.PI / 6, Math.sqrt(3) / 2.0);            put(Math.PI / 4, Math.sqrt(2) / 2.0);            put(Math.PI / 3, 0.5d);            put(Math.PI / 2, 0d);        }    });}
0
public void testTan()
{    assertValues("TAN", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 0d);            put(Math.PI / 6, Math.sqrt(3) / 3.0);            put(Math.PI / 4, 1d);            put(Math.PI / 3, Math.sqrt(3));            put(Math.PI / 2, Math.sin(Math.PI / 2) / Math.cos(Math.PI / 2));        }    });}
0
public void testExp()
{    assertValues("EXP", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 1d);            put(0.5d, Math.sqrt(Math.E));            put(-0.5d, 1 / Math.sqrt(Math.E));            put(1d, Math.E);            put(2d, Math.E * Math.E);        }    });}
0
public void testRound()
{    assertValues("ROUND", new HashMap<Double, Double>(baseExpectations) {        {            put(0d, 0d);            put(0.5d, 1d);            put(0.4d, 0d);            put(-0.5d, 0d);        }    });}
0
public void testNaturalLog()
{    testLog("LN", Math.E);}
0
public void testLog2()
{    testLog("LOG2", 2);}
0
public void testLog10()
{    testLog("LOG10", 10);}
0
public void testIsNaN()
{    Assert.assertTrue(runPredicate("IS_NAN(NaN)", new HashMap<>()));    Assert.assertFalse(runPredicate("IS_NAN(1.0)", new HashMap<>()));    Assert.assertTrue(runPredicate("IS_NAN(0.0/0.0)", new HashMap<>()));}
0
public void testIsNanWithNotNumberType()
{    runPredicate("IS_NAN('casey')", new HashMap<>());}
0
public void testIsNanWithNoArgs()
{    runPredicate("IS_NAN()", new HashMap<>());}
0
public void assertValues(String func, Map<Double, Double> expected)
{    for (Map.Entry<Double, Double> test : expected.entrySet()) {        for (String expr : ImmutableList.of(func + "(value)", func + "(" + test.getKey() + ")")) {            if (Double.isNaN(test.getValue())) {                Assert.assertTrue(expr + " != NaN, where value == " + test.getKey(), Double.isNaN(toDouble(run(expr, ImmutableMap.of("value", test.getKey())))));            } else {                Assert.assertEquals(expr + " != " + test.getValue() + " (where value == " + test.getKey() + ")", test.getValue(), toDouble(run(expr, ImmutableMap.of("value", test.getKey()))), EPSILON);            }        }    }}
0
public Double toDouble(Object n)
{    return ((Number) n).doubleValue();}
0
public void testLog(String logExpr, double base)
{    Map<Double, Double> expectedValues = new HashMap<Double, Double>(baseExpectations) {        {            put(base, 1d);            put(0d, Double.NEGATIVE_INFINITY);        }    };    for (int i = 1; i <= 10; ++i) {        expectedValues.put(Math.pow(base, i), (double) i);    }    assertValues(logExpr, expectedValues);}
0
public void setup() throws Exception
{    context = new Context.Builder().build();}
0
public void testMaxOfMixedNumerical() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(12L);            add(56.0);            add(56.3);        }    };    Object res = run("MAX(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNotNull(res);    Assert.assertEquals(56.3, res);}
0
public void testMinOfMixedNumerical() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(12L);            add(56.0);            add(457L);        }    };    Object res = run("MIN(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNotNull(res);    Assert.assertEquals(res, 12L);}
0
public void testMaxOfStringList() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add("value3");            add("value1");            add("23");            add("value2");        }    };    Object res = run("MAX(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals("value3"));}
0
public void testMaxOfIntegerList() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(12);            add(56);        }    };    Object res = run("MAX(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals(56));}
0
public void testMaxWithVarList() throws Exception
{    Object res = run("MAX([string1,string2])", ImmutableMap.of("string1", "abc", "string2", "def"));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals("def"));}
0
public void testMinWithNullInList() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(145);            add(null);        }    };    Object res = run("MIN(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals(145));}
0
public void testAllNullList() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(null);            add(null);        }    };    Object res = run("MAX(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNull(res);}
0
public void testMinOfIntegerList() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(56);            add(12);            add(23);            add(null);        }    };    Object res = run("MIN(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals(12));}
0
public void testMaxOfLongList() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(12L);            add(56L);            add(457L);        }    };    Object res = run("MAX(input_list)", ImmutableMap.of("input_list", inputList));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals(457L));}
0
public void testMaxOfMixedList() throws Exception
{    List<Object> inputList = new ArrayList<Object>() {        {            add(12);            add("string");            add(457L);        }    };    Object res = null;    try {        res = run("MAX(input_list)", ImmutableMap.of("input_list", inputList));    } catch (ParseException e) {        Assert.assertTrue(e.getMessage().contains("Incomparable objects were submitted to MAX: class java.lang.String is incomparable to class java.lang.Long"));        Assert.assertNull(res);    }}
0
public void testSetInput() throws Exception
{    Set<Object> inputSet = new HashSet<Object>() {        {            add(14L);            add(15.3d);            add(15);        }    };    Object res = run("MAX(input_set)", ImmutableMap.of("input_set", inputSet));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals(15.3d));}
0
public void testNonComparableList() throws Exception
{    class TestObject {        private String arg;        public TestObject(String arg) {            this.arg = arg;        }    }    List<Object> inputList = new ArrayList<Object>() {        {            add(new TestObject("one"));            add(new TestObject("two"));            add(new TestObject("three"));        }    };    Object res = null;    try {        res = run("MIN(input_list)", ImmutableMap.of("input_list", inputList));    } catch (ParseException e) {        Assert.assertTrue(e.getMessage().contains("Noncomparable object type org.apache.metron.stellar.dsl.functions.OrdinalFunctionsTest$1TestObject submitted to MIN"));        Assert.assertNull(res);    }}
0
public void testMaxOfStats() throws Exception
{    Ordinal provider = new Ordinal() {        @Override        public double getMin() {            return 10;        }        @Override        public double getMax() {            return 100;        }    };    Object res = run("MAX(input_list)", ImmutableMap.of("input_list", provider));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals(100.0d));}
0
public double getMin()
{    return 10;}
0
public double getMax()
{    return 100;}
0
public void testMinOfStats() throws Exception
{    Ordinal provider = new Ordinal() {        @Override        public double getMin() {            return 10;        }        @Override        public double getMax() {            return 100;        }    };    Object res = run("MIN(input_list)", ImmutableMap.of("input_list", provider));    Assert.assertNotNull(res);    Assert.assertTrue(res.equals(10.0d));}
0
public double getMin()
{    return 10;}
0
public double getMax()
{    return 100;}
0
public Object run(String rule, Map<String, Object> variables) throws Exception
{    StellarProcessor processor = new StellarProcessor();    return processor.parse(rule, new DefaultVariableResolver(x -> variables.get(x), x -> variables.containsKey(x)), StellarFunctions.FUNCTION_RESOLVER(), context);}
0
public void testRegExMatch() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("numbers", "12345");            put("numberPattern", "\\d(\\d)(\\d).*");            put("letters", "abcde");            put("letterPattern", "[a-zA-Z]+");            put("empty", "");        }    };    Assert.assertTrue(runPredicate("REGEXP_MATCH(numbers,numberPattern)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("REGEXP_MATCH(letters,numberPattern)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_MATCH(letters,[numberPattern,letterPattern])", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("REGEXP_MATCH(letters,[numberPattern])", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("REGEXP_MATCH(letters,[numberPattern,numberPattern])", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("REGEXP_MATCH(null,[numberPattern])", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("REGEXP_MATCH(letters,null)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("REGEXP_MATCH(letters,[null])", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testRegExGroupVal() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("numbers", "12345");            put("numberPattern", "\\d(\\d)(\\d).*");            put("numberPatternNoCaptures", "\\d\\d\\d.*");            put("letters", "abcde");            put("empty", "");        }    };    Assert.assertTrue(runPredicate("REGEXP_GROUP_VAL(numbers,numberPattern,2) == '3'", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_GROUP_VAL(letters,numberPattern,2) == null", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_GROUP_VAL(empty,numberPattern,2) == null", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_GROUP_VAL(numbers,numberPatternNoCaptures,2) == null", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    boolean thrown = false;    try {        runPredicate("REGEXP_GROUP_VAL(2) == null", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v)));    } catch (ParseException | IllegalStateException ise) {        thrown = true;    }    if (!thrown) {        Assert.assertTrue("Did not fail on wrong number of parameters", false);    }}
0
public void testRegExReplace() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("numbers", "12345");            put("numberPattern", "\\d(\\d)(\\d).*");            put("letters", "abcde");            put("empty", "");        }    };    Assert.assertTrue(runPredicate("REGEXP_REPLACE(empty, numberPattern, letters) == null", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_REPLACE(numbers, empty, empty) == numbers", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_REPLACE(numbers, empty, letters) == numbers", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_REPLACE(numbers, numberPattern, empty) == numbers", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_REPLACE(numbers, numberPattern, letters) == letters", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("REGEXP_REPLACE(letters, numberPattern, numbers) == letters", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public Set<Class<? extends StellarFunction>> resolvables()
{    return classesToResolve;}
0
public TestResolver withClass(Class<? extends StellarFunction> clazz)
{    this.classesToResolve.add(clazz);    return this;}
0
public Object apply(List<Object> args)
{    return null;}
0
public void close() throws IOException
{    closeCallCount++;    if (throwException) {        Throwable cause = new Throwable("Some nasty nasty cause.");        throw new IOException("Bad things happened", cause);    }}
0
public Object apply(List<Object> args)
{    return null;}
0
public void close() throws IOException
{    closeCallCount++;    if (throwException) {        throw new NullPointerException("A most annoying exception.");    }}
0
public void setup()
{    resolver = new TestResolver();    IAmAFunction.throwException = false;    IAmAnotherFunction.throwException = false;}
0
public void close_calls_all_loaded_function_close_methods() throws IOException
{    resolver.withClass(IAmAFunction.class);    resolver.withClass(IAmAnotherFunction.class);    resolver.close();    assertThat(IAmAFunction.closeCallCount, equalTo(1));    assertThat(IAmAnotherFunction.closeCallCount, equalTo(1));}
0
public void close_collects_all_exceptions_thrown_on_loaded_function_close_methods() throws IOException
{    IAmAFunction.throwException = true;    IAmAnotherFunction.throwException = true;    resolver.withClass(IAmAFunction.class);    resolver.withClass(IAmAnotherFunction.class);    exception.expect(IOException.class);    resolver.close();}
0
public void close_only_throws_exceptions_on_first_invocation() throws IOException
{    IAmAFunction.throwException = true;    IAmAnotherFunction.throwException = true;    resolver.withClass(IAmAFunction.class);    resolver.withClass(IAmAnotherFunction.class);    try {        resolver.close();        Assert.fail("Should have thrown an exception.");    } catch (IOException e) {        }    assertThat(IAmAFunction.closeCallCount, equalTo(1));    assertThat(IAmAnotherFunction.closeCallCount, equalTo(1));        resolver.close();    resolver.close();    resolver.close();    assertThat(IAmAFunction.closeCallCount, equalTo(1));    assertThat(IAmAnotherFunction.closeCallCount, equalTo(1));}
0
public static void setup()
{        Properties config = new Properties();        ClasspathFunctionResolver resolver = create(config);    expectedFunctions = Lists.newArrayList(resolver.getFunctions());}
0
public static ClasspathFunctionResolver create(Properties config)
{    ClasspathFunctionResolver resolver = new ClasspathFunctionResolver();    Context context = new Context.Builder().with(Context.Capabilities.STELLAR_CONFIG, () -> config).build();    resolver.initialize(context);    return resolver;}
0
public void testInclude()
{        Properties config = new Properties();    config.put(STELLAR_SEARCH_INCLUDES_KEY.param(), "org.apache.metron.*");        ClasspathFunctionResolver resolver = create(config);    List<String> actual = Lists.newArrayList(resolver.getFunctions());        Assert.assertEquals(expectedFunctions, actual);}
0
public void testWithMultipleIncludes()
{        Properties config = new Properties();    config.put(STELLAR_SEARCH_INCLUDES_KEY.param(), "org.apache.metron.common.*, org.apache.metron.management.*");        ClasspathFunctionResolver resolver = create(config);    List<String> actual = Lists.newArrayList(resolver.getFunctions());        Assert.assertTrue(actual.size() > 0);    Assert.assertTrue(actual.size() <= expectedFunctions.size());}
0
public void testExclude()
{        Properties config = new Properties();    config.put(STELLAR_SEARCH_EXCLUDES_KEY.param(), "org.apache.metron.*");        ClasspathFunctionResolver resolver = create(config);    List<String> actual = Lists.newArrayList(resolver.getFunctions());        Assert.assertEquals(0, actual.size());}
0
public void testExternalLocal() throws FileSystemException, ClassNotFoundException
{    File jar = new File("src/test/classpath-resources");    Assert.assertTrue(jar.exists());    Properties config = new Properties();    config.put(STELLAR_VFS_PATHS.param(), jar.toURI() + "/.*.jar");    ClasspathFunctionResolver resolver = create(config);    HashSet<String> functions = new HashSet<>(Lists.newArrayList(resolver.getFunctions()));    Assert.assertTrue(functions.contains("NOW"));}
0
public void testInvalidStellarClass() throws Exception
{    StellarFunction goodFunc = mock(StellarFunction.class);    StellarFunction badFunc = mock(StellarFunction.class);    ClasspathFunctionResolver resolver = new ClasspathFunctionResolver() {        @Override        protected Iterable<Class<?>> getStellarClasses(ClassLoader cl) {            return ImmutableList.of(goodFunc.getClass(), badFunc.getClass());        }        @Override        protected boolean includeClass(Class<?> c, FilterBuilder filterBuilder) {            if (c != goodFunc.getClass()) {                throw new LinkageError("failed!");            }            return true;        }    };    Set<Class<? extends StellarFunction>> funcs = resolver.resolvables();    Assert.assertEquals(1, funcs.size());    Assert.assertEquals(goodFunc.getClass(), Iterables.getFirst(funcs, null));}
0
protected Iterable<Class<?>> getStellarClasses(ClassLoader cl)
{    return ImmutableList.of(goodFunc.getClass(), badFunc.getClass());}
0
protected boolean includeClass(Class<?> c, FilterBuilder filterBuilder)
{    if (c != goodFunc.getClass()) {        throw new LinkageError("failed!");    }    return true;}
0
public void setup()
{    resolver = new SimpleFunctionResolver();}
0
public void testFunctionResolution()
{    resolver.withClass(IAmAFunction.class);    List<String> functions = Lists.newArrayList(resolver.getFunctions());    Assert.assertEquals(1, functions.size());    Assert.assertTrue(functions.contains("namespace_function"));}
0
public void testApply()
{    resolver.withClass(IAmAFunction.class);    final String functionName = "namespace_function";    StellarFunction fn = resolver.apply(functionName);    Assert.assertTrue(fn instanceof IAmAFunction);}
0
public void testFunctionResolutionWithMissingAnnotation()
{    resolver.withClass(MissingAnnotation.class);    List<String> functions = Lists.newArrayList(resolver.getFunctions());    Assert.assertEquals(0, functions.size());}
0
public void testIgnoreDuplicates()
{    resolver.withClass(IAmAFunction.class);    resolver.withClass(IAmAFunction.class);    List<String> functions = Lists.newArrayList(resolver.getFunctions());    Assert.assertEquals(1, functions.size());}
0
public Object apply(List<Object> args)
{    return null;}
0
public Object apply(List<Object> args, Context context) throws ParseException
{    return null;}
0
public void initialize(Context context)
{}
0
public boolean isInitialized()
{    return false;}
0
public void setup() throws Exception
{    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, HashMap::new).build();        basicAuthPasswordFile = tempDir.newFile("basicAuth.txt");    FileUtils.writeStringToFile(basicAuthPasswordFile, basicAuthPassword, StandardCharsets.UTF_8);    proxyBasicAuthPasswordFile = tempDir.newFile("proxyBasicAuth.txt");    FileUtils.writeStringToFile(proxyBasicAuthPasswordFile, proxyAuthPassword, StandardCharsets.UTF_8);        baseUri = String.format("http://localhost:%d", mockServerRule.getPort());    getUri = baseUri + "/get";    emptyGetUri = baseUri + "/get/empty";    postUri = baseUri + "/post";    emptyPostUri = baseUri + "/post/empty";    mockServerClient.when(request().withMethod("GET").withPath("/get")).respond(response().withBody("{\"get\":\"success\"}"));    mockServerClient.when(request().withMethod("GET").withPath("/get/empty")).respond(response().withStatusCode(404));    mockServerClient.when(request().withMethod("POST").withPath("/post").withBody("{\"key\":\"value\"}")).respond(response().withBody("{\"post\":\"success\"}"));    mockServerClient.when(request().withMethod("POST").withPath("/post/empty")).respond(response().withStatusCode(404));}
0
public void restGetShouldSucceed() throws Exception
{    Map<String, Object> actual = (Map<String, Object>) run(String.format("REST_GET('%s')", getUri), context);    assertEquals(1, actual.size());    assertEquals("success", actual.get("get"));}
0
public void restGetShouldSucceedWithQueryParameters() throws Exception
{    mockServerClient.when(request().withMethod("GET").withPath("/get/with/query/parameters").withQueryStringParameter("key", "value")).respond(response().withBody("{\"get.with.query.parameters\":\"success\"}"));    Map<String, Object> variables = ImmutableMap.of("queryParameters", ImmutableMap.of("key", "value"));    Map<String, Object> actual = (Map<String, Object>) run(String.format("REST_GET('%s', {}, queryParameters)", baseUri + "/get/with/query/parameters"), variables, context);    assertEquals(1, actual.size());    assertEquals("success", actual.get("get.with.query.parameters"));}
0
public void restGetShouldSucceedWithProxy()
{    mockServerClient.when(request().withMethod("GET").withPath("/get")).respond(response().withBody("{\"proxyGet\":\"success\"}"));    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> new HashMap<String, Object>() {        {            put(PROXY_HOST, "localhost");            put(PROXY_PORT, proxyRule.getHttpPort());        }    });    Map<String, Object> actual = (Map<String, Object>) run(String.format("REST_GET('%s')", getUri), context);    assertEquals(1, actual.size());    assertEquals("success", actual.get("proxyGet"));}
0
public void restGetShouldHandleErrorStatusCode()
{    mockServerClient.when(request().withMethod("GET").withPath("/get")).respond(response().withStatusCode(403));    assertNull(run(String.format("REST_GET('%s')", getUri), context));}
0
public void restGetShouldReturnEmptyContentOverride()
{    assertEquals("function config override", run(String.format("REST_GET('%s', %s)", emptyGetUri, emptyContentOverride), context));}
0
public void restGetShouldReturnErrorValueOverride()
{    mockServerClient.when(request().withMethod("GET").withPath("/get")).respond(response().withStatusCode(500));    Object result = run(String.format("REST_GET('%s', %s)", getUri, errorValueOverride), context);    assertEquals("error message", result);}
0
public void restGetShouldTimeout()
{    String uri = String.format("http://localhost:%d/get", mockServerRule.getPort());    mockServerClient.when(request().withMethod("GET").withPath("/get")).respond(response().withDelay(TimeUnit.MILLISECONDS, 1000).withBody("{\"get\":\"success\"}"));    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(STELLAR_REST_SETTINGS, new HashMap<String, Object>() {                {                    put(TIMEOUT, 10);                }            });        }    };    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    Map<String, Object> actual = (Map<String, Object>) run(String.format("REST_GET('%s')", uri), context);    assertNull(actual);}
0
public void restGetShouldTimeoutWithSuppliedTimeout()
{    String uri = String.format("http://localhost:%d/get", mockServerRule.getPort());    mockServerClient.when(request().withMethod("GET").withPath("/get")).respond(response().withDelay(TimeUnit.MILLISECONDS, 1000).withBody("{\"get\":\"success\"}"));    String expression = String.format("REST_GET('%s', %s)", uri, timeoutConfig);    Map<String, Object> actual = (Map<String, Object>) run(expression, context);    assertNull(actual);}
0
public void restGetShouldHandleURISyntaxException() throws IllegalArgumentException, IOException
{    thrown.expect(ParseException.class);    thrown.expectMessage("Unable to parse REST_GET('some invalid uri'): Unable to parse: REST_GET('some invalid uri') due to: Illegal character in path at index 4: some invalid uri");    run("REST_GET('some invalid uri')", context);}
0
public void restGetShouldThrownExceptionOnMissingParameter()
{    thrown.expect(ParseException.class);    thrown.expectMessage("Unable to parse REST_GET(): Unable to parse: REST_GET() due to: Expected at least 1 argument(s), found 0");    run("REST_GET()", context);}
0
public void restGetShouldUseGlobalConfig()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(STELLAR_REST_SETTINGS, new HashMap<String, Object>() {                {                    put(RESPONSE_CODES_ALLOWED, Arrays.asList(200, 404));                    put(EMPTY_CONTENT_OVERRIDE, "global config override");                }            });        }    };    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    assertEquals("global config override", run(String.format("REST_GET('%s')", emptyGetUri), context));}
0
public void restGetShouldUseGetConfig()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(STELLAR_REST_SETTINGS, new HashMap<String, Object>() {                {                    put(RESPONSE_CODES_ALLOWED, Arrays.asList(200, 404));                    put(EMPTY_CONTENT_OVERRIDE, "global config override");                }            });            put(STELLAR_REST_GET_SETTINGS, new HashMap<String, Object>() {                {                    put(EMPTY_CONTENT_OVERRIDE, "get config override");                }            });        }    };    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    assertEquals("get config override", run(String.format("REST_GET('%s')", emptyGetUri), context));}
0
public void restGetShouldUseFunctionConfig()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(STELLAR_REST_SETTINGS, new HashMap<String, Object>() {                {                    put(RESPONSE_CODES_ALLOWED, Arrays.asList(200, 404));                    put(EMPTY_CONTENT_OVERRIDE, "global config override");                }            });            put(STELLAR_REST_GET_SETTINGS, new HashMap<String, Object>() {                {                    put(EMPTY_CONTENT_OVERRIDE, "get config override");                }            });        }    };    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    assertEquals("function config override", run(String.format("REST_GET('%s', %s)", emptyGetUri, emptyContentOverride), context));}
0
public void restPostShouldSucceed() throws Exception
{    Map<String, Object> actual = (Map<String, Object>) run(String.format("REST_POST('%s', '{\"key\":\"value\"}')", postUri), context);    assertEquals(1, actual.size());    assertEquals("success", actual.get("post"));}
0
public void restPostShouldSucceedWithQueryParameters() throws Exception
{    mockServerClient.when(request().withMethod("POST").withPath("/post/with/query/parameters").withQueryStringParameter("key", "value")).respond(response().withBody("{\"post.with.query.parameters\":\"success\"}"));    Map<String, Object> variables = ImmutableMap.of("queryParameters", ImmutableMap.of("key", "value"));    Map<String, Object> actual = (Map<String, Object>) run(String.format("REST_POST('%s', {}, {}, queryParameters)", baseUri + "/post/with/query/parameters"), variables, context);    assertEquals(1, actual.size());    assertEquals("success", actual.get("post.with.query.parameters"));}
0
public void restPostShouldSucceedWithStellarMap() throws Exception
{    Map<String, Object> variables = ImmutableMap.of("body", ImmutableMap.of("key", "value"));    Map<String, Object> actual = (Map<String, Object>) run(String.format("REST_POST('%s', body)", postUri), variables, context);    assertEquals(1, actual.size());    assertEquals("success", actual.get("post"));}
0
public void restPostShouldHandleURISyntaxException() throws IllegalArgumentException, IOException
{    thrown.expect(ParseException.class);    thrown.expectMessage("Unable to parse REST_POST('some invalid uri', {}): Unable to parse: REST_POST('some invalid uri', {}) due to: Illegal character in path at index 4: some invalid uri");    run("REST_POST('some invalid uri', {})", context);}
0
public void restPostShouldThrowExceptionOnMalformedJson() throws IllegalArgumentException, IOException
{    thrown.expect(ParseException.class);    thrown.expectMessage(String.format("Unable to parse: REST_POST('%s', 'malformed json') due to: POST data 'malformed json' must be properly formatted JSON.  " + "Set the 'enforce.json' property to false to disable this check.", postUri));    run(String.format("REST_POST('%s', 'malformed json')", postUri), context);}
0
public void restPostShouldUseGlobalConfig()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(STELLAR_REST_SETTINGS, new HashMap<String, Object>() {                {                    put(RESPONSE_CODES_ALLOWED, Arrays.asList(200, 404));                    put(EMPTY_CONTENT_OVERRIDE, "global config override");                }            });        }    };    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    assertEquals("global config override", run(String.format("REST_POST('%s', {})", emptyGetUri), context));}
0
public void restPostShouldUseGetConfig()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(STELLAR_REST_SETTINGS, new HashMap<String, Object>() {                {                    put(RESPONSE_CODES_ALLOWED, Arrays.asList(200, 404));                    put(EMPTY_CONTENT_OVERRIDE, "global config override");                }            });            put(STELLAR_REST_POST_SETTINGS, new HashMap<String, Object>() {                {                    put(EMPTY_CONTENT_OVERRIDE, "post config override");                }            });        }    };    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    assertEquals("post config override", run(String.format("REST_POST('%s', {})", emptyGetUri), context));}
0
public void restPostShouldUseFunctionConfig()
{    Map<String, Object> globalConfig = new HashMap<String, Object>() {        {            put(STELLAR_REST_SETTINGS, new HashMap<String, Object>() {                {                    put(RESPONSE_CODES_ALLOWED, Arrays.asList(200, 404));                    put(EMPTY_CONTENT_OVERRIDE, "global config override");                }            });            put(STELLAR_REST_POST_SETTINGS, new HashMap<String, Object>() {                {                    put(EMPTY_CONTENT_OVERRIDE, "post config override");                }            });        }    };    context.addCapability(Context.Capabilities.GLOBAL_CONFIG, () -> globalConfig);    assertEquals("function config override", run(String.format("REST_POST('%s', {}, %s)", emptyGetUri, emptyContentOverride), context));}
0
public void setup() throws Exception
{    context = new Context.Builder().with(Context.Capabilities.GLOBAL_CONFIG, HashMap::new).build();        basicAuthPasswordFile = tempDir.newFile("basicAuth.txt");    FileUtils.writeStringToFile(basicAuthPasswordFile, basicAuthPassword, StandardCharsets.UTF_8);    proxyBasicAuthPasswordFile = tempDir.newFile("proxyBasicAuth.txt");    FileUtils.writeStringToFile(proxyBasicAuthPasswordFile, proxyAuthPassword, StandardCharsets.UTF_8);}
0
public void restGetShouldGetProxy()
{    {        RestConfig restConfig = new RestConfig();        Optional<HttpHost> actual = RestFunctions.getProxy(restConfig);        assertEquals(Optional.empty(), actual);    }    {        RestConfig restConfig = new RestConfig();        restConfig.put(PROXY_HOST, "localhost");        Optional<HttpHost> actual = RestFunctions.getProxy(restConfig);        assertEquals(Optional.empty(), actual);    }    {        RestConfig restConfig = new RestConfig();        restConfig.put(PROXY_PORT, 3128);        Optional<HttpHost> actual = RestFunctions.getProxy(restConfig);        assertEquals(Optional.empty(), actual);    }    {        RestConfig restConfig = new RestConfig();        restConfig.put(PROXY_HOST, "localhost");        restConfig.put(PROXY_PORT, 3128);        Optional<HttpHost> actual = RestFunctions.getProxy(restConfig);        assertEquals(new HttpHost("localhost", 3128), actual.get());    }}
0
public void restShouldBuildRestConfig() throws Exception
{    Map<String, Object> config = new HashMap<String, Object>() {        {            put(BASIC_AUTH_USER, "user");            put(PROXY_BASIC_AUTH_USER, "proxyUser");        }    };    Map<String, Object> priorityConfig = new HashMap<String, Object>() {        {            put(BASIC_AUTH_USER, "priorityUser");        }    };    RestConfig restConfig = RestFunctions.buildRestConfig(config, priorityConfig);    assertEquals(6, restConfig.size());    assertEquals(Collections.singletonList(200), restConfig.getResponseCodesAllowed());    assertEquals("priorityUser", restConfig.getBasicAuthUser());    assertEquals("proxyUser", restConfig.getProxyBasicAuthUser());    assertTrue(restConfig.enforceJson());    assertEquals(1000, restConfig.getTimeout().intValue());    assertFalse(restConfig.verifyContentLength());}
0
public void restGetShouldGetRequestConfig()
{    {        RequestConfig actual = RestFunctions.getRequestConfig(new RestConfig(), Optional.empty());        RequestConfig expected = RequestConfig.custom().build();        assertEquals(expected.getConnectTimeout(), actual.getConnectTimeout());        assertEquals(expected.getConnectionRequestTimeout(), actual.getConnectionRequestTimeout());        assertEquals(expected.getSocketTimeout(), actual.getSocketTimeout());        assertEquals(expected.getProxy(), actual.getProxy());    }    {        RestConfig restConfig = new RestConfig();        restConfig.put(CONNECT_TIMEOUT, 1);        restConfig.put(CONNECTION_REQUEST_TIMEOUT, 2);        restConfig.put(SOCKET_TIMEOUT, 3);        HttpHost proxy = new HttpHost("localhost", 3128);        Optional<HttpHost> proxyOptional = Optional.of(proxy);        RequestConfig actual = RestFunctions.getRequestConfig(restConfig, proxyOptional);        RequestConfig expected = RequestConfig.custom().setConnectTimeout(1).setConnectionRequestTimeout(2).setSocketTimeout(3).setProxy(proxy).build();        assertEquals(expected.getConnectTimeout(), actual.getConnectTimeout());        assertEquals(expected.getConnectionRequestTimeout(), actual.getConnectionRequestTimeout());        assertEquals(expected.getSocketTimeout(), actual.getSocketTimeout());        assertEquals(expected.getProxy(), actual.getProxy());    }}
0
public void restGetShouldGetHttpClientContext() throws Exception
{    HttpHost target = new HttpHost("localhost", 8080);    HttpHost proxy = new HttpHost("localhost", 3128);    {        RestConfig restConfig = new RestConfig();        HttpClientContext actual = RestFunctions.getHttpClientContext(restConfig, target, Optional.empty());        assertNull(actual.getCredentialsProvider());    }    {        RestConfig restConfig = new RestConfig();        restConfig.put(BASIC_AUTH_USER, "user");        restConfig.put(BASIC_AUTH_PASSWORD_PATH, basicAuthPasswordFile.getAbsolutePath());        HttpClientContext actual = RestFunctions.getHttpClientContext(restConfig, target, Optional.empty());        HttpClientContext expected = HttpClientContext.create();        CredentialsProvider expectedCredentialsProvider = new BasicCredentialsProvider();        expectedCredentialsProvider.setCredentials(new AuthScope(target), new UsernamePasswordCredentials(restConfig.getBasicAuthUser(), basicAuthPassword));        expected.setCredentialsProvider(expectedCredentialsProvider);        assertEquals(expected.getCredentialsProvider().getCredentials(new AuthScope(target)), actual.getCredentialsProvider().getCredentials(new AuthScope(target)));        assertEquals(expected.getCredentialsProvider().getCredentials(new AuthScope(proxy)), actual.getCredentialsProvider().getCredentials(new AuthScope(proxy)));    }    {        RestConfig restConfig = new RestConfig();        restConfig.put(PROXY_BASIC_AUTH_USER, "proxyUser");        restConfig.put(PROXY_BASIC_AUTH_PASSWORD_PATH, proxyBasicAuthPasswordFile.getAbsolutePath());        HttpClientContext actual = RestFunctions.getHttpClientContext(restConfig, target, Optional.of(proxy));        HttpClientContext expected = HttpClientContext.create();        CredentialsProvider expectedCredentialsProvider = new BasicCredentialsProvider();        expectedCredentialsProvider.setCredentials(new AuthScope(proxy), new UsernamePasswordCredentials(restConfig.getProxyBasicAuthUser(), proxyAuthPassword));        expected.setCredentialsProvider(expectedCredentialsProvider);        assertEquals(expected.getCredentialsProvider().getCredentials(new AuthScope(target)), actual.getCredentialsProvider().getCredentials(new AuthScope(target)));        assertEquals(expected.getCredentialsProvider().getCredentials(new AuthScope(proxy)), actual.getCredentialsProvider().getCredentials(new AuthScope(proxy)));    }    {        RestConfig restConfig = new RestConfig();        restConfig.put(BASIC_AUTH_USER, "user");        restConfig.put(BASIC_AUTH_PASSWORD_PATH, basicAuthPasswordFile.getAbsolutePath());        restConfig.put(PROXY_BASIC_AUTH_USER, "proxyUser");        restConfig.put(PROXY_BASIC_AUTH_PASSWORD_PATH, proxyBasicAuthPasswordFile.getAbsolutePath());        HttpClientContext actual = RestFunctions.getHttpClientContext(restConfig, target, Optional.of(proxy));        HttpClientContext expected = HttpClientContext.create();        CredentialsProvider expectedCredentialsProvider = new BasicCredentialsProvider();        expectedCredentialsProvider.setCredentials(new AuthScope(target), new UsernamePasswordCredentials(restConfig.getBasicAuthUser(), basicAuthPassword));        expectedCredentialsProvider.setCredentials(new AuthScope(proxy), new UsernamePasswordCredentials(restConfig.getProxyBasicAuthUser(), proxyAuthPassword));        expected.setCredentialsProvider(expectedCredentialsProvider);        assertEquals(expected.getCredentialsProvider().getCredentials(new AuthScope(target)), actual.getCredentialsProvider().getCredentials(new AuthScope(target)));        assertEquals(expected.getCredentialsProvider().getCredentials(new AuthScope(proxy)), actual.getCredentialsProvider().getCredentials(new AuthScope(proxy)));    }}
0
public void restGetShouldHandleIOException() throws IllegalArgumentException, IOException
{    RestFunctions.RestGet restGet = new RestFunctions.RestGet();    CloseableHttpClient httpClient = mock(CloseableHttpClient.class);    ScheduledExecutorService executorService = mock(ScheduledExecutorService.class);    RestFunctions.setCloseableHttpClient(httpClient);    RestFunctions.setScheduledExecutorService(executorService);    when(httpClient.execute(any(HttpRequestBase.class), any(HttpClientContext.class))).thenThrow(new IOException("io exception"));    Object result = restGet.apply(Collections.singletonList("http://www.host.com:8080/some/uri"), context);    Assert.assertNull(result);}
0
public void restGetShouldGetPoolingConnectionManager()
{    RestConfig restConfig = new RestConfig();    restConfig.put(POOLING_MAX_TOTAL, 5);    restConfig.put(POOLING_DEFAULT_MAX_PER_RUOTE, 2);    PoolingHttpClientConnectionManager cm = RestFunctions.getConnectionManager(restConfig);    assertEquals(5, cm.getMaxTotal());    assertEquals(2, cm.getDefaultMaxPerRoute());}
0
public void restGetShouldClose() throws Exception
{    RestFunctions.RestGet restGet = new RestFunctions.RestGet();    CloseableHttpClient httpClient = mock(CloseableHttpClient.class);    ScheduledExecutorService executorService = mock(ScheduledExecutorService.class);    RestFunctions.setCloseableHttpClient(httpClient);    RestFunctions.setScheduledExecutorService(executorService);    restGet.close();    verify(httpClient, times(1)).close();    verify(executorService, times(1)).shutdown();    verifyNoMoreInteractions(httpClient);}
0
public void restPostShouldClose() throws Exception
{    RestFunctions.RestPost restPost = new RestFunctions.RestPost();    CloseableHttpClient httpClient = mock(CloseableHttpClient.class);    ScheduledExecutorService executorService = mock(ScheduledExecutorService.class);    RestFunctions.setCloseableHttpClient(httpClient);    RestFunctions.setScheduledExecutorService(executorService);    restPost.close();    verify(httpClient, times(1)).close();    verify(executorService, times(1)).shutdown();    verifyNoMoreInteractions(httpClient);}
0
public void restGetShouldParseResponse() throws Exception
{    RestConfig restConfig = new RestConfig();    HttpGet httpGet = mock(HttpGet.class);    HttpEntity httpEntity = mock(HttpEntity.class);        when(httpEntity.getContent()).thenReturn(new ByteArrayInputStream("{\"get\":\"success\"}".getBytes(StandardCharsets.UTF_8)));    Optional<Object> actual = RestFunctions.parseResponse(restConfig, httpGet, httpEntity);    assertTrue(actual.isPresent());    assertEquals("success", ((Map<String, Object>) actual.get()).get("get"));}
0
public void restGetShouldParseResponseOnNullHttpEntity() throws Exception
{    RestConfig restConfig = new RestConfig();    HttpGet httpGet = mock(HttpGet.class);        assertEquals(Optional.empty(), RestFunctions.parseResponse(restConfig, httpGet, null));}
0
public void restGetShouldParseResponseOnNullContent() throws Exception
{    RestConfig restConfig = new RestConfig();    HttpGet httpGet = mock(HttpGet.class);    HttpEntity httpEntity = mock(HttpEntity.class);        when(httpEntity.getContent()).thenReturn(null);    assertEquals(Optional.empty(), RestFunctions.parseResponse(restConfig, httpGet, httpEntity));}
0
public void restGetShouldParseResponseOnEmptyInputStream() throws Exception
{    RestConfig restConfig = new RestConfig();    HttpGet httpGet = mock(HttpGet.class);    HttpEntity httpEntity = mock(HttpEntity.class);        when(httpEntity.getContent()).thenReturn(new ByteArrayInputStream("".getBytes(StandardCharsets.UTF_8)));    assertEquals(Optional.empty(), RestFunctions.parseResponse(restConfig, httpGet, httpEntity));}
0
public void restGetShouldThrowExceptionOnContentLengthMismatch() throws Exception
{    thrown.expect(IOException.class);    thrown.expectMessage("Stellar REST request to uri returned incorrect or missing content length. Content length in the response was -1 but the actual body content length was 17.");    RestFunctions.RestGet restGet = new RestFunctions.RestGet();    RestConfig restConfig = new RestConfig();    HttpGet httpGet = mock(HttpGet.class);    HttpEntity httpEntity = mock(HttpEntity.class);    restConfig.put(VERIFY_CONTENT_LENGTH, true);    when(httpGet.getURI()).thenReturn(new URI("uri"));    when(httpEntity.getContent()).thenReturn(new ByteArrayInputStream("{\"get\":\"success\"}".getBytes(StandardCharsets.UTF_8)));    when(httpEntity.getContentLength()).thenReturn(-1L);    RestFunctions.parseResponse(restConfig, httpGet, httpEntity);}
0
public void multisetInitTest_wrongType() throws Exception
{    Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_INIT({ 'foo' : 'bar'})", new HashMap<>());}
0
public void multisetInitTest() throws Exception
{    {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_INIT()", new HashMap<>());        Assert.assertEquals(0, s.size());    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_INIT([1,2,3,2])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.containsKey(1));        Assert.assertEquals(1, (int) s.get(1));        Assert.assertTrue(s.containsKey(2));        Assert.assertEquals(2, (int) s.get(2));        Assert.assertTrue(s.containsKey(3));        Assert.assertEquals(1, (int) s.get(3));    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_INIT(['one','two','three','two'])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.containsKey("one"));        Assert.assertEquals(1, (int) s.get("one"));        Assert.assertTrue(s.containsKey("two"));        Assert.assertEquals(2, (int) s.get("two"));        Assert.assertTrue(s.containsKey("three"));        Assert.assertEquals(1, (int) s.get("three"));    }}
0
public void multisetAddTest() throws Exception
{    {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_ADD(MULTISET_INIT(), 1)", new HashMap<>());        Assert.assertEquals(1, s.size());        Assert.assertTrue(s.containsKey(1));        Assert.assertEquals(1, (int) s.get(1));    }    {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_ADD(null, 1)", new HashMap<>());        Assert.assertEquals(1, s.size());        Assert.assertTrue(s.containsKey(1));        Assert.assertEquals(1, (int) s.get(1));    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_ADD(MULTISET_INIT([1,2,3,4,4]), 4)", new HashMap<>());        Assert.assertEquals(4, s.size());        Assert.assertTrue(s.containsKey(1));        Assert.assertEquals(1, (int) s.get(1));        Assert.assertTrue(s.containsKey(2));        Assert.assertEquals(1, (int) s.get(2));        Assert.assertTrue(s.containsKey(3));        Assert.assertEquals(1, (int) s.get(3));        Assert.assertTrue(s.containsKey(4));        Assert.assertEquals(3, (int) s.get(4));    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_ADD(MULTISET_INIT(['one','two','three', 'four', 'four']), 'four')", new HashMap<>());        Assert.assertEquals(4, s.size());        Assert.assertTrue(s.containsKey("one"));        Assert.assertEquals(1, (int) s.get("one"));        Assert.assertTrue(s.containsKey("two"));        Assert.assertEquals(1, (int) s.get("two"));        Assert.assertTrue(s.containsKey("three"));        Assert.assertEquals(1, (int) s.get("three"));        Assert.assertTrue(s.containsKey("four"));        Assert.assertEquals(3, (int) s.get("four"));    }}
0
public void multisetRemoveTest() throws Exception
{    {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_REMOVE(MULTISET_INIT([1]), 1)", new HashMap<>());        Assert.assertEquals(0, s.size());    }    {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_REMOVE(null, 1)", new HashMap<>());        Assert.assertEquals(0, s.size());    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_REMOVE(MULTISET_INIT([1,2,3,2]), 2)", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.containsKey(1));        Assert.assertEquals(1, (int) s.get(1));        Assert.assertTrue(s.containsKey(2));        Assert.assertEquals(1, (int) s.get(2));        Assert.assertTrue(s.containsKey(3));        Assert.assertEquals(1, (int) s.get(3));    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_REMOVE(MULTISET_INIT(['one','two','three', 'two']), 'two')", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.containsKey("one"));        Assert.assertEquals(1, (int) s.get("one"));        Assert.assertTrue(s.containsKey("two"));        Assert.assertEquals(1, (int) s.get("two"));        Assert.assertTrue(s.containsKey("three"));        Assert.assertEquals(1, (int) s.get("three"));    }}
0
public void multisetMergeTest_wrongType() throws Exception
{    Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_MERGE({ 'bar' : 'foo' } )", new HashMap<>());}
0
public void multisetMergeTest() throws Exception
{    {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_MERGE([MULTISET_INIT(), MULTISET_INIT(null), null])", new HashMap<>());        Assert.assertEquals(0, s.size());    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_MERGE([MULTISET_INIT([1,2]), MULTISET_INIT([2,3]), null, MULTISET_INIT()])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.containsKey(1));        Assert.assertEquals(1, (int) s.get(1));        Assert.assertTrue(s.containsKey(2));        Assert.assertEquals(2, (int) s.get(2));        Assert.assertTrue(s.containsKey(3));        Assert.assertEquals(1, (int) s.get(3));    }        {        Map<Object, Integer> s = (Map<Object, Integer>) StellarProcessorUtils.run("MULTISET_MERGE([MULTISET_INIT(['one','two']), MULTISET_INIT(['two', 'three'])])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.containsKey("one"));        Assert.assertEquals(1, (int) s.get("one"));        Assert.assertTrue(s.containsKey("two"));        Assert.assertEquals(2, (int) s.get("two"));        Assert.assertTrue(s.containsKey("three"));        Assert.assertEquals(1, (int) s.get("three"));    }}
0
public void setInitTest_wrongType() throws Exception
{    Set s = (Set) StellarProcessorUtils.run("SET_INIT({ 'foo' : 2})", new HashMap<>());}
0
public void setInitTest() throws Exception
{    {        Set s = (Set) StellarProcessorUtils.run("SET_INIT()", new HashMap<>());        Assert.assertEquals(0, s.size());    }        {        Set s = (Set) StellarProcessorUtils.run("SET_INIT([1,2,3])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.contains(1));        Assert.assertTrue(s.contains(2));        Assert.assertTrue(s.contains(3));    }        {        Set s = (Set) StellarProcessorUtils.run("SET_INIT(['one','two','three'])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.contains("one"));        Assert.assertTrue(s.contains("two"));        Assert.assertTrue(s.contains("three"));    }}
0
public void multisetToSetTest() throws Exception
{    {        Set s = (Set) StellarProcessorUtils.run("MULTISET_TO_SET(MULTISET_ADD(MULTISET_INIT(), 1))", new HashMap<>());        Assert.assertEquals(1, s.size());        Assert.assertTrue(s.contains(1));    }    {        Set s = (Set) StellarProcessorUtils.run("MULTISET_TO_SET(MULTISET_ADD(null, 1))", new HashMap<>());        Assert.assertEquals(1, s.size());        Assert.assertTrue(s.contains(1));    }        {        Set s = (Set) StellarProcessorUtils.run("MULTISET_TO_SET(MULTISET_ADD(MULTISET_INIT([1,2,3]), 4))", new HashMap<>());        Assert.assertEquals(4, s.size());        Assert.assertTrue(s.contains(1));        Assert.assertTrue(s.contains(2));        Assert.assertTrue(s.contains(3));        Assert.assertTrue(s.contains(4));    }        {        Set s = (Set) StellarProcessorUtils.run("MULTISET_TO_SET(MULTISET_ADD(MULTISET_INIT(['one','two','three']), 'four'))", new HashMap<>());        Assert.assertEquals(4, s.size());        Assert.assertTrue(s.contains("one"));        Assert.assertTrue(s.contains("two"));        Assert.assertTrue(s.contains("three"));        Assert.assertTrue(s.contains("four"));    }}
0
public void setAddTest() throws Exception
{    {        Set s = (Set) StellarProcessorUtils.run("SET_ADD(SET_INIT(), 1)", new HashMap<>());        Assert.assertEquals(1, s.size());        Assert.assertTrue(s.contains(1));    }    {        Set s = (Set) StellarProcessorUtils.run("SET_ADD(null, 1)", new HashMap<>());        Assert.assertEquals(1, s.size());        Assert.assertTrue(s.contains(1));    }        {        Set s = (Set) StellarProcessorUtils.run("SET_ADD(SET_INIT([1,2,3]), 4)", new HashMap<>());        Assert.assertEquals(4, s.size());        Assert.assertTrue(s.contains(1));        Assert.assertTrue(s.contains(2));        Assert.assertTrue(s.contains(3));        Assert.assertTrue(s.contains(4));    }        {        Set s = (Set) StellarProcessorUtils.run("SET_ADD(SET_INIT(['one','two','three']), 'four')", new HashMap<>());        Assert.assertEquals(4, s.size());        Assert.assertTrue(s.contains("one"));        Assert.assertTrue(s.contains("two"));        Assert.assertTrue(s.contains("three"));        Assert.assertTrue(s.contains("four"));    }}
0
public void setRemoveTest() throws Exception
{    {        Set s = (Set) StellarProcessorUtils.run("SET_REMOVE(SET_INIT([1]), 1)", new HashMap<>());        Assert.assertEquals(0, s.size());    }    {        Set s = (Set) StellarProcessorUtils.run("SET_REMOVE(null, 1)", new HashMap<>());        Assert.assertEquals(0, s.size());    }        {        Set s = (Set) StellarProcessorUtils.run("SET_REMOVE(SET_INIT([1,2,3]), 2)", new HashMap<>());        Assert.assertEquals(2, s.size());        Assert.assertTrue(s.contains(1));        Assert.assertTrue(s.contains(3));    }        {        Set s = (Set) StellarProcessorUtils.run("SET_REMOVE(SET_INIT(['one','two','three']), 'three')", new HashMap<>());        Assert.assertEquals(2, s.size());        Assert.assertTrue(s.contains("one"));        Assert.assertTrue(s.contains("two"));    }}
0
public void setMergeTest_wrongType() throws Exception
{    Set s = (Set) StellarProcessorUtils.run("SET_MERGE({ 'foo' : 'bar'} )", new HashMap<>());}
0
public void setMergeTest() throws Exception
{    {        Set s = (Set) StellarProcessorUtils.run("SET_MERGE([SET_INIT(), SET_INIT(null), null])", new HashMap<>());        Assert.assertEquals(0, s.size());    }        {        Set s = (Set) StellarProcessorUtils.run("SET_MERGE([SET_INIT([1,2]), SET_INIT([3]), null, SET_INIT()])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.contains(1));        Assert.assertTrue(s.contains(2));        Assert.assertTrue(s.contains(3));    }        {        Set s = (Set) StellarProcessorUtils.run("SET_MERGE([SET_INIT(['one','two']), SET_INIT(['three'])])", new HashMap<>());        Assert.assertEquals(3, s.size());        Assert.assertTrue(s.contains("one"));        Assert.assertTrue(s.contains("two"));        Assert.assertTrue(s.contains("three"));    }}
0
public void testListVarsWithVars()
{    Map<String, VariableResult> variables = ImmutableMap.of("foo", VariableResult.withExpression(2.0, "1 + 1"));    Context context = new Context.Builder().with(Context.Capabilities.SHELL_VARIABLES, () -> variables).build();    Object out = run("SHELL_LIST_VARS()", new HashMap<>(), context);    Assert.assertEquals(expectedListWithFoo, out);}
0
public void testListVarsWithoutVars()
{    Context context = new Context.Builder().with(Context.Capabilities.SHELL_VARIABLES, () -> new HashMap<>()).build();    Object out = run("SHELL_LIST_VARS()", new HashMap<>(), context);    Assert.assertEquals(expectedEmptyList, out);}
0
public void testMap2Table()
{    Map<String, Object> variables = ImmutableMap.of("map_field", ImmutableMap.of("field1", "val1", "field2", "val2"));    Context context = Context.EMPTY_CONTEXT();    Object out = run("SHELL_MAP2TABLE(map_field)", variables, context);    Assert.assertEquals(expectedMap2Table, out);}
0
public void testMap2TableNullInput()
{    Map<String, Object> variables = new HashMap<String, Object>() {        {            put("map_field", null);        }    };    Context context = Context.EMPTY_CONTEXT();    Object out = run("SHELL_MAP2TABLE(map_field)", variables, context);    Assert.assertEquals(expectedMap2TableNullInput, out);}
0
public void testMap2TableInsufficientArgs()
{    Map<String, Object> variables = new HashMap<>();    Context context = Context.EMPTY_CONTEXT();    Object out = run("SHELL_MAP2TABLE()", variables, context);    Assert.assertNull(out);}
0
public void testVars2Map()
{    Object out = run("SHELL_VARS2MAP('var1', 'var2')", new HashMap<>(), context);    Assert.assertTrue(out instanceof Map);    Map<String, String> mapOut = (Map<String, String>) out;        Assert.assertEquals(1, mapOut.size());    Assert.assertEquals("TO_UPPER('casey')", mapOut.get("var1"));}
0
public void testVars2MapEmpty()
{    Object out = run("SHELL_VARS2MAP()", new HashMap<>(), context);    Map<String, String> mapOut = (Map<String, String>) out;    Assert.assertEquals(0, mapOut.size());}
0
public void testGetExpression()
{    Object out = run("SHELL_GET_EXPRESSION('var1')", new HashMap<>(), context);    Assert.assertTrue(out instanceof String);    String expression = (String) out;        Assert.assertEquals("TO_UPPER('casey')", expression);}
0
public void testGetExpressionEmpty()
{    Object out = run("SHELL_GET_EXPRESSION()", new HashMap<>(), context);    Assert.assertNull(out);}
0
public void testEdit() throws Exception
{    System.getProperties().put("EDITOR", "/bin/cat");    Object out = run("TO_UPPER(SHELL_EDIT(foo))", ImmutableMap.of("foo", "foo"), context);    Assert.assertEquals("FOO", out);}
0
public void testStringFunctions() throws Exception
{    final Map<String, String> variableMap = new HashMap<String, String>() {        {            put("foo", "casey");            put("ip", "192.168.0.1");            put("empty", "");            put("spaced", "metron is great");        }    };    Assert.assertTrue(runPredicate("true and TO_UPPER(foo) == 'CASEY'", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in [ TO_LOWER('CASEY'), 'david' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("TO_UPPER(foo) in [ TO_UPPER('casey'), 'david' ] and IN_SUBNET(ip, '192.168.0.0/24')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("TO_LOWER(foo) in [ TO_UPPER('casey'), 'david' ]", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testStringFunctions_advanced() throws Exception
{    final Map<String, Object> variableMap = new HashMap<String, Object>() {        {            put("foo", "casey");            put("bar", "bar.casey.grok");            put("ip", "192.168.0.1");            put("empty", "");            put("spaced", "metron is great");            put("myList", ImmutableList.of("casey", "apple", "orange"));        }    };    Assert.assertTrue(runPredicate("foo in SPLIT(bar, '.')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("foo in SPLIT(ip, '.')", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("foo in myList", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertFalse(runPredicate("foo not in myList", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testLeftRightFills() throws Exception
{    final Map<String, Object> variableMap = new HashMap<String, Object>() {        {            put("foo", null);            put("bar", null);            put("notInt", "oh my");        }    };        Object left = run("FILL_LEFT('123','X', 10)", new HashedMap());    Assert.assertNotNull(left);    Assert.assertEquals(10, ((String) left).length());    Assert.assertEquals("XXXXXXX123", (String) left);        Object right = run("FILL_RIGHT('123','X', 10)", new HashedMap());    Assert.assertNotNull(right);    Assert.assertEquals(10, ((String) right).length());    Assert.assertEquals("123XXXXXXX", (String) right);        Object same = run("FILL_RIGHT('123','X', 3)", new HashedMap());    Assert.assertEquals(3, ((String) same).length());    Assert.assertEquals("123", (String) same);        Object tooBig = run("FILL_RIGHT('1234567890','X', 3)", new HashedMap());    Assert.assertEquals(10, ((String) tooBig).length());    Assert.assertEquals("1234567890", (String) tooBig);        boolean thrown = false;    try {        run("FILL_RIGHT('123',foo,bar)", variableMap);    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("are both required"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("FILL_RIGHT('123','X',bar)", variableMap);    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("are both required"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("FILL_RIGHT('123',foo, 7)", variableMap);    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("are both required"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("FILL_RIGHT('123','X', 'z' )", new HashedMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("not a valid Integer"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        Object returnValue = run("FILL_RIGHT('123','', 10 )", new HashedMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("cannot be an empty"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("FILL_RIGHT('123',foo)", variableMap);    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("expects three"));    }    Assert.assertTrue(thrown);}
0
public void shannonEntropyTest() throws Exception
{        Assert.assertEquals(0.0, (Double) run("STRING_ENTROPY('')", new HashMap<>()), 0.0);    Assert.assertEquals(0.0, (Double) run("STRING_ENTROPY(foo)", ImmutableMap.of("foo", "")), 0.0);    /*    Now consider the string aaaaaaaaaabbbbbccccc or 10 a's followed by 5 b's and 5 c's.    The probabilities of each character is as follows:    p(a) = 1/2    p(b) = 1/4    p(c) = 1/4    so the shannon entropy should be      -p(a)*log_2(p(a)) - p(b)*log_2(p(b)) - p(c)*log_2(p(c)) =      -0.5*-1 - 0.25*-2 - 0.25*-2 = 1.5     */    Assert.assertEquals(1.5, (Double) run("STRING_ENTROPY(foo)", ImmutableMap.of("foo", "aaaaaaaaaabbbbbccccc")), 0.0);}
0
public void testFormat() throws Exception
{    Map<String, Object> vars = ImmutableMap.of("cal", new Calendar.Builder().setDate(2017, 02, 02).build(), "x", 234, "y", 3);    Assert.assertEquals("no args", run("FORMAT('no args')", vars));    Assert.assertEquals("234.0", run("FORMAT('%.1f', TO_DOUBLE(234))", vars));    Assert.assertEquals("000234", run("FORMAT('%06d', 234)", vars));    Assert.assertEquals("03 2,2017", run("FORMAT('%1$tm %1$te,%1$tY', cal)", vars));    Assert.assertEquals("234 > 3", run("FORMAT('%d > %d', x, y)", vars));    boolean thrown = false;    try {        run("FORMAT('missing: %d', missing)", vars);    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);}
0
public void testFormatWithNoArguments() throws Exception
{    run("FORMAT()", Collections.emptyMap());}
0
public void testFormatWithMissingArguments() throws Exception
{    run("FORMAT('missing arg: %d')", Collections.emptyMap());}
0
public void testChomp() throws Exception
{    Assert.assertEquals("abc", run("CHOMP('abc')", new HashedMap()));    Assert.assertEquals("abc", run("CHOMP(msg)", ImmutableMap.of("msg", "abc\r\n")));    Assert.assertEquals("", run("CHOMP(msg)", ImmutableMap.of("msg", "\n")));    Assert.assertEquals("", run("CHOMP('')", new HashedMap()));    Assert.assertEquals(null, run("CHOMP(null)", new HashedMap()));        boolean thrown = false;    try {        run("CHOMP()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("missing argument"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("CHOMP(msg)", new HashedMap());    } catch (ParseException pe) {        thrown = true;    }    thrown = false;        try {        run("CHOMP(123)", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("cannot be cast"));    }    Assert.assertTrue(thrown);}
0
public void testChop() throws Exception
{    Assert.assertEquals("ab", run("CHOP('abc')", new HashedMap()));    Assert.assertEquals(null, run("CHOP(null)", new HashedMap()));    Assert.assertEquals("abc", run("CHOP(msg)", ImmutableMap.of("msg", "abc\r\n")));    Assert.assertEquals("", run("CHOP(msg)", ImmutableMap.of("msg", "")));    Assert.assertEquals("", run("CHOP(msg)", ImmutableMap.of("msg", "\n")));    Assert.assertEquals("", run("CHOP('')", new HashedMap()));        boolean thrown = false;    try {        run("CHOP()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("missing argument"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("CHOMP(msg)", new HashedMap());    } catch (ParseException pe) {        thrown = true;    }    thrown = false;        try {        run("CHOP(123)", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("cannot be cast"));    }    Assert.assertTrue(thrown);}
0
public void testPrependIfMissing() throws Exception
{    Assert.assertEquals("xyzabc", run("PREPEND_IF_MISSING('abc', 'xyz')", new HashedMap()));    Assert.assertEquals("xyzXYZabc", run("PREPEND_IF_MISSING('XYZabc', 'xyz', 'mno')", new HashedMap()));    Assert.assertEquals("mnoXYZabc", run("PREPEND_IF_MISSING('mnoXYZabc', 'xyz', 'mno')", new HashedMap()));    Assert.assertEquals(null, run("PREPEND_IF_MISSING(null, null, null)", new HashedMap()));    Assert.assertEquals("xyz", run("PREPEND_IF_MISSING('', 'xyz', null)", new HashedMap()));        boolean thrown = false;    try {        run("PREPEND_IF_MISSING()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("PREPEND_IF_MISSING('abc')", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("PREPEND_IF_MISSING('abc', 'def', 'ghi', 'jkl')", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("PREPEND_IF_MISSING(123, 'abc')", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("cannot be cast"));    }    Assert.assertTrue(thrown);}
0
public void testAppendIfMissing() throws Exception
{    Assert.assertEquals("apachemetron", run("APPEND_IF_MISSING('apache', 'metron')", new HashedMap()));    Assert.assertEquals("abcXYZxyz", run("APPEND_IF_MISSING('abcXYZ', 'xyz', 'mno')", new HashedMap()));    Assert.assertEquals(null, run("APPEND_IF_MISSING(null, null, null)", new HashedMap()));    Assert.assertEquals("xyz", run("APPEND_IF_MISSING('', 'xyz', null)", new HashedMap()));        boolean thrown = false;    try {        run("APPEND_IF_MISSING()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("APPEND_IF_MISSING('abc')", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("APPEND_IF_MISSING('abc', 'def', 'ghi', 'jkl')", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("APPEND_IF_MISSING(123, 'abc')", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("cannot be cast"));    }    Assert.assertTrue(thrown);}
0
public void testSubstring() throws Exception
{    Map<String, Object> variables = ImmutableMap.of("s", "apache metron");    Assert.assertEquals("metron", run("SUBSTRING(s, 7)", variables));    Assert.assertEquals("me", run("SUBSTRING(s, 7, 9)", variables));    Assert.assertNull(run("SUBSTRING(null, 7, 9)", new HashMap<>()));    Assert.assertNull(run("SUBSTRING(null, null, 9)", new HashMap<>()));    Assert.assertNull(run("SUBSTRING(s, null, 9)", variables));    Assert.assertNull(run("SUBSTRING(null, null, null)", new HashMap<>()));    Assert.assertEquals("metron", run("SUBSTRING(s, 7, null)", variables));}
0
public void testSubstring_invalidEmpty() throws Exception
{    Assert.assertEquals("metron", run("SUBSTRING()", new HashMap<>()));}
0
public void testSubstring_invalidWrongTypeStart() throws Exception
{    Map<String, Object> variables = ImmutableMap.of("s", "apache metron");    Assert.assertEquals("metron", (String) run("SUBSTRING(s, '7')", variables));}
0
public void testSubstring_invalidWrongTypeEnd() throws Exception
{    Map<String, Object> variables = ImmutableMap.of("s", "apache metron");    Assert.assertEquals("metron", (String) run("SUBSTRING(s, 7, '9')", variables));}
0
public void testSubstring_invalidWrongTypeInput() throws Exception
{    Map<String, Object> variables = ImmutableMap.of("s", 7);    Assert.assertEquals("metron", (String) run("SUBSTRING(s, 7, '9')", variables));}
0
public void testCountMatches() throws Exception
{    Assert.assertEquals(0, (int) run("COUNT_MATCHES(null, '*')", new HashedMap()));    Assert.assertEquals(2, (int) run("COUNT_MATCHES('apachemetron', 'e')", new HashedMap()));    Assert.assertEquals(2, (int) run("COUNT_MATCHES('anand', 'an')", new HashedMap()));    Assert.assertEquals(0, (int) run("COUNT_MATCHES('abcd', null)", new HashedMap()));        boolean thrown = false;    try {        run("COUNT_MATCHES()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("COUNT_MATCHES('abc')", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("incorrect arguments"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("COUNT_MATCHES(123, 456)", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("cannot be cast"));    }    Assert.assertTrue(thrown);}
0
public void testToJsonObject() throws Exception
{        Object ret1 = run("TO_JSON_OBJECT(msg)", ImmutableMap.of("msg", string1));    Assert.assertNotNull(ret1);    Assert.assertTrue(ret1 instanceof HashMap);    Object ret2 = run("TO_JSON_OBJECT(msg)", ImmutableMap.of("msg", string2));    Assert.assertNotNull(ret2);    Assert.assertTrue(ret2 instanceof HashMap);    Assert.assertEquals("def", run("MAP_GET( 'bar', returnval)", ImmutableMap.of("returnval", ret2)));        Object ret3 = run("TO_JSON_OBJECT(msg)", ImmutableMap.of("msg", string3));    Assert.assertNotNull(ret3);    Assert.assertTrue(ret3 instanceof ArrayList);    List<Object> result3 = (List<Object>) ret3;    Assert.assertEquals(2, result3.get(1));    Object ret4 = run("TO_JSON_OBJECT(msg)", ImmutableMap.of("msg", string4));    Assert.assertNotNull(ret4);    Assert.assertTrue(ret4 instanceof ArrayList);    List<Object> result4 = (List<Object>) ret4;    Assert.assertEquals("car", result4.get(2));        Object ret5 = run("TO_JSON_OBJECT(msg)", ImmutableMap.of("msg", string5));    Assert.assertNotNull(ret5);    Assert.assertTrue(ret5 instanceof ArrayList);    List<List<Object>> result5 = (List<List<Object>>) ret5;    HashMap<String, String> results5Map1 = (HashMap) result5.get(0);    Assert.assertEquals("def", results5Map1.get("bar1"));    HashMap<String, String> results5Map2 = (HashMap) result5.get(1);    Assert.assertEquals("ghi", results5Map2.get("foo2"));        boolean thrown = false;    try {        run("TO_JSON_OBJECT()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("Unable to parse"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("TO_JSON_OBJECT('123, 456')", new HashedMap<>());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("Valid JSON string not supplied"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("TO_JSON_OBJECT('{\"foo\" : 2')", new HashedMap<>());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("Valid JSON string not supplied"));    }    Assert.assertTrue(thrown);    thrown = false;}
0
public void testToJsonMap() throws Exception
{        Object ret1 = run("TO_JSON_MAP(msg)", ImmutableMap.of("msg", string1));    Assert.assertNotNull(ret1);    Assert.assertTrue(ret1 instanceof HashMap);    Object ret2 = run("TO_JSON_MAP(msg)", ImmutableMap.of("msg", string2));    Assert.assertNotNull(ret2);    Assert.assertTrue(ret2 instanceof HashMap);    Assert.assertEquals("def", run("MAP_GET( 'bar', returnval)", ImmutableMap.of("returnval", ret2)));        boolean thrown = false;    try {        Object o = run("TO_JSON_MAP(msg)", ImmutableMap.of("msg", string3));        System.out.println(string3 + " == " + o);    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);    thrown = false;    try {        run("TO_JSON_MAP(msg)", ImmutableMap.of("msg", string4));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);        thrown = false;    try {        run("TO_JSON_MAP(msg)", ImmutableMap.of("msg", string5));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);        try {        run("TO_JSON_MAP()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("Unable to parse"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("TO_JSON_MAP('123, 456')", new HashedMap<>());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("is not a valid JSON string"));    }    Assert.assertTrue(thrown);    thrown = false;        try {        run("TO_JSON_MAP('{\"foo\" : 2')", new HashedMap<>());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("is not a valid JSON string"));    }    Assert.assertTrue(thrown);    thrown = false;}
0
public void testToJsonList() throws Exception
{        Object ret3 = run("TO_JSON_LIST(msg)", ImmutableMap.of("msg", string3));    Assert.assertNotNull(ret3);    Assert.assertTrue(ret3 instanceof ArrayList);    List<Object> result3 = (List<Object>) ret3;    Assert.assertEquals(2, result3.get(1));    Object ret4 = run("TO_JSON_LIST(msg)", ImmutableMap.of("msg", string4));    Assert.assertNotNull(ret4);    Assert.assertTrue(ret4 instanceof ArrayList);    List<Object> result4 = (List<Object>) ret4;    Assert.assertEquals("car", result4.get(2));        Object ret5 = run("TO_JSON_LIST(msg)", ImmutableMap.of("msg", string5));    Assert.assertNotNull(ret5);    Assert.assertTrue(ret5 instanceof ArrayList);    List<List<Object>> result5 = (List<List<Object>>) ret5;    HashMap<String, String> results5Map1 = (HashMap) result5.get(0);    Assert.assertEquals("def", results5Map1.get("bar1"));    HashMap<String, String> results5Map2 = (HashMap) result5.get(1);    Assert.assertEquals("ghi", results5Map2.get("foo2"));        boolean thrown = false;    try {        run("TO_JSON_LIST(msg)", ImmutableMap.of("msg", string1));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);    thrown = false;    try {        run("TO_JSON_LIST(msg)", ImmutableMap.of("msg", string2));    } catch (ParseException pe) {        thrown = true;    }    Assert.assertTrue(thrown);        thrown = false;    try {        run("TO_JSON_LIST()", Collections.emptyMap());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("Unable to parse"));    }    Assert.assertTrue(thrown);        thrown = false;    try {        run("TO_JSON_LIST('123, 456')", new HashedMap<>());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("is not a valid JSON string"));    }    Assert.assertTrue(thrown);        thrown = false;    try {        run("TO_JSON_LIST('{\"foo\" : 2')", new HashedMap<>());    } catch (ParseException pe) {        thrown = true;        Assert.assertTrue(pe.getMessage().contains("is not a valid JSON string"));    }    Assert.assertTrue(thrown);}
0
public void smoke_test_non_mocked_env()
{    SystemFunctions.EnvGet envGet = new SystemFunctions.EnvGet();    String envVal = (String) envGet.apply(ImmutableList.of("ENV_GET_VAR"));    assertThat("Value should not exist", envVal, equalTo(null));}
0
public void env_get_returns_value()
{    Environment env = mock(Environment.class);    when(env.get("ENV_GET_VAR")).thenReturn("ENV_GET_VALUE");    SystemFunctions.EnvGet envGet = new SystemFunctions.EnvGet(env);    String envVal = (String) envGet.apply(ImmutableList.of("ENV_GET_VAR"));    assertThat("Value should match", envVal, equalTo("ENV_GET_VALUE"));}
0
public void env_get_returns_null_if_key_is_not_string()
{    SystemFunctions.EnvGet envGet = new SystemFunctions.EnvGet();    String envVal = (String) envGet.apply(ImmutableList.of(new ArrayList()));    assertThat("Value should be null", envVal, equalTo(null));}
0
public void property_get_returns_value()
{    System.getProperties().put("ENV_GET_VAR", "ENV_GET_VALUE");    SystemFunctions.PropertyGet propertyGet = new SystemFunctions.PropertyGet();    String propertyVal = (String) propertyGet.apply(ImmutableList.of("ENV_GET_VAR"));    assertThat("Value should match", propertyVal, equalTo("ENV_GET_VALUE"));}
0
public void property_get_nonexistent_returns_null()
{    SystemFunctions.PropertyGet propertyGet = new SystemFunctions.PropertyGet();    String propertyVal = (String) propertyGet.apply(ImmutableList.of("PROPERTY_MISSING"));    assertThat("Value should not exist", propertyVal, equalTo(null));}
0
public void property_get_returns_null_if_key_is_not_string()
{    SystemFunctions.PropertyGet propertyGet = new SystemFunctions.PropertyGet();    String propertyVal = (String) propertyGet.apply(ImmutableList.of(new ArrayList()));    assertThat("Value should be null", propertyVal, equalTo(null));}
0
public void testGetAvailableLanguageTags()
{    Object ret = run("FUZZY_LANGS()", new HashMap<>());    Assert.assertNotNull(ret);    Assert.assertTrue(ret instanceof List);    List<String> tags = (List<String>) ret;    Assert.assertTrue(tags.size() > 0);    Assert.assertTrue(tags.contains("en"));    Assert.assertTrue(tags.contains("fr"));}
0
public void testNoMatchStrings() throws Exception
{    Assert.assertTrue(runPredicate("0 == FUZZY_SCORE(metron,'z',english)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testMissingLanguage() throws Exception
{    runPredicate("0 == FUZZY_SCORE(metron,'z',klingon)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v)));}
0
public void testEmptyFirstArg() throws Exception
{    Assert.assertTrue(runPredicate("0 == FUZZY_SCORE(empty,'z',english)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testEmptyFirstTwoArgs() throws Exception
{    Assert.assertTrue(runPredicate("0 == FUZZY_SCORE(empty,empty,english)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void testEmptyArgs() throws Exception
{    runPredicate("0 == FUZZY_SCORE(empty,empty,empty)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v)));}
0
public void testNoArgs() throws Exception
{    runPredicate("0 == FUZZY_SCORE()", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v)));}
0
public void testHappyStringFunctions() throws Exception
{    Assert.assertTrue(runPredicate("1 == FUZZY_SCORE(metron,'m',english)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("16 == FUZZY_SCORE(metron,'metron',english)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));    Assert.assertTrue(runPredicate("3 == FUZZY_SCORE(asf,'asf',english)", new DefaultVariableResolver(v -> variableMap.get(v), v -> variableMap.containsKey(v))));}
0
public void open()
{    try {                this.autoCompleter = new DefaultStellarAutoCompleter();                Properties props = getProperty();        this.executor = createExecutor(props);    } catch (Exception e) {                throw new RuntimeException(e);    }}
1
public void close()
{}
0
public InterpreterResult interpret(final String input, InterpreterContext context)
{    InterpreterResult result = new InterpreterResult(SUCCESS, TEXT, "");    try {                String[] expressions = input.split(System.lineSeparator());        for (String expression : expressions) {            result = execute(expression);        }    } catch (Throwable t) {                String message = getErrorMessage(Optional.of(t), input);        result = new InterpreterResult(ERROR, TEXT, message);    }        return result;}
0
private InterpreterResult execute(final String expression)
{    InterpreterResult result;        StellarResult stellarResult = executor.execute(expression);    if (stellarResult.isSuccess()) {                Object value = stellarResult.getValue().orElse("");        String text = value.toString();        result = new InterpreterResult(SUCCESS, TEXT, text);    } else if (stellarResult.isError()) {                Optional<Throwable> e = stellarResult.getException();        String message = getErrorMessage(e, expression);        result = new InterpreterResult(ERROR, TEXT, message);    } else {                throw new IllegalStateException("Unexpected error. result=" + stellarResult);    }    return result;}
0
public void cancel(InterpreterContext context)
{}
0
public FormType getFormType()
{    return FormType.SIMPLE;}
0
public int getProgress(InterpreterContext context)
{        return 0;}
0
public List<InterpreterCompletion> completion(String buf, int cursor)
{        List<InterpreterCompletion> completes = new ArrayList<>();    for (String candidate : autoCompleter.autoComplete(buf)) {        completes.add(new InterpreterCompletion(candidate, candidate));    }    return completes;}
0
private String getErrorMessage(Optional<Throwable> e, String input)
{    String message;    if (e.isPresent()) {                String error = ExceptionUtils.getRootCauseMessage(e.get());        String trace = ExceptionUtils.getStackTrace(e.get());        message = error + System.lineSeparator() + trace;    } else {                message = "Invalid expression: " + input;    }    return message;}
0
private StellarShellExecutor createExecutor(Properties properties) throws Exception
{        String zookeeperURL = StellarInterpreterProperty.ZOOKEEPER_URL.get(properties, String.class);    StellarShellExecutor executor = new DefaultStellarShellExecutor(properties, Optional.ofNullable(zookeeperURL));        executor.addSpecialListener((magic) -> autoCompleter.addCandidateFunction(magic.getCommand()));    executor.addFunctionListener((fn) -> autoCompleter.addCandidateFunction(fn.getName()));    executor.addVariableListener((name, val) -> autoCompleter.addCandidateVariable(name));    executor.init();    return executor;}
0
public StellarShellExecutor getExecutor()
{    return executor;}
0
public String getKey()
{    return key;}
0
public T getDefault(Class<T> clazz)
{    return ConversionUtils.convert(defaultValue, clazz);}
0
public T get(Map<Object, Object> properties, Class<T> clazz)
{    Object o = properties.getOrDefault(key, defaultValue);    return o == null ? null : ConversionUtils.convert(o, clazz);}
0
public String toString()
{    return key;}
0
public void start() throws UnableToStartException
{    try {        upload();    } catch (Exception e) {        throw new UnableToStartException(e.getMessage(), e);    }}
0
public void stop()
{}
0
private void upload() throws Exception
{    assert zookeeperURL != null;    try (CuratorFramework client = getClient(zookeeperURL)) {        if (client.getState() != CuratorFrameworkState.STARTED) {            client.start();        }        if (globals != null) {            writeGlobalConfigToZookeeper(globals, client);        }    }}
0
public ConfigUploadComponent withZookeeperURL(String zookeeperURL)
{    this.zookeeperURL = zookeeperURL;    return this;}
0
public ConfigUploadComponent withGlobals(Map<String, Object> globals)
{    this.globals = globals;    return this;}
0
public void setup() throws Exception
{        Map<String, Object> globals = new HashMap<>();    ConfigUploadComponent configUploader = new ConfigUploadComponent().withGlobals(globals);        properties = new Properties();    zkServer = getZKServerComponent(properties);        zkServer.withPostStartCallback((zk) -> {        zookeeperURL = zk.getConnectionString();        configUploader.withZookeeperURL(zookeeperURL);    });        runner = new ComponentRunner.Builder().withComponent("zk", zkServer).withComponent("config", configUploader).build();    runner.start();    context = mock(InterpreterContext.class);}
0
public void tearDown() throws Exception
{    runner.stop();}
0
public void testOpenWithZookeeperURL()
{        Properties props = new Properties();    props.put(ZOOKEEPER_URL.toString(), zookeeperURL);        interpreter = new StellarInterpreter(props);    interpreter.open();        Optional<Object> zk = interpreter.getExecutor().getContext().getCapability(Context.Capabilities.ZOOKEEPER_CLIENT, false);    assertTrue(zk.isPresent());}
0
public void testGet()
{        final String expected = "zookeeper:2181";    Map<Object, Object> props = Collections.singletonMap("zookeeper.url", expected);        String actual = ZOOKEEPER_URL.get(props, String.class);    assertEquals(expected, actual);}
0
public void testGetWhenPropertyNotDefined()
{        Map<Object, Object> props = Collections.singletonMap("foo", "bar");    String actual = ZOOKEEPER_URL.get(props, String.class);        String expected = ZOOKEEPER_URL.getDefault(String.class);    assertEquals(expected, actual);}
0
public void setup()
{    Properties props = new Properties();    interpreter = new StellarInterpreter(props);    interpreter.open();    context = mock(InterpreterContext.class);}
0
public void testExecuteStellar()
{    InterpreterResult result = interpreter.interpret("2 + 2", context);        assertEquals(InterpreterResult.Code.SUCCESS, result.code());    assertEquals(1, result.message().size());        InterpreterResultMessage message = result.message().get(0);    assertEquals("4", message.getData());    assertEquals(InterpreterResult.Type.TEXT, message.getType());}
0
public void testExecuteWithStellarList()
{    final String expected = "[1, 2, 3, 4, 5]";    InterpreterResult result = interpreter.interpret("[1,2,3,4,5]", context);        assertEquals(InterpreterResult.Code.SUCCESS, result.code());    assertEquals(1, result.message().size());        InterpreterResultMessage message = result.message().get(0);    assertEquals(expected, message.getData());    assertEquals(InterpreterResult.Type.TEXT, message.getType());}
0
public void testExecuteWithStellarMap()
{    final String expected = "{foo=2, key=val}";    InterpreterResult result = interpreter.interpret("{ 'foo':2, 'key':'val' }", context);        assertEquals(InterpreterResult.Code.SUCCESS, result.code());    assertEquals(1, result.message().size());        InterpreterResultMessage message = result.message().get(0);    assertEquals(expected, message.getData());    assertEquals(InterpreterResult.Type.TEXT, message.getType());}
0
public void testExecuteBadStellar()
{    InterpreterResult result = interpreter.interpret("2 + ", context);        assertEquals(InterpreterResult.Code.ERROR, result.code());    assertEquals(1, result.message().size());        InterpreterResultMessage message = result.message().get(0);    assertTrue(message.getData().length() > 0);    assertEquals(InterpreterResult.Type.TEXT, message.getType());}
0
public void testExecuteNoop()
{        InterpreterResult result = interpreter.interpret("x", context);        assertEquals(InterpreterResult.Code.SUCCESS, result.code());    assertEquals(1, result.message().size());        InterpreterResultMessage message = result.message().get(0);    assertEquals(0, message.getData().length());    assertEquals(InterpreterResult.Type.TEXT, message.getType());}
0
public void testAutoCompletion()
{        final String buffer = "TO_";        int cursor = buffer.length();    List<InterpreterCompletion> completions = interpreter.completion(buffer, cursor);        assertTrue(completions.size() > 0);    for (InterpreterCompletion iCompletion : completions) {        String completion = iCompletion.getValue();                assertEquals("(", completion.substring(completion.length() - 1));                String function = completion.substring(0, completion.length() - 1);        Iterable<String> allFunctions = interpreter.getExecutor().getFunctionResolver().getFunctions();        String definedFunction = Iterables.find(allFunctions, (fn) -> StringUtils.equals(fn, function));        assertEquals(function, definedFunction);    }}
0
public void testAutoCompletionWithNoCompletions()
{        final String buffer = "NOTHING_AUTOCOMPLETES_THIS_";        int cursor = buffer.length();        List<InterpreterCompletion> completions = interpreter.completion(buffer, cursor);        assertEquals(0, completions.size());}
0
public void testOpenWithNoZookeeperURL()
{        Properties props = new Properties();        interpreter = new StellarInterpreter(props);    interpreter.open();        Optional<Object> zk = interpreter.getExecutor().getContext().getCapability(Context.Capabilities.ZOOKEEPER_CLIENT, false);    assertFalse(zk.isPresent());}
0
public void testExecuteStellarMultipleLines()
{        String input = "x := 2 + 2" + System.lineSeparator() + "y := 4 + 4";    InterpreterResult result = interpreter.interpret(input, context);        Map<String, VariableResult> vars = interpreter.getExecutor().getState();    assertEquals(4, vars.get("x").getResult());    assertEquals(8, vars.get("y").getResult());        assertEquals(InterpreterResult.Code.SUCCESS, result.code());    assertEquals(1, result.message().size());        InterpreterResultMessage message = result.message().get(0);    assertEquals("8", message.getData());    assertEquals(InterpreterResult.Type.TEXT, message.getType());}
0
